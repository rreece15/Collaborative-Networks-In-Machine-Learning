FN Clarivate Analytics Web of Science
VR 1.0
PT C
AU Li, RH
   Arora, A
   Li, SK
   Wu, QZ
   John, LK
AF Li, Ruihao
   Arora, Aman
   Li, Sikan
   Wu, Qinzhe
   John, Lizy K.
GP IEEE
TI Hardware-aware 3D Model Workload Selection and Characterization for
   Graphics and ML Applications
SO PROCEEDINGS OF THE TWENTY THIRD INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2022)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 23rd International Symposium on Quality Electronic Design (ISQED)
CY APR 06-07, 2022
CL Santa Jose, CA
AB 3D models are widely used in computer graphics, computer vision, and robotics applications. Multiple hardware accelerators are used for running 3D model related applications, since the computations required for models in 3D space are an order of magnitude higher than the computations in 2D space. Due to the high computation intensity of 3D model workloads, using large 3D model datasets for performance characterization is not a feasible choice during accelerator design. Representative subsets are widely used to save the execution or simulation time, e.g, ModelNet10, a subset of ModelNet40, is widely used in the machine learning (ML) domain to save training and inference time. However, this subset is picked by programmers from a software and application perspective.
   In this paper, we deploy statistical analysis based methodologies to guide the identification of hardware-aware representative subsets, which can maintain higher performance accuracy and achieve larger execution time savings with respect to subsets picked by software programmers. We believe that the methodology proposed in this paper can help hardware architects and engineers design efficient graphics or ML accelerators rapidly.
C1 [Li, Ruihao; Arora, Aman; Li, Sikan; Wu, Qinzhe; John, Lizy K.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Li, RH (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM liruihao@utexas.edu; aman.kbm@utexas.edu; sikanli@utexas.edu;
   qw2699@utexas.edu; ljohn@ece.utexas.edu
CR Nguyen A, 2013, PROCEEDINGS OF THE 2013 6TH IEEE CONFERENCE ON ROBOTICS, AUTOMATION AND MECHATRONICS (RAM), P225, DOI 10.1109/RAM.2013.6758588
   [Anonymous], LINUX PERF TOOL
   Behley J, 2015, IEEE INT CONF ROBOT, P3625, DOI 10.1109/ICRA.2015.7139702
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   BOTSCH M., 2010, POLYGON MESH PROCESS
   Burstedde C, 2011, SIAM J SCI COMPUT, V33, P1103, DOI 10.1137/100791634
   Deshmukh A, 2021, INT SYM PERFORM ANAL, P107, DOI 10.1109/ISPASS51385.2021.00028
   FRUCHTERMAN TMJ, 1991, SOFTWARE PRACT EXPER, V21, P1129, DOI 10.1002/spe.4380211102
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang WW, 2018, IEEE T COMPUT AID D, V37, P2542, DOI 10.1109/TCAD.2018.2857098
   Li RH, 2020, INT C HIGH PERFORM, P271, DOI 10.1109/HiPC50609.2020.00041
   Li YY, 2018, ADV NEUR IN, V31
   Maturana D, 2015, IEEE INT C INT ROBOT, P922, DOI 10.1109/IROS.2015.7353481
   Mo KC, 2019, PROC CVPR IEEE, P909, DOI 10.1109/CVPR.2019.00100
   N. Corporation, 2022, NVID CUD TOOLK DOC
   Panda R, 2018, INT S HIGH PERF COMP, P271, DOI 10.1109/HPCA.2018.00032
   Phansalkar A, 2007, CONF PROC INT SYMP C, P412, DOI 10.1145/1273440.1250713
   Prokopec A, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P31, DOI 10.1145/3314221.3314637
   Qi CR, 2017, PROC CVPR IEEE, P77, DOI 10.1109/CVPR.2017.16
   Qi CR, 2017, Arxiv, DOI [arXiv:1706.02413, DOI 10.48550/ARXIV.1706.02413]
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Sherwood T, 2002, ACM SIGPLAN NOTICES, V37, P45, DOI 10.1145/605432.605403
   SPEC org, 2021, WHAT IS REF MACH WHY
   Steder B, 2011, IEEE INT CONF ROBOT, P2601, DOI 10.1109/ICRA.2011.5980187
   Wang PS, 2017, ACM T GRAPHIC, V36, DOI 10.1145/3072959.3073608
   Wu ZR, 2015, PROC CVPR IEEE, P1912, DOI 10.1109/CVPR.2015.7298801
   Xie CH, 2019, INT S HIGH PERF COMP, P609, DOI 10.1109/HPCA.2019.00013
   Xie CH, 2017, INT S HIGH PERF COMP, P637, DOI 10.1109/HPCA.2017.37
   Xu TC, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P629, DOI 10.1145/3352460.3358259
   Zheng XN, 2016, DES AUT CON, DOI 10.1145/2897937.2897977
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 247
EP 254
DI 10.1109/ISQED54688.2022.9806296
WC Engineering, Biomedical; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Morijiri, K
   Takehana, K
   Mihana, T
   Kanno, K
   Naruse, M
   Uchida, A
AF Morijiri, Kensei
   Takehana, Kento
   Mihana, Takatomo
   Kanno, Kazutaka
   Naruse, Makoto
   Uchida, Atsushi
TI Parallel photonic accelerator for decision making using optical
   spatiotemporal chaos
SO OPTICA
DT Article
ID ARTIFICIAL-INTELLIGENCE
AB Photonic accelerators have attracted increasing attention for use in artificial intelligence applications. The multi-armed bandit problem is a fundamental problem of decision making using reinforcement learning. However, to the best of our knowledge, the scalability of photonic decision making has not yet been demonstrated in experiments because of the technical difficulties in the physical realization. We propose a parallel photonic decision-making system to solve large-scale multi-armed bandit problems using optical spatiotemporal chaos. We solved a 512-armed bandit problem online, which is larger than those in previous experiments by two orders of magnitude. The scaling property for correct decision making is examined as a function of the number of slot machines, evaluated as an exponent of 0.86. This exponent is smaller than that in previous studies, indicating the superiority of the proposed parallel principle. This experimental demonstration facilitates photonic decision making to solve large-scale multi-armed bandit problems for future photonic accelerators. (c) 2023 Optica Publishing Group under the terms of the Optica Open Access Publishing Agreement
C1 [Morijiri, Kensei; Takehana, Kento; Mihana, Takatomo; Kanno, Kazutaka; Uchida, Atsushi] Saitama Univ, Dept Informat & Comp Sci, 255 Shimo Okubo,Sakura Ku, Saitama City, Saitama 3388570, Japan.
   [Mihana, Takatomo; Naruse, Makoto] Univ Tokyo, Grad Sch Informat Sci & Technol, Dept Informat Phys & Comp, 7-3-1 Hongo,Bunkyo Ku, Tokyo 1138656, Japan.
RP Uchida, A (corresponding author), Saitama Univ, Dept Informat & Comp Sci, 255 Shimo Okubo,Sakura Ku, Saitama City, Saitama 3388570, Japan.
EM auchida@mail.saitama-u.ac.jp
CR Antonik P, 2019, NAT MACH INTELL, V1, P530, DOI 10.1038/s42256-019-0110-8
   Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Bueno J, 2018, OPTICA, V5, P756, DOI 10.1364/OPTICA.5.000756
   Chen XL, 2019, J LIGHTWAVE TECHNOL, V37, P4155, DOI 10.1109/JLT.2019.2923615
   Duan ZC, 2022, IEICE NONLINEAR THEO, V13, P72, DOI 10.1587/nolta.13.72
   El Gamal A, 2005, IEEE CIRCUITS DEVICE, V21, P6, DOI 10.1109/MCD.2005.1438751
   García-Ojalvo J, 2001, PHYS REV LETT, V86, P5204, DOI 10.1103/PhysRevLett.86.5204
   Genty G, 2021, NAT PHOTONICS, V15, P91, DOI 10.1038/s41566-020-00716-4
   Gong YZ, 2010, OPT EXPRESS, V18, P19743, DOI 10.1364/OE.18.019743
   Gupta S, 2021, IEEE T INFORM THEORY, V67, P6711, DOI 10.1109/TIT.2021.3081508
   Han YN, 2020, PHOTONICS RES, V8, P1792, DOI 10.1364/PRJ.403319
   Homma R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45754-3
   Horisaki R, 2018, APPL OPTICS, V57, P3859, DOI 10.1364/AO.57.003859
   IKEDA K, 1979, OPT COMMUN, V30, P257, DOI 10.1016/0030-4018(79)90090-7
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Ishihara T, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3178452
   Iwami R., 2022, SCI ADV, V8
   Kim SJ, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/8/083023
   Kim SJ, 2010, BIOSYSTEMS, V101, P29, DOI 10.1016/j.biosystems.2010.04.002
   Kima SJ, 2014, IEICE NONLINEAR THEO, V5, P198, DOI 10.1587/nolta.5.198
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kocsis L, 2006, LECT NOTES COMPUT SC, V4212, P282, DOI 10.1007/11871842_29
   Komuro T, 2003, IEEE T ELECTRON DEV, V50, P191, DOI 10.1109/TED.2002.807255
   Larger L, 2012, OPT EXPRESS, V20, P3241, DOI 10.1364/OE.20.003241
   Larger L, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.054103
   Mihana T, 2020, OPT EXPRESS, V28, P40112, DOI 10.1364/OE.411140
   Mihana T, 2019, OPT EXPRESS, V27, P26989, DOI 10.1364/OE.27.026989
   Mihana T, 2018, COMPLEXITY, DOI 10.1155/2018/4318127
   Morijiri K, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-12155-y
   Naruse M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29117-y
   Naruse M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08585-8
   Naruse M, 2016, ACS PHOTONICS, V3, P2505, DOI 10.1021/acsphotonics.6b00742
   Naruse M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13253
   Nguimdo RM, 2020, OPT EXPRESS, V28, P27989, DOI 10.1364/OE.400546
   Nose A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051313
   Oda A, 2022, IEICE NONLINEAR THEO, V13, P112, DOI 10.1587/nolta.13.112
   Rafayelyan M, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.041037
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Takabayashi M., 2019, P NOLTA, P477
   Takano K, 2018, OPT EXPRESS, V26, P29424, DOI 10.1364/OE.26.029424
   Takeuchi S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58541-2
   Talukder R., 2021, P IS PALD, P17
   Tang YH, 2022, NAT COMPUT SCI, V2, P169, DOI 10.1038/s43588-022-00215-2
   Tegin U, 2021, NAT COMPUT SCI, V1, P542, DOI 10.1038/s43588-021-00112-0
   Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.1093/biomet/25.3-4.285
   Uchida A., 2012, OPTICAL COMMUNICATIO, V1st
   Viarani L, 2004, IEEE SENS J, V4, P145, DOI 10.1109/JSEN.2003.822217
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
NR 55
TC 1
Z9 1
U1 6
U2 6
PD MAR 20
PY 2023
VL 10
IS 3
BP 339
EP 348
DI 10.1364/OPTICA.477433
WC Optics
DA 2023-11-11
ER

PT C
AU Zhu, ZH
   Lin, JL
   Cheng, M
   Xia, LX
   Sun, HB
   Chen, XM
   Wang, Y
   Yang, HZ
AF Zhu, Zhenhua
   Lin, Jilan
   Cheng, Ming
   Xia, Lixue
   Sun, Hanbo
   Chen, Xiaoming
   Wang, Yu
   Yang, Huazhong
GP Assoc Comp Machinery
TI Mixed Size Crossbar based RRAM CNN Accelerator Overlapped Mapping Method
SO 2018 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
   DIGEST OF TECHNICAL PAPERS
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 37th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 05-08, 2018
CL San Diego, CA
DE Convolutional Neural Networks; RRAM; Computer Architecture
AB Convolutional Neural Networks (CNNs) play)1e in machine learning. CNNs are typically both computing and memory intensive. Emerging resistive random-access memories (RRAMs) and RRAM crossbars have demonstrated great potentials in boosting the performance and energy efficiency of CNNs. Compared with small crossbars, large crossbars show better energy efficiency with less interface overhead. However, conventional workload mapping methods for small crossbars cannot make full use of the computation ability of large crossbars. In this paper, we propose an Overlapped Mapping Method (OMM) and Mixed Size Crossbar based RRAM CNN Accelerator (MISCA) to solve this problem. MISCA with OMM can reduce the energy consumption caused by the interface circuits, and improve the parallelism of computation by leveraging the idle RRAM cells in crossbars. The simulation results show that MISCA with OMNI can achieve 2.7x speedup, 30% utilization rate improvement, and 1.2x energy efficiency improvement on average compared with l'ixect size crossbars based accelerator using the conventional mapping method. In comparison with CPU platform, MISCA with OMM can perform 490.4x higher on average in energy efficiency and 20x higher on average in speedup. Compared with PRIME, an existing RRAM based accelerator, MISCA has 26.4x speedup and 1.65x energy efficiency improvement.
C1 [Zhu, Zhenhua; Lin, Jilan; Cheng, Ming; Xia, Lixue; Sun, Hanbo; Wang, Yu; Yang, Huazhong] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
   [Zhu, Zhenhua; Cheng, Ming; Xia, Lixue; Sun, Hanbo; Wang, Yu; Yang, Huazhong] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.
   [Chen, Xiaoming] Chinese Acad Sci, State Key Lab Comp Architecture, Inst Comp Technol, Beijing, Peoples R China.
RP Zhu, ZH (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.; Zhu, ZH (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.
CR [Anonymous], 2015, INT J ANTENN PROPAG
   Chang MF, 2014, ISSCC DIG TECH PAP I, V57, P332, DOI 10.1109/ISSCC.2014.6757457
   Chen S. Y-S, 2011, 2011 Symposium on VLSI Circuits. Digest of Technical Papers, P66
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gupta S., 2014, INT J ENG TECHNICAL
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Pancholi S., 2015, NEW DESIGN CMOS COMP
   Proesel J., 2010, P IEEE CUST INT CIRC, P1
   QIU JT, 2016, FPGA, P26, DOI DOI 10.1145/2847263.2847265
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharan C., 2014, ABS14100759 CORR
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Wang Y, 2016, IEEE INT SYMP CIRC S, P129, DOI 10.1109/ISCAS.2016.7527187
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Zhao XY, 2018, 12TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS), P95, DOI 10.1145/3240323.3240374
NR 18
TC 3
Z9 3
U1 0
U2 2
PY 2018
DI 10.1145/3240765.3240825
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kayanoma, R
   Nakahara, H
AF Kayanoma, Ryota
   Nakahara, Hiroki
GP IEEE COMP SOC
TI Fast Interface with Ensemble Ternary Neural Network
SO 2022 IEEE 52ND INTERNATIONAL SYMPOSIUM ON MULTIPLE-VALUED LOGIC (ISMVL
   2022)
SE International Symposium on Multiple-Valued Logic
DT Proceedings Paper
CT 52nd IEEE International Symposium on Multiple-Valued Logic (ISMVL)
CY MAY 18-20, 2022
CL ELECTR NETWORK
AB The use of machine learning is expanding in various applications such as image processing in data centers. With the spread of deep learning, neural-network-based models have frequently been adopted in recent years. Because the processing speed is slow when evaluating machine learning on a CPU, a fast-dedicated hardware accelerator is often used. In particular, the demand for hardware accelerators in data centers is increasing. A low power consumption and high-speed processing are required in a limited space. An implementation method for a ternary neural network utilizing the rewritable look-up table (LUT) of a field-programmable gate array (FPGA) is proposed. Binary/ternary neural networks, which are quantized to 1-2 bits for mapping to LUTs, suffer from a poor recognition accuracy. To prevent a decrease in the recognition accuracy, let q be the number of quantization bits to be stored in the LUT. The memory size of the LUT becomes O(2(q)) bits, and it tends to be exponential in size. We improved the accuracy using an ensemble ternary neural network. There are various ways to select data for ensembles during training, and various ways to select branch pruning for trivialized neural networks. We chose the greedy method for our design. An evaluation using various benchmark datasets showed that the ensemble approach achieved a recognition accuracy equivalent to that of the 32-bit float model. We also estimated the amount of memory required to implement an LUT for an ensemble ternary neural network. The size of the LUT is 1.9 Mbit, which can be realized on the current FPGAs.
C1 [Kayanoma, Ryota; Nakahara, Hiroki] Tokyo Inst Technol, Tokyo, Japan.
RP Kayanoma, R (corresponding author), Tokyo Inst Technol, Tokyo, Japan.
CR [Anonymous], KMNIST DATASET CTR O
   [Anonymous], MNIST HANDWRITTEN DI
   Qin HT, 2020, PATTERN RECOGN, V105, DOI 10.1016/j.patcog.2020.107281
   Soga N, 2020, DESIGN METHOD LUT NE, P294
   Soga N, 2021, INT SYM MVL, P142, DOI 10.1109/ISMVL51352.2021.00032
   Suzuki Y, 2020, INT SYM MVL, P188, DOI 10.1109/ISMVL49045.2020.000-7
   TPU, NEXT TPU
   Umuroglu Y, 2020, LOGICNET CODESIGNED
   Xiao H, FASHION MNIST NOVEL
   Zhu SL, 2019, PROC CVPR IEEE, P4918, DOI 10.1109/CVPR.2019.00506
NR 10
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 182
EP 187
DI 10.1109/ISMVL52857.2022.00035
WC Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic; Mathematics, Applied; Logic
DA 2023-11-11
ER

PT J
AU García-Nava, JL
   Flores, JJ
   Tellez, VM
   Calderon, F
AF Garcia-Nava, J-Luis
   Flores, Juan J.
   Tellez, Victor M.
   Calderon, Felix
TI Fast training of a transformer for global multi-horizon time series
   forecasting on tensor processing units
SO JOURNAL OF SUPERCOMPUTING
DT Article; Early Access
DE Deep learning; Self-attention; Cloud computing; TPU
AB Time Series Forecasting (TSF) is essential to key domains, and the Transformer neural network has advanced the state-of-the-art on global, multi-horizon TSF benchmarks. The quadratic time and memory complexity of the Vanilla Transformer (VT) hinders its application to Big Data environments; therefore, multiple efficient variants of the VT that lower complexity via sparse self-attention have been proposed. However, less complex algorithms do not directly produce faster executions, and machine learning models for Big Data are typically trained on accelerators designed for dense-matrix computation that render slower performance with sparse matrices. To better compare the accuracy-speed trade-off of the VT and its variants, it is essential to test them on such accelerators. We implemented a cloud-based VT on Tensor Processing Units to address this task. Experiments on large-scale datasets show that our Transformer achieves good predictive performance when compared to state-of-the-art models while reducing training times from hours to under 2 min.
C1 [Garcia-Nava, J-Luis; Flores, Juan J.; Tellez, Victor M.; Calderon, Felix] Univ Michoacana, Sch Elect Engn, Morelia 58030, Michoacan, Mexico.
   [Flores, Juan J.] Univ Oregon, Eugene, OR 97403 USA.
RP García-Nava, JL (corresponding author), Univ Michoacana, Sch Elect Engn, Morelia 58030, Michoacan, Mexico.
EM jose.garcia@umich.mx; juan.flores@umich.mx; 0906214j@umich.mx;
   felix.calderon@umich.mx
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abdellaoui I.A, 2020, DEEP MULTISTATIONS W, DOI [10.48550/ARXIV.2009.11239, DOI 10.48550/ARXIV.2009.11239]
   Abdellaoui I.A, 2021, 2021 IEEE S SER COMP, P01
   Alrowili S., 2021, P 20 WORKSH BIOM LAN, P221
   Bandara K, 2021, PATTERN RECOGN, V120, DOI 10.1016/j.patcog.2021.108148
   Belkhouja T, 2022, J ARTIF INTELL RES, V73, P1435
   Ben Taieb S, 2012, EXPERT SYST APPL, V39, P7067, DOI 10.1016/j.eswa.2012.01.039
   BOX GEP, 1968, ROY STAT SOC C-APP, V17, P91
   Cheng HT, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1763, DOI 10.1145/3097983.3098171
   Duan JD, 2021, IEEE ACCESS, V9, P49372, DOI 10.1109/ACCESS.2021.3068895
   Fournier Q, 2021, PRACTICAL SURVEY FAS, DOI [10.48550/ARXIV.2103.14636, DOI 10.48550/ARXIV.2103.14636]
   GARDNER ES, 1985, J FORECASTING, V4, P1, DOI 10.1002/for.3980040103
   Hauru M, 2021, SIMULATION QUANTUM P, DOI [10.48550/ARXIV.2111.10466, DOI 10.48550/ARXIV.2111.10466]
   He XY, 2020, PERS UBIQUIT COMPUT, DOI [10.1007/s00779-020-01439-7, 10.1109/sensors47125.2020.9278641]
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khan S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3505244
   Kingma D. P, 2015, 3 INT C LEARN REPR I
   Kung HT, 1979, SPARSE MATRIX P 1978, V1, P256, DOI DOI 10.1109/LED.2012.2210856
   Lim B, 2021, INT J FORECASTING, V37, P1748, DOI 10.1016/j.ijforecast.2021.03.012
   Lim B, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0209
   Lin T, 2021, SURVEY TRANSFORMERS, DOI [10.48550/ARXIV.2106.04554, DOI 10.48550/ARXIV.2106.04554]
   Liu L, 2022, ROBUST MULTIVARIATE, DOI [10.48550/ARXIV.2207.09572, DOI 10.48550/ARXIV.2207.09572]
   Pan ZX, 2022, DES AUT TEST EUROPE, P1127, DOI 10.23919/DATE54114.2022.9774739
   Poh D, 2022, TRANSFER RANKING FIN, DOI [10.48550/ARXIV.2208.09968, DOI 10.48550/ARXIV.2208.09968]
   Poh D, 2021, ENHANCING CROSSSECTI, DOI [10.48550/ARXIV.2105.10019, DOI 10.48550/ARXIV.2105.10019]
   Rangapuram SS, 2018, ADV NEUR IN, V31
   Salinas D, 2020, INT J FORECASTING, V36, P1181, DOI 10.1016/j.ijforecast.2019.07.001
   Sheng A, 2020, 2020 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (SSCI), P721, DOI 10.1109/SSCI47803.2020.9308334
   Srinivas A, 2021, PROC CVPR IEEE, P16514, DOI 10.1109/CVPR46437.2021.01625
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Tay Y, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3530811
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Wen Ruofeng, 2017, 31 C NEURAL INFORM P, DOI [10.48550/ARXIV.1711.11053, DOI 10.48550/ARXIV.1711.11053]
   Wongpanich A, 2021, 2021 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P947, DOI 10.1109/IPDPSW52791.2021.00146
   Woo G, 2022, ETSFORMER EXPONENTIA, DOI [10.48550/ARXIV.2202.01381, DOI 10.48550/ARXIV.2202.01381]
   Wu N, 2020, DEEP TRANSFORMER MOD, DOI [10.48550/ARXIV.2001.08317, DOI 10.48550/ARXIV.2001.08317]
   Wu S, 2020, ADV NEURAL INFORM PR, V33, P17105
   Xia J, 2020, MOL INFORM, V39, DOI 10.1002/minf.201900151
   Xu HR, 2021, 2021 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2021), P6663
   Xu J., 2021, P ADV NEUR INF PROC, V34, P22419, DOI DOI 10.48550/ARXIV.2106.13008
   You Y, 2019, IEEE T PARALL DISTR, V30, P2449, DOI 10.1109/TPDS.2019.2913833
   Yu Hsiang- Fu, 2016, ADV NEURAL INFORM PR, V29, P847, DOI [DOI 10.5555/3157096.3157191, 10.5555/3157096.3157191]
   Zhao L, 2021, ADV NEURAL INF PROCE, V34
   Zhou HY, 2021, AAAI CONF ARTIF INTE, V35, P11106
NR 44
TC 0
Z9 0
U1 0
U2 2
PD 2022 DEC 19
PY 2022
DI 10.1007/s11227-022-05009-x
EA DEC 2022
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lee, B
   Perkowski, M
AF Lee, Bryan
   Perkowski, Marek
BE Kitsos, P
TI Quantum Machine Learning Based on Minimizing Kronecker-Reed-Muller Forms
   and Grover Search Algorithm with Hybrid Oracles
SO 19TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2016)
DT Proceedings Paper
CT 19th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2016
CL Limassol, CYPRUS
DE Quantum Machine Learning; Kronecker-Reed-Muller forms; Grover's search
   algorithm; Quantum Oracle; Hybrid binary/ternary quantum circuits; exact
   minimization of AND/EXOR circuits; EDA tools (CAD tools)
AB This paper formulates the generic Machine Learning (ML) problem into finding the simplest spectral transform form (i.e. one having as many zero coefficients as possible) for an (in) complete binary function. The classical binary logic synthesis problem can be modeled to minimize a single output Boolean function with a two-level structure consisting of an exclusive-OR (EXOR) of ANDs of literals. The innovative approach in this paper is to build and simulate an accelerator that reduces learning to find the exact minimum expression of all 3(n) Kronecker Reed Muller (KRO) forms of a Boolean function with n input variables. This is in contrast to the previously studied quantum algorithm for the Fixed Polarity Reed-Muller forms (FPRM) which only selects from 2(n) possible forms. The algorithm, based on repeated application of a ternary Grover's Quantum Search algorithm, was simulated to find the minimum KRO form using a hybrid ternary/binary quantum oracle. This hybrid quantum system was simulated in Matlab and proved to be correct. The method can be also used as a future Quantum EDA Tool for exact minimization of AND/EXOR circuits, including reversible and quantum circuits.
C1 [Lee, Bryan; Perkowski, Marek] Portland State Univ, Dept Elect & Comp Engn, Portland, OR 97207 USA.
RP Lee, B (corresponding author), Portland State Univ, Dept Elect & Comp Engn, Portland, OR 97207 USA.
EM bryanleepdx@gmail.com; mperkows@ee.pdx.edu
CR [Anonymous], IEEE 44 INT S MULT V
   [Anonymous], 2000, QUANTUM COMPUTATION
   Cai X., 2015, QUANTUM PHYS, V114
   DAVIO M, 1978, DISCRETE SWITCHING F
   Di Y., 2012, QUANTUM PHYS
   Drechsler R, 1996, IEE P-COMPUT DIG T, V143, P364, DOI 10.1049/ip-cdt:19960789
   GROVER L, P 28 ANN ACM S THEOR, P212
   KALAY U, 2000, J MULT-VALUED LOG S, V5, P507
   Khalid A. U., 2005, THESIS
   Li L., 2006, 36 INT S MULT VAL LO
   Negovetic G., 2002, RES REPORT
   Rebentrost P, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.130503
   Sarabi A., 1992, Proceedings. 29th ACM/IEEE Design Automation Conference (Cat. No.92CH3144-3), P30, DOI 10.1109/DAC.1992.227867
   Singh S., 2004, THESIS
   Wang YS, 2011, INT SYM MVL, P294, DOI 10.1109/ISMVL.2011.42
   Yang G., 2004, RES REPORT
   Yoo S., 2014, NEW J PHYS, V16, P1
NR 17
TC 5
Z9 5
U1 0
U2 3
PY 2016
BP 413
EP 422
DI 10.1109/DSD.2016.30
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Park, Y
   Wang, ZY
   Yoo, S
   Lu, WD
AF Park, Yongmo
   Wang, Ziyu
   Yoo, Sangmin
   Lu, Wei D. D.
TI RM-NTT: An RRAM-Based Compute-in-Memory Number Theoretic Transform
   Accelerator
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Compute-in-memory (CIM); homomorphic encryption (HE); non-volatile
   memory (NVM); number theoretic transform (NTT); resistive random access
   memory (RRAM); ring learning with errors (RLWE)
AB As more cloud computing resources are used for machine learning training and inference processes, privacy-preserving techniques that protect data from revealing at the cloud platforms attract increasing interest. Homomorphic encryption (HE) is one of the most promising techniques that enable privacy-preserving machine learning because HE allows data to be evaluated under encrypted forms. However, deep neural network (DNN) implementations using HE are orders of magnitude slower than plaintext implementations. The use of very long polynomials and associated number theoretic transform (NTT) operations for polynomial multiplications is the main bottlenecks of HE implementation for practical uses. This article introduces RRAM number theoretic transform (RM-NTT): a resistive random access memory (RRAM)-based compute-in-memory (CIM) system to accelerate NTT and inverse NTT (INTT) operations. Instead of running fast Fourier transform (FFT)-like algorithms, RM-NTT uses a vector-matrix multiplication (VMM) approach to achieve maximal parallelism during NTT and INTT operations. To improve the efficiency, RM-NTT stores modified forms of the twiddle factors in the RRAM arrays to process NTT/INTT in the same RRAM array and employs a Montgomery reduction algorithm to convert the VMM results. The proposed optimization methods allow RM-NTT to significantly reduce NTT operation latency compared with other NTT accelerators, including both CIM and non-CIM-based designs. The effects of different RM-NTT design parameters and device nonidealities are also discussed.
C1 [Park, Yongmo; Wang, Ziyu; Yoo, Sangmin; Lu, Wei D. D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Lu, WD (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM wluee@umich.edu
CR Banerjee U, 2019, ISSCC DIG TECH PAP I, V62, P46, DOI 10.1109/ISSCC.2019.8662528
   Brakerski Z., 2014, ACM T COMPUT THEORY, V6, P1
   Chase M., 2017, 1 HOM ENCR ORG
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Correll JM, 2020, IEEE J EXPLOR SOLID-, V6, P36, DOI 10.1109/JXCDC.2020.2992228
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Fan J., 2012, IACR CRYPTOL EPRINT
   Fritzmann T, 2019, PROCEEDINGS OF THE 2019 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P141, DOI 10.1109/HST.2019.8741027
   Gaba S, 2013, NANOSCALE, V5, P5872, DOI 10.1039/c3nr01176c
   Gentry C, 2013, LECT NOTES COMPUT SC, V8042, P75, DOI 10.1007/978-3-642-40041-4_5
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hesamifard E, 2017, Arxiv, DOI arXiv:1711.05189
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Je-Min Hung, 2021, IEEE Open Journal of the Solid-State Circuits Society, V1, P171, DOI 10.1109/OJSSCS.2021.3123287
   Kaissis GA, 2020, NAT MACH INTELL, V2, P305, DOI 10.1038/s42256-020-0186-1
   Kull L, 2013, IEEE J SOLID-ST CIRC, V48, P3049, DOI 10.1109/JSSC.2013.2279571
   Laine Kim, 2017, SIMPLE ENCRYPTED ARI
   Lee JW, 2022, IEEE ACCESS, V10, P30039, DOI 10.1109/ACCESS.2022.3159694
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Li D, 2022, IEEE T VLSI SYST, V30, P579, DOI 10.1109/TVLSI.2022.3151321
   Li YB, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aade3f
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Mireshghallah F, 2020, Arxiv, DOI arXiv:2004.12254
   Morven Gentleman W., 1966, P NOVEMBER 7 10 1966, P563, DOI DOI 10.1145/1464291.1464352
   Nejatollahi H, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218730
   Özerk Ö, 2022, J SUPERCOMPUT, V78, P2840, DOI 10.1007/s11227-021-03980-5
   Phong LT, 2018, IEEE T INF FOREN SEC, V13, P1333, DOI 10.1109/TIFS.2017.2787987
   Reagen B, 2021, INT S HIGH PERF COMP, P26, DOI 10.1109/HPCA51647.2021.00013
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Saberi M, 2011, IEEE T CIRCUITS-I, V58, P1736, DOI 10.1109/TCSI.2011.2107214
   Shim W, 2020, SEMICOND SCI TECH, V35, DOI 10.1088/1361-6641/abb842
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang R, 2018, MATERIALS, V11, DOI 10.3390/ma11112102
   Wang XX, 2022, IEEE T CIRCUITS-II, V69, P559, DOI 10.1109/TCSII.2021.3097035
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
   Zhang C, 2022, PREP BIOCHEM BIOTECH, V52, P487, DOI 10.1080/10826068.2021.1966800
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 41
TC 1
Z9 1
U1 2
U2 5
PD DEC
PY 2022
VL 8
IS 2
BP 93
EP 101
DI 10.1109/JXCDC.2022.3202517
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Karthikeyan, A
   Priyakumar, UD
AF Karthikeyan, Akshaya
   Priyakumar, U. Deva
TI Artificial intelligence: machine learning for chemical sciences
SO JOURNAL OF CHEMICAL SCIENCES
DT Article
DE Deep learning; machine learning; computational chemistry; drug design;
   molecular design; computational materials; neural networks
ID DEEP NEURAL-NETWORKS; MOLECULAR DESCRIPTORS; PROPERTY PREDICTION;
   QUANTUM-CHEMISTRY; FREE-ENERGIES; FORCE-FIELDS; DESIGN; RENAISSANCE;
   POTENTIALS; GENERATION
AB Research in molecular sciences witnessed the rise and fall of Artificial Intelligence (AI)/Machine Learning (ML) methods, especially artificial neural networks, few decades ago. However, we see a major resurgence in the use of modern ML methods in scientific research during the last few years. These methods have had phenomenal success in the areas of computer vision, speech recognition, natural language processing (NLP), etc. This has inspired chemists and biologists to apply these algorithms to problems in natural sciences. Availability of high performance Graphics Processing Unit (GPU) accelerators, large datasets, new algorithms, and libraries has enabled this surge. ML algorithms have successfully been applied to various domains in molecular sciences by providing much faster and sometimes more accurate solutions compared to traditional methods like Quantum Mechanical (QM) calculations, Density Functional Theory (DFT) or Molecular Mechanics (MM) based methods, etc. Some of the areas where the potential of ML methods are shown to be effective are in drug design, prediction of high-level quantum mechanical energies, molecular design, molecular dynamics materials, and retrosynthesis of organic compounds, etc. This article intends to conceptually introduce various modern ML methods and their relevance and applications in computational natural sciences.
C1 [Karthikeyan, Akshaya; Priyakumar, U. Deva] Int Inst Informat Technol, Ctr Computat Nat Sci & Bioinformat, Hyderabad 500032, India.
RP Priyakumar, UD (corresponding author), Int Inst Informat Technol, Ctr Computat Nat Sci & Bioinformat, Hyderabad 500032, India.
EM deva@iiit.ac.in
CR Agar JC, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12750-0
   Agarwal S, 2021, DART DEEP LEARNING E, DOI [10.26434/chemrxiv.14672682.v1, DOI 10.26434/CHEMRXIV.14672682.V1]
   Ahuja K, 2021, J CHEM THEORY COMPUT, V17, P818, DOI 10.1021/acs.jctc.0c00971
   Ajay, 1998, J MED CHEM, V41, P3314, DOI 10.1021/jm970666c
   ALLCOCK HR, 1992, SCIENCE, V255, P1106, DOI 10.1126/science.255.5048.1106
   Alle S, 2020, COVID 19 RISK STRATI, DOI [10.1101/2020.12.19.20248524, DOI 10.1101/2020.12.19.20248524]
   AlQuraishi M, 2019, BIOINFORMATICS, V35, P4862, DOI 10.1093/bioinformatics/btz422
   Bagal V., 2021, LIGGPT MOL GENERATIO, DOI 10.26434/chemrxiv.14561901.v1
   Balachandran P V, 2021, MACHINE LEARNING MAT
   Ballester PJ, 2010, BIOINFORMATICS, V26, P1169, DOI 10.1093/bioinformatics/btq112
   Barducci A, 2013, P NATL ACAD SCI USA, V110, pE4708, DOI 10.1073/pnas.1320077110
   Bartók AP, 2015, INT J QUANTUM CHEM, V115, P1051, DOI 10.1002/qua.24927
   Bartók AP, 2013, PHYS REV B, V87, DOI 10.1103/PhysRevB.87.184115
   Bartók AP, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.136403
   Baskin II, 2016, EXPERT OPIN DRUG DIS, V11, P785, DOI 10.1080/17460441.2016.1201262
   Behler J, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.146401
   Bose S, 2018, PHYS CHEM CHEM PHYS, V20, P22987, DOI 10.1039/c8cp03138j
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Brown N., 2015, SILICO MED CHEM COMP
   Burden FR, 2000, J CHEM INF COMP SCI, V40, P1423, DOI 10.1021/ci000450a
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Butler KT, 2016, CHEM SOC REV, V45, P6138, DOI 10.1039/c5cs00841g
   Cai JZ, 2020, NANOSCALE ADV, V2, P3115, DOI 10.1039/d0na00388c
   Capecchi A, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00445-4
   Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302
   Chandrasekaran B, 2018, ADV PHARM PROD DEVL, P731, DOI 10.1016/B978-0-12-814421-3.00021-X
   Chattopadhyay A, 2018, J CHEM THEORY COMPUT, V14, P3365, DOI 10.1021/acs.jctc.7b01245
   CHIRIKI S, 2017, J CHEM PHYS, V103, P227
   Chiriki S, 2016, CHEM PHYS LETT, V652, P130, DOI 10.1016/j.cplett.2016.04.013
   Chithrananda S., 2020, ARXIV
   Cohn D. A., 1995, Advances in Neural Information Processing Systems 7, P705
   Collobert R., 2008, P 25 ICML, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   David L, 2020, J CHEMINFORMATICS, V12, DOI 10.1186/s13321-020-00460-5
   Davis MI, 2011, NAT BIOTECHNOL, V29, P1046, DOI 10.1038/nbt.1990
   De Cao Nicola, 2018, ICML 2018 WORKSH THE
   Dieb S, 2020, J APPL PHYS, V128, DOI 10.1063/5.0012351
   Dureckova H, 2019, J PHYS CHEM C, V123, P4133, DOI 10.1021/acs.jpcc.8b10644
   Eikerling, 2019, ARXIV190910124
   Elton DC, 2019, MOL SYST DES ENG, V4, P828, DOI 10.1039/c9me00039a
   Faber FA, 2017, J CHEM THEORY COMPUT, V13, P5255, DOI 10.1021/acs.jctc.7b00577
   Fersht AR, 2021, J MOL BIOL, V433, DOI 10.1016/j.jmb.2021.167088
   FREEMAN B, 1987, J NEUROSCI METH, V20, P115, DOI 10.1016/0165-0270(87)90044-6
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Glen RC, 2006, IDRUGS, V9, P199
   Goh G. B., 2017, ARXIV170606689
   Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Gómez-Bombarelli R, 2016, NAT MATER, V15, P1120, DOI [10.1038/nmat4717, 10.1038/NMAT4717]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Haghighatlari M, 2019, CURR OPIN CHEM ENG, V23, P51, DOI 10.1016/j.coche.2019.02.009
   Han JQ, 2019, J COMPUT PHYS, V399, DOI 10.1016/j.jcp.2019.108929
   Han YF, 2011, COMP MATER SCI, V50, P1009, DOI 10.1016/j.commatsci.2010.10.040
   HANSCH C, 1962, NATURE, V194, P178, DOI 10.1038/194178b0
   Hansen K, 2015, J PHYS CHEM LETT, V6, P2326, DOI 10.1021/acs.jpclett.5b00831
   Hansen K, 2013, J CHEM THEORY COMPUT, V9, P3404, DOI 10.1021/ct400195d
   Hao ZK, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P731, DOI 10.1145/3394486.3403117
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed., DOI DOI 10.1007/B94608
   Hautier G, 2010, CHEM MATER, V22, P3762, DOI 10.1021/cm100795d
   Hermann J, 2020, NAT CHEM, V12, P891, DOI 10.1038/s41557-020-0544-y
   HILLER SA, 1973, COMPUT BIOMED RES, V6, P411, DOI 10.1016/0010-4809(73)90074-8
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI 10.1109/9780470544037.ch14
   Hodas, 2017, PNNLSA129942
   Hong Y, 2020, WIRES COMPUT MOL SCI, V10, DOI 10.1002/wcms.1450
   Hospital Adam, 2015, Adv Appl Bioinform Chem, V8, P37, DOI 10.2147/AABC.S70333
   Huang B, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4964627
   Jin WG, 2018, PR MACH LEARN RES, V80
   Jones MR, 2015, SCIENCE, V347, DOI 10.1126/science.1260901
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Kadurin A, 2017, MOL PHARMACEUT, V14, P3098, DOI 10.1021/acs.molpharmaceut.7b00346
   Kapse S, 2021, APPL CATAL B-ENVIRON, V286, DOI 10.1016/j.apcatb.2020.119866
   Karthikeyan A, 2021, FRONT PUBLIC HEALTH, V9, DOI 10.3389/fpubh.2021.626697
   Khan Mahmud Tareq Hassan, 2007, Curr Drug Discov Technol, V4, P141, DOI 10.2174/157016307782109706
   Khare Y, 2021, I S BIOMED IMAGING, P1033, DOI 10.1109/ISBI48211.2021.9434063
   Kim B, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aax9324
   Kim KJ, 2018, NPJ MICROGRAVITY, V4, DOI 10.1038/s41526-018-0051-2
   Kim S, 2021, NUCLEIC ACIDS RES, V49, pD1388, DOI 10.1093/nar/gkaa971
   Kirkpatrick P, 2004, NATURE, V432, P823, DOI 10.1038/432823a
   Krakovsky M, 2016, COMMUN ACM, V59, P12, DOI 10.1145/2949662
   Krogh A, 2008, NAT BIOTECHNOL, V26, P195, DOI 10.1038/nbt1386
   Kuhn C, 1996, J PHYS CHEM-US, V100, P10595, DOI 10.1021/jp960518i
   Laghuvarapu S, 2020, J COMPUT CHEM, V41, DOI 10.1002/jcc.26128
   Lamb G., 2020, ARXIV PREPRINT ARXIV
   LeCun Y., 1995, HDB BRAIN THEORY NEU, P276, DOI 10.5555/303568.303704
   Lipinski C, 2004, NATURE, V432, P855, DOI 10.1038/nature03193
   Liu Y, 2017, J MATERIOMICS, V3, P159, DOI 10.1016/j.jmat.2017.08.002
   Lu CQ, 2019, AAAI CONF ARTIF INTE, P1052
   Marenich AV, 2012, MINNESOTA SOLVATION
   Mayr A, 2018, CHEM SCI, V9, P5441, DOI 10.1039/c8sc00148k
   MCCAMMON JA, 1977, NATURE, V267, P585, DOI 10.1038/267585a0
   McDonagh JL, 2018, J CHEM THEORY COMPUT, V14, P216, DOI 10.1021/acs.jctc.7b01157
   Meredig B, 2014, PHYS REV B, V89, DOI 10.1103/PhysRevB.89.094104
   Meyer JG, 2019, J CHEM INF MODEL, V59, P4438, DOI 10.1021/acs.jcim.9b00236
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mobley DL, 2014, J COMPUT AID MOL DES, V28, P711, DOI 10.1007/s10822-014-9747-x
   Montavon G, 2013, NEW J PHYS, V15, DOI 10.1088/1367-2630/15/9/095003
   Moolamalla STR, 2020, BIORXIV, DOI [10.1101/2020.08.02.232645, DOI 10.1101/2020.08.02.232645]
   Moosavi SM, 2020, J AM CHEM SOC, V142, P20273, DOI 10.1021/jacs.0c09105
   MORGAN HL, 1965, J CHEM DOC, V5, P107, DOI 10.1021/c160017a018
   Muller, 2017, ARXIV PREPRINT ARXIV
   Murugan NA, 2019, CHALL ADV COMPUT CHE, V27, P221, DOI 10.1007/978-3-030-05282-9_7
   Nagamani S, 2021, ACS OMEGA, V6, P17472, DOI 10.1021/acsomega.1c01865
   Noé F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331
   Noh J, 2019, MATTER-US, V1, P1370, DOI 10.1016/j.matt.2019.08.017
   Olivecrona M, 2017, J CHEMINFORMATICS, V9, DOI 10.1186/s13321-017-0235-x
   Palazzesi F, 2015, J CHEM THEORY COMPUT, V11, P2, DOI 10.1021/ct500718s
   Pathak J, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.024102
   Pathak Y, 2021, J CHEM INF MODEL, V61, P689, DOI 10.1021/acs.jcim.0c01413
   Pathak Y, 2020, PHYS CHEM CHEM PHYS, V22, P26935, DOI 10.1039/d0cp03508d
   Pattnaik P, 2020, J PHYS CHEM A, V124, P6954, DOI 10.1021/acs.jpca.0c03926
   Pfau D, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.033429
   Pissurlenkar Raghuvir R. S., 2009, Anti-Infective Agents in Medicinal Chemistry, V8, P128
   POLLICE R, 2021, ACCOUNTS CHEM RES, V2, P1120
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644
   Popova M, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aap7885
   Pozun ZD, 2012, J CHEM PHYS, V136, DOI 10.1063/1.4707167
   Prakash M K, 2020, PREDICTING INTERPRET
   Priyakumar, 2021, ENHANCED SAMPLING CH
   Priyakumar U D, 2021, J CHEM INF MODEL, V2021
   Priyakumar U D, P AAAI C ART INT APR, V34, P873
   Putin E, 2018, J CHEM INF MODEL, V58, P1194, DOI 10.1021/acs.jcim.7b00690
   Ragoza M, 2017, J CHEM INF MODEL, V57, P942, DOI 10.1021/acs.jcim.6b00740
   Rajan AC, 2018, CHEM MATER, V30, P4031, DOI 10.1021/acs.chemmater.8b00686
   Ramakrishnan R, 2017, REV COMP CH, V30, P225
   Ramakrishnan R, 2015, J CHEM THEORY COMPUT, V11, P2087, DOI 10.1021/acs.jctc.5b00099
   Ramakrishnan R, 2014, SCI DATA, V1, DOI 10.1038/sdata.2014.22
   RANDIC M, 1991, J MATH CHEM, V7, P155, DOI 10.1007/BF01200821
   Ratcliff LE, 2017, WIRES COMPUT MOL SCI, V7, DOI 10.1002/wcms.1290
   Reker D, 2015, DRUG DISCOV TODAY, V20, P458, DOI 10.1016/j.drudis.2014.12.004
   Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t
   Roy K., 2015, UNDERSTANDING BASICS, P151, DOI [10.1016/B978-0-12-801505-6.00005-3, DOI 10.1016/B978-0-12-801505-6.00005-3]
   Ruddigkeit L, 2012, J CHEM INF MODEL, V52, P2864, DOI 10.1021/ci300415d
   Rupp M, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.058301
   Saal JE, 2020, ANNU REV MATER RES, V50, P49, DOI 10.1146/annurev-matsci-090319-010954
   Samaga YBL, 2021, J PHYS CHEM B, V125, P10657, DOI 10.1021/acs.jpcb.1c04913
   Sanchez-Lengeling B, 2018, SCIENCE, V361, P360, DOI 10.1126/science.aat2663
   Schmidt J, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0221-0
   Schneider G, 1998, PROG BIOPHYS MOL BIO, V70, P175, DOI 10.1016/S0079-6107(98)00026-1
   Schneider G, 2018, MOL INFORM, V37, DOI 10.1002/minf.201880131
   Schneider G, 2018, NAT REV DRUG DISCOV, V17, P97, DOI 10.1038/nrd.2017.232
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   Sellwood MA, 2018, FUTURE MED CHEM, V10, P2025, DOI 10.4155/fmc-2018-0212
   Senior AW, 2019, PROTEINS, V87, P1141, DOI 10.1002/prot.25834
   Shi S., 2020, MACHINE LEARNING ASS
   Shiraogawa T, 2020, J PHYS CHEM C, V124, P13329, DOI 10.1021/acs.jpcc.0c01730
   Simm G., 2020, INT C MACH LEARN, P8959
   Singh S, 2020, P NATL ACAD SCI USA, V117, P1339, DOI 10.1073/pnas.1916392117
   Smith JS, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10827-4
   Snyder JC, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.253002
   Steinbeck C, 2004, PHYTOCHEMISTRY, V65, P2711, DOI 10.1016/j.phytochem.2004.08.027
   Sun F, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P1441, DOI 10.1145/3357384.3357895
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Tang J, 2014, J CHEM INF MODEL, V54, P735, DOI 10.1021/ci400709d
   Tian Y, 2020, J APPL PHYS, V128, DOI 10.1063/5.0012405
   Tkatchenko A, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17844-8
   Todeschini R, 1998, PERSPECT DRUG DISCOV, V9-11, P355, DOI 10.1023/A:1027284627085
   Todeschini R., 2008, HDB MOL DESCRIPTORS
   Tsai ST, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18959-8
   van den Herik HJ, 2002, ARTIF INTELL, V134, P277, DOI 10.1016/S0004-3702(01)00152-7
   Varnek A, 2012, J CHEM INF MODEL, V52, P1413, DOI 10.1021/ci200409x
   von Lilienfeld OA, 2020, NAT REV CHEM, V4, P347, DOI 10.1038/s41570-020-0189-9
   Walczak B., 2020, COMPREHENSIVE CHEMOM, P26
   Wang YL, 2009, NUCLEIC ACIDS RES, V37, pW623, DOI 10.1093/nar/gkp456
   Wang YH, 2020, CURR OPIN STRUC BIOL, V61, P139, DOI 10.1016/j.sbi.2019.12.016
   Wang ZJ, 2020, ARXIV PREPRINT ARXIV
   Ward L, 2018, ACTA MATER, V159, P102, DOI 10.1016/j.actamat.2018.08.002
   WARSHEL A, 1976, J MOL BIOL, V103, P227, DOI 10.1016/0022-2836(76)90311-9
   Wei GW, 2019, NAT MACH INTELL, V1, P336, DOI 10.1038/s42256-019-0086-4
   Wu ZQ, 2018, CHEM SCI, V9, P513, DOI 10.1039/c7sc02664a
   Yaghi OM, 2019, INTRODUCTION TO RETICULAR CHEMISTRY: METAL-ORGANIC FRAMEWORKS AND COVALENT ORGANIC FRAMEWORKS, P1, DOI 10.1002/9783527821099
   Yang K, 2019, J CHEM INF MODEL, V59, P3370, DOI 10.1021/acs.jcim.9b00237
   Yao ZP, 2021, NAT MACH INTELL, V3, P76, DOI 10.1038/s42256-020-00271-1
   Zhang J., 2020, J MATER SCI TECHNOL
   Zhou ZP, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47148-x
   Zhu Q, 2003, ACTA MATER, V51, P5051, DOI 10.1016/S1359-6454(03)00353-7
   Zhu WH, 2016, PROC INT CONF ANTI, P1, DOI 10.1109/ICASID.2016.7873885
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
NR 175
TC 17
Z9 17
U1 8
U2 79
PD MAR
PY 2022
VL 134
IS 1
DI 10.1007/s12039-021-01995-2
WC Chemistry, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Kasahara, H
   Kimura, K
   Kitamura, T
   Mikami, H
   Morita, K
   Fujita, K
   Yamamoto, K
   Kawasumi, T
AF Kasahara, Hironori
   Kimura, Keiji
   Kitamura, Toshiaki
   Mikami, Hiroki
   Morita, Kazutaka
   Fujita, Kazuki
   Yamamoto, Kazuki
   Kawasumi, Tohma
GP IEEE
TI OSCAR Parallelizing and Power Reducing Compiler and API for
   Heterogeneous Multicores (<i>Invited Paper</i>)
SO PROCEEDINGS OF PEHC 2021: WORKSHOP ON PROGRAMMING ENVIRONMENTS FOR
   HETEROGENEOUS COMPUTING
DT Proceedings Paper
CT Workshop on Programming Environments for Heterogeneous Computing (PEHC)
CY NOV 19, 2021
CL St Louis, MO
DE paralelizing compiler; heterogeneous multicore; accelerator
AB Heterogeneous computing systems, connecting general-purpose processor cores with accelerators and/or different kinds of general-purpose processor cores, have been widely used for HPC, cloud servers, self-driving vehicles, AI robots, and so on. They are used to obtain high performance and/or low power consumption. This paper introduces the OSCAR (Optimally Scheduled Advanced Multiprocessor) parallelizing compiler and OSCAR APL They allow users to automatically parallelize and power-reduce a C or Fortran program for various heterogeneous computing systems. OSCAR compiler has been developed since 1983, aiming at co-design of multiprocessor architecture and compiler. Currently, it can generate parallel machine codes for any shared memory homogeneous and heterogeneous multicores with or without hardware cache-coherent mechanism if a sequential C or Fortran compiler exists for the target multicore. OSCAR compiler translates a sequential user program written in C or Fortran into a parallelized C or Fortran program with OSCAR API compatible with frequency-voltage control, clock-gating, and power gating directives for each core, memory module, and interconnect defined in OSCAR API. The generated parallel program consists of threads specified by OpenMP "section" directives. The threads can be compiled into machine codes by an OpenMP compiler or a sequential C or Fortran compiler for a target general-purpose processor cores or accelerator cores. The compilation flow and execution and power-reduce performance for scientific and embedded applications and Deep Learning are shown on several heterogeneous systems, such as a heterogeneous multicore processor having eight general-purpose cores and 4 DRPs, or Dynamically Reconfigurable Processors, a heterogeneous multicore on FPGA using NIOS cores, and a new vector accelerator based on the past Japanese supercomputers and a personal vector supercomputer NEC Aurora Tsubasa.
C1 [Kasahara, Hironori; Kimura, Keiji; Kitamura, Toshiaki; Mikami, Hiroki; Fujita, Kazuki; Yamamoto, Kazuki; Kawasumi, Tohma] Waseda Univ, Shinjuku Ku, Tokyo, Japan.
   [Morita, Kazutaka] Nippon Telegraph & Tel Corp, Minato Ku, Tokyo, Japan.
RP Kasahara, H (corresponding author), Waseda Univ, Shinjuku Ku, Tokyo, Japan.
EM kasahara@waseda.jp; keiji@waseda.jp; toshi.kitamura@aoni.waseda.jp;
   hiroki@kasahara.cs.waseda.ac.jp; kazutaka.morita.fp@hco.ntt.co.jp;
   kazuki_fujita@kasahara.cs.waseda.ac.jp;
   kyamamoto@kasahara.cs.waseda.ac.jp; tohma@kasahara.cs.waseda.ac.jp
CR Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Hayashi A, 2011, LECT NOTES COMPUT SC, V6548, P184, DOI 10.1007/978-3-642-19595-2_13
   Ishizaka K, 2003, LECT NOTES COMPUT SC, V2624, P352, DOI 10.1007/3-540-35767-X_23
   Kasahara H., 1991, P 4 INT WORKSH LCPC, P283
   Kasahara Hironori, 2001, LNCS, P189, DOI DOI 10.1007/3-540-45574-413
   Kashimata T, 2019, 2019 IEEE/ACM 9TH WORKSHOP ON IRREGULAR APPLICATIONS - ARCHITECTURES AND ALGORITHMS (IA3), P71, DOI 10.1109/IA349570.2019.00017
   Kimura K, 2010, LECT NOTES COMPUT SC, V5898, P188, DOI 10.1007/978-3-642-13374-9_13
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   NEC Corporation, 2021, SX AUR TSUBASA PERF
   NEC Corporation, 2021, NEC SX AUR TSUBASA A
   Obata M, 2005, LECT NOTES COMPUT SC, V2481, P31, DOI 10.1007/11596110_3
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shikano H, 2008, IEEE J SOLID-ST CIRC, V43, P902, DOI 10.1109/JSSC.2008.917531
   The OpenMP ARB, 1997, OPENMP API SPEC PAR
   Wada Yasutaka, 2011, Transactions on High-Performance Embedded Architectures and Compilers IV, P215, DOI 10.1007/978-3-642-24568-8_11
   Winograd Shmuel, 1980, SOC IND APPL MATH, P71, DOI DOI 10.1137/1.9781611970364
   Yuyama Yoichi, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P100, DOI 10.1109/ISSCC.2010.5434031
NR 17
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 10
EP 19
DI 10.1109/PEHC54839.2021.00007
DA 2023-11-11
ER

PT C
AU Beach, TH
   Avis, NJ
AF Beach, Thomas H.
   Avis, Nicholas J.
GP ACM
TI An Intelligent Semi-Automatic Application Porting System for Application
   Accelerators
SO UCHPC-MAW09: UNCONVENTIONAL HIGH PERFORMANCE COMPUTING/MEMORY ACCESS: IS
   THE MEMORY FIT FOR MANYCORE?
DT Proceedings Paper
CT 6th ACM International Conference on Computing Frontiers and Workshops
CY MAY 18-20, 2009
CL Ischia, ITALY
DE Application Acceleration; Clearspeed; GPGPU; Performance Comparision;
   Semi-Automatic Porting
AB Work involving the use of application acceleration devices is showing great, promise, however, there are still major obstacles preventing their widespread adoption. Currently the process of porting applications to an accelerator requires expertise in both the computer science and application domains, due to the lack of abstraction available. We present. our work associated with the development of a novel solution to this abstraction problem; an intelligent semi-automatic application porting system, that will allow a higher level of abstraction, to be presented to the end user, while maintaining reasonable performance levels. A prototype system has been constructed that can successfully port applications to Graphics Processing Units (GPUs) and shows promising results in terms of performance comparisons between CPU and GPU. We are presently extending our prototype to other application acceleration devices and to allow the automatic selection of the most appropriate device, for all application using Machine Learning techniques. We expect our work and results will be of widespread interest to the increasing community involved in porting code to application accelerators.
C1 [Beach, Thomas H.; Avis, Nicholas J.] Cardiff Univ, Sch Comp Sci, Cardiff, S Glam, Wales.
RP Beach, TH (corresponding author), Cardiff Univ, Sch Comp Sci, 5 Parade, Cardiff, S Glam, Wales.
EM T.H.Beach@cs.cardiff.ac.uk; N.J.Avis@cs.cardiff.ac.uk
CR [Anonymous], 2006, LANDSCAPE PARALLEL C
   [Anonymous], VVS 94, DOI DOI 10.1145/197938.197972
   Buck I, 2004, ACM T GRAPHIC, V23, P777, DOI 10.1145/1015706.1015800
   CHINCHILLA F, 2004, PARALLEL N BODY SIMU
   *CLEARSP, 2007, CSX PROC ARCH
   *CLEARSP, 2007, CLEARSP APPL NOT GRO
   JEFFREY D, 1986, COMPILERS PRINCIPLES
   JOHN D, 2005, EUROGRAPHICS, V26, P80
   Kennedy A D M, 2003, Health Technol Assess, V7, P1
   LEE W, 2001, IEEE C FIELD PROGR L, P119
   *RAP, RAP PROD OV
   TIMOTHY J, 2002, ACM T GRAPHIC, V21, P703
   Witten I H, 2000, DATA MINING PRACTICA
NR 13
TC 3
Z9 3
U1 0
U2 0
PY 2009
BP 7
EP 10
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Bertone, G
   Bozorgnia, N
   Kim, JS
   Liem, S
   McCabe, C
   Otten, S
   de Austri, RR
AF Bertone, Gianfranco
   Bozorgnia, Nassim
   Kim, Jong Soo
   Liem, Sebastian
   McCabe, Christopher
   Otten, Sydney
   Ruiz de Austri, Roberto
TI Identifying WIMP dark matter from particle and astroparticle data
SO JOURNAL OF COSMOLOGY AND ASTROPARTICLE PHYSICS
DT Article
DE dark matter detectors; dark matter experiments; dark matter theory
ID LIKELIHOOD ANALYSIS; SIMPLIFIED MODELS; STABLE PARTICLES; SEARCHES;
   MSSM; ABUNDANCES; COSMOLOGY; PHYSICS; SCALAR; LIMITS
AB One of the most promising strategies to identify the nature of dark matter consists in the search for new particles at accelerators and with so-called direct detection experiments. Working within the framework of simplified models, and making use of machine learning tools to speed up statistical inference, we address the question of what we can learn about dark matter from a detection at the LHC and a forthcoming direct detection experiment. We show that with a combination of accelerator and direct detection data, it is possible to identify newly discovered particles as dark matter, by reconstructing their relic density assuming they are weakly interacting massive particles (WIMPs) thermally produced in the early Universe, and demonstrating that it is consistent with the measured dark matter abundance. An inconsistency between these two quantities would instead point either towards additional physics in the dark sector, or towards a non-standard cosmology, with a thermal history substantially different from that of the standard cosmological model.
C1 [Bertone, Gianfranco; Bozorgnia, Nassim; Liem, Sebastian] Univ Amsterdam, GRAPPA Inst, Inst Theoret Phys Amsterdam, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
   [Bertone, Gianfranco; Bozorgnia, Nassim; Liem, Sebastian] Univ Amsterdam, Delta Inst Theoret Phys, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
   [Bozorgnia, Nassim] Univ Durham, Dept Phys, Inst Particle Phys Phenomenol, Durham DH1 3LE, England.
   [Kim, Jong Soo] Univ Witwatersrand, Sch Phys, Natl Inst Theoret Phys, ZA-2050 Johannesburg, South Africa.
   [Kim, Jong Soo] Univ Witwatersrand, Mandelstam Inst Theoret Phys, ZA-2050 Johannesburg, South Africa.
   [McCabe, Christopher] Kings Coll London, Dept Phys, London WC2R 2LS, England.
   [Otten, Sydney] Rhein Westfal TH Aachen, Inst Theoret Particle Phys & Cosmol, D-52074 Aachen, Germany.
   [Ruiz de Austri, Roberto] IFIC UV CSIC, Inst Fis Corpuscular, Valencia, Spain.
RP Bertone, G (corresponding author), Univ Amsterdam, GRAPPA Inst, Inst Theoret Phys Amsterdam, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.; Bertone, G (corresponding author), Univ Amsterdam, Delta Inst Theoret Phys, Sci Pk 904, NL-1098 XH Amsterdam, Netherlands.
EM g.bertone@uva.nl; nassim.bozorgnia@durham.ac.uk;
   jongsoo.kim@tu-dortmund.de; sebastian.liem@uva.nl;
   christopher.mccabe@kcl.ac.uk; sydney.otten@rwth-aachen.de;
   rruiz@ific.uv.es
CR Aaboud M, 2018, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2018)126
   Aaboud M, 2017, EUR PHYS J C, V77, DOI [10.1140/epjc/s10052-017-4965-8, 10.1140/epjc/s10052-017-4766-0]
   Aaboud M, 2016, PHYS REV D, V94, DOI 10.1103/PhysRevD.94.032005
   Aalbers J., 2016, JCAP, V11, P017, DOI [DOI 10.1088/1475-7516/2016/11/017, 10.1088/1475-7516/2016/11/017]
   Aaltonen T, 2009, PHYS REV D, V79, DOI 10.1103/PhysRevD.79.112002
   Aartsen MG, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4689-9
   Abdallah J, 2015, PHYS DARK UNIVERSE, V9-10, P8, DOI 10.1016/j.dark.2015.08.001
   Abercrombie D., ARXIV150700966
   Ackermann M, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.231301
   Ade PAR, 2016, ASTRON ASTROPHYS, V594, DOI 10.1051/0004-6361/201525836
   Agnese R, 2018, PHYS REV D, V97, DOI 10.1103/PhysRevD.97.022002
   Agnese R, 2017, PHYS REV D, V95, DOI 10.1103/PhysRevD.95.082002
   Akerib DS, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.161302
   Akerib DS., 2017, PHYS REV LETT, V118, DOI DOI 10.1103/PHYSREVLETT.118.021303
   Alioli S, 2010, J HIGH ENERGY PHYS, DOI 10.1007/JHEP06(2010)043
   Allanach BC, 2006, PHYS REV D, V73, DOI 10.1103/PhysRevD.73.015013
   Alloul A, 2014, COMPUT PHYS COMMUN, V185, P2250, DOI 10.1016/j.cpc.2014.04.012
   Alves D, 2012, J PHYS G NUCL PARTIC, V39, DOI 10.1088/0954-3899/39/10/105005
   Alwall J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2014)079
   Amole C, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.251301
   An H., 2012, JHEP, V07, P182
   Angloher G, 2016, EUR PHYS J C, V76, DOI 10.1140/epjc/s10052-016-3877-3
   Angloher G, 2014, EUR PHYS J C, V74, DOI 10.1140/epjc/s10052-014-3184-9
   Angloher G., ARXIV150308065 CRESS
   Angloher G., ARXIV170108157 CRESS
   [Anonymous], ARXIV11112359
   [Anonymous], 2017, 15 INT C TOP ASTR UN
   [Anonymous], ARXIV170905681, Patent No. 170905681
   [Anonymous], 2010, PARTICLE DARK MATTER
   [Anonymous], 2017, ATLASCONF2017060
   [Anonymous], 2017, ATLAS DM SIMPLIFIED
   [Anonymous], ARXIV171111520 ATLAS
   [Anonymous], ARXIV150902910 LZ CO
   [Anonymous], ARXIV14092893
   [Anonymous], CMSPASEXO16048
   [Anonymous], ARXIV170305703
   [Anonymous], ARXIV170309144
   Aprile E, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.181301
   Aprile E, 2016, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2016/04/027
   Arbey A, 2014, PHYS REV D, V89, DOI 10.1103/PhysRevD.89.077701
   Arcadi G, 2018, EUR PHYS J C, V78, DOI 10.1140/epjc/s10052-018-5662-y
   Athron P, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5196-8
   Athron P, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5167-0
   Athron P, 2017, EUR PHYS J C, V77, DOI [10.1140/epjc/s10052-017-5321-8, 10.1140/epjc/s10052-017-5513-2]
   Athron P, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5113-1
   ATLAS Collaboration, 2016, SEARCH NEW LIGHT RES
   ATLAS Collaboration, 2016, ATLASCONF2016030
   Bagnaschi E, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4810-0
   Bagnaschi E, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4639-6
   Bagnaschi E., ARXIV171011091
   Bagnaschi EA, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3718-9
   Ball RD, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP04(2015)040
   Baltz EA, 2006, PHYS REV D, V74, DOI 10.1103/PhysRevD.74.103521
   Barducci D, 2018, COMPUT PHYS COMMUN, V222, P327, DOI 10.1016/j.cpc.2017.08.028
   Barr A, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4752-6
   Battaglieri M., ARXIV170704591
   Baudis L, 2013, PHYS REV D, V88, DOI 10.1103/PhysRevD.88.115014
   Baum S., ARXIV170906051
   Bell NF, 2017, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2017/03/015
   Bell NF, 2017, J COSMOL ASTROPART P, DOI 10.1088/1475-7512/2017/01/039
   Bergström L, 2000, REP PROG PHYS, V63, P793, DOI 10.1088/0034-4885/63/5/2r3
   Bernal N, 2009, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2009/01/046
   BERNSTEIN J, 1985, PHYS REV D, V32, P3261, DOI 10.1103/PhysRevD.32.3261
   Bertone G, 2007, PHYS REV LETT, V99, DOI 10.1103/PhysRevLett.99.151301
   Bertone G, 2005, PHYS REP, V405, P279, DOI 10.1016/j.physrep.2004.08.031
   Bertone G, 2010, PHYS REV D, V82, DOI 10.1103/PhysRevD.82.055008
   Bertone G., ARXIV161102704
   Bertone G, 2016, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2016/04/037
   Bertone G, 2010, NATURE, V468, P389, DOI 10.1038/nature09509
   Bishara F., ARXIV170802678
   Bishara F, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP11(2017)059
   Bishara F, 2017, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2017/02/009
   Bozorgnia N., 2016, JCAP, V05
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brennan AJ, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP05(2016)112
   Bringmann T, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5155-4
   Buchmueller O, 2016, EUR PHYS J C, V76, DOI 10.1140/epjc/s10052-016-4010-3
   Buchmueller O, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3675-3
   Buchmueller O, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2014)025
   Buchmueller O, 2011, EUR PHYS J C, V71, DOI 10.1140/epjc/s10052-011-1722-2
   Buchmueller O, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.181802
   Buchmueller O, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2015)037
   Buckley MR, 2015, PHYS REV D, V91, DOI 10.1103/PhysRevD.91.015017
   Busoni G., ARXIV160304156
   Busoni G, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/03/022
   Cacciari M, 2012, EUR PHYS J C, V72, DOI 10.1140/epjc/s10052-012-1896-2
   Cao XG, 2014, SCI CHINA PHYS MECH, V57, P1476, DOI 10.1007/s11433-014-5521-2
   Caron S, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-4814-9
   Cerdeño DG, 2015, PHYS REV D, V91, DOI 10.1103/PhysRevD.91.123530
   Chala M, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2015)089
   Charles E, 2016, PHYS REP, V636, P1, DOI 10.1016/j.physrep.2016.05.001
   Chollet F., 2015, KERAS
   CMS Collaboration, 2017, PHYS LETT B, V772, P882, DOI 10.1016/j.physletb.2017.09.029
   Costa JC, 2018, EUR PHYS J C, V78, DOI 10.1140/epjc/s10052-018-5633-3
   Cotta RC, 2014, PHYS REV D, V90, DOI 10.1103/PhysRevD.90.013020
   Crivellin A, 2014, PHYS REV LETT, V112, DOI 10.1103/PhysRevLett.112.191304
   Cui YO, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.095006
   D'Ambrosio G, 2002, NUCL PHYS B, V645, P155, DOI 10.1016/S0550-3213(02)00836-2
   D'Eramo F, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP08(2016)111
   D'Eramo F, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP04(2015)054
   de Favereau J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2014)057
   de Vries KJ, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3599-y
   Deisenroth M.P., ARXIV150202843
   Demir DA, 2014, PHYS REV D, V90, DOI 10.1103/PhysRevD.90.095015
   Dercks D, 2017, COMPUT PHYS COMMUN, V221, P383, DOI 10.1016/j.cpc.2017.08.021
   Dolan M. J., ARXIV171109906
   Drees M, 2015, COMPUT PHYS COMMUN, V187, P227, DOI 10.1016/j.cpc.2014.10.018
   Dreiner H, 2013, EPL-EUROPHYS LETT, V102, DOI 10.1209/0295-5075/102/51001
   Dror JA, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.075036
   Duerr M, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP04(2017)143
   Duerr M, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2016)042
   Duerr M, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.231801
   Dutta J, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP01(2016)051
   Ekstedt A, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP11(2016)071
   Ellis J, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP08(2017)053
   Englert C, 2016, PHYS DARK UNIVERSE, V14, P48, DOI 10.1016/j.dark.2016.09.002
   Fairbairn M, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2016)018
   Fallows S., TEVPA C 2017
   Feroz F, 2009, MON NOT R ASTRON SOC, V398, P1601, DOI 10.1111/j.1365-2966.2009.14548.x
   Fox PJ, 2013, PHYS REV D, V87, DOI 10.1103/PhysRevD.87.054030
   Frandsen MT, 2012, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2012)123
   Frixione S, 2007, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2007/12/070
   Fuetal C., 2017, PHYS REV LETT, V118
   Gelmini G, 2006, PHYS REV D, V74, DOI 10.1103/PhysRevD.74.083514
   GONDOLO P, 1991, NUCL PHYS B, V360, P145, DOI 10.1016/0550-3213(91)90438-4
   Green AM, 2008, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2008/07/005
   Haisch U, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP06(2015)078
   Haisch U, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2013)007
   Haisch U, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2013)125
   Harris P, 2015, PHYS REV D, V91, DOI 10.1103/PhysRevD.91.055009
   Hoferichter M, 2017, PHYS REV LETT, V119, DOI 10.1103/PhysRevLett.119.181803
   Hoferichter M, 2015, PHYS LETT B, V746, P410, DOI 10.1016/j.physletb.2015.05.041
   Hooper D, 2007, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2007/03/017
   HUT P, 1977, PHYS LETT B, V69, P85, DOI 10.1016/0370-2693(77)90139-3
   Ismail A, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2017)165
   Ismail A, 2017, NUCL PHYS B, V918, P220, DOI 10.1016/j.nuclphysb.2017.03.001
   Jacques T, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP10(2016)071
   Jacques T, 2015, J HIGH ENERGY PHYS, DOI 10.1007/JHEP06(2015)142
   Jin X., ARXIV151207030
   Jungman G, 1996, PHYS REP, V267, P195, DOI 10.1016/0370-1573(95)00058-5
   Kahlhoefer F, 2017, INT J MOD PHYS A, V32, DOI 10.1142/S0217751X1730006X
   Kahlhoefer F, 2016, J HIGH ENERGY PHYS, DOI 10.1007/JHEP02(2016)016
   Khachatryan V, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.031802
   Kim JS, 2015, COMPUT PHYS COMMUN, V196, P535, DOI 10.1016/j.cpc.2015.06.002
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Klos P, 2014, PHYS REV D, V89, DOI 10.1103/PhysRevD.89.029901
   Klos P, 2013, PHYS REV D, V88, DOI 10.1103/PhysRevD.88.083516
   LEE BW, 1977, PHYS REV LETT, V39, P165, DOI 10.1103/PhysRevLett.39.165
   Lefranc V, 2015, PHYS REV D, V91, DOI 10.1103/PhysRevD.91.122003
   Liem S., 2016, JHEP, V09
   Liu JY, 2012, J PHYS G NUCL PARTIC, V39, DOI 10.1088/0954-3899/39/5/055003
   Malik SA, 2015, PHYS DARK UNIVERSE, V9-10, P51, DOI 10.1016/j.dark.2015.03.003
   Mambrini Y, 2012, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2012/11/038
   Martini A., SPIN 0 SPIN 1 SIMPLI
   McCabe C., 2016, J COSMOL ASTROPART P, V05
   McCabe C, 2017, PHYS REV D, V96, DOI 10.1103/PhysRevD.96.043010
   McCabe C, 2010, PHYS REV D, V82, DOI 10.1103/PhysRevD.82.023530
   Nason P, 2004, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2004/11/040
   Olive KA, 2014, CHINESE PHYS C, V38, DOI 10.1088/1674-1137/38/9/090001
   Papucci M, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP11(2014)024
   Pérez PF, 2014, PHYS LETT B, V735, P283, DOI 10.1016/j.physletb.2014.06.057
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Rehagen T, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/06/039
   Rogers HE, 2017, PHYS REV D, V95, DOI 10.1103/PhysRevD.95.082003
   Ross GG, 2016, PHYS LETT B, V759, P110, DOI 10.1016/j.physletb.2016.05.053
   Roszkowski L, 2017, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2017/10/005
   Roszkowski L, 2016, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2016/08/03
   Roszkowski L, 2012, PHYS REV D, V86, DOI 10.1103/PhysRevD.86.095005
   SCHERRER RJ, 1986, PHYS REV D, V33, P1585, DOI 10.1103/PhysRevD.33.1585
   SCHERRER RJ, 1986, PHYS REV D, V34, P3263, DOI 10.1103/PhysRevD.34.3263
   Schumann M, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/10/016
   Silverwood H, 2015, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2015/03/055
   Sirunyan AM, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5317-4
   Sirunyan AM, 2017, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2017)014
   Sirunyan AM, 2017, PHYS LETT B, V769, P520, DOI 10.1016/j.physletb.2017.02.012
   Sjöstrand T, 2008, COMPUT PHYS COMMUN, V178, P852, DOI 10.1016/j.cpc.2008.01.036
   Skilling J, 2004, AIP CONF PROC, V735, P395, DOI 10.1063/1.1835238
   SREDNICKI M, 1988, NUCL PHYS B, V310, P693, DOI 10.1016/0550-3213(88)90099-5
   STEIGMAN G, 1979, ANNU REV NUCL PART S, V29, P313, DOI 10.1146/annurev.ns.29.120179.001525
   Steigman G, 2012, PHYS REV D, V86, DOI 10.1103/PhysRevD.86.023506
   Strege C, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP09(2014)081
   Strege C, 2012, J COSMOL ASTROPART P, DOI 10.1088/1475-7516/2012/03/030
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Trotta R, 2008, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2008/12/024
   WOLFRAM S, 1979, PHYS LETT B, V82, P65, DOI 10.1016/0370-2693(79)90426-X
NR 186
TC 26
Z9 26
U1 0
U2 18
PD MAR
PY 2018
IS 3
AR 026
DI 10.1088/1475-7516/2018/03/026
WC Astronomy & Astrophysics; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Taher, FN
   Callenes-Sloan, J
AF Taher, Farah Naz
   Callenes-Sloan, Joseph
GP IEEE
BE Wang, G
   Tsuchiya, T
   Xiang, D
TI Hardware Fault Compensation Using Discriminative Learning
SO 2015 IEEE 21ST PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE
   COMPUTING (PRDC)
SE IEEE Pacific Rim International Symposium on Dependable Computing
DT Proceedings Paper
CT IEEE 21st Pacific Rim International Symposium on Dependable Computing
   (PRDC 2015)
CY NOV 18-20, 2015
CL Zhangjiajie, PEOPLES R CHINA
DE Hardware Fault; Error Tolerance; Approximate Computing; Error
   Compensation; Supervised learning; Machine Learning
ID TOLERANCE; SYSTEMS; DEFECT
AB With process scaling and the adoption of post-CMOS technologies, permanent faults are becoming a fundamental problem. Circuits containing defects are either discarded (reducing yield) or partially disabled (reducing performance). In this paper, we propose a general approach using supervised and discriminative learning techniques to compensate for the effect of permanent faults on a circuit's output. The insight for this approach is that many emerging systems and applications are able to tolerate some loss of quality in their computed results. Therefore, more scalable and lower overhead compensation techniques may be used to approximately correct for the effect of hardware faults on the circuit output. The proposed approach is shown to improve the output quality of complex accelerator and application-specific logic by 2-3 orders of magnitude while incurring <10% area overhead and <3% performance overhead.
C1 [Taher, Farah Naz; Callenes-Sloan, Joseph] Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
RP Taher, FN (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richardson, TX 75083 USA.
EM farah.taher@utdallas.edu; jcallenes.sloan@utdallas.edu
CR Abdallah RA, 2013, IEEE T MULTIMEDIA, V15, P257, DOI 10.1109/TMM.2012.2231667
   Almukhaizim S, 2004, IEEE VLSI TEST SYMP, P319, DOI 10.1109/VTEST.2004.1299259
   [Anonymous], 2013, INT TECHNOLOGY ROADM
   [Anonymous], 2006, LANDSCAPE PARALLEL C
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Breuer MA, 2004, IEEE DES TEST COMPUT, V21, P216, DOI 10.1109/MDT.2004.8
   Cheng SW, 2003, ICECS 2003: PROCEEDINGS OF THE 2003 10TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND SYSTEMS, VOLS 1-3, P1168
   Cunningham P, 2008, COGN TECHNOL, P21, DOI 10.1007/978-3-540-75171-7_2
   Graphics Mentor, 2007, MODELSIM
   Hall Mark, 2009, SIGKDD EXPLORATIONS, V11, P10, DOI DOI 10.1145/1656274.1656278
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   KOREN I, 1990, COMPUTER, V23, P73, DOI 10.1109/2.56854
   Koren I, 1998, P IEEE, V86, P1819, DOI 10.1109/5.705525
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kotsiantis SB, 2007, INFORM-J COMPUT INFO, V31, P249
   Kuncheva LI, 2003, MACH LEARN, V51, P181, DOI 10.1023/A:1022859003006
   Lin JF, 2007, IEEE T CIRCUITS-I, V54, P1050, DOI 10.1109/TCSI.2007.895509
   Ng AY, 2002, ADV NEUR IN, V14, P841
   Sartori J, 2011, PROCEEDINGS OF THE PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURES AND SYNTHESIS FOR EMBEDDED SYSTEMS (CASES '11), P135
   Shanbhag N, 2002, DES AUT CON, P830, DOI 10.1109/DAC.2002.1012737
   Shim B, 2003, CONF REC ASILOMAR C, P1493
   Sloan J, 2013, 2013 43 ANN IEEE IFI, P1, DOI [10.1109/DSN.2013.6575309, DOI 10.1109/DSN.2013.6575309]
   Stanisavljevic M, 2011, RELIABILITY OF NANOSCALE CIRCUITS AND SYSTEMS: METHODOLOGIES AND CIRCUIT ARCHITECTURES, P1, DOI 10.1007/978-1-4419-6217-1
   Varatkar GV, 2006, ISLPED '06: PROCEEDINGS OF THE 2006 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P113, DOI 10.1109/LPE.2006.4271817
   Verma N, 2012, INT CONF ACOUST SPEE, P5285, DOI 10.1109/ICASSP.2012.6289113
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2015
BP 225
EP 234
DI 10.1109/PRDC.2015.44
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Schwenker, B
   Herzberg, L
   Buch, Y
   Frey, A
   Natochii, A
   Vahsen, S
   Nakayama, H
AF Schwenker, B.
   Herzberg, L.
   Buch, Y.
   Frey, A.
   Natochii, A.
   Vahsen, S.
   Nakayama, H.
TI A neural network for beam background decomposition in Belle II at
   SuperKEKB
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Belle II; SuperKEKB; Beam background; Neural networks; Nonlinear
   regression; Machine learning for accelerators
AB We describe a neural network for predicting the background hit rate in the Belle II detector produced by the SuperKEKB electron-positron collider. The neural network, BGNet, learns to predict the individual contributions of different physical background sources, such as beam-gas scattering or continuous top-up injections into the collider, to Belle II sub-detector rates. The samples for learning are archived 1 Hz time series of diagnostic variables from the SuperKEKB collider subsystems and measured hit rates of Belle II used as regression targets. We test the learned model by predicting detector hit rates on archived data from different run periods not used during training. We show that a feature attribution method can help interpret the source of changes in the background level over time.
C1 [Schwenker, B.; Herzberg, L.; Buch, Y.; Frey, A.] Georg August Univ Gottingen, Phys Inst 2, D-37073 Gottingen, Germany.
   [Natochii, A.; Vahsen, S.] Univ Hawaii, Honolulu, HI 96822 USA.
   [Nakayama, H.] High Energy Accelerator Res Org KEK, Tsukuba 3050801, Japan.
   [Nakayama, H.] Grad Univ Adv Studies, SOKENDAI, Hayama 2400193, Japan.
RP Schwenker, B (corresponding author), Georg August Univ Gottingen, Phys Inst 2, D-37073 Gottingen, Germany.
EM benjamin.schwenker@phys.uni-goettingen.de
CR Abadi Martin, 2015, TENSORFLOW LARGE SCA
   Abe T, 2010, Arxiv, DOI [arXiv:1011.0352, 10.48550/ARXIV.1011.0352, DOI 10.48550/ARXIV.1011.0352]
   Abe T., 2013, PROG THEOR EXP PHYS, V2013, DOI [10.1093/ptep/pts102, DOI 10.1093/PTEP/PTZ030]
   Adachi I, 2018, NUCL INSTRUM METH A, V907, P46, DOI 10.1016/j.nima.2018.03.068
   Bacher S, 2021, NUCL INSTRUM METH A, V997, DOI 10.1016/j.nima.2021.165157
   Chollet F., 2015, KERAS
   Erion G, 2020, Arxiv, DOI arXiv:1906.10670
   Glorot X., 2010, P JMLR WORKSH C P 13, P249, DOI DOI 10.1177/1753193409103364.
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Ishibashi T, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.053501
   Janizek JD, 2021, J MACH LEARN RES, V22
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Lemaître G, 2017, J MACH LEARN RES, V18
   Lewis PM, 2019, NUCL INSTRUM METH A, V914, P69, DOI 10.1016/j.nima.2018.05.071
   Liptak Z.J., 2021, MEASUREMENTS BEAM BA, V2, P22, DOI [10.1016/j.nima.2022.167168, DOI 10.1016/J.NIMA.2022.167168]
   Mitsuka G., 2021, PROC 3 J PARC S J PA, V33, DOI [10.7566/JPSCP.33.011007, DOI 10.7566/JPSCP.33.011007]
   Natochii A, 2023, Arxiv, DOI [arXiv:2302.01566, 10.48550/arXiv.2302.01566, DOI 10.48550/ARXIV.2302.01566]
   Ohnishi Y, 2013, PROG THEOR EXP PHYS, V2013, DOI 10.1093/ptep/pts083
   Park S, 2018, Arxiv, DOI arXiv:1806.08933
   Schwenker Benjamin, 2022, BGNET
   slacmshankar.github.io, EPICS ARCH APPL
   Suetsugu Y, 2008, NUCL INSTRUM METH A, V597, P153, DOI 10.1016/j.nima.2008.09.023
   Sundararajan M, 2017, PR MACH LEARN RES, V70
   The Belle II Collaboration, BELL 2 AN SOFTW FRAM
   Wolski A., 2014, BEAM DYNAMICS HIGH E
NR 25
TC 0
Z9 0
U1 2
U2 2
PD APR
PY 2023
VL 1049
AR 168112
DI 10.1016/j.nima.2023.168112
EA FEB 2023
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Wallis, L
   Paich, M
AF Wallis, Lyle
   Paich, Mark
BE Chan, V
   DAmbrogio, A
   Zacharewicz, G
   Mustafee, N
TI INTEGRATING ARTIFICAL INTELLIGENCE WITH ANYLOGIC SIMULATION
SO 2017 WINTER SIMULATION CONFERENCE (WSC)
SE Winter Simulation Conference Proceedings
DT Proceedings Paper
CT Winter Simulation Conference (WSC)
CY DEC 03-06, 2017
CL Las Vegas, NV
AB Simulation is one of five key technologies that PwC's Artificial Intelligence Accelerator lab uses to build Artificial Intelligence (AI) applications. Application of AI is accelerating rapidly, spawning new sectors, and resulting in unprecedented reach, power, and influence. Simulation explicitly captures the behavior of agents and processes that can either be described by or replaced by AI components. AI components can be embedded into a simulation to provide learning or adaptive behavior. And, simulation can be used to evaluate the impact of introducing AI into a "real world system" such as supply chains or production processes. In this workshop we will demonstrate an Agent-Based Model with Reinforcement Learning for Autonomous Fleet Coordination; demonstrate and describe in detail a version of the AnyLogic Consumer Market Model that has been modified to include adaptive dynamics based on deep learning; and describe approaches to integrating machine learning to the design and development of simulations.
C1 [Wallis, Lyle; Paich, Mark] PwC, 101 N Wacker Dr, Chicago, IL 60606 USA.
RP Wallis, L (corresponding author), PwC, 101 N Wacker Dr, Chicago, IL 60606 USA.
NR 0
TC 5
Z9 5
U1 1
U2 21
PY 2017
BP 4449
EP 4449
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Obermair, C
   Cartier-Michaud, T
   Apollonio, A
   Millar, W
   Felsberger, L
   Fischl, L
   Bovbjerg, HS
   Wollmann, D
   Wuensch, W
   Catalan-Lasheras, N
   Boronat, M
   Pernkopf, F
   Burt, G
AF Obermair, Christoph
   Cartier-Michaud, Thomas
   Apollonio, Andrea
   Millar, William
   Felsberger, Lukas
   Fischl, Lorenz
   Bovbjerg, Holger Severin
   Wollmann, Daniel
   Wuensch, Walter
   Catalan-Lasheras, Nuria
   Boronat, Marca
   Pernkopf, Franz
   Burt, Graeme
TI Explainable machine learning for breakdown prediction in high gradient
   rf cavities
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB The occurrence of vacuum arcs or radio frequency (rf) breakdowns is one of the most prevalent factors limiting the high-gradient performance of normal conducting rf cavities in particle accelerators. In this paper, we search for the existence of previously unrecognized features related to the incidence of rf breakdowns by applying a machine learning strategy to high-gradient cavity data from CERN's test stand for the Compact Linear Collider (CLIC). By interpreting the parameters of the learned models with explainable artificial intelligence (AI), we reverse-engineer physical properties for deriving fast, reliable, and simple rule-based models. Based on 6 months of historical data and dedicated experiments, our models show fractions of data with a high influence on the occurrence of breakdowns. Specifically, it is shown that the field emitted current following an initial breakdown is closely related to the probability of another breakdown occurring shortly thereafter. Results also indicate that the cavity pressure should be monitored with increased temporal resolution in future experiments, to further explore the vacuum activity associated with breakdowns.
C1 [Obermair, Christoph; Cartier-Michaud, Thomas; Apollonio, Andrea; Millar, William; Felsberger, Lukas; Fischl, Lorenz; Bovbjerg, Holger Severin; Wollmann, Daniel; Wuensch, Walter; Catalan-Lasheras, Nuria; Boronat, Marca] CERN, CH-1211 Geneva, Switzerland.
   [Obermair, Christoph] Graz Univ Technol, AT-8010 Graz, Austria.
   [Pernkopf, Franz] Graz Univ Technol, Graz, Austria.
   [Millar, William; Burt, Graeme] Univ Lancaster, Cockcroft Inst, Lancaster, England.
   [Fischl, Lorenz] Vienna Univ Technol, Vienna, Austria.
   [Bovbjerg, Holger Severin] Aalborg Univ, Aalborg, Denmark.
RP Obermair, C (corresponding author), CERN, CH-1211 Geneva, Switzerland.; Obermair, C (corresponding author), Graz Univ Technol, AT-8010 Graz, Austria.
EM christoph.obermair@cern.ch
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Adolphsen C, 2003, PROCEEDINGS OF THE 2003 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P668, DOI 10.1109/PAC.2003.1289005
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   [Anonymous], 2011, ULTIMATE QUOTABLE EI
   [Anonymous], 2007, PATTERN RECOGN, V16
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Banon Caballero D., 2019, P 10 INT PARTICLE AC
   Banon-Caballero D., 2019, P 10 INT PARTICLE AC, P2944
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Chattopadhay A, 2018, IEEE WINT CONF APPL, P839, DOI 10.1109/WACV.2018.00097
   Chen J., 2017, ADV NEUR IN, V30
   Christ M., 2016, DISTRIB PARALLEL DAT
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Convery O, 2021, PHYS REV ACCEL BEAMS, V24, DOI 10.1103/PhysRevAccelBeams.24.074602
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Craievich P., 2018, P 29 INT LINEAR ACCE
   Descoeudres A, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.092001
   Dolgashev V. A., 2010, P 25 INT LIN ACC C L, V2
   Donon Y, 2020, 2020 VI INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY AND NANOTECHNOLOGY (IEEE ITNT-2020), DOI 10.1109/ITNT49337.2020.9253296
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Engelberg EZ, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.123501
   Engelberg EZ, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.124801
   FARKAS ZD, 1974, 9 INT C HIGH EN ACC
   Fawaz HI, 2020, DATA MIN KNOWL DISC, V34, P1936, DOI 10.1007/s10618-020-00710-y
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Felsberger L., 2020, MACHINE LEARNING KNO, V12279
   Fol E, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.102805
   Franceschi J.-Y., 2019, ADV NEURAL INFORM PR, V32, P4650
   Gade K., 2020, EXPLAINABLE IND
   Ghorbani A, 2019, ADV NEUR IN, V32
   Giner Navarro J., 2016, THESIS U VALENCIA
   Girin L, 2022, Arxiv, DOI arXiv:2008.12595
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Grudiev A, 2009, PHYS REV SPEC TOP-AC, V12, DOI 10.1103/PhysRevSTAB.12.102001
   Guo J, 2020, IEEE T RELIAB, V69, P1110, DOI 10.1109/TR.2019.2957965
   Guyon I, 2002, MACH LEARN, V46, P389, DOI 10.1023/A:1012487302797
   Guyon I., 2003, Journal of Machine Learning Research, V3, P1157, DOI 10.1162/153244303322753616
   Hinton G., 2002, ADV NEURAL INFORM PR, V15, P833, DOI DOI 10.1109/TSMCB.2011.2106208
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Jeyakumar Jeya Vikranth, 2020, ADV NEURAL INFORM PR
   Kim B, 2018, PR MACH LEARN RES, V80
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Korsbäck A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.033102
   Kovermann J. W., 2010, THESIS
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lakkaraju H, 2017, PR MACH LEARN RES, V54, P166
   Lasheras N. C., 2017, P 28 INT LIN C, P4
   Lucas TG, 2019, NUCL INSTRUM METH A, V914, P46, DOI 10.1016/j.nima.2018.10.166
   Lundberg SM, 2017, ADV NEUR IN, V30
   Obermair C., 2021, P 12 INT PARTICLE AC
   Paszkiewicz J., 2019, P 10 INT PARTICLE AC
   Paszkiewicz J., 2021, THESIS STJOHNS COLL
   Qureshi MA, 2019, J INTELL INF SYST, V53, P137, DOI 10.1007/s10844-018-0511-x
   Ran YY, 2019, Arxiv, DOI arXiv:1912.07383
   Reardon Sara, 2019, Nature, V576, pS54, DOI 10.1038/d41586-019-03847-z
   Sak H, 2014, INTERSPEECH, P338
   Shapley L., 1997, VALUE N PERSON GAMES, P69, DOI 10.1515/9781400829156-012
   Shrikumar A., 2016, ARXIV
   Sicking E, 2020, NAT PHYS, V16, P386, DOI 10.1038/s41567-020-0834-8
   Simard PY, 2003, PROC INT CONF DOC, P958
   Simonyan K, 2014, Arxiv, DOI [arXiv:1312.6034, DOI 10.48550/ARXIV.1312.6034]
   Song L, 2007, Arxiv, DOI arXiv:0704.2668
   Szegedy C., 2016, ARXIV, DOI DOI 10.1609/AAAI.V31I1.11231
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Ribeiro MT, 2016, Arxiv, DOI [arXiv:1602.04938, DOI 10.48550/ARXIV.1602.04938]
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Weng SF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174944
   Wojtas M., 2020, ADV NEUR IN, V33
   WOLD S, 1987, CHEMOMETR INTELL LAB, V2, P37, DOI 10.1016/0169-7439(87)80084-9
   Woolley B, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.122002
   Woolley B. J., 2015, THESIS LANCASTER U
   Woolley B, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.101001
   Wuensch W., 2014, P 5 INT PART ACC C I
   Xie SR, 2019, PHYS REV B, V100, DOI 10.1103/PhysRevB.100.174513
   Yeh C.-K., 2020, ADV NEURAL INFORM PR
   Zennaro R., 2017, P 8 INT PARTICLE ACC, P4318
   Zhao BD, 2017, J SYST ENG ELECTRON, V28, P162, DOI 10.21629/JSEE.2017.01.18
NR 79
TC 4
Z9 5
U1 0
U2 0
PD OCT 4
PY 2022
VL 25
IS 10
AR 104601
DI 10.1103/PhysRevAccelBeams.25.104601
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Vandendriessche, J
   Wouters, N
   da Silva, B
   Lamrini, M
   Chkouri, MY
   Touhafi, A
AF Vandendriessche, Jurgen
   Wouters, Nick
   da Silva, Bruno
   Lamrini, Mimoun
   Chkouri, Mohamed Yassin
   Touhafi, Abdellah
TI Environmental Sound Recognition on Embedded Systems: From FPGAs to TPUs
SO ELECTRONICS
DT Article
DE environmental sound recognition; supervised learning; neural networks;
   embedded systems; FPGA; TPU; DPU; Vitis AI; hls4ml
AB In recent years, Environmental Sound Recognition (ESR) has become a relevant capability for urban monitoring applications. The techniques for automated sound recognition often rely on machine learning approaches, which have increased in complexity in order to achieve higher accuracy. Nonetheless, such machine learning techniques often have to be deployed on resource and power-constrained embedded devices, which has become a challenge with the adoption of deep learning approaches based on Convolutional Neural Networks (CNNs). Field-Programmable Gate Arrays (FPGAs) are power efficient and highly suitable for computationally intensive algorithms like CNNs. By fully exploiting their parallel nature, they have the potential to accelerate the inference time as compared to other embedded devices. Similarly, dedicated architectures to accelerate Artificial Intelligence (AI) such as Tensor Processing Units (TPUs) promise to deliver high accuracy while achieving high performance. In this work, we evaluate existing tool flows to deploy CNN models on FPGAs as well as on TPU platforms. We propose and adjust several CNN-based sound classifiers to be embedded on such hardware accelerators. The results demonstrate the maturity of the existing tools and how FPGAs can be exploited to outperform TPUs.
C1 [Vandendriessche, Jurgen; Touhafi, Abdellah] Vrije Univ Brussel VUB, Dept Engn Sci & Technol INDI, B-1050 Brussels, Belgium.
   [Wouters, Nick; da Silva, Bruno; Touhafi, Abdellah] Vrije Univ Brussel VUB, Dept Elect & Informat ETRO, B-1050 Brussels, Belgium.
   [Lamrini, Mimoun; Chkouri, Mohamed Yassin] Univ Abdelmalek Essaadi UAE, Dept Comp Engn SIGL Lab, Tetouan 93000, Morocco.
RP Vandendriessche, J (corresponding author), Vrije Univ Brussel VUB, Dept Engn Sci & Technol INDI, B-1050 Brussels, Belgium.; da Silva, B (corresponding author), Vrije Univ Brussel VUB, Dept Elect & Informat ETRO, B-1050 Brussels, Belgium.
EM Jurgen.Vandendriessche@vub.be; Nick.Wouters@vub.be;
   Bruno.da.Silva@vub.be; Lamrini.Mimoun-etu@uae.ac.ma;
   mychkouri@uae.ac.ma; Abdellah.Touhafi@vub.be
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Adamson A., 2019, PARIS TESTING NOISE
   Bountourakis V, 2015, PROCEEDINGS OF THE 10TH AUDIO MOSTLY: A CONFERENCE ON INTERACTION WITH SOUND, AM'15, DOI 10.1145/2814895.2814905
   Brandalero M, 2020, 2020 INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS (IEEE COINS 2020), P208, DOI 10.1109/coins49042.2020.9191672
   Coelho CN, 2021, NAT MACH INTELL, V3, P675, DOI 10.1038/s42256-021-00356-5
   Cosmas K, 2020, AEROSPACE-BASEL, V7, DOI 10.3390/aerospace7110159
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Fahim F., 2021, ARXIV210305579
   Faraone J, 2018, I C FIELD PROG LOGIC, P97, DOI 10.1109/FPL.2018.00025
   Font F., 2013, P 21 ACM INT C MULT, P411
   Hubara Itay, 2020, ARXIV200610518
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Ju-won Pak, 2019, 2019 International Conference on Artificial Intelligence in Information and Communication (ICAIIC), P430, DOI 10.1109/ICAIIC.2019.8669006
   Lhoest L, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188394
   Liu YZ, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1025
   López JM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030605
   McFee B., 2021, LIBROSA LIBROSA 0 8, DOI [10.5281/zenodo.4792298.25, DOI 10.5281/ZENODO.4792298.25]
   Nordby J., 2019, THESIS NORWEGIAN U L
   Ozkan Y., 2019, P 2019 IEEE INT S TE, P1, DOI [10.1109/HST47167.2019.9032996, DOI 10.1109/HST47167.2019.9032996]
   Pappalardo A., DOI 10.5281/zenodo.3333552
   Piczak KJ, 2015, IEEE INT WORKS MACH
   Piczak KJ, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P1015, DOI 10.1145/2733373.2806390
   Rancaño X, 2020, IEEE IND ELEC, P2286, DOI [10.1109/IECON43393.2020.9255055, 10.1109/iecon43393.2020.9255055]
   Salamon J, 2017, IEEE SIGNAL PROC LET, V24, P279, DOI 10.1109/LSP.2017.2657381
   Salamon J, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P1041, DOI 10.1145/2647868.2655045
   Shah SK, 2019, IEEE INT CONF BIG DA, P4179, DOI 10.1109/BigData47090.2019.9006176
   Silva B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9183885
   Srivastava S, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8378, DOI 10.1109/ICASSP39728.2021.9414287
   Tsalera E, 2020, ENERGY REP, V6, P223, DOI 10.1016/j.egyr.2020.08.045
   Turchet L, 2020, IEEE INTERNET THINGS, V7, P10233, DOI 10.1109/JIOT.2020.2997047
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Zhu M., 2017, ARXIV PREPRINT ARXIV
NR 34
TC 4
Z9 4
U1 1
U2 15
PD NOV
PY 2021
VL 10
IS 21
AR 2622
DI 10.3390/electronics10212622
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Elhosary, H
   Zakhari, MH
   Elgammal, MA
   Kelany, KAH
   Abd El Ghany, MA
   Salama, KN
   Mostafa, H
AF Elhosary, Heba
   Zakhari, Michael H.
   Elgammal, Mohamed A.
   Kelany, Khaled A. Helal
   Abd El Ghany, Mohamed A.
   Salama, Khaled N.
   Mostafa, Hassan
TI Hardware Acceleration of High Sensitivity Power-Aware Epileptic Seizure
   Detection System Using Dynamic Partial Reconfiguration
SO IEEE ACCESS
DT Article
DE Feature extraction; Support vector machines; Field programmable gate
   arrays; Training; Mathematical model; Sensitivity; Machine learning; Low
   power; support vector machine (SVM); sequential minimal optimization
   (SMO); accelerator IP; feature extraction; classification; FPGA; dynamic
   partial reconfiguration (DPR); ASIC
AB In this paper, a high-sensitivity low-cost power-aware Support Vector Machine (SVM) training and classification based system, is hardware implemented for a neural seizure detection application. The training accelerator algorithm, adopted in this work, is the sequential minimal optimization (SMO). System blocks are implemented to achieve the best trade-off between sensitivity and the consumption of area and power. The proposed seizure detection system achieves 98.38% sensitivity when tested with the implemented linear kernel classifier. The system is implemented on different platforms: such as Field Programmable Gate Array (FPGA) Xilinx Virtex-7 board and Application Specific Integrated Circuit (ASIC) using hardware-calibrated UMC 65nm CMOS technology. A power consumption evaluation is performed on both the ASIC and FPGA platforms showing that the ASIC power consumption is lower by at least 65% when compared with the FPGA counterpart. A power-aware system is implemented with FPGAs by the adoption of the Dynamic Partial Reconfiguration (DPR) technique that allows the dynamic operation of the system based on power level available to the system at the expense of degradation of the system accuracy. The proposed system exploits the advantages of DPR technology in FPGAs to switch between two proposed designs providing a decrease of 64% in power consumption.
C1 [Elhosary, Heba; Abd El Ghany, Mohamed A.] German Univ Cairo GUC, Dept Elect, New Cairo 11835, Egypt.
   [Zakhari, Michael H.; Elgammal, Mohamed A.; Kelany, Khaled A. Helal; Mostafa, Hassan] Cairo Univ, Dept Elect & Commun Engn, Giza 12613, Egypt.
   [Salama, Khaled N.] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn Div, Thuwal 23955, Saudi Arabia.
   [Mostafa, Hassan] Univ Sci & Technol, Zewail City Sci & Technol, Nanotechnol & Nanoelect Program, Giza 12578, Egypt.
   [Abd El Ghany, Mohamed A.] Tech Univ Darmstadt, Integrated Elect Syst Lab, D-64289 Darmstadt, Germany.
RP Mostafa, H (corresponding author), Cairo Univ, Dept Elect & Commun Engn, Giza 12613, Egypt.; Mostafa, H (corresponding author), Univ Sci & Technol, Zewail City Sci & Technol, Nanotechnol & Nanoelect Program, Giza 12578, Egypt.
EM hmostafa@uwaterloo.ca
CR Boonyakitanont P, 2020, INT CONF ACOUST SPEE, P1225, DOI [10.1109/ICASSP40776.2020.9053143, 10.1109/icassp40776.2020.9053143]
   Devarajan Kavya, 2014, International Journal of Engineering and Technology, V6, P215, DOI 10.7763/IJET.2014.V6.698
   Elgammal MA, 2019, MIDWEST SYMP CIRCUIT, P646, DOI [10.1109/MWSCAS.2019.8884989, 10.1109/mwscas.2019.8884989]
   Elgammal MA, 2018, MIDWEST SYMP CIRCUIT, P795, DOI 10.1109/MWSCAS.2018.8624031
   Elhazek Y., 2019, P 8 INT C MOD CIRC S P 8 INT C MOD CIRC S, P1
   Elhosary H, 2019, IEEE T BIOMED CIRC S, V13, P1324, DOI 10.1109/TBCAS.2019.2947044
   Feng LC, 2018, IEEE T BIOMED CIRC S, V12, P171, DOI 10.1109/TBCAS.2017.2762721
   Gammerman A, 2015, J MACH LEARN RES, V16, P2051
   GOTMAN J, 1990, ELECTROEN CLIN NEURO, V76, P317, DOI 10.1016/0013-4694(90)90032-F
   Hassan S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050746
   Kamaleldin A, 2017, IEEE INT SYMP CIRC S, P814
   Kerrigan JF, 2004, EPILEPSIA, V45, P346, DOI 10.1111/j.0013-9580.2004.01304.x
   Li SF, 2013, COMPUT BIOL MED, V43, P807, DOI 10.1016/j.compbiomed.2013.04.002
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Park YS, 2020, IEEE T BIO-MED ENG, V67, P817, DOI 10.1109/TBME.2019.2921448
   SCHMIDT D, 1982, J NEUROL NEUROSUR PS, V45, P1119, DOI 10.1136/jnnp.45.12.1119
   Serasinghe D, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P472, DOI 10.1109/DSD.2018.00084
   Shoeb H., 2009, THESIS MIT CAMBRIDGE THESIS MIT CAMBRIDGE
   Soliman S, 2019, INTEGRATION, V68, P108, DOI 10.1016/j.vlsi.2019.06.004
   Varsavsky A., 2016, EPILEPTIC SEIZURES E
   Wang HD, 2018, IEEE ACCESS, V6, P67277, DOI 10.1109/ACCESS.2018.2870883
   Yantir HE, 2020, MICROMACHINES-BASEL, V11, DOI 10.3390/mi11060622
   Yuan Q, 2011, EPILEPSY RES, V96, P29, DOI 10.1016/j.eplepsyres.2011.04.013
   Zhan TY, 2019, IEEE T BIOMED CIRC S, V13, P1175, DOI 10.1109/TBCAS.2019.2948301
   Zhang C, 2016, IEEE J BIOMED HEALTH, V20, P996, DOI 10.1109/JBHI.2016.2553368
NR 25
TC 1
Z9 1
U1 2
U2 4
PY 2021
VL 9
BP 75071
EP 75081
DI 10.1109/ACCESS.2021.3079155
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Peng, CH
   Chen, BW
   Kuan, TW
   Lin, PC
   Wang, JF
   Shih, NS
AF Peng, Chih-Hsiang
   Chen, Bo-Wei
   Kuan, Ta-Wen
   Lin, Po-Chuan
   Wang, Jhing-Fa
   Shih, Nai-Sheng
TI REC-STA: Reconfigurable and Efficient Chip Design With SMO-Based
   Training Accelerator
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Reconfigurable computing; sequential minimal optimization (SMO); speaker
   recognition; support vector machine (SVM); trimode coarse-grained
   reconfigurable architecture (TCRA); triple finite-state-machine with
   dynamic scheduling (TFDS); VLSI
ID ARCHITECTURE; PARALLEL
AB Sequential minimal optimization (SMO) and Karush-Kuhn-Tucker condition are often used to solve learning problems in support vector machines. However, during hardware implementation of the SMO algorithm, enhancing chip performance without excessively increasing chip area is often a crucial issue. The solution proposed in this paper is a novel reconfigurable and efficient chip design with SMO-based training accelerator (REC-STA). Two novel methods used in the proposed REC-STA are trimode coarse-grained reconfigurable architecture (TCRA) and triple finite-state-machine with dynamic scheduling The first method modifies the baseline SMO design by developing trimode reconfigurable architectures with parallel and pipeline computing capabilities. The second method provides a schedule for efficient reconfiguration of the TCRA. Use of these methods can remove kernel cache design. For chip manufacturing, the implementation of the REC-STA is synthesized, placed, and routed using the TSMC 0.18-mu m technology library. The core size is 2.94 mm x 2.94 mm and the power consumption is 77.3 mW. Compared with the baseline design, the FPGA simulation results show that the proposed architecture requires 50% less memory and 31% fewer gate counts but provides a 16-fold improvement in training performance. The experimental results confirm the efficacy of the proposed architecture and methods.
C1 [Peng, Chih-Hsiang; Chen, Bo-Wei; Kuan, Ta-Wen; Wang, Jhing-Fa; Shih, Nai-Sheng] Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
   [Lin, Po-Chuan] Tung Fang Design Inst, Multimedia & Embedded Syst Design Lab, Dept Elect Engn & Comp Sci, Kaohsiung 82941, Taiwan.
RP Peng, CH (corresponding author), Natl Cheng Kung Univ, Dept Elect Engn, Tainan 70101, Taiwan.
EM n28991188@mail.ncku.edu.tw; chenbw@mail.ncku.edu.tw;
   gwam.davin@gmail.com; tony178.lin@gmail.com; wangjf@mail.ncku.edu.tw;
   vonrandoll@hotmail.com
CR Alaria V, 2009, J OPT COMMUN NETW, V1, pB40, DOI 10.1364/JOCN.1.000B40
   [Anonymous], 1999, ADV NEURAL INFORM PR
   [Anonymous], 1998, MAKING LARGE SCALE S
   [Anonymous], 1982, ESTIMATION DEPENDENC
   [Anonymous], IEEE T NEURAL NETW
   Clemente JA, 2011, IEEE T VLSI SYST, V19, P1263, DOI 10.1109/TVLSI.2010.2050158
   Maestro JA, 2009, IEEE T DEVICE MAT RE, V9, P403, DOI 10.1109/TDMR.2009.2023081
   Billionnet A, 2007, MATH PROGRAM, V109, P55, DOI 10.1007/s10107-005-0637-9
   BUNCH JR, 1980, LINEAR ALGEBRA APPL, V34, P341, DOI 10.1016/0024-3795(80)90172-X
   Campbell WM, 2007, IEEE T AUDIO SPEECH, V15, P2085, DOI 10.1109/TASL.2007.902874
   Cao KK, 2010, J ZHEJIANG U-SCI C, V11, P620, DOI 10.1631/jzus.C0910500
   Cao LJ, 2006, IEEE T NEURAL NETWOR, V17, P1039, DOI 10.1109/TNN.2006.875989
   Chen JH, 2010, IEEE T VLSI SYST, V18, P1145, DOI 10.1109/TVLSI.2009.2020397
   Chen PH, 2006, IEEE T NEURAL NETWOR, V17, P893, DOI 10.1109/TNN.2006.875973
   Chen PL, 2009, IEEE T VLSI SYST, V17, P1152, DOI 10.1109/TVLSI.2009.2013983
   Chen TC, 2006, IEEE T CIRC SYST VID, V16, P673, DOI 10.1109/TCSVT.2006.873163
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dai KR, 2012, IEEE T VLSI SYST, V20, P459, DOI 10.1109/TVLSI.2010.2102780
   Hartenstein R, 2001, DESIGN, AUTOMATION AND TEST IN EUROPE, CONFERENCE AND EXHIBITION 2001, PROCEEDINGS, P642, DOI 10.1109/DATE.2001.915091
   He O, 2012, IEEE T VLSI SYST, V20, P1496, DOI 10.1109/TVLSI.2011.2159280
   Karush W, 1939, MINIMA FUNCTIONS SEV
   Kim Y, 2010, IEEE T VLSI SYST, V18, P1471, DOI 10.1109/TVLSI.2009.2025280
   Kuan TW, 2012, IEEE T VLSI SYST, V20, P673, DOI 10.1109/TVLSI.2011.2107533
   Kuhn HW, 1951, P 2 BERK S MATH STAT, P481, DOI DOI 10.1007/BF01582292
   Lin CT, 2008, IEEE T VLSI SYST, V16, P1058, DOI 10.1109/TVLSI.2008.2000676
   Lo CC, 2010, IEEE T CONSUM ELECTR, V56, P1670, DOI 10.1109/TCE.2010.5606311
   Moreano N, 2005, IEEE T COMPUT AID D, V24, P969, DOI 10.1109/TCAD.2005.850844
   MUKHERJEE D, 1993, 1993 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN - DIGEST OF TECHNICAL PAPERS, P720, DOI 10.1109/ICCAD.1993.580168
   Osuna E, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P276, DOI 10.1109/NNSP.1997.622408
   Pan ZX, 2008, IEEE T VLSI SYST, V16, P1465, DOI 10.1109/TVLSI.2008.2000974
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Soysal A, 2007, IEEE J SEL AREA COMM, V25, P1402, DOI 10.1109/JSAC.2007.070913
   Sterpone L, 2006, IEEE T COMPUT, V55, P732, DOI 10.1109/TC.2006.82
   Tsiaflakis P, 2008, IEEE T SIGNAL PROCES, V56, P4825, DOI 10.1109/TSP.2008.927460
   Wan V, 2005, IEEE T SPEECH AUDI P, V13, P203, DOI 10.1109/TSA.2004.841042
   Wang JF, 2011, IEEE SYS MAN CYBERN, P1621, DOI 10.1109/ICSMC.2011.6083903
   Wei H, 1998, IEEE T POWER SYST, V13, P870, DOI 10.1109/59.708745
NR 37
TC 10
Z9 10
U1 0
U2 10
PD AUG
PY 2014
VL 22
IS 8
BP 1791
EP 1802
DI 10.1109/TVLSI.2013.2278706
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Diaconu, D
   Petrica, L
   Blott, M
   Leeser, M
AF Diaconu, Dana
   Petrica, Lucian
   Blott, Michaela
   Leeser, Miriam
GP IEEE Comp Soc
TI Machine Learning Aided Hardware Resource Estimation for FPGA DNN
   Implementations
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE FPGA; DNN; FINN; Machine Learning; Support Vector Regression; Decision
   Tree Classifier; Resource Estimation
AB This paper explores methods of improving hardware resource estimation for the implementation of Deep Neural Networks(DNN) on FPGAs using machine learning algorithms. Current approaches consider the DNN and High Level Synthesis (HLS) levels. At the DNN level, most techniques are strictly analytical, and based on rough approximations and FPGA DNN implementation assumptions. The aim of this work is to facilitate design space exploration by providing more accurate resource estimates before running time consuming processes such as High Level Synthesis (HLS) or logic synthesis. We integrated the algorithms in FINN, an end-to-end framework for building Quantized Neural Networks (QNN) FPGA inference accelerators, in order to evaluate and compare them to existing estimation as well as the actual synthesized design. We generated Support Vector Regression (SVR) models for LUT and BRAM estimation, the former yields promising results, while the latter consistently underperforms in comparison to HLS and analytical FINN estimates. Combining the analytical approach used in FINN with SVR LUT estimation provided more accurate results because on its own, SVR had insufficient extrapolation capability. For BRAM estimation, we improved the analytical approach by using a Decision Tree Classifier for predicting distributed or BRAM memory implementation.
C1 [Diaconu, Dana; Leeser, Miriam] Northeastern Univ, Boston, MA 02115 USA.
   [Petrica, Lucian; Blott, Michaela] Xilinx Res, Dublin, Ireland.
RP Diaconu, D (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM diaconu.d@northeastern.edu; lucianp@xilinx.com; mblott@xilinx.com;
   mel@coe.neu.edu
CR Awad M., 2015, SUPPORT VECTOR REGRE, P67, DOI DOI 10.1007/978-1-4302-5990-9_4
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Cherkassky V, 2002, LECT NOTES COMPUT SC, V2415, P687
   CLEVELAND WS, 1979, J AM STAT ASSOC, V74, P829, DOI 10.2307/2286407
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   O'Neal K, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240816
   Xu Pengfei, 2020, P 2020 ACMSIGDA INT
   Ye HC, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218684
   Zennaro E, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P413, DOI 10.1109/DSD.2018.00076
NR 10
TC 0
Z9 0
U1 0
U2 6
PY 2022
BP 77
EP 83
DI 10.1109/IPDPSW55747.2022.00022
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Li, X
   Tang, JG
   Tang, JY
AF Li, Xu
   Tang, Jianguo
   Tang, Jiyong
TI Local Indiscernibility Relation Reduction for Information Tables
SO IEEE ACCESS
DT Article
DE Classification algorithms; Heuristic algorithms; Rough sets; Licenses;
   Machine learning; Computational complexity; Uncertainty; Discernibility
   matrix; information table; attribute reduction; indiscernibility
   relation; reduction algorithm
ID ATTRIBUTE REDUCTION; DECISION SYSTEMS; ACCELERATOR; SELECTION
AB Attribute reduction comes from machine learning and is an important component of rough set theory. Research on attribute reduction has produced many important achievements. The aim of attribute reduction is to reduce the complexity of data while retaining its original characteristics to the greatest extent. The concept of attribute reduction is of great significance in machine learning research. In previous studies, a variety of attribute reduction definitions have been proposed according to different rules. Based on the binary relations among objects and local decision rules, this paper describes a local indiscernibility relation reduction for information tables. The discernibility matrix for the proposed reduction is established, and examples for single- and multi-decision classes are presented to illustrate that the proposed local indiscernibility relation reduction can be applied to decision tables. According to the reduction concept developed in this paper, and considering a heuristic algorithm for calculating the significance of attributes and a binary integer programming algorithm based on the discernibility matrix, three reduction algorithms are proposed. Experiments are conducted using four classifiers and a number of publicly available datasets. A comparison of the experimental results presented in this paper demonstrates the feasibility of the proposed algorithms.
C1 [Li, Xu; Tang, Jianguo; Tang, Jiyong] Artificial Intelligence & Big Data Coll, Chongqing 401331, Peoples R China.
   [Li, Xu; Tang, Jianguo; Tang, Jiyong] Chongqing Coll Elect Engn, Chongqing 401331, Peoples R China.
   [Li, Xu] Xinjiang Univ Finance & Econ, Sch Informat Management, Urumqi 830012, Peoples R China.
RP Li, X (corresponding author), Artificial Intelligence & Big Data Coll, Chongqing 401331, Peoples R China.; Li, X (corresponding author), Chongqing Coll Elect Engn, Chongqing 401331, Peoples R China.; Li, X (corresponding author), Xinjiang Univ Finance & Econ, Sch Informat Management, Urumqi 830012, Peoples R China.
EM lixufe12@163.com
CR Che XY, 2022, FUZZY SET SYST, V426, P121, DOI 10.1016/j.fss.2021.03.016
   Chen DG, 2007, INFORM SCIENCES, V177, P3500, DOI 10.1016/j.ins.2007.02.041
   Chen D, 2006, LECT NOTES ARTIF INT, V3930, P588
   Chen DG, 2012, IEEE T KNOWL DATA EN, V24, P2080, DOI 10.1109/TKDE.2011.89
   Chen DG, 2010, FUZZY SET SYST, V161, P1871, DOI 10.1016/j.fss.2009.12.010
   Deng TQ, 2011, INT J COMPUT INT SYS, V4, P655
   Dong LJ, 2020, INT J MACH LEARN CYB, V11, P1339, DOI 10.1007/s13042-020-01065-y
   Fan J, 2017, INFORM SCIENCES, V397, P15, DOI 10.1016/j.ins.2017.02.032
   Feng YB, 2020, KNOWL-BASED SYST, V188, DOI 10.1016/j.knosys.2019.105047
   Fujita H, 2020, IEEE T FUZZY SYST, V28, P831, DOI 10.1109/TFUZZ.2019.2955047
   Inuiguchi M, 2005, LECT NOTES ARTIF INT, V3558, P215
   Jensen R, 2005, FUZZY SET SYST, V149, P5, DOI 10.1016/j.fss.2004.07.014
   Jiang ZH, 2020, INT J APPROX REASON, V119, P122, DOI 10.1016/j.ijar.2019.12.013
   Li X, 2022, SECUR COMMUN NETW, V2022, P1
   Liu G., 2021, INT J MACH LEARN CYB, V109, P1
   Liu GL, 2022, COGN COMPUT, V14, P1818, DOI 10.1007/s12559-021-09887-w
   Liu GL, 2018, KNOWL-BASED SYST, V139, P101, DOI 10.1016/j.knosys.2017.10.014
   Liu GL, 2018, INFORM SCIENCES, V422, P204, DOI 10.1016/j.ins.2017.09.007
   Liu GL, 2017, LECT NOTES ARTIF INT, V10313, P384, DOI 10.1007/978-3-319-60837-2_32
   Liu GL, 2016, KNOWL-BASED SYST, V109, P84, DOI 10.1016/j.knosys.2016.06.027
   Mi JS, 2004, INFORM SCIENCES, V159, P255, DOI 10.1016/j.ins.2003.07.004
   [苗夺谦 Miao Duoqian], 2002, [系统工程理论与实践, Systems Engineering-Theory & Practice], V22, P48
   Min F, 2011, INFORM SCIENCES, V181, P4928, DOI 10.1016/j.ins.2011.07.010
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Pawlak Z., 1991, SPRINGER SCI BUSINES, VVolume 9, DOI DOI 10.1007/978-94-011-3534-4
   Pawlak Z, 2006, LECT NOTES ARTIF INT, V4062, P12
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Qin KY, 2017, LECT NOTES ARTIF INT, V10313, P306, DOI 10.1007/978-3-319-60837-2_26
   Skowron A., 1993, Methodologies for Intelligent Systems. 7th International Symposium, ISMIS '93 Proceedings, P295
   Skowron A., 1992, DISCERNIBILITY MATRI, V11, P331, DOI [10.1007/978-94-015-7975-9_21, DOI 10.1007/978-94-015-7975-9_21]
   UCI Machine Learning Repository, **DATA OBJECT**
   Wang CZ, 2020, IEEE T FUZZY SYST, V28, P818, DOI 10.1109/TFUZZ.2019.2949765
   Wang CZ, 2015, APPL SOFT COMPUT, V26, P235, DOI 10.1016/j.asoc.2014.10.006
   Wang GQ, 2021, INFORM SCIENCES, V571, P475, DOI 10.1016/j.ins.2021.05.007
   Wang GY, 2005, FUND INFORM, V68, P289
   Xie X, 2021, KNOWL-BASED SYST, V228, P1
   Yang YY, 2014, NEUROCOMPUTING, V139, P336, DOI 10.1016/j.neucom.2014.02.023
   Yao YY, 2007, 2007 IEEE SYMPOSIUM ON FOUNDATIONS OF COMPUTATIONAL INTELLIGENCE, VOLS 1 AND 2, P302, DOI 10.1109/FOCI.2007.372184
   Yao YY, 2017, INFORM SCIENCES, V418, P601, DOI 10.1016/j.ins.2017.08.038
   Yuan Z, 2021, APPL SOFT COMPUT, V107, DOI 10.1016/j.asoc.2021.107353
   Zhang CC, 2020, INT J MACH LEARN CYB, V11, P1141, DOI 10.1007/s13042-020-01089-4
   Zhang QH, 2016, IEEE ACCESS, V4, P5399, DOI 10.1109/ACCESS.2016.2600252
   Zhang WX, 2003, INT J INTELL SYST, V18, P989, DOI 10.1002/int.10128
   Zheng K, 2014, EXPERT SYST APPL, V41, P6748, DOI 10.1016/j.eswa.2014.04.042
   Ziarko W., 2003, ELECTRON NOTES THEOR, V82, P263
NR 46
TC 1
Z9 1
U1 4
U2 9
PY 2022
VL 10
BP 78588
EP 78596
DI 10.1109/ACCESS.2022.3193791
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Li, DW
   Ren, YK
   Liu, D
   Guan, ZY
   Zhang, QY
   Wang, YZ
   Liu, JW
AF Li, Dawei
   Ren, Yangkun
   Liu, Di
   Guan, Zhenyu
   Zhang, Qianyun
   Wang, Yanzhao
   Liu, Jianwei
BE Memmi, G
   Yang, B
   Kong, L
   Zhang, T
   Qiu, M
TI PUF-Based Intellectual Property Protection for CNN Model
SO KNOWLEDGE SCIENCE, ENGINEERING AND MANAGEMENT, KSEM 2022, PT III
SE Lecture Notes in Artificial Intelligence
DT Proceedings Paper
CT 15th International Conference on Knowledge Science, Engineering, and
   Management (KSEM)
CY AUG 06-08, 2022
CL Singapore, SINGAPORE
DE PUF; CNN; IP protection; FPGA; Machine learning
AB It usually takes a lot of time and resources to train a high-accurate Machine Learning model, so it is believed that the trainer owns the Intellectual Property (IP) of the model. With the help of various computing accelerators, a Machine Learning model can run on FPGAs, and model providers render services by selling FPGAs with models embedded. Unauthorized copying of the model infringes the owner's copyrights, so there is an urgent need for the effective protection of model IP. In this paper, we propose a Physical Unclonable Function (PUF) based CNN model IP protection scheme. Before selling the model, the model providers confuse the parameters of the model with the response of a PUF, then embed the confused model into the FPGA where the PUF is. In this way, the protected model can get correct results only if running on the specific FPGA. Experimental results show that the performance difference between the confused model and the original model is negligible, and it is difficult for the adversary to get the correct parameters. Our approach effectively protects the IP of the model by restricting the model to only run on the specified FPGA and is easily extended to other models with convolutional layers and linear fully connected layers.
C1 [Li, Dawei; Ren, Yangkun; Liu, Di; Guan, Zhenyu; Zhang, Qianyun; Liu, Jianwei] Beihang Univ, Sch Cyber Sci & Technol, Beijing 100191, Peoples R China.
   [Wang, Yanzhao] Chinabond Finance & Informat Technol Co Ltd, Blockchain Lab, Beijing 100044, Peoples R China.
RP Guan, ZY (corresponding author), Beihang Univ, Sch Cyber Sci & Technol, Beijing 100191, Peoples R China.
EM lidawei@buaa.edu.cn; renyk1319@buaa.edu.cn; liudi2020@buaa.edu.cn;
   guanzhenyu@buaa.edu.cn; zhangqianyun@buaa.edu.cn;
   wangyz@chinabond.com.cn; liujianwei@buaa.edu.cn
CR Adi Y, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1615
   Berger J., 1985, STAT DECISION THEORY
   Chen HL, 2018, Arxiv, DOI arXiv:1811.03713
   Chen J., 2021, ARXIV
   Chen Y, 2019, IEEE COMP SOC ANN, P13, DOI 10.1109/ISVLSI.2019.00012
   Ciresan D, 2012, PROC CVPR IEEE, P3642, DOI 10.1109/CVPR.2012.6248110
   Guo JW, 2018, AIP CONF PROC, V2011, DOI [10.1063/1.5053382, 10.1145/3240765.3240862]
   Guo QL, 2018, ASIAN TEST SYMPOSIUM, P115, DOI 10.1109/ATS.2018.00032
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Holcomb D. E., 2007, P C RFID SECURITY, V7, P1
   Khan N, 2021, IEEE T INF FOREN SEC, V16, P2548, DOI 10.1109/TIFS.2021.3058777
   Lee JW, 2004, 2004 SYMPOSIUM ON VLSI CIRCUITS, DIGEST OF TECHNICAL PAPERS, P176, DOI 10.1109/VLSIC.2004.1346548
   Li YB, 2021, IEEE T IND INFORM, V17, P2833, DOI 10.1109/TII.2020.3008010
   Liu M., 2012, IEEE T SMC B, V44, P155
   Lu ZH, 2018, J PARALLEL DISTR COM, V118, P316, DOI 10.1016/j.jpdc.2017.11.001
   Mondai A., 2020, 57 ACMIEEE DAC, P1
   Nguyen P. H., 2018, CRYPTOLOGY EPRINT AR
   Pappu R, 2002, SCIENCE, V297, P2026, DOI 10.1126/science.1074376
   Qiu H, 2021, IEEE T IND INFORM, V17, P2124, DOI 10.1109/TII.2020.2994743
   Qiu H, 2020, IEEE NETWORK, V34, P172, DOI 10.1109/MNET.001.1900243
   Qiu H, 2020, INFORM FUSION, V55, P59, DOI 10.1016/j.inffus.2019.07.012
   Qiu MK, 2018, FUTURE GENER COMP SY, V87, P772, DOI 10.1016/j.future.2017.08.004
   Qiu MK, 2013, J COMPUT SYST SCI, V79, P518, DOI 10.1016/j.jcss.2012.11.002
   Rouhani BD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P485, DOI 10.1145/3297858.3304051
   Rührmair U, 2014, DES AUT TEST EUROPE
   Shao ZL, 2006, IEEE T COMPUT, V55, P443, DOI 10.1109/TC.2006.59
   Sharir O, 2020, Arxiv, DOI arXiv:2004.08900
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Suh GE, 2007, DES AUT CON, P9, DOI 10.1109/DAC.2007.375043
   Sun P., 2019, IEEE INT S CIRCUITS, P1
   Szyller Sebastian, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P4417, DOI 10.1145/3474085.3475591
   Uchida Y, 2017, PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MULTIMEDIA RETRIEVAL (ICMR'17), P274, DOI 10.1145/3078971.3078974
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang Y, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P273, DOI [10.1109/HOST45689.2020.9300270, 10.1109/host45689.2020.9300270]
   Wu HZ, 2021, IEEE T CIRC SYST VID, V31, P2591, DOI 10.1109/TCSVT.2020.3030671
   Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P159, DOI 10.1145/3196494.3196550
   Zhu Y.., 2021, ARXIV
NR 37
TC 1
Z9 1
U1 3
U2 7
PY 2022
VL 13370
BP 722
EP 733
DI 10.1007/978-3-031-10989-8_57
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Neshatpour, K
   Mokrani, HM
   Sasan, A
   Ghasemzadeh, H
   Rafatirad, S
   Homayoun, H
AF Neshatpour, Katayoun
   Mokrani, Hosein Mohammadi
   Sasan, Avesta
   Ghasemzadeh, Hassan
   Rafatirad, Setareh
   Homayoun, Houman
GP IEEE
TI Design Space Exploration for Hardware Acceleration of Machine Learning
   Applications in MapReduce
SO PROCEEDINGS 26TH IEEE ANNUAL INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE CUSTOM COMPUTING MACHINES (FCCM 2018)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 26th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY APR 29-MAY 01, 2018
CL Boulder, CO
AB Emerging big data applications heavily rely on machine learning algorithms which are computationally intensive. To meet computational requirements, and power and scalability challenges, FPGA based Hardware accelerators have found their way in data centers and cloud infrastructures. Recent efforts on HW acceleration of big data mainly attempt to accelerate a particular application and deploy it on a specific architecture that fits well its performance and power requirements. Given the diversity of architectures and ML applications, the important research question is which architecture is better suited to meet the performance, power and energy-efficiency requirements of a diverse range of ML-based analytics applications. In this work, we answer this question by investigating how the type of FPGA (low-end vs. high-end), and its integration with the CPU (on-chip vs. off-chip) along with the choice of CPU (high performance big vs. low power little servers) affects the speedup yield and power reduction in a CPU+FPGA architecture for machine learning applications implemented in MapReduce. We show that among the three architectural parameters, the type of CPU is the most dominant factor in determining the execution time and power in a CPU+FPGA architecture for MapReduce applications. The integration technology and FPGA type comes next, with the power and performance least sensitive to the FPGA type.
C1 [Neshatpour, Katayoun; Mokrani, Hosein Mohammadi; Sasan, Avesta; Rafatirad, Setareh; Homayoun, Houman] George Mason Univ, Fairfax, VA 22030 USA.
   [Ghasemzadeh, Hassan] Washington State Univ, Pullman, WA 99164 USA.
RP Neshatpour, K (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
NR 0
TC 4
Z9 4
U1 0
U2 0
PY 2018
BP 221
EP 221
DI 10.1109/FCCM.2018.00055
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kljucaric, L
   George, AD
AF Kljucaric, Luke
   George, Alan D.
GP IEEE
TI Deep-Learning Inferencing with High-Performance Hardware Accelerators
SO 2019 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 24-26, 2019
CL Waltham, MA
DE machine learning; FPGA; inference; xfDNN; Volta; AWS; F1; PAC; OpenVINO
AB In order to improve their performance-per-watt capabilities over general-purpose architectures, FPGAs are commonly employed to accelerate applications. With the exponential growth of available data, machine-learning apps have generated greater interest in order to more comprehensively understand that data and increase autonomous processing. As FPGAs become more readily available on cloud services like Amazon Web Services F1 platform, it is worth studying the performance of accelerating machine-learning apps on FPGAs over traditional fixed-logic devices, like CPUs and GPUs. FPGA frameworks for accelerating convolutional neural networks (CNN), which are used in many machine-learning apps, have begun to emerge for accelerated-application development. This research aims to compare the performance of these forthcoming frameworks on two commonly used CNNs, GoogLeNet and AlexNet. Specifically, handwritten Chinese character recognition is benchmarked across multiple FPGA frameworks on Xilinx and Intel FPGAs and compared against multiple CPU and GPU architectures featured on AWS, Google's Cloud platform, the University of Pittsburgh's Center for Research Computing (CRC), and Intel's vLab Academic Cluster. All NVIDIA GPUs have proven to have the best performance over every other device in this study. The Zebra framework available for Xilinx FPGAs showed to have an average 8.3 times and 9.3 times performance and efficiency improvement, respectively, over the OpenVINO framework available for Intel FPGAs. Although the Zebra framework on the Xilinx VU9P showed greater efficiency than the Pascal-based GPUs, the NVIDIA Tesla V100 proved to be the most efficient device at 125.9 and 47.2 images-per-secondper-Watt for AlexNet and GoogLeNet, respectively. Although currently lacking, FPGA frameworks and devices have the potential to compete with GPUs in terms of performance and efficiency.
C1 [Kljucaric, Luke; George, Alan D.] Univ Pittsburgh, Dept Elect & Comp Engn, NSF Ctr Space High Performance & Resilient Comp S, Pittsburgh, PA 15260 USA.
RP Kljucaric, L (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, NSF Ctr Space High Performance & Resilient Comp S, Pittsburgh, PA 15260 USA.
EM luke.kljucaric@nsf-shrec.org; alan.george@nsf-shrec.org
CR [Anonymous], 2017, NVID TESL V100 GPU A, P1
   [Anonymous], 2015, MISCELLANEOUS
   [Anonymous], 2018, VERS 1 AD COMP ACC P
   Delaye Elliot, 2018, INTEGRATING AI YOUR
   DiCecco R., 2016, FIELD PROGRAMMABLE T
   Du J, 2014, NEURAL REGEN RES, V9, P33, DOI 10.4103/1673-5374.125327
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   FARABET C, 2009, INT C FIELD PROGR LO
   Farabet C, 2010, IEEE INT S CIRC SYST
   Fowers J., 2012, ACM SIGDA INT S FIEL
   FWDNXT, 2018, SNOWFL
   Glorot X., 2011, P 14 INT C ART INT S
   Hennessy J., 2017, COMPUTER ARCHITECTUR
   Intel, 2018, KNL PROD SPEC
   Intel, 2018, SKYL PROC SPEC
   Intel, 2018, INT KNIGHTS MILL MIC
   Intel, 2018, INT OPT CAFF
   Intel, 2018, OPENVINO
   Intel, 2018, OPENVINO WHIT
   Intel, 2018, KNM PROC SPEC
   Intel, 2018, INT PAC
   Intel, 2017, KNIGHTS MILL NEW INT
   Jia Y., 2014, 22 ACM INT C MULT MM
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lai S., 2017, PATTERN RECOGNITION, V89
   LeCun Y., 1998, IEEE
   Liu CL, 2013, PATTERN RECOGN, V46, P155, DOI 10.1016/j.patcog.2012.06.021
   Mipsology, 2017, ZEBR
   NVIDIA, 2017, NVIDIA TESLA P100 AR
   NVIDIA, 2017, GEFORCE GTX 1080 TI
   NVIDIA, 2018, NVCAFFE
   Szegedy C., 2015, IEEE COMPUTER VISION
   Xilinx, 2018, AD INF ACC
   Xilinx, 2018, XIL POW EST
   Zhang C., 2015, ACM SIGDA INT S FIEL
   Zhong Z., 2015, 13 INT C DOC AN REC
NR 36
TC 4
Z9 4
U1 0
U2 3
PY 2019
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kumar, AKA
   Al-Salamin, S
   Amrouch, H
   Gerstlauer, A
AF Kumar, Ajay Krishna Ananda
   Al-Salamin, Sami
   Amrouch, Hussam
   Gerstlauer, Andreas
TI Machine Learning-Based Microarchitecture- Level Power Modeling of CPUs
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Analytical models; Predictive models; Logic gates; Feature extraction;
   Mathematical models; Training; Out of order; Machine learning; power
   modeling; micro-architecture simulation
ID METHODOLOGY
AB Energy efficiency has emerged as a key concern for modern processor design, especially when it comes to embedded and mobile devices. It is vital to accurately quantify the power consumption of different micro-architectural components in a CPU. Traditional RTL or gate-level power estimation is too slow for early design-space exploration studies. By contrast, existing architecture-level power models suffer from large inaccuracies. Recently, advanced machine learning techniques have been proposed for accurate power modeling. However, existing approaches still require slow RTL simulations, have large training overheads or have only been demonstrated for fixed-function accelerators and simple in-order cores with predictable behavior. In this work, we present a novel machine learning-based approach for microarchitecture-level power modeling of complex CPUs. Our approach requires only high-level activity traces obtained from microarchitecture simulations. We extract representative features and develop low-complexity learning formulations for different types of CPU-internal structures. Cycle-accurate models at the sub-component level are trained from a small number of gate-level simulations and hierarchically composed to build power models for complete CPUs. We apply our approach to both in-order and out-of-order RISC-V cores. Cross-validation results show that our models predict cycle-by-cycle power consumption to within 3% of a gate-level power estimation on average. In addition, our power model for the Berkeley Out-of-Order (BOOM) core trained on micro-benchmarks can predict the cycle-by-cycle power of real-world applications with less than 3.6% mean absolute error.
C1 [Kumar, Ajay Krishna Ananda; Gerstlauer, Andreas] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Al-Salamin, Sami] Hyperstone, D-78467 Constance, Germany.
   [Amrouch, Hussam] Univ Stuttgart, Elect Engn Fac, Chair Semicond Test & Reliabil STAR Comp Sci, D-70174 Stuttgart, Germany.
RP Al-Salamin, S (corresponding author), Hyperstone, D-78467 Constance, Germany.
EM ajaykrishna1111@utexas.edu; salsalamin@hyperstone.com;
   amrouch@iti.uni-stuttgart.de; gerstl@ece.utexas.edu
CR Ananda Kumar A. K., 2020, UTCERC2001
   [Anonymous], 2009, HP LAB
   [Anonymous], LEARNING BASED ARCHI
   [Anonymous], RISC V EMULATORS PAR
   [Anonymous], RISC V TESTS
   Ansys, POWERARTIST
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Bircher WL, 2007, INT SYM PERFORM ANAL, P158, DOI 10.1109/ISPASS.2007.363746
   Bogliolo A, 2000, ACM T DES AUTOMAT EL, V5, P337, DOI 10.1145/348019.348081
   Brooks D, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P83, DOI [10.1145/342001.339657, 10.1109/ISCA.2000.854380]
   Brooks D, 2003, IBM J RES DEV, V47, P653, DOI 10.1147/rd.475.0653
   Burger D., 1997, Computer Architecture News, V25, P13, DOI 10.1145/268806.268810
   Celio C., 2017, UCBEECS2017157
   Dam Sunwoo, 2010, Proceedings 2010 International Conference on Field Programmable Logic and Applications (FPL 2010), P310, DOI 10.1109/FPL.2010.69
   Donno M, 2003, DES AUT CON, P622
   Gal-On S., 2012, EMBEDDED MICROPROCES
   Jacobson H, 2011, INT S HIGH PERF COMP, P394, DOI 10.1109/HPCA.2011.5749746
   Kim D, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1050, DOI 10.1145/3352460.3358322
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kumar A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290607.3312928, 10.1109/imarc45935.2019.9118731]
   LeBeane M, 2015, INT SYM COMP ARCHIT, P106, DOI 10.1109/SBAC-PAD.2015.26
   Lee D, 2018, ACM T DES AUTOMAT EL, V23, DOI 10.1145/3177865
   Lee D, 2015, DES AUT TEST EUROPE, P1126
   Lee D, 2015, ICCAD-IEEE ACM INT, P847, DOI 10.1109/ICCAD.2015.7372659
   Lee W, 2015, I SYMPOS LOW POWER E, P189, DOI 10.1109/ISLPED.2015.7273512
   Li S, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2445572.2445577
   Li T., 2003, Performance Evaluation Review, V31, P160, DOI 10.1145/885651.781048
   Mentor, POWERPRO RTL LOW POW
   Park YH, 2011, IEEE T VLSI SYST, V19, P668, DOI 10.1109/TVLSI.2009.2039153
   Patel A, 2011, DES AUT CON, P1050
   PULP platform, PULPINO TEST SUITE
   Rossi D, 2016, IEEE HOT CHIP SYMP
   Sagi M, 2020, IEEE T COMPUT AID D, V39, P3152, DOI 10.1109/TCAD.2020.3013062
   Silvaco, SILVACO FREEPDK45 OP
   Synopsys, PRIMETIME
   Van den Steen S, 2016, IEEE T COMPUT, V65, P3537, DOI 10.1109/TC.2016.2547387
   Van den Steen S, 2015, INT SYM PERFORM ANAL, P32, DOI 10.1109/ISPASS.2015.7095782
   verywellmind, US
   Xi S, 2015, INT S HIGH PERF COMP, P577, DOI 10.1109/HPCA.2015.7056064
   Xie Z, 2021, PROC INT S MICROARCH, P1
   Yang JL, 2015, ASIA S PACIF DES AUT, P779, DOI 10.1109/ASPDAC.2015.7059105
   Zhai JW, 2023, IEEE T COMPUT AID D, V42, P243, DOI 10.1109/TCAD.2022.3169464
   Zhang Y., 2020, DES AUT CON, P1
   Zheng XN, 2017, INT J PARALLEL PROG, V45, P1488, DOI 10.1007/s10766-017-0487-0
   Zhou Y, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI [10.1145/3316781.3317884, 10.23919/eos/esd.2019.8869988]
NR 45
TC 0
Z9 0
U1 3
U2 8
PD APR 1
PY 2023
VL 72
IS 4
BP 941
EP 956
DI 10.1109/TC.2022.3185572
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Furuhata, R
   Zhao, ML
   Takahashi, K
   Shimomura, Y
   Takizawa, H
AF Furuhata, Reo
   Zhao, Minglu
   Takahashi, Keichi
   Shimomura, Yoichi
   Takizawa, Hiroyuki
GP IEEE Comp Soc
TI Automated selection of build configuration based on machine learning
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
AB Nowadays, High-Performance Computing (HPC) application codes are becoming larger and more complex. There is an increasing demand for optimizing such codes to reduce execution time and hence achieve high performance. Compilers are used to translate the codes into executable programs. Many optimization techniques have already been incorporated into compilers, and the performance gain by each combination of optimization techniques strongly depends on the code. By selecting a compiler and its option flags, programmers can change the compilation process and its behaviors so that an HPC application can achieve high performance. However, it is not easy to express the selection of a compiler and its option flags as an explicit algorithm. So far, a compiler and its option flags have been selected in a trial-and-error fashion, which is labor-intensive, time-consuming, and potentially leading to inappropriate selection. In addition, configuring the build process for more complex and heterogeneous HPC systems, in which different kinds of processors such as accelerators are employed, becomes even more challenging. Therefore, we propose an automatic compilation process configuration approach based on machine learning that uses dynamic information obtained by executing the code. A feature selection method is proposed to remove the irrelevant attributes for the machine learning model. A neural network is used to learn useful features from data to predict the appropriate build configuration for individual application codes. The evaluation results show that the proposed method outperforms other existing methods in the literature. The proposed feature selection helps the machine learning model characterize the application codes more accurately. Furthermore, it is demonstrated that the proposed approach can select the optimal configuration for each of different processors.
C1 [Furuhata, Reo; Zhao, Minglu; Takahashi, Keichi; Takizawa, Hiroyuki] Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
   [Takahashi, Keichi; Shimomura, Yoichi; Takizawa, Hiroyuki] Tohoku Univ, Cybersci Ctr, Sendai, Miyagi, Japan.
RP Furuhata, R (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Sendai, Miyagi, Japan.
EM furuhata@hpc.is.tohoku.ac.jp; mellow@hpc.is.tohoku.ac.jp;
   keichi@tohoku.ac.jp; shimomura32@tohoku.ac.jp; takizawa@tohoku.ac.jp
CR Alin A, 2010, WIRES COMPUT STAT, V2, P370, DOI 10.1002/wics.84
   [Anonymous], 2002, GCC COMPLETE REFEREN
   Callahan D., 1988, Proceedings. Supercomputing '88 (IEEE Cat. No.88CH2617-9), P98, DOI 10.1109/SUPERC.1988.44642
   Cavazos J, 2007, INT SYM CODE GENER, P185
   Fursin G, 2011, INT J PARALLEL PROG, V39, P296, DOI 10.1007/s10766-010-0161-2
   Furuhata Reo, 2020, 2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW), P172, DOI 10.1109/CANDARW51189.2020.00043
   Kawarabatake Y, 2018, IEEE SYM PARA DISTR, P1049, DOI 10.1109/IPDPSW.2018.00163
   Komatsu Kazuhiko, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P685, DOI 10.1109/SC.2018.00057
   Koprinkova P, 1999, ENG APPL ARTIF INTEL, V12, P281, DOI 10.1016/S0952-1976(99)00008-1
   Leather H, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2536688
   Nakano M, 2017, GEOSCI MODEL DEV, V10, P1363, DOI 10.5194/gmd-10-1363-2017
   Schultz KW, 2017, PURE APPL GEOPHYS, V174, P2269, DOI 10.1007/s00024-016-1428-3
   Takahashi K., 2006, ANN REPORT EARTH SIM
   Terpstra D., 2020, PAPI
   Terpstra D, 2010, TOOLS FOR HIGH PERFORMANCE COMPUTING 2009, P157, DOI 10.1007/978-3-642-11261-4_11
   Ting PS, 2017, INT CON ADV INFO NET, P1138, DOI 10.1109/AINA.2017.64
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 934
EP 941
DI 10.1109/IPDPSW55747.2022.00151
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Ringlein, B
   Abel, F
   Diamantopoulos, D
   Weiss, B
   Hagleitner, C
   Fey, D
AF Ringlein, Burkhard
   Abel, Francois
   Diamantopoulos, Dionysios
   Weiss, Beat
   Hagleitner, Christoph
   Fey, Dietmar
TI Advancing Compilation of DNNs for FPGAs Using Operation Set
   Architectures
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Computer architecture; Field programmable gate arrays; Engines;
   Bandwidth; Topology; Network topology; Throughput; Artificial
   intelligence; compilers; domain-specific architectures; reconfigurable
   hardware
AB The slow-down of technology scaling combined with the exponential growth of modern machine learning and artificial intelligence models has created a demand for specialized accelerators, such as GPUs, ASICs, and field-programmable gate arrays (FPGAs). FPGAs can be reconfigured and have the potential to outperform other accelerators, while also being more energy-efficient, but are cumbersome to use with today's fractured landscape of tool flows. We propose the concept of an operation set architecture to overcome the current incompatibilities and hurdles in using DNN-to-FPGA compilers by combining existing specialized frameworks into one organic compiler that also allows the efficient and automatic re-use of existing community tools. Furthermore, we demonstrate that mixing different existing frameworks can increase the efficiency by more than an order of magnitude.
C1 [Ringlein, Burkhard; Abel, Francois; Diamantopoulos, Dionysios; Weiss, Beat; Hagleitner, Christoph] IBM Res Europe, CH-8803 Ruschlikon, Switzerland.
   [Ringlein, Burkhard; Fey, Dietmar] Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
RP Ringlein, B (corresponding author), IBM Res Europe, CH-8803 Ruschlikon, Switzerland.; Ringlein, B (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
EM ngl@zurich.ibm.com; fab@zurich.ibm.com; did@zurich.ibm.com;
   wei@zurich.ibm.com; hle@zurich.ibm.com; dietmar.fey@fau.de
CR Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Hooker S, 2021, COMMUN ACM, V64, P58
   Montgomerie-Corcoran A, 2022, I C FIELD PROG LOGIC, P418, DOI 10.1109/FPL57034.2022.00069
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   The ONNX community, 2022, OP NEUR NETW EXCH IN
   Umuroglu Y, 2020, I C FIELD PROG LOGIC, P291, DOI 10.1109/FPL50879.2020.00055
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
NR 11
TC 0
Z9 0
U1 1
U2 4
PD JAN 1
PY 2023
VL 22
IS 1
BP 9
EP 12
DI 10.1109/LCA.2022.3227643
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Sethumadhavan, S
   Roberts, R
   Tsividis, Y
AF Sethumadhavan, Simha
   Roberts, Ryan
   Tsividis, Yannis
TI A Case for Hybrid Discrete-Continuous Architectures
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Hybrid systems; Processor architectures; Design studies
AB Current technology trends indicate that power- and energy-efficiency will limit chip throughput in the future. Current solutions to these problems, either in the way of programmable or fixed-function digital accelerators will soon reach their limits as microarchitectural overheads are successively trimmed. A significant departure from current computing methods is required to carry forward computing advances beyond digital accelerators. In this paper we describe how the energy-efficiency of a large class of problems can be improved by employing a hybrid of the discrete and continuous models of computation instead of the ubiquitous, traditional discrete model of computation. We present preliminary analysis of domains and benchmarks that can be accelerated with the new model. Analysis shows that machine learning, physics and up to one-third of SPEC, RMS and Berkeley suite of applications can be accelerated with the new hybrid model.
C1 [Sethumadhavan, Simha; Roberts, Ryan; Tsividis, Yannis] Columbia Univ, New York, NY 10027 USA.
RP Sethumadhavan, S (corresponding author), Columbia Univ, New York, NY 10027 USA.
EM simha@cs.columbia.edu
CR Amant RS, 2008, INT SYMP MICROARCH, P447, DOI 10.1109/MICRO.2008.4771812
   [Anonymous], 1989, ANALOG VLSI NEURAL S
   [Anonymous], P 38 INT S COMP ARCH
   [Anonymous], ELECT ANALOG HYBRID
   Chakrabartty, ADV NEURAL INFORM PR, P17
   Cowan GER, 2006, IEEE J SOLID-ST CIRC, V41, P42, DOI 10.1109/JSSC.2005.858618
   DOUGLAS CC, 1990, SIAM J SCI STAT COMP, V11, P1073, DOI 10.1137/0911060
   Franke H, 2010, IBM J RES DEV, V54, DOI 10.1147/JRD.2009.2036980
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Harrison J, 2004, ACM T GRAPHIC, V23, P569, DOI 10.1145/1015706.1015761
   KARPLUS WJ, 1971, IEEE T COMPUT, VC 20, P831, DOI 10.1109/T-C.1971.223357
   KORN GA, 1962, P IRE, V50, P1077, DOI 10.1109/JRPROC.1962.288009
   Peng SY, 2008, IEEE INT SYMP CIRC S, P860, DOI 10.1109/ISCAS.2008.4541554
   RUBIN AI, 1976, COMPUTER, V9, P37, DOI 10.1109/C-M.1976.218644
   Traub JF, 1999, PHYS TODAY, V52, P39, DOI 10.1063/1.882660
   Yeh Thomas Y., 2007, SIGARCH COMPUT ARCHI, V35, P232
NR 16
TC 5
Z9 5
U1 0
U2 5
PD JAN-JUN
PY 2012
VL 11
IS 1
BP 1
EP 4
DI 10.1109/L-CA.2011.22
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Huang, YX
   He, YF
   Yue, JS
   Yang, HZ
   Liu, YP
AF Huang, Yuxuan
   He, Yifan
   Yue, Jinshan
   Yang, Huazhong
   Liu, Yongpan
GP IEEE
TI A Non-Volatile Computing-In-Memory Framework With Margin Enhancement
   Based CSA and Offset Reduction Based ADC
SO 2021 26TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 26th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 18-21, 2021
CL ELECTR NETWORK
DE computing-in-memory; RRAM; margin enhancement; offset reduction
ID MACRO
AB Nowadays, deep neural network (DNN) has played an important role in machine learning. Non-volatile computing-in-memory (nvCIM) for DNN has become a new architecture to optimize hardware performance and energy efficiency. However, the existing nvCIM accelerators focus on system-level performance but ignore analog factors. In this paper, the sense margin and offset are considered in the proposed nvCIM framework. The margin enhancement based current-mode sense amplifier (MECSA) and the offset reduction based analog-to-digital converter (ORADC) are proposed to improve the accuracy of the ADC. Based on the above methods, the nvCIM framework is displayed and the experiment results show that the proposed framework has an improvement on area, power, and latency with the high accuracy of network models, and the energy efficiency is 2.3 - 20.4x compared to the existing RRAM based nvCIM accelerators.
C1 [Huang, Yuxuan; He, Yifan; Yue, Jinshan; Yang, Huazhong; Liu, Yongpan] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
RP Liu, YP (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
EM ypliu@tsinghua.edu.cn
CR Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Karen S, 2014, COMPUTER SCI
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lo CP, 2019, IEEE J SOLID-ST CIRC, V54, P584, DOI 10.1109/JSSC.2018.2873588
   Meng-Fan Chang, 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P206, DOI 10.1109/ISSCC.2011.5746284
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Xia LX, 2016, DES AUT TEST EUROPE, P469
   Xue CX, 2020, IEEE J SOLID-ST CIRC, V55, P203, DOI 10.1109/JSSC.2019.2951363
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Zhu ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317739
NR 12
TC 1
Z9 1
U1 2
U2 7
PY 2021
BP 126
EP 131
DI 10.1145/3394885.3431521
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Naab, FU
   Toader, OF
   Was, GS
AF Naab, F. U.
   Toader, O. F.
   Was, G. S.
BE McDaniel, FD
   Doyle, BL
   Glass, GA
   Wang, Y
TI Simulation Of Ion Beam Transport Through The 400 Kv Ion Implanter At
   Michigan Ion Beam Laboratory
SO APPLICATION OF ACCELERATORS IN RESEARCH AND INDUSTRY
SE AIP Conference Proceedings
DT Proceedings Paper
CT 22nd International Conference on the Application of Accelerators in
   Research and Industry (CAARI)
CY AUG 05-10, 2012
CL Fort Worth, TX
DE education; educational aids; electrostatic accelerators; beams in
   particle accelerators; computer modeling and simulation
AB The Michigan Ion Beam Laboratory houses a 400 kV ion implanter. An application that simulates the ion beam trajectories through the implanter from the ion source to the target was developed using the SIMION (R) code. The goals were to have a tool to develop an intuitive understanding of abstract physics phenomena and diagnose ion trajectories. Using this application, new implanter users of different fields in science quickly understand how the machine works and quickly learn to operate it. In this article we describe the implanter simulation application and compare the parameters of the implanter components obtained from the simulations with the measured ones. The overall agreement between the simulated and measured values of magnetic fields and electric potentials is similar to 10%.
C1 [Naab, F. U.; Toader, O. F.; Was, G. S.] Univ Michigan, Dept Engn & Radiol Sci, Ann Arbor, MI 48109 USA.
RP Naab, FU (corresponding author), Univ Michigan, Dept Engn & Radiol Sci, 2355 Bonisteel Blvd, Ann Arbor, MI 48109 USA.
CR KELLER R, 1984, VACUUM, V34, P31, DOI 10.1016/0042-207X(84)90102-7
   Manura D., 2008, SIMION VERSION 8 0 U
   TORP B, 1990, REV SCI INSTRUM, V61, P595, DOI 10.1063/1.1141928
   Was G. S., 2011, 21 INT C APPL ACC RE, P325
   Wollnik H., 1987, OPTICS CHARGED PARTI
NR 5
TC 0
Z9 0
U1 0
U2 10
PY 2013
VL 1525
BP 736
EP 740
DI 10.1063/1.4802424
WC Physics, Applied; Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Berger, G
   Freire, M
   Marini, R
   Dufrechou, E
   Ezzatti, P
AF Berger, Gonzalo
   Freire, Manuel
   Marini, Renzo
   Dufrechou, Ernesto
   Ezzatti, Pablo
GP IEEE COMP SOC
TI Unleashing the performance of bmSparse for the sparse matrix
   multiplication in GPUs
SO PROCEEDINGS OF SCALA 2021: 12TH WORKSHOP ON LATEST ADVANCES IN SCALABLE
   ALGORITHMS FOR LARGE- SCALE SYSTEMS
DT Proceedings Paper
CT 12th Workshop on Latest Advances in Scalable Algorithms for Large-Scale
   Systems (ScalA)
CY NOV 19, 2021
CL St Louis, MO
DE bmSparse; spGemm; GPU; task list indexing; segmented sort
ID PARALLELISM; ALGORITHMS
AB The evolution of data science and machine learning has increased the applicability of the sparse matrix multiplication (SPGEMM) kernel. Unlike more well-known operations such as the SPMV, in the SPGEMM the nonzero pattern of the result is determined by the interaction between the nonzero patterns of the inputs, which impose serious challenges to the development of high-performance implementations for accelerators. Recent efforts in this subject aim to mitigate this irregularity through the use of block-based sparse storage formats, obtaining promissing results on accelerators such as GPUs. In this work we study the format bmSparse [1] and propose optimizations to attack the principal bottlenecks of the original SPGEMM implementation for Nvidia GPUs. We evaluate the proposal using nine sparse matrices of different sizes, showing remarkable speedups with respect to CUSPARSE's CSR variant.
C1 [Berger, Gonzalo; Freire, Manuel; Marini, Renzo; Dufrechou, Ernesto; Ezzatti, Pablo] Univ Republica, Fac Ingn INCO, Montevideo, Uruguay.
RP Berger, G (corresponding author), Univ Republica, Fac Ingn INCO, Montevideo, Uruguay.
EM gberger@fing.edu.uy; mfreire@fing.edu.uy; rmarini@fing.edu.uy;
   edufrechou@fing.edu.uy; pezzatti@fing.edu.uy
CR Anh P. N. Q., 2016, ICS 16
   Azad A, 2016, SIAM J SCI COMPUT, V38, pC624, DOI 10.1137/15M104253X
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   cuSPARSE, CUDA TOOLK DOC
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Davis TA, 2018, IEEE HIGH PERF EXTR
   Deveci M., 2018, SPARSE MATRIX MATRIX
   Deveci M, 2018, PARALLEL COMPUT, V78, P33, DOI 10.1016/j.parco.2018.06.009
   Deveci M, 2017, IEEE SYM PARA DISTR, P693, DOI 10.1109/IPDPSW.2017.8
   Garland M, 2010, COMMUN ACM, V53, P58, DOI 10.1145/1839676.1839694
   Georgii J, 2010, ELECTRON T NUMER ANA, V37, P263
   Gilbert JR, 2007, LECT NOTES COMPUT SC, V4699, P260
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Gustavson F. G., 1978, ACM Transactions on Mathematical Software, V4, P250, DOI 10.1145/355791.355796
   Hou K., 2017, ICS 17
   Liu JH, 2019, INT J PARALLEL PROG, V47, P403, DOI 10.1007/s10766-018-0604-8
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Marini R., 2021, IN PRESS
   Merrill D, 2011, PARALLEL PROCESS LET, V21, P245, DOI 10.1142/S0129626411000187
   Nagasaka Y, 2017, PROC INT CONF PARAL, P101, DOI 10.1109/ICPP.2017.19
   Patwary MMA, 2015, LECT NOTES COMPUT SC, V9137, P48, DOI 10.1007/978-3-319-20119-1_4
   SamuelWilliams Leonid Oliker, 2007, SC 07, P1, DOI DOI 10.1145/1362622.1362674
   Satish N, 2009, INT PARALL DISTRIB P, P257
   Sodani A, 2016, IEEE HOT CHIP SYMP
   Volkov V, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P499
   Winter M, 2019, PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '19), P68, DOI 10.1145/3293883.3295701
   Zhang JT, 2018, GRADES-NDA '18: PROCEEDINGS OF THE 1ST ACM SIGMOD JOINT INTERNATIONAL WORKSHOP ON GRAPH DATA MANAGEMENT EXPERIENCES & SYSTEMS (GRADES) AND NETWORK DATA ANALYTICS (NDA) 2018 (GRADES-NDA 2018), DOI 10.1145/3210259.3210263
NR 28
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 19
EP 26
DI 10.1109/ScalA54577.2021.00008
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Mittal, S
   Verma, G
   Kaushik, B
   Khanday, FA
AF Mittal, Sparsh
   Verma, Gaurav
   Kaushik, Brajesh
   Khanday, Farooq A.
TI A survey of SRAM-based in-memory computing techniques and applications
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Review; Deep neural networks; SRAM; Cache; In-memory computing; Neural
   network; Automata computing
ID ENERGY-EFFICIENT; SENSE AMPLIFIER; FINFET CMOS; BIT-CELL; MACRO;
   ACCELERATOR; ARCHITECTURES; PROCESSOR; BITLINE; DESIGN
AB As von Neumann computing architectures become increasingly constrained by data-movement overheads, researchers have started exploring in-memory computing (IMC) techniques to offset data-movement overheads. Due to the widespread use of SRAM, IMC techniques for SRAM hold the promise of accelerating a broad range of computing systems and applications. In this article, we present a survey of techniques for in-memory computing using SRAM memory. We review the use of SRAM-IMC for implementing Boolean, search and arithmetic operations, and accelerators for machine learning (especially neural networks) and automata computing. This paper aims to accelerate co-design efforts by informing researchers in both algorithm and hardware architecture fields about the recent developments in SRAM-based IMC techniques.
C1 [Mittal, Sparsh; Verma, Gaurav; Kaushik, Brajesh] IIT Roorkee, Dept Elect & Commun Engn, Roorkee, Uttar Pradesh, India.
   [Khanday, Farooq A.] Univ Kashmir, Dept Elect & Instrumentat Technol, Srinagar, India.
RP Mittal, S (corresponding author), IIT Roorkee, Dept Elect & Commun Engn, Roorkee, Uttar Pradesh, India.
EM sparshfec@iitr.ac.in
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Agrawal A, 2018, IEEE WRK SIG PRO SYS, P19, DOI 10.1109/SiPS.2018.8598290
   Agrawal A, 2018, IEEE T CIRCUITS-I, V65, P4219, DOI 10.1109/TCSI.2018.2848999
   Akyel KC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
   Al-Hawaj K, IEEE INT S CIRC SYST
   Ali M, 2020, IEEE T CIRCUITS-I, V67, P2521, DOI 10.1109/TCSI.2020.2981901
   Angstadt K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P921, DOI [10.1109/MICRO.2018.00079, 10.1109/MICR0.2018.00079]
   [Anonymous], 2018, IEEE T COMPUT AID D, DOI DOI 10.1109/TCAD.2018.2857019
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Bose SK, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9181218
   Calin T, 1996, IEEE T NUCL SCI, V43, P2874, DOI 10.1109/23.556880
   Chen HC, 2019, PROCEEDINGS OF 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION ENGINEERING AND TECHNOLOGY (ICCET 2019), P139, DOI [10.1109/iccet.2019.8726871, 10.1109/ICCET.2019.8726871]
   Chen T, 2020, IEEE J SOLID-ST CIRC, V55, P1709, DOI 10.1109/JSSC.2019.2963591
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Dong Q, 2018, IEEE J SOLID-ST CIRC, V53, P1006, DOI 10.1109/JSSC.2017.2776309
   Dong Q, 2017, SYMP VLSI CIRCUITS, pC160, DOI 10.23919/VLSIC.2017.8008465
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Fujiki D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P397, DOI 10.1145/3307650.3322257
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Gao D, 2020, IEEE T COMPUT AID D, V39, P5011, DOI 10.1109/TCAD.2020.2966484
   Gauchi R, 2019, IEEE INT CONF VLSI, P166, DOI [10.1109/VLSI-SoC.2019.8920373, 10.1109/vlsi-soc.2019.8920373]
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Gupta S, 2019, PR GR LAK SYMP VLSI, P201, DOI 10.1145/3299874.3317977
   Hsueh F.-K., 2017, INT EL DEVICES MEET
   Hsueh FK, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993628
   Jaiswal A, 2020, IEEE T CIRCUITS-I, V67, P4651, DOI 10.1109/TCSI.2020.3005783
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Jao N, 2019, P IEEE ACM INT S NAN, P1
   Jao N, 2018, IEEE COMP SOC ANN, P447, DOI 10.1109/ISVLSI.2018.00087
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jha N.K., 2020, IEEE T COMPUT
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jiang HW, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P490, DOI 10.1145/3357526.3357552
   Jiang ZW, 2019, PR GR LAK SYMP VLSI, P417, DOI 10.1145/3299874.3319458
   Kang M, 2016, ARXIV PREPRINT ARXIV
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2015, IEEE INT SYMP CIRC S, P2505, DOI 10.1109/ISCAS.2015.7169194
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kulkarni J., 2013, IEEE S VLSI CIRCUITS, pC126
   Kulkarni JP, 2017, IEEE J SOLID-ST CIRC, V52, P229, DOI 10.1109/JSSC.2016.2607219
   Kulkarni JP, 2011, IEEE T VLSI SYST, V19, P1727, DOI 10.1109/TVLSI.2010.2055169
   Lee J, 2017, IEEE T VLSI SYST, V25, P2714, DOI 10.1109/TVLSI.2017.2664069
   Lee SK, 2019, IEEE J SOLID-ST CIRC, V54, P1982, DOI 10.1109/JSSC.2019.2913098
   Lin ZT, 2020, IEEE T VLSI SYST, V28, P1316, DOI 10.1109/TVLSI.2020.2976099
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Mittal Sparsh, 2017, Journal of Low Power Electronics and Applications, V7, DOI 10.3390/jlpea7030023
   Mittal S, 2021, IEEE T NEUR NET LEAR
   Mittal S, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102041
   Mittal S, 2020, J SYST ARCHITECT, V104, DOI 10.1016/j.sysarc.2019.101689
   Mittal S, 2019, J SYST ARCHITECT, V99, DOI 10.1016/j.sysarc.2019.101635
   Mittal S, 2019, J SYST ARCHITECT, V98, P135, DOI 10.1016/j.sysarc.2019.07.006
   Mittal S, 2019, J SYST ARCHITECT, V97, P373, DOI 10.1016/j.sysarc.2018.11.001
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2016, ACM J EMERG TECH COM, V12, DOI 10.1145/2821510
   Mittal S, 2014, SUSTAIN COMPUT-INFOR, V4, P33, DOI 10.1016/j.suscom.2013.11.001
   Nag A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P334, DOI 10.1145/3352460.3358308
   Nasrin S, 2019, ARXIV PREPRINT ARXIV
   Qazi M, 2011, IEEE J SOLID-ST CIRC, V46, P85, DOI 10.1109/JSSC.2010.2085970
   Rios M, 2019, IEEE INT CONF VLSI, P34, DOI [10.1109/vlsi-soc.2019.8920317, 10.1109/VLSI-SoC.2019.8920317]
   Sadredini E, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P219, DOI 10.1145/3373376.3378459
   Sadredini E, 2020, INT S HIGH PERF COMP, P86, DOI 10.1109/HPCA47549.2020.00017
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Sadredini E, 2019, IEEE COMPUT ARCHIT L, V18, P87, DOI 10.1109/LCA.2019.2909870
   Saha G, 2020, IEEE ACCESS, V8, P91405, DOI 10.1109/ACCESS.2020.2993989
   Saikia J, 2019, I SYMPOS LOW POWER E
   Shukla P, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180701
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2020, IEEE J SOLID-ST CIRC, V55, P189, DOI 10.1109/JSSC.2019.2952773
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Simon W, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317741
   Simon WA, 2020, IEEE T COMPUT, V69, P1349, DOI 10.1109/TC.2020.2972528
   Simon WA, 2019, PR GR LAK SYMP VLSI, P207, DOI 10.1145/3299874.3317979
   Srinivasa S, 2018, INT S LOW POW EL DES, P1
   Srinivasa S, 2019, IEEE INT SYMP CIRC S
   Srinivasa S, 2019, IEEE T CIRCUITS-I, V66, P2533, DOI 10.1109/TCSI.2019.2897497
   Srinivasa S, 2018, IEEE T VLSI SYST, V26, P671, DOI 10.1109/TVLSI.2017.2787562
   Srivastava P, 2018, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA.2018.00015
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Sun X., 2018, 14 IEEE INT C SOLID, P1, DOI 10.1109/ICC.2018.8422105
   Surana N, 2020, DES AUT TEST EUROPE, P1323, DOI 10.23919/DATE48585.2020.9116361
   Umesh S, 2019, J SYST ARCHITECT, V97, P349, DOI 10.1016/j.sysarc.2018.11.005
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yin SH, 2020, IEEE T VLSI SYST, V28, P48, DOI 10.1109/TVLSI.2019.2940649
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang JT, 2019, IEEE J EM SEL TOP C, V9, P358, DOI 10.1109/JETCAS.2019.2912352
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang YQ, 2017, SYMP VLSI CIRCUITS, pC264, DOI 10.23919/VLSIC.2017.8008501
NR 101
TC 17
Z9 17
U1 10
U2 38
PD OCT
PY 2021
VL 119
AR 102276
DI 10.1016/j.sysarc.2021.102276
EA SEP 2021
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Molnar, L
   Mehta, RK
   Robson, R
AF Molnar, Linda
   Mehta, Ranjana K.
   Robson, Robby
BE Rodrigo, MM
   Matsuda, N
   Cristea, AI
   Dimitrova, V
TI Artificial Intelligence (AI), the Future of Work, and the Building of a
   National Talent Ecosystem
SO ARTIFICIAL INTELLIGENCE IN EDUCATION: POSTERS AND LATE BREAKING RESULTS,
   WORKSHOPS AND TUTORIALS, INDUSTRY AND INNOVATION TRACKS, PRACTITIONERS
   AND DOCTORAL CONSORTIUM, PT II
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 23rd International Conference on Artificial Intelligence in Education
   (AIED)
CY JUL 27-31, 2022
CL Durham Univ, Durham, ENGLAND
HO Durham Univ
DE Convergence Accelerator; National Science Foundation; AI; Future of
   Work; SkillSync; Talent Ecosystem; VR; AR; Fairness
AB This article presents the background and vision of the Skills-based Talent Ecosystem for Upskilling (STEP UP) project. STEP UP is a collaboration among teams participating in the US National Science Foundation (NSF) Convergence Accelerator program, which supports translational use-inspired research. This article details the context for this work, describes the individual projects and the roles of AI in these projects, and explains how these projects are working synergistically towards the ambitious goals of increasing equity and efficiency in the US talent pipeline through skills-based training. The technologies that support this vision range in maturity from laboratory technologies to field-tested prototypes to production software and include applications of Natural Language Understanding and Machine Learning that have only become feasible over the past two to three years.
C1 [Molnar, Linda] Natl Sci Fdn, 2415 Eisenhower Ave, Alexandria, VA 22314 USA.
   [Mehta, Ranjana K.] Texas A&M Univ, College Stn, TX USA.
   [Robson, Robby] Eduworks Corp, STE 110, Corvallis, OR 97333 USA.
RP Robson, R (corresponding author), Eduworks Corp, STE 110, Corvallis, OR 97333 USA.
EM robby.robson@eduworks.com
CR Biden J. R., 2021, EXECUTIVE ORDER DIVE
   Devlin J., 2018, PREPRINT
   Goel Ashok K, 2018, LEARNING ENG ONLINE, P120
   Kirk HR., 2021, ADV NEURAL INF PROCE, V34, P2611
   MIT, 2021, NEWS MASSACHUSETTS I
   Modern Campus, 2021, STATE CONTINUING ED
   National Academies of Sciences Engineering andMedicine., 2022, P AVIRTUAL S
   National Science Foundation, CONVERGENCE ACCELERA
   Radford A., 2019, OPENAI BLOG
   Shi YM, 2020, ADV ENG INFORM, V46, DOI 10.1016/j.aei.2020.101153
   TheWhite House, 2021, BIDEN HARRIS ADM IMM
   US Chamber, 2022, T3 INNOVATION NETWOR
   US Chamber of Commerce Foundation, US
NR 13
TC 0
Z9 0
U1 3
U2 9
PY 2022
VL 13356
BP 99
EP 103
DI 10.1007/978-3-031-11647-6_17
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Education & Educational Research
DA 2023-11-11
ER

PT C
AU Hurst, W
   Shone, N
   Tully, D
   Shi, Q
   Chalmers, C
   Hulse, J
   O'Hare, D
AF Hurst, William
   Shone, Nathan
   Tully, David
   Shi, Qi
   Chalmers, Carl
   Hulse, Jamie
   O'Hare, Darryl
BE Yang, XS
   Sherratt, S
   Dey, N
   Joshi, A
TI Developing a Productivity Accelerator Platform to Support UK Businesses
   in the Industry 4.0 Revolution
SO THIRD INTERNATIONAL CONGRESS ON INFORMATION AND COMMUNICATION TECHNOLOGY
SE Advances in Intelligent Systems and Computing
DT Proceedings Paper
CT 3rd International Conference on Information and Communication Technology
   (ICICT)
CY FEB 27-28, 2018
CL London, ENGLAND
DE Industry 4.0; Productivity; Internet of Things; Smart homes
AB The growing Internet of Things (IoT), the increasing use of sensor technology and the digitisation of traditionally isolated analogue devices are transforming manufacturing and private dwellings in the UK. This ongoing revolution is often referred to as Industry 4.0, where real-time data informs the product value chain and digital applications are used for automating service allocation. Within this emerging environment, good practice is essential for productivity. Yet, the access to good practice guides and information is a challenge. Consequently, in this paper, the Productivity Accelerator (ProAccel) platform design is proposed. The system is a modular cloud-based multimedia platform that has the goal of helping UK businesses improve their productivity. ProAccel employs advanced machine learning and gamification techniques to revolutionise the way productivity information is shared.
C1 [Hurst, William; Shone, Nathan; Tully, David; Shi, Qi; Chalmers, Carl; Hulse, Jamie; O'Hare, Darryl] Liverpool John Moores Univ, Byrom St, Liverpool L3 3AF, Merseyside, England.
RP Hurst, W (corresponding author), Liverpool John Moores Univ, Byrom St, Liverpool L3 3AF, Merseyside, England.
EM W.Hurst@ljmu.ac.uk; N.Shone@ljmu.ac.uk; D.Tully@ljmu.ac.uk;
   Q.Shi@ljmu.ac.uk; C.Chalmers@ljmu.ac.uk; J.Hulse@ljmu.ac.uk;
   D.Ohare@ljmu.ac.uk
CR [Anonymous], 2015, GLOBAL SMART APPLIAN
   [Anonymous], 2005, SUPPORT VECTOR MACHI
   Breivold HP, 2017, INT CONF ENTERP SYST, P299, DOI 10.1109/ES.2017.56
   Chalmers C, 2018, IEEE TECHN SPONS COM
   Chalmers C, 2015, IEEE IJCNN
   Chen B., IEEE ACCESS, P1
   Chen SZ, 2014, IEEE INTERNET THINGS, V1, P349, DOI 10.1109/JIOT.2014.2337336
   Guttman U, 2018, 4 0 WHATS NEXT SAP P
   Haverkort BR, 2017, IEEE INTERNET COMPUT, V21, P8, DOI 10.1109/MIC.2017.22
   IDC, 2014, TECH REP
   Osuna E, 1997, NEURAL NETWORKS FOR SIGNAL PROCESSING VII, P276, DOI 10.1109/NNSP.1997.622408
   Swain KB, 2017, 2017 IEEE 3RD INTERNATIONAL CONFERENCE ON SENSING, SIGNAL PROCESSING AND SECURITY (ICSSS), P74, DOI 10.1109/SSPS.2017.8071568
NR 12
TC 2
Z9 2
U1 0
U2 6
PY 2019
VL 797
BP 517
EP 525
DI 10.1007/978-981-13-1165-9_47
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Dorband, JE
AF Dorband, John E.
BE Latifi, S
   Arai, K
   Carneiro, G
   Debnath, N
   Dias, LAV
   Hashemi, R
TI A Boltzmann Machine Implementation for the D-Wave
SO 2015 12TH INTERNATIONAL CONFERENCE ON INFORMATION TECHNOLOGY - NEW
   GENERATIONS
DT Proceedings Paper
CT 12th International Conference on Information Technology: New Generations
   ITNG
CY APR 13-15, 2015
CL Las Vegas, NV
DE component; quantum computing; D-Wave; neural network; Boltzmann machine;
   chimera graph; MNIST
AB The D-Wave is an adiabatic quantum computer. It is an understatement to say that it is not a traditional computer. It can be viewed as a computational accelerator or more precisely a computational oracle, where one asks it a relevant question and it returns a useful answer. The question is how do you ask a relevant question and how do you use the answer it returns. This paper addresses these issues in a way that is pertinent to machine learning. A Boltzmann machine is implemented with the D-Wave since the D-Wave is merely a hardware instantiation of a partially connected Boltzmann machine. This paper presents a prototype implementation of a 3-layered neural network where the D-Wave is used as the middle (hidden) layer of the neural network. This paper also explains how the D-Wave can be utilized in a multi-layer neural network (more than 3 layers) and one in which each layer may be multiple times the size of the Dave being used.
C1 [Dorband, John E.] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
RP Dorband, JE (corresponding author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
EM dorband@umbc.edu
CR [Anonymous], 2005, AISTATS BRIDGETOWN B
   [Anonymous], 1983, P 5 ANN C COGN SCI S
   Denil M., 2011, NIPS DEEP LEARN UNS
   Dumoulin V, 2013, ARXIV13125258
   Farhi Edward, 2936 MIT CTP
   Hinton Geoffrey B., P IEEE C COMP VIS IN, P448
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Santoro GE, 2006, J PHYS A-MATH GEN, V39, pR393, DOI 10.1088/0305-4470/39/36/R01
NR 8
TC 7
Z9 8
U1 0
U2 6
PY 2015
BP 703
EP 707
DI 10.1109/ITNG.2015.118
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Nakandala, S
   Saur, K
   Yu, GI
   Karanasos, K
   Curino, C
   Weimer, M
   Interlandi, M
AF Nakandala, Supun
   Saur, Karla
   Yu, Gyeong-In
   Karanasos, Konstantinos
   Curino, Carlo
   Weimer, Markus
   Interlandi, Matteo
GP USENIX Assoc
TI A Tensor Compiler for Unified Machine Learning Prediction Serving
SO PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND
   IMPLEMENTATION (OSDI '20)
DT Proceedings Paper
CT 14th USENIX Symposium on Operating Systems Design and Implementation
   (OSDI)
CY NOV 04-06, 2020
CL ELECTR NETWORK
ID OPTIMIZATION
AB Machine Learning (ML) adoption in the enterprise requires simpler and more efficient software infrastructure-the bespoke solutions typical in large web companies are simply untenable. Model scoring, the process of obtaining predictions from a trained model over new data, is a primary contributor to infrastructure complexity and cost as models are trained once but used many times. In this paper we propose HUMMINGBIRD, a novel approach to model scoring, which compiles featurization operators and traditional ML models (e.g., decision trees) into a small set of tensor operations. This approach inherently reduces infrastructure complexity and directly leverages existing investments in Neural Network compilers and runtimes to generate efficient computations for both CPU and hardware accelerators. Our performance results are intriguing: despite replacing imperative computations (e.g., tree traversals) with tensor computation abstractions, HUMMINGBIRD is competitive and often outperforms hand-crafted kernels on micro-benchmarks on both CPU and GPU, while enabling seamless end-to-end acceleration of ML pipelines. We have released HUMMINGBIRD as open source.
C1 [Saur, Karla; Yu, Gyeong-In; Karanasos, Konstantinos; Curino, Carlo; Weimer, Markus; Interlandi, Matteo] Microsoft, Redmond, WA USA.
   [Nakandala, Supun] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Yu, Gyeong-In] Seoul Natl Univ, Seoul, South Korea.
RP Nakandala, S (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM snakanda@eng.ucsd.edu; karla.saur@microsoft.com; gyeongin@snu.ac.kr;
   konstantinos.karanasos@microsoft.com; carlo.curino@microsoft.com;
   markus.weimer@microsoft.com; matteo.interlandi@microsoft.com
CR Agrawal Ashvin, 2019, ARXIV190900084
   Ahmed Z, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2448, DOI 10.1145/3292500.3330667
   Albanie S., 2019, EUCLIDEAN DISTANCE M
   Amazon, 2020, CONSUM REP 2020
   [Anonymous], MEMORY PROFILER PYTH
   [Anonymous], ONNX RUNTIME
   [Anonymous], 2019, ONNX ML VS SKLEARN B
   [Anonymous], 2020, IRIS DATASET
   [Anonymous], 2020, OPENML CC18 BENCHMAR
   [Anonymous], 2020, STATUS SPARSE OPERAT
   [Anonymous], 2020, GRADIENT BOOSTING AL
   [Anonymous], ONNX SUPPORTED FRAME
   [Anonymous], 2015, H2O ALGORITHMS ROADM
   [Anonymous], 2020, ONNX PORTABLE FORMAT
   [Anonymous], TORCHSCRIPT DOCUMENT
   [Anonymous], 2019, ESG TECHNICAL VALIDA
   [Anonymous], RAPIDS FOREST INFERE
   [Anonymous], 2018, P 12 USENIX C OPERAT
   [Anonymous], 2020, NOMAO DATASET
   [Anonymous], 2017, INT C FIELD PROGRAMM
   Baylor D, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1387, DOI 10.1145/3097983.3098021
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Crankshaw Daniel, 2018, ABS181201776 CORR
   Credit Suisse, 2012, APPS REV MAN
   Dash M., 1997, Intelligent Data Analysis, V1
   Devlin J., 2018, PREPRINT
   FirmAI, MACHINE LEARNING DAT
   Goodfellow Ian, 2016, DEEP LEARNING
   Intel, 2020, MACH LEARN FPGA
   Jouppi Norman P., ABS170404760 CORR
   Karanasos Konstantinos, 2020, CIDR 2020
   Ke Guolin, ADV NEURAL INFORM PR, V30, P3146
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kraft Peter, 2019, STATISTICALLY AWARE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lee Yunseong, 2018, P 13 USENIX S OP SYS, P611
   Li Ping, P 26 C ANN C UNC ART
   Li Shen, 2020, PROC VLDB ENDOW
   Palkar S, 2018, PROC VLDB ENDOW, V11, P1002, DOI 10.14778/3213880.3213890
   Paszke A., 2017, NEURIPS
   Polyzotis N, 2018, SIGMOD REC, V47, P17, DOI 10.1145/3299887.3299891
   Psallidas Fotis, 2019, DATA SCI LOOKING GLA
   Ramachandra K, 2017, PROC VLDB ENDOW, V11, P432, DOI 10.1145/3164135.3164140
   Sambanova, 2020, MASS MOD EV
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Sharp T, 2008, LECT NOTES COMPUT SC, V5305, P595, DOI 10.1007/978-3-540-88693-8_44
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Xu Faith, 2020, ACCELERATE TRADITION
NR 50
TC 20
Z9 20
U1 0
U2 0
PY 2020
BP 899
EP 917
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT J
AU Xiao, Y
   Nazarian, S
   Bogdan, P
AF Xiao, Yao
   Nazarian, Shahin
   Bogdan, Paul
TI Self-Optimizing and Self-Programming Computing Systems: A Combined
   Compiler, Complex Networks, and Machine Learning Approach
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Distributed Q-learning; domain-specific system-on-chip (DSSoC);
   heterogeneous systems; network-on-chip (NoC); neural networks (NNs);
   self-optimizing; self-programming; software-defined hardware (SDH)
ID GRAPH; FLOW
AB There exists an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. Therefore, in this paper, we pioneer a self-optimizing and selfprogramming computing system (SOSPCS) design framework that achieves both programmability and flexibility and exploits computing heterogeneity [e.g., CPUs, GPUs, and hardware accelerators (HWAs)]. First, at compile time, we form a task pool consisting of hybrid tasks with different processing element (PE) affinities according to target applications. Tasks preferred to be executed on GPUs or accelerators are detected from target applications by neural networks. Tasks suitable to run on CPUs are formed by community detection to minimize data movement overhead. Next, a distributed reinforcement learning-based approach is used at runtime to allow agents to map the tasks onto the network-on-chip-based heterogeneous PEs by learning an optimal policy based on Q values in the environment. We have conducted experiments on a heterogeneous platform consisting of CPUs, GPUs, and HWAs with deep learning algorithms such as matrix multiplication, ReLU, and sigmoid functions. We concluded that SOSPCS provides performance improvement up to 4.12x and energy reduction up to 3.24x compared to the state-of-the-art approaches.
C1 [Xiao, Yao; Nazarian, Shahin; Bogdan, Paul] Univ Southern Calif, Dept Elect & Comp Engn, Viterbi Sch Engn, Los Angeles, CA 90089 USA.
RP Xiao, Y (corresponding author), Univ Southern Calif, Dept Elect & Comp Engn, Viterbi Sch Engn, Los Angeles, CA 90089 USA.
EM xiaoyao@usc.edu; shahin.nazarian@usc.edu; pbogdan@usc.edu
CR Ahmed W., 2011, 2011 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P365
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Bogdan P, 2013, PROCEEDINGS OF THE TWENTY-FOURTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS (SODA 2013), P16
   Castrillon J, 2012, DES AUT CON, P1262
   Chafi H, 2011, ACM SIGPLAN NOTICES, V46, P35, DOI 10.1145/2038037.1941561
   Cheng MX, 2018, ASIA S PACIF DES AUT, P129, DOI 10.1109/ASPDAC.2018.8297294
   Choi J, 2012, DES AUT CON, P664
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Carvalho ELD, 2010, IEEE DES TEST COMPUT, V27, P26, DOI 10.1109/MDT.2010.106
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Fox G., 2016, TECH REP
   Hendrickson B, 2000, PARALLEL COMPUT, V26, P1519, DOI 10.1016/S0167-8191(00)00048-X
   Hoskote Y, 2007, IEEE MICRO, V27, P51, DOI 10.1109/MM.2007.4378783
   Jantsch A, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2017.2757143
   Javaid H, 2009, DES AUT CON, P250
   Jia Huang, 2011, Proceedings 2011 Design, Automation & Test in Europe
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kestor G, 2013, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2013.6704670
   Kwok YK, 2006, J PARALLEL DISTR COM, V66, P77, DOI 10.1016/j.jpdc.2005.06.015
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lee J, 2012, DIAGN MICR INFEC DIS, V73, P252, DOI 10.1016/j.diagmicrobio.2012.03.019
   Lee W, 2010, PRES VES P, P307
   M. T. Office, 2017, P DARPA, P1
   Manolache S, 2008, ACM T EMBED COMPUT S, V7, DOI 10.1145/1331331.1331343
   Masood A, 2015, IEEE I C EMBED SOFTW, P1865, DOI 10.1109/HPCC-CSS-ICESS.2015.295
   Newman MEJ, 2006, P NATL ACAD SCI USA, V103, P8577, DOI 10.1073/pnas.0601602103
   Newman MEJ, 2003, SIAM REV, V45, P167, DOI 10.1137/S003614450342480
   Piscitelli R, 2012, DES AUT TEST EUROPE, P781
   Railing BP, 2015, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2776893
   Schranzhofer A, 2010, IEEE T IND INFORM, V6, P692, DOI 10.1109/TII.2010.2062192
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Singh AK, 2010, J SYST ARCHITECT, V56, P242, DOI 10.1016/j.sysarc.2010.04.007
   Smit LT, 2005, 2005 INTERNATIONAL SYMPOSIUM ON SYSTEM-ON-CHIP, PROCEEDINGS, P78, DOI 10.1109/ISSOC.2005.1595649
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Taylor MB, 2004, CONF PROC INT SYMP C, P2
   Theocharides T, 2009, GLSVLSI 2009: PROCEEDINGS OF THE 2009 GREAT LAKES SYMPOSIUM ON VLSI, P121
   Thiele L, 2007, INT CONF APPL CONCUR, P29, DOI 10.1109/ACSD.2007.53
   Wu D, 2003, IEE P-COMPUT DIG T, V150, P262, DOI 10.1049/ip-cdt:20030837
   Xiao Y, 2017, ICCAD-IEEE ACM INT, P217, DOI 10.1109/ICCAD.2017.8203781
NR 41
TC 51
Z9 51
U1 2
U2 14
PD JUN
PY 2019
VL 27
IS 6
BP 1416
EP 1427
DI 10.1109/TVLSI.2019.2897650
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ranganath, K
   Abdolrashidi, A
   Song, SL
   Wong, D
AF Ranganath, Kiran
   Abdolrashidi, AmirAli
   Song, Shuaiwen Leon
   Wong, Daniel
TI Speeding up Collective Communications Through Inter-GPU Re-Routing
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Graphics processing units; Bandwidth; Routing; Machine learning;
   Servers; Training; Interference; Collective communication; GPU;
   interconnect
AB In order to address the vast needs of disparate domains, computing engines are becoming more sophisticated and complex. A typical high-performance computational engine is composed of several accelerator units, in most cases GPUs, plus one or more CPU controllers. All these components are becoming increasingly interconnected to satisfy bandwidth and latency tolerance demands from modern workloads. Due to these constraints, solutions to efficiently interconnect them or to systematically manage their trafficsuch as PCIe v3, NVLink v1 and v2 on the hardware side, and NVIDIA Collective Communication Library (NCCL) and AMD ROCM layer on the software sideare becoming more commonplace inside HPC systems and cloud data centers. However, as the number of accelerators increases, workloads (especially machine learning) might not be able to fully exploit the computational substrate due to inefficient use of hardware interconnects. Such scenarios can lead to performance bottlenecks where high-bandwidth links are not used by the underlying libraries and under-performing links are overused. This work proposes Workload Optimization Through Inter-GPU Re-routing (WOTIR), which consists of enhanced NCCL-based collective primitives that aim to boost bandwidth utilization (through more efficient routing) and reduce communication overhead. WOTIR targets GPUs with no direct NVLink communication path (which leads to PCIe communications) and instead re-routes communication through intermediate GPUs to bridge NVLink segments and avoid PCIe communications. Such method allows the maximum possible utilization of the NVLink bandwidth between the GPUs without routing through the PCIe bus. Using this method, we see a reduction of up to 34 percent in execution time for selected machine learning workloads when non-optimal GPU allocations arise.
C1 [Ranganath, Kiran; Abdolrashidi, AmirAli; Wong, Daniel] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Song, Shuaiwen Leon] Univ Sydney, Camperdown, NSW 2006, Australia.
RP Ranganath, K (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM kiran.ranganath@email.ucr.edu; amirali.abdolrashidi@email.ucr.edu;
   leonange1991@gmail.com; daniel.wong@ucr.edu
CR [Anonymous], AM EC2 EL GPUS
   [Anonymous], 2016, NVIDIA COLLECTIVE CO
   Awan AA, 2018, EUROMPI 2018: PROCEEDINGS OF THE 25TH EUROPEAN MPI USERS' GROUP MEETING, DOI 10.1145/3236367.3236381
   Deakin T, 2016, LECT NOTES COMPUT SC, V9945, P489, DOI 10.1007/978-3-319-46079-6_34
   Faraji I, 2016, IEEE SYM PARA DISTR, P712, DOI 10.1109/IPDPSW.2016.44
   Foley D., 2014, NVLINK PASCAL STACKE
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hines J, 2018, COMPUT SCI ENG, V20, P78, DOI 10.1109/MCSE.2018.021651341
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kato S., 2011, Proceedings of the 2011 IEEE 32nd Real-Time Systems Symposium (RTSS 2011), P57, DOI 10.1109/RTSS.2011.13
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li A, 2020, IEEE T PARALL DISTR, V31, P94, DOI 10.1109/TPDS.2019.2928289
   Luo X, 2018, HPDC '18: PROCEEDINGS OF THE 27TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P118, DOI 10.1145/3208040.3208054
   Microsoft, 2017, MICR AZ NC VIRT MACH
   NVidia, TUN CUDA APPL VOLT
   Park JJK, 2015, ACM SIGPLAN NOTICES, V50, P593, DOI [10.1145/2694344.2694346, 10.1145/2775054.2694346]
   Shen MH, 2018, PR IEEE COMP DESIGN, P595, DOI 10.1109/ICCD.2018.00095
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tanasic I, 2014, CONF PROC INT SYMP C, P193, DOI 10.1109/ISCA.2014.6853208
   Tavallaei S., 2017, MICROSOFT PROJECT OL
   Wang G., 2018, P C SYST MACH LEARN
NR 22
TC 7
Z9 7
U1 0
U2 3
PD JUL-DEC
PY 2019
VL 18
IS 2
BP 128
EP 131
DI 10.1109/LCA.2019.2933842
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Yu, SM
   Sun, XY
   Peng, XC
   Huang, SS
AF Yu, Shimeng
   Sun, Xiaoyu
   Peng, Xiaochen
   Huang, Shanshi
GP IEEE
TI Compute-in-Memory with Emerging Nonvolatile-Memories: Challenges and
   Prospects
SO 2020 IEEE CUSTOM INTEGRATED CIRCUITS CONFERENCE (CICC)
SE IEEE Custom Integrated Circuits Conference
DT Proceedings Paper
CT IEEE Custom Integrated Circuits Conference (CICC)
CY MAR 22-25, 2020
CL Boston, MA
DE in-memory computing; hardware accelerator; nonvolatile memory; deep
   learning
AB This invited paper surveys the recent progresses of compute-in-memory (CIM) prototype chip designs with emerging nonvolatile memories (eNVMs) such as resistive random access memory (RRAM) technology. 8kb to 4Mb CIM mixed-signal macros (with analog computation within the memory array) have been demonstrated by academia and industry, showing promising energy efficiency and throughput for machine learning inference acceleration. However, grand challenges exist for large-scale system design including the following: 1) substantial analog-to-digital (ADC) overhead; 2) scalability to advanced logic node limited by high write voltage of eNVMs; 3) process variations (e.g. ADC offset) that degrade the inference accuracy. Mitigation strategies and possible future research directions are discussed.
C1 [Yu, Shimeng; Sun, Xiaoyu; Peng, Xiaochen; Huang, Shanshi] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Chang MF, 2015, IEEE J EM SEL TOP C, V5, P183, DOI 10.1109/JETCAS.2015.2426531
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chou CC, 2018, ISSCC DIG TECH PAP I, P478
   Dünkel S, 2017, INT EL DEVICES MEET
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Lo CP, 2017, SYMP VLSI CIRCUITS, pC164, DOI 10.23919/VLSIC.2017.8008467
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   Ma M, 2018, PROCEEDINGS OF 2018 TENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI), P40, DOI 10.1109/ICACI.2018.8377544
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Peng XC, 2019, INT EL DEVICES MEET
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Si X., 2019, IEEE INT SOL STAT CI
   Song YJ, 2018, INT EL DEVICES MEET
   Sun X., 2018, DESIGN AUTOMATION TE
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Wei L., 2019, IEEE INT SOLID STATE
   Xue C.-X., 2019, IEEE INT SYMP CIRC S
   Yin S., 2019, IEEE MICRO
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 27
TC 29
Z9 29
U1 1
U2 7
PY 2020
DI 10.1109/cicc48029.2020.9075887
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Filippas, D
   Nicopoulos, C
   Dimitrakopoulos, G
AF Filippas, Dionysios
   Nicopoulos, Chrysostomos
   Dimitrakopoulos, Giorgos
GP IEEE
TI LeapConv: An Energy-Efficient Streaming Convolution Engine with
   Reconfigurable Stride
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE Strided convolution; convolutional neural networks; low power design;
   machine learning accelerators
AB Convolution is the central computation kernel for various machine learning applications. The convolution stride controls the number of pixels by which the kernel's window moves after each operation, thereby allowing for the reduction of the output's resolution. The streaming computation of strided convolution inherently involves large periods of inactivity interrupted by periods of actual computation. In this work, we propose LeapConv, a new streaming convolution engine that computes convolutions of arbitrary and reconfigurable stride using local buffering and by leveraging efficient data and memory reuse. The organization of LeapConv is based on the decomposition of strided convolutions into a set of parallel unity-stride convolution channels that are implemented by a merged hardware unit. The experimental results show that LeapConv reduces power consumption with increasing stride by eliminating redundant data movement. The incurred area overhead due to the additional multiplexing logic required to support reconfigurability is demonstrated to be marginal.
C1 [Filippas, Dionysios; Dimitrakopoulos, Giorgos] Democritus Univ Thrace DUTH, Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, Nicosia, Cyprus.
RP Filippas, D (corresponding author), Democritus Univ Thrace DUTH, Elect & Comp Engn, Xanthi, Greece.
CR Cavalcante M, 2020, IEEE T VLSI SYST, V28, P530, DOI 10.1109/TVLSI.2019.2950087
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dong YZ, 2007, LECT NOTES COMPUT SC, V4419, P110
   Filippas D, 2022, IEEE T VLSI SYST, V30, P201, DOI 10.1109/TVLSI.2021.3119511
   Harris D.M., 2010, CMOS VLSI DESIGN CIR
   Hershey S, 2017, INT CONF ACOUST SPEE, P131, DOI 10.1109/ICASSP.2017.7952132
   Ioannou L, 2020, IEEE T VLSI SYST, V28, P1392, DOI 10.1109/TVLSI.2020.2987202
   Jouppi N. P., 2021, INT S COMPUTER ARCHI
   Kong C, 2017, Arxiv, DOI [arXiv:1712.02502, DOI 10.48550/ARXIV.1712.02502, 10.48550/arXiv.1712.02502]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Liu Z., 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.03545
   Meinerzhagen P, 2011, IEEE J EM SEL TOP C, V1, P173, DOI 10.1109/JETCAS.2011.2162159
   Pan JH, 2021, ASIA S PACIF DES AUT, P358, DOI 10.1145/3394885.3431534
   Patsidis K, 2020, IEEE INT SYMP CIRC S
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Stitt G, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P173, DOI 10.1145/3174243.3174262
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Yang C, 2020, IEEE T CIRCUITS-I, V67, P3007, DOI 10.1109/TCSI.2020.2985727
   Yepez J, 2020, IEEE T VLSI SYST, V28, P853, DOI 10.1109/TVLSI.2019.2961602
NR 19
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 200
EP 205
DI 10.1109/ISVLSI54635.2022.00047
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Wszola, E
   Mendler-Dünner, C
   Jaggi, M
   Püschel, M
AF Wszola, Eliza
   Mendler-Dunner, Celestine
   Jaggi, Martin
   Pueschel, Markus
GP IEEE
TI On Linear Learning with Manycore Processors
SO 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS (HIPC)
DT Proceedings Paper
CT 26th International Conference on High Performance Computing, Data and
   Analytics (HiPCW)
CY DEC 17-20, 2019
CL Hyderabad, INDIA
DE Manycore; performance; machine learning; co-ordinate descent; GLM; SVM;
   Lasso
AB A new generation of manycore processors is on the rise that offers dozens and more cores on a chip and, in a sense, fuses host processor and accelerator. In this paper we target the efficient training of generalized linear models on these machines. We propose a novel approach for achieving parallelism which we call Heterogeneous Tasks on Homogeneous Cores (HTHC). It divides the problem into multiple fundamentally different tasks, which themselves are parallelized. For evaluation, we design a detailed, architecture-cognizant implementation of our scheme on a recent 72-core Knights Landing processor that is adaptive to the cache, memory, and core structure. Our library efficiently supports dense and sparse datasets as well as 4-bit quantized data for further possible gains in performance. We show benchmarks for Lasso and SVM with different data sets against straightforward parallel implementations and prior software. In particular, for Lasso on dense data, we improve the state-of-the-art by an order of magnitude.
C1 [Wszola, Eliza; Pueschel, Markus] Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
   [Mendler-Dunner, Celestine] Univ Calif Berkeley, Dept Elect Engn & Comp Sci, Berkeley, CA USA.
   [Jaggi, Martin] Ecole Polytech Fed Lausanne, Sch Comp & Commun Sci, Lausanne, Switzerland.
RP Wszola, E (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Zurich, Switzerland.
EM eliza.wszola@inf.ethz.ch; mendler@berkeley.edu; martin.jaggi@epfl.ch;
   pueschel@inf.ethz.ch
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Athanasopoulos A., 2012, P 12 INT WORKSH ACM, P177
   Boyd S., 2004, CONVEX OPTIMIZATION, DOI 10.1017/CBO9780511804441
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chang K. -W., 2011, P 17 ACM SIGKDD INT, P699
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chiang WL, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1485, DOI 10.1145/2939672.2939826
   Criteo, 2014, KAGGL DISPL ADV CHAL
   Dunner C., 2017, ADV NEURAL INFORM PR, P4258
   Dunner Celestine, 2016, P 33 INT C INT C MAC, P783
   Fan R., 2018, LIBSVM DATA CLASSIFI
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Franchetti F., 2005, FAST BARRIER X86 PLA
   Gawande NA, 2017, IEEE SYM PARA DISTR, P399, DOI 10.1109/IPDPSW.2017.36
   Heinze C, 2016, JMLR WORKSH CONF PRO, V51, P875
   Hsieh CJ, 2015, PR MACH LEARN RES, V37, P2370
   Karimireddy S. P., 2019, 22 INT C ART INT STA, P2887
   Knowledge 4 All Foundation Ltd, 2008, LARG SCAL LEARN CHAL
   Langford J., 2011, VOWPAL WABBIT
   Li JL, 2017, INT CONF MACH LEARN, P35
   Liu J, 2015, J MACH LEARN RES, V16, P285
   Massobrio R., 2017, LAT AM HIGH PERF COM, P277
   Matsushima S., P 18
   McCalpin John D., 1995, IEEE COMPUTER SOC TE, P19
   Moura JMF, 2005, P IEEE, V93, P211, DOI 10.1109/JPROC.2004.840488
   Perekrestenko D., 2017, P 20 INT C ART INT S, V54
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Rendle S, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1125, DOI 10.1145/2939672.2939790
   Richtárik P, 2016, MATH PROGRAM, V156, P433, DOI 10.1007/s10107-015-0901-6
   Shalev-Shwartz S, 2013, J MACH LEARN RES, V14, P567
   Stich S. U., 2017, ADV NEURAL INFORM PR, P4381
   Stojanov A, 2018, IEEE WRK SIG PRO SYS, P349, DOI 10.1109/SiPS.2018.8598402
   Wright SJ, 2015, MATH PROGRAM, V151, P3, DOI 10.1007/s10107-015-0892-3
   Yen IEH, 2013, 19TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'13), P248
   You Y., 2017, 100 EPOCH IMAGENET T
   You Y., 2016, ANN C NEUR INF PROC, P4689
   You Y, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.88
   Zhang A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2035, DOI 10.1145/2939672.2939819
   Zhaoguang Pan, 2015, 2015 IEEE Power & Energy Society General Meeting, P1, DOI 10.1109/PESGM.2015.7285868
NR 39
TC 1
Z9 1
U1 0
U2 0
PY 2019
BP 184
EP 194
DI 10.1109/HiPC.2019.00032
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Suri, M
   Parmar, V
   Singla, A
   Malviya, R
   Nair, S
AF Suri, Manan
   Parmar, Vivek
   Singla, Akshay
   Malviya, Rishabh
   Nair, Surag
GP IEEE
TI Neuromorphic Hardware Accelerated Adaptive Authentication System
SO 2015 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI)
DT Proceedings Paper
CT IEEE Symposium Series Computational Intelligence
CY DEC 07-10, 2015
CL Cape Town, SOUTH AFRICA
ID FACE RECOGNITION; MACHINE
AB In this paper we present a multimodal authentication (person identification) system based on simultaneous recognition of face and speech data using a novel bio-inspired architecture powered by the CM1K chip. The CM1K chip has a constant recognition time irrespective of the size of the knowledge base, which gives massive time gains in learning and recognition over software implementations of similar methods. We demonstrate a system utilizing the CM1K chip as a neural network accelerator along with data pre-processing done by a desktop PC. The system realized consumes energy of the order: 668 mu J for learning and 487 mu J for recognition, while operating at 25 MHz. The classification test accuracy of the system is approximately 91%.
C1 [Suri, Manan; Parmar, Vivek; Singla, Akshay; Malviya, Rishabh; Nair, Surag] Indian Inst Technol, Dept Elect Engn, Delhi, India.
RP Suri, M (corresponding author), Indian Inst Technol, Dept Elect Engn, Delhi, India.
EM manansuri@ee.iitd.ac.in
CR [Anonymous], 2007, PROC IEEE INT C COMP
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Boulet J. Y., 1996, cA Patent App, Patent No. [CA 2,149,478, 2149478]
   Cai D, 2006, IEEE T IMAGE PROCESS, V15, P3608, DOI 10.1109/TIP.2006.881945
   Genov R, 2003, IEEE T NEURAL NETWOR, V14, P1426, DOI 10.1109/TNN.2003.816345
   Gupta S., 2013, SIGNAL IMAGE PROCESS, V4, P101, DOI [10.5121/sipij.2013.4408, DOI 10.5121/SIPIJ.2013.4408]
   Hall DL., 2004, MATH TECHNIQUES MULT
   He XF, 2005, IEEE T PATTERN ANAL, V27, P328, DOI 10.1109/TPAMI.2005.55
   Jemaa Y. B., 2009, ARXIV09074984
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Kleinsteuber M., FEATURE EXTRACTION M
   Liao Y., 2015, NANOTECHNOLOGY IEEE
   Lyons J., MEL FREQUECNY CEPSTR
   Prahallad K., SPEECH TECHNOLOGY PR
   Samaria F. S., 1994, Proceedings of the Second IEEE Workshop on Applications of Computer Vision (Cat. No.94TH06742), P138, DOI 10.1109/ACV.1994.341300
   Sardar S, 2011, IEEE SYMP DIFF EVOL, P1
   Struc V, 2010, EURASIP J ADV SIG PR, DOI 10.1155/2010/847680
   Struc V, 2009, INFORMATICA-LITHUAN, V20, P115
   Suri M., 2013, THESIS
   Wang M., 2010, COMP APPL SYST MOD I, V3, pV3
   Yamagishi J., 2010, ENGLISH MULTISPEAKER
   Zhao W, 2003, ACM COMPUT SURV, V35, P399, DOI 10.1145/954339.954342
NR 22
TC 8
Z9 9
U1 0
U2 3
PY 2015
BP 1206
EP 1213
DI 10.1109/SSCI.2015.173
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT J
AU Al-Qutt, MM
   Khaled, H
   El Gohary, R
AF Al-Qutt, Mirvat Mahmoud
   Khaled, Heba
   El Gohary, Rania
TI Neural Network Inversion-Based Model for Predicting an Optimal Hardware
   Configuration: Solving Computationally Intensive Problems
SO INTERNATIONAL JOURNAL OF GRID AND HIGH PERFORMANCE COMPUTING
DT Article
DE CUDA; GPU; High Performance Computing; Machine Learning; Motif Finding
   (MF); Neural Network Inversion; Power Consumption
ID MULTIOBJECTIVE OPTIMIZATION; ALGORITHMS; DESIGN
AB Deciding the number of processors that can efficiently speed-up solving a computationally intensive problem while perceiving efficient power consumption constitutes a major challenge to researcher in the HPC high performance computing realm. This paper exploits machine learning techniques to propose and implement a recommender system that recommends the optimal HPC architecture given the problem size. An approach for multi-objective function optimization based on neural network (neural network inversion) is employed. The neural network inversion approach is used for forward problem optimization. The objective functions in concern are maximizing the speedup and minimizing the power consumption. The recommendations of the proposed prediction systems achieved more than 89% accuracy for both validation and testing set. The experiments were conducted on 2500 CUDA core on Tesla K20 Kepler GPU Accelerator and Intel(R) Xeon(R) CPU E5-2695 v2.
C1 [Al-Qutt, Mirvat Mahmoud; El Gohary, Rania] Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
   [Khaled, Heba] Ain Shams Univ, Dept Comp Syst, Fac Comp & Informat Sci, Cairo, Egypt.
RP Al-Qutt, MM (corresponding author), Ain Shams Univ, Fac Comp & Informat Sci, Cairo, Egypt.
CR Abbas MM, 2014, J SUPERCOMPUT, V69, P814, DOI 10.1007/s11227-014-1180-3
   Al-Qutt M. M., 2017, INT C DIST P TECH AP
   Andersson U., 2005, PARCO, P179
   [Anonymous], 2016, J KING SAUD U COMPUT
   [Anonymous], 2004, INTRO BIOINFORMATICS
   Bailey TL, 2009, NUCLEIC ACIDS RES, V37, pW202, DOI 10.1093/nar/gkp335
   Balasubramonian R, 2003, CONF PROC INT SYMP C, P275
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Carcangiu S, 2007, COMPEL, V26, P293, DOI 10.1108/03321640710727656
   Carcangiu S., 2008, P 13 IEEE C EL FIELD
   Carcangiu S, 2008, IEEE T MAGN, V44, P970, DOI 10.1109/TMAG.2007.916336
   Cau F, 2007, IEEE T MAGN, V43, P1557, DOI 10.1109/TMAG.2006.892096
   Chen C, 2008, LECT N BIOINFORMAT, V5265, P448, DOI 10.1007/978-3-540-88436-1_38
   Chen LJ, 2012, POWER ELECTRON POWER, P63, DOI 10.1007/978-1-4614-1605-0_3
   Cherubini D, 2005, IEEE T MAGN, V41, P1784, DOI 10.1109/TMAG.2005.845987
   Clemente JB, 2012, PROC INFO COMMUN, V5, P101
   Dasari N. S., 2010, 2010 International Conference on High Performance Computing & Simulation (HPCS 2010), P9, DOI 10.1109/HPCS.2010.5547161
   Dasari NS, 2013, CONCURR COMP-PRACT E, V25, P1340, DOI 10.1002/cpe.2935
   Di Barba P, 2005, COMPEL, V24, P921, DOI 10.1108/03321640510598238
   Faheem H. M., 2014, 16th International Conference on Enterprise Information Systems (ICEIS 2014). Proceedings, P526
   Faheem HM, 2010, INT CONF ADV COMMUN, P197
   Farouk Y., 2011, BIOINFORMATICS TREND, DOI [10.5772/23578, DOI 10.5772/23578]
   Fayez M., 2015, MATH COMPUTERS SCI I, P226
   Fellows MR, 2006, COMBINATORICA, V26, P141, DOI 10.1007/s00493-006-0011-4
   González-Alvarez DL, 2017, J SUPERCOMPUT, V73, P2285, DOI 10.1007/s11227-016-1916-3
   Haykin S., 1994, NEURAL NETWORKS COMP
   Hu M, 2010, NUCLEIC ACIDS RES, V38, P2154, DOI 10.1093/nar/gkp1180
   HWANG JN, 1991, IEEE T NEURAL NETWOR, V2, P131, DOI 10.1109/72.80299
   KINDERMANN J, 1990, PARALLEL COMPUT, V14, P277, DOI 10.1016/0167-8191(90)90081-J
   Kuksa PP, 2010, BMC BIOINFORMATICS, V11, DOI 10.1186/1471-2105-11-S8-S1
   Lawson G, 2015, PROCEEDINGS OF CO-HPC 2015: 2ND INTERNATIONAL WORKSHOP ON HARDWARE-SOFTWARE CO-DESIGN FOR HIGH PERFORMANCE COMPUTING, DOI 10.1145/2834899.2834903
   Lee JD, 2016, GRADIENT DESCENT CON
   Liu BQ, 2016, BMC GENOMICS, V17, DOI 10.1186/s12864-016-2982-x
   Liu YC, 2010, PATTERN RECOGN LETT, V31, P2170, DOI 10.1016/j.patrec.2009.10.009
   Marsan L, 2000, J COMPUT BIOL, V7, P345, DOI 10.1089/106652700750050826
   Nicolas F, 2003, LECT NOTES COMPUT SC, V2676, P315
   Pizzi C, 2008, THEOR COMPUT SCI, V395, P137, DOI 10.1016/j.tcs.2008.01.015
   Raddad M., 2014, IJCA, V5, P27, DOI DOI 10.5120/17685-8543
   Rai JK, 2011, INT J GRID HIGH PERF, V3, P14, DOI 10.4018/jghpc.2011100102
   Rao RV, 2014, J KING SAUD UNIV-COM, V26, P332, DOI 10.1016/j.jksuci.2013.12.004
   Rasheduzzaman M, 2014, INT J GRID HIGH PERF, V6, P34, DOI 10.4018/ijghpc.2014070103
   Smolka M, 2015, INT J AP MAT COM-POL, V25, P483, DOI 10.1515/amcs-2015-0036
   Surujon D, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0146577
   Wang YZH, 2015, ACM SIGPLAN NOTICES, V50, P265, DOI [10.1145/2688500.2688538, 10.1145/2858788.2688538]
   Xiong M., 2009, BIOINFORMATICS OXFOR, V25, P429
   Yang SY, 2004, IEEE T MAGN, V40, P1140, DOI 10.1109/TMAG.2004.824798
   Yu JD, 2010, CANCER CELL, V17, P443, DOI 10.1016/j.ccr.2010.03.018
   Yu LB, 2009, 2009 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING WITH APPLICATIONS, PROCEEDINGS, P555, DOI 10.1109/ISPA.2009.88
   Zandevakili P, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0036865
NR 49
TC 0
Z9 0
U1 0
U2 3
PD APR-JUN
PY 2021
VL 13
IS 2
BP 95
EP 117
DI 10.4018/IJGHPC.2021040106
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Blott, M
   Halder, L
   Leeser, M
   Doyle, L
AF Blott, Michaela
   Halder, Lisa
   Leeser, Miriam
   Doyle, Linda
TI QuTiBench: Benchmarking Neural Networks on Heterogeneous Hardware
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT 3rd Workshop on Hardware Algorithms for Learning On-a-Chip (HALO)
CY NOV 16, 2017
CL Irvine, CA
DE Neural networks; accelerators; benchmarks; heterogeneous hardware
ID ACCELERATOR; TIME
AB Neural Networks have become one of the most successful universal machine-learning algorithms. They play a key role in enabling machine vision and speech recognition and are increasingly adopted in other application domains. Their computational complexity is enormous and comes along with equally challenging memory requirements in regards to capacity and access bandwidth, which limits deployment in particular within energy constrained, embedded environments. To address these implementation challenges, a broad spectrum of new customized and heterogeneous hardware architectures have emerged, often accompanied with co-designed algorithms to extract maximum benefit out of the hardware. Furthermore, numerous optimization techniques are being explored for neural networks to reduce compute and memory requirements while maintaining accuracy. This results in an abundance of algorithmic and architectural choices, some of which fit specific use cases better than others.
   For system-level designers, there is currently no good way to compare the variety of hardware, algorithm, and optimization options. While there are many benchmarking efforts in this field, they cover only subsections of the embedded design space. None of the existing benchmarks support essential algorithmic optimizations such as quantization, an important technique to stay on chip, or specialized heterogeneous hardware architectures. We propose a novel benchmark suite, QuTiBench, that addresses this need. QuTiBench is a novel multi-tiered benchmarking methodology (Ti) that supports algorithmic optimizations such as quantization (Qu) and helps system developers understand the benefits and limitations of these novel compute architectures in regard to specific neural networks and will help drive future innovation. We invite the community to contribute to QuTiBench to support the full spectrum of choices in implementing machine-learning systems.
C1 [Blott, Michaela; Halder, Lisa] Xilinx Res Ireland, 2020 Bianconi Ave,Citywest Business Campus, Dublin D24 T683, Ireland.
   [Halder, Lisa] Ulm Univ, Ulm, Germany.
   [Leeser, Miriam] Northeastern Univ, Dept ECE, 360 Huntington Ave, Boston, MA 02115 USA.
   [Doyle, Linda] Trinity Coll Dublin, Coll Green, Dublin 2, Ireland.
RP Blott, M (corresponding author), Xilinx Res Ireland, 2020 Bianconi Ave,Citywest Business Campus, Dublin D24 T683, Ireland.
EM mblott@xilinx.com; lisa.halder@gmx.de; mel@coe.neu.edu;
   linda.doyle@tcd.ie
CR Adolf R, 2016, I S WORKL CHAR PROC, P148
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alemdar H, 2017, IEEE IJCNN, P2547, DOI 10.1109/IJCNN.2017.7966166
   Amodei D, 2016, PR MACH LEARN RES, V48
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], OP NEUR NETW EXCH FO
   [Anonymous], QUTIBENCH BENCHMARKI
   [Anonymous], STREAM SUSTAINABLE M
   [Anonymous], MLPERF BROAD ML BENC
   [Anonymous], 2016, BITWISE NEURAL NETWO
   [Anonymous], P ACM SIGDA INT S FI
   [Anonymous], 2017, TAK DEEP LOOK AMD RA
   [Anonymous], EFF IMPL NEUR NETW S
   [Anonymous], WHIT DEEP LEARN MPPA
   [Anonymous], 2016, BRIT MACHINE VISION
   [Anonymous], PROD BRIEF MYRIADX E
   [Anonymous], BINARIZED NEURAL NET
   [Anonymous], ACT TPC BENCHM
   [Anonymous], 2017, CVPR
   [Anonymous], 2017, P 8 WORKSH 6 WORKSH, DOI DOI 10.1145/3029580.3029586
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], P 1 REPR QUAL EFF SY
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], MLBENCH BENCHMARKING
   [Anonymous], BENCHMARKING DNN PRO
   [Anonymous], P BRIT MACH VIS C BM
   [Anonymous], 2017, INDEPTH LOOK GOOGLES
   [Anonymous], 2017, NIPS
   [Anonymous], END END DEEP LEARN C
   [Anonymous], ARXIV170609453
   [Anonymous], 2015, 32 ICML
   [Anonymous], TESL P40 INF ACC
   [Anonymous], COLL KNOWL
   [Anonymous], 2017, DEEP LEARNING BENCHM
   [Anonymous], 2017, ABS170904060 CORR
   [Anonymous], 2001, APPROXIMATION ARTIFI
   Armasu L., 2016, DEEP LEARNING STICK
   Blott M, 2017, PR IEEE COMP DESIGN, P419, DOI 10.1109/ICCD.2017.73
   Brockman G., 2016, ARXIV160601540, P1
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Coleman Cody, 2019, ACM SIGOPS Operating Systems Review, V53, P14, DOI 10.1145/3352020.3352024
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dally, 2016, ARXIV161201064
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Durant L., 2017, INSIDE VOLTA WORLDS
   Franklin, 2017, NVIDIA JETSON TX2 DE
   Gu YJ, 2015, LECT NOTES COMPUT SC, V9233, P558, DOI 10.1007/978-3-662-48096-0_43
   Guo KY, 2017, IEEE MICRO, V37, P18, DOI 10.1109/MM.2017.39
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hardawar D., 2018, AMDS RADEON VEGA GPU
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Houthooft R., 2016, P INT C MACH LEARN N, P1329
   Iandola F., 2014, ARXIV14041869, P1, DOI DOI 10.1080/08839514.2013.848751
   IBM, 2018, BLOG UNL PROM APPR C
   Jacob B, 2017, gemmlowp: a small self-contained low-precision gemm library
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H, 2014, IEEE BIPOL BICMOS, P76, DOI 10.1109/BCTM.2014.6981289
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Micikevicius P., 2017, ARXIV171003740
   Mishra Asit, 2017, WRPN WIDE REDUCED PR
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moss DJM, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P107, DOI 10.1145/3174243.3174258
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J., 2016, ARXIV160207360, P779
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Sun WY, 2017, NEUROCOMPUTING, V267, P385, DOI 10.1016/j.neucom.2017.06.050
   Sung Wonyong, 2015, CORR
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tao JH, 2018, J COMPUT SCI TECH-CH, V33, P1, DOI 10.1007/s11390-018-1805-8
   Teich P., 2018, TEARING APART GOOGLE
   Tianshi Chen, 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P36, DOI 10.1109/IISWC.2012.6402898
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhou S., 2016, DOREFANET TRAINING L
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
   Zhuang BH, 2018, PROC CVPR IEEE, P7920, DOI 10.1109/CVPR.2018.00826
NR 89
TC 12
Z9 12
U1 0
U2 1
PD DEC
PY 2019
VL 15
IS 4
SI SI
AR 37
DI 10.1145/3358700
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Dasalukunte, D
   Dorrance, R
   Liang, L
   Lu, L
AF Dasalukunte, Deepak
   Dorrance, Richard
   Liang, Le
   Lu, Lu
TI A Vector Processor for Mean Field Bayesian Channel Estimation
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE 5G NR; architecture; Bayesian inference; channel estimation (CE);
   machine learning for signal processing; matrix co-processor; vector
   processor; wireless
ID INFERENCE; PROPAGATION
AB Physical layer signal processing algorithms in the wireless domain are seeing increased use of machine learning algorithms, especially Bayesian methods. This work presents the hardware architecture and implementation of a vector processor for one such application, Bayesian channel estimation (CE) (BCE). The BCE vector processor supports a generic instruction set with a supplement of specialized instructions to realize Bayesian algorithms in the signal processing context. The vector processor is designed to work as an accelerator in a system-on-chip (SoC) with an AHB/AXI bus interface or as stand-alone unit. The vector processor achieves more than 4x improvement in performance when compared with a traditional CE algorithm running on a commercial vector processor. To the best of authors knowledge, this is a first known hardware implementation of a variational Bayesian inference algorithm for a wireless communication application.
C1 [Dasalukunte, Deepak; Dorrance, Richard; Liang, Le; Lu, Lu] Intel Corp, Hillsboro, OR 97124 USA.
   [Liang, Le] Southeast Univ, Sch Informat Sci & Engn, Nanjing 210096, Peoples R China.
RP Dasalukunte, D (corresponding author), Intel Corp, Hillsboro, OR 97124 USA.
EM deepak.dasalukunte@intel.com
CR [Anonymous], 2017, DOCUMENT T 38802
   [Anonymous], 2008, IEEE 19 INT S PERSON
   [Anonymous], 2011, TS 36101
   [Anonymous], 2007, PATTERN RECOGN, V16
   Bishop C. M, 1995, NEURAL NETWORKS PATT
   Blei DM, 2017, J AM STAT ASSOC, V112, P859, DOI 10.1080/01621459.2017.1285773
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Céspedes J, 2014, IEEE T COMMUN, V62, P2840, DOI 10.1109/TCOMM.2014.2332349
   Edfors O, 1996, 1996 IEEE 46TH VEHICULAR TECHNOLOGY CONFERENCE, PROCEEDINGS, VOLS 1-3, P923, DOI 10.1109/VETEC.1996.501446
   Evolved Universal Terrestrial Radio Access (E-UTRA), 2016, TS 36104
   IEEE Standard for Floating-Point Arithmetic, 2019, STANDARD 754 2019 IE
   Jones VK, 1998, GLOBECOM 98: IEEE GLOBECOM 1998 - CONFERENCE RECORD, VOLS 1-6, P980, DOI 10.1109/GLOCOM.1998.776875
   Khan OU, 2016, IEEE T VLSI SYST, V24, P837, DOI 10.1109/TVLSI.2015.2420663
   Kirkelund GE, 2010, GLOB TELECOMM CONF
   Miller KS., 1981, MATH MAG, V54, P67, DOI [DOI 10.1080/0025570X.1981.11976898, 10.1080/0025570X.1981.11976898]
   Mingas G, 2017, INT J APPROX REASON, V83, P413, DOI 10.1016/j.ijar.2016.10.011
   Minka T. P., 2001, P 17 C UNC ART INT, P362
   Molisch A. F., 2005, WIRELESS COMMUNICATI
   Mora HT, 2017, IEEE GLOB CONF SIG, P774, DOI 10.1109/GlobalSIP.2017.8309065
   Proakis J. G., 2007, DIGITAL COMMUNICATIO, V5th
   Riegler E, 2013, IEEE T INFORM THEORY, V59, P588, DOI 10.1109/TIT.2012.2218573
   Rossi PS, 2008, IEEE T WIREL COMMUN, V7, P4719, DOI 10.1109/T-WC.2008.070953
   Shute M., 1993, MICROELECTRON J, V24, P157
   Simko M., 2011, PROC 17 EUR WIRELESS, P1
   Wainwright MJ, 2008, FOUND TRENDS MACH LE, V1, P1, DOI 10.1561/2200000001
   Wang PY, 2019, IEEE INT C ELECTR TA, DOI [10.1109/icce-tw46550.2019.8991949, 10.1109/wimob.2019.8923232]
   Zhang JT, 2006, IEEE T INFORM THEORY, V52, P3168, DOI 10.1109/TIT.2006.876238
NR 27
TC 0
Z9 0
U1 1
U2 2
PD JUL
PY 2021
VL 29
IS 7
BP 1348
EP 1359
DI 10.1109/TVLSI.2021.3077408
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Fricker, JP
AF Fricker, Jean-Philippe
GP ACM
TI The Cerebras CS-2: Designing an AI Accelerator around the World's
   Largest 2.6 Trillion Transistor Chip
SO ISPD'22: PROCEEDINGS OF THE 2022 INTERNATIONAL SYMPOSIUM ON PHYSICAL
   DESIGN
DT Proceedings Paper
CT 31st edition of the ACM International Symposium on Physical Design
   (ISPD)
CY MAR 27-30, 2022
CL ELECTR NETWORK
DE Computing; Neural networks; AI; Wafer scale engine; Clusterscale
   performance
AB The computing and memory demands from state-of-the-art neural networks have increased several orders of magnitude in just the last couple of years, and there's no end in sight. Traditional forms of scaling chip performance are necessary but far from sufficient to run the machine learning models of the future.
   In this talk, Cerebras Co-Founder and Chief Systems Architect Jean-Philippe Fricker will explore the fundamental properties of neural networks and why they are not well served by traditional architectures. He will examine how co-design can relax the traditional boundaries between technologies and enable designs specialized for neural networks with new architectural capabilities and performance. Finally, Jean-Philippe will explore this rich new design space using the Cerebras architecture as a case study, highlighting design principles and tradeoffs that enable the machine learning models of the future.
C1 [Fricker, Jean-Philippe] Cerebras Syst, Sunnyvale, CA 94085 USA.
RP Fricker, JP (corresponding author), Cerebras Syst, Sunnyvale, CA 94085 USA.
EM jp@cerebras.net
NR 0
TC 0
Z9 0
U1 2
U2 2
PY 2022
BP 71
EP 71
DI 10.1145/3505170.3511036
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Koblischka, MR
   Koblischka-Veneva, A
AF Koblischka, Michael Rudolf
   Koblischka-Veneva, Anjela
TI Superconductivity 2022
SO METALS
DT Editorial Material
DE conventional superconductivity; high pressure; room-temperature
   superconductivity; metal hydrides; HEAs; Matthias rules; machine
   learning; 2D superconductors; topological superconductors;
   nanostructures; cables
ID T-C
AB Superconductivity in metals and alloys, i.e., conventional superconductivity, has seen many new developments in recent years, leading to a renewed interest in the principles of superconductivity and the search for new materials. The most striking discoveries include the near-room-temperature superconductivity in metal hydrides (LaH10) under pressure, the extreme stability of superconductivity in NbTi up to 261 GPa pressure, the discovery of high-entropy alloy (HEA) superconductor materials, and the machine learning prediction of new superconducting materials. Other interesting research concerns the properties of 2D superconductors, topological superconductors, e.g., in hybrid systems, and the use of nanotechnology to create nanowires and nanostructures with new properties. Furthermore, and most importantly, the drive from new accelerator and fusion reactors for stronger superconducting magnets has lead to improved cable materials, showing the highest critical current densities ever. Thus, this Special Issue aims to bring together a collection of papers reflecting the present activity in this field.
C1 [Koblischka, Michael Rudolf; Koblischka-Veneva, Anjela] Saarland Univ, Expt Phys, POB 151150, D-66041 Saarbrucken, Germany.
RP Koblischka, MR (corresponding author), Saarland Univ, Expt Phys, POB 151150, D-66041 Saarbrucken, Germany.
EM m.koblischka@gmail.com; a.koblischka@gmail.com
CR Anvar VA, 2020, FUSION ENG DES, V161, DOI 10.1016/j.fusengdes.2020.111898
   Azpeitia J, 2021, MATER ADV, V2, P3274, DOI 10.1039/d1ma00118c
   Conder K, 2016, SUPERCOND SCI TECH, V29, DOI 10.1088/0953-2048/29/8/080502
   Drozdov AP, 2019, NATURE, V569, P528, DOI 10.1038/s41586-019-1201-8
   Durajski AP, 2021, ANN PHYS-BERLIN, V533, DOI 10.1002/andp.202000518
   Eremets MI, 2022, J SUPERCOND NOV MAGN, V35, P965, DOI 10.1007/s10948-022-06148-1
   Frolov SM, 2020, NAT PHYS, V16, P718, DOI 10.1038/s41567-020-0925-6
   Gregoryanz E, 2020, MATTER RADIAT EXTREM, V5, DOI 10.1063/5.0002104
   Guo J, 2019, ADV MATER, V31, DOI 10.1002/adma.201807240
   Guo J, 2017, P NATL ACAD SCI USA, V114, P13144, DOI 10.1073/pnas.1716981114
   Hirsch J.E., 2022, MATTER RAD EXTREMES, DOI DOI 10.1063/5.0091404
   Kinjo T, 2016, SUPERCOND SCI TECH, V29, DOI 10.1088/0953-2048/29/3/03LT02
   Kitagawa J, 2020, METALS-BASEL, V10, DOI 10.3390/met10081078
   Koblischka MR, 2022, METALS-BASEL, V12, DOI 10.3390/met12020337
   Koblischka MR, 2020, METALS-BASEL, V10, DOI 10.3390/met10020158
   Konno T, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.014509
   Kostrzewa M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58065-9
   Kozelj P, 2014, PHYS REV LETT, V113, DOI 10.1103/PhysRevLett.113.107001
   Kruglov IA, 2020, PHYS REV B, V101, DOI 10.1103/PhysRevB.101.024508
   Marik S, 2019, PHYS REV MATER, V3, DOI 10.1103/PhysRevMaterials.3.060602
   MATTHIAS BT, 1963, REV MOD PHYS, V35, P1, DOI 10.1103/RevModPhys.35.1
   Minkov V.S., RESEARCHSQUARE
   Mitchell N, 2020, SUPERCOND SCI TECH, V33, DOI 10.1088/1361-6668/ab7ec2
   Mizuguchi Y, 2019, J PHYS SOC JPN, V88, DOI 10.7566/JPSJ.88.124708
   Moura KO, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-15738-2
   Qiu D, 2021, ADV MATER, V33, DOI 10.1002/adma.202006124
   Roeser HP, 2010, ACTA ASTRONAUT, V67, P1333, DOI 10.1016/j.actaastro.2010.06.048
   Saito T, 2003, SCIENCE, V300, P464, DOI 10.1126/science.1081957
   Sato M, 2017, REP PROG PHYS, V80, DOI 10.1088/1361-6633/aa6ac7
   Semenok DV, 2020, CURR OPIN SOLID ST M, V24, DOI 10.1016/j.cossms.2020.100808
   Somayazulu M, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.027001
   Stanev V, 2018, NPJ COMPUT MATER, V4, DOI [10.1038/s41524-018-0085-8, 10.1038/s41524-018-0099-2]
   Struzhkin VV, 1997, PHYS REV LETT, V79, P4262, DOI 10.1103/PhysRevLett.79.4262
   Sun LL, 2019, PHYS REV MATER, V3, DOI 10.1103/PhysRevMaterials.3.090301
   Talantsev EF, 2019, MATER RES EXPRESS, V6, DOI 10.1088/2053-1591/ab3bbb
   Tonkov E.Y., 2004, PHASE TRANSFORMATION, P237
   Wigner E, 1935, J CHEM PHYS, V3, P764, DOI 10.1063/1.1749590
   Wu JF, 2020, SCI CHINA MATER, V63, P823, DOI 10.1007/s40843-019-1237-5
   Xu XC, 2017, SUPERCOND SCI TECH, V30, DOI 10.1088/1361-6668/aa7976
   Yabuuchi T, 2006, J PHYS SOC JPN, V75, DOI 10.1143/JPSJ.75.083703
   Zhang GF, 2016, PHYS REV APPL, V6, DOI 10.1103/PhysRevApplied.6.064011
   Zherebtsov S, 2020, INTERMETALLICS, V116, DOI 10.1016/j.intermet.2019.106652
NR 42
TC 3
Z9 3
U1 10
U2 53
PD APR
PY 2022
VL 12
IS 4
AR 568
DI 10.3390/met12040568
WC Materials Science, Multidisciplinary; Metallurgy & Metallurgical
   Engineering
DA 2023-11-11
ER

PT C
AU Ward, L
   Pauloski, JG
   Hayot-Sasson, V
   Chard, R
   Babuji, Y
   Sivaraman, G
   Choudhury, S
   Chard, K
   Thakur, R
   Foster, I
AF Ward, Logan
   Pauloski, J. Gregory
   Hayot-Sasson, Valerie
   Chard, Ryan
   Babuji, Yadu
   Sivaraman, Ganesh
   Choudhury, Sutanay
   Chard, Kyle
   Thakur, Rajeev
   Foster, Ian
GP IEEE
TI Cloud Services Enable Efficient AI-Guided Simulation Workflows across
   Heterogeneous Resources
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS, IPDPSW
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
DE Heterogeneous Computing; Function-as-a-Service; Machine Learning;
   Distributed Systems; Computational Steering
AB Applications that fuse machine learning and simulation can benefit from the use of multiple computing resources, with, for example, simulation codes running on highly parallel supercomputers and AI training and inference tasks on specialized accelerators. Here, we present our experiences deploying two AI-guided simulation workflows across such heterogeneous systems. A unique aspect of our approach is our use of cloud-hosted management services to manage challenging aspects of cross-resource authentication and authorization, function-as-a-service (FaaS) function invocation, and data transfer. We show that these methods can achieve performance parity with systems that rely on direct connection between resources. We achieve parity by integrating the FaaS system and data transfer capabilities with a system that passes data by reference among managers and workers, and a user-configurable steering algorithm to hide data transfer latencies. We anticipate that this ease of use can enable routine use of heterogeneous resources in computational science.
C1 [Ward, Logan; Chard, Ryan; Thakur, Rajeev; Foster, Ian] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Pauloski, J. Gregory; Hayot-Sasson, Valerie; Babuji, Yadu; Chard, Kyle; Foster, Ian] Univ Chicago, Chicago, IL 60637 USA.
   [Choudhury, Sutanay] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
RP Ward, L (corresponding author), Argonne Natl Lab, Lemont, IL 60439 USA.
CR Aad G., 2022, Computing and Software for Big Science, V6, DOI 10.1007/s41781-021-00079-7
   Aktas MF, 2017, PROC INT CONF PARAL, P251, DOI 10.1109/ICPP.2017.34
   Amazon Lambda, US
   Apache OpenWhisk, US
   Babuji Y, 2020, Arxiv, DOI arXiv:2006.02431
   Babuji Y, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P25, DOI 10.1145/3307681.3325400
   Balaprakash P, 2018, INT C HIGH PERFORM, P42, DOI 10.1109/HiPC.2018.00014
   Balasubramanian V, 2019, RADICAL CYBERTOOLS M
   Bannwarth C, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1493
   Brace A, 2021, PROCEEDINGS OF THE PLATFORM FOR ADVANCED SCIENTIFIC COMPUTING CONFERENCE (PASC '21), DOI 10.1145/3468267.3470578
   Brunett S, 1998, SEVENTH INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING - PROCEEDINGS, P81, DOI 10.1109/HPDC.1998.709959
   CARRIERO NJ, 1994, PARALLEL COMPUT, V20, P633, DOI 10.1016/0167-8191(94)90032-9
   Chard K, 2014, IEEE CLOUD COMPUT, V1, P46, DOI 10.1109/MCC.2014.52
   Chard Ryan, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P65, DOI 10.1145/3369583.3392683
   Cholia S., 2010, GAT COMP ENV WORKSH, P1
   Choudhury S, 2020, MACHINE LEARNING PHY
   Chung Joaquin, 2022, HPDC '22: Proceedings of the 31st International Symposium on High-Performance Parallel and Distributed Computing, P185, DOI 10.1145/3502181.3531475
   Ciavotta M, 2021, IEEE INT CONF CL NET, P1, DOI 10.1109/CloudNet53349.2021.9657141
   Cohn DA, 1996, J ARTIF INTELL RES, V4, P129, DOI 10.1613/jair.295
   Dart E., 2013, SER SC 13
   Deelman E, 2019, COMPUT SCI ENG, V21, P22, DOI 10.1109/MCSE.2019.2919690
   Dunn A, 2019, J PHYS-MATER, V2, DOI 10.1088/2515-7639/ab0c3d
   Ejarque J, 2022, FUTURE GENER COMP SY, V134, P414, DOI 10.1016/j.future.2022.04.014
   Fanourgakis GS, 2006, J PHYS CHEM A, V110, P4100, DOI 10.1021/jp056477k
   Feller M., 2007, TERAGRID C
   Fn project, US
   Foster I., 2017, CLOUD COMPUTING SCI
   Fox GC, 2017, IEEE INT CONF CLOUD, P808, DOI 10.1109/CLOUD.2017.120
   Garcia C, 2020, INT WORKSHOP SCI GAT
   Ghaemi S, 2020, IEEE ACCESS, V8, P131760, DOI 10.1109/ACCESS.2020.3010119
   github, KNIX MICROFUNCTIONS
   Google, GOOGL CLOUD FUNCT
   Larsen AH, 2017, J PHYS-CONDENS MAT, V29, DOI 10.1088/1361-648X/aa680e
   Hudson S, 2020, IBENSEMBLE USERS MAN
   Jha S., 2022, ARXIV
   Kiar G, 2019, FRONT NEUROINFORM, V13, DOI 10.3389/fninf.2019.00012
   Landrum G., RDKIT OPEN SOURCE CH, DOI DOI 10.1007/S10822-016-9949-5
   Lee H, 2019, PROCEEDINGS OF 2019 IEEE/ACM THIRD WORKSHOP ON DEEP LEARNING ON SUPERCOMPUTERS (DLS), P12, DOI 10.1109/DLS49591.2019.00007
   Li M, 2020, SUSTAIN ENERG FUELS, V4, P4370, DOI 10.1039/d0se00800a
   Malawski M., 2016, WORKS SC, P25
   Microsoft, AZ FUNCT
   Montoya JH, 2020, CHEM SCI, V11, P8517, DOI 10.1039/d0sc01101k
   Moritz P, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P561
   Ostrovsky AE, 2022, NUCLEIC ACIDS RES, V50, pW345, DOI 10.1093/nar/gkac247
   Polykovskiy D, 2020, FRONT PHARMACOL, V11, DOI 10.3389/fphar.2020.565644
   Rocklin M., 2015, 14 PYTH SCI C, DOI DOI 10.25080/MAJORA-7B98E3ED-013
   Ross RB, 2020, J COMPUT SCI TECH-CH, V35, P121, DOI 10.1007/s11390-020-9802-0
   Schütt KT, 2018, J CHEM PHYS, V148, DOI 10.1063/1.5019779
   SMARR L, 1992, COMMUN ACM, V35, P44, DOI 10.1145/129888.129890
   Smith D, 2020, J CHEM PHYS, V152
   Smith D. G. A, 2020, WIRES COMPUTATIONAL, V11
   Soumagne J., 2013, IEEE INT C CL COMP, P1
   Spillner J, 2018, COMM COM INF SC, V796, P154, DOI 10.1007/978-3-319-73353-1_11
   St John PC, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5099132
   Stubbs Joe, 2021, Advances in Information and Communication. Proceedings of the 2021 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1363), P878, DOI 10.1007/978-3-030-73100-7_61
   Tuecke S, 2016, P IEEE INT C E-SCI, P203, DOI 10.1109/eScience.2016.7870901
   Vescovi R, 2022, PATTERNS, V3, DOI 10.1016/j.patter.2022.100606
   Wang LP, 2016, J CHEM PHYS, V144, DOI 10.1063/1.4952956
   Ward L, 2023, DATASET CLOUD SERVIC
   Wozniak JM, 2018, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2508-4
   Yildiz O, 2021, PROCEEDINGS OF 16TH WORKSHOP ON WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS21), P25, DOI 10.1109/WORKS54523.2021.00009
   Yong Zhao, 2007, 2007 IEEE Congress on Services, P199
NR 62
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 32
EP 41
DI 10.1109/IPDPSW59300.2023.00018
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Zhao, W
   Patil, I
   Han, B
   Yang, Y
   Xing, L
   Schüler, E
AF Zhao, Wei
   Patil, Ishan
   Han, Bin
   Yang, Yong
   Xing, Lei
   Schuler, Emil
TI Beam data modeling of linear accelerators (linacs) through machine
   learning and its potential applications in fast and robust linac
   commissioning and quality assurance
SO RADIOTHERAPY AND ONCOLOGY
DT Article
DE Radiotherapy; Beam data modeling; Machine learning; Linac commissioning;
   Quality assurance
ID REFERENCE DOSIMETRY; RADIATION-THERAPY; PHOTON; IMPLEMENTATION;
   ACCURACY; TG-106; SYSTEM
AB Background and purpose: To propose a novel machine learning-based method for reliable and accurate modeling of linac beam data applicable to the processes of linac commissioning and QA.
   Materials and methods: We hypothesize that the beam data is a function of inherent linac features and percentage depth doses (PDDs) and profiles of different field sizes are correlated with each other. The correlation is formulated as a multivariable regression problem using a machine learning framework. Varian TrueBeam beam data sets (n = 43) acquired from multiple institutions were used to evaluate the framework. The data sets included PDDs and profiles across different energies and field sizes. A multivariate regression model was trained for prediction of beam specific PDDs and profiles of different field sizes using a 10 x 10 cm(2) field as input.
   Results: Predictions of PDDs were achieved with a mean absolute percent relative error (%RE) of 0.19-0.35% across the different beam energies investigated. The maximum mean absolute %RE was 0.93%. For profile prediction, the mean absolute %RE was 0.66-0.93% with a maximum absolute %RE of 3.76%. The largest uncertainties in the PDD and profile predictions were found at the build-up region and at the field penumbra, respectively. The prediction accuracy increased with the number of training sets up to around 20 training sets.
   Conclusions: Through this novel machine learning-based method we have shown accurate and reproducible generation of beam data for linac commissioning for routine radiation therapy. This method has the potential to simplify the linac commissioning procedure, save time and manpower while increasing the accuracy of the commissioning process. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Zhao, Wei; Patil, Ishan; Han, Bin; Yang, Yong; Xing, Lei; Schuler, Emil] Stanford Univ, Dept Radiat Oncol, 875 Blake Wilbur Dr Room G233, Stanford, CA 94305 USA.
   [Schuler, Emil] Univ Texas MD Anderson Canc Ctr, Dept Radiat Phys, Houston, TX 77030 USA.
RP Xing, L (corresponding author), Stanford Univ, Dept Radiat Oncol, 875 Blake Wilbur Dr Room G233, Stanford, CA 94305 USA.; Schüler, E (corresponding author), UT MD Anderson Canc Ctr, Dept Radiat Phys, Radiat Oncol Div, 1515 Holcombe Blvd, Houston, TX 77030 USA.
EM zhaow85@stanford.edu; hanbin@stanford.edu; yongy66@stanford.edu;
   lei@stanford.edu; eschueler@mdanderson.org
CR Adnani N, 2010, J APPL CLIN MED PHYS, V11, P12, DOI 10.1120/jacmp.v11i3.3212
   Al Mashud A, 2017, POL J MED PHYS ENG, V23, P115, DOI 10.1515/pjmpe-2017-0019
   Almond PR, 1999, MED PHYS, V26, P1847, DOI 10.1118/1.598691
   Amols HI, 2010, MED PHYS, V37, P1379, DOI 10.1118/1.3298378
   Atun R, 2015, LANCET ONCOL, V16, P1153, DOI 10.1016/S1470-2045(15)00222-3
   Bentzen SM, 2006, NAT REV CANCER, V6, P702, DOI 10.1038/nrc1950
   Beyer GP, 2013, J APPL CLIN MED PHYS, V14, P273, DOI 10.1120/jacmp.v14i1.4077
   Bouchard H, 2004, MED PHYS, V31, P2454, DOI 10.1118/1.1781333
   Chang Z, 2012, MED PHYS, V39, P6981, DOI 10.1118/1.4762682
   Ciocca M, 2019, MED PHYS, V46, P1852, DOI 10.1002/mp.13389
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Das IJ, 2012, MED PHYS, V39, P569, DOI 10.1118/1.3658740
   De Ruysscher D, 2019, NAT REV DIS PRIMERS, V5, DOI 10.1038/s41572-019-0064-5
   Farr JB, 2018, MED PHYS, V45, P4227, DOI 10.1002/mp.13093
   Fogliata A, 2020, MED PHYS, V47, P3669, DOI 10.1002/mp.14217
   Glide-Hurst C, 2013, MED PHYS, V40, DOI 10.1118/1.4790563
   Huq MS, 2016, MED PHYS, V43, P4209, DOI 10.1118/1.4947547
   Ibbott GS, 2008, INT J RADIAT ONCOL, V71, pS71, DOI 10.1016/j.ijrobp.2007.08.083
   Kalach NI, 2003, MED PHYS, V30, P1546, DOI 10.1118/1.1573205
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   KOSUNEN A, 1993, MED PHYS, V20, P1181, DOI 10.1118/1.597150
   Kry SF, 2019, MED PHYS, V46, P3700, DOI 10.1002/mp.13638
   LARIVIERE PD, 1989, BRIT J RADIOL, V62, P473, DOI 10.1259/0007-1285-62-737-473
   Liu PZY, 2019, MED PHYS, V46, P1331, DOI 10.1002/mp.13356
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Miller KD, 2016, CA-CANCER J CLIN, V66, P271, DOI 10.3322/caac.21349
   Narayanasamy G, 2016, J APPL CLIN MED PHYS, V17, P179, DOI 10.1120/jacmp.v17i1.5799
   Netherton T, 2019, MED PHYS, V46, P4304, DOI 10.1002/mp.13723
   Njeh CF, 2008, J MED PHYS, V33, P136, DOI 10.4103/0971-6203.44472
   Tanaka Y, 2019, J APPL CLIN MED PHYS, V20, P51, DOI 10.1002/acm2.12518
   Teo PT, 2019, MED PHYS, V46, P1341, DOI 10.1002/mp.13378
   Van Dyk J, 2017, RADIOTHER ONCOL, V125, P178, DOI 10.1016/j.radonc.2017.08.021
   Venselaar J, 2001, RADIOTHER ONCOL, V60, P191, DOI 10.1016/S0167-8140(01)00377-2
   Yap Mei Ling, 2016, J Glob Oncol, V2, P207, DOI 10.1200/JGO.2015.001545
NR 35
TC 12
Z9 12
U1 0
U2 8
PD DEC
PY 2020
VL 153
SI SI
BP 122
EP 129
DI 10.1016/j.radonc.2020.09.057
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Li, R
   Li, D
   Zhang, S
AF Li, Rui
   Li, Da
   Zhang, Shuo
GP Assoc Comp Machinery
TI A Deep Learning Prediction Process Based on Low-power Heterogeneous
   Multi Core Architecture
SO ICAIP 2018: 2018 THE 2ND INTERNATIONAL CONFERENCE ON ADVANCES IN IMAGE
   PROCESSING
DT Proceedings Paper
CT 2nd International Conference on Advances in Image Processing (ICAIP) /
   2nd International Conference on Software Engineering and Development
   (ICSED
CY JUN 16-18, 2018
CL Chengdu, PEOPLES R CHINA
DE Accelerator; the deep learning prediction process; multi core; Arm
   Cortex core; Epiphany
AB With the rapid development of machine learning both in theory and practice in the past decade. And recently, it is widely used in applications and cloud services. As the emerging field of machine learning, deep learning shows excellent ability in solving complex learning problems. In this paper, we designed a deep learning prediction process based on low-power heterogeneous multi core architecture. Firstly, the fundamental principle of image recognition method based on deep learning reviewed as the basis of the research. Secondly, a set of key algorithm design to parallel access and process image for object detection based on Parallella multi core platform was proposed to improve the detection speed and the computational resource efficiency on single node. Thirdly, Rockchip RK3288 SoC with 4 Arm Cortex-A17 cores hardware platform, Xilinx Zynq and Adapteva Epiphany combined heterogeneous multi core hardware platform was introduced. Some key designs based on Parallella board's architecture to achieve image recognition was proposed to improve the recognition speed and the computational resource efficiency. Finally, The experimental results that based on Parallella board indicate that the proposed image recognition system can achieve nearly 14.8 times speedup than dual-core Arm which was integrated in Parallella board with similar accuracy and achieve 8.6 times speedup than RK3288 board which has the newest series of high-performance Arm core CPU as the control included 4 Arm Cortex-A17 cores.
C1 [Li, Rui; Li, Da; Zhang, Shuo] Beijing Univ Technol, Beijing Engn Res Ctr IoT Software & Syst, Beijing 100124, Peoples R China.
   [Li, Rui; Li, Da; Zhang, Shuo] Beijing Univ Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing 100124, Peoples R China.
RP Li, R (corresponding author), Beijing Univ Technol, Beijing Engn Res Ctr IoT Software & Syst, Beijing 100124, Peoples R China.; Li, R (corresponding author), Beijing Univ Technol, Beijing Adv Innovat Ctr Future Internet Technol, Beijing 100124, Peoples R China.
EM lirui0511@emails.bjut.edu.cn; lida1204@bjut.edu.cn;
   zhangshuo2013@emails.bjut.edu.cn
CR Adapteva Inc, 2013, EP E16G3 DAT
   Adapteva Inc, 2014, PAR 1 X REF MAN
   [Anonymous], ZYNQ 7000 ALL PROGR
   [Anonymous], 2017, IEEE INT C IMAGING V, DOI DOI 10.1109/ICIVPR.2017.7890866
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Hegde G, 2016, 2016 INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURE AND SYNTHESIS FOR EMBEDDED SYSTEMS (CASES), DOI 10.1145/2968455.2968511
   Loten T, 2009, IM VIS COMP NZ 2008, P1
   Mannan M A, 2002, TECHNICAL PAPER SOC
   Rath AK, 2006, INT C INT SENS INF P, P46
   Tanabe Y., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P222, DOI 10.1109/ISSCC.2012.6176984
   Wang C., 2014, IEEE T COMPUT, V99, P1
   Yu Q, 2015, P ANN ACM S THEOR CO, P585
NR 13
TC 0
Z9 0
U1 0
U2 4
PY 2018
BP 220
EP 224
DI 10.1145/3239576.3239609
WC Computer Science, Theory & Methods; Imaging Science & Photographic
   Technology
DA 2023-11-11
ER

PT J
AU Peng, XC
   Huang, SS
   Jiang, HW
   Lu, AN
   Yu, SM
AF Peng, Xiaochen
   Huang, Shanshi
   Jiang, Hongwu
   Lu, Anni
   Yu, Shimeng
TI DNN+NeuroSim V2.0: An End-to-End Benchmarking Framework for
   Compute-in-Memory Accelerators for On-Chip Training
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Training; Common Information Model (computing); System-on-chip; Computer
   architecture; Hardware; Benchmark testing; Integrated circuit modeling;
   Deep learning; emerging nonvolatile memory (eNVM); hardware accelerator;
   in-memory computing; on-chip training
AB DNN+NeuroSim is an integrated framework to benchmark compute-in-memory (CIM) accelerators for deep neural networks, with hierarchical design options from device-level, to circuit level and up to algorithm level. A python wrapper is developed to interface NeuroSim with a popular machine learning platform: Pytorch, to support flexible network structures. The framework provides automatic algorithm-to-hardware mapping, and evaluates chip-level area, energy efficiency and throughput for training or inference, as well as training/inference accuracy with hardware constraints. Our prior inference version of DNN+NeuroSim framework available at https://github.com/neurosim/DNN_NeuroSim_V1.2 was developed to estimate the impact of reliability in synaptic devices, and analog-to-digital converter (ADC) quantization loss on the accuracy and hardware performance of an inference engine. In this work, we further investigated the impact of the "analog" emerging nonvolatile memory (eNVM)'s nonideal device properties for on-chip training. By introducing the nonlinearity, asymmetry, device-to-device and cycle-to-cycle variation of weight update into the python wrapper, and peripheral circuits for error/weight gradient computation in NeuroSim core, we benchmarked CIM accelerators based on state-of-the-art SRAM and eNVM devices for VGG-8 on CIFAR-10 dataset, revealing the crucial specs of synaptic devices for on-chip training. The latest training version of the DNN+NeuroSim framework is available at https://github.com/neurosim/DNN_NeuroSim_V2.1.
C1 [Peng, Xiaochen; Huang, Shanshi; Jiang, Hongwu; Lu, Anni; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Peng, XC (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM xpeng76@gatech.edu
CR [Anonymous], ASU PTM MODEL
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chen PY, 2018, INT RELIAB PHY SYM
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen PY, 2016, IEEE INT SYMP CIRC S, P2310, DOI 10.1109/ISCAS.2016.7539046
   Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5
   Fumarola A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC)
   Huang S., 2020, P IEEE INT S CIRC SY, P1
   Huang SS, 2020, DES AUT TEST EUROPE, P1025, DOI [10.23919/date48585.2020.9116215, 10.23919/DATE48585.2020.9116215]
   Jerry Matthew, 2017, 2017 IEEE International Electron Devices Meeting (IEDM), P621, DOI 10.1109/IEDM.2017.8268338
   Jiang HW, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218524
   Jiang HW, 2020, IEEE T COMPUT, V69, P944, DOI 10.1109/TC.2020.2980533
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Kim S, 2011, 2011 11TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND SYSTEMS (ICCAS), P1
   Kim W, 2019, S VLSI TECH, pT66, DOI [10.23919/VLSIT.2019.8776551, 10.23919/vlsit.2019.8776551]
   Park S., 2013, TECHNOL DIG INT ELEC, DOI DOI 10.1109/IEDM.2013.6724692
   Peng XC, 2019, INT EL DEVICES MEET
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Sidler S, 2016, PROC EUR S-STATE DEV, P440, DOI 10.1109/ESSDERC.2016.7599680
   Tang J., 2018, 2018 IEEE INT EL DEV, DOI [10.1109/IEDM.2018.8614551, DOI 10.1109/IEDM.2018.8614551]
   Woo J, 2016, IEEE ELECTR DEVICE L, V37, P994, DOI 10.1109/LED.2016.2582859
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
   Wu W, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P103, DOI 10.1109/VLSIT.2018.8510690
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
NR 25
TC 73
Z9 73
U1 3
U2 25
PD NOV
PY 2021
VL 40
IS 11
BP 2306
EP 2319
DI 10.1109/TCAD.2020.3043731
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Tan, ZH
   Cai, HY
   Dong, RP
   Ma, KS
AF Tan, Zhanhong
   Cai, Hongyu
   Dong, Runpei
   Ma, Kaisheng
GP IEEE Comp Soc
TI NN-Baton: DNN Workload Orchestration and Chiplet Granularity Exploration
   for Multichip Accelerators
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
DE Accelerator; chiplet; MCM; neural network; deep learning; scheduling;
   design space exploration
ID NEURAL-NETWORK ACCELERATOR; 0.32-128 TOPS; INFERENCE
AB The revolution of machine learning poses an unprecedented demand for computation resources, urging more transistors on a single monolithic chip, which is not sustainable in the Post-Moore era. The multichip integration with small functional dies, called chiplets, can reduce the manufacturing cost, improve the fabrication yield, and achieve die-level reuse for different system scales. DNN workload mapping and hardware design space exploration on such multichip systems are critical, but missing in the current stage.
   This work provides a hierarchical and analytical framework to describe the DNN mapping on a multichip accelerator and analyze the communication overhead. Based on this framework, we propose an automatic tool called NN-Baton with a pre-design flow and a post-design flow. The pre-design flow aims to guide the chiplet granularity exploration with given area and performance budgets for the target workload. The post-design flow focuses on the workload orchestration on different computation levels - package, chiplet, and core - in the hierarchy. Compared to Simba, NN-Baton generates mapping strategies that save 22.5%similar to 44 % energy under the same computation and memory configurations. The architecture exploration demonstrates that area is a decisive factor for the chiplet granularity. For a 2048-MAC system under a 2 mm(2) chiplet area constraint, the 4-chiplet implementation with 4 cores and 16 lanes of 8-size vector-MAC is always the top-pick computation allocation across several benchmarks. In contrast, the optimal memory allocation policy in the hierarchy typically depends on the neural network models.
C1 [Tan, Zhanhong; Cai, Hongyu; Ma, Kaisheng] Tsinghua Univ, Beijing, Peoples R China.
   [Dong, Runpei] Xi An Jiao Tong Univ, Xian, Peoples R China.
RP Tan, ZH (corresponding author), Tsinghua Univ, Beijing, Peoples R China.
EM tanzh19@mails.tsinghua.edu.cn; h.tsai@hotmail.com;
   runpei.dong@gmail.com; kaisheng@mail.tsinghua.edu.cn
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], DES COMP
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Bannon P., 2019, P IEEE HOT CHIPS 31, P1
   Beck N, 2018, ISSCC DIG TECH PAP I, P40, DOI 10.1109/ISSCC.2018.8310173
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Ding CW, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P33, DOI 10.1145/3289602.3293904
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P122, DOI 10.1109/MM.2012.17
   Fang H, 2015, PROC CVPR IEEE, P1473, DOI 10.1109/CVPR.2015.7298754
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Greenhill D, 2017, ISSCC DIG TECH PAP I, P54, DOI 10.1109/ISSCC.2017.7870257
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083
   James M, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'20), P145, DOI 10.1145/3372780.3380846
   Jiao Y., 2020, IEEE HOT CHIPS 32 S, P1, DOI DOI 10.1109/HCS49909.2020.9220619
   Jiao Y, 2020, ISSCC DIG TECH PAP I, P136, DOI 10.1109/ISSCC19947.2020.9062984
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kang S, 2018, SYMP VLSI CIRCUITS, P137, DOI 10.1109/VLSIC.2018.8502266
   Kim Y, 2014, P 2014 C EMP METH NA, P1746, DOI [10.3115/v1/D14-1181, DOI 10.3115/V1/D14-1181]
   Ko G., 2020, P IEEE HOT CHIPS 32, P1, DOI [10.1109/HCS49909.2020.9220686, DOI 10.1109/HCS49909.2020.9220686]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   LaPedus M., 2017, 10NM VERSUS 7NM
   Lapedus Mark, 2017, BATTLING FAB CYCLE T
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Liao H., 2019, 2019 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2019.8875654
   Lin CH, 2020, ISSCC DIG TECH PAP I, P134, DOI 10.1109/ISSCC19947.2020.9063111
   Lin M., 2019, IEEE S VLSI CIRC, P28
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Meenderinck C, 2009, LECT NOTES COMPUT SC, V5415, P184
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Norrie T., 2020, 08 2020 HOT CHIPS S, P1
   Nvidia, 2017, NVDLA DEEP LEARN ACC
   Nvidia, NVID TESL V100 GPU A
   Ouyang J., 2020, 2020 IEEE HOT CHIPS, P1, DOI [10.1109/HCS49909.2020.9220641, DOI 10.1109/HCS49909.2020.9220641]
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pytorch, TORCHSCR
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santoro G, 2019, MICROMACHINES-BASEL, V10, DOI 10.3390/mi10060368
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shokrollahi A, 2016, ISSCC DIG TECH PAP I, V59, P182, DOI 10.1109/ISSCC.2016.7417967
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh T, 2020, ISSCC DIG TECH PAP I, P42, DOI 10.1109/ISSCC19947.2020.9063113
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Vivet P, 2020, ISSCC DIG TECH PAP I, P46, DOI 10.1109/ISSCC19947.2020.9062927
   Voogel M., 2020, IEEE HOT CHIPS 32 S, P1
   Weng YT, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS-TAIWAN (ICCE-TW), P19
   Wilson JM, 2018, ISSCC DIG TECH PAP I, P276, DOI 10.1109/ISSCC.2018.8310291
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yin JM, 2018, CONF PROC INT SYMP C, P726, DOI 10.1109/ISCA.2018.00066
   Yu YX, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P122, DOI 10.1145/3373087.3375311
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zimmer B, 2020, IEEE J SOLID-ST CIRC, V55, P920, DOI 10.1109/JSSC.2019.2960488
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
NR 78
TC 12
Z9 13
U1 0
U2 2
PY 2021
BP 1013
EP 1026
DI 10.1109/ISCA52012.2021.00083
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Liu, SL
   Du, ZD
   Tao, JH
   Han, D
   Luo, T
   Xie, Y
   Chent, YJ
   Chent, TS
AF Liu, Shaoli
   Du, Zidong
   Tao, Jinhua
   Han, Dong
   Luo, Tao
   Xie, Yuan
   Chent, Yunji
   Chent, Tianshi
GP IEEE
TI Cambricon: An Instruction Set Architecture for Neural Networks
SO 2016 ACM/IEEE 43RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 43rd ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2016
CL Seoul, SOUTH KOREA
AB Neural Networks (NN) are a family of models for a broad range of emerging machine learning and pattern recondition applications. NN techniques are conventionally executed on general-purpose processors (such as CPU and GPGPU), which are usually not energy-efficient since they invest excessive hardware resources to flexibly support various workloads. Consequently, application-specific hardware accelerators for neural networks have been proposed recently to improve the energy-efficiency. However, such accelerators were designed for a small set of NN techniques sharing similar computational patterns, and they adopt complex and informative instructions (control signals) directly corresponding to high-level functional blocks of an NN (such as layers), or even an NN as a whole. Although straightforward and easy-to-implement for a limited set of similar NN techniques, the lack of agility in the instruction set prevents such accelerator designs from supporting a variety of different NN techniques with sufficient flexibility and efficiency.
   In this paper, we propose a novel domain-specific Instruction Set Architecture (ISA) for NN accelerators, called Cambricon, which is a load-store architecture that integrates scalar, vector, matrix, logical, data transfer, and control instructions, based on a comprehensive analysis of existing NN techniques. Our evaluation over a total of ten representative yet distinct NN techniques have demonstrated that Cambricon exhibits strong descriptive capacity over a broad range of NN techniques, and provides higher code density than general-purpose ISAs such as x86, MIPS, and GPGPU. Compared to the latest state-of-the-art NN accelerator design DaDianNao [5] (which can only accommodate 3 types of NN techniques), our Cambricon-based accelerator prototype implemented in TSMC 65nm technology incurs only negligible latency/power/area overheads, with a versatile coverage of 10 different NN benchmarks.
C1 [Liu, Shaoli; Du, Zidong; Tao, Jinhua; Han, Dong; Luo, Tao; Chent, Yunji; Chent, Tianshi] Chinese Acad Sci, ICT, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Xie, Yuan] UCSB, Dept Elect & Comp Engn, Santa Barbara, CA USA.
   [Chent, Yunji; Chent, Tianshi] Chinese Acad Sci, Ctr Excellence Brain Sci & Intelligence Technol, Beijing, Peoples R China.
   [Liu, Shaoli; Du, Zidong; Tao, Jinhua; Han, Dong; Luo, Tao; Chent, Tianshi] Cambricon Ltd, Beijing, Peoples R China.
RP Liu, SL (corresponding author), Chinese Acad Sci, ICT, State Key Lab Comp Architecture, Beijing, Peoples R China.; Liu, SL (corresponding author), Cambricon Ltd, Beijing, Peoples R China.
EM liushaoli@ict.ac.cn; duzidong@ict.ac.cn; taojinhua@ict.ac.cn;
   handong2014@ict.ac.cn; luotao@ict.ac.cn; yuanxie@ece.ucsb.edu;
   cyj@ict.ac.cn; chentianshi@ict.ac.cn
CR [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 1981, P 8 ANN S COMP ARCH
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chang YF, 2014, ASIAPAC SIGN INFO PR
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Tianshi, 2015, IEEE MICRO
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi Ping, 2016, P INT S COMP ARCH IS
   Dahl GE, 2013, INT CONF ACOUST SPEE, P8609, DOI 10.1109/ICASSP.2013.6639346
   Eijkhout V., 2011, INTRO HIGH PERFORMAN
   Esmaeilzadeh H, 2006, IEEE INT SYMP CIRC S, P2773, DOI 10.1109/ISCAS.2006.1693199
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Graves A, 2005, IEEE IJCNN, P2047
   Hashmi A, 2011, ACM SIGPLAN NOTICES, V46, P145, DOI 10.1145/1961296.1950385
   Huang PS, 2013, PROCEEDINGS OF THE 22ND ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM'13), P2333
   James G, 2013, SPRINGER TEXTS STAT, V103, P1, DOI [10.1007/978-1-4614-7138-7, 10.1007/978-1-4614-7138-7_1]
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Kantabutra V., 1996, COMPUTERS IEEE T
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larochelle Hugo, 2007, P 24 INT C MACH LEAR, P473, DOI DOI 10.1145/1273496.1273556
   Le Q.V., 2013, P 2013 IEEE INT C AC
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu D., 2015, P 20 INT C ARCH SUPP
   Maashri A. A., 2012, P 49 ACM EDSAC IEEE
   Marsaglia George, 2000, J STAT SOFTWARE, P5
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Motter M. A., 1999, Proceedings of the 1999 American Control Conference (Cat. No. 99CH36251), P1659, DOI 10.1109/ACC.1999.786111
   Oliveira CS, 2004, IEEE IJCNN, P937
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pineda Fernando J, 1987, PHYS REV LETT
   Ren Shaoqing, 2015, ARXIV150201852
   Salakhutdinov R, 2012, NEURAL COMPUTATION
   Sankaradas M., 2009, P 20 IEEE INT C APPL
   Sarikaya R, 2014, IEEE-ACM T AUDIO SPE, V22, P778, DOI 10.1109/TASLP.2014.2303296
   Sermanet P, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P2809, DOI 10.1109/IJCNN.2011.6033589
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Wang Yu, 2015, P 25 ED GREAT LAK S
   Xu Cong, 2015, P 21 INT S HIGH PERF
   Xu Tao, 2012, P 2012 8 INT C NAT C
   Zeng XH, 2007, PROCEEDINGS OF 2007 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-7, P2885
   Zhang ZY, 1998, AUTOMATIC FACE AND GESTURE RECOGNITION - THIRD IEEE INTERNATIONAL CONFERENCE PROCEEDINGS, P454, DOI 10.1109/AFGR.1998.670990
   Zhao Jishen, 2013, ACM T ARCHITECTURE C
NR 48
TC 164
Z9 221
U1 2
U2 40
PY 2016
BP 393
EP 405
DI 10.1109/ISCA.2016.42
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Nasari, AS
   Le, HT
   Lawrence, R
   He, ZH
   Yang, X
   Krell, MM
   Tsyplikhin, A
   Tatineni, M
   Cockerill, T
   Perez, LM
   Chakravorty, DK
   Liu, HG
AF Nasari, Abhinand S.
   Le, Hieu T.
   Lawrence, Richard
   He, Zhenhua
   Yang, Xin
   Krell, Mario M.
   Tsyplikhin, Alex
   Tatineni, Mahidhar
   Cockerill, Tim
   Perez, Lisa M.
   Chakravorty, Dhruva K.
   Liu, Honggao
GP ACM
TI Benchmarking the Performance of Accelerators on National
   Cyberinfrastructure Resources for Artificial Intelligence / Machine
   LearningWorkloads
SO PRACTICE AND EXPERIENCE IN ADVANCED RESEARCH COMPUTING 2022
DT Proceedings Paper
CT Conference on Practice and Experience in Advanced Research Computing
   (PEARC) - Revolutionary - Computing, Connections, You
CY JUL 10-14, 2022
CL Boston, MA
DE ResNet50; ACES (Accelerating Computing for Emerging Sciences); Expanse;
   Graphics Processing Unit; Intelligence Processing Unit; PopVision;
   Classification; Convolution Neural Network; Optimization; Frontera;
   LoneStar6
AB Upcoming regional and National Science Foundation (NSF)-funded Cyberinfrastructure (CI) resources will give researchers opportunities to run their artificial intelligence / machine learning (AI/ML) workflows on accelerators. To effectively leverage this burgeoning CI-rich landscape, researchers need extensive benchmark data to maximize performance gains and map their workflows to appropriate architectures. This data will further assist CI administrators, NSF program officers, and CI allocation-reviewers make informed determinations on CI-resource allocations. Here, we compare the performance of two very different architectures: the commonly used Graphical Processing Units (GPUs) and the new generation of Intelligence Processing Units (IPUs), by running training benchmarks of common AI/ML models. We leverage the maturity of software stacks, and the ease of migration among these platforms to learn that performance and scaling are similar for both architectures. Exploring training parameters, such as batch size, however finds that owing to memory processing structures, IPUs run efficiently with smaller batch sizes, while GPUs benefit from large batch sizes to extract sufficient parallelism in neural network training and inference. This comes with different advantages and disadvantages as discussed in this paper.As such considerations of inference latency, inherent parallelism and model accuracy will play a role in researcher selection of these architectures. The impact of these choices on a representative image compression model system is discussed.
C1 [Nasari, Abhinand S.; Lawrence, Richard; He, Zhenhua; Perez, Lisa M.; Chakravorty, Dhruva K.; Liu, Honggao] Texas A&M Univ, HPRC, College Stn, TX USA.
   [Le, Hieu T.] Texas A&M Univ, Dept Elect & Comp Engn, College Stn, TX USA.
   [Krell, Mario M.; Tsyplikhin, Alex] Graphcore Inc, Palo Alto, CA USA.
   [Tatineni, Mahidhar] Univ San Diego, San Diego SuperComp Ctr, San Diego, CA USA.
   [Cockerill, Tim] Univ Texas Austin, Texas Adv Comp Ctr, Austin, TX USA.
RP Nasari, AS (corresponding author), Texas A&M Univ, HPRC, College Stn, TX USA.
EM abhinand@tamu.edu; hieult@tamu.edu; rlawrence@tamu.edu;
   happidence1@tamu.edu; karen890@tamu.edu; mmk@graphcore.ai;
   alext@graphcore.ai; mahidhar@sdsc.edu; cockerill@tacc.utexas.edu;
   perez@tamu.edu; chakravorty@tamu.edu; honggao@tamu.edu
CR [Anonymous], 2022, GRAPHCORE DOCUMENTS
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   COVID-19 HPC Consortium, 2021, US
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, DOI 10.48550/ARXIV.1704.04861]
   github, US
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hooker Sara, 2020, HARDWARE LOTTERY
   Jia Z, 2018, Arxiv, DOI [arXiv:1804.06826, 10.48550/ARXIV.1804.06826]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurzweil R, 1990, AGE INTELLIGENT MACH
   Lau Melinda Mei Lin, 2021, Proceedings of the Zoological Society (Calcutta), V74, P227, DOI 10.1007/s12595-021-00368-4
   Masters D, 2018, Arxiv, DOI [arXiv:1804.07612, DOI 10.48550/ARXIV.1804.07612]
   MLPerf, 2022, MLPERF NAM LOG AR TR
   National Science Foundation, 2021, US
   NVIDIA, 2022, NVID RTX
   NVIDIA, 2022, NGC CAT
   NVIDIA, 2020, A100 40GB PCIE PROD
   Russakovsky O, 2015, Arxiv, DOI arXiv:1409.0575
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Steinbuch K., 1963, IEEE T ELECT COMPUT, V12, P846, DOI [10.1109/PGEC.1963.263588, DOI 10.1109/PGEC.1963.263588, 10.1109/pgec.1963.263588]
   Steinkraus D, 2005, PROC INT CONF DOC, P1115, DOI 10.1109/ICDAR.2005.251
   TAMU HPRCWiki, 2021, US
   Tan MX, 2020, Arxiv, DOI [arXiv:1905.11946, DOI 10.48550/ARXIV.1905.11946]
   The Extreme Science and Engineering Discovery Environment (XSEDE), 2021, US
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3491418.3530772
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Wang, SY
   Zhang, XY
   Li, YX
   Bashizade, R
   Yang, S
   Dwyer, C
   Lebeck, AR
AF Wang, Siyang
   Zhang, Xiangyu
   Li, Yuxuan
   Bashizade, Ramin
   Yang, Song
   Dwyer, Chris
   Lebeck, Alvin R.
GP IEEE
TI Accelerating Markov Random Field Inference Using Molecular Optical Gibbs
   Sampling Units
SO 2016 ACM/IEEE 43RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 43rd ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2016
CL Seoul, SOUTH KOREA
ID NETWORK
AB The increasing use of probabilistic algorithms from statistics and machine learning for data analytics presents new challenges and opportunities for the design of computing systems. One important class of probabilistic machine learning algorithms is Markov Chain Monte Carlo (MCMC) sampling, which can be used on a wide variety of applications in Bayesian Inference. However, this probabilistic iterative algorithm can be inefficient in practice on today's processors, especially for problems with high dimensionality and complex structure. The source of inefficiency is generating samples from parameterized probability distributions.
   This paper seeks to address this sampling inefficiency and presents a new approach to support probabilistic computing that leverages the native randomness of Resonance Energy Transfer (RET) networks to construct RET-based sampling units (RSU). Although RSUs can be designed for a variety of applications, we focus on the specific class of probabilistic problems described as Markov Random Field Inference. Our proposed RSU uses a RET network to implement a molecular-scale optical Gibbs sampling unit (RSU-G) that can be integrated into a processor / GPU as specialized functional units or organized as a discrete accelerator. We experimentally demonstrate the fundamental operation of an RSU using a macro-scale hardware prototype. Emulation-based evaluation of two computer vision applications for HD images reveal that an RSU augmented GPU provides speedups over a GPU of 3 and 16. Analytic evaluation shows a discrete accelerator that is limited by 336 GB/s DRAM produces speedups of 21 and 54 versus the GPU implementations.
C1 [Wang, Siyang; Zhang, Xiangyu; Li, Yuxuan; Bashizade, Ramin; Yang, Song; Dwyer, Chris; Lebeck, Alvin R.] Duke Univ, Durham, NC 27708 USA.
RP Wang, SY (corresponding author), Duke Univ, Durham, NC 27708 USA.
EM siyang.wang@duke.edu; xiangyu.zhang@duke.edu; yuxuan.li@duke.edu;
   ramin.bashizade@duke.edu; song.yang@duke.edu; c.dwyer@duke.edu;
   alvy@duke.edu
CR [Anonymous], SENSORS J IEEE
   [Anonymous], ABS14024914 ARXIV
   [Anonymous], SENSORS J IEEE
   [Anonymous], MICRO IEEE
   [Anonymous], 1986, P INT C MATH INT C M
   [Anonymous], MARKOV RANDOM FIELD
   [Anonymous], COMPUTERS IEEE T
   [Anonymous], 2009, NATIVELY PROBABILIST
   [Anonymous], ADV CHEM PHYS
   [Anonymous], P 20 ANN INT C SUP C
   [Anonymous], 2008, CACTI 5 3
   [Anonymous], OPPORTUNITIES CHALLE
   [Anonymous], 2012, MACHINE LEARNING PRO
   [Anonymous], P 41 ANN INT S COMP
   Aono M, 2013, LANGMUIR, V29, P7557, DOI 10.1021/la400301p
   Assefa S, 2010, NATURE, V464, P80, DOI 10.1038/nature08813
   Bornholt J, 2014, ACM SIGPLAN NOTICES, V49, P51, DOI 10.1145/2541940.2541958
   Chakrapani LN, 2006, DES AUT TEST EUROPE, P1110
   de Kruijf M, 2011, INT SYMP MICROARCH, P140
   Devroye L, 1986, NONUNIFORM RANDOM VA
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Hill MT, 2014, NAT PHOTONICS, V8, P908, DOI 10.1038/nphoton.2014.239
   KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350
   LaBoda C, 2014, ACCOUNTS CHEM RES, V47, P1816, DOI 10.1021/ar500054u
   Luan L, 2012, IEEE SENS J, V12, P1794, DOI 10.1109/JSEN.2011.2179027
   Mandai S, 2012, OPT EXPRESS, V20, P5849, DOI 10.1364/OE.20.005849
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   Minka T.P., 2001, UNCERTAINTY ARTIFICI, V17, P362
   Mitzenmacher M, 2017, PROBABILITY COMPUTIN
   Naruse M, 2013, IEICE T COMMUN, VE96B, P2724, DOI 10.1587/transcom.E96.B.2724
   Pistol C, 2007, NANOTECHNOLOGY, V18, DOI 10.1088/0957-4484/18/12/125305
   Shambat G, 2012, IEEE J SEL TOP QUANT, V18, P1700, DOI 10.1109/JSTQE.2012.2193666
   Song T, 2014, ISSCC DIG TECH PAP I, V57, P232, DOI 10.1109/ISSCC.2014.6757413
   Stipcevic M, 2014, OPEN PROBLEMS MATH C, P275
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Szirányi T, 2000, REAL-TIME IMAGING, V6, P195, DOI 10.1006/rtim.1998.0159
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Valeur B., 2013, MOL FLUORESCENCE PRI
   Winn J, 2005, J MACH LEARN RES, V6, P661
NR 40
TC 8
Z9 8
U1 0
U2 0
PY 2016
BP 558
EP 569
DI 10.1109/ISCA.2016.55
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Moroz, L
   Samotyy, V
   Gepner, P
   Wegrzyn, M
   Nowakowski, G
AF Moroz, Leonid
   Samotyy, Volodymyr
   Gepner, Pawel
   Wegrzyn, Mariusz
   Nowakowski, Grzegorz
TI Power Function Algorithms Implemented in Microcontrollers and FPGAs
SO ELECTRONICS
DT Article
DE microcontrollers; FPGA; numerical methods; reconfigurable computing
   systems; accelerators for neural networks; machine learning; computer
   vision
ID LOGARITHM
AB The exponential function ax is widespread in many fields of science. Its calculation is a complicated issue for Central Processing Units (CPUs) and Graphics Processing Units (GPUs), as well as for specialised Digital Signal Processing (DSP) processors, such as Intelligent Processor Units (IPUs), for the needs of neural networks. This article presents some simple and accurate exponential function calculation algorithms in half, single, and double precision that can be prototyped in Field-Programmable Gate Arrays (FPGAs). It should be noted that, for the approximation, the use of effective polynomials of the first degree was proposed in most cases. The characteristic feature of such algorithms is that they only contain fast 'bithack' operations ('bit manipulation technique') and Floating-Point (FP) addition, multiplication, and (if necessary) Fused Multiply-Add (FMA) operations. We published an article on algorithms for this class of function recently, but the focus was on the use of approximations of second-degree polynomials and higher, requiring two multiplications and two additions or more, which poses some complications in FPGA implementation. This article considers algorithms based on piecewise linear approximation, with one multiplication and one addition. Such algorithms of low complexity provide decent accuracy and speed, sufficient for practical applications such as accelerators for neural networks, power electronics, machine learning, computer vision, and intelligent robotic systems. These are FP-oriented algorithms; therefore, we briefly describe the characteristic parameters of such numbers.
C1 [Moroz, Leonid; Gepner, Pawel] Warsaw Univ Technol, Fac Mech & Ind Engn, PL-00661 Warsaw, Poland.
   [Samotyy, Volodymyr; Wegrzyn, Mariusz; Nowakowski, Grzegorz] Cracow Univ Technol, Fac Elect & Comp Engn, Warszawska 24 Str, PL-31155 Krakow, Poland.
RP Nowakowski, G (corresponding author), Cracow Univ Technol, Fac Elect & Comp Engn, Warszawska 24 Str, PL-31155 Krakow, Poland.
EM leonid.moroz@pw.edu.pl; vsamotyy@pk.edu.pl; pawel.gepner@pw.edu.pl;
   mariusz.wegrzyn@pk.edu.pl; gnowakowski@pk.edu.pl
CR de Dinechin Florent, 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P110, DOI 10.1109/FPT.2010.5681764
   Dong HX, 2020, IEEE T VLSI SYST, V28, P2014, DOI 10.1109/TVLSI.2020.3004602
   Echeverria P., FPGA IMPLEMENTATION
   Eissa S, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458560
   Frenzen CL, 2010, J COMPUT APPL MATH, V234, P437, DOI 10.1016/j.cam.2009.12.035
   Geng X., 2018, P 14 AS C COMP VIS P
   Jamro E, 2007, I C FIELD PROG LOGIC, P718, DOI 10.1109/FPL.2007.4380753
   Malossi A.C.I., 2015, P C HIPEAC 2015 1 WO
   Moroz L, 2022, IEEE SIGNAL PROC MAG, V39, P130, DOI 10.1109/MSP.2022.3157460
   Nandagopal R, 2022, IEEE I C ELECT CIRC, DOI 10.1109/ICECS202256217.2022.9970828
   Nico W., 2011, P IEEE INT S POW LIN
   Perini F, 2018, COMBUST FLAME, V194, P37, DOI 10.1016/j.combustflame.2018.04.013
   Piñeiro JA, 2004, IEEE T COMPUT, V53, P1085, DOI 10.1109/TC.2004.53
   Schraudolph NN, 1999, NEURAL COMPUT, V11, P853, DOI 10.1162/089976699300016467
   Simmonds N, 2016, Arxiv, DOI arXiv:1605.03229
   Wei J., 2021, P IEEE 14 INT C ASIC
   Zheng QM, 2019, IEEE ACCESS, V7, P151359, DOI 10.1109/ACCESS.2019.2948112
NR 17
TC 0
Z9 0
U1 0
U2 0
PD AUG
PY 2023
VL 12
IS 16
AR 3399
DI 10.3390/electronics12163399
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Nakahara, H
   Jinguji, A
   Fujii, T
   Sato, S
AF Nakahara, Hiroki
   Jinguji, Akira
   Fujii, Tomonori
   Sato, Simpei
BE Song, YC
   Wang, S
   Nelson, B
   Li, J
   Peng, Y
TI An Acceleration of a Random Forest Classification using Altera SDK for
   OpenCL
SO 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT)
DT Proceedings Paper
CT 15th International Conference on Field-Programmable Technology (FPT)
CY DEC 07-09, 2016
CL Xian, PEOPLES R CHINA
AB A random forest (RF) is a kind of ensemble machine learning algorithm used for a classification and a regression. It consists of multiple decision trees that are built from randomly sampled data. The RF has a simple, fast learning, and identification capability compared with other machine learning algorithms. It is widely used for applicable to various recognition systems. Since it is necessary to un-balanced trace for each tree and requires communication for all the ones, the random forest is not suitable in SIMD architectures such as GPUs. Although the accelerators using the FPGA have been proposed, such implementations were based on HDL design. Thus, they required longer design time compared with the soft-ware based realizations. In this paper, we show the accelerator for the RF using the Altera SDK for OpenCL, which is a kind of high-level synthesis. To accelerate the RF classification, we propose the fully pipelined architecture to increase the memory bandwidth using on-chip memories on the FPGA. Also, we apply appropriate bit fixed point representation instead of 32 bit floating point one in order to reduce the hardware size, power consumption, and increase the memory bandwidth. We implemented the RF on the Terasic Corp. DE5-NET FPGA board, and compared with the CPU and the GPU implementations, As for the LPS (lookups per second), the FPGA realization was 10.7 times faster than the GPU one, and it was 14.0 times faster than the CPU one. As for the LPS per power consumption, the FPGA realization was 61.3 times better than the GPU one, and it was 12.1 times better than the CPU one.
C1 [Nakahara, Hiroki; Jinguji, Akira; Fujii, Tomonori; Sato, Simpei] Tokyo Inst Technol, Tokyo, Kanagawa, Japan.
RP Nakahara, H (corresponding author), Tokyo Inst Technol, Tokyo, Kanagawa, Japan.
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], 2011, COMP VIS LOW POW REC
   [Anonymous], 2010, CVPR
   [Anonymous], ALT SDK OPENCL
   [Anonymous], INT WORKSH OPENCL 20
   [Anonymous], 2012, ANN IEEE SYM FIELD P, DOI DOI 10.1109/FCCM.2012.47
   [Anonymous], MACH LEARN
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Le HA, 2008, ANN IEEE SYM FIELD P, P33, DOI 10.1109/FCCM.2008.9
   Lo WT, 2014, SCI WORLD J, DOI 10.1155/2014/745640
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Oberg J., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P330, DOI 10.1109/FPL.2012.6339226
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
NR 14
TC 12
Z9 12
U1 0
U2 0
PY 2016
BP 289
EP 292
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kang, MG
   Gonugondla, SK
   Shanbhag, NR
AF Kang, Mingu
   Gonugondla, Sujan K.
   Shanbhag, Naresh R.
TI Deep In-Memory Architectures in SRAM: An Analog Approach to Approximate
   Computing
SO PROCEEDINGS OF THE IEEE
DT Article
DE Accelerator; artificial intelligence; energy efficiency; in-memory
   computing; machine learning (ML); non-von Neumann
ID ACCELERATOR; MACRO; PROCESSOR; CMOS; CHIP
AB This article provides an overview of recently proposed deep in-memory architectures (DIMAs) in SRAM for energy- and latency-efficient hardware realization of machine learning (ML) algorithms. DIMA tackles the data movement problem in von Neumann architectures head-on by deeply embedding mixed-signal computations into a conventional memory array. In doing so, it trades off its computational signal-to-noise ratio (compute SNR) with energy and latency, and therefore, it represents an analog form of approximate computing. DIMA exploits the inherent error immunity of ML algorithms and SNR budgeting methods to operate its analog circuitry in a low-swing/low-compute SNR regime, thereby achieving $> 100\times $ reduction in the energy-delay product (EDP) over an equivalent von Neumann architecture with no loss in inference accuracy. This article describes DIMA's computational pipeline and provides a Shannon-inspired rationale for its robustness to process, temperature, and voltage variations and design guidelines to manage its analog nonidealities. DIMA's versatility, effectiveness, and practicality demonstrated via multiple silicon IC prototypes in a 65-nm CMOS process are described. A DIMA-based instruction set architecture (ISA) to realize an end-to-end application-to-architecture mapping for the accelerating diverse ML algorithms is also presented. Finally, DIMA's fundamental tradeoff between energy and accuracy in the low-compute SNR regime is analyzed to determine energy-optimum design parameters.
C1 [Kang, Mingu] Univ Calif San Diego UCSD, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
   [Gonugondla, Sujan K.] Amazon, Seattle, WA 98121 USA.
   [Shanbhag, Naresh R.] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL 61801 USA.
RP Kang, MG (corresponding author), Univ Calif San Diego UCSD, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM m7kang@ucsd.edu; gsujan@amazon.com; shanbhag@illinois.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], 2016, ARXIV161007501
   [Anonymous], 2018, ARXIV181104047
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2012, ANN IEEE SYM FIELD P, DOI DOI 10.1109/FCCM.2012.47
   [Anonymous], MACH LEARN
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi J, 2019, IND COMMER POWER, P400, DOI [10.1080/20469047.2019.1607056, 10.1109/icps.2019.8733345]
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Frustaci F, 2015, IEEE J SOLID-ST CIRC, V50, P1310, DOI 10.1109/JSSC.2015.2408332
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/vlsic.2019.8778028, 10.23919/VLSIC.2019.8778028]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Huang L., 2014, SPIE P, P1
   Huang PT, 2011, IEEE J SOLID-ST CIRC, V46, P507, DOI 10.1109/JSSC.2010.2082270
   Hubara I, 2016, ADV NEUR IN, V29
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jia H., 2018, ARXIV181104047
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang M., 2020, DEEP IN MEMORY ARCHI
   Kang M, 2020, IEEE T CIRCUITS-I, V67, P1627, DOI 10.1109/TCSI.2019.2960841
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/VLSIC.2019.8778160, 10.23919/vlsic.2019.8778160]
   KOBAYASHI T, 1993, IEEE J SOLID-ST CIRC, V28, P523, DOI 10.1109/4.210039
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y., 1988, P 1988 CONNECTIONIST, P21
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Ludwig JT, 1996, IEEE J SOLID-ST CIRC, V31, P395, DOI 10.1109/4.494201
   Miao J, 2014, ICCAD-IEEE ACM INT, P504, DOI 10.1109/ICCAD.2014.7001398
   Miao J, 2013, ICCAD-IEEE ACM INT, P779, DOI 10.1109/ICCAD.2013.6691202
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Murmann B, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P1341, DOI 10.1109/ACSSC.2015.7421361
   Nawab SH, 1997, J VLSI SIG PROC SYST, V15, P177, DOI 10.1023/A:1007986707921
   Nii K, 2014, ISSCC DIG TECH PAP I, V57, P240, DOI 10.1109/ISSCC.2014.6757417
   Okumura S, 2019, S VLSI TECH, pC248
   Onizawa N, 2012, INT SYMP ASYNCHRON C, P41, DOI 10.1109/ASYNC.2012.25
   Prisacariu Victor Adrian, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P3344, DOI 10.1109/ICPR.2010.816
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Sakr C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1090, DOI 10.1109/ICASSP.2018.8461702
   Sarpeshkar R, 1998, NEURAL COMPUT, V10, P1601, DOI 10.1162/089976698300017052
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Shanbhag NR, 2019, P IEEE, V107, P90, DOI 10.1109/JPROC.2018.2869867
   Shanbhag NR, 2010, DES AUT CON, P859
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shulaker M. M., 2014, IEDM, P4
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Srivastava P, 2018, CONF PROC INT SYMP C, P43, DOI 10.1109/ISCA.2018.00015
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Wang N., 2018, TRAINING DEEP NEURAL
   Wen W, 2016, ADV NEUR IN, V29
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yang ZX, 2013, 2013 13TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P690, DOI 10.1109/NANO.2013.6720793
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang BA, 2019, INT CONF ACOUST SPEE, P1388, DOI 10.1109/ICASSP.2019.8683521
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang JT, 2016, SYMP VLSI CIRCUITS
   Zhou ZM, 1997, IEEE T ELECTRON DEV, V44, P1759, DOI 10.1109/16.628833
NR 87
TC 13
Z9 13
U1 0
U2 9
PD DEC
PY 2020
VL 108
IS 12
BP 2251
EP 2275
DI 10.1109/JPROC.2020.3034117
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Reimann, S
   Droba, M
   Meusel, O
   Podlech, H
AF Reimann, S.
   Droba, M.
   Meusel, O.
   Podlech, H.
GP IOP
TI An algorithm for automated lattice design of transfer lines
SO 10TH INTERNATIONAL PARTICLE ACCELERATOR CONFERENCE
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 10th International Particle Accelerator Conference (IPAC)
CY MAY 19-24, 2019
CL Melbourne, AUSTRALIA
AB Since the last 20 years, modern heuristic algorithms and machine learning have been increasingly used for several purposes in accelerator technology and physics. Since computing power has become less and less of a limiting factor, these tools have become part of the physicist community's standard toolkit [1][2] [3] [4] [5]. This paper describes the construction of an algorithm that can be used to generate an optimised lattice design for transfer lines under the consideration of restrictions that usually limit design options in reality. The developed algorithm has been applied to the existing SIS18 to HADES transfer line in GSI.
C1 [Reimann, S.; Droba, M.; Meusel, O.; Podlech, H.] Goethe Univ, IAP, Frankfurt, Germany.
   [Reimann, S.] GSI Helmholtz Ctr, Darmstadt, Germany.
RP Reimann, S (corresponding author), Goethe Univ, IAP, Frankfurt, Germany.; Reimann, S (corresponding author), GSI Helmholtz Ctr, Darmstadt, Germany.
EM s.reimann@gsi.de
CR Agakichiev G, 2009, EUR PHYS J A, V41, P243, DOI 10.1140/epja/i2009-10807-5
   Appel S, 2015, P 6 INT PART ACC C R, P3689
   Appel S, 2019, COMMUNICATION
   Bakkali Taheri F, 2019, P 10 INT PART ACC C
   Geithner W, 2018, P IPAC 18 VANC CAN, P4712, DOI DOI 10.18429/JACOW-IPAC2018-THPML028
   Hinterberger F, 2008, PHYS TEILCHENBESCHLE
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Mitchell M., 1996, INTRO GENETIC ALGORI
   Noll D, 2011, P 2 INT PART ACC C S, P667
   Pietraszko J, 2016, P HIC4FAIR WORKSH DA
   Powell MJD, 2009, NA200906
   Sapinski M, 2017, P 8 INT PART ACC C C, P2214
   Sapinski M, 2019, P 10 INT PART ACC C
   Spiller P., 2018, PROC 9 INT PART ACCE, P63, DOI [10.18429/jacowipac2018-mozgbf2, DOI 10.18429/JACOWIPAC2018-MOZGBF2]
   Streichert M, 2012, P 11 INT COMP ACC PH, P72
NR 15
TC 1
Z9 1
U1 1
U2 1
PY 2019
VL 1350
AR 012110
DI 10.1088/1742-6596/1350/1/012110
WC Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Kruppe, H
   Sommer, L
   Weber, L
   Oppermann, J
   Axenie, C
   Koch, A
AF Kruppe, Hanna
   Sommer, Lukas
   Weber, Lukas
   Oppermann, Julian
   Axenie, Cristian
   Koch, Andreas
BE Orailoglu, A
   Jung, M
   Reichenbach, M
TI Efficient Operator Sharing Modulo Scheduling for Sum-Product Network
   Inference on FPGAs
SO EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION,
   SAMOS 2021
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 21st International Conference on Embedded Computer Systems -
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 04-08, 2021
CL ELECTR NETWORK
DE FPGA; Machine learning; Probabilistic model; Sum-product network; Modulo
   scheduling; Graph partitioning
AB Probabilistic models are receiving increasing attention as a complementary alternative to more widespread machine learning approaches such as neural networks. One particularly interesting class of models, so-called Sum-Product Networks (SPNs), combine the expressiveness of probabilistic models with tractable inference, making them an interesting candidate for use in real-world applications.
   Previously, inference in SPNs has successfully been accelerated by fully pipelined FPGA-based hardware. However, with these approaches, the maximum size of the SPN for FPGA acceleration has effectively been limited by the fully spatial mapping of arithmetic operations into hardware and the number of available resources in the FPGA.
   In this work, we present an extended and specialized modulo scheduling algorithm based on Integer Linear Programming (ILP) for time-multiplexed sharing of hardware arithmetic operators in the SPN inference accelerator. In addition and in order to scale the scheduling to large SPN graphs, we combine the scheduling algorithm with a graph-partitioning heuristic, exploiting the graph structure of SPNs.
   The combination of heuristic graph partitioning and ILP-based scheduling allows generating pipe-lined accelerators with the best possible initiation interval, while limiting the resource utilization to pre-set bounds. The evaluation discusses the effect different parameters have on convergence time and solution quality. A performance comparison shows that the FPGA improves the inference throughput over a comparable CPU- and GPU platform by a factor (geo.-mean) of 4.4x and 1.7x, respectively.
C1 [Kruppe, Hanna; Sommer, Lukas; Weber, Lukas; Oppermann, Julian; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
   [Axenie, Cristian] Huawei Munich Res Ctr, Intelligent Cloud Technol Lab, Munich, Germany.
RP Kruppe, H (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM kruppe@esa.tu-darmstadt.de; sommer@esa.tu-darmstadt.de;
   weber@esa.tu-darmstadt.de; oppermann@esa.tu-darmstadt.de;
   cristian.axenie@huawei.com; koch@esa.tu-darmstadt.de
CR Canis A., 2014, 2014 24 INT C FIELD, P1, DOI DOI 10.1109/FPL.2014.6927490
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Codina J. M., 2002, Conference Proceedings of the 2002 International Conference on SUPERCOMPUTING, P97, DOI 10.1145/514191.514208
   Cong J., 2008, P DES AUT TEST EUR, P1057, DOI DOI 10.1145/1403375.1403629
   Dai S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317842
   Fan K, 2005, INT SYMP MICROARCH, P219
   Heinz C, 2021, J SIGNAL PROCESS SYS, V93, P545, DOI 10.1007/s11265-021-01640-8
   Lam M., 1988, SIGPLAN Notices, V23, P318, DOI 10.1145/960116.54022
   Memik SO, 2003, DES AUT CON, P604
   Molina A, 2018, AAAI CONF ARTIF INTE, P3828
   Ober M., 2019, WORKSHOP HETEROGENEO
   Oppermann J., 2019, C PARALLEL DISTRIBUT
   Peharz R., 2019, P UAI
   Peharz R, 2015, JMLR WORKSH CONF PRO, V38, P744
   Poon H, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Rau BR, 1996, INT J PARALLEL PROG, V24, P3
   Sánchez-Cauce R, 2022, IEEE T PATTERN ANAL, V44, P3821, DOI 10.1109/TPAMI.2021.3061898
   Sittel P, 2018, I C FIELD PROG LOGIC, P265, DOI 10.1109/FPL.2018.00053
   Sommer L., 2018, IEEE INT C COMPUTER
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sucha P, 2011, COMPUT OPTIM APPL, V48, P71, DOI 10.1007/s10589-009-9239-4
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Weber L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P251, DOI 10.1109/ICFPT47387.2019.00040
   Zhang ZR, 2013, ICCAD-IEEE ACM INT, P211, DOI 10.1109/ICCAD.2013.6691121
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2022
VL 13227
BP 242
EP 258
DI 10.1007/978-3-031-04580-6_16
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Choudhury, R
   Ahamed, SR
   Guha, P
AF Choudhury, Rituparna
   Ahamed, S. R.
   Guha, Prithwijit
GP IEEE Comp Soc
TI Efficient Hardware Implementation of Decision Tree Training Accelerator
SO 2020 6TH IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES
   2020) (FORMERLY INIS)
DT Proceedings Paper
CT 6th IEEE International Symposium on Smart Electronic Systems (IEEE-iSES)
CY DEC 14-16, 2020
CL ELECTR NETWORK
DE Machine learning; Decision Tree; FPGA; Serial Architecture;
   Classification Algorithm
ID RANDOM FOREST; NEURAL TREE; CLASSIFICATION
AB This paper proposes a serial architecture as implementation for Two Means Decision Tree. This DT algorithm exhibits lower complexity. This architecture is implemented on Field Programmable Gate Array (FPGA) running at 62 MHz. Simulation results show that the proposed hardware architecture exhibits 10x speed-up as compared to its software implementation and runs 28x faster than C4.5 algorithm. It also consumes less power as compared to complex algorithms implemented On Graphical Processor Units (GPU). Hence the architecture is suitable for simple low power high speed applications.
C1 [Choudhury, Rituparna; Ahamed, S. R.; Guha, Prithwijit] Indian Inst Technol, Dept Elect & Elect Engn, Gauhati, India.
RP Choudhury, R (corresponding author), Indian Inst Technol, Dept Elect & Elect Engn, Gauhati, India.
EM ritup176102101@iitg.ac.in; rafiahamed@iitg.ac.in; pguha@iitg.ac.in
CR Ahmad MW, 2017, ENERG BUILDINGS, V147, P77, DOI 10.1016/j.enbuild.2017.04.038
   [Anonymous], 2001, FPGA 01
   Behnke S, 1998, IEEE T NEURAL NETWOR, V9, P1352, DOI 10.1109/72.728387
   Buschjäger S, 2018, IEEE T CIRCUITS-I, V65, P209, DOI 10.1109/TCSI.2017.2710627
   Canilho J, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577313
   Chrysos G, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400706
   Davey N, 2000, APPL INTELL, V12, P75, DOI 10.1023/A:1008364004705
   Dua D, 2020, UCI MACHINE LEARNING
   Foresti GL, 2004, IEEE T SYST MAN CY B, V34, P988, DOI 10.1109/TSMCB.2003.818538
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Shoaran M, 2018, IEEE J EM SEL TOP C, V8, P693, DOI 10.1109/JETCAS.2018.2844733
   Tong D, 2017, IEEE T PARALL DISTR, V28, P3046, DOI 10.1109/TPDS.2017.2714661
NR 13
TC 1
Z9 1
U1 1
U2 2
PY 2020
BP 212
EP 215
DI 10.1109/iSES50453.2020.00055
WC Green & Sustainable Science & Technology; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Oliveira, GF
   Santos, PC
   Alves, MAZ
   Carro, L
AF Oliveira, Geraldo F.
   Santos, Paulo C.
   Alves, Marco A. Z.
   Carro, Luigi
BE Wong, S
   Beck, AC
   Bertels, K
   Carro, L
TI NIM: An HMC-Based Machine for Neuron Computation
SO APPLIED RECONFIGURABLE COMPUTING
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 13th International Symposium on Applied Reconfigurable Computing (ARC)
CY APR 03-07, 2017
CL Delft, NETHERLANDS
DE Processing in memory; Near-data processing; Neuron simulator; Neural
   networks; Hybrid memory cube; Vector operations
ID SIMULATIONS
AB Neuron Network simulation has arrived as a methodology to help one solve computational problems by mirroring behavior. However, to achieve consistent simulation results, large sets of workloads need to be evaluated. In this work, we present a neural in-memory simulator capable of executing deep learning applications inside 3D-stacked memories. With the reduction of data movement and by including a simple accelerator layer near to memory, our system was able to overperform traditional multi-core devices, while reducing overall system energy consumption.
C1 [Oliveira, Geraldo F.; Santos, Paulo C.; Carro, Luigi] Fed Univ Rio Grande, Inst Informat, Porto Alegre, RS, Brazil.
   [Alves, Marco A. Z.] Univ Fed Parana, Dept Informat, Curitiba, Parana, Brazil.
RP Oliveira, GF (corresponding author), Fed Univ Rio Grande, Inst Informat, Porto Alegre, RS, Brazil.
EM gfojunior@inf.ufrgs.br; pcssjunior@inf.ufrgs.br; mazalves@inf.ufpr.br;
   carro@inf.ufrgs.br
CR Alves M. A. Z., 2015, HIGH PERF COMP C
   Alves MAZ, 2016, DES AUT TEST EUROPE, P1249
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Beuler Marcel, 2012, Artificial Neural Networks and Machine Learning - ICANN 2012. Proceedings of the 22nd International Conference on Artificial Neural Networks, P97, DOI 10.1007/978-3-642-33269-2_13
   De Gruijl JR, 2012, PLOS COMPUT BIOL, V8, DOI 10.1371/journal.pcbi.1002814
   Hines M, 2011, FRONT COMPUT NEUROSC, V5, DOI 10.3389/fncom.2011.00049
   HODGKIN AL, 1990, B MATH BIOL, V52, P25, DOI 10.1016/S0092-8240(05)80004-7
   Hybrid Memory Cube Consortium, 2013, HYBR MEM CUB SPEC RE
   Izhikevich EM, 2003, IEEE T NEURAL NETWOR, V14, P1569, DOI 10.1109/TNN.2003.820440
   Lee DU, 2014, ISSCC DIG TECH PAP I, V57, P432, DOI 10.1109/ISSCC.2014.6757501
   Li S, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2445572.2445577
   Sakai K, 1997, COMPUT BIOL MED, V27, P257, DOI 10.1016/S0010-4825(96)00029-7
   Santos P. C., 2017, 2017 DES AUT TEST EU
   Smaragdos G., 2014, P 2014 ACM SIGDA INT, P89
   Wang MC, 2011, 2011 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN), P3184, DOI 10.1109/IJCNN.2011.6033643
   Xu L., 2015, WONDP
   Zenke F, 2014, FRONT NEUROINFORM, V8, DOI 10.3389/fninf.2014.00076
   Zhang YW, 2013, IEEE T COMPUT, V62, P599, DOI 10.1109/TC.2011.257
NR 18
TC 10
Z9 10
U1 0
U2 0
PY 2017
VL 10216
BP 28
EP 35
DI 10.1007/978-3-319-56258-2_3
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Park, J
   Lee, S
   Jeon, D
AF Park, Jeongwoo
   Lee, Sunwoo
   Jeon, Dongsuk
TI A Neural Network Training Processor With 8-Bit Shared Exponent Bias
   Floating Point and Multiple-Way Fused Multiply-Add Trees
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Training; Tensors; Neural networks; Hardware; Task analysis;
   Computational modeling; Degradation; Computational efficiency; digital
   integrated circuits; learning systems; neural network accelerators; very
   large-scale integration
AB Recent advances in deep neural networks (DNNs) and machine learning algorithms have induced the demand for services based on machine learning algorithms that require a large number of computations, and specialized hardware ranging from accelerators for data centers to on-device computing systems have been introduced. Low-precision math such as 8-bit integers have been used in neural networks for energy-efficient neural network inference, but training with low-precision numbers without performance degradation have remained to be a challenge. To overcome this challenge, this article presents an 8-bit floating-point neural network training processor for state-of-the-art non-sparse neural networks. As naive 8-bit floating-point numbers are insufficient for training DNNs robustly, two additional methods are introduced to ensure high-performance DNN training. First, a novel numeric system which we dub as 8-bit floating point with shared exponent bias (FP8-SEB) is introduced. Moreover, multiple-way fused multiply-add (FMA) trees are used in FP8-SEB's hardware implementation to ensure higher numerical precision and reduced energy. FP8-SEB format combined with multiple-way FMA trees is evaluated under various scenarios to show a trained-from-scratch performance that is close to or even surpasses that of current networks trained with full-precision (FP32). Our silicon-verified DNN training processor utilizes 24-way FMA trees implemented with FP8-SEB math and flexible 2-D routing schemes to show 2.48x higher energy efficiency than prior low-power neural network training processors and 78.1x lower energy than standard GPUs.
C1 [Park, Jeongwoo; Lee, Sunwoo; Jeon, Dongsuk] Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Seoul 08826, South Korea.
   [Park, Jeongwoo; Lee, Sunwoo; Jeon, Dongsuk] Seoul Natl Univ, Interuniv Semicond Res Ctr, Seoul 08826, South Korea.
RP Jeon, D (corresponding author), Seoul Natl Univ, Grad Sch Convergence Sci & Technol, Seoul 08826, South Korea.
EM djeon1@snu.ac.kr
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   [Anonymous], 1997, NEURAL COMPUT
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   Fox S., 2021, PROC INT C LEARN REP, P1
   Gupta S, 2015, I C DEPEND SYS NETWO, P37, DOI 10.1109/DSN.2015.52
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G.E., 2012, ADV NEURAL INF PROCE, P1097
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jeongwoo Park, 2021, 2021 IEEE International Solid- State Circuits Conference (ISSCC), P1, DOI 10.1109/ISSCC42613.2021.9366031
   Kang S, 2020, ISSCC DIG TECH PAP I, P140, DOI 10.1109/ISSCC19947.2020.9062989
   Kim C, 2019, ISSCC DIG TECH PAP I, V62, P136, DOI [10.1109/isscc.2019.8662447, 10.1109/ISSCC.2019.8662447]
   Kim S., 2020, SYMP VLSI CIRCUITS, P1
   Konecny J., 2016, FEDERATED LEARNING S
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Micikevicius Paulius, 2017, P INT C LEARN REPR I
   Monniaux D, 2008, ACM T PROGR LANG SYS, V30, DOI 10.1145/1353445.1353446
   Oh J., 2020, PROC IEEE S VLSI CIR, P1
   Radford A., 2015, ARXIV151106434, DOI DOI 10.1007/978-3-319-71589-6_9
   Ramachandran P., 2017, CORR, P1
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Sun X, 2019, ADV NEUR IN, V32
   Wang N., 2018, ADV NEURAL INFORM PR, P7675, DOI DOI 10.1109/THERMINIC.2018.8593303
   Xie Cihang, 2020, ARXIV200614536
   Zhou S., 2016, ARXIV160606160
NR 27
TC 10
Z9 10
U1 0
U2 4
PD MAR
PY 2022
VL 57
IS 3
BP 965
EP 977
DI 10.1109/JSSC.2021.3103603
EA AUG 2021
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ferikoglou, A
   Oroutzoglou, I
   Kokkinis, A
   Danopoulos, D
   Masouros, D
   Chondrogiannis, E
   Gómez, AF
   Kretsis, A
   Kokkinos, P
   Varvarigos, E
   Siozios, K
AF Ferikoglou, Aggelos
   Oroutzoglou, Ioannis
   Kokkinis, Argyris
   Danopoulos, Dimitrios
   Masouros, Dimosthenis
   Chondrogiannis, Efthymios
   Gomez, Aitor Fernandez
   Kretsis, Aristotelis
   Kokkinos, Panagiotis
   Varvarigos, Emmanouel
   Siozios, Kostas
BE Orailoglu, A
   Jung, M
   Reichenbach, M
TI Towards Efficient HW Acceleration in Edge-Cloud Infrastructures: The
   SERRANO Approach Invited Paper
SO EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION,
   SAMOS 2021
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 21st International Conference on Embedded Computer Systems -
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 04-08, 2021
CL ELECTR NETWORK
DE Edge computing; Cloud continuum; Hardware accelerators; GPU; FPGA;
   Heterogeneous
AB Nowadays, we witness an ever-increased number of applications deployed over Edge, Cloud and HPC infrastructures. This rapid explosion of computing devices across the computing continuum poses new challenges in terms of providing a power-efficient, secure and automatic way for deployment of different applications in such heterogeneous environments. Moreover, the need for performance efficient deployments within such environments, has introduced the presence of hardware accelerators over the entire computing stack.
   In this paper, we present SERRANO's approach for providing efficient HW accelerated deployments over edge-cloud infrastructures. First, we give a brief overview of the SERRANO project, describing its goals and objectives, providing a high-level overview of SERRANO's platform architecture and presenting the use-cases involved. Then, we describe SERRANO's approach for providing efficient HW accelerators by identifying trade-offs between performance, accuracy and power consumption and also demonstrate how SERRANO aims to automate the optimization process through machine learning models in order to construct a generic optimization heuristic to fine-tune programs for both GPU and FPGA accelerators. Through some illustrative examples, we showcase that by applying approximation and optimization techniques, we are able to achieve an average decrease of 28% in power consumption for FPGA devices and trade-off between performance and power usage for GPUs, achieving up to x1.21 speedups and 8% power improvement.
C1 [Ferikoglou, Aggelos; Oroutzoglou, Ioannis; Kokkinis, Argyris; Danopoulos, Dimitrios; Masouros, Dimosthenis; Siozios, Kostas] Aristotle Univ Thessaloniki, Thessaloniki, Greece.
   [Chondrogiannis, Efthymios] Innovat Acts Ltd, Nicosia, Cyprus.
   [Gomez, Aitor Fernandez] IDEKO, ICT & AUTOMAT Res Grp, Elgoibar, Basque Country, Spain.
   [Kretsis, Aristotelis; Kokkinos, Panagiotis; Varvarigos, Emmanouel] Natl Tech Univ Athens, Athens, Greece.
RP Ferikoglou, A (corresponding author), Aristotle Univ Thessaloniki, Thessaloniki, Greece.
EM aferikog@physics.auth.gr; ioroutzo@physics.auth.gr;
   akokkino@physics.auth.gr; ddanopou@physics.auth.gr;
   dmasoura@physics.auth.gr; afgomez@ideko.es; akretsis@mail.ntua.gr;
   kokkinop@mail.ntua.gr; vmanos@mail.ntua.gr; ksiop@physics.auth.gr
CR [Anonymous], VIT PLATF
   [Anonymous], 2021, GARTN FOR WORLDW PUB
   [Anonymous], FUTURE CLOUD COMPUTI
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Danopoulos D., 2019, QUANTITATIVE COMP IM, P171, DOI [10.1201/9780429399602-8, DOI 10.1201/9780429399602-8]
   Danopoulos D, 2019, 2019 14TH INTERNATIONAL SYMPOSIUM ON RECONFIGURABLE COMMUNICATION-CENTRIC SYSTEMS-ON-CHIP (RECOSOC 2019), P59, DOI 10.1109/ReCoSoC48741.2019.9034938
   Finnerty A., 2017, REDUCE POWER COST CO
   Grauer-Gray Scott, 2012, INNOVATIVE PARALLEL, P1
   Ko JH, 2017, Arxiv, DOI arXiv:1712.01340
   Koliogeorgi K, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST), DOI 10.1109/mocast.2019.8742064
   Kouris A, 2019, IEEE COMP SOC ANN, P570, DOI 10.1109/ISVLSI.2019.00107
   Magni A, 2014, INT CONFER PARA, P455, DOI 10.1145/2628071.2628087
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Sinha S, 2016, IEEE T VLSI SYST, V24, P2665, DOI 10.1109/TVLSI.2016.2520979
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Tziantzioulis G, 2018, IEEE MICRO, V38, P60, DOI 10.1109/MM.2018.043191126
   Wang Z, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P307
   Xilinx, US
NR 20
TC 1
Z9 1
U1 0
U2 0
PY 2022
VL 13227
BP 354
EP 367
DI 10.1007/978-3-031-04580-6_24
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Hamerly, R
   Bernstein, L
   Sludds, A
   Soljacic, M
   Englund, D
AF Hamerly, Ryan
   Bernstein, Liane
   Sludds, Alexander
   Soljacic, Marin
   Englund, Dirk
TI Large-Scale Optical Neural Networks Based on Photoelectric
   Multiplication
SO PHYSICAL REVIEW X
DT Article
ID NOISE; PHOTODETECTOR; GENERATION; CONVERSION; MACHINE; STORAGE; DESIGN
AB Recent success in deep neural networks has generated strong interest in hardware accelerators to improve speed and energy consumption. This paper presents a new type of photonic accelerator based on coherent detection that is scalable to large (N greater than or similar to 10(6)) networks and can be operated at high (gigahertz) speeds and very low (subattojoule) energies per multiply and accumulate (MAC), using the massive spatial multiplexing enabled by standard free-space optical components. In contrast to previous approaches, both weights and inputs are optically encoded so that the network can be reprogrammed and trained on the fly. Simulations of the network using models for digit and image classification reveal a "standard quantum limit" for optical neural networks, set by photodetector shot noise. This bound, which can be as low as 50 zJ/MAC, suggests that performance below the thermodynamic (Landauer) limit for digital irreversible computation is theoretically possible in this device. The proposed accelerator can implement both fully connected and convolutional networks. We also present a scheme for backpropagation and training that can be performed in the same hardware. This architecture will enable a new class of ultralow-energy processors for deep learning.
C1 [Hamerly, Ryan; Bernstein, Liane; Sludds, Alexander; Soljacic, Marin; Englund, Dirk] MIT, Res Lab Elect, 50 Vassar St, Cambridge, MA 02139 USA.
RP Hamerly, R (corresponding author), MIT, Res Lab Elect, 50 Vassar St, Cambridge, MA 02139 USA.
EM rhamerly@mit.edu
CR [Anonymous], 1974, NEW TOOLS PREDICTION
   [Anonymous], ARXIV160605718
   [Anonymous], ARXIV12070580
   Atabaki AH, 2018, NATURE, V556, P349, DOI 10.1038/s41586-018-0028-z
   Bagherian  H., ARXIV180803303
   Brunsma DL, 2016, INSTITUTIONS UNBOUND: SOCIAL WORLDS AND HUMAN RIGHTS, P1
   Canziani A, 2017, IEEE INT SYMP CIRC S, P224
   Cao LY, 2010, NANO LETT, V10, P1229, DOI 10.1021/nl9037278
   CAVES CM, 1981, PHYS REV D, V23, P1693, DOI 10.1103/PhysRevD.23.1693
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chetlur S., ARXIV14100759
   Chung S, 2018, IEEE J SOLID-ST CIRC, V53, P275, DOI 10.1109/JSSC.2017.2757009
   Clements WR, 2016, OPTICA, V3, P1460, DOI 10.1364/OPTICA.3.001460
   Einstein A, 1905, ANN PHYS-BERLIN, V17, P132
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   George S, 2016, IEEE T VLSI SYST, V24, P2253, DOI 10.1109/TVLSI.2015.2504119
   Gibbs H., 2012, OPTICAL BISTABILITY
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Grote H, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.181101
   Haffner C, 2018, NATURE, V556, P483, DOI 10.1038/s41586-018-0031-4
   Hayat MM, 1996, IEEE T NEURAL NETWOR, V7, P700, DOI 10.1109/72.501727
   HOLMSTROM L, 1992, IEEE T NEURAL NETWOR, V3, P24, DOI 10.1109/72.105415
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hu S, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat2355
   Inagaki T, 2016, NAT PHOTONICS, V10, P415, DOI [10.1038/NPHOTON.2016.68, 10.1038/nphoton.2016.68]
   Ishi T, 2005, JPN J APPL PHYS 2, V44, pL364, DOI 10.1143/JJAP.44.L364
   JAEKEL MT, 1990, EUROPHYS LETT, V13, P301, DOI 10.1209/0295-5075/13/4/003
   Ji XC, 2017, OPTICA, V4, P619, DOI 10.1364/OPTICA.4.000619
   Jonsson B., 2011, P INT WORKSH ADC MOD, P1
   Kahn JM, 2017, NAT PHOTONICS, V11, P5, DOI 10.1038/nphoton.2016.256
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kerckhoff J, 2011, OPT EXPRESS, V19, P24468, DOI 10.1364/OE.19.024468
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Koos C, 2016, J LIGHTWAVE TECHNOL, V34, P256, DOI 10.1109/JLT.2015.2499763
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LANDAUER R, 1961, IBM J RES DEV, V5, P183, DOI 10.1147/rd.53.0183
   Larger L, 2012, OPT EXPRESS, V20, P3241, DOI 10.1364/OE.20.003241
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P324, DOI [10.1145/355841.355847, 10.1145/355841.355848]
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Marandi A, 2014, NAT PHOTONICS, V8, P937, DOI [10.1038/nphoton.2014.249, 10.1038/NPHOTON.2014.249]
   McMahon PL, 2016, SCIENCE, V354, P614, DOI 10.1126/science.aah5178
   Michaels A, 2018, OPT EXPRESS, V26, P4766, DOI 10.1364/OE.26.004766
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Miller DAB, 2012, OPT EXPRESS, V20, pA293, DOI 10.1364/OE.20.00A293
   Miller DAB, 2010, NAT PHOTONICS, V4, P3, DOI 10.1038/nphoton.2009.240
   MOORE GE, 1965, ELECTRONICS, V38
   NAGAMATSU M, 1990, IEEE J SOLID-ST CIRC, V25, P494, DOI 10.1109/4.52175
   Nahmias MA, 2013, IEEE J SEL TOP QUANT, V19, DOI 10.1109/JSTQE.2013.2257700
   New N. J., 2017, U.S. Patent, Patent No. [9,594,394, 9594394]
   Notomi M, 2014, OPT COMMUN, V314, P3, DOI 10.1016/j.optcom.2013.09.073
   Nozaki K, 2016, OPTICA, V3, P483, DOI 10.1364/OPTICA.3.000483
   PAEK EG, 1987, OPT ENG, V26, P428, DOI 10.1117/12.7974093
   Paquot Y, 2012, SCI REP-UK, V2, DOI 10.1038/srep00287
   Peng  Y., IMPLEMENTATION ALEXN
   Phare C.T., ARXIV180204624
   PIERCE JR, 1956, P IRE, V44, P601, DOI 10.1109/JRPROC.1956.275123
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Rogalski A, 2012, PROG QUANT ELECTRON, V36, P342, DOI 10.1016/j.pquantelec.2012.07.001
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saeedi S, 2016, J LIGHTWAVE TECHNOL, V34, P2924, DOI 10.1109/JLT.2015.2494060
   Santori C, 2014, PHYS REV APPL, V1, DOI 10.1103/PhysRevApplied.1.054005
   SAVAGE CM, 1988, IEEE J QUANTUM ELECT, V24, P1495, DOI 10.1109/3.7075
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Smith W., 1966, MODERN OPTICAL ENG
   Srinivasan SA, 2016, J LIGHTWAVE TECHNOL, V34, P419, DOI 10.1109/JLT.2015.2478601
   Steinkraus D, 2005, PROC INT CONF DOC, P1115, DOI 10.1109/ICDAR.2005.251
   Sun C, 2015, NATURE, V528, P534, DOI 10.1038/nature16454
   Sun J, 2013, NATURE, V493, P195, DOI 10.1038/nature11727
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Tang L, 2008, NAT PHOTONICS, V2, P226, DOI 10.1038/nphoton.2008.30
   Timurdogan E, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5008
   VANDERLUGT A, 1964, IEEE T INFORM THEORY, V10, P139
   Vandoorne K, 2008, OPT EXPRESS, V16, P11182, DOI 10.1364/OE.16.011182
   Walls DF, 2007, QUANTUM OPTICS
   Wang C, 2018, OPTICA, V5, P1438, DOI 10.1364/OPTICA.5.001438
   YAO HH, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P359, DOI 10.1109/ACSSC.1993.342534
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   2017, PROCEEDINGS OF THE A, P1, DOI DOI 10.1145/3079856.3080246
NR 87
TC 204
Z9 208
U1 20
U2 162
PD MAY 16
PY 2019
VL 9
IS 2
AR 021032
DI 10.1103/PhysRevX.9.021032
WC Physics, Multidisciplinary
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Pinos, M
   Mrazek, V
   Sekanina, L
AF Pinos, Michal
   Mrazek, Vojtech
   Sekanina, Lukas
BE Jenihhin, M
   Kubatova, H
   Metens, N
   Raik, J
   Ahmed, F
   Belohoubek, J
TI Prediction of Inference Energy on CNN Accelerators Supporting
   Approximate Circuits
SO 2023 26TH INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS AND SYSTEMS, DDECS
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 26th International Symposium on Design and Diagnostics of Electronic
   Circuits and Systems (DDECS)
CY MAY 03-05, 2023
CL Tallinn, ESTONIA
ID DESIGN
AB Design methodologies developed for optimizing hardware implementations of convolutional neural networks (CNN) or searching for new hardware-aware neural architectures rely on the fast and reliable estimation of key hardware parameters, such as the energy needed for one inference. Utilizing approximate circuits in hardware accelerators of CNNs faces the designers with new problems during their simulation commonly used tools (TimeLoop, Accelergy, Maestro) do not support approximate arithmetic operations. This work addresses the fast and efficient prediction of consumed energy in hardware accelerators of CNNs that utilize approximate circuits such as approximate multipliers. First, we extend the state-of-the-art software frameworks TimeLoop and Accelergy to predict the inference energy when exact multipliers are replaced with various approximate implementations. The energies obtained using the modified tools are then considered the ground truth (reference) values. Then, we propose and evaluate, using two accelerators (Eyeriss and Simba) and two types of networks (CNNs generated by EvoApproxNAS and standard ResNet CNNs), two predictors of inference energy. We conclude that a simple predictor based on summing the energies needed for all multiplications highly correlates with the reference values if the CNN's architecture is fixed. For complex CNNs with variable architectures typically generated by neural architecture search algorithms, a more sophisticated predictor based on a machine learning model has to be employed. The proposed predictors are 420-533x faster than reference solutions.
C1 [Pinos, Michal; Mrazek, Vojtech; Sekanina, Lukas] Brno Univ Technol, Brno, Czech Republic.
RP Pinos, M (corresponding author), Brno Univ Technol, Brno, Czech Republic.
EM ipinos@fit.vutbr.cz; mrazek@fit.vutbr.cz; sekanina@fit.vutbr.cz
CR Cai H, 2019, INT C LEARNING REPRE
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Fasfous N, 2022, DES AUT TEST EUROPE, P238, DOI 10.23919/DATE54114.2022.9774574
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   Kao SC, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415639
   Lee Jaeseong, 2020, Arxiv, DOI arXiv:2009.02009
   Lin YJ, 2021, DES AUT CON, P1051, DOI 10.1109/DAC18074.2021.9586250
   Lu BQ, 2021, P ACM MEAS ANAL COMP, V5, DOI 10.1145/3491046
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Pinos M, 2022, GENET PROGRAM EVOL M, V23, P351, DOI 10.1007/s10710-022-09441-z
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Sarwar SS, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3097264
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sze V., 2020, EFFICIENT PROCESSING
   Velasco-Montero D, 2020, IEEE INTERNET THINGS, V7, P9227, DOI 10.1109/JIOT.2020.2981684
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
   Zhang LLN, 2020, IEEE COMPUT SOC CONF, P2959, DOI 10.1109/CVPRW50498.2020.00354
   Zhou YQ, 2021, Arxiv, DOI arXiv:2102.08619
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 45
EP 50
DI 10.1109/DDECS57882.2023.10139724
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU De, S
   Huisken, J
   Corporaal, H
AF De, Sayandip
   Huisken, Jos
   Corporaal, Henk
BE Novotny, M
   Konofaos, N
   Skavhaug, A
TI Designing Energy Efficient Approximate Multipliers for Neural
   Acceleration
SO 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018)
DT Proceedings Paper
CT 21st Euromicro Conference on Digital System Design (DSD)
CY AUG 29-31, 2018
CL Prague, CZECH REPUBLIC
DE Approximate Computing; Machine Learning; Neural Networks; Low Power
   Design
AB Many error resilient applications can be approximated using multi-layer perceptrons (MLPs) with insignificant degradation in output quality. Faster and energy efficient execution of such an application is achieved using a neural accelerator (NA). This work exploits the error resilience characteristics of a MLP by approximating the accelerator itself. An error resilience analysis of the MLP is performed to obtain key constraints which are used for designing energy efficient approximate multipliers. A systematic methodology for the design of approximate multipliers is used. A graph based netlist modification approach is considered. Approximate versions of basic standard cells are generated and these are used to replace accurate cells in the synthesized netlist in a systematic quality controlled manner. These approximate multipliers are further used for approximating the multiply and accumulate (MAC) units in the neural accelerator (NA). The results are validated by considering approximate neural replication of a robotic application, inversek2j. System level energy savings of upto 14% is obtained for less than 7% degradation in output quality. Average application speedup of 24% is obtained over accurate neural accelerator (NA). The results are compared with state-of-the-art approximate multipliers and a comparison with truncation (bit-wise scaling) is performed. Moreover, error healing capability of MLPs is shown by studying the impact of retraining on networks with approximate multipliers.
C1 [De, Sayandip; Huisken, Jos; Corporaal, Henk] Eindhoven Univ Technol, Dept Elect Engn, Postbus 513, NL-5600 MB Eindhoven, Netherlands.
RP De, S (corresponding author), Eindhoven Univ Technol, Dept Elect Engn, Postbus 513, NL-5600 MB Eindhoven, Netherlands.
EM sayandip.de@tue.nl; j.a.huisken@tue.nl; h.corporaal@tue.nl
CR [Anonymous], 2016, P INT C COMP AID DES
   Chippa V. K., 2013, P 50 ANN DESIGN AUTO, P1, DOI DOI 10.1145/2463209.2488873
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Gysel P., 2016, ABS160506402 CORR, Vabs /1605.06402
   Jiang H., 2017, ACM J EMERG TECH COM, V13, P1, DOI DOI 10.1145/3094124
   Mack CA, 2011, IEEE T SEMICONDUCT M, V24, P202, DOI 10.1109/TSM.2010.2096437
   Momeni A, 2015, IEEE T COMPUT, V64, P984, DOI 10.1109/TC.2014.2308214
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Mrazek V., 2016, P 35 INT C COMP AID, P1
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Shafique M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2633408
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Tu F., 2018, IEEE T CIRCUITS SYST, V11, P1
   Tu FB, 2015, IEEE INT SYMP CIRC S, P2509, DOI 10.1109/ISCAS.2015.7169195
   Zendegani R, 2017, IEEE T VLSI SYST, V25, P393, DOI 10.1109/TVLSI.2016.2587696
NR 18
TC 5
Z9 5
U1 0
U2 2
PY 2018
BP 288
EP 295
DI 10.1109/DSD.2018.00059
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Weber, L
   Wirth, J
   Sommer, L
   Koch, A
AF Weber, Lukas
   Wirth, Johannes
   Sommer, Lukas
   Koch, Andreas
GP IEEE Comp Soc
TI Exploiting High-Bandwidth Memory for FPGA-Acceleration of Inference on
   Sum-Product Networks
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Sum-Product Network; Probabilistic Models; Machine Learning;
   High-Bandwidth Memory; FPGA
AB Due to the memory wall becoming increasingly problematic in high-performance computing, there is a steady push to improve memory architectures, mainly focusing on better bandwidth as well as latency. One of the results of this push is the development of High-Bandwidth Memory (HBM) which is an alternative to the regular DRAM typically used by accelerator-cards.
   This work adapts an existing accelerator architecture for inference on Sum-Product Networks (SPN) to exploit the HBM present on more recent high-performance FPGA-accelerator cards. The evaluation shows that the use of HBM enables almost linear scaling of the performance due to the embarrassingly parallel nature of batch-wise SPN inference. It is also shown that the only hindrance to this scaling is the limited bandwidth available for data-transfers between host and FPGA. Even with this bottleneck, the prior FPGA-based implementation is outperformed by up to 1.50x (geo.-mean 1.29x). Similarly, the CPU and GPU baselines are outperformed by up to 2.4x (geo.mean 1.6x) and 8.4x (geo.-mean 6.9x) respectively.
   Based on the evaluation, the scaling potential of HBM-based FPGA-accelerators is explored to give an outlook on what is to come with future generations of PCIe-based interfaces.
C1 [Weber, Lukas; Wirth, Johannes; Sommer, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Weber, L (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM weber@esa.tu-darmstadt.de; wirth@esa.tu-darmstadt.de;
   sommer@esa.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR Forencich A, 2020, ANN IEEE SYM FIELD P, P38, DOI 10.1109/FCCM48280.2020.00015
   Guo K., 2017, SURVEY FPGA BASED NE
   Hartmann M., 2021, 2021 IEEEACM INT WOR
   Hilprecht B, 2019, Arxiv, DOI arXiv:1909.00607
   Jaiswal MK, 2019, IEEE ACCESS, V7, P74586, DOI 10.1109/ACCESS.2019.2920936
   Kara K, 2020, I C FIELD PROG LOGIC, P1, DOI 10.1109/FPL50879.2020.00013
   Korinth Jens, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P214, DOI 10.1007/978-3-030-17227-5_16
   Lu A., 2021, DEMYSTIFYING MEMORY
   Molina A., 2019, SPFLOW EASY EXTENSIB
   Molina A, 2018, AAAI CONF ARTIF INTE, P3828
   Ober M., 2019, WORKSHOP HETEROGENEO
   Peharz R., 2018, ARXIV180601910
   Poon H, 2011, 2011 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCV WORKSHOPS)
   Shah N, 2020, DES AUT TEST EUROPE, P322, DOI 10.23919/DATE48585.2020.9116326
   Sommer L., 2022, 2022 IEEE ACM INT S, P1
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Weber L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P251, DOI 10.1109/ICFPT47387.2019.00040
NR 18
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 112
EP 119
DI 10.1109/IPDPSW55747.2022.00028
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Krasilenko, VG
   Lazarev, AA
   Nikitovich, DV
AF Krasilenko, Vladimir G.
   Lazarev, Alexander A.
   Nikitovich, Diana V.
BE Sciamanna, M
   Bienstman, P
TI Design and simulation of optoelectronic neuron-equivalentors as hardware
   accelerators of self-learning equivalent-convolutional neural structures
   (SLECNS)
SO NEURO-INSPIRED PHOTONIC COMPUTING
SE Proceedings of SPIE
DT Proceedings Paper
CT Conference on Neuro-Inspired Photonic Computing
CY APR 23, 2018
CL Strasbourg, FRANCE
DE self-learning equivalent-convolutional neural structures; optoelectronic
   neuron-equivalentor; current mirror; equivalent models;
   continuous-logical operations; 2D spatial function; accelerator;
   teaming; nonlinear processing
ID RECOGNITION ALGORITHMS; MODELS; DEVICES
AB In the paper, we consider the urgent need to create highly efficient hardware accelerators for machine learning algorithms, including convolutional and deep neural networks (CNN and DNNS), for associative memory models, clustering, and pattern recognition. These algorithms usually include a large number of multiply-accumulate (and the like) operations. We show a brief overview of our related works the advantages of the equivalent models (EM) for describing and designing neural networks and recognizing bio-inspired systems. The capacity of NN on the basis of EM and of its modifications, including auto-and hetero-associative memories for 2D images, is in several times quantity of neurons. Such neuroparadigms are very perspective for processing, clustering. recognition, storing large size and strongly correlated and highly noised images. They are also very promising for solving the problem of creating machine uncontrolled learning. And since the basic operational functional nodes of EM are such vector-matrix or matrix-tensor procedures with continuous-logical operations as: normalized vector operations "equivalence", "nonequivalence", "auto equivalence". "auto-nonequivalence", we consider in this paper new conceptual approaches to the design of full-scale arrays of such neuron-equivalentors (NEs) with extended functionality, including different activation functions. Our approach is based on the use of analog and mixed (with special coding) methods for implementing the required operations, building NEs (with number of synapsis from 8 up to 128 and more) and their base cells, nodes based on photosensitive elements and CMOS current mirrors. We show the results of modeling the proposed new modular scalable implementations of NEs, we estimates and compare them. Simulation results show that processing time in such circuits does not exceed units of micro seconds, and for some variants 50-100 nanoseconds. Circuits are simple, have low supply voltage (1.5 - 3.3 V), low power consumption (milliwatts), low levels of input signals (microwatts), integrated construction, satisfy the problem of interconnections and cascading. Signals at the output of such neurons can be both digital and analog, or hybrid, and also with two complement outputs. They realize principle of dualism which gives a number of advantages of such complement dual NEs.
C1 [Krasilenko, Vladimir G.] Vinnytsia Social Econ Inst, 86-131 Kelestskaya Str, UA-21021 Vinnytsia, Ukraine.
   [Lazarev, Alexander A.; Nikitovich, Diana V.] Vinnytsia Natl Tech Univ, Vinnytsia, Ukraine.
RP Krasilenko, VG (corresponding author), Vinnytsia Social Econ Inst, 86-131 Kelestskaya Str, UA-21021 Vinnytsia, Ukraine.
EM krasvg@i.ua
CR Krasilenko V, 1997, P SOC PHOTO-OPT INS, V3055, P137, DOI 10.1117/12.267700
   Krasilenko V. G., 2010, Optical Memory & Neural Networks (Information Optics), V19, P31, DOI 10.3103/S1060992X10010054
   Krasilenko Vladimir G., 2005, Proceedings of the SPIE - The International Society for Optical Engineering, V5948, p59481G, DOI 10.1117/12.623365
   Krasilenko V. G, 2010, SCI SESS MIFI 2010, V2, P83
   Krasilenko V. G., 2014, VISNYK KHMELJNYCJKOG, V2, P165
   Krasilenko V.G., 2015, 7 UKR POL SCI PRACT, P129
   Krasilenko V.G, 2014, PYTANNJA PRYKLADNOJI, P167
   Krasilenko V.G., 2017, P SOC PHOTO-OPT INS
   Krasilenko V.G, P SPIE, V7703
   Krasilenko V. G., 2004, P SPIE, V5439
   Krasilenko V. G., 2014, SYSTEMY OBROBKY INFO, V4, P113
   Krasilenko V. G., 2009, P SCI C VSEI ENTR U, P68
   Krasilenko V. G., 2009, P SPIE, V7343
   Krasilenko V.G., 2002, RADIOELEKTRONIKA INF, P45
   Krasilenko V. G., 2012, P 11 ALL UKR INT C, P107
   Krasilenko V.G., 2001, P 8 STC MEAS COMP DE, P325
   Krasilenko VG, 2004, P SOC PHOTO-OPT INS, V5421, P183, DOI 10.1117/12.543000
   Krasilenko VG, 2002, P SOC PHOTO-OPT INS, V4731, P154, DOI 10.1117/12.458380
   Krasilenko VG, 1997, P SOC PHOTO-OPT INS, V3317, P211, DOI 10.1117/12.295685
   Krasilenko VG, 2001, P SOC PHOTO-OPT INS, V4387, P247, DOI 10.1117/12.421146
   Krasilenko VG, 1998, P SOC PHOTO-OPT INS, V3402, P398, DOI 10.1117/12.304973
   KRASILENKO VG, 2012, P SOC PHOTO-OPT INS, V8398
   Krasilenko VG, 2017, PROC SPIE, V10609, DOI 10.1117/12.2285797
   Krasilenko VG, 2015, PROC SPIE, V9450, DOI 10.1117/12.2073893
   Krasilenko VG, 2014, PROC SPIE, V9286, DOI 10.1117/12.2066068
   Krasilenko VG, 2013, PROC SPIE, V8662, DOI 10.1117/12.2003169
   Krasilenko VG, 2012, PROC SPIE, V8559, DOI 10.1117/12.2001103
   Krasilenko VG, 2011, PROC SPIE, V8001, DOI 10.1117/12.894483
   Krasilenko VG, 2011, PROC SPIE, V8055, DOI 10.1117/12.883669
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Q. V., 2011, 2011 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P3361, DOI 10.1109/CVPR.2011.5995496
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, HDB BRAIN THEORY NEU
   Rudenko OG, 2005, ARTIFICIAL NEURAL NE
   Schlottmann CR, 2011, IEEE J EM SEL TOP C, V1, P403, DOI 10.1109/JETCAS.2011.2165755
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Taylor GW, 2010, LECT NOTES COMPUT SC, V6316, P140, DOI 10.1007/978-3-642-15567-3_11
   Veacheslav Perju, 2012, P SOC PHOTO-OPT INS, V8398
   Zang D, 2015, J ELECTRON IMAGING, V24, DOI 10.1117/1.JEI.24.3.033001
NR 39
TC 1
Z9 1
U1 0
U2 3
PY 2018
VL 10689
AR UNSP 106890C
DI 10.1117/12.2316352
WC Optics
DA 2023-11-11
ER

PT C
AU Du, ZD
   Palem, K
   Lingamneni, A
   Temam, O
   Chen, YJ
   Wu, CY
AF Du, Zidong
   Palem, Krishna
   Lingamneni, Avinash
   Temam, Olivier
   Chen, Yunji
   Wu, Chengyong
GP IEEE
TI Leveraging the Error Resilience of Machine-Learning Applications for
   Designing Highly Energy Efficient Accelerators
SO 2014 19TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 19th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 20-23, 2014
CL Suntec, SINGAPORE
AB In recent years, inexact computing has been increasingly regarded as one of the most promising approaches for reducing energy consumption in many applications that can tolerate a degree of inaccuracy. Driven by the principle of trading tolerable amounts of application accuracy in return for significant resource savings-the energy consumed, the (critical path) delay and the (silicon) area being the resources-this approach has been limited to certain application domains. In this paper, we propose to expand the application scope, error tolerance as well as the energy savings of inexact computing systems through neural network architectures. Such neural networks are fast emerging as popular candidate accelerators for future heterogeneous multi-core platforms, and have flexible error tolerance limits owing to their ability to be trained. Our results based on simulated 65nm technology designs demonstrate that the proposed inexact neural network accelerator could achieve 43.91%-62.49% savings in energy consumption (with corresponding delay and area savings being 18.79% and 31.44% respectively) when compared to existing baseline neural network implementation, at the cost of an accuracy loss (quantified as the Mean Square Error (MSE) which increases from 0.14 to 0.20 on average).
C1 [Du, Zidong; Chen, Yunji; Wu, Chengyong] Chinese Acad Sci, ICT, CARCH, Beijing, Peoples R China.
   [Palem, Krishna; Lingamneni, Avinash] Rice Univ, Houston, TX 77251 USA.
   [Temam, Olivier] INRIA, Valbonne, France.
RP Du, ZD (corresponding author), Chinese Acad Sci, ICT, CARCH, Beijing, Peoples R China.
EM duzidong@ict.ac.cn; palem@rice.edu; avinash.l@rice.edu;
   olivier.temam@inria.fr; cyj@ict.ac.cn; cwu@ict.ac.cn
CR [Anonymous], 2003, P 2003 INT C COMPILE, DOI DOI 10.1145/951710.951712
   [Anonymous], 2008, INT C PAR ARCH COMP
   [Anonymous], INT S WORKL CHAR
   [Anonymous], P 21 INT WORKSH POW
   [Anonymous], EE TIM DES ARM VIRT
   [Anonymous], 2005, TECHNOLOGY INTEL MAG
   [Anonymous], ACM T EMBED COMPUT S
   [Anonymous], 1997, P 31 AS C SIGN SYST
   [Anonymous], INT S COMP ARCH PORT
   Asuncion A., 2007, UCI MACHINE LEARNING
   Bengio, 2007, ICML, P473
   Esmaeilzadeh H., 2012, INT S MICR
   Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301
   George J, 2006, CASES 06 P 2006 INT, P158, DOI 10.1145/1176760.1176781
   HAYKIN S., 1999, NEURAL NETWORK COMPR
   Kedem Z, 2010, PROCEEDINGS OF THE 2010 INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURES AND SYNTHESIS FOR EMBEDDED SYSTEMS (CASES '10), P177, DOI 10.1145/1878921.1878948
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lingamneni A, 2013, 50TH DESIGN AUTOMATI, P20, DOI [10.1145/2463209.2488759, DOI 10.1145/2463209.2488759]
   Lingamneni A, 2011, DES AUT TEST EUROPE, P764
   Mahdiani H. R., 2010, IEEE Transactions on Circuits and Systems I: Regular Papers, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Merolla P, 2011, IEEE CUST INTEGR CIR
   Palem K, 2012, DES AUT CON, P924
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Stojilovic M, 2012, DES AUT TEST EUROPE, P1543
   Venkatesh G, 2010, ACM SIGPLAN NOTICES, V45, P205, DOI 10.1145/1735971.1736044
NR 25
TC 67
Z9 69
U1 1
U2 8
PY 2014
BP 201
EP 206
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Sadredini, E
   Rahimi, R
   Verma, V
   Stan, M
   Skadron, K
AF Sadredini, Elaheh
   Rahimi, Reza
   Verma, Vaibhav
   Stan, Mircea
   Skadron, Kevin
GP Assoc Comp Machinery
TI eAP: A Scalable and Efficient In-Memory Accelerator for Automata
   Processing
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE processing-in-memory; embedded DRAM; automata processing; reconfigurable
   computing; interconnect
AB Accelerating finite automata processing benefits regular-expression workloads and a wide range of other applications that do not map obviously to regular expressions, including pattern mining, bioinformatics, and machine learning. Existing in-memory automata processing accelerators suffer from inefficient routing architectures. They are either incapable of efficiently place-and-route a highly connected automaton or require an excessive amount of hardware resources.
   In this paper, first, we propose a compact, low-overhead, and yet flexible interconnect architecture that efficiently implements routing for next-state activation, and can be applied to the existing in-memory automata processing architectures. Then, we present eAP (embedded Automata Processor), a high-throughput and scalable in-memory automata processing accelerator. Performance benefits of eAP are achieved by (1) exploiting subarray-level parallelism in memory, (2) a compact memory-based interconnect architecture, (3) an optimal pipeline for state matching and state transition, and (4) efficiently mapping to appropriate memory technologies.
   Overall, eAP achieves 5.1x and 207x better throughput per unit area compared to Cache Automaton and Micron's Automata Processor, respectively, as well as lower power consumption and better scaling.
C1 [Sadredini, Elaheh; Rahimi, Reza; Verma, Vaibhav; Stan, Mircea; Skadron, Kevin] Univ Virginia, Charlottesville, VA 22903 USA.
RP Sadredini, E (corresponding author), Univ Virginia, Charlottesville, VA 22903 USA.
EM elaheh@virginia.edu; rahimi@virginia.edu; vv8dn@virginia.edu;
   mircea@virginia.edu; skadron@virginia.edu
CR Agrawal A., 2018, ARXIV180700343
   Amat E, 2016, IEEE T COMPUT, V65, P1068, DOI 10.1109/TC.2014.2375204
   [Anonymous], 2012, PROC IEEE 27 CONV EL
   [Anonymous], 2017, 2017 IEEE 86 VEH TEC
   [Anonymous], 1961, RUSSIAN MATH SURVEYS
   [Anonymous], 2019, IEEE COMPUTER ARCHIT
   [Anonymous], THESIS
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Bhoj AN, 2009, PR IEEE COMP DESIGN, P390, DOI 10.1109/ICCD.2009.5413127
   Bo CK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P311, DOI 10.1109/BigData.2016.7840617
   Bo Chunkun, 2018, 24 IEEE INT S HIGH P
   Chang L, 2005, 2005 Symposium on VLSI Technology, Digest of Technical Papers, P128
   Chun KC, 2012, IEEE J SOLID-ST CIRC, V47, P547, DOI 10.1109/JSSC.2011.2168729
   Chun KC, 2011, IEEE J SOLID-ST CIRC, V46, P1495, DOI 10.1109/JSSC.2011.2128150
   Computer Sciences Corporation, 2012, BIG DAT UN BEG EXPL
   Dlugosch Paul, 2014, PARALLEL DISTRIBUTED, V25, P12
   DNV GL, 2016, AR YOU ABL LEV BIG D
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Fu Y., 2016, LECT NOTES COMPUT SC, P200, DOI DOI 10.1007/978-3-319-41321-1_11
   Gogte, 2016, MICR MICRO 2016 49 A, P1, DOI DOI 10.1109/MICRO.2016.7783747
   Gwennap L., 2014, NEW CHIP SPEEDS NFA
   Hammarlund P, 2014, IEEE MICRO, V34, P6, DOI 10.1109/MM.2014.10
   Hamzaoglu Fatih, 2014, SOL STAT CIRC ISSCCC
   HLSWang Michael, 2016, NUCL INSTRUMENTS M A, V832, P219
   Jaksic Z, 2012, PR IEEE COMP DESIGN, P309, DOI 10.1109/ICCD.2012.6378657
   Jaksic Zoran, 2015, THESIS
   Ki Chul Chun, 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P506, DOI 10.1109/ISSCC.2011.5746418
   Kim Y, 2012, CONF PROC INT SYMP C, P368
   Lenjani M, 2014, IET COMPUT DIGIT TEC, V8, P30, DOI 10.1049/iet-cdt.2011.0066
   Liu C, 2013, IEEE T COMPUT, V62, P310, DOI 10.1109/TC.2011.231
   Liu Hongyuan, 2018, 2018 51 ANN IEEE ACM
   Liu Rui, 2018, P 55 ANN DES AUT C, V21
   Meinerzhagen Pascal, 2013, Journal of Low Power Electronics and Applications, V3, P54, DOI 10.3390/jlpea3020054
   ReemKaraki, 2017, P INT C REC COMP FPG, P1
   Roy Indranil, 2014, 2014 IEEE International Parallel & Distributed Processing Symposium (IPDPS), P415, DOI 10.1109/IPDPS.2014.51
   Sadredini E., 2017, INT C SUP ICS
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Subramaniyan A., 2017, P 50 ANN IEEE ACM IN
   Tandon P, 2016, PROC INT CONF DATA, P469, DOI 10.1109/ICDE.2016.7498263
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wadden J, 2016, I S WORKL CHAR PROC, P105, DOI 10.1109/IISWC.2016.7581271
   Wang K, 2016, CELL MOL BIOENG, V9, P1, DOI 10.1007/s12195-015-0417-4
   Wang Ke, INT J PARALLEL PROGR
   Wang Ke, 2016, ACM INT C COMP FRONT
   Zhang W, 2013, IEEE T CIRCUITS-I, V60, P2030, DOI 10.1109/TCSI.2013.2252652
   Zhou K, 2015, IEEE INT C SEMANT CO, P236, DOI 10.1109/ICOSC.2015.7050812
NR 47
TC 16
Z9 16
U1 0
U2 2
PY 2019
BP 87
EP 99
DI 10.1145/3352460.3358324
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Jia, LC
   Luo, ZZ
   Lu, LQ
   Liang, Y
AF Jia, Liancheng
   Luo, Zizhang
   Lu, Liqiang
   Liang, Yun
TI Automatic Generation of Spatial Accelerator for Tensor Algebra
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Hardware; Tensors; System-on-chip; Algebra; Computer architecture;
   Convolution; Codes; Accelerator architectures; linear algebra; Index
   Terms; parallel architectures; programmable logic arrays
ID LANGUAGE; COMPILER; HARDWARE
AB Tensor algebra finds applications in various domains, including machine learning applications, data analytics, and others. Spatial hardware accelerators are widely used to boost the performance of tensor algebra applications. It has a complex hardware architecture and rich design space. Prior approaches based on manual implementation lead to low programming productivity, making it hard to explore the large design space. In this article, we propose Tensorlib, a framework for generating spatial hardware accelerators for tensor algebra applications. Tensorlib is motivated by the observation that, tensor dataflows can be expressed with linear transformations, and they share common hardware modules which can be reused across different designs. Tensorlib first uses space-time transformation to explore different dataflows, which can compactly represent the hardware dataflow using a transformation matrix. Next, we identify the common structures of different dataflows and build parameterized hardware module templates. Our generation framework can select the needed hardware modules for each dataflow, connect the modules using a specified interconnection pattern, and automatically generate the complete hardware accelerator design. Tensorlib remarkably improves the productivity for the development and optimization of spatial hardware architecture, providing a rich design space with tradeoffs in performance, area, and power. Experiments show that Tensorlib can automatically generate hardware designs with different dataflows for a variety of tensor algebra programs. Tensorlib can achieve 318-MHz frequency and 786-GFLOP/s throughput for matrix multiplication kernel on Xilinx VU9P FPGA, which outperforms the state-of-the-art generators.
C1 [Jia, Liancheng; Luo, Zizhang; Liang, Yun] Peking Univ, Ctr Energy Efficient Comp & Applicat, Beijing 100871, Peoples R China.
   [Lu, Liqiang] Zhejiang Univ, Coll Comp Sci & Technol, Hangzhou 310027, Peoples R China.
RP Liang, Y (corresponding author), Peking Univ, Ctr Energy Efficient Comp & Applicat, Beijing 100871, Peoples R China.
EM jlc@pku.edu.cn; semiwaker@pku.edu.cn; liqianglu@zju.edu.cn;
   ericlyun@pku.edu.cn
CR [Anonymous], 2019, NVDLA DEEP LEARN ACC
   Bachrach J, 2012, DES AUT CON, P1212
   Baltus D. G., 1993, Proceedings. International Conference on Application-Specific Array Processors (Cat. No.93TH0572-8), P428, DOI 10.1109/ASAP.1993.397164
   Banerjee S., 2014, LINEAR ALGEBRA MATRI, V181
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cong J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240838
   Dave S, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358198
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Fortes J., 1988, COMPUTER ARCHITECTUR
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Genc H, 2021, Arxiv, DOI arXiv:1911.09925
   Guo LC, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218718
   Jia LC, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P67, DOI 10.1145/3489517.3530411
   Jia LC, 2021, DES AUT CON, P865, DOI 10.1109/DAC18074.2021.9586329
   Jia LC, 2020, IEEE MICRO, V40, P85, DOI 10.1109/MM.2020.2997611
   Jiang SN, 2020, IEEE MICRO, V40, P58, DOI 10.1109/MM.2020.2997638
   Jie Wang, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P93, DOI 10.1145/3431920.3439292
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Lai YH, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415644
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Le Verge H., 1991, Journal of VLSI Signal Processing, V3, P173, DOI 10.1007/BF00925828
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Liang Y, 2022, IEEE T COMPUT AID D, V41, P2546, DOI 10.1109/TCAD.2021.3108065
   Liang Y, 2021, IEEE T COMPUT AID D, V40, P1648, DOI 10.1109/TCAD.2020.3023903
   Licheng Guo, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P81, DOI 10.1145/3431920.3439289
   Licht JD, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P244, DOI 10.1145/3373087.3375296
   Lu LQ, 2022, IEEE T COMPUT AID D, V41, P4733, DOI 10.1109/TCAD.2021.3135322
   Lu LQ, 2021, CONF PROC INT SYMP C, P720, DOI 10.1109/ISCA52012.2021.00062
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Membarth R, 2016, IEEE T PARALL DISTR, V27, P210, DOI 10.1109/TPDS.2015.2394802
   MIRANKER WL, 1984, COMPUTING, V32, P93, DOI 10.1007/BF02253685
   Moreau T, 2019, Arxiv, DOI arXiv:1807.04188
   Moss DJM, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P107, DOI 10.1145/3174243.3174258
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Rong H., 2017, ARXIV
   Samajdar Ananda, 2018, ARXIV
   Sharma H, 2016, INT SYMP MICROARCH
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Weng J, 2020, ANN I S COM, P268, DOI 10.1109/ISCA45697.2020.00032
   Xiao Q., 2020, P DAC, P1
   Xiao QC, 2021, CONF PROC INT SYMP C, P1055, DOI 10.1109/ISCA52012.2021.00086
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zheng SZ, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P859, DOI 10.1145/3373376.3378508
NR 58
TC 0
Z9 0
U1 2
U2 2
PD JUN
PY 2023
VL 42
IS 6
BP 1898
EP 1911
DI 10.1109/TCAD.2022.3209949
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Huang, SZ
   Tang, EH
   Li, S
   Ping, XZ
   Chen, RQ
AF Huang, Shizhen
   Tang, Enhao
   Li, Shun
   Ping, Xiangzhan
   Chen, Ruiqi
TI Hardware-friendly compression and hardware acceleration for transformer:
   A survey
SO ELECTRONIC RESEARCH ARCHIVE
DT Review
DE transformer; hardware accelerators; self-attention; compression; FPGA
ID MODEL COMPRESSION; NEURAL-NETWORKS
AB The transformer model has recently been a milestone in artificial intelligence. The algorithm has enhanced the performance of tasks such as Machine Translation and Computer Vision to a level previously unattainable. However, the transformer model has a strong performance but also requires a high amount of memory overhead and enormous computing power. This significantly hinders the deployment of an energy-efficient transformer system. Due to the high parallelism, low latency, and low power consumption of field-programmable gate arrays (FPGAs) and application specific integrated circuits (ASICs), they demonstrate higher energy efficiency than Graphics Processing Units (GPUs) and Central Processing Units (CPUs). Therefore, FPGA and ASIC are widely used to accelerate deep learning algorithms. Several papers have addressed the issue of deploying the Transformer on dedicated hardware for acceleration, but there is a lack of comprehensive studies in this area. Therefore, we summarize the transformer model compression algorithm based on the hardware accelerator and its implementation to provide a comprehensive overview of this research domain. This paper first introduces the transformer model framework and computation process. Secondly, a discussion of hardware-friendly compression algorithms based on self-attention and Transformer is provided, along with a review of a state-of-the-art hardware accelerator framework. Finally, we considered some promising topics in transformer hardware acceleration, such as a high-level design framework and selecting the optimum device using reinforcement learning.
C1 [Huang, Shizhen; Tang, Enhao; Li, Shun] Fuzhou Univ, Coll Phys & Informat Engn, Fuzhou 350116, Peoples R China.
   [Ping, Xiangzhan] Chongqing Univ Posts & Telecommun, Dept Optoelect Informat Engn, Chongqing 400065, Peoples R China.
   [Chen, Ruiqi] Fudan Univ, Zhangjiang Fudan Int Innovat Ctr, Shanghai 200433, Peoples R China.
RP Chen, RQ (corresponding author), Fudan Univ, Zhangjiang Fudan Int Innovat Ctr, Shanghai 200433, Peoples R China.
EM ruiqichen@ieee.org
CR Gordon MA, 2020, Arxiv, DOI arXiv:2002.08307
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Bai HL, 2021, Arxiv, DOI [arXiv:2012.15701, 10.48550/arXiv.2012.15701]
   Barrett R., 1994, SOC IND APPL MATH, DOI [10.1137/1.9781611971538, DOI 10.1137/1.9781611971538]
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Charikar M. S., 2002, P 34 ANN ACM S THEOR, P380
   Chen MH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P12250, DOI 10.1109/ICCV48922.2021.01205
   Chen T., 2021, ADV NEURAL INF PROCE, V34, P19974, DOI DOI 10.48550/ARXIV.2106.04533
   Chen Tianlong, 2020, ADV NEURAL INFORM PR, V33, P15834
   Cheng SB, 2022, J COMPUT PHYS, V464, DOI 10.1016/j.jcp.2022.111302
   Cheng SB, 2021, J COMPUT SCI-NETH, V53, DOI 10.1016/j.jocs.2021.101405
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chowdhury SA, 2020, P 5 ARABIC NATURAL L, P226
   Chung JY, 2014, Arxiv, DOI [arXiv:1412.3555, DOI 10.48550/ARXIV.1412.3555]
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Ding CW, 2018, PR GR LAK SYMP VLSI, P353, DOI 10.1145/3194554.3194625
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Ganesh P, 2021, T ASSOC COMPUT LING, V9, P1061, DOI 10.1162/tacl_a_00413
   Gong YC, 2013, PROC CVPR IEEE, P484, DOI 10.1109/CVPR.2013.69
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Ham TJ, 2021, CONF PROC INT SYMP C, P692, DOI 10.1109/ISCA52012.2021.00060
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   He HT, 2019, IEEE WIREL COMMUN, V26, P77, DOI 10.1109/MWC.2019.1800447
   Hou L, 2020, Arxiv, DOI arXiv:2004.04037
   Hu R., 2018, 2018 IEEE 23 INT C D, P1
   Hu ZX, 2020, IEEE T IND ELECTRON, V67, P3216, DOI 10.1109/TIE.2019.2912763
   Jiang W., 2019, P 2019 ACM SIGDA INT, P305, DOI DOI 10.1145/3289602
   Jiang Weiwen, 2020, Arxiv, DOI arXiv:1907.08985
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jiao XQ, 2020, Arxiv, DOI arXiv:1909.10351
   Kannan R, 2013, INT C HIGH PERFORM, P286, DOI 10.1109/HiPC.2013.6799135
   Li B., 2020, P ACMIEEE INT S LOW, P175
   Li BB, 2020, Arxiv, DOI arXiv:2009.08065
   Lin ZH, 2017, Arxiv, DOI [arXiv:1703.03130, DOI 10.48550/ARXIV.1703.03130]
   Liu SC, 2021, IEEE T MOBILE COMPUT, V20, P3282, DOI 10.1109/TMC.2020.2999956
   Liu SC, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P389, DOI 10.1145/3210240.3210337
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Liu Y, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P5070
   Liu ZJ, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P513, DOI 10.23919/DATE51398.2021.9474043
   Liu ZH, 2021, Arxiv, DOI arXiv:2106.14156
   Liu ZY, 2022, IEEE T WIREL COMMUN, V21, P1214, DOI 10.1109/TWC.2021.3103120
   Lu SY, 2020, IEEE INT SOC CONF, P84, DOI 10.1109/SOCC49529.2020.9524802
   Ma XL, 2020, AAAI CONF ARTIF INTE, V34, P5117
   Ma XD, 2019, Arxiv, DOI arXiv:1906.09777
   Michel Paul, 2019, ARXIV
   Narang Sharan, 2017, Arxiv, DOI arXiv:1711.02782
   Ozfatura E, 2022, Arxiv, DOI arXiv:2206.09457
   Pan V., 2001, STRUCTURED MATRICES, DOI 10.1007/978-1-4612-0129-8
   Parikh A. P., 2016, P 2016 C EMPIRICAL M, P2249, DOI [DOI 10.18653/V1/D16-1244, 10.18653/v1/D16-1244]
   Peng HW, 2021, INT SYM QUAL ELECT, P142, DOI 10.1109/ISQED51717.2021.9424344
   Qi P., 2021, GREAT LAK S VLSI, P163
   Qi PJ, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643586
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sanh V, 2020, Arxiv, DOI [arXiv:1910.01108, DOI 10.48550/ARXIV.1910.01108]
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shen S, 2019, Arxiv, DOI arXiv:1909.05840
   Shi P, 2019, Arxiv, DOI [arXiv:1904.05255, DOI 10.48550/ARXIV.1904.05255]
   Smith JO., 2007, MATH DISCRETE FOURIE
   So DR, 2019, PR MACH LEARN RES, V97
   Sun MS, 2022, Arxiv, DOI arXiv:2201.06618
   Sun S, 2019, ARXIV
   Touvron H, 2021, PR MACH LEARN RES, V139, P7358
   Tran VL, 2020, THIN WALL STRUCT, V152, DOI 10.1016/j.tws.2020.106744
   Wang H., 2020, THESIS
   Wang MQ, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P223, DOI 10.1109/APCCAS.2018.8605654
   Wang Q, 2019, Arxiv, DOI [arXiv:1906.01787, DOI 10.48550/ARXIV.1906.01787]
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wang WH, 2020, Arxiv, DOI arXiv:2002.10957
   Wen W, 2016, Arxiv, DOI arXiv:1608.03665
   Wu ZH, 2020, Arxiv, DOI arXiv:2004.11886
   Xu H, 2019, Arxiv, DOI arXiv:1904.02232
   Yang SS, 2022, IEEE T PARALL DISTR, V33, P4039, DOI 10.1109/TPDS.2022.3177782
   Zafrir Ofir, 2019, 2019 Fifth Workshop on Energy Efficient Machine Learning and Cognitive Computing - NeurIPS Edition (EMC2-NIPS), P36, DOI 10.1109/EMC2-NIPS53020.2019.00016
   Zechun Liu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12359), P143, DOI 10.1007/978-3-030-58568-6_9
   Zhang XY, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3477002
   Zhang X, 2015, IEEE I CONF COMP VIS, P2929, DOI 10.1109/ICCV.2015.335
   Zhao L, 2017, PR MACH LEARN RES, V70
NR 79
TC 0
Z9 0
U1 20
U2 54
PY 2022
VL 30
IS 10
BP 3755
EP 3785
DI 10.3934/era.2022192
WC Mathematics
DA 2023-11-11
ER

PT J
AU Qian, YH
   Liang, JY
   Pedrycz, W
   Dang, CY
AF Qian, Yuhua
   Liang, Jiye
   Pedrycz, Witold
   Dang, Chuangyin
TI An efficient accelerator for attribute reduction from incomplete data in
   rough set framework
SO PATTERN RECOGNITION
DT Article
DE Feature selection; Rough set theory; Incomplete information systems;
   Positive approximation; Granular computing
ID FEATURE-SELECTION; KNOWLEDGE REDUCTION; INFORMATION; GRANULATION;
   ENTROPY; DIMENSIONALITY; UNCERTAINTY; SYSTEMS
AB Feature selection (attribute reduction) from large-scale incomplete data is a challenging problem in areas such as pattern recognition, machine learning and data mining. In rough set theory, feature selection from incomplete data aims to retain the discriminatory power of original features. To address this issue, many feature selection algorithms have been proposed, however, these algorithms are often computationally time-consuming. To overcome this shortcoming, we introduce in this paper a theoretic framework based on rough set theory, which is called positive approximation and can be used to accelerate a heuristic process for feature selection from incomplete data. As an application of the proposed accelerator, a general feature selection algorithm is designed. By integrating the accelerator into a heuristic algorithm, we obtain several modified representative heuristic feature selection algorithms in rough set theory. Experiments show that these modified algorithms outperform their original counterparts. It is worth noting that the performance of the modified algorithms becomes more visible when dealing with larger data sets. (C) 2011 Elsevier Ltd. All rights reserved.
C1 [Qian, Yuhua; Liang, Jiye] Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.
   [Qian, Yuhua; Dang, Chuangyin] City Univ Hong Kong, Dept Mfg Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
RP Liang, JY (corresponding author), Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.
EM jinchengqyh@126.com; ljy@sxu.edu.cn; pedrycz@ee.ualberta.ca;
   mecdang@cityu.edu.hk
CR Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P1632, DOI 10.1016/j.patrec.2005.01.006
   Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044
   Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086
   Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/j.patrec.2005.09.004
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   [黄兵 Huang Bing], 2005, [系统工程理论与实践, Systems Engineering-Theory & Practice], V25, P55
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kryszkiewicz M, 1998, INFORM SCIENCES, V112, P39, DOI 10.1016/S0020-0255(98)10019-1
   Kwak N, 2002, IEEE T NEURAL NETWOR, V13, P143, DOI 10.1109/72.977291
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Leung Y, 2003, INFORM SCIENCES, V153, P85, DOI 10.1016/S0020-0255(03)00061-6
   Li DY, 2004, INT J UNCERTAIN FUZZ, V12, P651, DOI 10.1142/S0218488504003132
   Liang J, 2006, INT J GEN SYST, V35, P641, DOI 10.1080/03081070600687668
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X
   Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642, DOI 10.1109/69.617056
   [米据生 Mi Jusheng], 2003, [模糊系统与数学, Fuzzy Systems and Mathematics], V17, P54
   MODRZEJEWSKI M, 1993, EUR C MACH LEARN, P213
   Pavlenko T, 2003, J STAT PLAN INFER, V115, P565, DOI 10.1016/S0378-3758(02)00166-0
   Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9
   Qian YH, 2008, COMPUT MATH APPL, V56, P1994, DOI 10.1016/j.camwa.2008.04.021
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2009, PROCEEDINGS OF 2009 INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND CYBERNETICS, VOLS 1-6, P350, DOI 10.1109/ICMLC.2009.5212472
   Qian YH, 2010, IEEE T SYST MAN CY A, V40, P420, DOI 10.1109/TSMCA.2009.2035436
   Qian YH, 2009, INT J UNCERTAIN FUZZ, V17, P855, DOI 10.1142/S0218488509006303
   Qian YH, 2009, INT J APPROX REASON, V50, P174, DOI 10.1016/j.ijar.2008.08.004
   Shao MW, 2005, INT J INTELL SYST, V20, P13, DOI 10.1002/int.20051
   Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016
   SKOWRON A, 1995, COMPUT INTELL, V11, P371, DOI 10.1111/j.1467-8640.1995.tb00039.x
   Slezak D, 2002, FUND INFORM, V53, P365
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GY, 2005, FUND INFORM, V68, P289
   WU SX, 2004, J SYSTEM SCI INFORM, V2, P557
   Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002
   YANG CS, 2006, COMPUTER TECHNOLOGY, V16, P72
   YANG CS, 2006, COMPUT TECHNOL DEV, V16, P68
   Yu J, 2005, IEEE T PATTERN ANAL, V27, P1197, DOI 10.1109/TPAMI.2005.160
   Zhou ZH, 2003, ARTIF INTELL, V143, P139, DOI 10.1016/S0004-3702(02)00357-0
   ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2
NR 46
TC 153
Z9 170
U1 1
U2 45
PD AUG
PY 2011
VL 44
IS 8
BP 1658
EP 1670
DI 10.1016/j.patcog.2011.02.020
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Carmichael, Z
   Langroudi, HF
   Khazanov, C
   Lillie, J
   Gustafson, JL
   Kudithipudi, D
AF Carmichael, Zachariah
   Langroudi, Hamed F.
   Khazanov, Char
   Lillie, Jeffrey
   Gustafson, John L.
   Kudithipudi, Dhireesha
GP ACM
TI Performance-Efficiency Trade-off of Low-Precision Numerical Formats in
   Deep Neural Networks
SO CONFERENCE FOR NEXT GENERATION ARITHMETIC 2019 (CONGA)
DT Proceedings Paper
CT 2nd Conference on Next-Generation Arithmetic (CoNGA)
CY MAR 13-14, 2019
CL Singapore, SINGAPORE
DE DNN accelerators; posit numerical format; deep neural networks; machine
   learning; floating point; tapered precision; low-precision
AB Deep neural networks (DNNs) have been demonstrated as effective prognostic models across various domains, e.g. natural language processing, computer vision, and genomics. However, modern-day DNNs demand high compute and memory storage for executing any reasonably complex task. To optimize the inference time and alleviate the power consumption of these networks, DNN accelerators with low-precision representations of data and DNN parameters are being actively studied. An interesting research question is in how low-precision networks can be ported to edge-devices with similar performance as high-precision networks. In this work, we employ the fixed-point, floating point, and posit numerical formats at <= 8-bit precision within a DNN accelerator, Deep Positron, with exact multiply-and-accumulate (EMAC) units for inference. A unified analysis quantifies the trade-offs between overall network efficiency and performance across five classification tasks. Our results indicate that posits are a natural fit for DNN inference, outperforming at <= 8-bit precision, and can be realized with competitive resource requirements relative to those of floating point.
C1 [Carmichael, Zachariah; Langroudi, Hamed F.; Khazanov, Char; Lillie, Jeffrey; Kudithipudi, Dhireesha] Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
   [Gustafson, John L.] Natl Univ Singapore, Singapore 119077, Singapore.
RP Carmichael, Z (corresponding author), Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
CR [Anonymous], 2018, 2018 IEEE 88 VEH TEC
   [Anonymous], IS T SPIE 1993 INT S
   [Anonymous], P C NEXT GEN AR
   [Anonymous], 2014, CORR
   [Anonymous], 2018, PROC INT C ELECT ELE
   [Anonymous], 2016, CHANGING GAME
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], 2018, 2018 1 WORKSH EN, DOI DOI 10.1109/EMC2.2018.00012
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Carmichael Z., 2019, DES AUT TEST EUR DAT
   Chaurasiya R, 2018, PR IEEE COMP DESIGN, P334, DOI 10.1109/ICCD.2018.00057
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Colangelo P, 2018, ANN IEEE SYM FIELD P, P73, DOI 10.1109/FCCM.2018.00020
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P., 2016, THESIS
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han S, 2016, ABS151000149 CORR
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Iwata A., 1989, IJCNN, V2, P171
   Jaiswal G, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), P100, DOI 10.1109/ICCSP.2018.8524267
   Jaiswal MK, 2018, DES AUT TEST EUROPE, P1159, DOI 10.23919/DATE.2018.8342187
   Johnson J., 2018, ARXIV181101721
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kulisch U., 2013, COMPUTER ARITHMETIC, V33
   Mishra A., 2018, ARXIV180300227
   Podobas A, 2018, IEEE SYM PARA DISTR, P138, DOI 10.1109/IPDPSW.2018.00029
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Schlimmer JC, 1987, CONCEPT ACQUISITION
   SHANNON CE, 1948, BELL SYST TECH J, V27, P623, DOI 10.1002/j.1538-7305.1948.tb00917.x
   Shazeer Noam, 2017, CORR
   Xiao Han, 2017, ARXIV170807747, P4321
NR 33
TC 36
Z9 36
U1 0
U2 1
PY 2019
DI 10.1145/3316279.3316282
WC Mathematics
DA 2023-11-11
ER

PT J
AU Verma, V
   Ii, TT
   Stan, MR
AF Verma, Vaibhav
   Tracy II, Tommy
   Stan, Mircea R.
TI EXTREM-EDGE-EXtensions To RISC-V for Energy-efficient ML inference at
   the EDGE of IoT
SO SUSTAINABLE COMPUTING-INFORMATICS & SYSTEMS
DT Article
DE Artificial intelligence; RISC-V ISA extensions; Machine learning;
   Hardware; software co-design; AI hardware
AB Artificial intelligence (AI) and machine learning (ML) have emerged as the fastest growing workloads ranging from applications like object detection, natural language processing and facial recognition to self-driving cars. The proliferation of these compute-intensive workloads resulted in numerous hardware accelerators to fill the gap between the performance and energy-efficiency requirements of AI applications and the capabilities of current architectures like CPU and GPU. In most cases these accelerators are specialized for a particular task, are costly to produce, require special programming tools, and can become obsolete as new ML algorithms are introduced. To solve these problems, we present EXTREM-EDGE, a hardware/software co-design approach to add custom extensions to the open-source RISC-V Instruction Set architecture (ISA) for designing a scalable and flexible ML processor architecture. EXTREM-EDGE augments the RISC-V processor with hardware AI functional units (AFU) along with ISA extensions which directly target these AFUs. EXTREM-EDGE is a system-level solution which is easy to program, enables royalty-free production and provides flexibility for future workloads. It enables the designers to quickly adapt to any hardware or ISA/software changes and allows the design space exploration of various available hardware, instructions and software options. This enables a processor architecture which addresses the requirements of current AI/ML workloads, gives the flexibility to hot-swap AFUs when better hardware is available and scales with new AI instructions in response to rapidly evolving AI algorithms while providing a streamlined development flow for both hardware and software. EXTREM-EDGE provides 1.75x (MAC) to 17.63x (PIM VMM) performance improvements for a GEMV kernel and 1.41x (MAC) to 4.41x (PIM VMM) reductions in processor clock cycles for ResNet-8 neural network model from MLPerf Tiny benchmark depending upon the size of added accelerators and complexity of added instructions.
C1 [Verma, Vaibhav; Stan, Mircea R.] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22903 USA.
   [Tracy II, Tommy] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
RP Verma, V (corresponding author), Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22903 USA.
EM vv8dn@virginia.edu; tjt7a@virginia.edu; mircea@virginia.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Banbury Colby R., 2021, BENCHMARKING TINYML
   Chen B., 2019, ARXIV190303129
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chowdhery A., 2019, ARXIV190605721
   Deng SG, 2020, IEEE INTERNET THINGS, V7, P7457, DOI 10.1109/JIOT.2020.2984887
   FAUTH A, 1995, EUR CONF DESIG AUTOM, P503, DOI 10.1109/EDTC.1995.470354
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jun H, 2017, IEEE INT MEM WORKSH, P99
   Kadetotad D, 2020, IEEE J SOLID-ST CIRC, V55, P1877, DOI 10.1109/JSSC.2020.2992900
   Kurtz Mark, 2020, P MACHINE LEARNING R, V119, P5533
   Lee J, 2017, IEEE ASIAN SOLID STA, P237, DOI 10.1109/ASSCC.2017.8240260
   Lee Y, 2014, PROC EUR SOLID-STATE, P199, DOI 10.1109/ESSCIRC.2014.6942056
   Matveev A, 2017, ACM SIGPLAN NOTICES, V52, P267, DOI [10.1145/3018743.3018766, 10.1145/3155284.3018766]
   Moyer Steven A, 1991, PERFORMANCE IPSC 860
   Paszke A, 2019, ADV NEUR IN, V32
   Paulin G, 2021, IEEE T VLSI SYST, V29, P1624, DOI 10.1109/TVLSI.2021.3093242
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   synopsys.com, ASIP DES
   Turing A. M., 1950, MIND, V59, P433, DOI https://doi.org/10.1093/mind/LIX.236.433
   Warden P., 2019, TINYML MACHINE LEARN
   Waterman A, 2014, UCBEECS201454, VI
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Zhang J, 2021, IEEE INTERNET THINGS, V8, P7789, DOI 10.1109/JIOT.2020.3039359
NR 29
TC 3
Z9 3
U1 5
U2 11
PD SEP
PY 2022
VL 35
AR 100742
DI 10.1016/j.suscom.2022.100742
EA MAY 2022
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT C
AU Kulkarni, A
   Abtahi, T
   Shea, C
   Kulkarni, A
   Mohsenin, T
AF Kulkarni, Adwaya
   Abtahi, Tahmid
   Shea, Colin
   Kulkarni, Amey
   Mohsenin, Tinoosh
GP IEEE
TI PACENet: Energy Efficient Acceleration for Convolutional Network on
   Embedded Platform
SO 2017 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-31, 2017
CL Baltimore, MD
DE Energy efficient; Domain-specific many-core; Convolutional Neural
   Network (CNN); Accelerator; Machine Learning
AB Lightweight convolutional neural network (CNN) on tiny embedded platforms can offer energy efficient solution for today's IoT devices. However, CNN implementation on embedded system faces processing bottleneck in convolutional layers and memory storage issues in fully connected layers. In past years, heterogeneous acceleration, where compute intensive tasks are performed on kernel specific cores, has gained attention. In this paper we propose, a domain specific and programmable accelerator "PACENet" Programmable many-core ACcElerator for convolution neural Network architecture. It consists of neural network kernel specific instruction set architecture such as convolution, maxpool and relu. To demonstrate efficiency of the proposed PACENet, we implemented ResNet-20 for CIFAR-10 dataset, where PACENet performs convolution layer, Relu activations, Maxpool layer, and fully-connected layer. We also implemented ResNet-20 for CIFAR-10 dataset on NVIDIA TX1 mobile GPU platform using Tensorflow and cuDNN libraries. Compared to NVIDIA TX1 platform implementation PACENet platform implementation performs 1.4x to 4.5x faster and saves 2.8x to 9x energy consumption respectively. PACENet achieves 2.9x to 9.3x higher throughput per watt as compared to TX1 platform implementation
C1 [Kulkarni, Adwaya; Abtahi, Tahmid; Shea, Colin; Kulkarni, Amey; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
RP Kulkarni, A (corresponding author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
CR Gautschi M, 2016, ISSCC DIG TECH PAP I, V59, P82, DOI 10.1109/ISSCC.2016.7417917
   He K., 2015, ARXIV150601497
   KULKARNI A, 2017, 2017 DES AUT TEST EU
   Kulkarni A., IEEE T CIRCUITS SY 1
   Kulkarni A, 2016, ACM J EMERG TECH COM, V13, DOI 10.1145/2827699
   Kulkarni A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P57, DOI 10.1145/2902961.2902984
   Kulkarni A, 2016, IEEE INT SYMP CIRC S, P1138, DOI 10.1109/ISCAS.2016.7527446
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Page A., J EMERGING IN PRESS, P10
   Page A, 2016, ANN IEEE SYM FIELD P, P200, DOI 10.1109/FCCM.2016.58
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Zhu M., 2016, CORR
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2017
BP 448
EP 451
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Luszczek, P
   Yamazaki, I
   Dongarra, J
AF Luszczek, Piotr
   Yamazaki, Ichitaro
   Dongarra, Jack
GP IEEE
TI Increasing Accuracy of Iterative Refinement in Limited Floating-Point
   Arithmetic on Half-Precision Accelerators
SO 2019 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 24-26, 2019
CL Waltham, MA
AB The emergence of deep learning as a leading computational workload for machine learning tasks on large-scale cloud infrastructure installations has led to plethora of accelerator hardware releases. However, the reduced precision and range of the floating-point numbers on these new platforms makes it a non-trivial task to leverage these unprecedented advances in computational power for numerical linear algebra operations that come with a guarantee of robust error bounds. In order to address these concerns, we present a number of strategies that can be used to increase the accuracy of limited-precision iterative refinement. By limited precision, we mean 16-bit floating-point formats implemented in modern hardware accelerators and are not necessarily compliant with the IEEE half-precision specification. We include the explanation of a broader context and connections to established IEEE floating-point standards and existing high-performance computing (HPC) benchmarks. We also present a new formulation of LU factorization that we call signed square root LU which produces more numerically balanced L and U factors which directly address the problems of limited range of the low-precision storage formats. The experimental results indicate that it is possible to recover substantial amounts of the accuracy in the system solution that would otherwise be lost. Previously, this could only be achieved by using iterative refinement based on single-precision floating-point arithmetic. The discussion will also explore the numerical stability issues that are important for robust linear solvers on these new hardware platforms.
C1 [Luszczek, Piotr] Univ Tennessee, Knoxville, TN 37996 USA.
   [Yamazaki, Ichitaro] Sandia Natl Labs, Livermore, CA 94550 USA.
   [Dongarra, Jack] Univ Tennessee, Oak Ridge Natl Lab, Knoxville, TN 37996 USA.
   [Dongarra, Jack] Univ Manchester, Manchester, Lancs, England.
RP Luszczek, P (corresponding author), Univ Tennessee, Knoxville, TN 37996 USA.
CR [Anonymous], 1963, ROUNDING ERRORS ALGE
   [Anonymous], 1989, THESIS
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2015, CORR
   Baboulin M, 2009, COMPUT PHYS COMMUN, V180, P2526, DOI 10.1016/j.cpc.2008.11.005
   Buttari A., 2007, EXPLOITING MIXED PRE
   Buttari A., 2007, 2007124 MIMS U MANCH
   Carson E, 2017, SIAM J SCI COMPUT, V39, pA2834, DOI 10.1137/17M1122918
   Chen Y. F., 2018, CORR
   Dongarra JJ, 2003, CONCURR COMP-PRACT E, V15, P803, DOI 10.1002/cpe.728
   Haidar A., 2018, SC 18
   Hauser J., 2018, BERKELEY SOFTFLOAT
   Hauser JR, 1996, ACM T PROGR LANG SYS, V18, P139, DOI 10.1145/227699.227701
   Higham N. J., 2018, SQUEEZING MATRIX HAL
   Howell G. W., 2015, P PAR PROC APPL MATH
   Jouppi N. P., 2017, CORR, Vabs/1704.04760
   Langou J., 2006, SC 06, P50, DOI [10.1109/SC.2006, DOI 10.1109/SC.2006]
   Lee J., 2009, 2009 S APPL ACCELERA
   PETERS G, 1970, COMPUT J, V13, P309, DOI 10.1093/comjnl/13.3.309
   PETERS G, 1975, COMMUN ACM, V18, P20, DOI 10.1145/360569.360653
   Stewart G. W., 2001, MATRIX ALGORITHMS, VI
   STEWART JJ, 2001, MATRIX ALGORITHMS, V2
   Wilkinson J. H., 1965, ALGEBRAIC EIGENVALUE
NR 23
TC 5
Z9 5
U1 0
U2 1
PY 2019
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kalet, IJ
   Jacky, JP
   Risler, R
   Rohlin, S
   Wootton, P
AF Kalet, IJ
   Jacky, JP
   Risler, R
   Rohlin, S
   Wootton, P
TI Integration of radiotherapy planning systems and radiotherapy treatment
   equipment: 11 years experience
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
DT Article
DE neutrons; multileaf collimator; radiation treatment planning; computer
   network; computer control; record and verify
ID COLLIMATOR; PROSTATE; DELIVERY; THERAPY; RECORD
AB Purpose: We have investigated the requirements, design, implementation, and operation of a computer-controlled medical accelerator with multileaf collimator (MLC), integrated with a radiation treatment-planning system (RTPS), and we report on the performance, benefits, and lessons learned from this experience.
   Methods and Materials: In 1984 the University of Washington installed a computer-controlled radiation therapy machine (the Clinical Neutron Therapy System, or CNTS) with a multileaf collimator. Since the beginning of operation the control system computer has been connected by commercially available network hardware and software to three generations of radiation treatment-planning systems. Semiautomated setup and completely computerized check and confirm were incorporated into the system from the beginning of clinical operation in 1984. The system cannot deliver a patient treatment without a computer-prepared treatment plan.
   Results: The CNTS has been in use for routine patient treatments for over 11 years. The cost of the network connection and software was an insignificant fraction of the facility cost. Operation has been efficient and reliable. Of the 441 machine-related session reschedulings (out of 18,432 sessions total) during the past 9 years, only 20 were due to problems with data transfer between the RTPS and CNTS, associated primarily with two incidents. Close integration with the treatment-planning system allows complex treatments to be delivered. Dramatic evolution of the departmental treatment-planning system has not required any changes or redesign of either the accelerator control system or the network connection.
   Conclusions: Our experience shows that a large degree of automation is possible with reasonable effort, by using well-known software and hardware design strategies. The lessons we have learned from this can be carried over into photon therapy now that photon accelerators with MLC facilities are commercially available. (C) 1997 Elsevier Science Inc.
C1 ERICSSON HEWLETT PACKARD TELECOMMUN, GOTHENBURG, SWEDEN.
RP Kalet, IJ (corresponding author), UNIV WASHINGTON, DEPT RADIAT ONCOL, BOX 356043, SEATTLE, WA 98195 USA.
CR *AM NAT STAND I, 1977, ANSI X3 4 1977 COD I
   AUSTINSEYMOUR M, 1994, INT J RADIAT ONCOL, V30, P1065, DOI 10.1016/0360-3016(94)90311-5
   COMER D, 1991, INTERNETWORKING TCP, V1
   COSTA A, 1987, INT J RADIAT ONCOL, V13, P1949, DOI 10.1016/0360-3016(87)90365-8
   DACRUZ F, 1984, KERMIT FILE TRANSFER
   DAVY TJ, 1987, DOSIMETRY RADIOTHERA, P277
   DICKOF P, 1984, MED PHYS, V11, P525, DOI 10.1118/1.595640
   Digital Equipment Corporation Intel Corporation and XEROX Corporation, 1980, ETH LOC AR NETW DAT
   *EL IND ASS, 1981, RS232C EIA
   ESSEN CFV, 1980, J CAN ASSOC RADIOL, V31, P19
   HOUNSELL AR, 1992, BRIT J RADIOL, V65, P321, DOI 10.1259/0007-1285-65-772-321
   *IEC, 1981, INT EL COMM PUBL
   *ISO, 1983, 74981983 ISO
   JACKY J, 1990, 901201 U WASH RAD ON
   JACKY J, 1992, 920501 U WASH RAD ON
   JACKY JP, 1987, COMMUN ACM, V30, P772, DOI 10.1145/30401.30403
   KALET IJ, 1982, COMPUT PROG BIOMED, V14, P85, DOI 10.1016/0010-468X(82)90094-0
   KALET IJ, 1993, 930902 U WASH RAD ON
   KALET IJ, 1993, 930802 U WASH RAD ON
   LEUNENS G, 1992, RADIOTHER ONCOL, V23, P217, DOI 10.1016/S0167-8140(92)80124-2
   MAGERAS GS, 1992, MED PHYS, V19, P945, DOI 10.1118/1.596782
   MAGERAS GS, 1994, INT J RADIAT ONCOL, V30, P971, DOI 10.1016/0360-3016(94)90374-3
   MCSHAN DL, 1994, 11TH P INT C US COMP, P210
   METCALFE RM, 1976, COMMUN ACM, V19, P395, DOI 10.1145/360248.360253
   MOHAN R, 1984, INT J RADIAT ONCOL, V10, P1975, DOI 10.1016/0360-3016(84)90281-5
   MOHAN R, 1983, INT J RADIAT ONCOL, V9, P1225, DOI 10.1016/0360-3016(83)90185-2
   MOORE CJ, 1994, 11TH P INT C US COMP, P44
   MORREY D, 1987, P 9 INT C US COMP RA, P13
   REKONEN A, 1987, P 9 INT C US COMP RA, P17
   RISLER R, 1984, P 10 INT C CYCL THEI, P428
   ROSENBLOOM ME, 1977, BRIT J RADIOL, V50, P637, DOI 10.1259/0007-1285-50-597-637
   SMITH AR, 1988, AM J CLIN ONCOL-CANC, V11, P187, DOI 10.1097/00000421-198806000-00001
   TAKAHASHI S, 1965, ACTA RADIOL S, V242
NR 33
TC 6
Z9 6
U1 0
U2 3
PD APR 1
PY 1997
VL 38
IS 1
BP 213
EP 221
DI 10.1016/S0360-3016(97)00281-2
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Paszke, A
   Gross, S
   Massa, F
   Lerer, A
   Bradbury, J
   Chanan, G
   Killeen, T
   Lin, ZM
   Gimelshein, N
   Antiga, L
   Desmaison, A
   Köpf, A
   Yang, E
   DeVito, Z
   Raison, M
   Tejani, A
   Chilamkurthy, S
   Steiner, B
   Fang, L
   Bai, JJ
   Chintala, S
AF Paszke, Adam
   Gross, Sam
   Massa, Francisco
   Lerer, Adam
   Bradbury, James
   Chanan, Gregory
   Killeen, Trevor
   Lin, Zeming
   Gimelshein, Natalia
   Antiga, Luca
   Desmaison, Alban
   Kopf, Andreas
   Yang, Edward
   DeVito, Zach
   Raison, Martin
   Tejani, Alykhan
   Chilamkurthy, Sasank
   Steiner, Benoit
   Fang, Lu
   Bai, Junjie
   Chintala, Soumith
BE Wallach, H
   Larochelle, H
   Beygelzimer, A
   d'Alche-Buc, F
   Fox, E
   Garnett, R
TI PyTorch: An Imperative Style, High-Performance Deep Learning Library
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 32 (NIPS 2019)
SE Advances in Neural Information Processing Systems
DT Proceedings Paper
CT 33rd Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 08-14, 2019
CL Vancouver, CANADA
AB Deep learning frameworks have often focused on either usability or speed, but not both. PyTorch is a machine learning library that shows that these two goals are in fact compatible: it provides an imperative and Pythonic programming style that supports code as a model, makes debugging easy and is consistent with other popular scientific computing libraries, while remaining efficient and supporting hardware accelerators such as GPUs.
   In this paper, we detail the principles that drove the implementation of PyTorch and how they are reflected in its architecture. We emphasize that every aspect of PyTorch is a regular Python program under the full control of its user. We also explain how the careful and pragmatic implementation of the key components of its runtime enables them to work together to achieve compelling performance.
   We demonstrate the efficiency of individual subsystems, as well as the overall speed of PyTorch on several common benchmarks.
C1 [Paszke, Adam] Univ Warsaw, Warsaw, Poland.
   [Gross, Sam; Massa, Francisco; Lerer, Adam; Chanan, Gregory; Lin, Zeming; Yang, Edward; DeVito, Zach; Steiner, Benoit; Chintala, Soumith] Facebook AI Res, Menlo Pk, CA USA.
   [Bradbury, James] Google, Mountain View, CA 94043 USA.
   [Gimelshein, Natalia] NVIDIA, Santa Clara, CA USA.
   [Antiga, Luca] Orobix, Bergamo, Italy.
   [Desmaison, Alban] Univ Oxford, Oxford, England.
   [Kopf, Andreas] Xamla, Westphalia, Germany.
   [Raison, Martin] Nabla, Paris, France.
   [Tejani, Alykhan] Twitter, San Francisco, CA USA.
   [Chilamkurthy, Sasank] Qure Ai, Mumbai, Maharashtra, India.
   [Fang, Lu; Bai, Junjie] Facebook, Menlo Pk, CA USA.
RP Paszke, A (corresponding author), Univ Warsaw, Warsaw, Poland.
EM adam.paszke@gmail.com; sgross@fb.com; fmassa@fb.com; alerer@fb.com;
   jekbradbury@gmail.com; gchanan@fb.com; killeent@cs.washington.edu;
   zlin@fb.com; ngimelshein@nvidia.com; luca.antiga@orobix.com;
   alban@robots.ox.ac.uk; andreas.koepf@xamla.com; ezyang@fb.com;
   zdevito@cs.stanford.edu; martinraison@gmail.com; atejani@twitter.com;
   sasankchilamkurthy@gmail.com; benoitsteiner@fb.com; lufang@fb.com;
   jbai@fb.com; soumith@gmail.com
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Abrams Philip S., 1970, THESIS
   [Anonymous], MATLAB STAT TOOLB
   [Anonymous], 2017, ICLR
   Baydin AG., 2017, J MACH LEARN RES, V18, P5595
   Bezanson J, 2017, SIAM REV, V59, P65, DOI 10.1137/141000671
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Collobert R., 2002, TECHNICAL REPORT
   Collobert R., 2011, BIGLEARN
   DMLC, DLPACK OP MEM TENS S
   Evans J., 2006, BSDCAN TECHN BSD C M
   Fabian JH, 2000, MESA MG, P117
   Gabriel Richard, RISE WORSE IS BETTER
   Ghemawat S., TCMALLOC THREAD CACH
   Guennebaud G., 2010, EIGEN V3
   Hertz M, 2005, ACM SIGPLAN NOTICES, V40, P313, DOI 10.1145/1103845.1094836
   Huang Austin, JUNJI HASHIMOTO SAM
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Johnson Matthew, 2018, JAX
   Lavin A., 2015, MAXDNN EFFICIENT CON
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LeCun Y, 2002, TECHNICAL REPORT
   LeCun Y., MNIST HANDWRITTEN DI
   Leuck Holger, 1999, IEEE COMP SOC C COMP, P2360
   Luitjens Justin, 2014, GPU TECHN C
   Maclaurin Dougal, 2016, THESIS HARVARD U
   McKinney W., 2010, DATA STRUCTURES STAT
   Neubig Graham, 2017, ARXIV170103980
   OLIPHANT TE, 2006, GUIDE NUMPY
   Peterson P, 2001, SCIPY OPEN SOURCE SC
   Petrantoni Giovanni, NIMTORCH
   Piponi D., 2004, Journal of Graphics Tools, V9, P41, DOI 10.1080/10867651.2004.10504901
   R Core Team, R LANG ENV STAT COMP
   Recht B., 2011, ADV NEURAL INFORM PR, P693
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Sermanet P, 2009, PROC INT C TOOLS ART, P693
   Synnaeve G, 2018, PROC INT C NEURAL IN, P10761
   The Python team, CPYTH GLOB INT LOCK
   The PyTorch team, PYT AUT PROF
   The PyTorch team, TORCH SCRIPT
   Theano Development Team, 2016, ABS160502688 ARXIV
   Tokui S., 2015, P WORKSH MACH LEARN, V5, P1
   Vinyals O., 2017, ARXIV170804782
NR 43
TC 7750
Z9 7754
U1 64
U2 389
PY 2019
VL 32
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Mishty, K
   Sadi, M
AF Mishty, Kaniz
   Sadi, Mehdi
GP ACM
TI System and Design Technology Co-optimization of Chiplet-based AI
   Accelerator with Machine Learning
SO PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2023, GLSVLSI 2023
DT Proceedings Paper
CT 33rd Great Lakes Symposium on VLSI (GLSVLSI)
CY JUN 05-07, 2023
CL Knoxville, TN
DE Chiplet-based architectures; Deep Learning hardware; advanced packaging;
   2.5D; 3D; PPA optimization; STCO
AB With the availability of advanced packaging technology and its attractive features, the chiplet-based architecture has gained traction among chip designers. The large design space and the lack of system and package-level co-design methods make it difficult for the designers to create the optimum design choices. In this research, considering the colossal design space of advanced packaging technologies, resource allocation, and chiplet placement, we design an optimizer that looks for the design choices that maximize the Power, Performance, and Area (PPA) and minimize the cost of the chiplet-based AI accelerator. Inspired by the Bayesian approach for black-box function optimization, our optimizer guides the search space toward global maxima instead of randomly traversing through the search space. We analytically synthesize a dataset from the search space and train an ML model to predict the target value of our defined cost function at the optimizer-suggested points. The optimizer locates the optimum design choices from the specified search space (>= 1M data points) with minimal iterations (<= 200 iterations) and trivial run time.
C1 [Mishty, Kaniz; Sadi, Mehdi] Auburn Univ, Auburn, AL 36849 USA.
RP Mishty, K (corresponding author), Auburn Univ, Auburn, AL 36849 USA.
EM kzm0114@auburn.edu; mzs0190@auburn.edu
CR [Anonymous], 2015, HIGH BANDWIDTH MEMOR
   [Anonymous], 2021, HETEROGENEOUS INTEGR
   Chen F.C., 2019, 2019 IEEE 69 ELECT C
   Coskun Ayse, 2022, 2020 IEEE T COMPUTER, V39
   Games W, 2020, ISSCC DIG TECH PAP I, P144
   Hsieh Kenny Cheng-Hsiang, 2021, ISSCC 2021 FORUMS
   Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   Ingerly DB, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993637
   Jiang Hong, 2022, 2022 IEEE HOT CHIPS, P1
   Kao Sheng-Chun, 2020, ARXIV
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Krishnan Srivatsan, 2022, ARXIV
   Kumar A., 2021, ARXIV
   Lee FJC, 2020, S VLSI TECH
   Lin MS, 2019, SYMP VLSI CIRCUITS, pC28, DOI 10.23919/VLSIC.2019.8778161
   Lin TR, 2020, INT S HIGH PERF COMP, P99, DOI 10.1109/HPCA47549.2020.00018
   Mahajan R, 2016, ELEC COMP C, P557, DOI 10.1109/ECTC.2016.201
   Mishty K, 2021, IEEE T VLSI SYST, V29, P1730, DOI 10.1109/TVLSI.2021.3105958
   Naffziger S, 2021, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA52012.2021.00014
   Naffziger S, 2020, ISSCC DIG TECH PAP I, P44, DOI 10.1109/ISSCC19947.2020.9063103
   Park John, 2022, CADENCE
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Tan ZH, 2021, CONF PROC INT SYMP C, P1013, DOI 10.1109/ISCA52012.2021.00083
   Wang TQ, 2022, INT S HIGH PERF COMP, P1198, DOI 10.1109/HPCA53966.2022.00091
   Wu YB, 2022, INT S HIGH PERF COMP, P986, DOI 10.1109/HPCA53966.2022.00076
   Zhang D, 2022, Arxiv, DOI arXiv:2105.12842
NR 27
TC 0
Z9 0
U1 2
U2 2
PY 2023
BP 697
EP 702
DI 10.1145/3583781.3590233
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ricci, M
   Stitic, B
   Urbinati, L
   Di Guglielmo, G
   Vasquez, JAT
   Carloni, LP
   Vipiana, F
   Casu, MR
AF Ricci, Marco
   Stitic, Bernardita
   Urbinati, Luca
   Di Guglielmo, Giuseppe
   Vasquez, Jorge A. Tobon
   Carloni, Luca P.
   Vipiana, Francesca
   Casu, Mario R.
TI Machine-Learning-Based Microwave Sensing: A Case Study for the Food
   Industry
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Sensors; Microwave imaging; Microwave theory and techniques; Microwave
   circuits; Microwave antennas; Machine learning; Production; Microwave
   sensing; microwave antenna arrays; machine learning; MLP classifier;
   food safety; high level synthesis; food technology; contactless
   diagnostics
ID IMAGING TECHNOLOGY
AB Despite the meticulous attention of food industries to prevent hazards in packaged goods, some contaminants may still elude the controls. Indeed, standard methods, like X-rays, metal detectors and near-infrared imaging, cannot detect low-density materials. Microwave sensing is an alternative method that, combined with machine learning classifiers, can tackle these deficiencies. In this paper we present a design methodology applied to a case study in the food sector. Specifically, we offer a complete flow from microwave dataset acquisition to deployment of the classifiers on real-time hardware and we show the effectiveness of this method in terms of detection accuracy. In the case study, we apply the machine-learning based microwave sensing approach to the case of food jars flowing at high speed on a conveyor belt. First, we collected a dataset from hazelnut-cocoa spread jars which were uncontaminated or contaminated with various intrusions, including low-density plastics. Then, we performed a design space exploration to choose the best MLPs as binary classifiers, which resulted to be exceptionally accurate. Finally, we selected the two most light-weight models for implementation on both an ARM-based CPU and an FPGA SoC, to cover a wide range of possible latency requirements, from loose to strict, to detect contaminants in real-time. The proposed design flow facilitates the design of the FPGA accelerator that might be required to meet the timing requirements by using a high-level approach, which might be suited for the microwave domain experts without specific digital hardware skills.
C1 [Ricci, Marco; Urbinati, Luca; Vasquez, Jorge A. Tobon; Vipiana, Francesca; Casu, Mario R.] Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
   [Stitic, Bernardita] Pontificia Univ Catolica Chile, Sch Engn, Santiago 7820436, Chile.
   [Di Guglielmo, Giuseppe; Carloni, Luca P.] Columbia Univ, Dept Comp Sci, New York, NY 10027 USA.
RP Casu, MR (corresponding author), Politecn Torino, Dept Elect & Telecommun, I-10129 Turin, Italy.
EM bastitic@uc.cl; mario.casu@polito.it
CR [Anonymous], 2020, M980XA SER PXLE VECT
   Bisgin H, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-24926-7
   Carloni LP, 2016, DES AUT CON, DOI 10.1145/2897937.2905018
   David R., 2020, ARXIV201008678
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Edwards M.C., 2004, DETECTING FOREIGN BO
   Fan SX, 2020, J FOOD ENG, V286, DOI 10.1016/j.jfoodeng.2020.110102
   Haff Ronald P., 2008, Sensing and Instrumentation for Food Quality and Safety, V2, P262, DOI 10.1007/s11694-008-9059-8
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jördens C, 2008, OPT ENG, V47, DOI 10.1117/1.2896597
   Krupa, 2021, ARXIV210305579
   Lahti S, 2019, IEEE T COMPUT AID D, V38, P898, DOI 10.1109/TCAD.2018.2834439
   Lee WH, 2014, MICROW OPT TECHN LET, V56, P1211, DOI 10.1002/mop.28303
   Lim DK, 2017, FOOD RES INT, V100, P814, DOI 10.1016/j.foodres.2017.08.006
   Lorenzi N., 2019, INSPECTION DETECTION
   LoVetri J, 2020, IEEE ANTENN PROPAG M, V62, P33, DOI 10.1109/MAP.2020.3003206
   Muradov M., 2020, P 6 INT EL C SENS AP, V42, P54
   Ng A., STRUCTURING MACHINE
   Piccolboni L, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126566
   Ravikanth L, 2017, FOOD BIOPROCESS TECH, V10, P1, DOI 10.1007/s11947-016-1817-8
   Scapaticci R, 2018, IEEE T ANTENN PROPAG, V66, P7328, DOI 10.1109/TAP.2018.2871266
   Schimmer O, 2008, HANN BEITR NACHRICHT, V2, P141, DOI 10.1109/ICUWB.2008.4653371
   Urbinati L, 2020, IEEE INT SYMP CIRC S
   Vásquez JAT, 2020, IEEE ANTENN PROPAG M, V62, P18, DOI 10.1109/MAP.2020.3012898
   Vasquez JAT, 2019, INT J ANTENN PROPAG, V2019, DOI 10.1155/2019/8065036
   Wang KQ, 2017, TRENDS FOOD SCI TECH, V67, P93, DOI 10.1016/j.tifs.2017.06.001
   Wu ZP, 2017, IEEE ANTENN PROPAG M, V59, P61, DOI 10.1109/MAP.2017.2731201
   Yan SS, 2021, TALANTA, V226, DOI 10.1016/j.talanta.2021.122195
   Zhang JY, 2020, IEEE T INSTRUM MEAS, V69, P6446, DOI 10.1109/TIM.2020.2972655
   Zhou L, 2019, COMPR REV FOOD SCI F, V18, P1793, DOI 10.1111/1541-4337.12492
   Zidane F, 2020, IEEE T ANTENN PROPAG, V68, P8062, DOI 10.1109/TAP.2020.3016184
NR 31
TC 7
Z9 7
U1 2
U2 19
PD SEP
PY 2021
VL 11
IS 3
BP 503
EP 514
DI 10.1109/JETCAS.2021.3097699
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bian, S
   Kundi, DES
   Hirozawa, K
   Liu, WQ
   Sato, T
AF Bian, Song
   Kundi, Dur E. Shahwar
   Hirozawa, Kazuma
   Liu, Weiqiang
   Sato, Takashi
TI APAS: Application-Specific Accelerators for RLWE-Based Homomorphic
   Linear Transformations
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
DT Article
DE Cryptography; Protocols; Computer architecture; Transforms; Standards;
   Libraries; Lattices; Homomorphic encryption; ring learning with errors;
   secure inference; neural networks; homomorphic linear transformation;
   number theoretic transform
ID ENCRYPTION; RING; KEY
AB Recently, the application of multi-party secure computing schemes based on homomorphic encryption in the field of machine learning attracts attentions across the research fields. Previous studies have demonstrated that secure protocols adopting packed additive homomorphic encryption (PAHE) schemes based on the ring learning with errors (RLWE) problem exhibit significant practical merits, and are particularly promising in enabling efficient secure inference in machine-learning-as-a-service applications. In this work, we introduce a new technique for performing homomorphic linear transformation (HLT) over PAHE ciphertexts. Using the proposed HLT technique, homomorphic convolutions and inner products can be executed without the use of number theoretic transform and the rotate-and-add algorithms that were proposed in existing works. To maximize the efficiency of the HLT technique, we propose APAS, a hardware-software co-design framework consisting of approximate arithmetic units for the hardware acceleration of HLT. In the experiments, we use actual neural network architectures as benchmarks to show that APAS can improve the computational and communicational efficiency of homomorphic convolution by 8x and 3x, respectively, with an energy reduction of up to 26x as compared to the ASIC implementations of existing methods.
C1 [Bian, Song; Hirozawa, Kazuma; Sato, Takashi] Kyoto Univ, Dept Commun & Comp Engn, Kyoto 6068501, Japan.
   [Kundi, Dur E. Shahwar; Liu, Weiqiang] Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
   [Kundi, Dur E. Shahwar] Natl Univ Sci & Technol, Dept Elect Engn, Islamabad 44000, Pakistan.
RP Bian, S (corresponding author), Kyoto Univ, Dept Commun & Comp Engn, Kyoto 6068501, Japan.; Liu, WQ (corresponding author), Nanjing Univ Aeronaut & Astronaut, Coll Elect & Informat Engn, Nanjing 211106, Peoples R China.
EM sbian@easter.kuee.kyoto-u.ac.jp; shahwar@pnec.nust.edu.pk;
   liuweiqiang@nuaa.edu.cn; takashi@easter.kuee.kyoto-u.ac.jp
CR Albrecht MR, 2015, J MATH CRYPTOL, V9, P169, DOI 10.1515/jmc-2015-0016
   Alkim E, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P327
   [Anonymous], 2013, DES COMP 1 2013 06
   BARRETT P, 1987, LECT NOTES COMPUT SC, V263, P311
   Bian, 2020, ARXIV200111854
   Bian S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317850
   Bian S, 2019, DES AUT TEST EUROPE, P1739, DOI [10.23919/DATE.2019.8715110, 10.23919/date.2019.8715110]
   Bian S, 2018, DES AUT CON, DOI 10.1145/3195970.3196032
   Blömer J, 2007, LECT NOTES COMPUT SC, V4596, P65, DOI 10.1016/j.tcs.2008.12.045
   Cathebras J., 2018, THESIS U PARIS SACLA
   Chen HL, 2017, IEEE INT C COMPUT, P3, DOI 10.1109/CSE-EUC.2017.12
   Chou Edward, 2018, ABS181109953 CORR
   COOLEY JW, 1969, IEEE T EDUC, VE 12, P27, DOI 10.1109/TE.1969.4320436
   Doröz Y, 2015, IEEE T COMPUT, V64, P1509, DOI 10.1109/TC.2014.2345388
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Fan J., 2012, IACR CRYPTOL EPRINT
   Gilad-Bachrach, 2018, ARXIV181210659
   HUNT BR, 1971, IEEE T ACOUST SPEECH, VAU19, P285, DOI 10.1109/TAU.1971.1162202
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Keller M, 2020, CCS '20: PROCEEDINGS OF THE 2020 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1575, DOI 10.1145/3372297.3417872
   Keller M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P830, DOI 10.1145/2976749.2978357
   Kyoto University, 2021, HOM LIN TRANSF
   Langlois A, 2015, DESIGN CODE CRYPTOGR, V75, P565, DOI 10.1007/s10623-014-9938-4
   Lindner R, 2011, LECT NOTES COMPUT SC, V6558, P319, DOI 10.1007/978-3-642-19074-2_21
   Liu J, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P619, DOI 10.1145/3133956.3134056
   Liu WQ, 2020, P IEEE, V108, P394, DOI 10.1109/JPROC.2020.2975695
   Liu WQ, 2019, IEEE T VLSI SYST, V27, P2459, DOI 10.1109/TVLSI.2019.2922999
   Liu Z, 2015, LECT NOTES COMPUT SC, V9293, P663, DOI 10.1007/978-3-662-48324-4_33
   Lou Q., 2020, ARXIV200604219
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Microsoft Research, 2019, MICR SEAL REL 3 6
   Migliore V, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126558
   Mishra P, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2505
   Mohassel P, 2017, P IEEE S SECUR PRIV, P19, DOI [10.1109/SP.2017.12, 10.1145/3132747.3132768]
   Öztürk E, 2017, IEEE T COMPUT, V66, P3, DOI 10.1109/TC.2016.2574340
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Peikert C, 2017, ACM S THEORY COMPUT, P461, DOI 10.1145/3055399.3055489
   Peikert C, 2016, LECT NOTES COMPUT SC, V9841, P411, DOI 10.1007/978-3-319-44618-9_22
   Pöppelmann T, 2014, LECT NOTES COMPUT SC, V8282, P68, DOI 10.1007/978-3-662-43414-7_4
   Polyakov Y, 2018, PALISADE LATTICE CRY
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Riazi MS, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P1501
   Rouhani BD, 2018, DES AUT CON, DOI [10.1145/3195970.3196023, 10.1109/DAC.2018.8465894]
   Roy Sujoy Sinha, 2017, IEEE Transactions on Computers, V66, P1562, DOI 10.1109/TC.2017.2686385
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Roy SS, 2014, LECT NOTES COMPUT SC, V8731, P371, DOI 10.1007/978-3-662-44709-3_21
   Smart NP, 2010, LECT NOTES COMPUT SC, V6056, P420
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Yao A. C., 1982, 23rd Annual Symposium on Foundations of Computer Science, P160, DOI 10.1109/SFCS.1982.38
NR 49
TC 1
Z9 1
U1 2
U2 12
PY 2021
VL 16
BP 4663
EP 4678
DI 10.1109/TIFS.2021.3114032
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zoulkarni, A
   Kachris, C
   Soudris, D
AF Zoulkarni, Asim
   Kachris, Christoforos
   Soudris, Dimitrios
GP IEEE
TI Hardware Acceleration of Decision Tree Learning Algorithm
SO 2020 9TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS
   TECHNOLOGIES (MOCAST)
DT Proceedings Paper
CT 9th International Conference on Modern Circuits and Systems Technologies
   (MOCAST)
CY SEP 07-09, 2020
CL ELECTR NETWORK
DE machine learning; data mining; decision tree; C4.5; SDSoC; hardware
   acceleration
AB Decision Tree Classification variants are among the most popular machine learning algorithms and have been applied in various fields with success. Their versatility and popularity along with the ease to use make it imperative that solutions be found regarding its performance optimization problem, hence in this paper we tackle this issue by applying methods to optimize a Decision Tree Learning implementation (version C4.5), that will be executed in a heterogeneous computing system involving FPGA along with CPU, making use of the tools offered by the Software-Defined System On Chip (SDSoC) development platform. Initially, a profiling of the code is done, after which the computationally intensive part of the algorithm is determined, that is found to be the decision tree training part and within that part specifically, the Information Gain computations. Then the kernel has been developed as a hardware accelerated function that assumes the latter computations. The presented performance of the kernel was evaluated on a Zed platform integrated with Xilinx Zynq-7000 SoC in a FPGA-based heterogeneous system and it was shown that the accelerator can yield up to 2.48x kernel speedup in a single decision tree's training part, compared to an embedded ARM processor based implementation.
C1 [Zoulkarni, Asim; Soudris, Dimitrios] NTUA, Dept Elect & Comp Engn, Athens, Greece.
   [Kachris, Christoforos] NTUA, Inst Commun & Comp Syst, Athens, Greece.
RP Zoulkarni, A (corresponding author), NTUA, Dept Elect & Comp Engn, Athens, Greece.
EM el13068@mail.ntua.gr; kachris@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr
CR [Anonymous], 2017, UCI MACHINE LEARNING
   Lin Z, 2019, ANN IEEE SYM FIELD P, P172, DOI 10.1109/FCCM.2019.00032
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Owaida M, 2018, I C FIELD PROG LOGIC, P295, DOI 10.1109/FPL.2018.00057
   Quinlan J. Ross, 1993, C4 5 PROGRAMS MACHIN, P24
   Struharik R, 2015, I S INTELL SYST INFO, P101, DOI 10.1109/SISY.2015.7325359
   Xilinx Inc, 2019, SDX PRAGMA REFERENCE, P33
   Xilinx Inc, 2018, VIVADO DESIGN SUITE, P167
   Zhang C., 2017, 2017 27 INT C FIELD
   Zhao S., 2018, 2018 IEEE 4 INT C CO
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/mocast49295.2020.9200255
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Baumgartner, S
   Huemer, M
   Lunglmayr, M
AF Baumgartner, Stefan
   Huemer, Mario
   Lunglmayr, Michael
TI Efficient Majority Voting in Digital Hardware
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Random forests; Clocks; Random access memory; Adders; Field programmable
   gate arrays; Hardware acceleration; Decoding; Random forests; majority
   decision; classification; field programmable gate array (FPGA); hardware
   acceleration
ID CLASSIFICATION
AB In recent years, machine learning methods became increasingly important for a manifold number of applications. However, they often suffer from high computational requirements impairing their efficient use in real-time systems, even when employing dedicated hardware accelerators. Ensemble learning methods are especially suitable for hardware acceleration since they can be constructed from individual learners of low complexity and thus offer large parallelization potential. For classification, the outputs of these learners are typically combined by majority voting, which often represents the bottleneck of a hardware accelerator for ensemble inference. In this brief, we present a novel architecture that allows obtaining a majority decision in a number of clock cycles that is logarithmic in the number of inputs. We show, that for the example application of handwritten digit recognition a random forest processing engine employing this majority decision architecture implemented on an FPGA allows the classification of more than seven million images per second, resulting in a speed-up factor of more than 29 compared to the fastest state-of-the-art implementation considered.
C1 [Baumgartner, Stefan; Huemer, Mario] Johannes Kepler Univ Linz, JKU LIT SAL eSPML Lab, A-4040 Linz, Austria.
   [Baumgartner, Stefan; Huemer, Mario; Lunglmayr, Michael] Johannes Kepler Univ Linz, Inst Signal Proc, A-4040 Linz, Austria.
RP Baumgartner, S (corresponding author), Johannes Kepler Univ Linz, JKU LIT SAL eSPML Lab, A-4040 Linz, Austria.; Baumgartner, S (corresponding author), Johannes Kepler Univ Linz, Inst Signal Proc, A-4040 Linz, Austria.
EM stefan.baumgartner@jku.at; mario.huemer@jku.at; michael.lunglmayr@jku.at
CR [Anonymous], 2012, BOOSTING ADAPTIVE CO
   Barbareschi M, 2021, KNOWL INF SYST, V63, P1577, DOI 10.1007/s10115-021-01565-5
   Barbareschi M, 2015, LECT NOTES COMPUT SC, V9132, P194, DOI 10.1007/978-3-319-20248-8_17
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chang XP, 2021, IEEE T CIRCUITS-I, V68, P1706, DOI 10.1109/TCSI.2020.3048260
   CORMEN T, 2001, INTRO ALGORITHMS
   Fernández-Delgado M, 2014, J MACH LEARN RES, V15, P3133
   Gilan AA, 2020, IEEE T CIRCUITS-II, V67, P755, DOI 10.1109/TCSII.2019.2922372
   Hacene G. B., 2019, 2019 17 IEEE INT NEW, P1
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   Li SX, 2021, IEEE T CIRCUITS-I, V68, P1543, DOI 10.1109/TCSI.2021.3052885
   Lunglmayr M., MNISTRF
   Medus LD, 2019, IEEE ACCESS, V7, P76084, DOI 10.1109/ACCESS.2019.2920885
   Mujawar S, 2018, 2018 SECOND INTERNATIONAL CONFERENCE ON ADVANCES IN ELECTRONICS, COMPUTERS AND COMMUNICATIONS (ICAECC)
   Papadonikolakis M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P283, DOI 10.1109/FPT.2010.5681485
   PARHAMI B, 1994, IEEE T RELIAB, V43, P617, DOI 10.1109/24.370218
   Qin K, 2011, COMPUT MATH APPL, V62, P2824, DOI 10.1016/j.camwa.2011.07.048
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Struharik J. R., 2011, Proceedings of the 2011 IEEE 9th International Symposium on Intelligent Systems and Informatics (SISY 2011), P41, DOI 10.1109/SISY.2011.6034358
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Yuan T, 2021, IEEE T CIRCUITS-I, V68, P250, DOI 10.1109/TCSI.2020.3030663
NR 23
TC 4
Z9 4
U1 0
U2 6
PD APR
PY 2022
VL 69
IS 4
BP 2266
EP 2270
DI 10.1109/TCSII.2022.3144047
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kang, M
   Kim, Y
   Patil, AD
   Shanbhag, NR
AF Kang, Mingu
   Kim, Yongjune
   Patil, Ameya D.
   Shanbhag, Naresh R.
TI Deep In-Memory Architectures for Machine Learning-Accuracy Versus
   Efficiency Trade-Offs
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article; Proceedings Paper
CT IEEE NEWCAS Conference
CY JUN 23-26, 2019
CL Munich, GERMANY
DE In-memory computing; analog processing; machine learning; processor;
   accelerator
ID VLSI ARCHITECTURE; ENERGY; INFERENCE; SRAM; PROCESSOR
AB In-memory architectures, in particular, the deep in-memory architecture (DIMA) has emerged as an attractive alternative to the traditional von Neumann (digital) architecture for realizing energy and latency-efficient machine learning systems in silicon. Multiple DIMA integrated circuit (IC) prototypes have demonstrated energy-delay product (EDP) gains of up to $100\times $ over a digital architecture. These EDP gains were achieved minimal or sometimes no loss in decision-making accuracy which is surprising given its intrinsic analog mixed-signal nature. This paper establishes models and methods to understand the fundamental energy-delay and accuracy trade-offs underlying DIMA by: 1) presenting silicon-validated energy, delay, and accuracy models; and 2) employing these to quantify DIMA's decision-level accuracy and to identify the most effective design parameters to maximize its EDP gains at a given level of accuracy. For example, it is shown that: 1) DIMA has the potential to realize between $21\times $ -to- $1365\times $ gains; 2) its energy-per-decision is approximately $10\times $ lower at the same decision-making accuracy under most conditions; 3) its accuracy can always be improved by increasing the input vector dimension and/or by increasing the bitline swing; and 4) unlike the digital architecture, there are quantifiable conditions under which DIMA's accuracy is fundamentally limited due to noise.
C1 [Kang, Mingu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Kim, Yongjune] Western Digital Res, Milpitas, CA 95035 USA.
   [Patil, Ameya D.; Shanbhag, Naresh R.] Univ Illinois, Coordinated Sci Lab, Urbana, IL 61801 USA.
RP Kim, Y (corresponding author), Western Digital Res, Milpitas, CA 95035 USA.
EM mingu.kang@ibm.com; yongjune.kim@wdc.com; adpatil2@illinois.edu;
   shanbhag@illinois.edu
CR [Anonymous], 2011, P IEEE CICC
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Bankman D, 2016, IEEE ASIAN SOLID STA, P21, DOI 10.1109/ASSCC.2016.7844125
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Frustaci F, 2016, IEEE T VLSI SYST, V24, P2128, DOI 10.1109/TVLSI.2015.2503733
   Frustaci F, 2015, IEEE J SOLID-ST CIRC, V50, P1310, DOI 10.1109/JSSC.2015.2408332
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kim Y, 2018, IEEE T COMMUN, V66, P4826, DOI 10.1109/TCOMM.2018.2841406
   Kim Y, 2018, IEEE INT SYMP INFO, P1670, DOI 10.1109/ISIT.2018.8437564
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Shanbhag N., 2015, U.S. Patent, Patent No. 14614743
   Simonyan K, 2015, 3 INT C LEARN REPR I
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma N, 2011, IEEE T VLSI SYST, V19, P1695, DOI 10.1109/TVLSI.2010.2055906
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Wang Z, 2017, IEEE T CIRCUITS-I, V64, P2954, DOI 10.1109/TCSI.2017.2703880
   Wang Z, 2015, IEEE T VLSI SYST, V23, P1459, DOI 10.1109/TVLSI.2014.2342153
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yang L, 2020, INT J PAVEMENT ENG, V21, P781, DOI 10.1080/10298436.2018.1511781
   Zhang J, 2015, INT SYM MIX AUGMENT, P1, DOI 10.1109/ISMAR-MASHD.2015.17
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 33
TC 9
Z9 9
U1 0
U2 7
PD MAY
PY 2020
VL 67
IS 5
BP 1627
EP 1639
DI 10.1109/TCSI.2019.2960841
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Evans, RD
   Liu, LF
   Aamodt, TM
AF Evans, R. David
   Liu, Lufei
   Aamodt, Tor M.
GP IEEE
TI JPEG-ACT: Accelerating Deep Learning via Transform-based Lossy
   Compression
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
DE GPU; Hardware Acceleration; CNN Training; Compression
AB A reduction in the time it takes to train machine learning models can be translated into improvements in accuracy. An important factor that increases training time in deep neural networks (DNNs) is the need to store large amounts of temporary data during the back-propagation algorithm. To enable training very large models this temporary data can be offloaded from limited size GPU memory to CPU memory but this data movement incurs large performance overheads.
   We observe that in one important class of DNNs, convolutional neural networks (CNNs), there is spatial correlation in these temporary values. We propose JPEG for ACTivations (JPEGACT), a lossy activation offload accelerator for training CNNs that works by discarding redundant spatial information. JPEGACT adapts the well-known JPEG algorithm from 2D image compression to activation compression. We show how to optimize the JPEG algorithm so as to ensure convergence and maintain accuracy during training. JPEG-ACT achieves 2.4x higher training performance compared to prior offload accelerators, and 1.6x compared to prior activation compression methods. An efficient hardware implementation allows JPEG-ACT to consume less than 1% of the power and area of a modern GPU.
C1 [Evans, R. David; Liu, Lufei; Aamodt, Tor M.] Univ British Columbia, Elect & Comp Engn, Vancouver, BC, Canada.
RP Evans, RD (corresponding author), Univ British Columbia, Elect & Comp Engn, Vancouver, BC, Canada.
EM rdevans@ece.ubc.ca; lucy.lufei@alumni.ubc.ca; aamodt@ece.ubc.ca
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Abali B, 2001, HPCA: SEVENTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTING ARCHITECTURE, PROCEEDINGS, P73, DOI 10.1109/HPCA.2001.903253
   ACZL J, 1975, MEASURES INFORM THEI
   Agustsson E, 2017, IEEE COMPUT SOC CONF, P1122, DOI 10.1109/CVPRW.2017.150
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2002, J ELECTRON IMAGING
   [Anonymous], 2015, CORR ABS14126572
   [Anonymous], 2014, ARXIV14127024CS
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   BRENON M, 2018, LIGHTWEIGHT PORTABLE
   CHEN T, 2016, ARXIV160406174V2CS
   CHEN YH, 2018, ARXIV180707928CS
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Ekman M, 2005, CONF PROC INT SYMP C, P74, DOI 10.1109/ISCA.2005.6
   Gomez A. N., 2017, P 31 INT C NEUR INF, P2211
   Hallnor EG, 2005, INT S HIGH PERF COMP, P201, DOI 10.1109/HPCA.2005.4
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   HOFFER E, 2017, ARXIV170508741CSSTAT
   Howard A. G., 2017, ARXIV
   Huang YP, 2019, ADV NEUR IN, V32
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   ISHIHARA H, 2006, JPEG DECODER
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jaderberg M., 2016, DECOUPLED NEURAL INT
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jia Z., 2018, ARXIV180406826CS
   KHAIRY M, 2018, ARXIV181007269CS
   Kim H, 2017, INT SYM PERFORM ANAL, P55, DOI 10.1109/ISPASS.2017.7975270
   Komodakis N, 2016, BMVC, P1, DOI DOI 10.5244/C.30.87
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A., 2009, EECE1742S PROGRAMMIN
   Kwon Y, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P148, DOI 10.1109/MICRO.2018.00021
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lew J, 2019, INT SYM PERFORM ANAL, P151, DOI 10.1109/ISPASS.2019.00028
   Li F., 2016, ARXIV160504711CS
   Li H, 2018, ADV NEUR IN, V31
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   LIN YC, 2017, DEEP GRADIENT COMPRE, P3756
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   LUNDGREN D, 2009, JPEG ENCODER VERILOG
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   MATTSON P, 2019, MLPERF TRAINING BENC
   *NVID CORP, 2018, TESL V100 DAT GPU NV
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Paszke A., 2017, P NEUR INF PROC SYST, P1, DOI DOI 10.1017/CBO9781107707221.009
   Pekhimenko G, 2012, INT CONFER PARA, P377
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Redmon J., 2016, ARXIV160207360, P779
   Rhu M, 2016, INT SYMP MICROARCH
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   ROBINSON AH, 1967, PR INST ELECTR ELECT, V55, P356, DOI 10.1109/PROC.1967.5493
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   SAITO S, 2018, CHAINER CIFAR10 VARI
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stine JE, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC SYSTEMS EDUCATION, PROCEEDINGS, P173, DOI 10.1109/MSE.2007.44
   Tan Mingxing, 2019, INT C MACH LEARN, P6105, DOI DOI 10.48550/ARXIV.1905.11946
   Tokui S, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2002, DOI 10.1145/3292500.3330756
   Tremaine RB, 2001, IBM J RES DEV, V45, P271, DOI 10.1147/rd.452.0271
   Wallace G. K., 1991, Communications of the ACM, V34, P30, DOI 10.1145/103085.103089
   Wang J, 2016, PROCEEDINGS OF THE 12TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'16), P253, DOI 10.1145/2999572.2999589
   WILLIAMSON D, 1991, IEEE PACIF, P315, DOI 10.1109/PACRIM.1991.160742
   WU SH, 2018, INT C LEARN REPR, DOI DOI 10.1109/CISS.2018.8362280
   Yao J, 2012, PROC CVPR IEEE, P702, DOI 10.1109/CVPR.2012.6247739
   Zhang YT, 2000, ACM SIGPLAN NOTICES, V35, P150, DOI 10.1145/384264.379235
NR 71
TC 19
Z9 19
U1 0
U2 1
PY 2020
BP 860
EP 873
DI 10.1109/ISCA45697.2020.00075
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Kim, Y
   Imani, M
   Rosing, T
AF Kim, Yeseong
   Imani, Mohsen
   Rosing, Tajana
GP IEEE
TI ORCHARD: Visual Object Recognition Accelerator Based on Approximate
   In-Memory Processing
SO 2017 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 36th International Conference on Computer-Aided Design (ICCAD)
CY NOV 13-16, 2017
CL Irvine, CA
DE Adaboost; object recognition; processing in-memory; non-volatile memory
AB In recent years, machine learning for visual object recognition has been applied to various domains, e.g., autonomous vehicle, heath diagnose, and home automation. However, the recognition procedures still consume a lot of processing energy and incur a high cost of data movement for memory accesses. In this paper, we propose a novel hardware accelerator design, called ORCHARD, which processes the object recognition tasks inside memory. The proposed design accelerates both the image feature extraction and boosting-based learning algorithm, which are key subtasks of the state-of-the-art image recognition approaches. We optimize the recognition procedures by leveraging approximate computing and emerging non-volatile memory (NVM) technology. The NVM-based in-memory processing allows the proposed design to mitigate the CMOS-based computation overhead, highly improving the system efficiency. In our evaluation conducted on circuit-and device-level simulations, we show that ORCHARD successfully performs practical image recognition tasks, including text, face, pedestrian, and vehicle recognition with 0.3% of accuracy loss made by computation approximation. In addition, our design significantly improves the performance and energy efficiency by up to 376x and 1896x, respectively, compared to the existing processor-based implementation.
C1 [Kim, Yeseong; Imani, Mohsen; Rosing, Tajana] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Kim, Y (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM yek048@ucsd.edu; moimani@ucsd.edu; tajana@ucsd.edu
CR Agarwal S., 2004, IEEE T PATTERN ANAL
   Ahn Junwhan, 2015, COMP ARCH ISCA 2015
   AKHLAGHI V, 2016, AUT TEST EUROPE, P1441
   Angelova Anelia, 2005, COMP VIS PATT REC 20
   [Anonymous], 2017, P 54 ANN DES AUT C 2
   [Anonymous], IEEE T CIRCUITS SY 2
   [Anonymous], 1998, P IEEE
   [Anonymous], 2015, ICML
   [Anonymous], 2014, EUR C COMP VIS
   [Anonymous], PERF AN SYST SOFTW I
   [Anonymous], 2001, PROC IEEE COMPUT SOC
   [Anonymous], IEEE T EMERGING TOPI
   Dalal N., 2005, 2005 IEEE COMP SOC C, DOI DOI 10.1109/CVPR.2005.177
   del Mundo Carlo C, 2015, P 2015 INT S MEM SYS
   Dong X., 2014, EMERGING MEMORY TECH
   Everingham M., PASCAL VISUAL OBJECT
   Hinton G, 2009, LEARNING MULTIPLE LA
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Imani M, 2017, ASIA S PACIF DES AUT, P757, DOI 10.1109/ASPDAC.2017.7858415
   Ji Zhu, 2009, STAT ITS INTERFACE
   Kadlcek Filip, 2013, P 10 FPGAWORLD C
   Keisuke DOHI, 2013, IEICE T INFORM SYSTE
   Kim Y, 2015, ICCAD-IEEE ACM INT, P690, DOI 10.1109/ICCAD.2015.7372637
   Kyrkou Christos, 2011, IEEE T VERY LARGE SC
   Manyika J, 2011, BIG DATA NEXT FRONTI
   Motaman S, 2015, I SYMPOS LOW POWER E, P7, DOI 10.1109/ISLPED.2015.7273482
   Negi Kazuhiro, 2011, FIELD PROGR TECHN FP
   Oliveira M., 2008, AUTOMATIC DETECTION
   Qing Guo, 2013, ACM SIGARCH COMPUTER
   Silva Juan, 2014, INT J COMPUTER ASSIS
   Tao Luo, 2017, IEEE T COMPUTERS
   Thomee B., 2016, COMMUNICATIONS ACM
   Xiao Shanlin, 2016, INF COMM TECHN EMB S
   Yang Yao-Tsung, 2014, AC SPEECH SIGN PROC
   Yin Shouyi, 2015, IEEE SYSTEMS J
   Zhang Shanshan, 2015, COMP VIS PATT REC CV
NR 36
TC 30
Z9 30
U1 0
U2 0
PY 2017
BP 25
EP 32
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Hoang, D
   Boffo, C
   Tran, N
   Krave, S
   Kazi, S
   Stoynev, S
   Marinozzi, V
AF Hoang, Duc
   Boffo, Cristian
   Tran, Nhan
   Krave, Steven
   Kazi, Sujay
   Stoynev, Stoyan
   Marinozzi, Vittorio
TI Intelliquench: An Adaptive Machine Learning System for Detection of
   Superconducting Magnet Quenches
SO IEEE TRANSACTIONS ON APPLIED SUPERCONDUCTIVITY
DT Article
DE Machine learning; online learning; quench detection; real-time system;
   superconducting magnets; quench
ID ACOUSTIC-EMISSION
AB In superconducting magnets, the irreversible transition of a portion of the conductor to resistive state is called a "quench." Having large stored energy, magnets can be damaged by quenches due to localized heating, high voltage, or large force transients. Unfortunately, current quench protection systems can only detect a quench after it happens, and mitigating risks in Low Temperature Superconducting (ITS) accelerator magnets often requires fast response (down to ms). Additionally, protection of High Temperature Superconducting (HTS) magnets is still suffering from prohibitively slow quench detection. In this study, we lay the groundwork for a quench prediction system using an auto-encoder fully-connected deep neural network. After dynamically trained with data features extracted from acoustic sensors around the magnet, the system detects anomalous events seconds before the quench in most of our data. While the exact nature of the events is under investigation, we show that the system can "forecast" a quench before it happens under magnet training conditions through a randomized experiment. This opens up the way of integrated data processing, potentially leading to faster and better diagnostics and detection of magnet quenches.
C1 [Hoang, Duc] Dept Phys, Rhodes Coll, Memphis, TN 38112 USA.
   [Boffo, Cristian; Tran, Nhan; Krave, Steven; Stoynev, Stoyan; Marinozzi, Vittorio] Fermilab Natl Accelerator Lab, Tech Div, Batavia, IL 60510 USA.
   [Kazi, Sujay] MIT, Cambridge, MA 02139 USA.
RP Hoang, D (corresponding author), Dept Phys, Rhodes Coll, Memphis, TN 38112 USA.
EM minhduc8199@gmail.com
CR Anerella, 2017, MQXFS1 QUADRUPOLE FA
   Anerella, 2016, MQXFS1 QUADRUPOLE DE
   Bajas H, 2018, IEEE T APPL SUPERCON, V28, DOI 10.1109/TASC.2018.2810100
   Baldi P., 2012, P ICML WORKSH UNS TR, P37, DOI DOI 10.1561/2200000006
   Chollet F., 2015, KERAS
   Denz R, 2006, IEEE T APPL SUPERCON, V16, P1725, DOI 10.1109/TASC.2005.864258
   DEVRED A, 1992, AIP CONF PROC, V249, P1262
   Ferracin P, 2019, IEEE T APPL SUPERCON, V29, DOI 10.1109/TASC.2019.2895908
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Han Y., 2017, P DET CLASS AC SCEN, P80
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Marchevsky M, 2015, CRYOGENICS, V69, P50, DOI 10.1016/j.cryogenics.2015.03.005
   Nawaz AS, 2016, CONF CONTR FAULT-TOL, P196, DOI 10.1109/SYSTOL.2016.7739750
   PAPPE M, 1983, IEEE T MAGN, V19, P1086, DOI 10.1109/TMAG.1983.1062394
   Seidel P., 2015, APPL SUPERCOND
   TSUKAMOTO O, 1982, APPL PHYS LETT, V40, P538, DOI 10.1063/1.93135
   TSUKAMOTO O, 1981, APPL PHYS LETT, V39, P172, DOI 10.1063/1.92652
   TSUKAMOTO O, 1983, J APPL PHYS, V54, P997, DOI 10.1063/1.332027
   Wielgosz M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18113933
   Wielgosz M, 2017, NUCL INSTRUM METH A, V867, P40, DOI 10.1016/j.nima.2017.06.020
   Wilson MN, 1997, IEEE T APPL SUPERCON, V7, P950, DOI 10.1109/77.614662
   Zhang CX, 2019, AAAI CONF ARTIF INTE, P1409
   Zlobin, IEEE T APPL SUPERCON, VPP, P1
   Zlobin A., 2020, REASSEMBLY TES UNPUB
NR 27
TC 4
Z9 4
U1 2
U2 11
PD AUG
PY 2021
VL 31
IS 5
AR 4900805
DI 10.1109/TASC.2021.3058229
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU LEVESON, NG
   TURNER, CS
AF LEVESON, NG
   TURNER, CS
TI AN INVESTIGATION OF THE THERAC-25 ACCIDENTS
SO COMPUTER
DT Article
AB Risk in any complex technology is unavoidable. One of the best ways to reduce risk in the future is to learn from the mistakes of the past.
   Between June 1985 and January 1987, the Therac-25, a computerized radiation therapy machine, was involved in six massive radiation overdoses. As a result. several people died and others were seriously injured. These accidents have been described as the worst series of radiation accidents in the 35-year history of medical accelerators.
   Published descriptions of the Therac-25 medical electron accelerator accidents leave out important details and are thus often misleading. The authors present a detailed investigation of the factors involved in the overdoses and attempts by users, manufacturers, and government agencies to deal with the accidents.
   Most accidents are system accidents stemming from complex interactions between various components and activities. To attribute a single cause to an accident is usually a mistake. The authors demonstrate (1) the complex nature of accidents and (2) the need to investigate all aspects of system development and operation in order to prevent future accidents.
   The authors also present some lessons learned in terms of system engineering, software engineering, and government regulation of safety-critical systems containing software components.
C1 UNIV CALIF IRVINE,DEPT INFORMAT & COMP SCI,IRVINE,CA 92717.
RP LEVESON, NG (corresponding author), UNIV WASHINGTON,DEPT COMP SCI & ENGN,FR-35,SEATTLE,WA 98195, USA.
CR BOWMAN WC, 1991, C PROBABILISTIC SAFE
   BOWSHER CA, 1990, GAOTPEMD902046987139
   HOUSTON F, 1985, IEEE COMPUTERS MED C
   KIVEL M, 1986, RADIOLOGICAL HLTH B, V20
   LEVESON N, 1986, ACM COMPUT SURV, V18, P25
   LEVESON NG, 1991, COMMUN ACM, V34, P34, DOI 10.1145/102792.102799
   MILLER E, 1987, P C STATE RAD CONTRO
   RAWLINSON JA, 1987, MAY OCTRF OCI PHYS M
   RUCKELSHAUS WD, 1984, RISK ANAL, V4, P157, DOI 10.1111/j.1539-6924.1984.tb00135.x
   RYDER EA, 1984, C EUROPEAN MAJOR HAZ
   1989, GAOPEMD906
NR 11
TC 352
Z9 361
U1 2
U2 60
PD JUL
PY 1993
VL 26
IS 7
BP 18
EP 41
DI 10.1109/MC.1993.274940
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Le Jeune, L
   Sateesan, A
   Rabbani, MM
   Goedemé, T
   Vliegen, J
   Mentens, N
AF Le Jeune, Laurens
   Sateesan, Arish
   Rabbani, Md Masoom
   Goedeme, Toon
   Vliegen, Jo
   Mentens, Nele
BE Batina, L
   Picek, S
   Mondal, M
TI SoK - Network Intrusion Detection on FPGA
SO SECURITY, PRIVACY, AND APPLIED CRYPTOGRAPHY ENGINEERING, SPACE 2021
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 11th International Conference on Security, Privacy, and Applied
   Cryptography Engineering (SPACE)
CY DEC 10-13, 2021
CL IIT Kharagpur, ELECTR NETWORK
HO IIT Kharagpur
DE Network intrusion detection; Deep learning; FPGA
ID EXTREME LEARNING-MACHINE; BINARY NEURAL-NETWORKS; ALGORITHMS; SKETCH
AB The amount of Internet traffic is ever increasing. With a well maintained network infrastructure, people find their way to Internet forums, video streaming services, social media and webshops on a day-to-day basis. With the growth of the online world, criminal activities have also spread out to the Internet. Security researchers and system administrators develop and maintain infrastructures to control these possible threats. This work focuses on one aspect of network security: intrusion detection. An Intrusion Detection System (IDS) is only one of the many components in the security engineer's toolbox. An IDS is a passive component that tries to detect malicious activities. With the increase of Internet traffic and bandwidth, the detection speed of IDSs needs to be improved accordingly. This work focuses on how Field-programmable Gate Arrays (FPGA) are used as hardware accelerators to assist the IDS in keeping up with high network speed. We give an overview of three approaches: Intrusion detection based on machine learning, pattern matching, and large flow detection. This work is concluded with a comparison between the three approaches on the most relevant metrics.
C1 [Le Jeune, Laurens; Sateesan, Arish; Rabbani, Md Masoom; Vliegen, Jo; Mentens, Nele] Katholieke Univ Leuven, ESAT, ES&S Imec COSIC, Leuven, Belgium.
   [Le Jeune, Laurens; Goedeme, Toon] Katholieke Univ Leuven, ESAT, EAVISE PSI, Leuven, Belgium.
   [Mentens, Nele] Leiden Univ, LIACS, Leiden, Netherlands.
RP Mentens, N (corresponding author), Katholieke Univ Leuven, ESAT, ES&S Imec COSIC, Leuven, Belgium.; Mentens, N (corresponding author), Leiden Univ, LIACS, Leiden, Netherlands.
EM laurensle.jeune@kuleuven.be; arish.sateesan@kuleuven.be;
   mdmasoom.rabbani@kuleuven.be; toon.goedem@kuleuven.be;
   jo.vliegen@kuleuven.be; nele.mentens@kuleuven.be
CR AbuHmed T., 2008, ARXIV PREPRINT ARXIV
   Al-Dalky R, 2014, INT WIREL COMMUN, P869, DOI 10.1109/IWCMC.2014.6906470
   Al-Hisnawi M., 2017, 2017 NTICT
   Al-Qatf M, 2018, IEEE ACCESS, V6, P52843, DOI 10.1109/ACCESS.2018.2869577
   Al-Yaseen WL, 2017, EXPERT SYST APPL, V67, P296, DOI 10.1016/j.eswa.2016.09.041
   Alrawashdeh K, 2017, PROC NAECON IEEE NAT, P57, DOI 10.1109/NAECON.2017.8268745
   [Anonymous], 2007, IEEE GLOBECOM 2007 I
   Artan N.S., 2005, GLOBECOM 2005, V3
   Barrera D, 2017, COMMUN ACM, V60, P56, DOI 10.1145/3085591
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Ceska M, 2019, 2019 IEEE 27 ANN INT
   Ceska M, 2018, LECT NOTES COMPUT SC, V10806, P155, DOI 10.1007/978-3-319-89963-3_9
   CISCO, 2015, CISCO IOS NETFLOW VE
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Das A, 2008, IEEE T INF FOREN SEC, V3, P118, DOI 10.1109/TIFS.2007.916288
   Dharmapurikar S, 2003, HOT INTERCONNECTS 11, P44
   Dharmapurikar S, 2006, IEEE J SEL AREA COMM, V24, P1781, DOI 10.1109/JSAC.2006.877131
   Dreger H., 2004, ACM CCS
   Ngo DM, 2019, L N INST COMP SCI SO, V298, P47, DOI 10.1007/978-3-030-34365-1_5
   Ngo DM, 2020, MOBILE NETW APPL, V25, P1178, DOI 10.1007/s11036-019-01437-x
   Fan B, 2014, PROCEEDINGS OF THE 2014 CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT'14), P75, DOI 10.1145/2674005.2674994
   FLAJOLET P, 1985, J COMPUT SYST SCI, V31, P182, DOI 10.1016/0022-0000(85)90041-8
   Gordon H., 2021, 2021 IEEE INT S LOC
   Harwayne-Gidansky J., 2009, IEEE SOUTHEASTCON 20
   Ho T, 2018, IET INFORM SECUR, V12, P381, DOI 10.1049/iet-ifs.2017.0421
   Ioannou L, 2019, I C FIELD PROG LOGIC, P232, DOI 10.1109/FPL.2019.00043
   Kang J, 2019, IEEE SYMP COMP COMMU, P1199, DOI 10.1109/iscc47284.2019.8969630
   KDD Cup, 1999, DATA
   Kefu X., 2008, 2008 IEEE ICNSC
   Khan MA, 2021, PROCESSES, V9, DOI 10.3390/pr9050834
   Kim DS, 2003, LECT NOTES COMPUT SC, V2662, P747
   Krishnamurthy P., 2003, P 2003 C APPL TECHN
   Lai YK, 2020, ASIAPAC SIGN INFO PR, P1566
   Le Jeune L., 2021, ACNS WORKSH
   Li CX, 2021, COMPUT SECUR, V106, DOI 10.1016/j.cose.2021.102271
   Li Y.Z., 2009, 2009 INT C NETW SEC, V1
   Lin PC, 2009, IEEE T VLSI SYST, V17, P1008, DOI 10.1109/TVLSI.2008.2012011
   Liu L, 2021, IEEE ACCESS, V9, P7550, DOI 10.1109/ACCESS.2020.3048198
   Liu Z., 2021, 30 USENIX SEC 21
   Liu ZX, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P101, DOI 10.1145/2934872.2934906
   Lopez-Martin M, 2019, EXPERT SYST APPL, V124, P196, DOI 10.1016/j.eswa.2019.01.063
   Luinaud T., 2017, GLSVLSI 2017
   Maciel L.A., 2020, IEEE T CIRC SYST 2 E, V67, P459
   MORRIS R, 1978, COMMUN ACM, V21, P840, DOI 10.1145/359619.359627
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Mukkamala S, 2002, IEEE IJCNN, P1702, DOI 10.1109/IJCNN.2002.1007774
   Murovic T, 2021, COMPUT COMMUN, V179, P1, DOI 10.1016/j.comcom.2021.07.015
   Murovic T, 2020, MICROELECTRON J, V97, DOI 10.1016/j.mejo.2020.104724
   Murovic T, 2019, ELEKTROTEH VESTN, V86, P47
   Pappalardo A., 2021, XILINXBREVITAS, DOI DOI 10.5281/ZENODO.3333552
   Pati S., 2007, ICFPT
   Pfahringer B, 2000, SIGKDD EXPLORATIONS, V2, P65, DOI [10.1145/846183.846200, DOI 10.1145/846183.846200]
   Roh JH, 2020, IEEE IND ELEC, P2121, DOI [10.1109/iecon43393.2020.9255158, 10.1109/IECON43393.2020.9255158]
   Saavedra A, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P38, DOI 10.1109/DSD.2018.00022
   Sateesan A., P 2021 31 INT C FIEL, P219
   Sateesan A, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P262, DOI 10.1109/DSD51259.2020.00050
   Scherrer Simon, 2021, ARXIV PREPRINT ARXIV
   Schweller R, 2007, IEEE ACM T NETWORK, V15, P1059, DOI 10.1109/TNET.2007.896150
   sFlow, 2003, TRAFF MON US FLOW
   Tavallaee M., 2009, IEEE S COMP INT SEC, P1
   Tong D., 2016, ACM SIGARCH COMPUT A, V43, P70
   Tong D, 2018, IEEE T PARALL DISTR, V29, P929, DOI 10.1109/TPDS.2017.2766633
   Tran C., 2017, NAFOSTED NICS 2017
   Umuroglu Y., 2020, FPL 2020
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wada T., 2018, 2018 6 CAN DAR
   Wang X, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P631
   Wang ZD, 2021, IEEE ACCESS, V9, P16062, DOI 10.1109/ACCESS.2021.3051074
   Wellem T., 2016, IEEE 17 HPSR
   Yang T, 2019, IEEE INFOCOM SER, P2017, DOI [10.1109/INFOCOM.2019.8737531, 10.1109/infocom.2019.8737531]
   Yang T, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P561, DOI 10.1145/3230543.3230544
   Yu Y, 2017, LECT NOTES ARTIF INT, V10571, P144, DOI 10.1007/978-3-319-67422-3_13
   Zazo J.F., 2017, PROC INT CONF RECON, P1
   Zhang J, 2008, IEEE T SYST MAN CY C, V38, P649, DOI 10.1109/TSMCC.2008.923876
   Zhao Z., 2020, 14 USENIX OSDI20
   Zhou Y, 2019, P ACM MEAS ANAL COMP, V3, DOI 10.1145/3366699
NR 77
TC 0
Z9 0
U1 0
U2 3
PY 2022
VL 13162
BP 242
EP 261
DI 10.1007/978-3-030-95085-9_13
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Kala, S
   Mathew, J
   Jose, BR
   Nalesh, S
AF Kala, S.
   Mathew, Jimson
   Jose, Babita R.
   Nalesh, S.
GP IEEE
TI UniWiG: Unified Winograd-GEMM Architecture for Accelerating CNN on FPGAs
SO 2019 32ND INTERNATIONAL CONFERENCE ON VLSI DESIGN AND 2019 18TH
   INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS (VLSID)
SE International Conference on VLSI Design
DT Proceedings Paper
CT 32nd International Conference on VLSI Design (VLSID) / 18th
   International Conference on Embedded Systems (ES)
CY JAN 05-09, 2019
CL New Delhi, INDIA
DE CNN; Deep learning; FPGA; Machine learning
AB Convolutional Neural Networks (CNN) have emerged as the most efficient technique for solving a host of machine learning tasks, especially in image and video processing domains. However deploying CNNs on computing systems with smaller form factors have found to be extremely challenging due to the complex nature of CNNs. Hardware acceleration of CNNs using FPGAs have emerged as a promising approach due to high performance, energy efficiency and reconfigurability of FPGAs. Winograd filtering based convolution is the most efficient algorithm for calculating convolution for smaller filter sizes. In this paper, we propose a unified architecture named UniWiG, where both Winograd based convolution and general matrix multiplication (GEMM) can be accelerated using the same set of processing elements. This enables efficient utilization of FPGA hardware resources for accelerating all the layers in the CNNs. The proposed architecture has been used to accelerate AlexNet CNN, which shows performance improvement in the range of 1.4 x to 4.02 x with only 13% additional FPGA resources than state-of-art GEMM accelerator. We have also analyzed the performance with varying Winograd tile sizes and found out the most appropriate tile sizes for maximizing the performance while reducing on-chip memory resources.
C1 [Kala, S.; Jose, Babita R.] Cochin Univ Sci & Technol, Sch Engn, Kochi, Kerala, India.
   [Mathew, Jimson] Indian Inst Technol Patna, Dept Comp Sci, Patna, Bihar, India.
   [Nalesh, S.] Cochin Univ Sci & Technol, Dept Elect, Kochi, Kerala, India.
RP Kala, S (corresponding author), Cochin Univ Sci & Technol, Sch Engn, Kochi, Kerala, India.
EM kalas@cusat.ac.in; jimson@iitp.ac.in; babitajose@cusat.ac.in;
   nalesh@cusat.ac.in
CR [Anonymous], 2016, IEEE CVPR
   Chakradhar Srimat, ACM ISCA 2010
   DiCecco Roberto, IEEE FPT 2016
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Krizhevsky A., NIPS 2012
   Li Huimin, FPL 2016
   Lu Liqiang, 2017, IEEE FCCM
   Ma Yufei, FPL 2016
   Mathieu Michael, ICLR 2014
   Motamedi Mohammad, IEEE ASP DAC 2016
   Peemen Maurice, IEEE ICCD 2013
   Qiu Jiantao, ACM SIGDA FPGA 2016
   Shen Junzhong, IEEE ISCAS 2018
   Simonyan Karen, ICLR 2015
   Zhang Chen, ACM SIGDA FPGA 2015
NR 15
TC 10
Z9 12
U1 0
U2 11
PY 2019
BP 209
EP 214
DI 10.1109/VLSID.2019.00055
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Seng, KP
   Lee, PJ
   Ang, LM
AF Seng, Kah Phooi
   Lee, Paik Jen
   Ang, Li Minn
TI Embedded Intelligence on FPGA: Survey, Applications and Challenges
SO ELECTRONICS
DT Review
DE embedded intelligence; FPGA; embedded systems; deep learning; neural
   networks; artificial intelligence
ID CONVOLUTIONAL NEURAL-NETWORKS; ACCELERATOR; IMPLEMENTATION;
   ARCHITECTURE; RECOGNITION; SENSORS; SYSTEMS
AB Embedded intelligence (EI) is an emerging research field and has the objective to incorporate machine learning algorithms and intelligent decision-making capabilities into mobile and embedded devices or systems. There are several challenges to be addressed to realize efficient EI implementations in hardware such as the need for: (1) high computational processing; (2) low power consumption (or high energy efficiency); and (3) scalability to accommodate different network sizes and topologies. In recent years, an emerging hardware technology which has demonstrated strong potential and capabilities for EI implementations is the FPGA (field programmable gate array) technology. This paper presents an overview and review of embedded intelligence on FPGA with a focus on applications, platforms and challenges. There are four main classification and thematic descriptors which are reviewed and discussed in this paper for EI: (1) EI techniques including machine learning and neural networks, deep learning, expert systems, fuzzy intelligence, swarm intelligence, self-organizing map (SOM) and extreme learning; (2) applications for EI including object detection and recognition, indoor localization and surveillance monitoring, and other EI applications; (3) hardware and platforms for EI; and (4) challenges for EI. The paper aims to introduce interested researchers to this area and motivate the development of practical FPGA solutions for EI deployment.
C1 [Seng, Kah Phooi] Univ New South Wales UNSW Adfa, Sch Engn & Informat Technol, Canberra, ACT 2612, Australia.
   [Lee, Paik Jen; Ang, Li Minn] Univ Sunshine Coast, Sch Sci Technol & Engn, Petrie, Qld 4502, Australia.
   [Lee, Paik Jen] Natl Instruments M, George Town 11960, Malaysia.
RP Seng, KP (corresponding author), Univ New South Wales UNSW Adfa, Sch Engn & Informat Technol, Canberra, ACT 2612, Australia.
EM k.seng@unsw.edu.au; lee.p.jen@outlook.com; lang@usc.edu.au
CR Afifi A, 2011, INT J CIRC THEOR APP, V39, P357, DOI 10.1002/cta.638
   Alsop T, INTEL S PROGRAMMABLE, DOI 1096397/intel-programmable-solutions-group-revenue/
   Ang L. M., 2013, WIRELESS MULTIMEDIA
   [Anonymous], 2019, XIL REP REC REV EXC
   [Anonymous], 2020, FPGA LEAD MULT PROC
   [Anonymous], 2020, PID FUZZ LOG TOOLK
   [Anonymous], 2012, PID FUZZ LOG TOOLK
   [Anonymous], SNN NEWS
   [Anonymous], 2016, ARXIV170406756
   [Anonymous], 2019, VK REINV STOR SOC NE
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], 2020, SPEEDST 7T FPGAS
   [Anonymous], 2011, XIL PROV TWITCH PLUG
   [Anonymous], OBJECT DETECTION SPE
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Appiah K, 2012, IEEE T CIRC SYST VID, V22, P1150, DOI 10.1109/TCSVT.2012.2197077
   Biswas A, 2014, COMPUT INTELL-US, V319, P253
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Bottou L., 2007, LARGE SCALE KERNEL M, V3, P320
   Bouganis C.-S., P 2015 25 INT C FIEL, P1
   Calazan RM, 2014, APPL SOFT COMPUT, V14, P347, DOI 10.1016/j.asoc.2012.12.034
   Chattapadhyay P., P 2015 INT C EN POW, P1
   Chen H., P 2019 IEEE 21 INT C, P1674
   Chen VC, 2008, IET SIGNAL PROCESS, V2, P291, DOI 10.1049/iet-spr:20070137
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Hao C, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON E-BUSINESS, INFORMATION MANAGEMENT AND COMPUTER SCIENCE, P1, DOI 10.1145/3210506.3210507
   Chew LW, 2012, INT J SENS NETW, V11, P33, DOI 10.1504/IJSNET.2012.045033
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Das S.R., P 7 C EM NETW EXP TE, P1
   de Sousa MAD, 2020, NEURAL NETWORKS, V125, P349, DOI 10.1016/j.neunet.2020.02.019
   Del-Moral-Hernandez E., P 2017 IEEE INT S CI, P1
   Ding W, 2019, J SYST ARCHITECT, V97, P278, DOI 10.1016/j.sysarc.2018.12.008
   Diniz WFS, 2017, MICROPROCESS MICROSY, V52, P261, DOI 10.1016/j.micpro.2017.06.013
   Dorigo M, 2005, THEOR COMPUT SCI, V344, P243, DOI 10.1016/j.tcs.2005.05.020
   [段英宏 DUAN Yinghong], 2006, [计算机仿真, Computer Simulation], V23, P290
   Eberchart J.K.R, P IEEE INT C NEUR NE
   Farabet Clement, 2009, 2009 IEEE 12th International Conference on Computer Vision Workshops, ICCV Workshops, P878, DOI 10.1109/ICCVW.2009.5457611
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Faraone J, 2020, IEEE T VLSI SYST, V28, P115, DOI 10.1109/TVLSI.2019.2939429
   Frances-Villora JV, 2016, COMPUT ELECTR ENG, V51, P139, DOI 10.1016/j.compeleceng.2016.02.007
   García GJ, 2014, SENSORS-BASEL, V14, P6247, DOI 10.3390/s140406247
   Gaydadjiev G.N., P 3 HIPEAC WORKSH RE, P41
   Ghaffari A, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9122200
   Gilbert E G., 1966, SIAM J CONTROL, V4, P61
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Hanh PX, 2019, PROCEDIA COMPUT SCI, V151, P651, DOI 10.1016/j.procs.2019.04.087
   Hu QS, 2020, IEEE SENS J, V20, P8007, DOI 10.1109/JSEN.2020.2980207
   Jaksic Z, 2020, FUTURE GENER COMP SY, V104, P201, DOI 10.1016/j.future.2019.10.025
   Kale I., P 2003 INT S CIRC SY, VVolume 4, pIV
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Kim SK, 2009, I C FIELD PROG LOGIC, P367, DOI 10.1109/FPL.2009.5272262
   Lachmair J, 2017, IEEE IJCNN, P4299, DOI 10.1109/IJCNN.2017.7966400
   LeCun Y, 1999, LECT NOTES COMPUT SC, V1681, P319, DOI 10.1007/3-540-46805-6_19
   Lei P, 2019, IEEE ACCESS, V7, P88917, DOI 10.1109/ACCESS.2019.2926381
   Li DL, 2018, IEEE ACCESS, V6, P72327, DOI 10.1109/ACCESS.2018.2882455
   Li S, 2020, IEEE ACCESS, V8, P105455, DOI 10.1109/ACCESS.2020.3000009
   Lin K, 2016, IEEE T AUTOM SCI ENG, V13, P1294, DOI 10.1109/TASE.2016.2543242
   Liu C, 2020, IEEE ACCESS, V8, P65609, DOI 10.1109/ACCESS.2020.2985162
   Liu SS, 2019, P IEEE, V107, P1697, DOI 10.1109/JPROC.2019.2915983
   Liu X, 2018, PROCEDIA COMPUT SCI, V141, P104, DOI 10.1016/j.procs.2018.10.155
   Liu Y., P 2010 2 INT C COMP, VVolume 4, P402
   Liu Z, P AAAI C ART NEW ORL
   Liviu T, P 2018 22 INT C SYST
   Lopes FE, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060631
   Luo C, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/2/022403
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   McKenna M, 2001, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2001.939015
   Nurvitadhi E., P 2018 ACM SIGDA INT, P107
   Olson C.B, P 2012 IEEE 20 INT S
   Parpinelli RS, 2011, INT J BIO-INSPIR COM, V3, P1, DOI 10.1504/IJBIC.2011.038700
   Poddar S., P 2020 4 INT C COMP, P471
   Rahaman H., P 2020 INT S DEV CIR, P1
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sato S., P 2018 ACM SIGDA INT, P31
   Shafique M., P 2018 IEEE INT S CI, P1
   Shan Y, 2018, I C FIELD PROG LOGIC, P465, DOI 10.1109/FPL.2018.00092
   Shaout A., P 2017 INT C NEW TRE
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Spadotto AA, 2008, 2008 3RD INTERNATIONAL SYMPOSIUM ON COMMUNICATIONS, CONTROL AND SIGNAL PROCESSING, VOLS 1-3, P735, DOI 10.1109/ISCCSP.2008.4537320
   Struharik RJR, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102991
   Suda N, P 2016 ACM SIGDA INT
   Trimberger Stephen M. Steve, 2018, IEEE Solid-State Circuits Magazine, V10, P16, DOI 10.1109/MSSC.2018.2822862
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Van Broekhoven E, 2008, FUZZY SET SYST, V159, P2819, DOI 10.1016/j.fss.2008.03.014
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Véstias MP, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103136
   Wang C, 2020, IEEE T PARALL DISTR, V31, P2346, DOI 10.1109/TPDS.2020.2990924
   Wang XY, 2015, IEEE WCNC, P1666, DOI 10.1109/WCNC.2015.7127718
   Xie T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19183983
   Xue JY, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P3005
   Yoon YH, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9071169
   Youssef M, 2005, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES (MOBISYS 2005), P205, DOI 10.1145/1067170.1067193
   YU HJ, 2000, INTELLIGENT DIAGNOSI
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang F., P 2018 IEEE 4 INT C, P2075
   Zhao SR, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P263, DOI 10.1109/ICFPT47387.2019.00043
NR 100
TC 31
Z9 31
U1 30
U2 159
PD APR
PY 2021
VL 10
IS 8
AR 895
DI 10.3390/electronics10080895
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU IENNE, P
   VIREDAZ, MA
AF IENNE, P
   VIREDAZ, MA
TI GENES-IV - A BIT-SERIAL PROCESSING ELEMENT FOR A MULTIMODEL
   NEURAL-NETWORK ACCELERATOR
SO JOURNAL OF VLSI SIGNAL PROCESSING
DT Article
AB A systolic array of dedicated processing elements (PEs) is presented as the heart of a multi-model neural-network accelerator.  The instruction set of the PEs makes possible to implement several widely-used neural models, including multi-layer Perceptrons with the back-propagation learning rule and Kohonen feature maps.  Each PE holds an element of the synaptic weight matrix.  An instantaneous swapping mechanism for the weight matrix makes the efficient implementation of neural networks larger than the physical PE array possible.  A systolically-flowing instruction accompanies each input vector propagating in the array.  This avoids the need of emptying and refilling the array when the operating mode of the array is changed.  Fixed point arithmetic is used in the PE.  The problem of optimally scaling real variables in fixed-point format is addressed.
   Both the GENES IV chip, containing a matrix of 2 x 2 PEs, and an auxiliary arithmetic circuit have been manufactured and successfully tested.  The MANTRA I machine has been built around these chips.  Peak performances of the full system are between 200 and 400 MCPS in the evaluation phase and between 100 and 200 MCUPS during the learning phase (depending on the algorithm being implemented).
RP IENNE, P (corresponding author), SWISS FED INST TECHNOL,MICROCOMP LAB,IN-F ECUBLENS,CH-1015 LAUSANNE,SWITZERLAND.
CR [Anonymous], 1993, TIME SERIES PREDICTI
   Asanovic K., 1991, 2ND P INT C MICR NEU, P9
   BATTITI R, 1992, NEURAL COMPUT, V4, P141, DOI 10.1162/neco.1992.4.2.141
   BLAYO F, 1990, THESIS ECOLE POLYTEC
   DADDA L, 1985, 7TH IEEE COMP AR, P57
   Hertz J.A., 1991, INTRO THEORY NEURAL
   HOLT JL, 1991, JUL P INT JOINT C NE
   IENNE P, 1994, IEEE T COMPUT, V43, P1445, DOI 10.1109/12.338107
   LEHMANN C, 1993, THESIS ECOLE POLYTEC
   MAUDUIT N, 1992, IEEE T NEURAL NETWOR, V3, P414, DOI 10.1109/72.129414
   MORGAN N, 1992, J PARALLEL DISTR COM, V14, P248, DOI 10.1016/0743-7315(92)90067-W
   MULLER UA, 1992, IEEE MICRO, P55
   Ramacher U., 1991, VLSI Design of Neural Networks, P271
   SATO Y, 1993, OCT P INT JOINT C NE, V2, P1967
   THIRAN P, 1994, IEEE T NEURAL NETWOR, V5, P450, DOI 10.1109/72.286915
   VIREDAZ MA, 1993, OCT P EUR ARCH 93 C, P99
   YASUNAGA M, 1991, JUL P INT JOINT C NE, P1844
   1994, CNAPS SERVER 2
NR 18
TC 10
Z9 10
U1 0
U2 1
PD APR
PY 1995
VL 9
IS 3
BP 257
EP 273
DI 10.1007/BF02407088
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Moreau, N
   Bonnor, L
   Jaudet, C
   Lechippey, L
   Falzone, N
   Batalla, A
   Bertaut, C
   Corroyer-Dulmont, A
AF Moreau, Noemie
   Bonnor, Laurine
   Jaudet, Cyril
   Lechippey, Laetitia
   Falzone, Nadia
   Batalla, Alain
   Bertaut, Cindy
   Corroyer-Dulmont, Aurelien
TI Deep Hybrid Learning Prediction of Patient-Specific Quality Assurance in
   Radiotherapy: Implementation in Clinical Routine
SO DIAGNOSTICS
DT Article
DE machine learning; deep hybrid learning; radiotherapy; VMAT; quality
   assurance; clinical routine
ID CLASSIFICATION-REGRESSION MODEL; PLAN COMPLEXITY; QA; IMRT
AB Background: Arc therapy allows for better dose deposition conformation, but the radiotherapy plans (RT plans) are more complex, requiring patient-specific pre-treatment quality assurance (QA). In turn, pre-treatment QA adds to the workload. The objective of this study was to develop a predictive model of Delta4-QA results based on RT-plan complexity indices to reduce QA workload. Methods. Six complexity indices were extracted from 1632 RT VMAT plans. A machine learning (ML) model was developed for classification purpose (two classes: compliance with the QA plan or not). For more complex locations (breast, pelvis and head and neck), innovative deep hybrid learning (DHL) was trained to achieve better performance. Results. For not complex RT plans (with brain and thorax tumor locations), the ML model achieved 100% specificity and 98.9% sensitivity. However, for more complex RT plans, specificity falls to 87%. For these complex RT plans, an innovative QA classification method using DHL was developed and achieved a sensitivity of 100% and a specificity of 97.72%. Conclusions. The ML and DHL models predicted QA results with a high degree of accuracy. Our predictive QA online platform is offering substantial time savings in terms of accelerator occupancy and working time.
C1 [Moreau, Noemie; Bonnor, Laurine; Jaudet, Cyril; Lechippey, Laetitia; Batalla, Alain; Corroyer-Dulmont, Aurelien] CLCC Francois Baclesse, Med Phys Dept, F-14000 Caen, France.
   [Falzone, Nadia] Genesis Care Theranost, Bldg 1 & 11,Mill,41-43 Bourke Rd, Alexandria, NSW 2015, Australia.
   [Bertaut, Cindy] Cherbourg Hosp, Med Phys Dept, F-50100 Cherbourg, France.
   [Corroyer-Dulmont, Aurelien] Normandie Univ, UNICAEN, CNRS, ISTCT, F-14000 Caen, France.
RP Corroyer-Dulmont, A (corresponding author), CLCC Francois Baclesse, Med Phys Dept, F-14000 Caen, France.; Corroyer-Dulmont, A (corresponding author), Normandie Univ, UNICAEN, CNRS, ISTCT, F-14000 Caen, France.
EM a.corroyer-dulmont@baclesse.unicancer.fr
CR Agazaryan Nzhde, 2003, J Appl Clin Med Phys, V4, P40, DOI 10.1120/1.1525243
   [Anonymous], 2020, AN SOFTW DISTR
   Antoine M, 2019, PHYS MEDICA, V64, P98, DOI 10.1016/j.ejmp.2019.05.024
   Chan MF, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.577620
   Chiavassa S, 2019, BRIT J RADIOL, V92, DOI 10.1259/bjr.20190270
   Chollet F., 2015, KERAS
   Chow VUY, 2020, J APPL CLIN MED PHYS, V21, P179, DOI 10.1002/acm2.13053
   Corroyer-Dulmont A., 2022, DEEP HYBRID LEARNING
   Darzidehkalani Erfan, 2022, J Am Coll Radiol, V19, P969, DOI 10.1016/j.jacr.2022.03.015
   Defoor DL, 2015, J APPL CLIN MED PHYS, V16, P206, DOI 10.1120/jacmp.v16i3.5283
   Ge YR, 2019, MED PHYS, V46, P2760, DOI 10.1002/mp.13526
   Granville DA, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab142e
   Hirashima H, 2020, RADIOTHER ONCOL, V153, P250, DOI 10.1016/j.radonc.2020.07.031
   Hunter JD, 2007, COMPUT SCI ENG, V9, P90, DOI 10.1109/MCSE.2007.55
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Jazouli Z., 2021, RADIOTHER ONCOL, V92, pS87, DOI [10.1016/S1120-1797(22)00184-3, DOI 10.1016/S1120-1797(22)00184-3]
   Khan SH, 2021, COMPUT BIOL MED, V137, DOI 10.1016/j.compbiomed.2021.104816
   Kimura Y, 2020, PHYS MEDICA, V73, P57, DOI 10.1016/j.ejmp.2020.03.022
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kubben P, 2019, FUNDAMENTALS OF CLINICAL DATA SCIENCE, P1, DOI 10.1007/978-3-319-99713-1
   Legrand C., PHYS MED, V44, P24
   Lemaître G, 2017, J MACH LEARN RES, V18
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Miften M, 2018, MED PHYS, V45, pE53, DOI 10.1002/mp.12810
   Otto K, 2008, MED PHYS, V35, P310, DOI 10.1118/1.2818738
   Sadowski B, 2022, J PERS MED, V12, DOI 10.3390/jpm12122071
   Savjani RR, 2021, RADIOL-IMAG CANCER, V3, DOI 10.1148/rycan.2021200075
   Shen CY, 2023, J APPL CLIN MED PHYS, V24, DOI 10.1002/acm2.13918
   Simon L, 2021, CANCER RADIOTHER, V25, P623, DOI 10.1016/j.canrad.2021.06.012
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Wang L, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/abb31c
   Waskom ML., 2021, J OPEN SOURCE SOFTW, V6, P3021, DOI DOI 10.21105/JOSS.03021
   Yang RJ, 2021, RADIOTHER ONCOL, V161, P230, DOI 10.1016/j.radonc.2021.06.024
NR 33
TC 0
Z9 0
U1 2
U2 2
PD MAR
PY 2023
VL 13
IS 5
AR 943
DI 10.3390/diagnostics13050943
WC Medicine, General & Internal
DA 2023-11-11
ER

PT C
AU Hanif, MA
   Shafique, M
AF Hanif, Muhammad Abdullah
   Shafique, Muhammad
GP IEEE
TI Dependable Deep Learning: Towards Cost-Efficient Resilience of Deep
   Neural Network Accelerators against Soft Errors and Permanent Faults
SO 2020 26TH IEEE INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN (IOLTS 2020)
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 26th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 13-16, 2020
CL ELECTR NETWORK
DE Reliability; Dependability; Cost; Efficiency; Deep Learning; DL; Deep
   Neural Networks; DNNs; Faults; Soft Errors; Aging; Permanent Faults;
   Manufacturing Defects; Yield; Resilience; Robustness; Systems;
   Architecture; Accelerator
ID TRENDS
AB Deep Learning has enabled machines to learn computational models (i.e., Deep Neural Networks - DNNs) that can perform certain complex tasks with claims to be close to human-level precision. This state-of-the-art performance offered by DNNs in many Artificial Intelligence (AI) applications has paved their way to being used in several safety-critical applications where even a single failure can lead to catastrophic results. Therefore, improving the robustness of these models to hardware-induced faults (such as soft errors, aging, and manufacturing defects) is of significant importance to avoid any disastrous event. Traditional redundancy-based fault mitigation techniques cannot be employed in a wide of applications due to their high overheads, which, when coupled with the compute-intensive nature of DNNs, lead to undesirable resource consumption. In this article, we present an overview of different low-cost fault-mitigation techniques that exploit the intrinsic characteristics of DNNs to limit their overheads. We discuss how each technique can contribute to the overall resilience of a DNN-based system, and how they can be integrated together to offer resilience against multiple diverse hardware-induced reliability threats. Towards the end, we highlight several key future directions that are envisioned to help in achieving highly dependable DL-based systems.
C1 [Hanif, Muhammad Abdullah; Shafique, Muhammad] Tech Univ Wien TU Wien, Vienna, Austria.
RP Hanif, MA (corresponding author), Tech Univ Wien TU Wien, Vienna, Austria.
EM muhammad.hanif@tuwien.ac.at; muhammad.shafique@tuwien.ac.at
CR Al-Qizwini M, 2017, IEEE INT VEH SYM, P89, DOI 10.1109/IVS.2017.7995703
   [Anonymous], 2011, ROAD VEHICLES FUNCTI
   Azizi A, 2019, INT J INTERACT DES M, V13, P373, DOI 10.1007/s12008-018-0501-9
   Baumann RC, 2005, IEEE T DEVICE MAT RE, V5, P305, DOI 10.1109/TDMR.2005.853449
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen Z., 2019, ACM HPCA, P69
   Chen Z., 2020, ARXIV200313874
   Chu L.-C., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P639, DOI 10.1109/IJCNN.1990.137773
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Fawaz HI, 2019, DATA MIN KNOWL DISC, V33, P917, DOI 10.1007/s10618-019-00619-1
   Guo J, 2014, IEEE T CIRCUITS-I, V61, P1994, DOI 10.1109/TCSI.2014.2304658
   Guo YM, 2016, NEUROCOMPUTING, V187, P27, DOI 10.1016/j.neucom.2015.09.116
   Hanif MA, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0164
   Hanif MA, 2018, IEEE INT ON LINE, P257, DOI 10.1109/IOLTS.2018.8474192
   Hoang L., 2020, IEEE DATE
   Huval B., 2015, COMPUTER VISION PATT
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim S, 2018, IEEE T CIRCUITS-I, V65, P4285, DOI 10.1109/TCSI.2018.2839613
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Limbrick DB, 2013, IEEE T NUCL SCI, V60, P2776, DOI 10.1109/TNS.2013.2240699
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   LYONS RE, 1962, IBM J RES DEV, V6, P200, DOI 10.1147/rd.62.0200
   Marchisio A, 2019, IEEE COMP SOC ANN, P555, DOI 10.1109/ISVLSI.2019.00105
   Massa R, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207109
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mozaffari S., 2019, ARXIV191211676
   Naseer M, 2020, DES AUT TEST EUROPE, P666, DOI 10.23919/DATE48585.2020.9116247
   Prabakaran B. S., 2020, ARXIV200410491
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shafiq M. Zubair, 2013, Performance Evaluation Review, V41, P17
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Shankland S., MEET TESLAS SELF DRI
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Vadlamani R, 2010, DES AUT TEST EUROPE, P27
   Vera X, 2009, ACM T COMPUT SYST, V27, DOI 10.1145/1658357.1658359
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang J, 2018, IEEE VLSI TEST SYMP
   Zhao K., 2020, ARXIV200312203
NR 41
TC 9
Z9 9
U1 0
U2 1
PY 2020
DI 10.1109/iolts50870.2020.9159734
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Rong, LM
AF Rong, Limin
TI RETRACTED: Remote case teaching mode based on computer FPGA platform and
   data mining (Retracted article. See vol. 101, 2023)
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article; Retracted Publication
DE Remote cases; Teaching; Web-based learning; FPGA and data mining;
   Distance learning; Emulator program
AB The development of research and education. In the first two weeks, the same is accurate, and then a professor involved personally attended the Delft meeting. So, how to change the direction of distance learning. North Star (Polaris) has launched a research-based learning network to improve his education's efficiency, and knowledge poses a direct extension of his past used innovation. Compared with conventional courses, technical facilities more, Example: two computers for student PowerPoint presentations and Harvard small whiteboard, two powerful features for computer projection presentation projector, remote teachers and hall of Delft University of video images, distributed a microphone 50 for student desks discussed for open Delft coordinator hand microphone, a monitor control panel and several techniques, two cameras, focused on the projection wall the combined small webcam, teachers and for remote feedback of a large number of cables. Calendar clock design is called a case of Field-Programmable Gate Array (FPGA)-based digital electronic education programs to create research projects. The project aims to develop a case study of Project-Based Learning (PBL), a case study aimed at electronics/computer engineering students or a new digital circuit designer professor of digital design education. To achieve high-performance support using k-mean algorithm learning support. Calendar clock design is the second in a series of content-rich and engaging examples, designed to enhance use counters, multiplexers, comparators and decoder design skills to accomplish this simultaneously. Another option is to use a FieldProgrammable Gate Array (FPGA) device as a hardware accelerator. The application of data mining FPGA hardware accelerators. Three kinds of data mining algorithms: tree classification and regression trees, support vector machine and k-means clustering.
C1 [Rong, Limin] Northeast Normal Univ, Sch Business, Changchun 130117, Jilin, Peoples R China.
RP Rong, LM (corresponding author), Northeast Normal Univ, Sch Business, Changchun 130117, Jilin, Peoples R China.
EM nenumba@126.com
CR [Anonymous], 2013, 6922013 IEEE, P1, DOI DOI 10.1109/IEEESTD.2013.6613502
   Bai Y., 2016, P IEEE NPSS REAL TIM, DOI [10.1109/etc.2016.7543135, DOI 10.1109/ETC.2016.7543135]
   Bai YP, 2017, IEEE T NUCL SCI, V64, P1219, DOI 10.1109/TNS.2017.2708510
   Balid W, 2013, IEEE GLOB ENG EDUC C, P23, DOI 10.1109/EduCon.2013.6530082
   Brown N, 2019, PROCEEDINGS OF H2RC 2019: 2019 FIFTH IEEE/ACM INTERNATIONAL WORKSHOP ON HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC), P1, DOI 10.1109/H2RC49586.2019.00006
   Byszuk A, 2013, PROC SPIE, V8903, DOI 10.1117/12.2035457
   Carra P., 2018, IEEE T RADIAT PLASMA, V1, DOI [10.1109/terms.2018.2882709, DOI 10.1109/TERMS.2018.2882709]
   Carra P., 2017, AUTOCALIBRATING TDC, DOI [10.1109/ICECENG.2011.6057173, DOI 10.1109/ICECENG.2011.6057173]
   Flores-Fuentes W., 2017, P IEEE 26 INT S IND, DOI [10.1109/sie.2017.8001494, DOI 10.1109/SIE.2017.8001494]
   Goodenough D.G., 2013, P INT GEOSC REM SENS, V1, P464, DOI [10.1109/IGARSS.1995.520310, DOI 10.1109/IGARSS.1995.520310]
   Guntha R, 2016, 2016 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P1833, DOI 10.1109/ICACCI.2016.7732315
   Hariharan R, 2017, 2017 7TH WORLD ENGINEERING EDUCATION FORUM (WEEF), P925, DOI 10.1109/WEEF.2017.8467022
   Junfang L., 2020, MICROPROCESS MICROSY
   Laird JS, 2013, NUCL INSTRUM METH B, V306, P71, DOI 10.1016/j.nimb.2012.12.045
   Liu P, 2022, MECH ADV MATER STRUC, V29, P1386, DOI 10.1080/15376494.2020.1821137
   Pasero E, 2005, BIOLOGICAL AND ARTIFICIAL INTELLIGENCE ENVIRONMENTS, P141, DOI 10.1007/1-4020-3432-6_17
   Pullen J.M., 2013, P FRONT ED FIE 96 26, V1, P285
   Samoila C, 2016, INT CONF REMOT ENGIN, P204, DOI 10.1109/REV.2016.7444466
   Tahghighi M, 2016, LECT NOTES COMPUT SC, P159, DOI 10.1007/978-3-319-30481-6_13
   Wu L., 2013, P 3 INT C ADV COMP T
NR 20
TC 2
Z9 3
U1 2
U2 15
PD JUN
PY 2021
VL 83
AR 103986
DI 10.1016/j.micpro.2021.103986
EA JAN 2021
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yuan, Y
   Virupakshappa, K
   Jiang, YY
   Oruklu, E
AF Yuan, Yu
   Virupakshappa, Kushal
   Jiang, Yiyue
   Oruklu, Erdal
GP IEEE
TI Comparison of GPU and FPGA based Hardware Platforms for Ultrasonic Flaw
   Detection using Support Vector Machines
SO 2017 IEEE INTERNATIONAL ULTRASONICS SYMPOSIUM (IUS)
SE IEEE International Ultrasonics Symposium
DT Proceedings Paper
CT IEEE International Ultrasonics Symposium (IUS)
CY SEP 06-09, 2017
CL Washington, DC
DE GPU; Support Vector Machine; NDT; flaw detection; TensorFlow
AB This study investigates the performance of different hardware platforms and development frameworks for efficient realization of an ultrasonic flaw detection algorithm based on the Support Vector Machine (SVM) classifier. The proposed algorithm is based on subband decomposition of ultrasonic signals followed by classification with a trained SVM model that uses subband filter outputs as feature inputs. Target host platforms include an FPGA-based Xilinx ZedBoard, a GPU-based Tegra System-on-Chip (SoC) and a high-performance computing (HPC) server with GPU accelerators. GPU development is done with CUDA library functions provided by NVIDIA and TensorFlow by Google. TensorFlow is a numerical computation library used primarily for building machine learning algorithms. RTL code for FPGA implementation is generated by System Generator tool by Xilinx. Implementation results show that while all platforms can achieve real-time operation with small data sets, scalability is a difficult challenge for embedded hardware. TensorFlow provides the shortest development time and enables code migration from servers to embedded systems.
C1 [Yuan, Yu; Virupakshappa, Kushal; Jiang, Yiyue; Oruklu, Erdal] IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
RP Yuan, Y (corresponding author), IIT, Dept Elect & Comp Engn, Chicago, IL 60616 USA.
CR Abadi M, 2016, TENSORFLOW LARGE SCA
   Bergstra  J., 2011, BIG LEARN WORKSH NIP
   Jia Y., 2014, P 22 ACM INT C MULTI
   Jiang Y., 2017, 2017 MIDW S CIRC SYS
   Oruklu, 2016, 2016 IEEE INT ULTR S, P1
   Oruklu E., 2011, SPRINGER J OFSIG SEP
   Virupakshappa K, 2015, IEEE INT ULTRA SYM, DOI 10.1109/ULTSYM.2015.0128
   Weber J, 2011, IEEE T IND ELECTRON, V58, P871, DOI 10.1109/TIE.2009.2030214
NR 8
TC 0
Z9 0
U1 0
U2 2
PY 2017
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Mannocci, P
   Baroni, A
   Melacarne, E
   Zambelli, C
   Olivo, P
   Pérez, E
   Wenger, C
   Ielmini, D
AF Mannocci, Piergiulio
   Baroni, Andrea
   Melacarne, Enrico
   Zambelli, Cristian
   Olivo, Piero
   Perez, Eduardo
   Wenger, Christian
   Ielmini, Daniele
GP IEEE
TI Experimental verification and benchmark of in-memory principal component
   analysis by crosspoint arrays of resistive switching memory
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
DE In-memory computing; resistive random access memory; hardware
   accelerator; principal component analysis
AB In-memory computing (IMC) is gaining momentum as the most promising candidate for the upcoming non-vonNeumann, machine learning-optimized computing paradigm. Its intrinsic parallelism is well-suited to accelerate matrix-vector multiplications (MVM), which prove challenging for traditional architectures and are a fundamental operation in principal component analysis (PCA), one of the most renowned algorithms for data classification. Here, we show an experimental demonstration of a novel, IMC-based PCA algorithm by inmemory power iteration and deflation executed in a 4-kbit array of resistive random-access memory (RRAM). Our algorithm achieves 95.25% classification accuracy on the Wisconsin Diagnostic Breast Cancer dataset, matching closely results of a floating-point machine while providing a 250x improvement in energy efficiency.
C1 [Mannocci, Piergiulio; Melacarne, Enrico; Ielmini, Daniele] Politecn Milan, Milan, Italy.
   [Baroni, Andrea; Zambelli, Cristian; Olivo, Piero] Univ Ferrara, Ferrara, Italy.
   [Perez, Eduardo; Wenger, Christian] IHP Microelect, Frankfurt, Germany.
RP Mannocci, P (corresponding author), Politecn Milan, Milan, Italy.
CR [Anonymous], ACTIVE TECHNOLOGIES
   [Anonymous], NVIDIA QUADRO RTX 80
   Bache K., 2013, BREAST CANC WISCONSI
   Bishop C.M., 2006, PATTERN RECOGN, DOI DOI 10.1007/978-0-387-45528-0
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jolliffe I., 2005, ENCY STAT BEHAV SCI, P1580, DOI [DOI 10.1002/0470013192.BSA501, 10.1002/0470013192.bsa501,3]
   Liu WY, 2017, INT CONF DAT MIN WOR, P134, DOI 10.1109/ICDMW.2017.23
   Milo V, 2021, IEEE T ELECTRON DEV, V68, P3832, DOI 10.1109/TED.2021.3089995
   Pérez E, 2019, MICROELECTRON ENG, V214, P104, DOI 10.1016/j.mee.2019.05.004
   Strubell E, 2019, Arxiv, DOI [arXiv:1906.02243, DOI 10.48550/ARXIV.1906.02243]
   Wang AL, 2018, INTEGRATION, V62, P246, DOI 10.1016/j.vlsi.2018.03.010
   YEOMANS KA, 1982, J ROY STAT SOC D-STA, V31, P221
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 326
EP 330
DI 10.1109/ISCAS48785.2022.9937653
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Lopes, FE
   Ferreira, JC
   Fernandes, MAC
AF Lopes, Felipe E.
   Ferreira, Joao Canas
   Fernandes, Marcelo A. C.
TI Parallel Implementation on FPGA of Support Vector Machines Using
   Stochastic Gradient Descent
SO ELECTRONICS
DT Article
DE reconfigurable computing; machine learning; FPGA; SVM; SGD
AB Sequential Minimal Optimization (SMO) is the traditional training algorithm for Support Vector Machines (SVMs). However, SMO does not scale well with the size of the training set. For that reason, Stochastic Gradient Descent (SGD) algorithms, which have better scalability, are a better option for massive data mining applications. Furthermore, even with the use of SGD, training times can become extremely large depending on the data set. For this reason, accelerators such as Field-programmable Gate Arrays (FPGAs) are used. This work describes an implementation in hardware, using FPGA, of a fully parallel SVM using Stochastic Gradient Descent. The proposed FPGA implementation of an SVM with SGD presents speedups of more than 10,000x relative to software implementations running on a quad-core processor and up to 319x compared to state-of-the-art FPGA implementations while requiring fewer hardware resources. The results show that the proposed architecture is a viable solution for highly demanding problems such as those present in big data analysis.
C1 [Lopes, Felipe E.; Fernandes, Marcelo A. C.] Univ Fed Rio Grande do Norte, Lab Machine Learning & Intelligent Instrumentat, BR-59078970 Natal, RN, Brazil.
   [Ferreira, Joao Canas] Univ Porto, INESC TEC, P-4200465 Porto, Portugal.
   [Ferreira, Joao Canas] Univ Porto, Fac Engn, P-4200465 Porto, Portugal.
   [Fernandes, Marcelo A. C.] Univ Fed Rio Grande do Norte, Dept Comp & Automat Engn, BR-59078970 Natal, RN, Brazil.
RP Fernandes, MAC (corresponding author), Univ Fed Rio Grande do Norte, Lab Machine Learning & Intelligent Instrumentat, BR-59078970 Natal, RN, Brazil.
EM felipelopes@dca.ufrn.br; jcf@fe.up.pt; mfernandes@dca.ufrn.br
CR Afifi S, 2019, MICROPROCESS MICROSY, V65, P57, DOI 10.1016/j.micpro.2018.12.005
   Da Silva LMD, 2019, IEEE ACCESS, V7, P2782, DOI 10.1109/ACCESS.2018.2885950
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Demir-Kavuk O, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-412
   Dheeru D., UCI MACHINE LEARNING
   Haykin S, 2009, NEURAL NETWORKS LEAR
   Ho SMH, 2016, PROC INT CONF RECON
   Kara K., 2017, P IEEE 25 ANN INT S
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kyrkou C, 2016, IEEE T NEUR NET LEAR, V27, P99, DOI 10.1109/TNNLS.2015.2428738
   Panagiotakopoulos C., 2013, P JOINT EUR C MACH L
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Rasoori S., 2018, P 2018 GREAT LAK S V
   Scholkopf B., 2001, LEARNING KERNELS SUP
   Shalev-Shwartz S, 2011, MATH PROGRAM, V127, P3, DOI 10.1007/s10107-010-0420-4
   Wang Z, 2012, J MACH LEARN RES, V13, P3103
   Wisniewski R, 2019, INTEGRATION, V64, P163, DOI 10.1016/j.vlsi.2018.10.002
NR 17
TC 20
Z9 20
U1 1
U2 5
PD JUN
PY 2019
VL 8
IS 6
AR 631
DI 10.3390/electronics8060631
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Patil, VK
   Pawar, VR
   Kulkarni, P
   Mehta, TA
   Khare, NR
AF Patil, V. K.
   Pawar, V. R.
   Kulkarni, P.
   Mehta, T. A.
   Khare, N. R.
TI Real Time Emotion Recognition with AD8232 ECG Sensor for Classwise
   Performance Evaluation of Machine Learning Methods
SO INTERNATIONAL JOURNAL OF ENGINEERING
DT Article
DE Emotion Recognition; Machine Learning; Support Vector Machine; Naive
   Bayes; Electrocardiogram; Heart Rate Variability
ID SIGNAL
AB Emotions are the accelerators of human intellect and innovation and creativity, so the ability to recognize emotions is in high demand. Real-time hardware has hurdles of Noise and hardware factors as compared to simulations. An electrocardiogram (ECG) sensor (AD8232), a temperature sensor (LM35), and a signal processing circuit is hardware of the proposed real-time emotion identification. The RR intervals are calculated from the ECG data. Emotions prediction using machine learning makes use of RR intervals and body temperature as features. One of the four emotions (namely 1. Happy 2. Stressed 3. Neutral 4. Sad.) is visualized at the serial port of the processor by using WESAD benchmark dataset and the HRV, serial, and pickle libraries.This article's innovation factors are (1) Use of ECG for emotion detection rather than disease detection with Emotion induction method, RR interval capturing and design of RR interval GUI for real time capture of temperature and ECG (2) Display of current emotion on Arduino serial port. (3) Measurement of Class performance using F1 score, macro average, and weighted average instead of general term accuracy. (4) Use of the probability based Navies Bayes as compared to traditional KNN, SVM, Random Forest nethods (5) Class wise performance for example Navies Bayes' specificity or accuracy is lower than SVM's (0.96), but its recall or sensitivity is higher (0.97) vs. (0.94) for stress.In this article, we presented performance parameters in terms of interactive computations, tabular form and graphical display.
C1 [Patil, V. K.; Kulkarni, P.; Mehta, T. A.; Khare, N. R.] AISSMS Inst Informat Technol, Dept Elect & Telecommun Engn, Pune, India.
   [Pawar, V. R.] Bharti Vidyapeeth Coll Engn, Dept Elect & Telecommun Engn, Pune, India.
RP Patil, VK (corresponding author), AISSMS Inst Informat Technol, Dept Elect & Telecommun Engn, Pune, India.
EM varshapatil101@gmail.com
CR Barrett LF, 2019, PSYCHOL SCI PUBL INT, V20, P1, DOI 10.1177/1529100619832930
   Basharirad B, 2017, AIP CONF PROC, V1891, DOI 10.1063/1.5005438
   Bravo-Zanoguera M, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20205962
   Brundin E, 2022, LONG RANGE PLANN, V55, DOI 10.1016/j.lrp.2021.102144
   Bulagang AF., 2020, INFORM MED UNLOCKED, DOI [10.1016/j.imu.2020.100363, DOI 10.1016/J.IMU.2020.100363]
   Butkeviciute E, 2022, MATHEMATICS-BASEL, V10, DOI 10.3390/math10183395
   Dhuheir M, 2021, INT WIREL COMMUN, P681, DOI 10.1109/IWCMC51323.2021.9498861
   Dissanayake T, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19204495
   Dzedzickis A, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030592
   Emami N, 2021, INT J ENG-IRAN, V34, P2545, DOI 10.5829/ije.2021.34.11b.17
   Fernández-Caballero A, 2016, J BIOMED INFORM, V64, P55, DOI 10.1016/j.jbi.2016.09.015
   Goshvarpour A, 2017, BIOMED J, V40, P355, DOI 10.1016/j.bj.2017.11.001
   Guo XH, 2011, PROCEDIA ENGINEER, V15, DOI 10.1016/j.proeng.2011.08.452
   Haag A, 2004, LECT NOTES COMPUT SC, V3068, P36
   Hasnul MA, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21155015
   Hui TKL, 2018, BIOSENSORS-BASEL, V8, DOI 10.3390/bios8020030
   Kumar S, 2017, INT J ENG-IRAN, V30, P1723, DOI 10.5829/ije.2017.30.11b.13
   Lewis K, 2017, SIEGEL I ETHICS RES, V1, P3
   Londhe Supriya, 2018, ICTACT Journal on Communication Technology, V9, P1815, DOI 10.21917/ijct.2018.0265
   Manullang M.C.T., 2019, INDONESIAN J ARTIFIC, V2, P61, DOI [10.24014/ijaidm.v2i2.7593, DOI 10.24014/IJAIDM.V2I2.7593]
   Maria E, 2019, ELECTRON NOTES THEOR, V343, P35, DOI 10.1016/j.entcs.2019.04.009
   Patil Varsha K., 2022, 2022 International Conference on Signal and Information Processing (IConSIP), P1, DOI 10.1109/ICoNSIP49665.2022.10007500
   Patil V.K., 2021, 2021 IEEE PUNE SECTI, P1
   Rodríguez R., 2015, J. appl. res. technol, V13, P261
   Roshani S., 2022, HIGHTECH INNOV J, V3, P356, DOI DOI 10.28991/HIJ-2022-03-03-010
   Schmidt P, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P400, DOI 10.1145/3242969.3242985
   Shin D, 2017, MULTIMED TOOLS APPL, V76, P11449, DOI 10.1007/s11042-016-4203-7
   Shu L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030718
   Shu L, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18072074
   Sun B, 2022, Arxiv, DOI [arXiv:2203.08477, DOI 10.48550/ARXIV.2203.08477]
   Valderas MT, 2015, IEEE ENG MED BIO, P6134, DOI 10.1109/EMBC.2015.7319792
   TIVATANSAKUL Somchanok, 2016, INT J AFFECT ENG, V15, P51, DOI [10.5057/ijae.IJAE-D-15-00036, DOI 10.5057/IJAE.IJAE-D-15-00036]
   Zenonos A, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND COMMUNICATION WORKSHOPS (PERCOM WORKSHOPS)
   Zhongze Zhang, 2020, Journal of Physics: Conference Series, V1678, DOI 10.1088/1742-6596/1678/1/012091
NR 34
TC 0
Z9 0
U1 2
U2 2
PD JUN
PY 2023
VL 36
IS 6
BP 1040
EP 1047
DI 10.5829/ije.2023.36.06c.02
WC Engineering, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Irtija, N
   Anagnostopoulos, I
   Zervakis, G
   Tsiropoulou, EE
   Amrouch, H
   Henkel, J
AF Irtija, Nafis
   Anagnostopoulos, Iraklis
   Zervakis, Georgios
   Tsiropoulou, Eirini Eleni
   Amrouch, Hussam
   Henkel, Joerg
TI Energy Efficient Edge Computing Enabled by Satisfaction Games and
   Approximate Computing
SO IEEE TRANSACTIONS ON GREEN COMMUNICATIONS AND NETWORKING
DT Article
DE Quality of service; Task analysis; FAA; Internet of Things; Trajectory;
   Energy consumption; Approximate computing; Edge computing; energy
   efficiency; satisfaction games; reinforcement learning; deep neural
   networks accelerators; approximate computing
AB In this paper, we introduce an energy efficient edge computing solution to collaboratively utilize Multi-access Edge Computing (MEC) and Fully Autonomous Aerial Systems (FAAS) to support the computing demands of the Internet of Things (IoT) nodes residing in Areas of Interest (AoIs) and executing machine learning tasks. The Satisfaction Games are adopted to determine whether the nodes' optimal partial task should be offloaded to the MEC server or to a hovering FAAS above the AoI. The decision is taken by considering IoT nodes' latency, energy consumption, and acceptable level of Deep Neural Network (DNN) inference accuracy drop constraints. We exploit the error resilience of DNNs and we enhance the FAAS with a heterogeneous approximate DNN accelerator that supports different computational precision and throughput, thus allowing to intelligently adapt to different computing demands. A reinforcement learning-based technique is introduced to enable the FAAS to autonomously optimize its trajectory, aiming at increasing the IoT nodes' satisfaction of their computing demands, while accounting for its flying and data processing energy cost. Our experimental results show the benefits of FAAS, MEC, and approximate computing in terms of increasing the number of satisfied users by 40% under a maximum accuracy drop of only 1%.
C1 [Irtija, Nafis; Tsiropoulou, Eirini Eleni] Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
   [Anagnostopoulos, Iraklis] Southern Illinois Univ, Sch Elect Comp & Biomed Engn, Carbondale, IL 62901 USA.
   [Zervakis, Georgios; Henkel, Joerg] Karlsruhe Inst Technol, Dept Comp Sci, Chair Embedded Syst, D-76131 Karlsruhe, Germany.
   [Amrouch, Hussam] Univ Stuttgart, Elect Engn Fac, Chair Semicond Test & Reliabil, Comp Sci, D-70569 Stuttgart, Germany.
RP Tsiropoulou, EE (corresponding author), Univ New Mexico, Dept Elect & Comp Engn, Albuquerque, NM 87131 USA.
EM nafis@unm.edu; iraklis.anagno@siu.edu; georgios.zervakis@kit.edu;
   eirini@unm.edu; amrouch@iti.uni-stuttgart.de; henkel@kit.edu
CR Amrouch H, 2020, IEEE T COMPUT AID D, V39, P3842, DOI 10.1109/TCAD.2020.3012753
   [Anonymous], 2016, 22TH EUROPEAN WIRELE
   Apostolopoulos PA, 2019, PROCEEDINGS OF THE 14TH WORKSHOP ON CHALLENGED NETWORKS (CHANTS '19):, P21, DOI 10.1145/3349625.3355437
   Banner R, 2019, ADV NEUR IN, V32
   Boubin JG, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P74, DOI 10.1145/3318216.3363306
   Cao B, 2017, IEEE NETWORK, V31, P44, DOI 10.1109/MNET.2016.1500273NM
   Cass S., 2019, IEEE SPECTRUM, V56, P16, DOI [DOI 10.1109/MSPEC.2019.8701189, 10.1109/MSPEC.2019.8701189]
   Chang H., 2021, ARXIV210202078
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diamanti M, 2020, IEEE OPEN J COMM SOC, V1, P1485, DOI 10.1109/OJCOMS.2020.3024778
   Hu HM, 2021, IEEE INTERNET THINGS, V8, P1211, DOI 10.1109/JIOT.2020.3012835
   Hua M, 2019, IEEE T GREEN COMMUN, V3, P664, DOI 10.1109/TGCN.2019.2910590
   Jeong S, 2018, IEEE T VEH TECHNOL, V67, P2049, DOI 10.1109/TVT.2017.2706308
   Jiao X, 2018, DES AUT TEST EUROPE, P1223, DOI 10.23919/DATE.2018.8342202
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Liu Q, 2020, IEEE T VEH TECHNOL, V69, P5723, DOI 10.1109/TVT.2020.2982508
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Palomar DP, 2006, IEEE J SEL AREA COMM, V24, P1439, DOI 10.1109/JSAC.2006.879350
   Papavassiliou S, 2021, IEEE NETWORK, V35, P348, DOI 10.1109/MNET.011.2000368
   Perlaza SM, 2012, IEEE J-STSP, V6, P104, DOI 10.1109/JSTSP.2011.2180507
   Porambage P, 2018, IEEE COMMUN SURV TUT, V20, P2961, DOI 10.1109/COMST.2018.2849509
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Samajdar Ananda, 2018, SCALE SIM SYSTOLIC C
   Sarwar SS, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3097264
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Sikeridis D, 2018, J NETW COMPUT APPL, V123, P69, DOI 10.1016/j.jnca.2018.09.003
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Wang R, 2020, COMPUT COMMUN, V149, P324, DOI 10.1016/j.comcom.2019.10.021
   Wang YS, 2020, IEEE T GREEN COMMUN, V4, P1091, DOI 10.1109/TGCN.2020.3005290
   Zervakis G., 2021, ARXIV210209642
   Zervakis G, 2020, IEEE ACCESS, V8, P53522, DOI 10.1109/ACCESS.2020.2981395
   Zhang J, 2019, IEEE INTERNET THINGS, V6, P3688, DOI 10.1109/JIOT.2018.2890133
   Zhu SC, 2021, IEEE T VEH TECHNOL, V70, P928, DOI 10.1109/TVT.2020.3048938
NR 35
TC 10
Z9 10
U1 1
U2 9
PD MAR
PY 2022
VL 6
IS 1
BP 281
EP 294
DI 10.1109/TGCN.2021.3122911
WC Telecommunications
DA 2023-11-11
ER

PT J
AU Lu, J
   Verma, N
   Jha, NK
AF Lu, Jie
   Verma, Naveen
   Jha, Niraj K.
TI Convolutional Autoencoder-Based Transfer Learning for Multi-Task Image
   Inferences
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Convolutional neural networks; energy reduction; machine learning;
   multi-task images; transfer learning
ID DEEP; REPRESENTATION
AB Pattern-recognition algorithms from machine learning play a prominent role in embedded sensing systems to derive inferences from sensor data. Very often, such systems face severe energy constraints, especially when dealing with high-dimensional data, such as images. The focus of this study is on reducing computational energy by exploiting the concept of transfer learning and energy-efficient dataflow accelerators. We show that the use of convolutional autoencoders can enable various opportunities to reduce computational energy and avoid significant reduction in inference performance when multiple task categories are targeted for inference. We validate our approach through a multi-task case study. The study targets a set of pictures with each picture containing four different task categories: gender, smile, glasses, and pose. In order to minimize inference time and computational energy, a convolutional autoencoder is used for learning a generalized representation of the images. Three scenarios are analyzed: transferring layers using convolutional autoencoders, transferring layers using convolutional neural networks trained on different tasks, and no layer transfer. We show that when the convolutional layers with one fully-connected layer are transferred using convolutional autoencoders, we can achieve a reduction of 6.58x in computational energy, while improving performance by 1.98, 1.88, 4.11, and 1.47 percent for gender, smile, glasses, and pose inferences, respectively, as compared to the no-transfer method, when the number of training samples is small.
C1 [Lu, Jie; Verma, Naveen; Jha, Niraj K.] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Lu, J (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM jielu@princerton.edu
CR Ayodele TO., 2010, NEW ADV MACH LEARN, V3, P19, DOI DOI 10.5772/9385
   Bengio Y, 2006, ADV NEURAL INFORM PR, P19, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen M, 2021, IEEE T BIG DATA, V7, P750, DOI 10.1109/TBDATA.2017.2717439
   Chen M, 2017, IEEE ACCESS, V5, P326, DOI 10.1109/ACCESS.2016.2641480
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Ciresan D, 2012, ADV NEURAL INFORM PR, V2843, P2851, DOI DOI 10.5555/2999325.2999452
   Courbariaux M, 2015, ADV NEUR IN, V28
   Du B, 2018, IEEE T IMAGE PROCESS, V27, P4219, DOI 10.1109/TIP.2018.2836324
   Du B, 2017, IEEE T CYBERNETICS, V47, P1017, DOI 10.1109/TCYB.2016.2536638
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C, 2013, IEEE T PATTERN ANAL, V35, P1915, DOI 10.1109/TPAMI.2012.231
   Gao SH, 2015, IEEE T INF FOREN SEC, V10, P2108, DOI 10.1109/TIFS.2015.2446438
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Huang ZL, 2017, REMOTE SENS-BASEL, V9, DOI 10.3390/rs9090907
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Kallenberg M, 2016, IEEE T MED IMAGING, V35, P1322, DOI 10.1109/TMI.2016.2532122
   Kemker R, 2017, IEEE T GEOSCI REMOTE, V55, P2693, DOI 10.1109/TGRS.2017.2651639
   Krizhevsky Alex, 2011, ESANN, P489
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liou CY, 2014, NEUROCOMPUTING, V139, P84, DOI 10.1016/j.neucom.2013.09.055
   Masci J, 2011, LECT NOTES COMPUT SC, V6791, P52, DOI 10.1007/978-3-642-21735-7_7
   Oquab M, 2014, PROC CVPR IEEE, P1717, DOI 10.1109/CVPR.2014.222
   Özdenizci O, 2019, I IEEE EMBS C NEUR E, P207, DOI [10.1109/NER.2019.8716897, 10.1109/ner.2019.8716897]
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Saenko K, 2010, LECT NOTES COMPUT SC, V6314, P213, DOI 10.1007/978-3-642-15561-1_16
   Shen W, 2017, PATTERN RECOGN, V61, P663, DOI 10.1016/j.patcog.2016.05.029
   Su H, 2016, IEEE T MED IMAGING, V35, P762, DOI 10.1109/TMI.2015.2494582
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tommasi T, 2010, PROC CVPR IEEE, P3081, DOI 10.1109/CVPR.2010.5540064
   Vincent P., 2008, P 25 INT C MACH LEAR, P1096
   Whatmough P. N., 2019, ARXIV 190211128
   Xiao J., 2020, ARXIV 200704514
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zeiler M. D., 2014, THESIS NYU NEW YORK
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang J, 2014, LECT NOTES COMPUT SC, V8690, P1, DOI 10.1007/978-3-319-10605-2_1
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhou S., 2016, ARXIV160606160
NR 45
TC 5
Z9 5
U1 1
U2 5
PD APR-JUN
PY 2022
VL 10
IS 2
BP 1045
EP 1057
DI 10.1109/TETC.2021.3068063
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Zhou, KJ
   Zhao, CY
   Fang, JB
   Jiang, JW
   Chen, DY
   Huang, YJ
   Jing, MG
   Han, J
   Tian, HD
   Xiong, XK
   Liu, Q
   Xue, XY
   Zeng, XY
AF Zhou, Keji
   Zhao, Chenyang
   Fang, Jinbei
   Jiang, Jingwen
   Chen, Deyang
   Huang, Yujie
   Jing, Minge
   Han, Jun
   Tian, Haidong
   Xiong, Xiankui
   Liu, Qi
   Xue, Xiaoyong
   Zeng, Xiaoyang
TI An Energy Efficient Computing-in-Memory Accelerator With 1T2R Cell and
   Fully Analog Processing for Edge AI Applications
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Energy efficiency; Artificial neural networks; Training; Clamps; Voltage
   measurement; Neurons; Current mirrors; ReRAM; neural network (NN);
   computing-in-memory (CIM); machine learning (ML)
AB In this work, a ReRAM-based energy-efficient CIM accelerator is presented with two techniques for edge AI applications. Firstly, a circuit-algorithm co-design scheme is proposed to realize fully analog processing, which improves the energy efficiency and the throughput of neural network. To deal with the I-V nonlinearity of ReRAM, a nonlinear-aware training algorithm is proposed to improve the network accuracy. Secondly, a 1T2R cell is proposed to replace previous 2T2R for weight storage with 35% area saving. For evaluation, a neural network with two fully connected layers and one ReLU layer is built for the MNIST dataset. The error rate can be reduced by >46% and the energy efficiency is 99 TOPS/W@200 MHz, 2.6X improvement over the digital method.
C1 [Zhou, Keji; Zhao, Chenyang; Fang, Jinbei; Jiang, Jingwen; Chen, Deyang; Huang, Yujie; Jing, Minge; Han, Jun; Liu, Qi; Xue, Xiaoyong; Zeng, Xiaoyang] Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
   [Zhou, Keji; Liu, Qi] Fudan Univ, Frontier Inst Chip & Syst, Shanghai 200438, Peoples R China.
   [Tian, Haidong; Xiong, Xiankui] State Key Lab Mobile Network & Mobile Commun Mult, ZTE, Shenzhen 518057, Peoples R China.
RP Xue, XY (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai 201203, Peoples R China.
EM xuexiaoyong@fudan.edu.cn
CR Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Kim H, 2020, IEEE IND APPLIC SOC, DOI 10.1109/IAS44978.2020.9334884
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Xue CX, 2020, IEEE J SOLID-ST CIRC, V55, P203, DOI 10.1109/JSSC.2019.2951363
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang J, 2020, PROC IEEE INT ELECT
   Zhang C., 2016, ARXIV PREPRINT ARXIV
NR 9
TC 7
Z9 7
U1 5
U2 20
PD AUG
PY 2021
VL 68
IS 8
BP 2932
EP 2936
DI 10.1109/TCSII.2021.3065697
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zulberti, L
   Monopoli, M
   Nannipieri, P
   Fanucci, L
AF Zulberti, Luca
   Monopoli, Matteo
   Nannipieri, Pietro
   Fanucci, Luca
GP IEEE
TI Architectural Implications for Inference of Graph Neural Networks on
   CGRA-based Accelerators
SO PRIME 2022: 17TH INTERNATIONAL CONFERENCE ON PHD RESEARCH IN
   MICROELECTRONICS AND ELECTRONICS
DT Proceedings Paper
CT 17th Conference on Ph.D Research in Microelectronics and Electronics
   (PRIME)
CY JUN 12-15, 2022
CL Villasimius, ITALY
DE Coarse-Grained Reconfigurable Arrays; Graph Neural Networks; algorithms;
   architectures; accelerators
AB Reconfigurable computing has become very popular in recent years. Among all available architectures, Coarse-Grained Reconfigurable Arrays are the most prominent ones. They permit to efficiently accelerate several classes of data-intensive algorithms without giving up architecture versatility, and their use in machine learning applications is becoming increasingly widespread. In particular, the typical workload of Convolutional Neural Networks fits very well on this kind of architecture. Unfortunately, their use in Graph Neural Networks is not well investigated. Graph Neural Network algorithms apply to use cases that are characterized by non-euclidean data, such as computer vision, natural language processing, traffic forecasting, chemistry, and recommendation systems. In this work, we analyse the most relevant Coarse-Grained Reconfigurable Array devices and Graph Neural Network models. Our contribution includes a comparison between the hardware architectures and their use for the inference of Graph Neural Network models. We highlight their limitations and discuss possible directions that the development of these architectures could take.
C1 [Zulberti, Luca; Monopoli, Matteo; Nannipieri, Pietro; Fanucci, Luca] Univ Pisa, Dept Informat Engn, Pisa, Italy.
RP Zulberti, L (corresponding author), Univ Pisa, Dept Informat Engn, Pisa, Italy.
CR Abadal S, 2022, ACM COMPUT SURV, V54, DOI 10.1145/3477141
   Charitopoulos G, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3447970
   De Sutter B, 2010, HANDBOOK OF SIGNAL PROCESSING SYSTEMS, P449, DOI 10.1007/978-1-4419-6345-1_17
   Hamilton W. L., 2018, INDUCTIVE REPRESENTA
   Li Y., 2015, P 4 INT C LEARNING R
   Liang S., 2020, ENG HIGH THROUGHPUT
   Nguyen Q. M, 2021, MICRO 21, P1064
   Podobas A, 2020, IEEE ACCESS, V8, P146719, DOI 10.1109/ACCESS.2020.3012084
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Schlichtkrull M., 2017, MODELING RELATIONAL
   Tan C, 2021, IEEE T PARALL DISTR, V32, P2880, DOI 10.1109/TPDS.2021.3081074
   Tan C, 2020, PR IEEE COMP DESIGN, P381, DOI 10.1109/ICCD50377.2020.00070
   Velickovic P., 2017, INT C LEARN REPR, V1050, P10, DOI DOI 10.48550/ARXIV.1710.10903
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Zhang Si, 2019, Comput Soc Netw, V6, P11, DOI 10.1186/s40649-019-0069-y
   Zhang ZH, 2020, IEEE COMPUT ARCHIT L, V19, P59, DOI 10.1109/LCA.2020.2988991
NR 18
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 305
EP 308
DI 10.1109/PRIME55000.2022.9816810
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sun, ZR
   Zhu, YX
   Zheng, Y
   Wu, H
   Cao, ZH
   Xiong, P
   Hou, JJ
   Huang, T
   Que, ZQ
AF Sun, Zhanrui
   Zhu, Yongxin
   Zheng, Yu
   Wu, Hao
   Cao, Zihao
   Xiong, Peng
   Hou, Junjie
   Huang, Tian
   Que, Zhiqiang
GP IEEE
TI FPGA acceleration of LSTM based on data for test flight
SO 2018 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD)
DT Proceedings Paper
CT 3rd IEEE International Conference on Smart Cloud (SmartCloud)
CY SEP 21-23, 2018
CL Columbia Univ, New York, NY
HO Columbia Univ
DE LSTM; RNN; FPGA; Deep Learning
ID NEURAL-NETWORK; PREDICTION
AB Long Short-Term Memory Recurrent neural networks are generally used in speech recognition, machine translation and other fields. And LSTM-RNN also performs well in data anomaly detection. However, Due to the repeatability of LSTM-RNN, general-purpose processors such as CPU and GPGPU cannot efficiently implement LSTM-RNN, most of the existing model optimizations on FPGA are aimed at LSTM cells or large-scale model accelerations that do not require high accuracy (such as speech recognition). For the model of aircraft anomaly detection, which models with short data sampling intervals, high speed requirements and high precision requirements, the accuracy and speed of existing models are insufficient. Therefore, we proposed an FPGA-based LSTM-RNN accelerator to optimize the accuracy and speed of existing models. We achieve the optimization in the computation speed without sacrificing the accuracy, and balance performance and resources utilized in FPGA. The peak performance of our accelerator reaches 13.45 GOP/s, which is superior to other existing methods.
C1 [Sun, Zhanrui; Zhu, Yongxin; Zheng, Yu; Wu, Hao; Cao, Zihao; Xiong, Peng; Hou, Junjie] Shanghai Jiao Tong Univ, Sch Microelect, Shanghai, Peoples R China.
   [Zhu, Yongxin] Chinese Acad Sci, Shanghai Adv Res Inst, Beijing, Peoples R China.
   [Huang, Tian] Univ Cambridge, Dept Phys, Cambridge, England.
   [Que, Zhiqiang] Imperial Coll, Dept Comp, London, England.
RP Zhu, YX (corresponding author), Shanghai Jiao Tong Univ, Sch Microelect, Shanghai, Peoples R China.; Zhu, YX (corresponding author), Chinese Acad Sci, Shanghai Adv Res Inst, Beijing, Peoples R China.
EM KUIflying@sjtu.edu.cn; zhuyongxin@sjtu.edu.cn;
   sea_7seclouds@sjtu.edu.cn; wh_sjtu@sjtu.edu.cn; zhcaoic@sjtu.edu.cn;
   woshixp@sjtu.edu.cn; hjj123@sjtu.edu.cn; th523@cam.ac.uk;
   z.que@imperial.ac.uk
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   Chang A X M, 2015, COMPUTER SCI
   Chen Q, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1657, DOI 10.18653/v1/P17-1152
   Ferreira J.C., 2017, INT C REC COMP FPGAS, P1
   Gai KK, 2020, IEEE T CLOUD COMPUT, V8, P1212, DOI 10.1109/TCC.2016.2594172
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Greff K., 2016, ARXIV150304069, V28, P2222, DOI DOI 10.1109/TNNLS.2016.2582924
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S., 2017, ESE EFFICIENT SPEECH
   Ma XL, 2015, TRANSPORT RES C-EMER, V54, P187, DOI 10.1016/j.trc.2015.03.014
   Otte Sebastian, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P1, DOI 10.1007/978-3-319-11179-7_1
   Pascanu R., 2013, INT C MACH LEARN, P1310, DOI DOI 10.5555/3042817.3043083
   Ringeval F, 2015, PATTERN RECOGN LETT, V66, P22, DOI 10.1016/j.patrec.2014.11.007
   Sak H, 2014, INTERSPEECH, P338
   Schmidhuber Jurgen, 1993, NETZWERKARCHITEKTURE
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
NR 17
TC 18
Z9 19
U1 0
U2 2
PY 2018
BP 1
EP 6
DI 10.1109/SmartCloud.2018.00009
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Bakar, A
   Goel, R
   de Winkel, J
   Huang, J
   Ahmed, S
   Islam, B
   Pawelczak, P
   Yildirim, KS
   Hester, J
AF Bakar, Abu
   Goel, Rishabh
   de Winkel, Jasper
   Huang, Jason
   Ahmed, Saad
   Islam, Bashima
   Pawelczak, Przemyslaw
   Yildirim, Kasim Sinan
   Hester, Josiah
TI Protean: ADAPTIVE HARDWARE-ACCELERATED INTERMITTENT COMPUTING
SO GETMOBILE-MOBILE COMPUTING & COMMUNICATIONS REVIEW
DT Article; Proceedings Paper
CT Proceedings of the 20th ACM Conference on Embedded Networked Sensor
   Systems
CY NOV 06-09, 2022
CL Boston, MA
AB Today's smart devices have short battery lifetimes, high installation and maintenance costs, and rapid obsolescence - all leading to the explosion of electronic waste in the past two decades. These problems will worsen as the number of connected devices grows to one trillion by 2035. Energy harvesting, battery-free devices offer an alternative. Getting rid of the battery reduces e-waste, promises long lifetimes, and enables deployment in new applications and environments. Unfortunately, developing sophisticated inference-capable applications is still challenging. The lack of platform support for advanced (32-bit) microprocessors and specialized accelerators, which can execute data-intensive machine-learning tasks, has held back batteryless devices.
C1 [Bakar, Abu; Goel, Rishabh; Islam, Bashima] Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
   [de Winkel, Jasper; Pawelczak, Przemyslaw] Delft Univ Technol, Delft, Netherlands.
   [Huang, Jason] Northwestern Univ, Comp Sci, Evanston, IL USA.
   [Islam, Bashima] Worcester Polytech Inst, Dept Elect & Comp Engn, Worcester, MA USA.
   [Islam, Bashima] Worcester Polytech Inst, Dept Comp Sci, Worcester, MA USA.
   [Islam, Bashima] Univ Illinois, Urbana, IL USA.
   [Yildirim, Kasim Sinan] Univ Trento, Dept Informat Engn & Comp Sci, Trento, Italy.
   [Hester, Josiah] Georgia Inst Technol, Interact Comp & Comp Sci, Atlanta, GA USA.
RP Bakar, A (corresponding author), Georgia Inst Technol, Sch Interact Comp, Atlanta, GA 30332 USA.
CR Abu Bakar Rishabh, 2022, P 20 ACM C EMBEDDED
   Bakar A, 2022, PROCEEDINGS OF THE 2022 THE 23RD ANNUAL INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE '22), P22, DOI 10.1145/3508396.3512870
   Colin A, 2018, ACM SIGPLAN NOTICES, V53, P767, DOI [10.1145/3296957.3173210, 10.1145/3173162.3173210]
   de Winkel J, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3411839
   Gobieski G, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P199, DOI 10.1145/3297858.3304011
   Hester J, 2017, PROCEEDINGS OF THE 15TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS (SENSYS'17), DOI 10.1145/3131672.3131673
   Kortbeek V, 2020, PROC ACM INTERACT MO, V4, DOI 10.1145/3432191
   Montanari Alessandro, 2020, SenSys '20: Proceedings of the 18th Conference on Embedded Networked Sensor Systems, P382, DOI 10.1145/3384419.3430782
   Sparkfun, WHAT IS MICROMOD
NR 9
TC 0
Z9 0
U1 0
U2 0
PD MAR
PY 2023
VL 27
IS 1
BP 5
EP 10
WC Telecommunications
DA 2023-11-11
ER

PT C
AU Kalms, L
   Ibrahim, H
   Göhringer, D
AF Kalms, Lester
   Ibrahim, Hassan
   Goehringer, Diana
BE Andrews, D
   Cumplido, R
   Feregrino, C
   Stroobandt, D
TI Full-HD Accelerated and Embedded Feature Detection Video System with
   63fps using ORB for FREAK
SO 2018 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY DEC 03-05, 2018
CL Cancun, MEXICO
DE FPGA; Feature Detection; Image Processing; Real-Time; Video Processing
   System
AB Detecting features using pattern recognition algorithms is a fast method to recognize objects without needing large image databases. Feature detection can be used in e.g. machine learning or Simultaneous Localization and Mapping (SLAM) algorithms. For several application areas, real-time requirements and power constraints are important. FPGAs are predestined for these requirements, due to the possibility of clock-accurate computations. This work proposes a hardware accelerator of the Oriented FAST and Rotated BRIEF (ORB) feature detector implemented as a pipelined design on an FPGA SoC. The accelerator is integrated into an HDMI input/ output video processing system. The final system runs with a frequency of 148.5 MHz and processes a 1080p video stream with 63 frames per second (fps). Furthermore, we propose to replace the Binary Robust Independent Elementary Features (BRIEF) with the Fast Retina Keypoint (FREAK) descriptor to improve the performance and repeatability of the algorithm.
C1 [Kalms, Lester; Goehringer, Diana] Tech Univ Dresden, Dresden, Germany.
   [Ibrahim, Hassan] GUC, Cairo, Egypt.
RP Kalms, L (corresponding author), Tech Univ Dresden, Dresden, Germany.
EM lester.kalms@tu-dresden.de; hassan.ibrahim@student.guc.edu.eg;
   diana.goehringer@tu-dresden.de
CR Alahi A, 2012, PROC CVPR IEEE, P510, DOI 10.1109/CVPR.2012.6247715
   Alcantarilla PF, 2013, PROCEEDINGS OF THE BRITISH MACHINE VISION CONFERENCE 2013, DOI 10.5244/C.27.13
   [Anonymous], ZEDBOARD HW USERS GU
   [Anonymous], 2014, INT J CONTROL AUTOM, DOI DOI 10.14257/ijca.2014.7.3.20
   [Anonymous], 2017, P IEEE 2017 C DES AR, DOI DOI 10.1109/DASIP.2017.8122130
   [Anonymous], 2008, COMPUT VIS IMAGE UND, DOI DOI 10.1016/j.cviu.2007.09.014
   Calonder M, 2012, IEEE T PATTERN ANAL, V34, P1281, DOI 10.1109/TPAMI.2011.222
   Eigen D, 2013, IEEE I CONF COMP VIS, P633, DOI 10.1109/ICCV.2013.84
   Fularz M, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/61434
   Kalms L, 2017, I C FIELD PROG LOGIC
   Leutenegger S, 2011, IEEE I CONF COMP VIS, P2548, DOI 10.1109/ICCV.2011.6126542
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Manjunath BS, 1996, PATTERN RECOGN, V29, P627, DOI 10.1016/0031-3203(95)00115-8
   Mur-Artal R, 2017, IEEE T ROBOT, V33, P1255, DOI 10.1109/TRO.2017.2705103
   Rosten E, 2006, LECT NOTES COMPUT SC, V3951, P430, DOI 10.1007/11744023_34
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2018
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Kim, DH
   Lim, S
   Chung, KJ
   Hwang, YS
   Kim, HS
   Dang, JJ
   Lee, SH
   Choe, K
   Jung, WH
   Kwon, HJ
AF Kim, Dong-Hwan
   Lim, Soobin
   Chung, Kyoung-Jae
   Hwang, Yong-Seok
   Kim, Han-Sung
   Dang, Jeong-Jeung
   Lee, Seung-Hyun
   Choe, Kyumin
   Jung, Won-Hyeok
   Kwon, Hyeok-Jung
TI Validation of neural networks model based on beam dynamics simulation
   for an automated control in high-intensity proton injector
SO JOURNAL OF THE KOREAN PHYSICAL SOCIETY
DT Article
DE Low-energy beam transport; Proton injector; Beam dynamics; Artificial
   neural network; Beam optimization model
AB We have studied the feasibility of automatic and fast control of the low energy beam transport section in the newly developed radio-frequency quadrupole at KOMAC (Korea Multipurpose Accelerator Complex) by combining a simple neural network model with a beam profile monitor. Extensive beam dynamics simulations on the proton injector with varying beam transport parameters are performed to generate the training set for the machine learning and to obtain optimization model for the injector. These datasets are well-trained and show good ability to estimate the beam parameters at position under consideration. These results can be a steppingstone to develop an auto-tuning or feedback control system based on artificial intelligence for a high-intensity accelerator. This paper presents the calculation conditions and the training process in detail, as well as the cross-validation of the trained neural network model by using the results obtained by beam dynamics code.
C1 [Kim, Dong-Hwan; Lim, Soobin; Chung, Kyoung-Jae; Hwang, Yong-Seok] Seoul Natl Univ, Dept Nucl Engn, Seoul 08826, South Korea.
   [Kim, Dong-Hwan; Kim, Han-Sung; Dang, Jeong-Jeung; Lee, Seung-Hyun; Choe, Kyumin; Jung, Won-Hyeok; Kwon, Hyeok-Jung] KAERI, Korea Multipurpose Accelerator Complex, Gyeongju 38180, South Korea.
RP Hwang, YS (corresponding author), Seoul Natl Univ, Dept Nucl Engn, Seoul 08826, South Korea.
EM yhwang@snu.ac.kr
CR Chauvin N, 2012, REV SCI INSTRUM, V83, DOI 10.1063/1.3678658
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Fol Elena, 2018, 7 INT BEAM INSTR C S
   Fol Elena., 2019, 39 FREE EL LAS C 201
   Kwon HJ, 2016, J KOREAN PHYS SOC, V69, P967, DOI 10.3938/jkps.69.967
   Kwon Hyeok-Jung, 2014, P 27 LIN ACC X GEN S
   Miyamoto R, 2019, 10 INT PART ACC C ME
   Uriot D., 2015, 6 INT PART ACC C RI
   Wangler T.P., 2008, RF LINEAR ACCELERATO, P32, DOI [10.1002/9783527623426, DOI 10.1002/9783527623426]
   Winklehner D, 2014, REV SCI INSTRUM, V85, DOI 10.1063/1.4854315
NR 10
TC 1
Z9 1
U1 0
U2 6
PD JUN
PY 2021
VL 78
IS 12
BP 1185
EP 1190
DI 10.1007/s40042-021-00193-0
EA MAY 2021
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Carbon, A
   Philippe, JM
   Bichler, O
   Schmit, R
   Tain, B
   Briand, D
   Ventroux, N
   Paindavoine, M
   Brousse, O
AF Carbon, A.
   Philippe, J-M.
   Bichler, O.
   Schmit, R.
   Tain, B.
   Briand, D.
   Ventroux, N.
   Paindavoine, M.
   Brousse, O.
GP IEEE
TI PNeuro: a scalable energy-efficient programmable hardware accelerator
   for neural networks
SO PROCEEDINGS OF THE 2018 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 19-23, 2018
CL Dresden, GERMANY
DE Neural networks; Neural network hardware; Computer architectures; FPGA;
   ASIC; Low power
AB Artificial intelligence and especially Machine Learning recently gained a lot of interest from the industry. Indeed, new generation of neural networks built with a large number of successive computing layers enables a large amount of new applications and services implemented from smart sensors to data centers. These Deep Neural Networks (DNN) can interpret signals to recognize objects or situations to drive decision processes. However, their integration into embedded systems remains challenging due to their high computing needs.
   This paper presents PNeuro, a scalable energy-efficient hardware accelerator for the inference phase of DNN processing chains. Simple programmable processing elements architectured in SIMD clusters perform all the operations needed by DNN (convolutions, pooling, non-linear functions, etc.). An FDSOI 28 inn prototype shows an energy efficiency of 700 GMACS/s/W at 800 MHz. These results open important perspectives regarding the development of smart energy-efficient solutions based on Deep Neural Networks.
C1 [Carbon, A.; Philippe, J-M.; Bichler, O.; Schmit, R.; Tain, B.; Briand, D.; Ventroux, N.] CEA, LIST, F-91191 Gif Sur Yvette, France.
   [Paindavoine, M.; Brousse, O.] GlobalSensing Technol, 14 Rue Pierre de Coubertin, F-21000 Dijon, France.
RP Carbon, A (corresponding author), CEA, LIST, F-91191 Gif Sur Yvette, France.
EM alexandre.carbon@cea.fr; michel.paindavoine@gsensing.eu
CR [Anonymous], 2017, IEEE J SOLID-ST CIRC, P1
   Bechara C., 2011, 2011 18th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2011), P685, DOI 10.1109/ICECS.2011.6122367
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Farabet C., 2011, IEEE COMP VIS PATT R
   Fei-Fei L., 2004, IEEE WORKSH GEN MOD
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ovtcharov K., 2015, HOT CHIPS 27 S HCS 2, P1
   Redmon J., 2016, ARXIV160207360, P779
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 11
TC 10
Z9 10
U1 0
U2 2
PY 2018
BP 1039
EP 1044
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kurz, S
AF Kurz, Stefan
BE VanBeurden, M
   Budko, N
   Schilders, W
TI Hybrid Modeling: Towards the Next Level of Scientific Computing in
   Engineering
SO SCIENTIFIC COMPUTING IN ELECTRICAL ENGINEERING (SCEE 2020)
SE Mathematics in Industry-Cham
DT Proceedings Paper
CT 13th International Conference on Scientific Computing in Electrical
   Engineering (SCEE)
CY FEB 16-20, 2020
CL Eindhoven, NETHERLANDS
AB The integration of machine learning (Keplerian paradigm) and more general artificial intelligence technologies with physical modeling based on first principles (Newtonian paradigm) will impact scientific computing in engineering in fundamental ways. Such hybrid models combine first principle-based models with data-based models into a joint architecture. This paper will give some background, explain trends and showcase recent achievements from an applied mathematics and industrial perspective. Examples include characterization of superconducting accelerator magnets by blending data with physics, data-driven magnetostatic field simulation without an explicit model of the constitutive law, and Bayesian free-shape optimization of a trace pair with bend on a printed circuit board.
C1 [Kurz, Stefan] Bosch Ctr Artificial Intelligence, Renningen, Germany.
   [Kurz, Stefan] Tech Univ Darmstadt, Ctr Computat Engn, Darmstadt, Germany.
RP Kurz, S (corresponding author), Bosch Ctr Artificial Intelligence, Renningen, Germany.; Kurz, S (corresponding author), Tech Univ Darmstadt, Ctr Computat Engn, Darmstadt, Germany.
EM stefan.kurz2@de.bosch.com
CR [Anonymous], 2007, PATTERN RECOGN, V16
   [Anonymous], 2019, ICIAM INT C IND APPL
   Bardsley J.M, 2018, COMPUTATIONAL UNCERT, V19
   Belbute-Peres FD, 2018, ADV NEUR IN, V31
   Conti S, 2018, ARCH RATION MECH AN, V229, P79, DOI 10.1007/s00205-017-1214-0
   Coveney PV, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2016.0153
   De Gersem H., 2020, ARXIV200203715
   Frazier, 2018, RECENT ADV OPTIMIZAT, DOI 10.1287/educ.2018.0188
   Gazda C, 2012, IEEE T ELECTROMAGN C, V54, P704, DOI 10.1109/TEMC.2012.2187210
   Guarino Nicola, 2009, HDB ONTOLOGIES, P1, DOI [10.1007/978-3-540-92673-3_0, DOI 10.1007/978-3-540-92673-3_0]
   Higham CF, 2019, SIAM REV, V61, P860, DOI 10.1137/18M1165748
   Holland J.R., 2019, AIAA SCIT FOR AIAA, P1884
   Kalman RE., 1960, NEW APPROACH LINEAR, V82, P35
   Kirchdoerfer T, 2016, COMPUT METHOD APPL M, V304, P81, DOI 10.1016/j.cma.2016.02.001
   Lee S., 2018, BASIC RESEARCH NEEDS
   Liebsch M, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2019.2952092
   Parish EJ, 2016, J COMPUT PHYS, V305, P758, DOI 10.1016/j.jcp.2015.11.012
   Pieczynski W, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL PROCESSING, VOL VI, PROCEEDINGS, P57
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   RIKABI J, 1988, INT J NUMER METH ENG, V26, P1963, DOI 10.1002/nme.1620260906
   Schuhmacher S, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2017.2774107
   Stuart A, 2019, BOEING DISTINGUISHED
   Swischuk R, 2019, COMPUT FLUIDS, V179, P706, DOI 10.1016/j.compfluid.2018.07.021
   Tonti E, 2013, MODEL SIMUL SCI ENG, P1, DOI 10.1007/978-1-4614-7422-7
   Tonti E., 2014, DISCRETE PHYS ALGEBR
   Trowbridge B., 2001, COMPUMAG C THE 1 25
   Walker M, 2018, TECH REP G00340159
   Wikipedia contributors, 2019, NEWTONS LAWS MOTION
   Willcox K, 2019, ICIAM INT C IND APPL
   Zhu YH, 2019, J COMPUT PHYS, V394, P56, DOI 10.1016/j.jcp.2019.05.024
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2021
VL 36
BP 251
EP 263
DI 10.1007/978-3-030-84238-3_25
WC Engineering, Industrial; Engineering, Electrical & Electronic;
   Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Lu, YC
   Matsushita, Y
   Ino, F
AF Lu, Yuechao
   Matsushita, Yasuyuki
   Ino, Fumihiko
TI Block Randomized Singular Value Decomposition on GPUs
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
DT Article
DE randomized singular value decomposition; GPU
ID FACE-RECOGNITION; ALGORITHMS; COMMUNICATION; APPROXIMATION; QR
AB Fast computation of singular value decomposition (SVD) is of great interest in various machine learning tasks. Recently, SVD methods based on randomized linear algebra have shown significant speedup in this regime. For processing large-scale data, computing systems with accelerators like GPUs have become the mainstream approach. In those systems, access to the input data dominates the overall process time; therefore, it is needed to design an out-of-core algorithm to dispatch the computation into accelerators. This paper proposes an accurate two-pass randomized SVD, named block randomized SVD (BRSVD), designed for matrices with a slow-decay singular spectrum that is often observed in image data. BRSVD fully utilizes the power of modern computing system architectures and efficiently processes large-scale data in a parallel and out-of-core fashion. Our experiments show that BRSVD effectively moves the performance bottleneck from data transfer to computation, so that outperforms existing randomized SVD methods in terms of speed with retaining similar accuracy.
C1 [Lu, Yuechao; Matsushita, Yasuyuki; Ino, Fumihiko] Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan.
RP Lu, YC (corresponding author), Osaka Univ, Grad Sch Informat Sci & Technol, Suita, Osaka 5650871, Japan.
EM yc-lu@ist.osaka-u.ac.jp
CR Abhari K., 2012, 2012 11th International Conference on Information Sciences, Signal Processing and their Applications (ISSPA), P259, DOI 10.1109/ISSPA.2012.6310556
   [Anonymous], 2019, CUBLAS LIB US GUID
   [Anonymous], 2010, IEEE INT S PARALLEL
   [Anonymous], 1998, DAIMI REPORT SERIES, DOI DOI 10.7146/DPB.V27I537.7070
   [Anonymous], 2012, MATRIX COMPUTATIONS
   Ballard G, 2011, SIAM J MATRIX ANAL A, V32, P866, DOI 10.1137/090769156
   Choi J., 1995, CS95283 UT
   Demmel J, 2013, INT PARALL DISTRIB P, P585, DOI 10.1109/IPDPS.2013.123
   Demmel J, 2012, SIAM J SCI COMPUT, V34, pA206, DOI 10.1137/080731992
   Demmel JW, 2015, SIAM J MATRIX ANAL A, V36, P55, DOI 10.1137/13092157X
   Dongarra J, 2018, SIAM REV, V60, P808, DOI 10.1137/17M1117732
   Frieze A, 2004, J ACM, V51, P1025, DOI 10.1145/1039488.1039494
   Georghiades AS, 2001, IEEE T PATTERN ANAL, V23, P643, DOI 10.1109/34.927464
   Golub G., 1965, J SOC IND APPL MATH, V2, P205, DOI DOI 10.1137/0702016
   Haidar A, 2017, PROCEEDINGS OF THE GENERAL PURPOSE GPUS (GPGPU-10), P42, DOI 10.1145/3038228.3038237
   Haidar Azzam, 2017, 2017 IEEE HIGH PERFO, P1
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Hoemmen M. F., 2010, THESIS UC BERKELEY
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Intel Corporation, 2019, DEV REF INT MATH KER
   Irony D, 2004, J PARALLEL DISTR COM, V64, P1017, DOI 10.1016/j.jpdc.2004.03.021
   Jablin TB, 2011, ACM SIGPLAN NOTICES, V46, P142, DOI 10.1145/1993316.1993516
   Liberty E, 2007, P NATL ACAD SCI USA, V104, P20167, DOI 10.1073/pnas.0709640104
   Martinsson P-G, 2006, YALEUDCSTR1361
   NVIDIA Corporation, 2019, PROF US GUID VERS 10
   NVIDIA Corporation, 2018, CURAND LIB PROGR GUI
   NVIDIA Corporation, 2018, CUSOLVER LIB V10 1
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Phillips PJ, 1997, PROC CVPR IEEE, P137, DOI 10.1109/CVPR.1997.609311
   Rokhlin V, 2009, SIAM J MATRIX ANAL A, V31, P1100, DOI 10.1137/080736417
   Sarlós T, 2006, ANN IEEE SYMP FOUND, P143
   SHEPP LA, 1974, IEEE T NUCL SCI, VNS21, P21, DOI 10.1109/TNS.1974.6499235
   Titov EV, 2011, J THERMOPHYS HEAT TR, V25, P48, DOI 10.2514/1.49993
   Tropp JA, 2017, SIAM J MATRIX ANAL A, V38, P1454, DOI 10.1137/17M1111590
   Turk M. A., 1991, Proceedings 1991 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (91CH2983-5), P586, DOI 10.1109/CVPR.1991.139758
   VERHOEVEN D, 1993, APPL OPTICS, V32, P3736, DOI 10.1364/AO.32.003736
   Volkov V., 2008, P 20 INT C HIGH PERF
   Voronin S., 2016, ARXIV150205366V3, V2
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yamazaki I., 2015, P 27 INT C HIGH PERF
   Yu WJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3350
NR 41
TC 0
Z9 0
U1 1
U2 6
PD SEP
PY 2020
VL E103D
IS 9
BP 1949
EP 1959
DI 10.1587/transinf.2019EDP7265
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Kuroczycki, S
   Górny, K
   Pietrowski, W
AF Kuroczycki, Sebastian
   Gorny, Konrad
   Pietrowski, Wojciech
BE Nawrowski, R
   Lorenc, J
   Nadolny, Z
   Tomczewski, A
   Jajczyk, J
   Kasprzyk, L
   Bugala, A
   Budnik, K
TI Assessment of failure to the stator winding of the induction motor by
   means of deep neural network
SO COMPUTER APPLICATIONS IN ELECTRICAL ENGINEERING (ZKWE'2019)
SE ITM Web of Conferences
DT Proceedings Paper
CT Conference on Computer Applications in Electrical Engineering (ZkwE)
CY APR 15, 2019
CL Poznan, POLAND
AB Due to the fact that inter-turn short-circuits are the ones of the most common causes of damage to stator of induction motors, research on their early detection is still gaining in importance. The scientific novelty in the presented article is an approach in which a decision element informing about the failure of stator of induction machine is a deep artificial neural network. In the learning process, torque waveforms subjected to a continuous wavelet transform were used. In order to classify of the stator winding failures the accelerator of artificial neural networks was used.
C1 [Kuroczycki, Sebastian; Gorny, Konrad; Pietrowski, Wojciech] Poznan Univ Tech, Inst Elect Engn & Elect, Poznan, Poland.
RP Górny, K (corresponding author), Poznan Univ Tech, Inst Elect Engn & Elect, Poznan, Poland.
EM konrad.gorny@put.poznan.pl
CR Cusido J., IEEE T IND ELECT, V55, P663
   Grubic S., IEEE T IND ELECT, V55, P4127
   HSU JS, 1995, IEEE T IND APPL, V31, P1016, DOI 10.1109/28.464514
   Pandarakone E.S., IEEJ J IND APPL, V7, P473
   Su H, 2011, NEURAL COMPUT APPL, V20, P183, DOI 10.1007/s00521-010-0512-3
NR 5
TC 0
Z9 0
U1 1
U2 1
PY 2019
VL 28
AR 01049
DI 10.1051/itmconf/20192801049
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kurz, S
   De Gersem, H
   Galetzka, A
   Klaedtke, A
   Liebsch, M
   Loukrezis, D
   Russenschuck, S
   Schmidt, M
AF Kurz, Stefan
   De Gersem, Herbert
   Galetzka, Armin
   Klaedtke, Andreas
   Liebsch, Melvin
   Loukrezis, Dimitrios
   Russenschuck, Stephan
   Schmidt, Manuel
TI Hybrid modeling: towards the next level of scientific computing in
   engineering
SO JOURNAL OF MATHEMATICS IN INDUSTRY
DT Article
AB The integration of machine learning (Keplerian paradigm) and more general artificial intelligence technologies with physical modeling based on first principles (Newtonian paradigm) will impact scientific computing in engineering in fundamental ways. Such hybrid models combine first principle-based models with data-based models into a joint architecture. This paper will give some background, explain trends and showcase recent achievements from an applied mathematics and industrial perspective. Examples include characterization of superconducting accelerator magnets by blending data with physics, data-driven magnetostatic field simulation without an explicit model of the constitutive law, and Bayesian free-shape optimization of a trace pair with bend on a printed circuit board.
C1 [Kurz, Stefan; Klaedtke, Andreas; Schmidt, Manuel] Robert Bosch GmbH, Renningen, Germany.
   [De Gersem, Herbert; Galetzka, Armin; Loukrezis, Dimitrios] Tech Univ Darmstadt, TEMF, Darmstadt, Germany.
   [Liebsch, Melvin; Russenschuck, Stephan] CERN, Geneva, Switzerland.
RP Kurz, S (corresponding author), Robert Bosch GmbH, Renningen, Germany.
EM stefan.kurz2@de.bosch.com
CR Anglada JR., 2020, 2020 IEEE INT INSTR, P1, DOI DOI 10.1109/I2MTC43012.2020.9129153
   [Anonymous], 2018, BASIC RES NEEDS SCI
   [Anonymous], 2019, ICIAM INT C IND APPL
   Bardsley J M., 2018, COMPUTATIONAL UNCERT
   Belbute-Peres FD, 2018, ADV NEUR IN, V31
   Bishop C.M., 2006, PATTERN RECOGN, DOI DOI 10.1007/978-0-387-45528-0
   Conti S, 2018, ARCH RATION MECH AN, V229, P79, DOI 10.1007/s00205-017-1214-0
   Coveney PV, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2016.0153
   De Gersem H, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2020.3002092
   Dölz J, 2018, COMPUT METHOD APPL M, V330, P83, DOI 10.1016/j.cma.2017.10.020
   Duraisamy K, 2021, PHYS REV FLUIDS, V6, DOI 10.1103/PhysRevFluids.6.050504
   Frazier, 2018, RECENT ADV OPTIMIZAT, DOI 10.1287/educ.2018.0188
   Galetzka A, 2022, COMPEL, V41, P615, DOI 10.1108/COMPEL-06-2021-0219
   Galetzka A, 2021, INT J NUMER METH ENG, V122, P1538, DOI 10.1002/nme.6589
   Gazda C, 2012, IEEE T ELECTROMAGN C, V54, P704, DOI 10.1109/TEMC.2012.2187210
   Guarino Nicola, 2009, HDB ONTOLOGIES, P1, DOI [10.1007/978-3-540-92673-3_0, DOI 10.1007/978-3-540-92673-3_0]
   Guennebaud G., 2010, EIGEN V3
   Haag R., 1992, LOCAL QUANTUM PHYS F, DOI [10.1007/978-3-642-97306-2_2, DOI 10.1007/978-3-642-97306-2, 10.1007/978-3-642-97306-2]
   Haussmann M, 2021, PR MACH LEARN RES, V130, P478
   He RJ, 2020, IEEE T ELECTROMAGN C, V62, P1572, DOI 10.1109/TEMC.2020.3006127
   Higham CF, 2019, SIAM REV, V61, P860, DOI 10.1137/18M1165748
   Hülsmann T, 2014, COMPEL, V33, P1251, DOI 10.1108/COMPEL-11-2012-0359
   Kalman RE., 1960, NEW APPROACH LINEAR, V82, P35
   Kanno Y, 2019, OPTIM LETT, V13, P1505, DOI 10.1007/s11590-019-01409-w
   Karniadakis GE, 2021, NAT REV PHYS, V3, P422, DOI 10.1038/s42254-021-00314-5
   Kirchdoerfer T, 2016, COMPUT METHOD APPL M, V304, P81, DOI 10.1016/j.cma.2016.02.001
   Korzeniowski TF, 2021, COMPUT METHOD APPL M, V379, DOI 10.1016/j.cma.2021.113740
   Kurz S., 2022, SCI COMPUTING ELECT
   Liebsch M, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2019.2952092
   Nishimura A, ARXIV181012437, V2021
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Ramabathiran AA, 2021, J COMPUT PHYS, V445, DOI 10.1016/j.jcp.2021.110600
   RIKABI J, 1988, INT J NUMER METH ENG, V26, P1963, DOI 10.1002/nme.1620260906
   Robert C., 2013, MONTE CARLO STAT MET
   Schuhmacher S, 2018, IEEE T MAGN, V54, DOI 10.1109/TMAG.2017.2774107
   Stuart AM, 2019, BOEING DIST C
   Stysch J, 2022, IEEE T ELECTROMAGN C, V64, P750, DOI 10.1109/TEMC.2021.3134323
   Swischuk R, 2019, COMPUT FLUIDS, V179, P706, DOI 10.1016/j.compfluid.2018.07.021
   Tonti E, 2013, MODEL SIMUL SCI ENG, P1, DOI 10.1007/978-1-4614-7422-7
   Tonti E., 2014, DISCRETE PHYS ALGEBR
   Trowbridge B., 2001, COMPUMAG C THE 1 25
   Walker M, 2018, G00340159 GARTH RES
   Weinan E, 2018, COMMUN MATH STAT, V6, P1, DOI 10.1007/s40304-018-0127-z
   Wikipedia contributors, 2019, NEWT LAWS MOT WIK FR
   Willcox K, 2019, ICIAM INT C IND APPL
NR 45
TC 7
Z9 7
U1 0
U2 10
PD MAR 3
PY 2022
VL 12
IS 1
AR 8
DI 10.1186/s13362-022-00123-0
WC Mathematics, Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Jiang, ZW
   Yin, SH
   Seo, JS
   Seok, M
AF Jiang, Zhewei
   Yin, Shihui
   Seo, Jae-Sun
   Seok, Mingoo
GP IEEE
TI C3SRAM: In-Memory-Computing SRAM Macro Based on Capacitive-Coupling
   Computing
SO IEEE 45TH EUROPEAN SOLID STATE CIRCUITS CONFERENCE (ESSCIRC 2019)
SE Proceedings of the European Solid-State Circuits Conference
DT Proceedings Paper
CT IEEE 45th European Solid State Circuits Conference (ESSCIRC)
CY SEP 23-26, 2019
CL Cracow, POLAND
DE Capacitive coupling; in-memory-computing (IMC); machine learning
   accelerator; mixed-signal processing; neural network
AB This letter presents C3SRAM, an in-memory-computing SRAM macro, which utilizes analog-mixed-signal capacitive-coupling computing to perform XNOR-and-accumulate operations for binary deep neural networks. The 256 x 64 C3SRAM macro asserts all 256 rows simultaneously and equips one ADC per column, realizing fully parallel vector-matrix multiplication in one cycle. C3SRAM demonstrates 672 TOPS/W and 1638 GOPS, and achieves 98.3% accuracy for MNIST and 85.5% for CIFAR-10 dataset. It achieves 3975 x smaller energy-delay product than conventional digital processors.
C1 [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Elect Engn Dept, New York, NY 10027 USA.
   [Yin, Shihui; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
RP Jiang, ZW (corresponding author), Columbia Univ, Elect Engn Dept, New York, NY 10027 USA.
EM zj2139@columbia.edu
CR Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/vlsic.2019.8778028, 10.23919/VLSIC.2019.8778028]
   Hubara I, 2018, J MACH LEARN RES, V18
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/VLSIC.2019.8778160, 10.23919/vlsic.2019.8778160]
   Okumura S, 2019, S VLSI TECH, pC248
   Si X., 2019, P IEEE ISSCC
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Zhan J, 2016, INT SYMP MICROARCH
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
NR 12
TC 23
Z9 24
U1 0
U2 2
PY 2019
BP 131
EP +
DI 10.1109/LSSC.2019.2934831
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Wen, Y
   O'Boyle, MFP
AF Wen, Yuan
   O'Boyle, Michael F. P.
GP ACM
TI Merge or Separate? Multi-job Scheduling for OpenCL Kernels on CPU/GPU
   Platforms
SO PROCEEDINGS OF THE GENERAL PURPOSE GPUS (GPGPU-10)
DT Proceedings Paper
CT Workshop on General Purpose GPUs (GPGPU)
CY FEB 04-08, 2017-2018
CL Austin, TX
DE CPU-GPU runtime system; GPU kernel scheduling; concurrent kernel;
   machine learning
AB Computer systems are increasingly heterogeneous with nodes consisting of CPUs and GPU accelerators. As such systems become mainstream, they move away from specialized high-performance single application platforms to a more general setting with multiple, concurrent, application jobs. Determining how jobs should be dynamically best scheduled to heterogeneous devices is non-trivial. In certain cases, performance is maximized if jobs are allocated to a single device, in others, sharing is preferable. In this paper, we present a runtime framework which schedules multi-user OpenCL tasks to their most suitable device in a CPU/GPU system. We use a machine learning-based predictive model at runtime to detect whether to merge OpenCL kernels or schedule them separately to the most appropriate devices without the need for ahead-of-time profiling. We evaluate out approach over a wide range of workloads, on two separate platforms. We consistently show significant performance and turn-around time improvement over the state-of-the-art across programs, workload, and platforms.
C1 [Wen, Yuan; O'Boyle, Michael F. P.] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Wen, Y (corresponding author), Univ Edinburgh, Edinburgh, Midlothian, Scotland.
EM ywen@inf.ed.ac.uk; mob@inf.ed.ac.uk
CR Ahmad W, 2015, LECT NOTES ARTIF INT, V9329, P316, DOI 10.1007/978-3-319-24069-5_30
   Aji AM, 2015, IEEE INT C CL COMP, P42, DOI 10.1109/CLUSTER.2015.15
   Al-Najjar NI, 2014, J ECON THEORY, V150, P467, DOI 10.1016/j.jet.2013.12.003
   [Anonymous], 2012, 4 USENIX WORKSH HOT
   Augonnet Cedric, 2009, CONCURRENCY COMPUTAT
   Cawley GC, 2008, MACH LEARN, V71, P243, DOI 10.1007/s10994-008-5055-9
   Courtes  L., 2013, ABS13040878 CORR
   Filipovic  J., J SUPERCOMPUTING
   Grewe  D., 2013, 2 INT C PERS TECHN
   Guevara Marisabel, 2009, WORKSH PROGR MOD EM, V9
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Hugo Andra-Ecaterina, 2013, 2013 IEEE International Symposium on Parallel and Distributed Processing, Workshops and PhD Forum (IPDPSW), P1050, DOI 10.1109/IPDPSW.2013.217
   Jablin T. B., 2012, 10 ANN IEEE ACM INT
   Jiao Q, 2015, P 13 ANN IEEE ACM IN
   Jog  A., 2014, 7 WORKSH GEN PURP PR
   Kaleem R, 2014, INT CONFER PARA, P151, DOI 10.1145/2628071.2628088
   Li T, 2015, INT C PAR DISTRIB SY, P562, DOI 10.1109/ICPADS.2015.76
   Margiolas C, 2016, INT SYM CODE GENER, P82, DOI 10.1145/2854038.2854040
   Neelima  B., 2015, CONCURRENCY COMPUTAT, V27
   O'Boyle M. F. P., 2015, P 29 ACM INT C SUP I
   Pai  S., 2013, ARCHITECTURAL SUPPOR
   Pandit  P., 2014, 12 ANN IEEE ACM INT
   Park J. J. K., 2015, P 20 INT C ARCH SUPP
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Ravi V. T., 2012, SC C HIGH PERF COMP
   Sarkar S., 2015, PROFILE GUIDED APPRO, P176
   Sartori J, 2013, IEEE T MULTIMEDIA, V15, P279, DOI 10.1109/TMM.2012.2232647
   Wang G., 2010, 2010 IEEE ACM INT C
   Wen Y, 2014, INT C HIGH PERFORM
   Zhong  J., IEEE T PARALLEL DIST
NR 30
TC 23
Z9 23
U1 0
U2 3
PY 2017
BP 22
EP 31
DI 10.1145/3038228.3038235
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Marchisio, A
   Mrazek, V
   Hanif, MA
   Shafique, M
AF Marchisio, Alberto
   Mrazek, Vojtech
   Hanif, Muhammad Abdullah
   Shafique, Muhammad
TI DESCNet: Developing Efficient Scratchpad Memories for Capsule Network
   Hardware
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Memory management; Hardware; System-on-chip; Two dimensional displays;
   Memory architecture; Routing; Capsule networks (CapsNets); design space
   exploration (DSE); energy efficiency; machine learning (ML); memory
   design; memory management; performance; power gating; scratchpad memory
   (SPM); special-purpose hardware
AB Deep neural networks (DNNs) have been established as the state-of-the-art method for advanced machine learning applications. Recently proposed by the Google Brain's team, the capsule networks (CapsNets) have improved the generalization ability, as compared to DNNs, due to their multidimensional capsules and preserving the spatial relationship between different objects. However, they pose significantly high computational and memory requirements, making their energy-efficient inference a challenging task. This article provides, for the first time, an in-depth analysis to highlight the design and runtime challenges for the (on-chip scratchpad) memories deployed in hardware accelerators executing fast CapsNets inference. To enable an efficient design, we propose an application-specific memory architecture, called DESCNet, which minimizes the off-chip memory accesses, while efficiently feeding the data to the hardware accelerator executing CapsNets inference. We analyze the corresponding on-chip memory requirement and leverage it to propose a methodology for exploring different scratchpad memory (SPM) designs and their energy/area tradeoffs. Afterward, an application-specific power-gating technique for the on-chip SPM is employed to further reduce its energy consumption, depending upon the mapped dataflow of the CapsNet and the utilization across different operations of its processing. We integrated our DESCNet memory design, as well as another state-of-the-art memory design Marchisio et al. [2018] for comparison studies, with an opensource DNN accelerator executing Google's CapsNet model Sabour et al. [2017] for the MNIST dataset. We also enhanced the design to execute the recent deep CapsNet model Rajasegaran et al. [2019] for the CIFAR10 dataset. Note: we use the same benchmarks and test conditions for which these CapsNets have been proposed and evaluated by their respective teams. The complete hardware is synthesized for a 32-nm CMOS technology using the ASIC-design flow with Synopsys tools and CACTI-P, and detailed area, performance, and power/energy estimation is performed using different configurations. Our results for a selected Pareto-optimal solution demonstrate no performance loss and an energy reduction of 79% for the complete accelerator, including computational units and memories, when compared to the state-of-the-art design.
C1 [Marchisio, Alberto; Hanif, Muhammad Abdullah] Tech Univ Wien, Inst Comp Engn, Dept Informat, A-1040 Vienna, Austria.
   [Mrazek, Vojtech] Brno Univ Technol, Dept Comp Syst, Brno 61266, Czech Republic.
   [Shafique, Muhammad] New York Univ, Div Engn, Abu Dhabi, U Arab Emirates.
RP Marchisio, A (corresponding author), Tech Univ Wien, Inst Comp Engn, Dept Informat, A-1040 Vienna, Austria.
EM alberto.marchisio@tuwien.ac.at
CR Ahmed K, 2019, ADV NEUR IN, V32
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Duarte K, 2018, ADV NEUR IN, V31
   Hahn T., 2019, ADV NEURAL INFORM PR, V32, P7656
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   LaLonde R., 2018, ARXIV180404241
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li H., 2019, P DAC, P131
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Marchisio A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415731
   Marchisio A, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9207533
   Marchisio A, 2020, DES AUT TEST EUROPE, P1205, DOI [10.23919/date48585.2020.9116393, 10.23919/DATE48585.2020.9116393]
   Marchisio A, 2019, DES AUT TEST EUROPE, P964, DOI [10.23919/DATE.2019.8714922, 10.23919/date.2019.8714922]
   MUKHOMETZIANOV Rinat, 2018, ARXIV PREPRINT ARXIV
   Panda P. R., ACM T DESIGN AUTOM E
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin Y, 2020, P ICLR, P1
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Roy S, 2011, IEEE T COMPUT, V60, P1547, DOI 10.1109/TC.2010.249
   Sabour S., 2017, ADV NEURAL INFORM PR, P3856
   Salakhutdinov R., 2020, P AAAI C ART INT, P1
   Saqur R, 2020, ADV INTELL SYST COMP, V944, P511, DOI 10.1007/978-3-030-17798-0_41
   Wang MX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P803
   Xi E., 2017, CAPSULE NETWORK PERF
   Xiao Han, 2017, ARXIV170807747, P4321
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
NR 32
TC 8
Z9 8
U1 0
U2 2
PD SEP
PY 2021
VL 40
IS 9
BP 1768
EP 1781
DI 10.1109/TCAD.2020.3030610
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jiang, ZW
   Yin, SH
   Seo, JS
   Seok, M
AF Jiang, Zhewei
   Yin, Shihui
   Seo, Jae-Sun
   Seok, Mingoo
TI C3SRAM: In-Memory-Computing SRAM Macro Based on Capacitive-Coupling
   Computing
SO IEEE SOLID-STATE CIRCUITS LETTERS
DT Article
DE Capacitive coupling; in-memory-computing (IMC); machine learning
   accelerator; mixed-signal processing; neural network
AB This letter presents C3SRAM, an in-memory-computing SRAM macro, which utilizes analog-mixed-signal capacitive-coupling computing to perform XNOR-and-accumulate operations for binary deep neural networks. The 256 x 64 C3SRAM macro asserts all 256 rows simultaneously and equips one ADC per column, realizing fully parallel vector-matrix multiplication in one cycle. C3SRAM demonstrates 672 TOPS/W and 1638 GOPS, and achieves 98.3% accuracy for MNIST and 85.5% for CIFAR-10 dataset. It achieves 3975x smaller energy-delay product than conventional digital processors.
C1 [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Elect Engn Dept, New York, NY 10027 USA.
   [Yin, Shihui; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
RP Jiang, ZW (corresponding author), Columbia Univ, Elect Engn Dept, New York, NY 10027 USA.
EM zj2139@columbia.edu
CR Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Garnett W., 2017, ADV NEURAL INFORM PR, V30, P345, DOI DOI 10.48550/ARXIV.1711.11294
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/vlsic.2019.8778028, 10.23919/VLSIC.2019.8778028]
   Hubara I, 2018, J MACH LEARN RES, V18
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/VLSIC.2019.8778160, 10.23919/vlsic.2019.8778160]
   Okumura S, 2019, S VLSI TECH, pC248
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 12
TC 8
Z9 8
U1 0
U2 4
PD SEP
PY 2019
VL 2
IS 9
BP 131
EP 134
DI 10.1109/LSSC.2019.2934831
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Shoaib, M
   Jha, N
   Verma, N
AF Shoaib, Mohammed
   Jha, Niraj
   Verma, Naveen
GP ACM
   IEEE
   EDAC
TI A Low-Energy Computation Platform for Data-Driven Biomedical Monitoring
   Algorithms
SO PROCEEDINGS OF THE 48TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 48th ACM/IEEE/EDAC Design Automation Conference (DAC)
CY JUN 05-09, 2011
CL San Diego, CA
ID CLASSIFICATION
AB A key challenge in closed-loop chronic biomedical systems is the ability to detect complex physiological states from patient signals within a constrained power budget. Data-driven machine-learning techniques are major enablers for the modeling and interpretation of such states. Their computational energy, however, scales with the complexity of the required models. In this paper, we propose a low-energy, biomedical computation platform optimized through the use of an accelerator for data-driven classification. The accelerator retains selective flexibility through hardware reconfiguration and exploits voltage scaling and parallelism to operate at a subthreshold minimum-energy point. Using cardiac arrhythmia detection algorithms with patient data from the MIT-BIH database, classification is achieved in 2.96 mu J (at V-dd = 0.4 V), over four orders of magnitude smaller than that on a low-power general-purpose processor. The energy of feature extraction is 148 mu J while retaining flexibility for a range of possible biomarkers.
C1 [Shoaib, Mohammed; Jha, Niraj; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Shoaib, M (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM mshoaib@princeton.edu; jha@princeton.edu; nverma@princeton.edu
CR AbuKhater IS, 1996, IEEE J SOLID-ST CIRC, V31, P1535, DOI 10.1109/4.540066
   Benabid A. L., CURRENT OP NEUROBIOL, V13, P696
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Csavoy A, 2009, SYMP VLSI CIRCUITS, P4
   de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359
   Dishman E, 2004, COMPUTER, V37, P34, DOI 10.1109/MC.2004.1297237
   Hau D., 1994, P AAAI S ART INT MED, VSS-94-01, P67
   Jaffe AS, 2006, J AM COLL CARDIOL, V48, P1, DOI 10.1016/j.jacc.2006.02.056
   Jaochims T., SVM LIGHT SUPPORT VE
   Khan F. M., 2005, P IEEE INT S CIRC SY, P23
   Lebedev MA, 2006, TRENDS NEUROSCI, V29, P536, DOI 10.1016/j.tins.2006.07.004
   Meyfroidt G, 2009, BEST PRAC RES-CL ANA, V23, P127, DOI 10.1016/j.bpa.2008.09.003
   Physionet, MIT BIH PHYS DAT
   Shoeb A., 2005, P IEEE INT C EMBS, P4202
   Shoeb A., 2010, P C MACH LEARN JUN
   Shoeb AH, 2009, APPL MACHINE LEARNIN
   Shoeb A, 2007, P ANN INT IEEE EMBS, P4110, DOI 10.1109/IEMBS.2007.4353240
   Sze V, 2007, ISLPED'07: PROCEEDINGS OF THE 2007 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P262, DOI 10.1145/1283780.1283837
   *TENS INC, XTENS PROC
   Übeyli ED, 2007, DIGIT SIGNAL PROCESS, V17, P675, DOI 10.1016/j.dsp.2006.11.009
   Verma N, 2009, SYMP VLSI CIRCUITS, P62
   Vitale SA, 2010, P IEEE, V98, P333, DOI 10.1109/JPROC.2009.2034476
   Wang A, 2005, IEEE J SOLID-ST CIRC, V40, P310, DOI 10.1109/JSSC.2004.837945
NR 23
TC 11
Z9 11
U1 1
U2 2
PY 2011
BP 591
EP 596
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Siu, K
   Stuart, DM
   Mahmoud, M
   Moshovos, A
AF Siu, Kevin
   Stuart, Dylan Malone
   Mahmoud, Mostafa
   Moshovos, Andreas
GP IEEE
TI Memory Requirements for Convolutional Neural Network Hardware
   Accelerators
SO 2018 IEEE INTERNATIONAL SYMPOSIUM ON WORKLOAD CHARACTERIZATION (IISWC)
SE International Symposium on Workload Characterization Proceedings
DT Proceedings Paper
CT IEEE International Symposium on Workload Characterization (IISWC)
CY SEP 30-OCT 02, 2018
CL Raleigh, NC
AB The rapid pace and successful application of machine learning research and development has seen widespread deployment of deep convolutional neural networks (CNNs). Alongside these algorithmic efforts, the compute- and memory-intensive nature of CNNs has stimulated a large amount of work in the field of hardware acceleration for these networks. In this paper, we profile the memory requirements of CNNs in terms of both on-chip memory size and off-chip memory bandwidth, in order to understand the impact of the memory system on accelerator design. We show that there are fundamental trade-offs between performance, bandwidth, and on-chip memory. Further, this paper explores how the wide variety of CNNs for different application domains each have fundamentally different characteristics. We show that bandwidth and memory requirements for different networks, and occasionally for different layers within a network, can each vary by multiple orders of magnitude. This makes designing fast and efficient hardware for all CNN applications difficult. To remedy this, we outline heuristic design points that attempt to optimize for select dataflow scenarios.
C1 [Siu, Kevin; Stuart, Dylan Malone; Mahmoud, Mostafa; Moshovos, Andreas] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
RP Siu, K (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM siukevi4@ece.utoronto.ca; malones2@ece.utoronto.ca;
   mostafam@ece.utoronto.ca; moshovos@ece.utoronto.ca
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chanana Ashish, 2017, 2017 42nd International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2017.8067214
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Geras KJ, 2017, ARXIV PREPRINT ARXIV
   Gharbi M, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2980179.2982399
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2015, ARXIV
   Howard A. G., 2017, ARXIV
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hubara I, 2018, J MACH LEARN RES, V18
   Iandola F. N., 2016, ARXIV
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd  P., 2018, ABS180303688 CORR
   Judd  P., 2016, P 2016 INT C SUP
   Kim J., 2015, ABS151104587 CORR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Oord A. V. D., 2016, ARXIV
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Szegedy C., 2013, ADV NEURAL INFORM PR, P2553
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Teichmann M., 2016, ARXIV161207695
   Xiao Huaxin, 2017, ABS170701629 CORR
   Yang Xuan, 2016, ARXIV160604209
   Zhang K., 2016, ABS160803981 CORR, V5
   ZHANG K, 2017, PROC CVPR IEEE, P2808, DOI DOI 10.1109/CVPR.2017.300
   Zhang Kai, 2017, ABS171004026 CORR
NR 34
TC 41
Z9 42
U1 0
U2 0
PY 2018
BP 111
EP 121
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zervakis, G
   Saadat, H
   Amrouch, H
   Gerstlauer, A
   Parameswaran, S
   Henkel, J
AF Zervakis, Georgios
   Saadat, Hassaan
   Amrouch, Hussam
   Gerstlauer, Andreas
   Parameswaran, Sri
   Henkel, Joerg
GP IEEE
TI Approximate Computing for ML: State-of-the-art, Challenges and Visions
SO 2021 26TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 26th Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 18-21, 2021
CL ELECTR NETWORK
DE Approximate Computing; Architecture; Accelerator; High-Level Synthesis;
   Inference; Logic; Low-power; Multiplier; Neural Network; Renconfigurable
   Accuracy; Temperature
ID POWER
AB In this paper, we present our state-of-the-art approximate techniques that cover the main pillars of approximate computing research. Our analysis considers both static and reconfigurable approximation techniques as well as operation-specific approximate components (e.g., multipliers) and generalized approximate high-level synthesis approaches. As our application target, we discuss the improvements that such techniques bring on machine learning and neural networks. In addition to the conventionally analyzed performance and energy gains, we also evaluate the improvements that approximate computing brings in the operating temperature.
C1 [Zervakis, Georgios; Henkel, Joerg] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Saadat, Hassaan; Parameswaran, Sri] Univ New South Wales, Sydney, NSW, Australia.
   [Amrouch, Hussam] Univ Stuttgart, Stuttgart, Germany.
   [Gerstlauer, Andreas] Univ Texas Austin, Austin, TX 78712 USA.
RP Zervakis, G (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM georgios.zervakis@kit.edu; h.saadat@unsw.edu.au;
   amrouch@iti.uni-stuttgart.de; gerstl@ece.utexas.edu;
   sri.parameswaran@unsw.edu.au; henkel@kit.edu
CR Alan T, 2020, DES AUT TEST EUROPE, P1578, DOI 10.23919/DATE48585.2020.9116272
   Amrouch H, 2020, IEEE T COMPUT AID D, V39, P3842, DOI 10.1109/TCAD.2020.3012753
   Amrouch H, 2017, DES AUT CON, DOI 10.1145/3061639.3062331
   [Anonymous], 2015, P 52 ANN DESIGN AUTO
   Ansari MS, 2019, DES AUT TEST EUROPE, P928, DOI [10.23919/date.2019.8714868, 10.23919/DATE.2019.8714868]
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   Boroujerdian B, 2018, PR IEEE COMP DESIGN, P202, DOI 10.1109/ICCD.2018.00039
   Bulman G, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms10302
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   He K, 2011, DES AUT TEST EUROPE, P758
   Jain S, 2018, DES AUT CON, DOI 10.1145/3195970.3196012
   Jiang H., 2017, ACM J EMERG TECH COM, V13, P1, DOI DOI 10.1145/3094124
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim H, 2020, IEEE T CIRCUITS-I, V67, P1319, DOI 10.1109/TCSI.2020.2969462
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kyaw K Y, 2010, IEEE INT C ELECT DEV, DOI DOI 10.1109/EDSSC.2010.5713751
   Lee S., 2016, IEEE INT S QUAL EL D
   Lee S., 2019, APPROXIMATE CIRCUITS
   Lee S, 2018, IEEE EMBED SYST LETT, V10, P18, DOI 10.1109/LES.2017.2764542
   Lee S, 2017, DES AUT TEST EUROPE, P187, DOI 10.23919/DATE.2017.7926980
   Lee S, 2013, IEEE INT CONF VLSI, P266, DOI 10.1109/VLSI-SoC.2013.6673287
   Miao J., 2012, IEEE ACM INT C COMP
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Narayanamoorthy S, 2015, IEEE T VLSI SYST, V23, P1180, DOI 10.1109/TVLSI.2014.2333366
   Raha A, 2017, DES AUT CON, DOI 10.1145/3061639.3062333
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Saadat H, 2020, DES AUT TEST EUROPE, P1366, DOI 10.23919/DATE48585.2020.9116315
   Saadat H, 2018, IEEE T COMPUT AID D, V37, P2623, DOI 10.1109/TCAD.2018.2857262
   Sarwar SS, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3097264
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tong JYF, 2000, IEEE T VLSI SYST, V8, P273, DOI 10.1109/92.845894
   Wang E., 2019, ARXIV PREPRINT ARXIV
   Zervakis G, 2020, IEEE ACCESS, V8, P53522, DOI 10.1109/ACCESS.2020.2981395
   Zervakis G, 2019, IEEE T VLSI SYST, V27, P1460, DOI 10.1109/TVLSI.2019.2900160
   Zervakis G, 2019, IEEE T CIRCUITS-II, V66, P607, DOI 10.1109/TCSII.2018.2869025
   Zhang H, 2014, PR IEEE COMP DESIGN, P48, DOI 10.1109/ICCD.2014.6974661
NR 38
TC 17
Z9 17
U1 0
U2 4
PY 2021
BP 189
EP 196
DI 10.1145/3394885.3431632
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Hu, YC
   Li, YL
   Tseng, HW
AF Hu, Yu-Ching
   Li, Yuliang
   Tseng, Hung-Wei
GP ACM
TI TCUDB: Accelerating Database with Tensor Processors
SO PROCEEDINGS OF THE 2022 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA
   (SIGMOD '22)
SE International Conference on Management of Data
DT Proceedings Paper
CT International Conference on Management of Data (SIGMOD)
CY JUN 12-17, 2022
CL Philadelphia, PA
DE Tensor Cores; Database Engine; GPU
ID SCALABLE LINEAR ALGEBRA; GPU; PERFORMANCE; MANAGEMENT; SYSTEMS
AB The emergence of novel hardware accelerators has powered the tremendous growth of machine learning in recent years. These accelerators deliver incomparable performance gains in processing high-volume matrix operators, particularly matrix multiplication, a core component of neural network training and inference. In this work, we explored opportunities of accelerating database systems using NVIDIA's Tensor Core Units (TCUs). We present TCUDB, a TCU-accelerated query engine processing a set of query operators including natural joins and group-by aggregates as matrix operators within TCUs. Matrix multiplication was considered inefficient in the past; however, this strategy has remained largely unexplored in conventional GPU-based databases, which primarily rely on vector or scalar processing. We demonstrate the significant performance gain of TCUDB in a range of real-world applications including entity matching, graph query processing, and matrix-based data analytics. TCUDB achieves up to 288x speedup compared to a baseline GPU-based query engine.
C1 [Hu, Yu-Ching; Tseng, Hung-Wei] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Li, Yuliang] Megagon Labs, Mountain View, CA USA.
RP Hu, YC (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM yhu130@ucr.edu; yuliang@megagon.ai; htseng@ucr.edu
CR Abadi D. J., 2008, P ACM SIGMOD INT C M, DOI DOI 10.1145/1376616.1376712
   Abadi DJ, 2009, PROC VLDB ENDOW, V2, P1664, DOI 10.14778/1687553.1687625
   Aberger CR, 2018, PROC INT CONF DATA, P449, DOI 10.1109/ICDE.2018.00048
   AMD, 2014, DIRECTGMA AMDS FIREP
   [Anonymous], 2019, GPUDIRECT RDMA
   [Anonymous], 2014, OSDI
   [Anonymous], 2009, DATABASE THEORY ICDT, DOI DOI 10.1145/1514894.1514909
   [Anonymous], 2015, SYNTHESIS LECT SEMAN, DOI DOI 10.2200/S00655ED1V01Y201507WBE013
   Apple Inc, 2020, APPL M1
   Bakkum P., 2010, P 3 WORKSH GEN PURP, DOI DOI 10.1145/1735688.1735706
   Boncz P.A., 2005, CIDR
   Bress S, 2018, VLDB J, V27, P797, DOI 10.1007/s00778-018-0512-y
   Bress S, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1891, DOI 10.1145/2882903.2882936
   Bress S, 2013, PROC VLDB ENDOW, V6, P1398
   Brijder R, 2019, ACM T DATABASE SYST, V44, DOI 10.1145/3331445
   Chengxin Guo, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P1060, DOI 10.1109/HPCC/SmartCity/DSS.2019.00151
   Choi W., 2020, IEEE T COMPUT, P1
   Chrysogelos Periklis, 2019, 9 BIENN C INN DAT SY
   D'silva JV, 2018, PROC VLDB ENDOW, V11, P1400, DOI 10.14778/3236187.3236194
   Dakkak A, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P46, DOI 10.1145/3330345.3331057
   Davis Tim, 2017, GRAPHBLAS STANDARD
   Deep S, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1213, DOI 10.1145/3318464.3380607
   Deutsch A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P377, DOI 10.1145/3318464.3386144
   Do Jaeyoung, 2009, P 5 INT WORKSH DAT H, P1
   Do Jaeyoung, 2013, P 2013 ACM SIGMOD IN, P1221
   Dolmatova O, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2573, DOI 10.1145/3318464.3389747
   Dong XL, 2013, PROC INT CONF DATA, P1245, DOI 10.1109/ICDE.2013.6544914
   Elmagarmid AK, 2007, IEEE T KNOWL DATA EN, V19, P1, DOI 10.1109/TKDE.2007.250581
   Fang J, 2020, VLDB J, V29, P33, DOI 10.1007/s00778-019-00581-w
   Funke H, 2018, INT CONF MANAGE DATA, P1603, DOI 10.1145/3183713.3183734
   Gagliardelli Luca, 2019, EDBT 2019 22 INT C E
   Gleich DF, 2015, SIAM REV, V57, P321, DOI 10.1137/140976649
   Govindaraju N., 2006, P 2006 ACM SIGMOD IN, P325, DOI DOI 10.1145/1142473.1142511
   Govindaraju Naga K., 2004, P 2004 ACM SIGMOD IN, P215, DOI [10.1145/1007568.1007594, DOI 10.1145/1007568.1007594]
   He B., 2013, GPUDB SOURCE CODE
   He B, 2008, SIGMOD, P511, DOI [10.1145/1376616.1376670, DOI 10.1145/1376616.1376670]
   He BS, 2009, ACM T DATABASE SYST, V34, DOI 10.1145/1620585.1620588
   He J, 2013, PROC VLDB ENDOW, V6, P889, DOI 10.14778/2536206.2536216
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Holanda P, 2019, 15TH INTERNATIONAL WORKSHOP ON DATA MANAGEMENT ON NEW HARDWARE (DAMON 2019), DOI 10.1145/3329785.3329932
   Hu YC, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P196, DOI 10.1145/3352460.3358282
   Hutchison Dylan, 2017, P 4 ACM SIGMOD WORKS, V2, P1, DOI 10.1145
   Inc S.A.S., 2015, BLAZINGDB
   Jamour F, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303962
   Jin YQ, 2017, INT S HIGH PERF COMP, P373, DOI 10.1109/HPCA.2017.15
   Jun SW, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P1, DOI 10.1145/2749469.2750412
   Kaldewey Tim, 2012, P 8 INT WORKSH DAT M, P55
   Karnagel Tomas, 2015, ADMS VLDB, V8, P20
   Kinetica DB Inc, 2016, KIN
   Konda P, 2016, PROC VLDB ENDOW, V9, P1197
   Koo G, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P219, DOI 10.1145/3123939.3124553
   LAM MS, 1991, SIGPLAN NOTICES, V26, P63, DOI 10.1145/106973.106981
   Leskovec J, 2009, INTERNET MATH, V6, P29, DOI 10.1080/15427951.2009.10129177
   Li J, 2016, PROC VLDB ENDOW, V9, P1647, DOI 10.14778/3007328.3007331
   Liu Y, 2016, PR IEEE COMP DESIGN, P376, DOI 10.1109/ICCD.2016.7753307
   Liu Yu-Chia, 2021, 54 ANN IEEEACM INT S
   Luo SY, 2019, IEEE T KNOWL DATA EN, V31, P1224, DOI 10.1109/TKDE.2018.2827988
   Lutz C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1633, DOI 10.1145/3318464.3389705
   Mahajan D, 2018, PROC VLDB ENDOW, V11, P1317, DOI 10.14778/3236187.3236188
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Mitliagkas I, 2015, PROC VLDB ENDOW, V8, P874, DOI 10.14778/2757807.2757812
   Mudgal S, 2018, INT CONF MANAGE DATA, P19, DOI 10.1145/3183713.3196926
   Mueller R, 2009, ACM SIGMOD/PODS 2009 CONFERENCE, P999
   Needham M., 2019, GRAPH ALGORITHMS PRA, V1st
   Ngo HQ, 2018, J ACM, V65, DOI 10.1145/3180143
   O'Neil P, 2009, LECT NOTES COMPUT SC, V5895, P237, DOI 10.1007/978-3-642-10424-4_17
   OmniSci Inc, 2018, OPEN SOURCE ANAL DAT
   Owaida M, 2019, PROC VLDB ENDOW, V13, P71, DOI 10.14778/3357377.3357383
   Papadakis G, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3377455
   Paszke A, 2019, ADV NEUR IN, V32
   Paul J, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1935, DOI 10.1145/2882903.2915224
   Pedram Ghodsnia., 2012, IN GPU MEMORY COLUMN, P54
   Pelley S, 2013, PROC VLDB ENDOW, V7, P121, DOI 10.14778/2732228.2732231
   Rungsawang A., 2012, Proceedings of the 2012 20th Euromicro International Conference on Parallel, Distributed and Network-Based Processing (PDP 2012), P450, DOI 10.1109/PDP.2012.78
   Sato K, 2017, IN DEPTH LOOK GOOGLE
   Shanbhag A, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1617, DOI 10.1145/3318464.3380595
   Shi XH, 2018, ACM COMPUT SURV, V50, DOI 10.1145/3128571
   Sioulas P, 2019, PROC INT CONF DATA, P698, DOI 10.1109/ICDE.2019.00068
   Sitaridi Evangelia A, 2013, P 9 INT WORKSHOP DAT, P1
   Thomas A, 2018, PROC VLDB ENDOW, V11, P2168, DOI 10.14778/3275366.3275367
   Tianji Wu, 2010, Proceedings 39th International Conference on Parallel Processing (ICPP 2010), P81, DOI 10.1109/ICPP.2010.17
   Tseng Hung-Wei, 2015, GULLFOSS ACCELERATIN
   Volk P., 2010, ADMS VLDB
   Walkowiak S, 2010, PROCEDIA COMPUT SCI, V1, P505, DOI 10.1016/j.procs.2010.04.054
   Wang Endong, 2014, HIGH PERFORMANCE COM, P167, DOI [10.1007/978-3-319-06486-4_7, DOI 10.1007/978-3-319-06486-47]
   Wang JG, 2017, PROC VLDB ENDOW, V10, P853, DOI 10.14778/3090163.3090164
   Wang Jianguo, 2016, IEEE T COMPUT, V2016
   Wang KB, 2014, PROC VLDB ENDOW, V7, P1011
   Wang Zeke, 2016, P 2016 ACMSIGDA INT, P274
   Wu H., 2014, INT WORKSHOP ACCELER, P1
   Wu HC, 2012, INT SYMP MICROARCH, P107, DOI 10.1109/MICRO.2012.19
   Yuan Y, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P273, DOI 10.1109/BigData.2016.7840613
   Yuan Y, 2013, PROC VLDB ENDOW, V6, P817
   Zachariadis O, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106848
   Zhang J, 2015, INT CONFER PARA, P13, DOI 10.1109/PACT.2015.43
   Zhang K, 2015, J COMPUT SCI TECH-CH, V30, P657, DOI 10.1007/s11390-015-1553-y
   Zimmerman Zach, 2016, MSPLITGEMM LARGE MAT
NR 97
TC 3
Z9 3
U1 2
U2 2
PY 2022
BP 1360
EP 1374
DI 10.1145/3514221.3517869
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU da Rosa, MMA
   Paim, G
   Castro-Godínez, J
   da Costa, EAC
   Soares, RI
   Bampi, S
AF da Rosa, Morgana M. A.
   Paim, Guilherme
   Castro-Godinez, Jorge
   da Costa, Eduardo A. C.
   Soares, Rafael I.
   Bampi, Sergio
GP IEEE
TI AxRSU: Approximate Radix-4 Squarer Unit
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS 22)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 28-JUN 01, 2022
CL Austin, TX
DE Approximate Computing; Approximate Squarer Unit; Radix-4 Squarer Unit;
   VLSI Hardware Design
ID COMPRESSORS; HARDWARE; DESIGN; ADDER
AB Approximate computing emerged as a design alternative to boost design efficiency by leveraging the intrinsic error resiliency of many applications. Several error-resilient and compute-intensive applications such as signal, image, and video processing, computer vision, and supervised machine learning perform mean squared error (MSE) estimation during the runtime demanding dedicated squarer logic units in their hardware accelerators. This work proposes an approximate Radix-4 squarer unit architecture (AxRSU). Our AxRSU proposal reduces the encoder complexity and the number of required partial products, which considerably boosts energy and circuit area savings. We demonstrate the AxRSU error-quality trade-off in an SSD (Sum Squared Difference) hardware accelerator as a case study targeting a video processing application. We offer a new Pareto front with eighth optimal AxRSU solutions ranging 52-97% of cross-correlation (i.e., accuracy) for savings of 15-47% in energy consumption and 12-32% in circuit area.
C1 [da Rosa, Morgana M. A.; Soares, Rafael I.] Fed Univ Pelotas UFPel, Grad Program Comp, Pelotas, Brazil.
   [Castro-Godinez, Jorge] Inst Tecnol Costa Rica TEC, Sch Elect Engn, Cartago, Costa Rica.
   [da Costa, Eduardo A. C.] Catholic Univ Pelotas UCPel, Grad Program Elect Engn & Comp, Pelotas, Brazil.
   [Paim, Guilherme; Bampi, Sergio] Fed Univ Rio Grande do Sul UFRGS, PPGC & PGMICRO Informat Inst, Porto Alegre, Brazil.
RP da Rosa, MMA (corresponding author), Fed Univ Pelotas UFPel, Grad Program Comp, Pelotas, Brazil.
CR BANERJEE A, 2016, 19 INT S VLSI DES TE, V10, P205, DOI DOI 10.1049/IET-CDT.2015.0170
   Bossen F, 2013, JCTVCL1100
   Bui S, 2014, IEEE INT SYMP CIRC S, P361, DOI 10.1109/ISCAS.2014.6865140
   Chen YH, 2015, IEEE T CIRCUITS-II, V62, P851, DOI 10.1109/TCSII.2015.2435752
   da Rosa M. M. A., 2020, 2020 27 IEEE INT C E, P1
   Dadda L., 1965, ALTA FREQUENZA
   Gillani GA, 2018, IEEE ACCESS, V6, P49112, DOI 10.1109/ACCESS.2018.2868036
   Guidotti V, 2020, CIRC SYST SIGNAL PR, V39, P5729, DOI 10.1007/s00034-020-01431-9
   Hisham MB, 2015, IEEE ST CONF RES DEV, P100, DOI 10.1109/SCORED.2015.7449303
   HM, 2017, HEVC TEST MOD HM 16
   Jaikumar R., 2015, INT J APPL ENG RES, V10, P1
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P189, DOI 10.1109/TCSI.2018.2856245
   Kommu C., 2018, INT C SMART SYSTEMS
   Liddicoat A., 2014, PARALLEL SQUARE CUBE
   Reddy KM, 2020, IEEE T VLSI SYST, V28, P1230, DOI 10.1109/TVLSI.2020.2976131
   Paim G., 2019, 2019 17 IEEE INT NEW, P1
   Paim G., 2016, P 14 IEEE INT NEWCAS, P1
   Paim G, 2021, IEEE T CIRCUITS-I, V68, P1481, DOI 10.1109/TCSI.2021.3058451
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2020, J REAL-TIME IMAGE PR, V17, P1735, DOI 10.1007/s11554-019-00939-x
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Pashaeifar M, 2019, IEEE T CIRCUITS-I, V66, P327, DOI 10.1109/TCSI.2018.2856757
   Rocha L. M. G., 2020, J INTEGRATED CIRCUIT, V15, P1
   Rocha LMG, 2017, IEEE I C ELECT CIRC, P478, DOI 10.1109/ICECS.2017.8292065
   Schiavon T, 2016, IEEE LAT AMER SYMP, P383, DOI 10.1109/LASCAS.2016.7451090
   Seidel HB, 2021, IEEE T CIRCUITS-I, V68, P1814, DOI 10.1109/TCSI.2021.3057584
   Shao BT, 2015, IEEE T CIRCUITS-I, V62, P1081, DOI 10.1109/TCSI.2015.2388839
   Sharath D., IJRET INT J RES ENG
   Sharma R., 2015, INT C IND INSTR CONT
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tsai KL, 2021, IEEE T CIRCUITS-I, V68, P3328, DOI 10.1109/TCSI.2021.3085572
   Wallace C., 1964, IEEE T ELETRONIC COM
   Zervakis G, 2021, ASIA S PACIF DES AUT, P189, DOI 10.1145/3394885.3431632
   Zhang GH, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7120428
NR 38
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1655
EP 1659
DI 10.1109/ISCAS48785.2022.9937770
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jao, N
   Ramanathan, AK
   Sampson, J
   Narayanan, V
AF Jao, Nicholas
   Ramanathan, Akshay Krishna
   Sampson, John
   Narayanan, Vijaykrishnan
TI Sparse Vector-Matrix Multiplication Acceleration in Diode-Selected
   Crossbars
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Accelerator architectures; approximate computing; nonvolatile memory
   (NVM); sparse matrices
ID CMOS VOLTAGE REFERENCE; NONVOLATILE; MEMORY; PERFORMANCE; PRECISION
AB Conventional processors suffer from high access latency and power dissipation due to the demand for memory bandwidth for data-intensive workloads, such as machine learning and analytic. In-memory computing support for various memory technologies has provided formidable improvement in performance and energy for such workloads, alleviating the repeated accesses and data movement between CPU and storage. While many processing in-memory (PIM) works have been proposed to efficiently compute dot products using Kirchoff's law, such solutions are unsuitable for many analytic workloads where working data is too large and too sparse to efficiently store in memory. This article closely focuses on the peripheral circuit design for diode-selected crossbars and configures the compute-embedded fabric to efficiently compute sparse matrix-vector multiplication (SpMV). On average, our proposed end-to-end SpMV accelerator achieves 7.7x speed up and 4.9x energy-savings compared to the state-of-the-art Fulcrum.
C1 [Jao, Nicholas; Ramanathan, Akshay Krishna; Sampson, John; Narayanan, Vijaykrishnan] Penn State Univ, Dept Elect Engn & Comp Sci EECS, University Pk, PA 16801 USA.
RP Jao, N (corresponding author), Penn State Univ, Dept Elect Engn & Comp Sci EECS, University Pk, PA 16801 USA.
EM naj5075@psu.edu
CR Amini M. R., 2009, ADV NEURAL INFORM PR, V22, P1
   Awasthi M., 2011, P NONV MEM WORKSH, P2
   Awasthi M, 2012, INT S HIGH PERF COMP, P15
   Aziz A, 2016, IEEE T CIRCUITS-I, V63, P2222, DOI 10.1109/TCSI.2016.2620475
   Challapalle N, 2020, ANN I S COM, P433, DOI 10.1109/ISCA45697.2020.00044
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chiang HL, 2020, IEEE T ELECTRON DEV, V67, P3102, DOI 10.1109/TED.2020.3005118
   Choi J, 2019, IEEE T COMPUT, V68, P1741, DOI 10.1109/TC.2019.2930972
   Dheeru D., 2017, UCI MACHINE LEARNING
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Ferdman M, 2012, ACM SIGPLAN NOTICES, V47, P37, DOI 10.1145/2248487.2150982
   Ghosh S., 2018, IEEE T MAGN, V54, P1
   He MZ, 2019, IEEE ELECTR DEVICE L, V40, P1595, DOI 10.1109/LED.2019.2935890
   Hughes JC, 1997, TWENTY FIRST IEEE/CPMT INTERNATIONAL ELECTRONICS MANUFACTURING TECHNOLOGY SYMPOSIUM, P88, DOI 10.1109/IEMT.1997.626882
   Imani M, 2019, IEEE T COMPUT AID D, V38, P628, DOI 10.1109/TCAD.2018.2819080
   Jao N, 2019, P IEEE ACM INT S NAN, P1
   Jao N., 2019, P IEEE INT S CIRC SY, P1
   Lee K, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993551
   Lee KS, 2010, JPN J APPL PHYS, V49, DOI 10.1143/JJAP.49.08JF03
   Lenjani M, 2020, INT S HIGH PERF COMP, P556, DOI 10.1109/HPCA47549.2020.00052
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Li WT, 2020, ANN I S COM, P832, DOI 10.1109/ISCA45697.2020.00073
   Liang Jin, 2010, 2010 14th Biennial IEEE Conference on Electromagnetic Field Computation (CEFC 2010), DOI 10.1109/CEFC.2010.5481718
   Liu Y, 2018, IEEE T VLSI SYST, V26, P201, DOI 10.1109/TVLSI.2017.2754442
   Lo CP, 2017, SYMP VLSI CIRCUITS, pC164, DOI 10.23919/VLSIC.2017.8008467
   Luo YD, 2020, IEEE T COMPUT, V69, P1113, DOI 10.1109/TC.2020.3000218
   Lv HB, 2017, INT EL DEVICES MEET
   Ma J., 2009, P 26 ANN INT C MACH, P681, DOI DOI 10.1145/1553374.1553462
   Madani O, 2013, MACH LEARN, V92, P457, DOI 10.1007/s10994-013-5377-0
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Nurvitadhi E, 2016, DES AUT TEST EUROPE, P1616
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   Oh JH, 2006, INT EL DEVICES MEET, P515
   Osaki Y, 2013, IEEE J SOLID-ST CIRC, V48, P1530, DOI 10.1109/JSSC.2013.2252523
   Pabst H., 2012, Proceedings of the 2012 11th International Symposium on Parallel and Distributed Computing (ISPDC 2012), P3, DOI 10.1109/ISPDC.2012.9
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shao CZ, 2021, IEEE J SOLID-ST CIRC, V56, P1795, DOI 10.1109/JSSC.2020.3028506
   Singh S, 2020, ANN I S COM, P363, DOI 10.1109/ISCA45697.2020.00039
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Stine JE, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC SYSTEMS EDUCATION, PROCEEDINGS, P173, DOI 10.1109/MSE.2007.44
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yin SH, 2020, IEEE T ELECTRON DEV, V67, P4185, DOI 10.1109/TED.2020.3015178
   Yongtae Kim, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P328, DOI 10.1109/SOCC.2012.6398336
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zheng L, 2020, INT PARALL DISTRIB P, P696, DOI 10.1109/IPDPS47924.2020.00077
NR 48
TC 0
Z9 0
U1 1
U2 2
PD DEC
PY 2021
VL 29
IS 12
BP 2186
EP 2196
DI 10.1109/TVLSI.2021.3114186
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Passalis, N
   Mourgias-Alexandris, G
   Pleros, N
   Tefas, A
AF Passalis, Nikolaos
   Mourgias-Alexandris, George
   Pleros, Nikos
   Tefas, Anastasios
GP IEEE
TI ADAPTIVE INITIALIZATION FOR RECURRENT PHOTONIC NETWORKS USING SIGMOIDAL
   ACTIVATIONS
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
ID MACHINE
AB Photonic Deep Learning (DL) accelerators are among the most promising approaches for providing fast and energy efficient neural network implementations for several applications. However, photonic accelerators require using different activation functions compared to those typically used in DL. This renders the training process especially difficult to tune, often requiring several trials just for selecting the appropriate initialization hyper-parameters for the network. This process becomes even more difficult for recurrent networks, where exploding gradient phenomena can further destabilize the training process. In this paper, we propose an adaptive data-driven initialization approach for recurrent photonic neural networks. The proposed method is activation-agnostic, while it takes into account the actual distribution of the data used to train the network, overcoming a number of significant limitations of existing approaches. The proposed method is simple and easy to implement, yet it leads to significant improvements in the performance of DL models, as it was experimentally demonstrated using two large-scale challenging time-series datasets.
C1 [Passalis, Nikolaos; Tefas, Anastasios] Aristotle Univ Thessaloniki, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
   [Mourgias-Alexandris, George; Pleros, Nikos] Aristotle Univ Thessaloniki, Photon Syst & Networks Res Grp, Thessaloniki, Greece.
RP Passalis, N (corresponding author), Aristotle Univ Thessaloniki, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
EM passalis@csd.auth.gr; mourgias@csd.auth.gr; npleros@csd.auth.gr;
   tefas@csd.auth.gr
CR [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   Chakraborty I, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-31365-x
   Chung J., 2014, CORR, DOI DOI 10.48550/ARXIV.1412.3555
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Greff K, 2017, IEEE T NEUR NET LEAR, V28, P2222, DOI 10.1109/TNNLS.2016.2582924
   Hebrail G, 2012, INDIVIDUAL HOUSEHOLD
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Mourgias-Alexandris G, 2019, OPT EXPRESS, V27, P9620, DOI 10.1364/OE.27.009620
   Nousi P, 2019, IEEE ACCESS, V7, P64722, DOI 10.1109/ACCESS.2019.2916793
   Ntakaris A, 2018, J FORECASTING, V37, P852, DOI 10.1002/for.2543
   Passalis N., 2019, IEEE T EMERGING TOPI
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Rahimi A., 2007, ADV NEURAL INFORM PR, V20, DOI DOI 10.5555/2981562.2981710
   Rosenbluth D, 2009, OPT EXPRESS, V17, P22767, DOI 10.1364/OE.17.022767
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sun J.(, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tsakyridis A., 2019, P EUR C OPT COMM
NR 21
TC 0
Z9 0
U1 0
U2 1
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zheng, HY
   Liu, Q
   Zhou, Y
   Kravchenko, II
   Huo, YK
   Valentine, J
AF Zheng, Hanyu
   Liu, Quan
   Zhou, You
   Kravchenko, Ivan I.
   Huo, Yuankai
   Valentine, Jason
TI Meta-optic accelerators for object classifiers
SO SCIENCE ADVANCES
DT Article
AB Rapid advances in deep learning have led to paradigm shifts in a number of fields, from medical image analysis to autonomous systems. These advances, however, have resulted in digital neural networks with large computational requirements, resulting in high energy consumption and limitations in real-time decision-making when computation resources are limited. Here, we demonstrate a meta-optic-based neural network accelerator that can off-load computationally expensive convolution operations into high-speed and low-power optics. In this architecture, metasurfaces enable both spatial multiplexing and additional information channels, such as polarization, in object classification. End-to-end design is used to co-optimize the optical and digital systems, resulting in a robust classifier that achieves 93.1% accurate classification of handwriting digits and 93.8% accuracy in classifying both the digit and its polarization state. This approach could enable compact, high-speed, and low-power image and information processing systems for a wide range of applications in machine vision and artificial intelligence.
C1 [Zheng, Hanyu] Vanderbilt Univ, Dept Elect & Comp Engn, Nashville, TN 37212 USA.
   [Liu, Quan; Huo, Yuankai] Vanderbilt Univ, Dept Comp Sci, Nashville, TN 37212 USA.
   [Zhou, You] Vanderbilt Univ, Interdisciplinary Mat Sci Program, Nashville, TN 37212 USA.
   [Kravchenko, Ivan I.] Oak Ridge Natl Lab, Ctr Nanophase Mat Sci, POB 2009, Oak Ridge, TN 37830 USA.
   [Valentine, Jason] Vanderbilt Univ, Dept Mech Engn, Nashville, TN 37212 USA.
RP Valentine, J (corresponding author), Vanderbilt Univ, Dept Mech Engn, Nashville, TN 37212 USA.
EM jason.g.valentine@vanderbilt.edu
CR Arbabi E, 2018, ACS PHOTONICS, V5, P3132, DOI 10.1021/acsphotonics.8b00362
   Cao GT, 2021, MATER TODAY, V50, P499, DOI 10.1016/j.mattod.2021.06.014
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Colburn S, 2019, APPL OPTICS, V58, P3179, DOI 10.1364/AO.58.003179
   del Hougne P, 2020, ADV SCI, V7, DOI 10.1002/advs.201901913
   Devlin J., 2018, PREPRINT
   Ding F, 2021, ADV PHOTON RES, V2, DOI 10.1002/adpr.202000173
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Guo Q, 2019, P NATL ACAD SCI USA, V116, P22959, DOI 10.1073/pnas.1912154116
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Howes A, 2018, OPTICA, V5, P787, DOI 10.1364/OPTICA.5.000787
   Hugonin JP, 2021, Arxiv, DOI arXiv:2101.00901
   Kamali SM, 2018, NANOPHOTONICS-BERLIN, V7, P1041, DOI 10.1515/nanoph-2017-0129
   Khorasaninejad M, 2016, SCIENCE, V352, P1190, DOI 10.1126/science.aaf6644
   Kim I, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23814-5
   Kwon H, 2020, NAT PHOTONICS, V14, P109, DOI 10.1038/s41566-019-0536-x
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li LL, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0209-z
   Li LF, 2020, ACS NANO, V14, P16634, DOI 10.1021/acsnano.0c00724
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Lin Z, 2021, Arxiv, DOI arXiv:2111.01071
   Long O. Y., 2021, PHYS REV APPL, V10
   Luo XH, 2021, Arxiv, DOI arXiv:2107.07873
   McClung A, 2020, SCI ADV, V6, DOI 10.1126/sciadv.abc7646
   Mennel L, 2020, NATURE, V579, P62, DOI 10.1038/s41586-020-2038-x
   Neshatpour K, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3355553
   Overvig AC, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0201-7
   Qian C, 2020, LIGHT-SCI APPL, V9, DOI 10.1038/s41377-020-0303-2
   Qiu CW, 2021, NANO LETT, V21, P5461, DOI 10.1021/acs.nanolett.1c00828
   Ren HR, 2020, NAT NANOTECHNOL, V15, P948, DOI 10.1038/s41565-020-0768-4
   Reshef O, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23358-8
   Rubin NA, 2019, SCIENCE, V365, P43, DOI 10.1126/science.aax1839
   Sak H, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P1468
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shi ZJ, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba3367
   Simonyan K., 2015, ICLR
   Wang GT, 2018, IEEE T MED IMAGING, V37, P1562, DOI 10.1109/TMI.2018.2791721
   Wang TY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27774-8
   Wang XC, 2020, PHYS REV APPL, V14, DOI 10.1103/PhysRevApplied.14.024089
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Wu CM, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20365-z
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yan T, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.023901
   Zhang H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20719-7
   Zhao RZ, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0091-0
   Zhou TK, 2021, NAT PHOTONICS, V15, P367, DOI 10.1038/s41566-021-00796-w
   Zhou Y, 2020, NAT PHOTONICS, V14, P316, DOI 10.1038/s41566-020-0591-3
   Zhou Y, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0193-3
   Zhou Y, 2018, NANO LETT, V18, P7529, DOI 10.1021/acs.nanolett.8b03017
NR 52
TC 6
Z9 6
U1 10
U2 36
PD JUL 29
PY 2022
VL 8
IS 30
AR eabo6410
DI 10.1126/sciadv.abo6410
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Essertel, G
   Tahboub, RY
   Wang, F
   Decker, J
   Rompf, T
AF Essertel, Gregory
   Tahboub, Ruby Y.
   Wang, Fei
   Decker, James
   Rompf, Tiark
TI Flare & Lantern: Efficiently Swapping Horses Midstream
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article
AB Running machine learning (ML) workloads at scale is as much a data management problem as a model engineering problem. Big performance challenges exist when data management systems invoke ML classifiers as user-defined functions (UDFs) or when stand-alone ML frameworks interact with data stores for data loading and pre-processing (ETL). In particular, UDFs can be precompiled or simply a black box for the data management system and the data layout may be completely different from the native layout, thus adding overheads at the boundaries. In this demo, we will show how bottlenecks between existing systems can be eliminated when their engines are designed around runtime compilation and native code generation, which is the case for many state-of-the-art relational engines as well as ML frameworks. We demonstrate an integration of Flare (an accelerator for Spark SQL), and Lantern (an accelerator for TensorFlow and PyTorch) that results in a highly optimized end-to-end compiled data path, switching between SQL and ML processing with negligible overhead.
C1 [Essertel, Gregory; Tahboub, Ruby Y.; Wang, Fei; Decker, James; Rompf, Tiark] Purdue Univ, W Lafayette, IN 47907 USA.
RP Essertel, G (corresponding author), Purdue Univ, W Lafayette, IN 47907 USA.
EM gesserte@purdue.edu; rtahboub@purdue.edu; wang603@purdue.edu;
   decker31@purdue.edu; tiark@purdue.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Armbrust M, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1383, DOI 10.1145/2723372.2742797
   Bassett Andrew Mark, 2018, BMC MED EDUC, V18, DOI [10.1186/s12909-018-1217-z, DOI 10.1186/S12909-018-1217-Z]
   Brown KJ, 2016, INT SYM CODE GENER, P194, DOI 10.1145/2854038.2854042
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Essertel GM, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P799
   Futamura Y., 1971, SYST COMPUT CONTROL, V25, P45
   Leskovec J., 2014, SNAP DATASETS STANFO
   Neumann T, 2011, PROC VLDB ENDOW, V4, P539, DOI 10.14778/2002938.2002940
   Palkar Shoumik, 2017, CIDR
   Rompf, 2018, ICLR WORKSH TRACK
   Rompf T, 2012, COMMUN ACM, V55, P121, DOI 10.1145/2184319.2184345
   Rompf Tiark, 2018, ABS180310228 CORR
   SUJEETH AK, 2014, TECS, V13, DOI DOI 10.1145/2584665
   Tahboub RY, 2018, INT CONF MANAGE DATA, P307, DOI 10.1145/3183713.3196893
   The Transaction Processing Council, TPC H VERS 2 15 0
NR 16
TC 3
Z9 3
U1 0
U2 1
PD AUG
PY 2019
VL 12
IS 12
BP 1910
EP 1913
DI 10.14778/3352063.3352097
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Nezhadi, A
   Angizi, S
   Roohi, A
AF Nezhadi, Ali
   Angizi, Shaahin
   Roohi, Arman
BE Wani, MA
   Kantardzic, M
   Palade, V
   Neagu, D
   Yang, L
   Chan, KY
TI semiMul: Floating-Point Free Implementations for Efficient and Accurate
   Neural Network Training
SO 2022 21ST IEEE INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND
   APPLICATIONS, ICMLA
DT Proceedings Paper
CT 21st IEEE International Conference on Machine Learning and Applications
   (IEEE ICMLA)
CY DEC 12-14, 2022
CL Nassau, BAHAMAS
DE Neural Networks; Machine Learning; Approximate Computing
ID SPEED
AB Multiply-accumulate operation (MAC) is a fundamental component of machine learning tasks, where multiplication (either integer or float multiplication) compared to addition is costly in terms of hardware implementation or power consumption. In this paper, we approximate floating-point multiplication by converting it to integer addition while preserving the test accuracy of shallow and deep neural networks. We mathematically show and prove that our proposed method can be utilized with any floating-point format (e.g., FP8, FP16, FP32, etc.). It is also highly compatible with conventional hardware architectures and can be employed in CPU, GPU, or ASIC accelerators for neural network tasks with minimum hardware cost. Moreover, the proposed method can be utilized in embedded processors without a floating-point unit to perform neural network tasks. We evaluated our method on various datasets such as MNIST, FashionMNIST, SVHN, Cifar-10, and Cifar-100, with both FP16 and FP32 arithmetics. The proposed method preserves the test accuracy and, in some cases, overcomes the overfitting problem and improves the test accuracy.
C1 [Nezhadi, Ali; Roohi, Arman] Univ Nebraska Lincoln, Sch Comp, Lincoln, NE 68588 USA.
   [Angizi, Shaahin] New Jersey Inst Technol, Dept Elect & Comp Engn, Newark, NJ USA.
RP Nezhadi, A (corresponding author), Univ Nebraska Lincoln, Sch Comp, Lincoln, NE 68588 USA.
EM anezhadikhelejani@cse.unl.edu; shaahin.angizi@njit.edu;
   aroohi@cse.unl.edu
CR Alali MH, 2022, MICROMACHINES-BASEL, V13, DOI 10.3390/mi13081364
   Blinn JF, 1997, IEEE COMPUT GRAPH, V17, P80, DOI 10.1109/38.595279
   Cai GR, 2021, SCI CHINA TECHNOL SC, V64, P2627, DOI 10.1007/s11431-021-1936-2
   Camus V, 2016, PROC EUR SOLID-STATE, P465, DOI 10.1109/ESSCIRC.2016.7598342
   Coleman JN, 2000, IEEE T COMPUT, V49, P702, DOI 10.1109/12.863040
   Donovan W, 1994, DIRECT OUTCODE CALCU, P125
   Gustafson J. L., 2017, END ERROR UNUM COMPU
   Gysel P., 2016, ARXIV, DOI [10.48550/ARXIV.1604.03168, DOI 10.48550/ARXIV.1604.03168]
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jiao X, 2017, DES AUT TEST EUROPE, P482, DOI 10.23919/DATE.2017.7927037
   Johnson J, 2018, Arxiv, DOI arXiv:1811.01721
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kosko B, 2020, NEURAL NETWORKS, V129, P359, DOI 10.1016/j.neunet.2020.04.004
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3233231
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leon V, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3448980
   McEniry Charles, 2007, MATH FAST INVERSE SQ
   Miyashita D, 2016, Arxiv, DOI arXiv:1603.01025
   Narayanamoorthy S, 2015, IEEE T VLSI SYST, V23, P1180, DOI 10.1109/TVLSI.2014.2333366
   Neelakantan A, 2015, Arxiv, DOI [arXiv:1511.06807, DOI 10.48550/ARXIV.1511.06807]
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   Peroni D. N., 2019, THESIS UC SAN DIEGO
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rodrigues G, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9040557
   Roohi A, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643531
   Roohi A, 2020, IEEE T COMPUT, V69, P349, DOI 10.1109/TC.2019.2949042
   Xiao H, 2017, ARXIV PREPRINT ARXIV
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Zendegani R, 2017, IEEE T VLSI SYST, V25, P393, DOI 10.1109/TVLSI.2016.2587696
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 837
EP 842
DI 10.1109/ICMLA55696.2022.00139
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Li, PL
   Luo, Y
   Zhang, N
   Cao, Y
AF Li, Peilong
   Luo, Yan
   Zhang, Ning
   Cao, Yu
GP IEEE
TI HeteroSpark: A Heterogeneous CPU/GPU Spark Platform for Machine Learning
   Algorithms
SO PROCEEDINGS OF THE 2015 IEEE INTERNATIONAL CONFERENCE ON NETWORKING,
   ARCHITECTURE AND STORAGE (NAS)
DT Proceedings Paper
CT IEEE International Conference on Networking, Architecture and Storage
   (NAS 2015)
CY AUG 06-07, 2015
CL Boston, MA
AB Analytics algorithms on big data sets require tremendous computational capabilities. Spark is a recent development that addresses big data challenges with data and computation distribution and in-memory caching. However, as a CPU only framework, Spark cannot leverage GPUs and a growing set of GPU libraries to achieve better performance and energy efficiency. We present HeteroSpark, a GPU-accelerated heterogeneous architecture integrated with Spark, which combines the massive compute power of GPUs and scalability of CPUs and system memory resources for applications that are both data and compute intensive. We make the following contributions in this work: ( 1) we integrate the GPU accelerator into current Spark framework to further leverage data parallelism and achieve algorithm acceleration; ( 2) we provide a plug-n-play design by augmenting Spark platform so that current Spark applications can choose to enable/disable GPU acceleration; ( 3) application acceleration is transparent to developers, therefore existing Spark applications can be easily ported to this heterogeneous platform without code modifications. The evaluation of HeteroSpark demonstrates up to 18x speedup on a number of machine learning applications.
C1 [Li, Peilong; Luo, Yan] Univ Massachusetts Lowell, Dept Elect & Comp Engn, Lowell, MA 01852 USA.
   [Zhang, Ning; Cao, Yu] Univ Massachusetts Lowell, Dept Comp Sci, Lowell, MA 01852 USA.
RP Li, PL (corresponding author), Univ Massachusetts Lowell, Dept Elect & Comp Engn, Lowell, MA 01852 USA.
CR Chakrabarti DR, 2014, ACM SIGPLAN NOTICES, V49, P433, DOI [10.1145/2660193.2660224, 10.1145/2714064.2660224]
   Chatzistergiou A, 2015, PROC VLDB ENDOW, V8, P497, DOI 10.14778/2735479.2735483
   Giles E., 2013, MEM ARCH ORG WORKSH
   Giles E., 2015, 31 INT C MASS STOR S
   Pelley S, 2014, CONF PROC INT SYMP C, P265, DOI 10.1109/ISCA.2014.6853222
   Volos H, 2011, ACM SIGPLAN NOTICES, V46, P91, DOI [10.1145/1961296.1950379, 10.1145/1961295.1950379]
NR 6
TC 58
Z9 59
U1 0
U2 3
PY 2015
BP 347
EP 350
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT C
AU Li, TM
   Romaszkan, W
   Pamarti, S
   Gupta, P
AF Li, Tianmu
   Romaszkan, Wojciech
   Pamarti, Sudhakar
   Gupta, Puneet
GP IEEE
TI GEO: Generation and Execution Optimized Stochastic Computing Accelerator
   for Neural Networks
SO PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2021)
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY FEB 01-05, 2021
CL ELECTR NETWORK
AB Stochastic computing (SC) has seen a renaissance in recent years as a means for machine learning acceleration due to its compact arithmetic and approximation properties. Still, SC accuracy remains an issue, with prior works either not fully utilizing the computational density or suffering from significant accuracy losses. In this work, we propose GEO - Generation and Execution Optimized Stochastic Computing Accelerator for Neural Networks, which optimizes stream generation and execution components of SC, and bridges the accuracy gap between stochastic computing and fixed-point neural networks. It improves accuracy by coupling controlled stream sharing with training and balancing OR and binary accumulations. GEO further optimizes the SC execution through progressive shadow buffering and architectural optimizations. GEO can improve accuracy compared to state-of-the-art SC by 2.2-4.0% points while being up to 4.4X faster and 5.3X more energy efficient. GEO eliminates the accuracy gap between SC and fixed-point architectures while delivering up to 5.6X higher throughput and 2.6X lower energy.
C1 [Li, Tianmu; Romaszkan, Wojciech; Pamarti, Sudhakar; Gupta, Puneet] Univ Calif Los Angeles, Elect & Comp Engn Dept, Los Angeles, CA 90095 USA.
RP Li, TM (corresponding author), Univ Calif Los Angeles, Elect & Comp Engn Dept, Los Angeles, CA 90095 USA.
EM litianmu1995@ucla.edu; wromaszkan@ucla.edu; spamarti@ucla.edu;
   puneetg@ucla.edu
CR Alaghi A., 2014, DATE
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Daniels MW, 2020, PHYS REV APPL, V13, DOI 10.1103/PhysRevApplied.13.034016
   Nguyen DA, 2018, PROCEEDINGS OF 2018 5TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS 2018), P237, DOI 10.1109/NICS.2018.8606843
   Faraji SR, 2019, DES AUT TEST EUROPE, P1757, DOI [10.23919/DATE.2019.8714937, 10.23919/date.2019.8714937]
   Gaines B. R., 1969, ADV INFORM SYSTEMS S, V2, P37
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   H. Labs, CACTI 6 5 CACHE ACCE
   Hojabr R, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317911
   Ichihara H, 2014, PR IEEE COMP DESIGN, P361, DOI 10.1109/ICCD.2014.6974706
   Kim K, 2015, INT SOC DESIGN CONF, P123, DOI 10.1109/ISOCC.2015.7401667
   Lai L., 2018, CMSIS NN EFFICIENT N
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2019, GLSVLSI
   Li BZ, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3309882
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Li Z., 2018, IEEE TCAD, V0070, P1
   Liu ST, 2017, DES AUT TEST EUROPE, P650, DOI 10.23919/DATE.2017.7927069
   Ma X., 2018, MEMORY MULTIPLICATIO
   Mondal A., 2018, DATA DRIVEN OPTIMIZA
   Neugebauer F, 2017, 2017 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P1, DOI 10.1109/DSD.2017.29
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Ren A, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P405, DOI 10.1145/3037697.3037746
   Romaszkan W, 2020, DES AUT TEST EUROPE, P768, DOI 10.23919/DATE48585.2020.9116289
   Sayal A, 2019, ISSCC DIG TECH PAP I, V62, P228, DOI 10.1109/ISSCC.2019.8662510
   Sim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062290
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Wang SD, 2017, DES AUT TEST EUROPE, P1438, DOI 10.23919/DATE.2017.7927218
   Wu D, 2020, ANN I S COM, P377, DOI 10.1109/ISCA45697.2020.00040
   Zhakatayev A, 2018, DES AUT CON, DOI [10.1145/3195970.3196113, 10.1109/DAC.2018.8465807]
   Zhang YW, 2019, IEEE WRK SIG PRO SYS, P19, DOI [10.1109/SiPS47522.2019.9020615, 10.1109/sips47522.2019.9020615]
NR 33
TC 1
Z9 2
U1 0
U2 1
PY 2021
BP 689
EP 694
DI 10.23919/DATE51398.2021.9473911
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Kim, EP
   Shanbhag, NR
AF Kim, Eric P.
   Shanbhag, Naresh R.
GP IEEE
TI Energy-efficient Accelerator Architecture for Stereo Image Matching
   using Approximate Computing and Statistical Error Compensation
SO 2014 IEEE GLOBAL CONFERENCE ON SIGNAL AND INFORMATION PROCESSING
   (GLOBALSIP)
DT Proceedings Paper
CT IEEE Global Conference on Signal and Information Processing (GlobalSIP)
CY DEC 03-05, 2014
CL Atlanta, GA
DE statistical error compensation; approximate computing; low power;
   voltage overscaling
AB Modern nanoscale processes exhibit stochastic behavior that can no longer be ignored. Statistical error compensation (SEC) has shown significant benefits in achieving energy efficiency and error resiliency by embracing the stochastic nature of the underlying process. Approximate computing (AC), on the other hand, employs deterministic designs that produce imprecise results to achieve energy efficiency. In this paper, we bridge the two design paradigms by utilizing SEC and AC in the design of a machine learning accelerator core. ANT, a form of SEC, was applied to an AC based stereo image matching implementation in a 45 nm process. Simulation results show that ANT combined with AC achieves energy savings of 44% compared to a conventional system, and 32.7% compared to an AC only system, while its performance degradation is less than 4%. This result shows that embracing the stochasticity of the architecture is crucial in achieving high energy efficiency, and that AC and ANT are synergistic.
C1 [Kim, Eric P.; Shanbhag, Naresh R.] Univ lllinois Urbana Champaign, Coordinated Sci Lab, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
RP Kim, EP (corresponding author), Univ lllinois Urbana Champaign, Coordinated Sci Lab, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
EM epkim2@illinois.edu; shanbhag@illinois.edu
CR [Anonymous], 2013, P ACMSIGDA INT S FIE
   [Anonymous], 2011, DESIGN AUTOMATION TE, P1
   [Anonymous], IEEE WORKSH SIGN PRO
   [Anonymous], CISC VIS NETW IND GL
   [Anonymous], 49 ACM EDAC IEEE DES
   [Anonymous], 49 ACM EDAC IEEE DES
   [Anonymous], 2013, IEEE EUROPEAN TEST S, DOI DOI 10.1109/ETS.2013.6569370
   Black AW, 2007, INT CONF ACOUST SPEE, P1229
   Chippa VK, 2010, DES AUT CON, P555
   Choi JW, 2007, IEEE T SIGNAL PROCES, V55, P5084, DOI 10.1109/TSP.2007.896072
   Choudhury MR, 2008, DES AUT TEST EUROPE, P782
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hirschmuller H., 2007, 2007 IEEE C COMP VIS, P1
   Kim EP, 2012, IEEE WORKSHOP SIG, P149, DOI 10.1109/SiPS.2012.60
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kyaw K Y, 2010, IEEE INT C ELECT DEV, DOI DOI 10.1109/EDSSC.2010.5713751
   Lee YC, 2002, INT CONF ACOUST SPEE, P2077
   Liang CK, 2011, IEEE T CIRC SYST VID, V21, P525, DOI 10.1109/TCSVT.2011.2125570
   Ludwig JT, 1996, IEEE J SOLID-ST CIRC, V31, P395, DOI 10.1109/4.494201
   Mahdiani H. R., 2010, IEEE Transactions on Circuits and Systems I: Regular Papers, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Nawab SH, 1997, J VLSI SIG PROC SYST, V15, P177, DOI 10.1023/A:1007986707921
   Park J, 2010, IEEE T VLSI SYST, V18, P787, DOI 10.1109/TVLSI.2009.2016839
   Shanbhag NR, 2010, DES AUT CON, P859
   Shanbhag NR, 2004, COMPUTER, V37, P42, DOI 10.1109/MC.2004.1274003
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Sinha A, 2000, ISLPED '00: PROCEEDINGS OF THE 2000 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P31, DOI 10.1109/LPE.2000.876753
   Sun J, 2003, IEEE T PATTERN ANAL, V25, P787, DOI 10.1109/TPAMI.2003.1206509
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Tappen MF, 2003, NINTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOLS I AND II, PROCEEDINGS, P900
   Yang Z, 2013, IEEE INT CONF PEER
NR 32
TC 3
Z9 3
U1 0
U2 1
PY 2014
BP 55
EP 59
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Garland, J
   Gregg, D
AF Garland, James
   Gregg, David
TI Low Complexity Multiply-Accumulate Units for Convolutional Neural
   Networks with Weight-Sharing
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE CNN; power efficiency; multiply accumulate; arithmetic hardware
   circuits; ASIC; FPGA
AB Convolutional neural networks (CNNs) are one of the most successful machine-learning techniques for image, voice, and video processing. CNNs require large amounts of processing capacity and memory bandwidth. Hardware accelerators have been proposed for CNNs that typically contain large numbers of multiply-accumulate (MAC) units, the multipliers of which are large in integrated circuit (IC) gate count and power consumption. "Weight-sharing" accelerators have been proposed where the full range of weight values in a trained CNN are compressed and put into bins, and the bin index is used to access the weight-shared value. We reduce power and area of the CNN by implementing parallel accumulate shared MAC (PASM) in a weight-shared CNN. PASM re-architects the MAC to instead count the frequency of each weight and place it in a bin. The accumulated value is computed in a subsequent multiply phase, significantly reducing gate count and power consumption of the CNN. In this article, we implement PASM in a weight-shared CNN convolution hardware accelerator and analyze its effectiveness. Experiments show that for a clock speed 1GHz implemented on a 45nm ASIC process our approach results in fewer gates, smaller logic, and reduced power with only a slight increase in latency. We also show that the same weight-shared-with-PASM CNN accelerator can be implemented in resource-constrained FPGAs, where the FPGA has limited numbers of digital signal processor (DSP) units to accelerate the MAC operations.
C1 [Garland, James; Gregg, David] Trinity Coll Dublin, Sch Comp Sci & Stal ist ics, Dublin D02 DP70, Ireland.
RP Garland, J (corresponding author), Trinity Coll Dublin, Sch Comp Sci & Stal ist ics, Dublin D02 DP70, Ireland.
EM jgarland@tcd.ie; david.gregg@cs.tcd.ie
CR Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dettmers T., 2016, ICLR
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Fürer M, 2007, ACM S THEORY COMPUT, P57, DOI 10.1145/1250790.1250800
   Gangadharan Sridhar, 2015, CONSTRAINING DESIGNS
   Garland J, 2017, IEEE COMPUT ARCHIT L, V16, P132, DOI 10.1109/LCA.2017.2656880
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2016, INT C LEARN REPR ICL
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Sabeetha S, 2015, 2015 2ND INTERNATIONAL CONFERENCE ON ELECTRONICS AND COMMUNICATION SYSTEMS (ICECS), P180, DOI 10.1109/ECS.2015.7124888
   Seide Frank, 2014, P ANN C INT SPEECH C
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Yao Fu, 2016, DEEP LEARNING INT8 O, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 22
TC 17
Z9 17
U1 2
U2 16
PD OCT
PY 2018
VL 15
IS 3
AR 31
DI 10.1145/3233300
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Struharik, R
AF Struharik, R.
BE Szakal, A
TI IP Cores for Hardware Acceleration of Decision Tree Ensemble Classifiers
SO INES 2015 - IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT
   ENGINEERING SYSTEMS
SE IEEE International Conference on Intelligent Engineering Systems
DT Proceedings Paper
CT 19th IEEE International Conference on Intelligent Engineering Systems
   (INES)
CY SEP 03-05, 2015
CL Bratislava, SLOVAKIA
DE machine learning; decision trees; ensemble classifiers; hardware
   acceleration; VHDL; FPGA
ID ARCHITECTURE
AB This paper proposes four different hardware architectures for parallel implementation of decision trees forming an ensemble classifier are presented. Proposed architectures can accelerate ensemble classifiers composed of axis-parallel, oblique and nonlinear decision tree (DTs). Hardware architectures for the implementation of a number of combination rules are also presented, enabling the complete ensemble classifier hardware accelerators. Conducted experiments, based on 29 UCI datasets, indicate that the Field Programmable Gate Array (FPGA) implementations based on proposed architectures offer significant improvement in the instance classification time in comparison with the traditional software implementations.
C1 [Struharik, R.] Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
RP Struharik, R (corresponding author), Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
EM rasti@uns.ac.rs
CR Abe S, 2010, ADV PATTERN RECOGNIT, P331, DOI 10.1007/978-1-84996-098-4_7
   Anguita D, 2011, J CIRCUIT SYST COMP, V20, P263, DOI 10.1142/S0218126611007244
   [Anonymous], 2014, UCI REPOSITORY MACHI
   Bekkerman R., 2011, SCALING MACHINE LEAR
   Buhlmann P, 2012, HDB COMPUTATIONAL ST
   Choudhary AN, 2011, WIRES DATA MIN KNOWL, V1, P41, DOI 10.1002/widm.9
   Flach P., 2012, MACHINE LEARNING ART
   Haykin S., 2008, NEURAL NETWORKS LEAR
   Huang Y. S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P347, DOI 10.1109/CVPR.1993.1626170
   Jacobs RA, 1991, NEURAL COMPUT, V3, P79, DOI 10.1162/neco.1991.3.1.79
   Lesk A., 2014, INTRO BIOINFORMATICS
   Liu B, 2011, DATA CENTRIC SYST AP, P1, DOI 10.1007/978-3-642-19460-3
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Ozay M., 2008, P IEEE 16 SIGN PROC, P1
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Prince S. J., 2012, COMPUTER VISION MODE
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L., 2007, DATA MINING DECISION, V69
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Savich A, 2012, MICROPROCESS MICROSY, V36, P138, DOI 10.1016/j.micpro.2010.12.001
   Struharik R., 2012, 9 IEEE INT S INT SYS, P41
   Vainbrand D, 2011, MICROPROCESS MICROSY, V35, P152, DOI 10.1016/j.micpro.2010.08.005
   Witten IH, 2011, MOR KAUF D, P1
   Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2015
BP 45
EP 50
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Meloni, P
   Deriu, G
   Conti, F
   Loi, I
   Raffo, L
   Benini, L
AF Meloni, Paolo
   Deriu, Gianfranco
   Conti, Francesco
   Loi, Igor
   Raffo, Luigi
   Benini, Luca
BE Athanas, P
   Cumplido, R
   Feregrino, C
   Sass, R
TI A High-Efficiency Runtime Reconfigurable IP for CNN Acceleration on a
   Mid-Range All-Programmable SoC
SO 2016 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG16)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY NOV 30-DEC 02, 2016
CL Cancun, MEXICO
AB Convolutional Neural Networks (CNNs) are a nature-inspired model, extensively employed in a broad range of applications in computer vision, machine learning and pattern recognition. The CNN algorithm requires execution of multiple layers, commonly called convolution layers, that involve application of 2D convolution filters of different sizes over a set of input image features. Such a computation kernel is intrinsically parallel, thus significantly benefits from acceleration on parallel hardware. In this work, we propose an accelerator architecture, suitable to be implemented on mid-to high-range FPGA devices, that can be re-configured at runtime to adapt to different filter sizes in different convolution layers. We present an accelerator configuration, mapped on a Xilinx Zynq XC-Z7045 device, that achieves up to 120 GMAC/s (16 bit precision) when executing 5x5 filters and up to 129 GMAC/s when executing 3x3 filters, consuming less than 10W of power, reaching more than 97% DSP resource utilizazion at 150MHz operating frequency and requiring only 16B/cycle I/O bandwidth.
C1 [Meloni, Paolo; Deriu, Gianfranco; Raffo, Luigi] Univ Cagliari, Dipartimento Ingn Elettr & Elettron, Cagliari, Italy.
   [Conti, Francesco; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab, Zurich, Switzerland.
   [Conti, Francesco; Loi, Igor; Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn, Bologna, Italy.
RP Meloni, P (corresponding author), Univ Cagliari, Dipartimento Ingn Elettr & Elettron, Cagliari, Italy.
EM paolo.meloni@diee.unica.it; gianfranco.deriu@unica.it; f.conti@unibo.it;
   igor.loi@unibo.it; raffo@unica.it; lbenini@iis.ee.ethz.ch
CR [Anonymous], DAC 15
   [Anonymous], ABS151106488 CORR
   [Anonymous], 2012, SCENE PARSING MULTIS
   [Anonymous], ABS160207360 CORR
   [Anonymous], 2014, CVPR 2014 WORKSH
   [Anonymous], PROC CVPR IEEE
   [Anonymous], P 2014 IEEE C COMP V
   [Anonymous], J SIGNAL PR IN PRESS
   [Anonymous], CVPR 2014 WORKSH
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Meloni P, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P376, DOI 10.1145/2903150.2911715
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Rahimi A, 2011, DES AUT TEST EUROPE, P485
   Simonyan K., 2014, VERY DEEP CONVOLUTIO
   Szegedy C., 2015, IEEE CVPR
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 23
TC 1
Z9 1
U1 0
U2 0
PY 2016
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Kala, S
   Jose, BR
   Mathew, J
   Nalesh, S
AF Kala, S.
   Jose, Babita R.
   Mathew, Jimson
   Nalesh, S.
TI High-Performance CNN Accelerator on FPGA Using Unified Winograd-GEMM
   Architecture
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Convolutional neural networks (CNNs); field-programmable gate arrays
   (FPGAs); hardware accelerators; side-channel attacks
ID ALGORITHMS
AB Deep neural networks have revolutionized a variety of applications in varying domains like autonomous vehicles, weather forecasting, cancer detection, surveillance, traffic management, and so on. The convolutional neural network (CNN) is the state-of-the-art technique for many machine learning tasks in the image and video processing domains. Deployment of CNNs on embedded systems with lower processing power and smaller power budget is a challenging task. Recent studies have shown the effectiveness of field-programmable gate array (FPGA) as a hardware accelerator for the CNNs that can deliver high performance at low power budgets. Majority of computations in CNNs involve 2-D convolution. Winograd minimal filtering-based algorithm is the most efficient technique for calculating convolution for smaller filter sizes. CNNs also consist of fully connected layers that are computed using general element-wise matrix multiplication (GEMM). In this article, we propose a unified architecture named UniWiG, where bothWinograd-based convolution and GEMM can be accelerated using the same set of processing elements. This approach leads to efficient utilization of FPGA hardware resources while computing all layers in the CNN. The proposed architecture shows performance improvement in the range of 1.4x to 4.02x with only 13% additional FPGA resources with respect to the baseline GEMM-based architecture. We have mapped popular CNN models like AlexNet and VGG-16 onto the proposed accelerator and the measured performance compares favorably with other state-of-the-art implementations. We have also analyzed the vulnerability of the accelerator to the side-channel attacks. Preliminary investigations show that the UniWiG architecture is more robust to memory side-channel attacks than direct convolution-based techniques.
C1 [Kala, S.; Jose, Babita R.] Cochin Univ Sci & Technol, Sch Engn, Div Elect & Commun Engn, Kochi 682022, Kerala, India.
   [Mathew, Jimson] IIT Patna, Dept Comp Sci & Engn, Patna 801103, Bihar, India.
   [Nalesh, S.] Cochin Univ Sci & Technol, Dept Elect, Kochi 682022, Kerala, India.
RP Kala, S (corresponding author), Cochin Univ Sci & Technol, Sch Engn, Div Elect & Commun Engn, Kochi 682022, Kerala, India.
EM kalas@cusat.ac.in; babitajose@cusat.ac.in; jimson@iitp.ac.in;
   nalesh@cusat.ac.in
CR Abtahi T., 2017, 2017 IEEE INT S CIRC, P1
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Clements J., 2018, HARDWARE TROJAN ATTA
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hua Weizhe, 2018, P INT C IM SIGN PROC, P1, DOI DOI 10.1109/DAC.2018.8465773
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kala S, 2019, I CONF VLSI DESIGN, P209, DOI 10.1109/VLSID.2019.00055
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON RECENT TRENDS IN ELECTRONICS, INFORMATION & COMMUNICATION TECHNOLOGY (RTEICT), P1, DOI 10.1109/RTEICT.2016.7807769
   Li LC, 2017, INT J INF SECUR, V16, P23, DOI 10.1007/s10207-016-0329-x
   Li Z, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P6
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Ma YF, 2018, IEEE T VLSI SYST, V26, P1354, DOI 10.1109/TVLSI.2018.2815603
   Mathieu Michael, 2014, 2 INT C LEARN REPR
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Shen JZ, 2018, IEEE INT SYMP CIRC S, DOI [10.1109/ISCAS.2018.8351474, 10.1109/ICOPS35962.2018.9575483]
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Yu JC, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P227, DOI 10.1109/FPT.2017.8280147
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhuge CH, 2018, PR GR LAK SYMP VLSI, P123, DOI 10.1145/3194554.3194597
NR 31
TC 47
Z9 49
U1 1
U2 30
PD DEC
PY 2019
VL 27
IS 12
BP 2816
EP 2828
DI 10.1109/TVLSI.2019.2941250
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Lyakh, DI
   Nguyen, T
   Claudino, D
   Dumitrescu, E
   McCaskey, AJ
AF Lyakh, Dmitry I.
   Nguyen, Thien
   Claudino, Daniel
   Dumitrescu, Eugene
   McCaskey, Alexander J.
TI ExaTN: Scalable GPU-Accelerated High-Performance Processing of General
   Tensor Networks at Exascale
SO FRONTIERS IN APPLIED MATHEMATICS AND STATISTICS
DT Article
DE tensor network; quantum many-body theory; quantum computing; quantum
   circuit; high performance computing; GPU
ID MATRIX RENORMALIZATION-GROUP
AB We present ExaTN (Exascale Tensor Networks), a scalable GPU-accelerated C++ library which can express and process tensor networks on shared- as well as distributed-memory high-performance computing platforms, including those equipped with GPU accelerators. Specifically, ExaTN provides the ability to build, transform, and numerically evaluate tensor networks with arbitrary graph structures and complexity. It also provides algorithmic primitives for the optimization of tensor factors inside a given tensor network in order to find an extremum of a chosen tensor network functional, which is one of the key numerical procedures in quantum many-body theory and quantum-inspired machine learning. Numerical primitives exposed by ExaTN provide the foundation for composing rather complex tensor network algorithms. We enumerate multiple application domains which can benefit from the capabilities of our library, including condensed matter physics, quantum chemistry, quantum circuit simulations, as well as quantum and classical machine learning, for some of which we provide preliminary demonstrations and performance benchmarks just to emphasize a broad utility of our library.
C1 [Lyakh, Dmitry I.] Oak Ridge Natl Lab, Natl Ctr Computat Sci, Oak Ridge, TN 37830 USA.
   [Nguyen, Thien; Claudino, Daniel] Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN USA.
   [Dumitrescu, Eugene] Oak Ridge Natl Lab, Computat Sci & Engn Div, Oak Ridge, TN USA.
   [McCaskey, Alexander J.] NVIDIA Corp, Santa Clara, CA USA.
RP Lyakh, DI (corresponding author), Oak Ridge Natl Lab, Natl Ctr Computat Sci, Oak Ridge, TN 37830 USA.
EM quant4me@gmail.com
CR [Anonymous], 2015, DASK PARALLEL COMPUT, DOI [10.25080/Majora-7b98-3ed-013, DOI 10.25080/MAJORA-7B98-3ED-013]
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Chan GKL, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4955108
   Cirac JI, 2009, J PHYS A-MATH THEOR, V42, DOI 10.1088/1751-8113/42/50/504004
   Daley AJ, 2004, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2004/04/P04005
   Dmitry, 2022, TAL SH TENSOR ALGEBR
   Evenbly G, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.180405
   Evenbly G., 2019, ARXIV191102558
   Evenbly G., 2019, PREPRINT
   Fishman M., 2020, SCIPOST PHYS, V4
   Gao ZF, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.023300
   Gray J, 2018, J OPEN SOURCE SOFTW, V3, P819, DOI [DOI 10.21105/JOSS.00819, 10.21105/joss.00819]
   Gray J, 2021, QUANTUM-AUSTRIA, V5, DOI 10.22331/q-2021-03-15-410
   Hauschild J., 2018, SCIPOST PHYS LECT NO, V5, DOI DOI 10.21468/SCIPOSTPHYSLECTNOTES.5
   Holmes A, 2020, IEEE INTERNATIONAL CONFERENCE ON QUANTUM COMPUTING AND ENGINEERING (QCE20), P169, DOI 10.1109/QCE49297.2020.00030
   Hrinchuk O., 2020, PREPRINT
   Hynninen AP., 2017, PREPRINT
   Kalachev G., 2021, PREPRINT
   Karypis G., 1998, TECHNICAL REPORT, DOI [10.1109/SC.1998.10018, DOI 10.1109/SC.1998.10018]
   Kossaifi J, 2019, J MACH LEARN RES, V20
   Levy Ro ee, 2022, EFFECTS SOCIAL MOVEM, DOI [10.2139/ssrn.3496903, DOI 10.2139/SSRN.3496903]
   Li X, 2017, J CHEM THEORY COMPUT, V13, P3493, DOI 10.1021/acs.jctc.7b00171
   Lyakh DI., 2022, EXATN EXASCALE TENSO
   Lyakh DI, 2015, COMPUT PHYS COMMUN, V189, P84, DOI 10.1016/j.cpc.2014.12.013
   Ma LJ, 2020, INT CONFER PARA, P125, DOI 10.1145/3410463.3414647
   Markov IL, 2008, SIAM J COMPUT, V38, P963, DOI 10.1137/050644756
   Martyn J., 2020, ARXIV200706082
   McCaskey A, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0206704
   McCaskey AJ, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab6bf6
   Nakatani N, 2013, J CHEM PHYS, V138, DOI 10.1063/1.4798639
   Nguyan T., 2021, PREPRINT
   Nishino T, 1996, J PHYS SOC JPN, V65, P891, DOI 10.1143/JPSJ.65.891
   Noh K, 2020, QUANTUM-AUSTRIA, V4, DOI 10.22331/q-2020-09-11-318
   Orús R, 2014, EUR PHYS J B, V87, DOI 10.1140/epjb/e2014-50502-9
   Orús R, 2014, ANN PHYS-NEW YORK, V349, P117, DOI 10.1016/j.aop.2014.06.013
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Pang Yuchen, 2020, SC20, P1
   Parrish RM, 2019, PHYS REV LETT, V122, DOI 10.1103/PhysRevLett.122.230401
   Pfeifer RNC., 2015, PREPRINT
   Pfeifer RNC, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.033315
   Psarras C., 2021, PREPRINT
   Reyes J., 2020, PREPRINT
   Roberts C., 2019, PREPRINT
   Schollwöck U, 2005, REV MOD PHYS, V77, P259, DOI 10.1103/RevModPhys.77.259
   Schollwöck U, 2011, ANN PHYS-NEW YORK, V326, P96, DOI 10.1016/j.aop.2010.09.012
   Schutski R, 2020, PHYS REV A, V102, DOI 10.1103/PhysRevA.102.062614
   Shi YY, 2006, PHYS REV A, V74, DOI 10.1103/PhysRevA.74.022320
   Sisto A, 2014, ACCOUNTS CHEM RES, V47, P2857, DOI 10.1021/ar500229p
   Solomonik E, 2013, INT PARALL DISTRIB P, P813, DOI 10.1109/IPDPS.2013.112
   Song QQ, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3278607
   Stoudenmire E., 2016, ADV NEURAL INFORM PR, V29, P4799
   Troyer M, 2005, PHYS REV LETT, V94, DOI 10.1103/PhysRevLett.94.170201
   Verstraete F, 2004, PHYS REV A, V70, DOI 10.1103/PhysRevA.70.060302
   Vidal G, 2007, PHYS REV LETT, V99, DOI 10.1103/PhysRevLett.99.220405
   Vidal G, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.070201
   Vidal G, 2003, PHYS REV LETT, V91, DOI 10.1103/PhysRevLett.91.147902
   Vidal G, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.110501
   Villalonga B, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab7eeb
   Villalonga B, 2019, NPJ QUANTUM INFORM, V5, DOI 10.1038/s41534-019-0196-1
   Wall ML, 2021, PHYS REV RES, V3, DOI 10.1103/PhysRevResearch.3.023010
   WHITE SR, 1992, PHYS REV LETT, V69, P2863, DOI 10.1103/PhysRevLett.69.2863
   White SR, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.076401
   Zhou YQ, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.041038
NR 64
TC 1
Z9 1
U1 1
U2 15
PD JUL 6
PY 2022
VL 8
AR 838601
DI 10.3389/fams.2022.838601
WC Mathematics, Interdisciplinary Applications
DA 2023-11-11
ER

PT C
AU Leipnitz, MT
   Nazar, GL
AF Leipnitz, Marcos T.
   Nazar, Gabriel L.
GP IEEE Comp Soc
TI Throughput-Oriented Spatio-Temporal Optimization in Approximate
   High-Level Synthesis
SO 2020 IEEE 38TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2020)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 38th IEEE International Conference on Computer Design (ICCD)
CY OCT 18-21, 2020
CL ELECTR NETWORK
DE High-Level Synthesis; Approximate Computing; Design Space Exploration
AB Current and emerging systems for high-throughput applications, such as machine learning, cloud computing, and real-time video encoding demand real-time processing computations, heavily constrained by latency and power requirements. To deal with the increasing computational complexity, designers may resort to approximate accelerators for error-resilient compute-intensive kernels to meet such requirements with acceptable deviation from the exact implementation. However, since time-to-market is crucial when dealing with evolving applications, technologies, and standards, hand-crafting approximate accelerators may impose prohibitive development time and cost overheads. In this scenario, approximate High-Level Synthesis (HLS) methodologies have been proposed to deal with the complexity of exploring approximation techniques. Nevertheless, current tools are not suitable for exploring throughput optimizations, being instead constrained to perform specific improvements on area, power, and performance. In this work, we propose the use of HLS to generate Pareto-optimal accelerators for throughput-constrained applications. Particularly, we present a throughput-oriented approximate HLS methodology that explores both delay and area optimizations to increase the reuse over time and parallelism of such accelerators. Results show that our method is able to improve throughput by up to 80% with no additional area costs or to sustain the same throughput of the exact design with about 45% less area while introducing manageable error for most applications. Moreover, our method can attain throughput improvements of up to 18% when compared with recent works focusing only on performance or area optimizations, with no additional costs.
C1 [Leipnitz, Marcos T.; Nazar, Gabriel L.] Univ Fed Rio Grande do Sul, Informat Inst, Porto Alegre, RS, Brazil.
RP Leipnitz, MT (corresponding author), Univ Fed Rio Grande do Sul, Informat Inst, Porto Alegre, RS, Brazil.
EM mtleipnitz@inf.ufrgs.br; glnazar@inf.ufrgs.br
CR [Anonymous], 2020, ITU T TEST SIGNALS T
   [Anonymous], 2020, USC SIPI IMAGE DATAB
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Coussy P, 2009, IEEE DES TEST COMPUT, V26, P8, DOI 10.1109/MDT.2009.69
   Elango K, 2019, J ELECTR ENG TECHNOL, V14, P1717, DOI 10.1007/s42835-019-00168-z
   Hara Yuko, 2009, J INFORM PROCESSING, V17, P242
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P313, DOI 10.1109/TCSI.2018.2856513
   Kang Y, 2016, PR IEEE COMP DESIGN, P96, DOI 10.1109/ICCD.2016.7753266
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Dang LDT, 2014, I SYMPOS LOW POWER E, P259, DOI 10.1145/2627369.2627650
   Lee S, 2018, IEEE EMBED SYST LETT, V10, P18, DOI 10.1109/LES.2017.2764542
   Lee S, 2017, DES AUT TEST EUROPE, P187, DOI 10.23919/DATE.2017.7926980
   Leipnitz M. T., 2019, 2019 56 ACM IEEE DES, P1
   Leipnitz MT, 2020, 17TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2020 (CF 2020), P221, DOI 10.1145/3387902.3394039
   Leipnitz MT, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358182
   Li CF, 2015, DES AUT CON, DOI 10.1145/2744769.2744863
   Li YTS, 1997, IEEE T COMPUT AID D, V16, P1477, DOI 10.1109/43.664229
   Liao QV, 2018, PROCEEDINGS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS (CHI 2018), DOI 10.1145/3173574.3173577
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Nepal K, 2014, DES AUT TEST EUROPE
   Nepal K, 2019, IEEE T EMERG TOP COM, V7, P18, DOI 10.1109/TETC.2016.2598283
   Porto Roger, 2019, 2019 IEEE 10th Latin American Symposium on Circuits & Systems (LASCAS). Proceedings, P65, DOI 10.1109/LASCAS.2019.8667554
   Porto R, 2017, IEEE INT WORKSH MULT
   Schafer BC, 2017, IEEE T COMPUT AID D, V36, P97, DOI 10.1109/TCAD.2016.2550501
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Vaverka F., 2016, PROC IEEE S SER COMP, P1, DOI [10.1109/SSCI.2016.7850168, DOI 10.1109/SSCI.2016.7850168]
   Venkataramani S, 2015, DES AUT CON, DOI 10.1145/2744769.2744904
   Xu SY, 2017, IEEE T VLSI SYST, V25, P3077, DOI 10.1109/TVLSI.2017.2735299
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
   Yeh TY, 2007, INT SYMP MICROARCH, P394, DOI 10.1109/MICRO.2007.9
NR 30
TC 1
Z9 1
U1 1
U2 3
PY 2020
BP 316
EP 323
DI 10.1109/ICCD50377.2020.00060
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Dalmia, P
   Mahapatra, R
   Sinclair, MD
AF Dalmia, Preyesh
   Mahapatra, Rohan
   Sinclair, Matthew D.
GP IEEE Comp Soc
TI Only Buffer When You Need To: Reducing On-chip GPU Traffic with
   Reconfigurable Local Atomic Buffers
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE GPGPU; Relaxed Atomics; Machine Learning; Graph Analytics; Buffering
ID GRAPH; SYNCHRONIZATION; CACHE
AB In recent years, due to their wide availability and ease of programming, GPUs have emerged as the accelerator of choice for a wide variety of applications including graph analytics and machine learning training. These applications use atomics to update shared global variables. However, since GPUs do not efficiently support atomics, this limits scalability. We propose to use hardware-software co-design to address this bottleneck and improve scalability. At the software level, we leverage recently proposed extensions to the GPU memory consistency model to identify atomic updates where the ordering can be relaxed. For example, in these algorithms the updates are commutative. At the hardware level, we propose a buffering mechanism that extends the reconfigurable local SRAM per SM. By buffering partial updates of these atomics locally, our design increases reuse, reduces atomic serialization cost, and minimizes overhead. Thus, our mechanism alleviates the impact of global atomic updates and improves performance by 28%, energy by 19%, and network traffic by 19% on average and outperforms hLRC and PHI.
C1 [Dalmia, Preyesh; Sinclair, Matthew D.] Univ Wisconsin Madison, Madison, WI 53706 USA.
   [Mahapatra, Rohan] Univ Calif San Diego, San Diego, CA 92103 USA.
   [Sinclair, Matthew D.] AMD Res, Hyderabad, India.
RP Dalmia, P (corresponding author), Univ Wisconsin Madison, Madison, WI 53706 USA.
EM pdalmia@wisc.edu; rohan@ucsd.edu; sinclair@cs.wisc.edu
CR Ahn J, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/2994149
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alsop J, 2018, CONF PROC INT SYMP C, P261, DOI 10.1109/ISCA.2018.00031
   Alvarez L, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P720, DOI 10.1145/2749469.2750411
   [Anonymous], 2017, NVID TESL V100 GPU A, P1
   [Anonymous], 2016, P 49 ANN IEEE ACM IN, DOI DOI 10.1109/MICRO.2016.7783729
   [Anonymous], 2020, CUDA C PROGRAMMING G
   [Anonymous], 2013, P 6 WORKSHOP GEN PUR
   [Anonymous], 2013, PROC IEEEACM 7 INT S
   [Anonymous], 2007, HISTOGRAM CALCULATIO
   Bader D. A., 2018, BENCHMARKING GRAPH C, P161
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Balaji Vignesh, 2017, ARXIV170909491
   Boehm HJ, 2008, ACM SIGPLAN NOTICES, V43, P68, DOI 10.1145/1379022.1375591
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   Chauvin Y., 1995, BACKPROPAGATION THEO, P1, DOI DOI 10.5555/201784.201785
   Che S, 2013, I S WORKL CHAR PROC, P185, DOI 10.1109/IISWC.2013.6704684
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Che Shuai, 2010, INT S WORKLOAD CHARA, P1
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chou YH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P981, DOI 10.1109/MICRO50266.2020.00083
   Collange S., 2014, FULL SPEED DETERMINI
   Cook H., 2009, UCBEECS2009131
   Dally W. J., 2018, SYSML KEYNOTE
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Defour D, 2015, ACSIS-ANN COMPUT SCI, V5, P721, DOI 10.15439/2015F86
   Demetrescu C., 2006, 9 DIMACS IMPLEMENTAT
   Diamos Greg, 2016, INT C MACHINE LEARNI, P2024
   Dong S, 2017, PROCEEDINGS OF THE GENERAL PURPOSE GPUS (GPGPU-10), P63, DOI 10.1145/3038228.3038239
   Egielski I, 2014, ACM SIGPLAN NOTICES, V49, P93, DOI [10.1145/2602988.2602993, 10.1145/2775049.2602993]
   El Hajj I, 2016, INT SYMP MICROARCH
   Feinberg B, 2020, ANN I S COM, P1076, DOI 10.1109/ISCA45697.2020.00091
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gaster BR, 2015, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2701618
   Gebhart M, 2012, INT SYMP MICROARCH, P96, DOI 10.1109/MICRO.2012.18
   Google, 2017, HOT CHIPS 2017 CLOS
   GOTTLIEB A, 1983, IEEE T COMPUT, V32, P175, DOI 10.1109/TC.1983.1676201
   Grauer-Gray Scott, 2012, INNOVATIVE PARALLEL, P1
   Ham TJ, 2016, INT SYMP MICROARCH
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He K., 2015, DEEP RESIDUAL LEARNI
   Hechtman Blake A., 2013, IEEE International Symposium on Performance Analysis of Systems and Software (ISPASS 2013), P118
   Hechtman BA, 2014, INT S HIGH PERF COMP, P189, DOI 10.1109/HPCA.2014.6835930
   Hower DR, 2014, ACM SIGPLAN NOTICES, V49, P427, DOI 10.1145/2541940.2541981
   Howes Lee, 2015, OPENCL SPECIFICATION
   HSA Foundation, 2015, HSA PLATFORM SYSTEM
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jia ZH, 2017, PROC VLDB ENDOW, V11, P297, DOI 10.14778/3157794.3157799
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kandiah V., 2021, PROC ANN IEEEACM INT, P738
   Kerr Andrew, 2017, CUTLASS FAST LINEAR
   Khairy M., 2018, CORR
   Khairy M, 2020, ANN I S COM, P473, DOI 10.1109/ISCA45697.2020.00047
   Khorasani F, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P377, DOI 10.1109/MICRO.2018.00038
   Khronos OpenCL Working Group, OPENCL SPECIFICATION, P2021
   Kim J, 2014, INT SYMP MICROARCH, P75, DOI [10.1109/MICRO.2014.24, 10.12720/ijeee.2.1.75-79]
   Kim W., 2016, IPDPS, P555
   Klenk B, 2020, ANN I S COM, P996, DOI 10.1109/ISCA45697.2020.00085
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Koukos K, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/2889488
   Kyrola Aapo, 2012, OSDI, P31
   Lee JH, 2015, INT CONFER PARA, P241, DOI 10.1109/PACT.2015.42
   Leng Jingwen, 2013, ISCA
   Lew J, 2019, INT SYM PERFORM ANAL, P151, DOI 10.1109/ISPASS.2019.00028
   Li BC, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3322127
   Lustig D, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P257, DOI 10.1145/3297858.3304043
   Ma LX, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P195
   Merrill D., 2020, NVIDIA CUB LIB
   Mukkara Anurag, 2019, MICR 52 ANN IEEEACM, DOI DOI 10.1145/3352460.3358254
   Nor MHM, 2016, 2016 IEEE 6TH INTERNATIONAL CONFERENCE ON UNDERWATER SYSTEM TECHNOLOGY: THEORY AND APPLICATIONS, P7, DOI 10.1109/USYS.2016.7893945
   NVIDIA, 2020, LIBC C STAND LIB YOU
   NVIDIA, 2018, CUDNN GPU ACC DEEP L
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Orr MS, 2015, ACM SIGPLAN NOTICES, V50, P73, DOI [10.1145/2775054.2694350, 10.1145/2694344.2694350]
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pourghassemi B, 2020, PROCEEDINGS OF THE 32ND ACM SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES (SPAA '20), P567, DOI 10.1145/3350755.3400266
   Power Jason, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P457, DOI 10.1145/2540708.2540747
   Raihan MA, 2019, INT SYM PERFORM ANAL, P79, DOI 10.1109/ISPASS.2019.00016
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren XW, 2020, INT S HIGH PERF COMP, P582, DOI 10.1109/HPCA47549.2020.00054
   Ren XW, 2017, INT S HIGH PERF COMP, P625, DOI 10.1109/HPCA.2017.40
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Salvador G, 2020, INT SYM PERFORM ANAL, P123, DOI 10.1109/ISPASS48437.2020.00027
   Scott SL, 1996, ACM SIGPLAN NOTICES, V31, P26, DOI 10.1145/248209.237144
   Segura A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P424, DOI 10.1145/3307650.3322254
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Sinclair MD, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P161, DOI [10.1145/3140659.3080206, 10.1145/3079856.3080206]
   Sinclair MD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P647, DOI 10.1145/2830772.2830821
   Singh I, 2013, INT S HIGH PERF COMP, P578, DOI 10.1109/HPCA.2013.6522351
   Sorensen T, 2019, I S WORKL CHAR PROC, P155, DOI 10.1109/IISWC47752.2019.9042139
   Stratton J. A., 2012, IMPACT1201 U ILL
   Tabbakh A, 2018, INT S HIGH PERF COMP, P403, DOI 10.1109/HPCA.2018.00042
   Villa O, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P372, DOI 10.1145/3352460.3358307
   Vineet V, 2008, PROC CVPR IEEE, P1070
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Wickerson J, 2015, ACM SIGPLAN NOTICES, V50, P731, DOI [10.1145/2814270.2814283, 10.1145/2858965.2814283]
   Wittenbrink CM, 2011, IEEE MICRO, V31, P50, DOI 10.1109/MM.2011.24
   Yang YF, 2020, ANN I S COM, P419, DOI 10.1109/ISCA45697.2020.00043
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang GW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P13, DOI 10.1145/2830772.2830774
   Zhang Hao, 2020, ADV NEUR IN, V33, P906
   Zheng BJ, 2019, Arxiv, DOI arXiv:1805.08899
   Zheng Z., 2015, LEARNINGSYS
   Zhu F., 2018, ICLR
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
   Zhu M., 2016, TRAINING LONG SHORT
NR 112
TC 2
Z9 2
U1 0
U2 2
PY 2022
BP 676
EP 691
DI 10.1109/HPCA53966.2022.00056
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Struharik, R
AF Struharik, R.
GP IEEE
TI Decision Tree Ensemble Hardware Accelerators for Embedded Applications
SO IEEE 13TH INTERNATIONAL SYMPOSIUM ON INTELLIGENT SYSTEMS AND INFORMATICS
   (SISY)
SE International Symposium on Intelligent Systems and Informatics
DT Proceedings Paper
CT 13th IEEE International Symposium on Intelligent Systems and Informatics
   (SISY)
CY SEP 17-19, 2015
CL Subotica, SERBIA
ID ARCHITECTURE
AB This paper presents four different architectures for the hardware acceleration of axis-parallel, oblique and non-linear decision tree ensemble classifier systems. Hardware architectures for the implementation of a number of ensemble combination rules are also presented. The proposed architectures are optimized for size, making them particularly interesting for embedded applications where the size of the system is critical constraint. Proposed architectures are suitable for the implementation using FPGA and ASIC technology. Experiment results obtained using 29 datasets from the standard UCI Machine Learning Repository database suggest that the FPGA implementations offer significant improvement in the classification time in comparison with the pure software implementations.
C1 [Struharik, R.] Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
RP Struharik, R (corresponding author), Univ Novi Sad, Fac Tech Sci, Novi Sad 21000, Serbia.
EM rasti@uns.ac.rs
CR Abe S, 2010, ADV PATTERN RECOGNIT, P331, DOI 10.1007/978-1-84996-098-4_7
   Anguita D, 2011, J CIRCUIT SYST COMP, V20, P263, DOI 10.1142/S0218126611007244
   Bekkerman R., 2011, SCALING MACHINE LEAR
   Bermak A, 2003, IEEE T NEURAL NETWOR, V14, P1097, DOI 10.1109/TNN.2003.816362
   Blake C.L., UCI REPOSITORY MACHI
   Choudhary AN, 2011, WIRES DATA MIN KNOWL, V1, P41, DOI 10.1002/widm.9
   Flach P., 2012, MACHINE LEARNING ART
   Haykin S., 2008, NEURAL NETWORKS LEAR
   Huang Y. S., 1993, Proceedings. 1993 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (Cat. No.93CH3309-2), P347, DOI 10.1109/CVPR.1993.1626170
   Lesk A., 2014, INTRO BIOINFORMATICS
   Liu B, 2011, DATA CENTRIC SYST AP, P1, DOI 10.1007/978-3-642-19460-3
   Ma Y, 2012, ENSEMBLE MACHINE LEARNING: METHODS AND APPLICATIONS, P1, DOI 10.1007/978-1-4419-9326-7
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Prince S. J., 2012, COMPUTER VISION MODE
   Rokach L, 2005, IEEE T SYST MAN CY C, V35, P476, DOI 10.1109/TSMCC.2004.843247
   Rokach L., 2007, DATA MINING DECISION, V69
   Saqib F, 2015, IEEE T COMPUT, V64, P280, DOI 10.1109/TC.2013.204
   Savich A, 2012, MICROPROCESS MICROSY, V36, P138, DOI 10.1016/j.micpro.2010.12.001
   Struharik R., 2012, 9 IEEE INT S INT SYS, P41
   Vainbrand D, 2011, MICROPROCESS MICROSY, V35, P152, DOI 10.1016/j.micpro.2010.08.005
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Witten IH, 2011, MOR KAUF D, P1
   Wu X, 2009, CH CRC DATA MIN KNOW, P1, DOI 10.1201/9781420089653
NR 24
TC 8
Z9 8
U1 0
U2 1
PY 2015
BP 101
EP 106
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Ekeberg, T
   Engblom, S
   Liu, J
AF Ekeberg, Tomas
   Engblom, Stefan
   Liu, Jing
TI Machine learning for ultrafast X-ray diffraction patterns on large-scale
   GPU clusters
SO INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS
DT Article
DE Expectation-maximization; X-ray laser diffraction; GPU cluster;
   single-molecule imaging
AB The classical method of determining the atomic structure of complex molecules by analyzing diffraction patterns is currently undergoing drastic developments. Modern techniques for producing extremely bright and coherent X-ray lasers allow a beam of streaming particles to be intercepted and hit by an ultrashort high-energy X-ray beam. Through machine learning methods the data thus collected can be transformed into a three-dimensional volumetric intensity map of the particle itself. The computational complexity associated with this problem is very high such that clusters of data parallel accelerators are required. We have implemented a distributed and highly efficient algorithm for the inversion of large collections of diffraction patterns targeting clusters of hundreds of GPUs. With the expected enormous amount of diffraction data to be produced in the foreseeable future, this is the required scale to approach real-time processing of data at the beam site. Using both real and synthetic data we look at the scaling properties of the application and discuss the overall computational viability of this exciting and novel imaging technique.
C1 [Ekeberg, Tomas; Liu, Jing] Uppsala Univ, Dept Cell & Mol Biol, Lab Mol Biophys, SE-75105 Uppsala, Sweden.
   [Engblom, Stefan; Liu, Jing] Uppsala Univ, Dept Informat Technol, Div Comp Sci, SE-75105 Uppsala, Sweden.
RP Engblom, S (corresponding author), Uppsala Univ, Dept Informat Technol, Div Comp Sci, Box 337, SE-75105 Uppsala, Sweden.
EM stefane@it.uu.se
CR Andreasson J, 2014, OPT EXPRESS, V22, P2497, DOI 10.1364/OE.22.002497
   Chapman HN, 2006, J OPT SOC AM A, V23, P1179, DOI 10.1364/JOSAA.23.001179
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Ekeberg T, 2012, THESIS UPPSALA U
   Emma P, 2010, NAT PHOTONICS, V4, P641, DOI [10.1038/nphoton.2010.176, 10.1038/NPHOTON.2010.176]
   Engblom S, 2014, LECT NOTES COMPUT SC, V8384, P480, DOI 10.1007/978-3-642-55224-3_45
   Fung R, 2009, NAT PHYS, V5, P64, DOI [10.1038/nphys1129, 10.1038/NPHYS1129]
   Gaffney KJ, 2007, SCIENCE, V316, P1444, DOI 10.1126/science.1135923
   GPU Bench, 2012, GPU COMP REP QUADR K
   Jacobsen DA, 2010, 48 AIAA AER SCI M EX, V16, DOI [10.2514/6.2010-522, DOI 10.2514/6.2010-522]
   Loh ND, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.225501
   Loh NTD, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026705
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   Neutze R, 2000, NATURE, V406, P752, DOI 10.1038/35021099
   Pennycook S. J., 2011, Performance Evaluation Review, V38, P23, DOI 10.1145/1964218.1964223
   Schneidmiller E. A., 2011, PHOTON BEAM PROPERTI
   Seibert MM, 2011, NATURE, V470, P78, DOI 10.1038/nature09748
   Serkez S, 2014, PREPRINT
   Shapiro D, 2005, P NATL ACAD SCI USA, V102, P15343, DOI 10.1073/pnas.0503305102
   Wang YQ, 2014, CONCURR COMP-PRACT E, V26, P748, DOI 10.1002/cpe.3046
   Zaspel P, 2013, COMPUT FLUIDS, V80, P356, DOI 10.1016/j.compfluid.2012.01.021
NR 21
TC 4
Z9 4
U1 1
U2 8
PD SUM
PY 2015
VL 29
IS 2
BP 233
EP 243
DI 10.1177/1094342015572030
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Yang, YA
   Zhao, LP
   Li, YM
   Zhang, HY
   Li, J
   Zhao, MY
   Chen, XZ
   Li, KQ
AF Yang, Yanan
   Zhao, Laiping
   Li, Yiming
   Zhang, Huanyu
   Li, Jie
   Zhao, Mingyang
   Chen, Xingzhen
   Li, Keqiu
BE Falsafi, B
   Ferdman, M
   Lu, S
   Weinisch, T
TI INFless: A Native Serverless System for Low-Latency, High-Throughput
   Inference
SO ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON
   ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 27th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY FEB 28-MAR 04, 2022
CL Lausanne, SWITZERLAND
DE Serverless Computing; Machine Learning; Inference System
AB Modern websites increasingly rely on machine learning (ML) to improve their business efficiency. Developing and maintaining ML services incurs high costs for developers. Although serverless systems are a promising solution to reduce costs, we find that the current general purpose serverless systems cannot meet the low latency, high throughput demands of ML services.
   While simply "patching" general serverless systems does not resolve the problem completely, we propose that such a system should natively combine the features of inference with a serverless paradigm. We present INFless, the first ML domain-specific serverless platform. It provides a unified, heterogeneous resource abstraction between CPU and accelerators, and achieves high throughput using built-in batching and non-uniform scaling mechanisms. It also supports low latency through coordinated management of batch queuing time, execution time and coldstart rate. We evaluate INF-less using both a local cluster testbed and a large-scale simulation. Experimental results show that INFless outperforms state-of-the-art systems by 2x-5x on system throughput, meeting the latency goals of ML services.
C1 [Yang, Yanan] Tianjin Univ, Coll Intelligence & Comp CIC, Tianjin Key Lab Adv Networking, Tianjin, Peoples R China.
   [Zhao, Laiping; Li, Yiming; Zhang, Huanyu; Li, Jie; Zhao, Mingyang; Li, Keqiu] Tianjin Univ, CIC, TANKLAB, Tianjin, Peoples R China.
   [Chen, Xingzhen] 58 Com, Beijing, Peoples R China.
RP Zhao, LP (corresponding author), Tianjin Univ, CIC, TANKLAB, Tianjin, Peoples R China.
EM ynyang@tju.edu.cn; laiping@tju.edu.cn; l_ym@tju.edu.cn;
   3016218159@tju.edu.cn; lijie20@tju.edu.cn; mingyang@tju.edu.cn;
   chenxingzhen@58.com; keqiu@tju.edu.cn
CR Adolf R, 2016, I S WORKL CHAR PROC, P148
   AILab, 2019, DEEP LEARN INF
   Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   [Anonymous], 2018, TENS SERV BENCHM
   AWS, 2020, SERV APPL LENS AL SK
   AWS Lambda, 2015, SERV COMP AM WEB SER
   Bhattacharjee A, 2019, INT CONF CLOUD ENG, P23, DOI 10.1109/IC2E.2019.00-10
   Cao YK, 2018, INT CONF SYST INFORM, P1182, DOI 10.1109/ICSAI.2018.8599486
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chollet F., 2015, KERAS, P33
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Devlin J., 2018, PREPRINT
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   Du D, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P467, DOI 10.1145/3373376.3378512
   Eismann Simon, 2020, ARXIV
   Ellis A, 2020, OPENFAAS
   Google, 2020, GOOGL CLOUD FUNCT
   GoogleCloud, 2020, SERV OPT CHAR REC OC
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Gunasekaran JR, 2020, PROCEEDINGS OF THE 2020 21ST INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE '20), P280, DOI 10.1145/3423211.3425683
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   IBM, 2020, OP
   Le TN, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387547
   Liu Chen, 2017, 2017 IEEE 16th International Conference on Cognitive Informatics & Cognitive Computing (ICCI*CC). Proceedings, P243, DOI 10.1109/ICCI-CC.2017.8109757
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Microsoft, 2021, AZ FUNCT
   Muens Philipp., 2020, SERVERLESS FACEBOOK
   NVIDIA, 2018, NVIDIA TUR ARCH WHIT
   Oakes E, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P57
   Olston Christopher, 2017, CORR ABS171206139 20
   Park Jongsoo, 2018, CORR ABS181109886 20
   Parkhi O. M., 2015, P BMVC, V1, P6, DOI DOI 10.5244/C.29.41
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Romero Francisco, 2019, CORR ABS190513348 20
   Shahrad M, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P205
   Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658
   Sreekanti Vikram, 2020, ABS200705832 CORR
   Tianyi Yu, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P30, DOI 10.1145/3419111.3421280
   Wang L, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P133
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhou Y, 2019, 2019 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI 2019), P2776, DOI 10.1109/SSCI44817.2019.9003100
NR 41
TC 13
Z9 14
U1 2
U2 7
PY 2022
BP 768
EP 781
DI 10.1145/3503222.3507709
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Salvador, R
   Fabelo, H
   Lazcano, R
   Ortega, S
   Madroñal, D
   Callic, GM
   Juárez, E
   Sanz, C
AF Salvador, R.
   Fabelo, H.
   Lazcano, R.
   Ortega, S.
   Madronal, D.
   Callic, G. M.
   Juarez, E.
   Sanz, C.
BE Nezan, JF
TI Demo: HELICoiD Tool Demonstrator for Real-Time Brain Cancer Detection
SO PROCEEDINGS OF THE 2016 CONFERENCE ON DESIGN AND ARCHITECTURES FOR
   SIGNAL & IMAGE PROCESSING
SE Conference on Design and Architectures for Signal and Image Processing
DT Proceedings Paper
CT Conference on Design and Architectures for Signal and Image Processing
   (DASIP)
CY OCT 12-14, 2016
CL Rennes, FRANCE
DE Hyperspectral Imaging; Machine Learning; Supervised Classification;
   Massively Parallel Processing; Real Time Processing; KNN Filtering
AB In this paper, a demonstrator of three different elements of the EU FET HELICoiD project is introduced. The goal of this demonstration is to show how the combination of hyperspectral imaging and machine learning can be a potential solution to precise real-time detection of tumor tissues during surgical operations. The HELICoiD setup consists of two hyperspectral cameras, a scanning unit, an illumination system, a data processing system and an EMB01 accelerator platform, which hosts an MPPA-256 manycore chip. All the components are mounted fulfilling restrictions from surgical environments, as shown in the accompanying video recorded at the operating room. An in-vivo human brain hyperspectral image data base, obtained at the University Hospital Doctor Negrin in Las Palmas de Gran Canaria, has been employed as input to different supervised classification algorithms (SVM, RF, NN) and to a spatial-spectral filtering stage (SVM-KNN). The resulting classification maps are shown in this demo. In addition, the implementation of the SVM-KNN classification algorithm on the MPPA EMB01 platform is demonstrated in the live demo.
C1 [Salvador, R.; Lazcano, R.; Madronal, D.; Juarez, E.; Sanz, C.] Tech Univ Madrid UPM, Ctr Software Technol & Multimedia Syst CITSEM, Madrid, Spain.
   [Fabelo, H.; Ortega, S.; Callic, G. M.] Univ Las Palmas Gran Canaria, Res Inst Appl Microelect IUMA, Las Palmas Gran Canaria, Spain.
RP Salvador, R (corresponding author), Tech Univ Madrid UPM, Ctr Software Technol & Multimedia Syst CITSEM, Madrid, Spain.
EM ruben.salvador@upm.es; hfabelo@iuma.ulpgc.es; raquel.lazcano@upm.es;
   sortega@iuma.ulpgc.es; daniel.madronal@upm.es; gustavo@iuma.ulpgc.es;
   eduardo.juarez@upm.es; cesar.sanz@upm.es
CR Lai J, 2016, SENS IMAGING, V17, DOI 10.1007/s11220-016-0138-3
NR 1
TC 3
Z9 3
U1 1
U2 1
PY 2016
BP 237
EP 238
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Chen, D
   Goins, C
   Waugaman, M
   Dimou, GD
   Beerel, PA
AF Chen, Dake
   Goins, Christine
   Waugaman, Maxwell
   Dimou, Georgios D.
   Beerel, Peter A.
GP ACM
TI Island-based Random Dynamic Voltage Scaling vs ML-Enhanced Power
   Side-Channel Attacks
SO PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2023, GLSVLSI 2023
DT Proceedings Paper
CT 33rd Great Lakes Symposium on VLSI (GLSVLSI)
CY JUN 05-07, 2023
CL Knoxville, TN
DE Hardware security; Side-channel attack; Machine learning
AB In this paper, we describe and analyze an island-based random dynamic voltage scaling (iRDVS) approach to thwart power side-channel attacks. We first analyze the impact of the number of independent voltage islands on the resulting signal-to-noise ratio and trace misalignment. As part of our analysis of misalignment, we propose a novel unsupervised machine learning (ML) based attack that is effective on systems with three or fewer independent voltages. Our results show that iRDVS with four voltage islands, however, cannot be broken with 200k encryption traces, suggesting that iRDVS can be effective. We finish the talk by describing an iRDVS test chip in a 12nm FinFet process that incorporates three variants of an AES-256 accelerator, all originating from the same RTL. This included a synchronous core, an asynchronous core with no protection, and a core employing the iRDVS technique using asynchronous logic. Lab measurements from the chips indicated that both unprotected variants failed the test vector leakage assessment (TVLA) security metric test, while the iRDVS was proven secure in a variety of configurations.
C1 [Chen, Dake; Beerel, Peter A.] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Goins, Christine; Dimou, Georgios D.] Niobium Microsyst Inc, Dayton, OH USA.
RP Chen, D (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM dakechen@usc.edu; christine@niobiummicrosystems.com;
   wellwaugaman@gmail.com; georgios@niobiummicrosystems.com;
   pabeerel@usc.edu
CR Baddam K, 2007, I CONF VLSI DESIGN, P854, DOI 10.1109/VLSID.2007.79
   Bayrak AG, 2013, DES AUT TEST EUROPE, P410
   Becker G.T., 2013, P INT CRYPT MOD C GA
   Beerel P. A., 2010, DESIGNERS GUIDE ASYN
   Brier E, 2004, LECT NOTES COMPUT SC, V3156, P16, DOI 10.1007/978-3-540-28632-5_2
   CHANDRAKASAN AP, 1992, IEEE J SOLID-ST CIRC, V27, P473, DOI 10.1109/4.126534
   Chen Dake, 2023, 2023 ISQED
   DeTrano Alexander, 2015, 2015 HASP, V7, P1
   Jayasinghe Darshana, 2019, 2019 IEEE ACM ICCAD, P1
   Kar M, 2017, I SYMPOS LOW POWER E
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Liu PC, 2012, IEEE T CIRCUITS-II, V59, P103, DOI 10.1109/TCSII.2011.2180094
   Lu YX, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P201, DOI 10.1109/FPT.2008.4762384
   MacQueen J., 1967, P 5 BERK S MATH STAT, P1
   Mangard S, 2004, LECT NOTES COMPUT SC, V2964, P222
   O'Flynn C, 2015, CAN CON EL COMP EN, P750, DOI 10.1109/CCECE.2015.7129369
   Pei Luo, 2014, 2014 International Conference on Reconfigurable Computing and FPGAs (ReConFig14), P1, DOI 10.1109/ReConFig.2014.7032555
   SAKURAI T, 1990, IEEE J SOLID-ST CIRC, V25, P584, DOI 10.1109/4.52187
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Singh A, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P51, DOI 10.1109/ESSCIRC.2017.8094523
   van Woudenberg JGJ, 2011, LECT NOTES COMPUT SC, V6558, P104, DOI 10.1007/978-3-642-19074-2_8
   Yang SQ, 2005, DES AUT TEST EUROPE, P64
   Yu WZ, 2017, IEEE T COMPUT AID D, V36, P2149, DOI 10.1109/TCAD.2017.2682113
   Yu WZ, 2018, IEEE T EMERG TOP COM, V6, P244, DOI 10.1109/TETC.2016.2620382
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 333
EP 338
DI 10.1145/3583781.3590266
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Mukhopadhyay, S
   Long, Y
   Mudassar, B
   Nair, CS
   DeProspo, BH
   Torun, HM
   Kathaperumal, M
   Smet, V
   Kim, D
   Yalamanchili, S
   Swaminathan, M
AF Mukhopadhyay, S.
   Long, Y.
   Mudassar, B.
   Nair, C. S.
   DeProspo, B. H.
   Torun, H. M.
   Kathaperumal, M.
   Smet, V
   Kim, D.
   Yalamanchili, S.
   Swaminathan, M.
TI Heterogeneous integration for artificial intelligence: Challenges and
   opportunities
SO IBM JOURNAL OF RESEARCH AND DEVELOPMENT
DT Article
AB The recent progress in artificial intelligence (AI) and machine learning (ML) has enabled computing platforms to solve highly complex difficult problems in computer vision, robotics, finance, security, and science. The algorithmic progress in AI/ML have motivated new research in hardware accelerators. The dedicated accelerators promise high energy efficiency compared to software solutions using CPU. However, as AI/ML models become complex, the increasing memory demands and, hence, high energy/time cost of communication between logic and memory possess a major challenge to energy efficiency. We review the potential of heterogeneous integration in addressing the preceding challenge and present different approaches to leverage heterogeneous integration for energy-efficient AI platforms. First, we discuss packaging technologies for efficient chip-to-chip communication. Second, we present near-memory-processing architecture for AI accelerations that leverages 3D die-stacking. Third, processing-in-memory architectures using heterogeneous integration of CMOS and embedded non-volatile memory are presented. Finally, the article presents case studies that integrate preceding concepts to advance AI/ML hardware platform for different application domains.
C1 [Mukhopadhyay, S.; Long, Y.; Mudassar, B.; Nair, C. S.; DeProspo, B. H.; Torun, H. M.; Kathaperumal, M.; Smet, V; Kim, D.; Yalamanchili, S.; Swaminathan, M.] Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Mukhopadhyay, S (corresponding author), Georgia Inst Technol, Elect & Comp Engn, Atlanta, GA 30332 USA.
EM saibal@ece.gatech.edu; yunlong@gatech.edu; burhan.mudassar@gatech.edu;
   cnair3@gatech.edu; bdeprospo@gatech.edu; htorun3@gatech.edu;
   kmohan@ece.gatech.edu; vanessa.smet@prc.gatech.edu; dkim.gt@gmail.com;
   sudha@gatech.edu; madhavan.swaminathan@ece.gatech.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Amir M., 2018, P IEEE SOI 3D SUBTHR
   Amir M. F., 2016, 2016 IEEE SOI3DS, P1
   [Anonymous], 2014, S VLSI CIRC
   [Anonymous], 2014, LINCOLN LAB J
   [Anonymous], 2017, NANGATE FREEPDK15 OP
   [Anonymous], 2014, 2 WIDE IO
   [Anonymous], 2012, JESD793F DDR3 SDRAM
   [Anonymous], 2014, THESIS U MARYLAND
   [Anonymous], 2018, JESD235
   Azarkhish E, 2018, IEEE T PARALL DISTR, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Azarkhish E, 2015, DES AUT TEST EUROPE, P1317
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Bernt M., 2018, P INT S MICROELECTRO, V2018
   Bewley A, 2016, IEEE IMAGE PROC, P3464, DOI 10.1109/ICIP.2016.7533003
   Bullier J., 2005, 23 PROBLEMS SYSTEMS, P103
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chung Junyoung, 2014, NIPS 2014 DEEP LEARN
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Galoogahi HK, 2017, IEEE I CONF COMP VIS, P1144, DOI [10.1109/ICCV.2017.129, 10.1109/ICCV.2017.128]
   Gao M., 2017, IEEE ANTENNAS PROP, P751, DOI DOI 10.1145/3037697.3037702
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Goossens S, 2017, NAT PHOTONICS, V11, P366, DOI [10.1038/NPHOTON.2017.75, 10.1038/nphoton.2017.75]
   Gould S, 2009, IEEE I CONF COMP VIS, P1, DOI 10.1109/ICCV.2009.5459211
   Haruta T, 2017, ISSCC DIG TECH PAP I, P76, DOI 10.1109/ISSCC.2017.7870268
   Hatamkhani H, 2006, IEEE T CIRCUITS-II, V53, P1230, DOI 10.1109/TCSII.2006.882348
   He K., 2016, P IEEE C COMPUTER VI
   He SM, 2018, INT SYM COMPUT INTEL, P3, DOI 10.1109/ISCID.2018.00007
   Hotz S., 2014, ADDITIONAL PAPERS PR, V2014
   Hybrid Memory Cube Consortium, 2013, HYBRID MEMORY CUBE S
   Ishida M., 2014, P IEEE 64 EL COMP TE
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Kim D, 2018, IEEE T COMPUT AID D, V37, P2360, DOI 10.1109/TCAD.2018.2858358
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kleinfelder S, 2001, IEEE J SOLID-ST CIRC, V36, P2049, DOI 10.1109/4.972156
   Ko JH, 2015, IEEE T MULTI-SCALE C, V1, P7, DOI 10.1109/TMSCS.2015.2478469
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee DU, 2014, ISSCC DIG TECH PAP I, V57, P432, DOI 10.1109/ISSCC.2014.6757501
   Li H, 2015, DES AUT TEST EUROPE, P1425
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu FH, 2019, IEEE T COMP PACK MAN, V9, P1426, DOI 10.1109/TCPMT.2019.2896173
   Liu FH, 2017, ELEC COMP C, P2097, DOI 10.1109/ECTC.2017.284
   Long Y, 2018, IEEE T VLSI SYST, V26, P2781, DOI 10.1109/TVLSI.2018.2819190
   Long Y, 2019, IEEE J EXPLOR SOLID-, V5, P113, DOI 10.1109/JXCDC.2019.2923745
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   MALLADI KT, 2012, ACM SIGARCH COMPUT A, P37
   Martwick A, 2015, ELEC COMP C, P266, DOI 10.1109/ECTC.2015.7159603
   Mudassar BA, 2019, DES AUT TEST EUROPE, P680, DOI 10.23919/DATE.2019.8715258
   Mukhopodhyay S, 2018, DES AUT TEST EUROPE, P1299, DOI 10.23919/DATE.2018.8342214
   Na T, 2016, I SYMPOS LOW POWER E, P58, DOI 10.1145/2934583.2934625
   O'Connor M., 2014, P MEM FOR WORKSH JUN
   Okamoto D, 2019, ELEC COMP C, P2112, DOI 10.1109/ECTC.2019.00-31
   Rinner B, 2008, P IEEE, V96, P1565, DOI 10.1109/JPROC.2008.928742
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Skorka O, 2014, PROC SPIE, V9060, DOI 10.1117/12.2044808
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Torun HM, 2019, IEEE T MICROW THEORY, V67, P2128, DOI 10.1109/TMTT.2019.2915298
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wei F, 2016, ELEC COMP C, P1740, DOI 10.1109/ECTC.2016.301
   Yu SM, 2016, INT EL DEVICES MEET
   Zhao JS, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2541228.2541231
NR 69
TC 15
Z9 15
U1 4
U2 36
PD NOV-DEC
PY 2019
VL 63
IS 6
AR 4
DI 10.1147/JRD.2019.2947373
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Du, GM
   Tian, C
   Li, ZM
   Zhang, DL
   Yin, YS
   Ouyang, YM
AF Du, Gaoming
   Tian, Chao
   Li, Zhenmin
   Zhang, Duoli
   Yin, Yongsheng
   Ouyang, Yiming
GP Assoc Comp Machinery
TI Efficient Softmax Hardware Architecture for Deep Neural Networks
SO GLSVLSI '19 - PROCEEDINGS OF THE 2019 ON GREAT LAKES SYMPOSIUM ON VLSI
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT 29th Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 09-11, 2019
CL Tysons Corner, VA
ID ACCELERATOR
AB Deep neural network (DNN) has become a pivotal machine learning and object recognition technology in the big data era. The softmax layer is one of the key component layers for completing multi-classification tasks. However, the softmax layer contains complex exponential and division operations, resulting in low accuracy and long critical paths in hardware accelerator design. In order to solve the above issues, we present a softmax hardware architecture with proper accuracy, good trade-off and strong expansibility. We summarize the classification rules of neural network and balance the calculation accuracy between resource consumption. On this basis, we proposed an exponential calculation unit based on the group lookup table, and improve a natural logarithmic calculation unit based on the Maclaurin series and the data preprocessing scheme matching them. The experimental results show that the softmax hardware architecture proposed in this paper can achieve the calculation accuracy of 3 decimal fraction and the classification accuracy of 99.01%. Theoretically, it can accomplish the classification task of infinite categories.
C1 [Du, Gaoming; Tian, Chao; Li, Zhenmin; Zhang, Duoli; Yin, Yongsheng; Ouyang, Yiming] HeFei Univ Technol, Hefei, Anhui, Peoples R China.
RP Du, GM (corresponding author), HeFei Univ Technol, Hefei, Anhui, Peoples R China.
EM dugaoming@hfut.edu.cn
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], IEEE ACM INT S MICR
   Arisoy E, 2014, IEEE-ACM T AUDIO SPE, V22, P184, DOI 10.1109/TASLP.2013.2286919
   Aroutchelvame S. M., 2005, IEEE INT C EL CIRC S
   Bin Rabieah M, 2015, I C FIELD PROG LOGIC
   Brabec Tom, 2006, GAMM IMACS INT S SCI
   Camunas-Mesa L., 2011, IEEE T CIRCUITS-I, V58, P777
   Chen SY, 2016, IEEE C EVOL COMPUTAT, P4599, DOI 10.1109/CEC.2016.7744376
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Hormigo J, 2000, IEEE INT CONF ASAP, P215, DOI 10.1109/ASAP.2000.862392
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim SS, 2004, IEEE INT CONF ROBOT, P4639
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li XM, 2016, DISCRETE DYN NAT SOC, V2016, DOI 10.1155/2016/8061069
   Lin Kaiwen, 2017, APPL RES COMPUTERS
   Nilsson Peter, 2015, NORCHIP C JAN 2015
   Papadonikolakis M, 2012, IEEE T NEUR NET LEAR, V23, P1040, DOI 10.1109/TNNLS.2012.2196446
   Pouyan P., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P709, DOI 10.1109/ECCTD.2011.6043642
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   YUAN B, 2017, SYST ON CHIP C, P323
NR 23
TC 20
Z9 20
U1 1
U2 16
PY 2019
BP 75
EP 80
DI 10.1145/3299874.3317988
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ye, T
   Kuppannagari, SR
   Kannan, R
   Prasanna, VK
AF Ye, Tian
   Kuppannagari, Sanmukh R.
   Kannan, Rajgopal
   Prasanna, Viktor K.
GP IEEE COMP SOC
TI Performance Modeling and FPGA Acceleration of Homomorphic Encrypted
   Convolution
SO 2021 31ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL 2021)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 31st International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 30-SEP 03, 2021
CL ELECTR NETWORK
DE Homomorphic Encryption; Convolutional Neural Network; FPGA
AB Privacy of data is a critical concern when applying Machine Learning (ML) techniques to domains with sensitive data. Homomorphic Encryption (HE), by enabling computations on encrypted data, has emerged as a promising approach to perform inference on ML models such as Convolution Neural Network (CNN) in a privacy preserving manner. A significant portion of the total inference latency is in performing convolution over homomorphic encrypted data (HE-Convolution). For performing convolution over plaintext data, low latency accelerator designs have been proposed using algorithms such as im2col, frequency domain convolution, etc. However, developing accelerators for the HE versions of these algorithms is non-trivial. In this work, we develop a unified FPGA design that enables low latency execution of both im2col and frequency domain HE Convolution. To enable selection of the efficient algorithm for each convolution layer of a CNN, we develop a performance model that takes the parameters about the encryption and convolution layer as input and outputs the computation and resource requirements of the two algorithms for that layer. We use the performance model to select convolution algorithm for each layer of ResNet-50 and obtain the first low latency batch-1 inference accelerator for CNN inference with HE-Convolution targeting FPGAs using HLS. We compare our design against prior techniques on CPUs and show that our accelerator achieves speedups in the range of 3.4x similar to 6.7x in latency.
C1 [Ye, Tian] Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90007 USA.
   [Kuppannagari, Sanmukh R.; Prasanna, Viktor K.] Univ Southern Calif, Dept Elect Engn, Los Angeles, CA 90007 USA.
   [Kannan, Rajgopal] US Army Res Lab, Playa Vista, CA USA.
RP Ye, T (corresponding author), Univ Southern Calif, Dept Comp Sci, Los Angeles, CA 90007 USA.
EM tye69227@usc.edu; kuppanna@usc.edu; rajgopal.kannan.civ@mail.mil;
   prasanna@usc.edu
CR [Anonymous], 2018, MICR SEAL REL 3 0
   Badawi A. A., 2018, 20181056 CRYPT EPRIN
   Bajard Jean-Claude, 2017, Selected Areas in Cryptography - SAC 2016. 23rd International Conference. Revised Selected Papers: LNCS 10532, P423, DOI 10.1007/978-3-319-69453-5_23
   BARRETT P, 1987, LECT NOTES COMPUT SC, V263, P311
   Bian S., 2020, P IEEECVF C COMPUTER, P9400, DOI DOI 10.1109/CVPR42600.2020.00942
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Brakerski Z, 2012, LECT NOTES COMPUT SC, V7417, P868, DOI 10.1007/978-3-642-32009-5_50
   Chase M., 2017, SECURITY HOMOMORPHIC
   Chellapilla Kumar, 2006, 10 INT WORKSH FRONT
   Cheon J. H., 2016, 2016421 CRYPT EPRINT
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Fan J., 2012, IACR CRYPTOL EPRINT
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hesamifard E., 2017, CRYPTODL DEEP NEURAL
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Meng Y., 2021, 2021 ACM SIGDA INT S, P183, DOI 10.1145/3431920.3439286
   OpenMP Architecture Review Board, 2015, OPENMP APPL PROGRAM
   Reagen B., 2020, CHEETAH OPTIMIZING A
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Xilinx, 2020, VIVADO DESIGN SUITE
   Xilinx, 2021, ULTRASCALE ARCHITECT
   Ye T, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286219
NR 24
TC 6
Z9 6
U1 1
U2 3
PY 2021
BP 115
EP 121
DI 10.1109/FPL53798.2021.00027
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Mahajan, D
   Kim, JK
   Sacks, J
   Ardalan, A
   Kumar, A
   Esmaeilzadeh, H
AF Mahajan, Divya
   Kim, Joon Kyung
   Sacks, Jacob
   Ardalan, Adel
   Kumar, Arun
   Esmaeilzadeh, Hadi
TI In-RDBMS Hardware Acceleration of Advanced Analytics
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article
ID MAD-SKILLS; LIBRARY
AB The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UM), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL, provides, on average, 8.3 x end-to-end speedup for real datasets, with a maximum of 28.2x. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0x faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in approximate to 30-60 lines of Python.
C1 [Mahajan, Divya; Kim, Joon Kyung; Sacks, Jacob] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Ardalan, Adel] Univ Wisconsin Madison, Madison, WI USA.
   [Kumar, Arun; Esmaeilzadeh, Hadi] Univ Calif San Diego, San Diego, CA 92103 USA.
RP Mahajan, D (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM divya_mahajan@gatech.edu; jkkim@gatech.edu; jsacks@gatech.edu;
   adel@cs.wisc.edu; arunkk@eng.ucsd.edu; hadi@eng.ucsd.edu
CR [Anonymous], 2005, P 31 INT C VERY LARG
   [Anonymous], INT C ARCH SUPP PROG
   [Anonymous], 2009, PROC VLDB ENDOW, DOI DOI 10.14778/1687627.1687730
   [Anonymous], 2016, MICRO
   [Anonymous], 2014, P 19 INT C ARCH SUPP
   [Anonymous], 2016, ISCA
   [Anonymous], NEURAL INFORM PROCES
   [Anonymous], 2016, ISCA
   [Anonymous], 2016, HPCA
   [Anonymous], 2016, ISCA
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Caulfield Adrian M., 2016, MICROARCHITECTURE MI, P1, DOI DOI 10.1109/MICRO.2016.7783710
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng Y., 2012, P 2012 ACM SIGMOD IN, P697
   Chung E. S., 2013, ISCA
   Cohen J, 2009, PROC VLDB ENDOW, V2, P1481, DOI 10.14778/1687553.1687576
   Crotty A, 2015, PROC VLDB ENDOW, V8, P1466
   Das Dipankar, 2016, ARXIV160206709CS
   Dekel O, 2012, J MACH LEARN RES, V13, P165
   Du Z., 2015, 42 INT S COMP ARCH I
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Feng X., 2012, P 2012 ACM SIGMOD IN, P325, DOI 10.1145/2213836.2213874
   Frank A., 2010, IRVINE UCI MACHINE L
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hellerstein JM, 2012, PROC VLDB ENDOW, V5, P1700, DOI 10.14778/2367502.2367510
   Idreos S, 2012, IEEE DATA ENG B, V35, P40
   Kara K, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P433, DOI 10.1145/3035918.3035946
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Kim JK, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901331
   Koc ML, 2011, PROC VLDB ENDOW, V4, P302, DOI 10.14778/1952376.1952380
   Kumar A, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1717, DOI 10.1145/3035918.3054775
   Kumar A, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1969, DOI 10.1145/2723372.2723713
   Langford J., 2009, NIPS
   Li J, 2016, PROC VLDB ENDOW, V9, P1647, DOI 10.14778/3007328.3007331
   MAHAJAN D, 2016, IEEE INT S HIGH PERF
   Mann G., 2009, NIPS
   Owaida M, 2017, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2017.37
   Palkar Shoumik, 2017, WELD COMMON RUNTIME
   Papadonikolakis M, 2010, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2010.39
   Park J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P367, DOI 10.1145/3123939.3123979
   Patterson David, 2017, ABS170404760 CORR
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Putnam Andrew R., 2008, FIELD PROGRAMMABLE G
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Seide F, 2014, ICASSP
   Sharma Hardik, 2016, ACM IEEE INT S MICR
   Sidler David, 2017, 2017 27th International Conference on Field Programmable Logic and Applications (FPL), DOI 10.23919/FPL.2017.8056864
   Wang DZ, 2010, PROC VLDB ENDOW, V3, P1057, DOI 10.14778/1920841.1920974
   Wick M, 2010, PROC VLDB ENDOW, V3, P794, DOI 10.14778/1920841.1920942
   Xin Reynold S, 2013, P 2013 ACM SIGMOD IN, P13
   Xing HQ, 2016, INT WORKS EARTH OB
   Zhang Ce, 2014, ABS14037550 CORR
NR 52
TC 26
Z9 29
U1 1
U2 4
PD JUL
PY 2018
VL 11
IS 11
BP 1317
EP 1331
DI 10.14778/3236187.3236188
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Alnaser, Y
   Langer, J
   Stoll, M
AF Alnaser, Yousef
   Langer, Jan
   Stoll, Martin
GP IEEE
TI Accelerating Kernel Ridge Regression with Conjugate Gradient Method for
   large-scale data using FPGA High-level Synthesis
SO 2022 IEEE/ACM INTERNATIONAL WORKSHOP ON HETEROGENEOUS HIGH-PERFORMANCE
   RECONFIGURABLE COMPUTING (H2RC)
DT Proceedings Paper
CT 8th IEEE/ACM International Workshop on Heterogeneous High-Performance
   Reconfigurable Computing (H2RC)
CY NOV 13-18, 2022
CL Dallas, TX
DE High-Level Synthesis; Kernel Ridge Regression; Conjugate Gradient Method
AB In this work, we accelerate the Kernel Ridge Regression algorithm on an FPGA-based adaptive computing platform to achieve higher performance within faster development time by employing a design approach using high-level synthesis (HLS). We partition the overall algorithm into a quadratic complexity part that runs on the FPGA fabric and a linear complexity part that runs in Python on the ARM processors.
   In order to avoid storing the potentially huge kernel matrix in external memory, the designed accelerator computes the matrix on-the-fly in each iteration. Moreover, we overcome the memory bandwidth limitation by partitioning the kernel matrix into smaller tiles that are pre-fetched to small local memories and reused multiple times. The design is also parallelized and fully pipelined.
   The final accelerator can be used for any large-scale data without kernel matrix storage limitations and with an arbitrary number of features. The accelerator reaches 86 GFLOPS on a Kria XCK26 FPGA and 231 GFLOPS on an Alveo U30 card which is within 72% and 90% of the estimated peak performance of those boards.
   We use the Pynq framework to directly call the accelerator from our Python code. This work is an important first step towards a library for accelerating different Kernel methods for Machine Learning applications for different FPGA platforms that can be used conveniently from Python with a NumPy-like interface.
C1 [Alnaser, Yousef; Langer, Jan] Fraunhofer ENAS, Chemnitz, Germany.
   [Stoll, Martin] TU Chemnitz, Dept Math, Chemnitz, Germany.
RP Alnaser, Y (corresponding author), Fraunhofer ENAS, Chemnitz, Germany.
CR An S, 2007, PROC CVPR IEEE, P1033
   [Anonymous], 2005, PROC ACM SIGDA 13 IN
   Calore E, 2021, I C FIELD PROG LOGIC, P83, DOI 10.1109/FPL53798.2021.00022
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Dave N, 2007, MEMOCODE'07: FIFTH ACM & IEEE INTERNATIONAL CONFERENCE ON FORMAL METHODS AND MODELS FOR CO-DESIGN, PROCEEDINGS, P97, DOI 10.1109/MEMCOD.2007.371239
   Douak F, 2013, APPL ENERG, V103, P328, DOI 10.1016/j.apenergy.2012.09.055
   Dua D., 2019, UCI MACHINE LEARNING
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Jang JW, 2005, IEEE T VLSI SYST, V13, P1305, DOI 10.1109/TVLSI.2005.859562
   Kumar V., 2010, INT J PARALLEL PROG, V38
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Meanti G., 2020, P 34 INT C NEURAL IN
   Ohshima S, 2007, LECT NOTES COMPUT SC, V4395, P305
   Rampalli Sahithi, 2019, FPGA, DOI [10.1145/3289602.3294004, DOI 10.1145/3289602.3294004]
   Roldao A, 2010, ACM T RECONFIG TECHN, V3, DOI 10.1145/1661438.1661439
   Rudi A, 2017, ADV NEUR IN, V30
   Strenski D., 2012, HPC WIRE
   Stuke A, 2019, J CHEM PHYS, V150, DOI 10.1063/1.5086105
   Wu XH, 2021, PHYS LETT B, V819, DOI 10.1016/j.physletb.2021.136387
   You Y., 2021, CCF T HIGH PERFORM C
   You Y, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P307, DOI 10.1145/3205289.3205290
   Zachariadis O, 2020, COMPUT ELECTR ENG, V88, DOI 10.1016/j.compeleceng.2020.106848
   Zhuo L., 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
NR 23
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 28
EP 36
DI 10.1109/H2RC56700.2022.00009
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Lustig, D
   Cooksey, S
   Giroux, O
AF Lustig, Daniel
   Cooksey, Simon
   Giroux, Olivier
GP ACM
TI Mixed-Proxy Extensions for the NVIDIA PTX Memory Consistency Model
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE memory consistency; memory ordering; GPU; synchronization
ID SEMANTICS
AB In recent years, there has been a trend towards the use of accelerators and architectural specialization to continue scaling performance in spite of a slowing of Moore's Law. GPUs have always relied on dedicated hardware for graphics workloads, but modern GPUs now also incorporate compute-domain accelerators such as NVIDIA's Tensor Cores for machine learning. For these accelerators to be successfully integrated into a general-purpose programming language such as C++ or CUDA, there must be a forward- and backward-compatible API for the functionality they provide. To the extent that all of these accelerators interact with program threads through memory, they should be incorporated into the GPU's memory consistency model. Unfortunately, the use of accelerators and/or special non-coherent paths into memory produces non-standard memory behavior that existing GPU memory models cannot capture.
   In this work, we describe the "proxy" extensions added to version 7.5 of NVIDIA's PTX ISA for GPUs. A proxy is an extra tag abstractly applied to every memory or fence operation. Proxies generalize the notion of address translation and specialized non-coherent cache hierarchies into an abstraction that cleanly describes the resulting non-standard behavior. The goal of proxies is to facilitate integration of these specialized memory accesses into the general-purpose PTX programming model in a fully composable manner. This paper characterizes the behaviors that proxies can capture, the microarchitectural intuition behind them, the necessary updates to the formal memory model, and the tooling that we built in order to ensure that the resulting model both is sound and meets the needs of business-critical workloads that they are designed to support.
C1 [Lustig, Daniel; Giroux, Olivier] NVIDIA, Santa Clara, CA USA.
   [Cooksey, Simon] Univ Kent, Canterbury, Kent, England.
RP Lustig, D (corresponding author), NVIDIA, Santa Clara, CA USA.
EM dlustig@nvidia.com; simon@graymalk.in; ogiroux@apple.com
CR Manerkar YA, 2016, Arxiv, DOI arXiv:1611.01507
   Abdulla PA, 2012, LECT NOTES COMPUT SC, V7214, P204, DOI 10.1007/978-3-642-28756-5_15
   Alglave J, 2017, ACM T PROGR LANG SYS, V39, DOI 10.1145/2994593
   Alglave J, 2015, ACM SIGPLAN NOTICES, V50, P577, DOI [10.1145/2694344.2694391, 10.1145/2775054.2694391]
   Alglave J, 2014, ACM T PROGR LANG SYS, V36, DOI 10.1145/2627752
   Alglave Jade, 2008, P 4 WORKSHOP DECLARA
   [Anonymous], 2003, 17 ANN INT C SUPERCO
   ARM, 2021, ARM ARCHITECTURE REF
   Batty M, 2015, LECT NOTES COMPUT SC, V9032, P283, DOI 10.1007/978-3-662-46669-8_12
   Batty M, 2011, POPL 11: PROCEEDINGS OF THE 38TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P55, DOI 10.1145/1926385.1926394
   Boehm H.-J., 2013, N3710 SPECIFYING ABS
   Boehm HJ, 2008, ACM SIGPLAN NOTICES, V43, P68, DOI 10.1145/1379022.1375591
   Boehm Hans-J., 2014, P WORKSH MEM SYST PE
   Boehm Hans-J., 2013, N3786 PROHIBITING LO
   Bornholt J, 2017, ACM SIGPLAN NOTICES, V52, P467, DOI [10.1145/3062341.3062353, 10.1145/3140587.3062353]
   Flur S, 2017, ACM SIGPLAN NOTICES, V52, P429, DOI 10.1145/3093333.3009839
   Hower Derek R., 2014, P 19 INT C ARCHITECT
   HSA Foundation, 2015, HSA PLATFORM SYSTEM
   Jackson D, 2002, ACM T SOFTW ENG METH, V11, P256, DOI 10.1145/505145.505149
   Jeffrey A, 2016, PROCEEDINGS OF THE 31ST ANNUAL ACM-IEEE SYMPOSIUM ON LOGIC IN COMPUTER SCIENCE (LICS 2016), P759, DOI 10.1145/2933575.2934536
   Jeffrey Alan, 2022, P 49 ACM SIGPLAN S P
   Kang J, 2017, ACM SIGPLAN NOTICES, V52, P175, DOI 10.1145/3093333.3009850
   Khronos Vulkan Working Group, 2018, VULK 1192 A SPEC
   Kuperstein Michael, 2010, 2010 Formal Methods in Computer-Aided Design (FMCAD 2010), P111
   Lahav O, 2017, ACM SIGPLAN NOTICES, V52, P618, DOI [10.1145/3062341.3062352, 10.1145/3140587.3062352]
   Lustig D, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P257, DOI 10.1145/3297858.3304043
   Lustig D, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P661, DOI 10.1145/3037697.3037723
   Mador-Haim Sela, 2012, Computer Aided Verification. Proceedings 24th International Conference, CAV 2012, P495, DOI 10.1007/978-3-642-31424-7_36
   Manson J, 2005, ACM SIGPLAN NOTICES, V40, P378, DOI 10.1145/1047659.1040336
   Maranget Luc, 2015, FORMALIZATION HSA ME
   Matt Godbolt, 2022, COMP EXPL
   McKenny Paul E., 2016, P0422 OUT OFTHIN AIR
   MLCommons, 2021, GEN MLPERF SUBMISSIO
   NVIDIA, 2021, PTX ISA CUDA TOOLK D
   NVIDIA, 2021, NVIDIA CUDA C PROGR
   NVIDIA, 2017, NVIDIA TESLA V100 GP
   Orr MS, 2015, ACM SIGPLAN NOTICES, V50, P73, DOI [10.1145/2775054.2694350, 10.1145/2694344.2694350]
   Pavoitti Marco, 2020, P TWENTYNINTH EUROPE
   Pichon-Pharabod J, 2016, ACM SIGPLAN NOTICES, V51, P622, DOI 10.1145/2914770.2837616
   RISC-V Foundation, 2022, RISC V INSTRUCTION S
   Sarkar Susmit, 2018, P 45 ACM SIGPLAN S P
   Sewell P, 2010, COMMUN ACM, V53, P89, DOI 10.1145/1785414.1785443
   Simner Ben, 2020, P 20 9 EUROPEAN S PR
   Simner Ben, 2022, P THIRTYFIRST EUROPE
   Sinclair MD, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P161, DOI [10.1145/3140659.3080206, 10.1145/3079856.3080206]
   Sinclair MD, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P647, DOI 10.1145/2830772.2830821
   Sorensen Tyler, 2016, P 37 ACM SIGPLAN C P
   Wickerson J, 2017, ACM SIGPLAN NOTICES, V52, P190, DOI 10.1145/3093333.3009838
   Wickerson John, 2017, P 44 ACM SIGPLAN S P
NR 49
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1058
EP 1070
DI 10.1145/3470496.3533045
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Huang, Y
   Zheng, L
   Yao, PC
   Wang, QG
   Liao, XF
   Jin, H
   Xue, JL
AF Huang, Yu
   Zheng, Long
   Yao, Pengcheng
   Wang, Qinggang
   Liao, Xiaofei
   Jin, Hai
   Xue, Jingling
GP IEEE Comp Soc
TI Accelerating Graph Convolutional Networks Using Crossbar-based
   Processing-In-Memory Architectures
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE accelerator; processing-in-memory; graph convolutional network; crossbar
   architectures
AB Graph convolutional networks (GCNs) are promising to enable machine learning on graphs. GCNs exhibit mixed computational kernels, involving regular neural-network-like computing and irregular graph-analytics-like processing. Existing GCN accelerators obey a divide-and-conquer philosophy to architect two separate types of hardware to accelerate these two types of GCN kernels, respectively. This hybrid architecture improves intra-kernel efficiency but considers little inter-kernel interactions in a holistic view for improving overall efficiency.
   In this paper, we present a new GCN accelerator, REFLIP, with three key innovations in terms of architecture design, algorithm mappings, and practical implementations. First, REFLIP leverages PIM-featured crossbar architectures to build a unified architecture for supporting the two types of GCN kernels simultaneously. Second, REFLIP adopts novel algorithm mappings that can maximize potential performance gains reaped from the unified architecture by exploiting the massive crossbar-structured parallelism. Third, REFLIP assembles software/hardware co-optimizations to process real-world graphs efficiently. Compared to the state-of-the-art software frameworks running on Intel Xeon E5-2680v4 CPU and NVIDIA Tesla V100 GPU, REFLIP achieves the average speedups of 6,432 x and 86.32 x and the average energy savings of 9,817x and 302.44 x, respectively. In addition, REFLIP also outperforms a state-of-the-art GCN hardware accelerator, AWB-GCN, by achieving an average speedup of 5.06 x and an average energy saving of 15.63x.
C1 [Huang, Yu; Zheng, Long; Yao, Pengcheng; Wang, Qinggang; Liao, Xiaofei; Jin, Hai] Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Cluster & Grid Comp, Wuhan, Peoples R China.
   [Xue, Jingling] UNSW Sydney, Sydney, NSW, Australia.
RP Huang, Y (corresponding author), Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Cluster & Grid Comp, Wuhan, Peoples R China.
EM yuh@hust.edu.cn; longzh@hust.edu.cn; pcyao@hust.edu.cn;
   qgwang@hust.edu.cn; xfliao@hust.edu.cn; hjin@hust.edu.cn;
   jingling@cse.unsw.edu.au
CR Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], SNAP DATASETS
   [Anonymous], SYNOPSYS
   [Anonymous], MXNET
   [Anonymous], TRANSISTOR AMPLIFIER
   [Anonymous], HIGHLIGHTS HIGH BAND
   [Anonymous], PYTORCH SCATTER LIB
   [Anonymous], TENSORFLOW
   Auten A, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218751
   Bourlard H., 1988, ADV NEURAL INFORMATI, V1, P502
   Challapalle N, 2020, ANN I S COM, P433, DOI 10.1109/ISCA45697.2020.00044
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Dadu V, 2021, CONF PROC INT SYMP C, P595, DOI 10.1109/ISCA52012.2021.00053
   Dai GH, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P120, DOI 10.1145/3287624.3287637
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fey Matthias, 2019, ICLR WORKSHOP
   Fout A, 2017, ADV NEUR IN, V30
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Gonzalez Joseph E, 2012, 10 USENIX S OP SYST, P17, DOI DOI 10.1145/74850.74870
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu W., 2020, NEURIPS
   Huang Y, 2020, INT PARALL DISTRIB P, P684, DOI 10.1109/IPDPS47924.2020.00076
   Huang Y, 2019, DES AUT TEST EUROPE, P1273, DOI [10.23919/date.2019.8715192, 10.23919/DATE.2019.8715192]
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kipf T.N., 2016, ARXIV
   Krestinskaya O, 2015, 2015 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P538, DOI 10.1109/ICACCI.2015.7275664
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Li WT, 2020, ANN I S COM, P832, DOI 10.1109/ISCA45697.2020.00073
   Ma LX, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P443
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Niu DM, 2013, ICCAD-IEEE ACM INT, P17, DOI 10.1109/ICCAD.2013.6691092
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shun JL, 2013, ACM SIGPLAN NOTICES, V48, P135, DOI 10.1145/2517327.2442530
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Tailor S. A., 2021, P INT C LEARNING REP
   Thorpe J, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P495
   Velickovic P., 2018, INT C LEARN REPR
   Wang M., 2019, CORR
   Wang YK, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P515
   Xu K., 2019, P INT C LEARNING REP
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yan MY, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P615, DOI 10.1145/3352460.3358318
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Ying R, 2018, ADV NEUR IN, V31
   Zhang ZH, 2020, IEEE COMPUT ARCHIT L, V19, P59, DOI 10.1109/LCA.2020.2988991
   Zheng L, 2020, INT PARALL DISTRIB P, P696, DOI 10.1109/IPDPS47924.2020.00077
   CACTI
NR 55
TC 7
Z9 7
U1 2
U2 5
PY 2022
BP 1029
EP 1042
DI 10.1109/HPCA53966.2022.00079
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Dong, YC
   Jia, TY
   Du, KX
   Jing, YQ
   Wang, QJ
   Zhan, PX
   Zhang, YD
   Yan, FY
   Ma, YF
   Liang, Y
   Ye, L
   Huang, R
AF Dong, Yanchi
   Jia, Tianyu
   Du, Kaixuan
   Jing, Yiqi
   Wang, Qijun
   Zhan, Pixian
   Zhang, Yadong
   Yan, Fengyun
   Ma, Yufei
   Liang, Yun
   Ye, Le
   Huang, Ru
GP IEEE
TI A Model-Specific End-to-End Design Methodology for Resource-Constrained
   TinyML Hardware
SO 2023 60TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC
DT Proceedings Paper
CT 60th ACM/IEEE Design Automation Conference (DAC)
CY JUL 09-13, 2023
CL San Francisco, CA
DE TinyML; Accelerator; Design space exploration
AB Tiny machine learning (TinyML) becomes appealing as it enables machine learning on resource-constrained devices with ultra low energy and small form factor. In this paper, a model-specific end-to- end design methodology is presented for TinyML hardware design. First, we introduce an end-to-end system evaluation method using Roofline models, which considering both AI and other general-purpose computing to guide the architecture design choices. Second, to improve the efficiency of AI computation, we develop an enhanced design space exploration framework, TinyScale, to enable optimal low-voltage operation for energy-efficient TinyML. Finally, we present a use case driven design selection method to search the optimal hardware design across a set of application use cases. Our model-specific design methodology is evaluated on both TSMC 22nm and 55nm technology for MLPerf Tiny benchmark and a keyword spotting (KWS) SoC design. With the help of our end-to-end design methodology, an optimal TinyML hardware can be automatically explored with significant energy and EDP improvements for a diverse of TinyML use cases.
C1 [Dong, Yanchi; Jia, Tianyu; Du, Kaixuan; Jing, Yiqi; Ma, Yufei; Liang, Yun; Ye, Le; Huang, Ru] Peking Univ, Beijing, Peoples R China.
   [Wang, Qijun; Zhan, Pixian; Zhang, Yadong; Yan, Fengyun] Nano Core Chip Elect Technol, Hangzhou, Peoples R China.
   [Ye, Le] Peking Univ, Adv Inst Informat Techonol, Hangzhou, Peoples R China.
RP Jia, TY; Ye, L (corresponding author), Peking Univ, Beijing, Peoples R China.; Ye, L (corresponding author), Peking Univ, Adv Inst Informat Techonol, Hangzhou, Peoples R China.
EM tianyuj@pku.edu.cn; yele@pku.edu.cn
CR Banbury C., 2021, P NEUR INF PROC SYST
   Banbury C, 2021, MLSYS
   Buch M, 2021, INT SYM PERFORM ANAL, P96, DOI 10.1109/ISPASS51385.2021.00027
   Genc H, 2021, DES AUT CON, P769, DOI 10.1109/DAC18074.2021.9586216
   Jain R, 2014, IEEE J SOLID STATE C
   Jia T., 2020, IEEE MICRO
   Ju Y., 2022, IEEE ISSCC
   Lin J., 2020, NEURIPS
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Prakash S, 2022, Arxiv, DOI arXiv:2201.01863
   Russo E, 2022, DES AUT TEST EUROPE, P226, DOI 10.23919/DATE54114.2022.9774747
   Shan WW, 2021, IEEE J SOLID-ST CIRC, V56, P151, DOI 10.1109/JSSC.2020.3029097
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sheng Y, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P163, DOI 10.1145/3489517.3530427
   Skillman A, 2020, IEEE HOT CHIPS 32 S
   Ueyoshi K., 2022, IEEE ISSCC
   Wu YN, 2022, INT SYMP MICROARCH, P1377, DOI 10.1109/MICRO56248.2022.00096
   Wu YN, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942149
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/DAC56929.2023.10247791
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Sridharan, S
   Stevens, JR
   Roy, K
   Raghunathan, A
AF Sridharan, Shrihari
   Stevens, Jacob R. R.
   Roy, Kaushik
   Raghunathan, Anand
TI X-Former: In-Memory Acceleration of Transformers
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article; Early Access
DE In-memory computing; machine learning; neural networks
AB Transformers have achieved great success in a wide variety of natural language processing (NLP) tasks due to the attention mechanism, which assigns an importance score for every word relative to other words in a sequence. However, these models are very large, often reaching hundreds of billions of parameters, and therefore require a large number of DRAM accesses. Hence, traditional deep neural network (DNN) accelerators such as GPUs and TPUs face limitations in processing Transformers efficiently. In-memory accelerators based on non-volatile memory promise to be an effective solution to this challenge, since they provide high storage density while performing massively parallel matrix vector multiplications within memory arrays. However, attention score computations, which are frequently used in Transformers (unlike CNNs and RNNs), require matrix vector multiplications (MVM) where both operands change dynamically for each input. As a result, conventional NVM-based accelerators incur high write latency and write energy when used for Transformers, and further suffer from the low endurance of most NVM technologies. To address these challenges, we present X-Former, a hybrid in-memory hardware accelerator that consists of both NVM and CMOS processing elements to execute transformer workloads efficiently. To improve the hardware utilization of X-Former, we also propose a sequence blocking dataflow, which overlaps the computations of the two processing elements and reduces execution time. Across several benchmarks, we show that X-Former achieves upto 85x and 7.5x improvements in latency and energy over a NVIDIA GeForce GTX 1060 GPU and upto 10.7x and 4.6x improvements in latency and energy over a state-of-the-art in-memory NVM accelerator.
C1 [Sridharan, Shrihari; Stevens, Jacob R. R.; Roy, Kaushik; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Stevens, Jacob R. R.] Meta Platforms Inc, Cambridge, MA 02140 USA.
RP Sridharan, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM sridhar4@purdue.edu
CR Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   Ali M, 2021, IEEE SOLID-ST CIRC L, V4, P129, DOI 10.1109/LSSC.2021.3093354
   Ankit A, 2020, IEEE T COMPUT, V69, P1128, DOI 10.1109/TC.2020.2998456
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Chakraborty I, 2020, P IEEE, V108, P2276, DOI 10.1109/JPROC.2020.3003007
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Devlin J, 2019, 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES (NAACL HLT 2019), VOL. 1, P4171
   Goyal S, 2020, Arxiv, DOI arXiv:2001.08950
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Laguna AF, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1839, DOI 10.23919/DATE51398.2021.9474146
   Li HT, 2021, IEEE T ELECTRON DEV, V68, P6637, DOI 10.1109/TED.2021.3110464
   Lin Y, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3759
   Lu AN, 2021, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.659060
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Murmann B, ADC PERFORMANCE SURV
   Nagarajan A., 2020, ARXIV
   Park J., 2020, P MACHINE LEARNING S, P363
   Rajendran B, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL WORKSHOP ON THE PHYSICS OF SEMICONDUCTOR DEVICES: IWPSD-2007, P92, DOI 10.1109/IWPSD.2007.4472460
   Rajpurkar Pranav., 2016, P 2016 C EMP METH NA, P2383, DOI 10.18653/v1/D16-1264
   Roy S, 2021, IEEE T VLSI SYST, V29, P730, DOI 10.1109/TVLSI.2021.3063543
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stevens JR, 2021, DES AUT CON, P469, DOI 10.1109/DAC18074.2021.9586134
   Tambe Thierry, 2021, MICRO54 54 ANN IEEEA, P830, DOI 10.1145/3466752.3480095
   Tay Y, 2022, Arxiv, DOI arXiv:2009.06732
   Tu F., 2022, IEEE INT SOLID STATE, V65, P466, DOI DOI 10.1109/TVLSI.2022.3153605
   Vaswani A., 2017, P 31 INT C NEURAL IN
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang Alex., 2018, P 2018 EMNLP WORKSH, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]
   Wang HR, 2021, INT S HIGH PERF COMP, P97, DOI 10.1109/HPCA51647.2021.00018
   Wolf T, 2020, PROCEEDINGS OF THE 2020 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING: SYSTEM DEMONSTRATIONS, P38
   Yang XX, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415640
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071
   Zahoor F, 2020, NANOSCALE RES LETT, V15, DOI 10.1186/s11671-020-03299-9
NR 38
TC 0
Z9 0
U1 3
U2 3
PD 2023 JUN 19
PY 2023
DI 10.1109/TVLSI.2023.3282046
EA JUN 2023
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Mo, H
   Zhu, LG
   Shi, L
   Tan, SF
   Wang, SP
AF Mo, Hao
   Zhu, Ligu
   Shi, Lei
   Tan, Songfu
   Wang, Suping
TI HetSev: Exploiting Heterogeneity-Aware Autoscaling and
   Resource-Efficient Scheduling for Cost-Effective Machine-Learning Model
   Serving
SO ELECTRONICS
DT Article
DE inference serving; autoscaling; cost effectiveness; multi-tenant
   inference
AB To accelerate the inference of machine-learning (ML) model serving, clusters of machines require the use of expensive hardware accelerators (e.g., GPUs) to reduce execution time. Advanced inference serving systems are needed to satisfy latency service-level objectives (SLOs) in a cost-effective manner. Novel autoscaling mechanisms that greedily minimize the number of service instances while ensuring SLO compliance are helpful. However, we find that it is not adequate to guarantee cost effectiveness across heterogeneous GPU hardware, and this does not maximize resource utilization. In this paper, we propose HetSev to address these challenges by incorporating heterogeneity-aware autoscaling and resource-efficient scheduling to achieve cost effectiveness. We develop an autoscaling mechanism which accounts for SLO compliance and GPU heterogeneity, thus provisioning the appropriate type and number of instances to guarantee cost effectiveness. We leverage multi-tenant inference to improve GPU resource utilization, while alleviating inter-tenant interference by avoiding the co-location of identical ML instances on the same GPU during placement decisions. HetSev is integrated into Kubernetes and deployed onto a heterogeneous GPU cluster. We evaluated the performance of HetSev using several representative ML models. Compared with default Kubernetes, HetSev reduces resource cost by up to 2.15x while meeting SLO requirements.
C1 [Mo, Hao; Zhu, Ligu; Shi, Lei; Tan, Songfu; Wang, Suping] Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.
   [Zhu, Ligu] Beijng Key Lab Big Data Secur & Protect Ind, Beijing 100024, Peoples R China.
RP Zhu, LG; Shi, L (corresponding author), Commun Univ China, State Key Lab Media Convergence & Commun, Beijing 100024, Peoples R China.; Zhu, LG (corresponding author), Beijng Key Lab Big Data Secur & Protect Ind, Beijing 100024, Peoples R China.
EM zhuligu@cuc.edu.cn; leiky_shi@cuc.edu.cn
CR Al-Haidari F, 2013, INT CONF CLOUD COMP, P256, DOI 10.1109/CloudCom.2013.142
   Albahar H, 2022, 2022 22ND IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2022), P695, DOI 10.1109/CCGrid54584.2022.00079
   amazon, AMAZON SAGEMAKER
   amazon, AWS AUT
   amazon, AMAZON MACHINE LEARN
   [Anonymous], 2011, 2011 USENIX ANN TECH
   archive, TWITTER STREAMING TR
   aws.amazon, AWS EC2 PRICING
   Bandanau D, 2016, INT CONF ACOUST SPEE, P4945, DOI 10.1109/ICASSP.2016.7472618
   Borowiec D, 2022, IEEE INT CONF CLOUD, P374, DOI 10.1109/CLOUD55607.2022.00061
   Casalicchio E, 2019, CLUSTER COMPUT, V22, P995, DOI 10.1007/s10586-018-02890-1
   Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700
   Choi S, 2021, Arxiv, DOI arXiv:2109.01611
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   DCGM Exporter, NVIDIA GPU METR EXP
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   Docker, US
   Gandhi A, 2012, ACM T COMPUT SYST, V30
   Ghodrati S, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P681, DOI 10.1109/MICRO50266.2020.00062
   github, US
   github, AWSLABS MULTIMODEL S
   github, SELDONIO SELDON CORE
   github, OPEN NEURAL NETWORK
   github, PROMETHEUS
   google, GOOGLE CLOUD PREDICT
   GOOGLE, GOOGL CLOUD AUT
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu YT, 2018, MIDDLEWARE'18: PROCEEDINGS OF THE 2018 ACM/IFIP/USENIX MIDDLEWARE CONFERENCE, P53, DOI 10.1145/3274808.3274813
   Jog Adwait, 2014, GPGPU 7, DOI [10.1145/2576779.2576780, DOI 10.1145/2576779.2576780]
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Luksa M., 2017, Kubernetes in action
   Mars J, 2013, ISCA, P619
   Mendoza D, 2021, PROCEEDINGS OF THE 1ST WORKSHOP ON MACHINE LEARNING AND SYSTEMS (EUROMLSYS'21), P80, DOI 10.1145/3437984.3458837
   microsoft, MICROSOFT AZURE MACH
   Novakovic D, 2013, USENIX ATC, P219
   Olston C, 2017, Arxiv, DOI arXiv:1712.06139
   Perri D, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11030450
   Phull R., 2012, P 21 INT S HIGH PERF, P109
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Ting-An Yeh, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P173, DOI 10.1145/3369583.3392679
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang H, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218702
   Xiao WC, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P533
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
   Xiaorui Wu, 2020, APNet '20: Proceedings of the 4th Asia-Pacific Workshop on Networking, P36, DOI 10.1145/3411029.3411035
   Xu J., 2022, ARXIV
   Yaoyao, 2021, P MACHINE LEARNING S, V3, P167
   Yu FY, 2021, IEEE ICC, DOI 10.1109/ICC42927.2021.9500334
   Yu FX, 2022, Arxiv, DOI arXiv:2203.09040
   Yu Fuxun, 2021, ARXIV
   Zhang CL, 2022, IEEE T CLOUD COMPUT, V10, P1765, DOI 10.1109/TCC.2020.3006751
   Zhu JY, 2022, IEEE T PARALL DISTR, V33, P4818, DOI 10.1109/TPDS.2022.3202493
NR 60
TC 0
Z9 0
U1 0
U2 0
PD JAN
PY 2023
VL 12
IS 1
AR 240
DI 10.3390/electronics12010240
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Shafiee, A
   Nag, A
   Muralimanohar, N
   Balasubramonian, R
   Strachan, JP
   Hu, M
   Williams, RS
   Srikumar, V
AF Shafiee, Ali
   Nag, Anirban
   Muralimanohar, Naveen
   Balasubramonian, Rajeev
   Strachan, John Paul
   Hu, Miao
   Williams, R. Stanley
   Srikumar, Vivek
GP IEEE
TI ISAAC: A Convolutional Neural Network Accelerator with In-Situ Analog
   Arithmetic in Crossbars
SO 2016 ACM/IEEE 43RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 43rd ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2016
CL Seoul, SOUTH KOREA
DE CNN; DNN; memristor; analog; neural; accelerator
AB A number of recent efforts have attempted to design accelerators for popular machine learning algorithms, such as those involving convolutional and deep neural networks (CNNs and DNNs). These algorithms typically involve a large number of multiply-accumulate (dot-product) operations. A recent project, DaDianNao, adopts a near data processing approach, where a specialized neural functional unit performs all the digital arithmetic operations and receives input weights from adjacent eDRAM banks.
   This work explores an in-situ processing approach, where memristor crossbar arrays not only store input weights, but are also used to perform dot-product operations in an analog manner. While the use of crossbar memory as an analog dot-product engine is well known, no prior work has designed or characterized a full-fledged accelerator based on crossbars. In particular, our work makes the following contributions: (i) We design a pipelined architecture, with some crossbars dedicated for each neural network layer, and eDRAM buffers that aggregate data between pipeline stages. (ii) We define new data encoding techniques that are amenable to analog computations and that can reduce the high overheads of analog-to-digital conversion (ADC). (iii) We define the many supporting digital components required in an analog CNN accelerator and carry out a design space exploration to identify the best balance of memristor storage/compute, ADCs, and eDRAM storage on a chip. On a suite of CNN and DNN workloads, the proposed ISAAC architecture yields improvements of 14.8x, 5.5x, and 7.5x in throughput, energy, and computational density (respectively), relative to the state-of-the-art DaDianNao architecture.
C1 [Shafiee, Ali; Nag, Anirban; Balasubramonian, Rajeev; Srikumar, Vivek] Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
   [Muralimanohar, Naveen; Strachan, John Paul; Hu, Miao; Williams, R. Stanley] Hewlett Packard Labs, Palo Alto, CA USA.
RP Shafiee, A (corresponding author), Univ Utah, Sch Comp, Salt Lake City, UT 84112 USA.
EM shafiee@cs.utah.edu; anirban@cs.utah.edu; naveen.muralimanohar@hpe.com;
   rajeev@cs.utah.edu; john-paul.strachan@hpe.com; miao.hu@hpe.com;
   stan.williams@hpe.com; svivek@cs.utah.edu
CR Alibart F., 2013, NATURE
   [Anonymous], 2013, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2013.6638947
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2012, ADC PERFORMANCE EVOL
   Belhadj B., 2013, P ISCA 40
   Bojnordi M. N., 2016, P HPCA 22
   Boser B. E., 1991, J SOLID STATE CIRCUI
   Burr G., 2014, P IEDM
   Cavigelli L., 2015, P GLSVLSI 25
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y., 2014, P MICRO 47
   Chi P., 2016, P ISCA 43
   Cloutier J., 1996, VIP FPGA BASED PROCE
   Coates A., 2013, P ICML 30
   Du Z., 2015, P ISCA 42
   Du Z., 2014, P ASPDAC 19
   Farabet C., 2009, P INT C FIELD PROGR
   Farabet C., 2011, P CVPR
   Fieres J., 2006, P ART NEUR NETW PATT
   Genov R., 2001, CHARGE MODE PARALLEL
   Grigorian B., 2015, P HPCA 21
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hashmi A., 2011, P ISCA 38
   Hauswald J., 2015, P ISCA 42
   He KM, 2015, DELVING DEEP RECTIFI
   Ho Y., 2009, P ICCAD 28
   Hu M., 2016, P DAC 53
   Iakymchuk T, 2015, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-015-0059-4
   Jarrett K., 2009, P ICCV 12
   Joubert A., 2012, P IJCNN
   Kavehei O., 2011, P ISSNIP
   Kiigeler C., 2008, P NVMTS 9
   Kim D., 2016, P ISCA 43
   Kim K.-H., 2011, NANO LETT
   Kim Y., 2012, P SOCC 3
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kull L., 2013, J SOLID STATE CIRCUI
   Le Q. V., 2013, P IEEE INT C AC SPEE
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LiKamWa R., 2016, P ISCA 43
   Lim K., 2013, P ISCA
   Liu D., P ASPLOS 20
   Liu X., 2014, P HPEC 18
   Liu X., 2015, P DAC 52
   Merolla P., 2011, P CICC
   Muralimanohar N., 2007, P MICRO
   Murmann B., 2015, ADC PERF SURV 1997 2
   Nere A., 2013, P HPCA 19
   O'Halloran M., 2004, J SOLID STATE CIRCUI
   Ouyang W., 2014, ARXIV14093505
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Pershin Y. V., 2010, NEURAL NETWORKS
   Pham P.-H., 2012, P MWSCAS 55
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Putnam A., 2014, P ISCA 41
   Qadeer W., 2013, P ISCA 40
   Ramakrishnan S., 2014, VECTOR MATRIX MULTIP
   Reagen B., 2016, P ISCA 43
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Saberi M., 2011, ANAL POWER CONSUMPTI
   Sackinger E., 1991, IEEE T NEURAL NETWOR
   Schemmel J., 2008, P IJCNN
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Starzyk J., 2014, T CIRCUITS SYSTEMS 1, VI
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sufi M., 2011, P IJCNN
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Taha T., 2013, P IJCNN
   Tam S. M., 1990, P INT C SYST MAN CYB
   Temam O., 2012, P ISCA 39
   Vontobel PO, 2009, NANOTECHNOLOGY, V20, DOI 10.1088/0957-4484/20/42/425204
   Wu L., 2013, P ISCA 40
   Xu C, 2015, INT S HIGH PERF COMP, P476, DOI 10.1109/HPCA.2015.7056056
   Yakopcic C., 2013, PROCEEDINGS OF IJCNN
   Yazdanbakhsh A., 2014, P ISCA 41
   Zangeneh M., 2014, P T VLSI SYST
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 80
TC 1135
Z9 1213
U1 10
U2 90
PY 2016
BP 14
EP 26
DI 10.1109/ISCA.2016.12
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU El-Helw, I
   Hofman, R
   Bal, HE
AF El-Helw, Ismail
   Hofman, Rutger
   Bal, Henri E.
GP IEEE
TI Towards Fast Overlapping Community Detection
SO 2016 16TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID
   COMPUTING (CCGRID)
SE IEEE-ACM International Symposium on Cluster Cloud and Grid Computing
DT Proceedings Paper
CT 16th IEEE/ACM International Symposium on Cluster, Cloud and Grid
   Computing (CCGrid)
CY MAY 16-19, 2016
CL Cartagena, COLOMBIA
DE Algorithms for Accelerators and Heterogeneous Systems; Performance
   Analysis; Combinatorial and Data Intensive Application; Statistical
   Learning
AB Accelerating sequential algorithms in order to achieve high performance is often a nontrivial task. However, there are certain properties that can exacerbate this process and make it particularly daunting. For example, building an efficient parallel solution for a data-intensive algorithm requires a deep analysis of the memory access patterns and data reuse potential. Attempting to scale out the computations on clusters of machines introduces further complications due to network speed limitations. In this context, the optimization landscape can be extremely complex owing to the large number of trade-off decisions.
   In this paper, we discuss our experience designing two parallel implementations of an existing data-intensive machine learning algorithm that detects overlapping communities in graphs. The first design uses a single GPU to accelerate the computations of small data sets. We employed a code generation strategy in order to test and identify the best performing combination of optimizations. The second design uses a cluster of machines to scale out the computations for larger problem sizes. We used a mixture of MPI, RDMA and pipelining in order to circumvent networking overhead. Both these efforts bring us closer to understanding the complex relationships hidden within networks of entities.
C1 [El-Helw, Ismail; Hofman, Rutger; Bal, Henri E.] Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.
RP El-Helw, I (corresponding author), Vrije Univ Amsterdam, Dept Comp Sci, Amsterdam, Netherlands.
EM ielhelw@cs.vu.nl; rutger@cs.vu.nl; bal@cs.vu.nl
CR [Anonymous], 2016, NVIDIA GEFORCE GTX T
   [Anonymous], P ACM SIGKDD WORKSH
   [Anonymous], 2013, P 6 ACM INT C WEB SE, DOI [DOI 10.1145/2433396.2433471, 10.1145/2433396.2433471]
   Bae SH, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807668
   El-Helw I., 2016, P 2016 IEEE INT PAR
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Gonzalez Joseph E., 2014, OSDI, P599
   Hong S, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807620
   Hou Q., 2008, ACM SIGGRAPH 2008 PA, P19
   Kirmani S, 2013, INT CONF HIGH PERFOR
   LeBeane M, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807632
   Lee K, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807604
   Lee K, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503302
   Li W., 2016, P 19 INT C ART INT S
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
NR 16
TC 3
Z9 3
U1 0
U2 2
PY 2016
BP 175
EP 178
DI 10.1109/CCGrid.2016.98
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yang, Y
   Kuppannagari, SR
   Kannan, R
   Prasanna, VK
AF Yang, Yang
   Kuppannagari, Sanmukh R.
   Kannan, Rajgopal
   Prasanna, Viktor K.
GP IEEE
TI FPGA Accelerator for Homomorphic Encrypted Sparse Convolutional Neural
   Network Inference
SO 2022 IEEE 30TH INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM
   COMPUTING MACHINES (FCCM 2022)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT IEEE 30th International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 15-18, 2022
CL New York, NY
DE FPGA acceleration; homomorphic encryption; sparse neural networks;
   parallel computing
AB Homomorphic Encryption (HE) is a promising solution to the increasing concerns of privacy in machine learning. But HE-based CNN inference remains impractically slow. Pruning can significantly reduce the compute and memory footprint of CNNs. However, homomorphic encrypted Sparse Convolutional Neural Networks (SCNN) have vastly different compute and memory characteristics compared with unencrypted SCNN. Simply extending the design principles of existing SCNN accelerators may offset the potential acceleration offered by sparsity. To realize fast execution, we propose an FPGA accelerator to speedup the computation of linear layers, the main computational bottleneck in HE SCNN batch inference. First, we analyze the memory requirements of various linear layers in HE SCNN and discuss the unique challenges. Motivated by the analysis, we present a novel dataflow specially designed to optimize HE SCNN data reuse coupled with an efficient scheduling policy that minimizes on-chip SRAM access conflicts. Leveraging the proposed dataflow and scheduling algorithm, we demonstrate the first end-to-end acceleration of HE SCNN batch inference targeting CPU-FPGA heterogeneous platforms. For a batch of 8K images, our design achieves up to 5.6x speedup in inference latency compared with the CPU-only solution for widely studied 6-layer and 11-layer HE CNNs.
C1 [Yang, Yang; Kuppannagari, Sanmukh R.; Prasanna, Viktor K.] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
   [Kannan, Rajgopal] US Army Res Lab, Adelphi, MD USA.
RP Yang, Y (corresponding author), Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
EM yyang172@usc.edu; kuppanna@usc.edu; rajgopal.kannan.civ@mail.mil;
   prasanna@usc.edu
CR Albrecht M., 2018, HOMOMORPHIC ENCRYPTI
   [Anonymous], 2020, MICROSOFT SEAL RELEA
   [Anonymous], 2018, FASTER CRYPTONETS LE
   Bajard Jean-Claude, 2017, Selected Areas in Cryptography - SAC 2016. 23rd International Conference. Revised Selected Papers: LNCS 10532, P423, DOI 10.1007/978-3-319-69453-5_23
   Boemer F., 2020, SER PPMLP 20
   Boemer F, 2019, PROCEEDINGS OF THE 7TH ACM WORKSHOP ON ENCRYPTED COMPUTING & APPLIED HOMOMORPHIC CRYPTOGRAPHY (WAHC'19), P45, DOI 10.1145/3338469.3358944
   Boemer F, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P3, DOI 10.1145/3310273.3323047
   Brutzkus A, 2019, PR MACH LEARN RES, V97
   Cheon Jung Hee, 2018, Sel Areas Cryptogr, V11349, P347, DOI 10.1007/978-3-030-10970-7_16
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Dathathri R, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P546, DOI 10.1145/3385412.3386023
   Dathathri R, 2019, PROCEEDINGS OF THE 40TH ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '19), P142, DOI 10.1145/3314221.3314628
   Dowlin N, 2016, PR MACH LEARN RES, V48
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gale T., 2021, 2021 ACM C COMPUTER
   Garimella K., 2021, CRYPTONITE REVEALING
   Gentry C., 2009, FULLY HOMOMORPHIC EN, DOI [DOI 10.1103/PHYSREVLETT.109.150501, 10.1145/1536414.1536440]
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Han, 2016, 4 INT C LEARNING REP
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hesamifard E., ANN COMPUTER SECURIT
   Intel, STRAT 10 MX FPGAS
   Juvekar C, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P1651
   Migliore V, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126558
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Mishra P, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2505
   Nejatollahi H., 2020, DES AUT CON
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pei D., 1996, CHINESE REMAINDER TH
   QaisarAhmadAlBadawi A., IEEE T EMERG TOP COM
   Reagen B, 2021, INT S HIGH PERF COMP, P26, DOI 10.1109/HPCA51647.2021.00013
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Roy SS, 2019, INT S HIGH PERF COMP, P387, DOI 10.1109/HPCA.2019.00052
   Samardzic N., 2021, F1 FAST PROGRAMMABLE
   Syed D, 2020, INFORMATION, V11, DOI 10.3390/info11070357
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tajbakhsh N, 2016, IEEE T MED IMAGING, V35, P1299, DOI 10.1109/TMI.2016.2535302
   Xilinx, XIL ULTRASCALE FPGAS
   Xilinx, XIL VIT DEV PLATF
   Ye T., 2021, 2021 INT C FIELD PRO
   Ye T, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286219
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
   Zhu Michael, 2017, ARXIV171001878
NR 44
TC 0
Z9 0
U1 2
U2 9
PY 2022
BP 81
EP 89
DI 10.1109/FCCM53951.2022.9786115
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Qian, YH
   Liang, JY
   Pedrycz, W
   Dang, CY
AF Qian, Yuhua
   Liang, Jiye
   Pedrycz, Witold
   Dang, Chuangyin
TI Positive approximation: An accelerator for attribute reduction in rough
   set theory
SO ARTIFICIAL INTELLIGENCE
DT Article
DE Rough set theory; Attribute reduction; Decision table; Positive
   approximation; Granular computing
ID KNOWLEDGE REDUCTION; FEATURE-SELECTION; INFORMATION GRANULATION;
   DECISION TABLES; DIMENSIONALITY; UNCERTAINTY; ENTROPY; SYSTEMS
AB Feature selection is a challenging problem in areas such as pattern recognition, machine learning and data mining. Considering a consistency measure introduced in rough set theory, the problem of feature selection, also called attribute reduction, aims to retain the discriminatory power of original features. Many heuristic attribute reduction algorithms have been proposed however, quite often, these methods are computationally time-consuming. To overcome this shortcoming, we introduce a theoretic framework based on rough set theory, called positive approximation, which can be used to accelerate a heuristic process of attribute reduction. Based on the proposed accelerator, a general attribute reduction algorithm is designed. Through the use of the accelerator, several representative heuristic attribute reduction algorithms in rough set theory have been enhanced. Note that each of the modified algorithms can choose the same attribute reduct as its original version, and hence possesses the same classification accuracy. Experiments show that these modified algorithms outperform their original counterparts. It is worth noting that the performance of the modified algorithms becomes more visible when dealing with larger data sets. (C) 2010 Elsevier B.V. All rights reserved.
C1 [Qian, Yuhua; Liang, Jiye] Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.
   [Pedrycz, Witold] Univ Alberta, Dept Elect & Comp Engn, Edmonton, AB, Canada.
   [Qian, Yuhua; Dang, Chuangyin] City Univ Hong Kong, Dept Mfg Engn & Engn Management, Hong Kong, Hong Kong, Peoples R China.
RP Liang, JY (corresponding author), Minist Educ, Key Lab Computat Intelligence & Chinese Informat, Taiyuan 030006, Shanxi, Peoples R China.
EM jinchengqyh@sxu.edu.cn; ljy@sxu.edu.cn; pedrycz@ee.ualberta.ca;
   mecdang@cityu.edu.hk
CR Bazan Y., 1998, ROUGH SETS KNOWLEDGE, P321
   Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P1632, DOI 10.1016/j.patrec.2005.01.006
   Bhatt RB, 2005, PATTERN RECOGN LETT, V26, P965, DOI 10.1016/j.patrec.2004.09.044
   Chmielewski MR, 1996, INT J APPROX REASON, V15, P319, DOI 10.1016/S0888-613X(96)00074-6
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Düntsch I, 1998, ARTIF INTELL, V106, P109, DOI 10.1016/S0004-3702(98)00091-5
   Gediga G, 2001, ARTIF INTELL, V132, P219, DOI 10.1016/S0004-3702(01)00147-3
   Grzymala-Busse J. W., 1991, MANAGING UNCERTAINTY, P66
   Grzymala-Busse JW, 1992, INTELLIGENT DECISION, P3, DOI [10.1007/978-94-015-7579-5, DOI 10.1007/978-94-015-7975-9_]
   Guan JW, 1998, ARTIF INTELL, V105, P77, DOI 10.1016/S0004-3702(98)00090-3
   Guyon I., 2003, J MACH LEARN RES, V3, P1157, DOI DOI 10.1162/153244303322753616
   Hu QH, 2006, IEEE T FUZZY SYST, V14, P191, DOI 10.1109/TFUZZ.2005.864086
   Hu QH, 2006, PATTERN RECOGN LETT, V27, P414, DOI 10.1016/j.patrec.2005.09.004
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Jensen R., 2008, COMPUTATIONAL INTELL
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Kryszkiewicz M, 2001, INT J INTELL SYST, V16, P105, DOI 10.1002/1098-111X(200101)16:1<105::AID-INT8>3.0.CO;2-S
   Kryszkiewicz M, 2008, LECT NOTES COMPUT SC, V5390, P76, DOI 10.1007/978-3-540-89876-4_5
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Li DY, 2004, INT J UNCERTAIN FUZZ, V12, P651, DOI 10.1142/S0218488504003132
   Liang JY, 2005, LECT NOTES ARTIF INT, V3641, P701, DOI 10.1007/11548669_72
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   Liang JY, 2002, INT J UNCERTAIN FUZZ, V10, P95, DOI 10.1142/S021848850200134X
   Liu H, 1997, IEEE T KNOWL DATA EN, V9, P642, DOI 10.1109/69.617056
   [米据生 Mi Jusheng], 2003, [模糊系统与数学, Fuzzy Systems and Mathematics], V17, P54
   MODRZEJEWSKI M, 1993, P EUR C MACH LEARN, P213
   Nguyen HS, 2006, LECT NOTES COMPUT SC, V4100, P334
   Pavlenko T, 2003, J STAT PLAN INFER, V115, P565, DOI 10.1016/S0378-3758(02)00166-0
   Pawlak Z., 1991, SPRINGER SCI BUSINES, VVolume 9, DOI DOI 10.1007/978-94-011-3534-4
   Pawlak Z, 2007, INFORM SCIENCES, V177, P28, DOI 10.1016/j.ins.2006.06.006
   Pawlak Z, 2007, INFORM SCIENCES, V177, P41, DOI 10.1016/j.ins.2006.06.007
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pedrycz W, 2002, PATTERN RECOGN, V35, P825, DOI 10.1016/S0031-3203(01)00102-9
   Polkowski L, 2000, STUD FUZZ SOFT COMP, V56, P49
   POLKOWSKI L, 1992, INTELLIGENT DECISION, V11, P305
   Qian YH, 2008, COMPUT MATH APPL, V56, P1994, DOI 10.1016/j.camwa.2008.04.021
   Qian YH, 2008, FUZZY SET SYST, V159, P2353, DOI 10.1016/j.fss.2007.12.016
   Qian YH, 2008, COMPUT MATH APPL, V55, P1754, DOI 10.1016/j.camwa.2007.08.031
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2008, INFORM SCIENCES, V178, P181, DOI 10.1016/j.ins.2007.08.010
   Qian YH, 2010, IEEE T SYST MAN CY A, V40, P420, DOI 10.1109/TSMCA.2009.2035436
   Qian YH, 2009, INFORM SCIENCES, V179, P2809, DOI 10.1016/j.ins.2009.04.007
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Shao MW, 2005, INT J INTELL SYST, V20, P13, DOI 10.1002/int.20051
   Shen Q, 2004, PATTERN RECOGN, V37, P1351, DOI 10.1016/j.patcog.2003.10.016
   SKOWRON A, 1995, COMPUT INTELL, V11, P371, DOI 10.1111/j.1467-8640.1995.tb00039.x
   Slezak D, 2002, FUND INFORM, V53, P365
   Slezak D., 2000, IPMU 00, V1, P248
   SLEZAK D, 1995, APPROXIMATE REDUCTS
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GY, 2005, FUND INFORM, V68, P289
   WU SX, 2004, J SYSTEM SCI INFORM, V2, P557
   Wu WZ, 2005, INFORM SCIENCES, V174, P143, DOI 10.1016/j.ins.2004.09.002
   Xu Zhang-Yan, 2006, Chinese Journal of Computers, V29, P391
   Yao YY, 2001, INT J INTELL SYST, V16, P87, DOI 10.1002/1098-111X(200101)16:1<87::AID-INT7>3.0.CO;2-S
   ZIARKO W, 1993, J COMPUT SYST SCI, V46, P39, DOI 10.1016/0022-0000(93)90048-2
NR 60
TC 522
Z9 636
U1 9
U2 135
PD JUN
PY 2010
VL 174
IS 9-10
BP 597
EP 618
DI 10.1016/j.artint.2010.04.018
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Jang, JW
   Lee, S
   Kim, D
   Park, H
   Ardestani, AS
   Choi, Y
   Kim, C
   Kim, Y
   Yu, H
   Abdel-Aziz, H
   Park, JS
   Lee, H
   Lee, D
   Kim, MW
   Jung, H
   Nam, H
   Lim, D
   Lee, S
   Song, JH
   Kwon, S
   Hassoun, J
   Lim, S
   Choi, C
AF Jang, Jun-Woo
   Lee, Sehwan
   Kim, Dongyoung
   Park, Hyunsun
   Ardestani, Ali Shafiee
   Choi, Yeongjae
   Kim, Channoh
   Kim, Yoojin
   Yu, Hyeongseok
   Abdel-Aziz, Hamzah
   Park, Jun-Seok
   Lee, Heonsoo
   Lee, Dongwoo
   Kim, Myeong Woo
   Jung, Hanwoong
   Nam, Heewoo
   Lim, Dongguen
   Lee, Seungwon
   Song, Joon-Ho
   Kwon, Suknam
   Hassoun, Joseph
   Lim, SukHwan
   Choi, Changkyu
GP IEEE Comp Soc
TI Sparsity-Aware and Re-configurable NPU Architecture for Samsung Flagship
   Mobile SoC
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
DE neural processing unit; neural network; accelerator; sparsity;
   mixed-precision; re-configurable
ID ACCELERATOR
AB Of late, deep neural networks have become ubiquitous in mobile applications. As mobile devices generally require immediate response while maintaining user privacy, the demand for on-device machine learning technology is on the increase. Nevertheless, mobile devices suffer from restricted hardware resources, whereas deep neural networks involve considerable computation and communication. Therefore, the implementation of a neural-network specialized hardware accelerator, generally called neural processing unit (NPU), has started to gain attention for the mobile application processor (AP). However, NPUs for commercial mobile AP face two challenges that are difficult to realize simultaneously: execution of a wide range of applications and efficient performance.
   In this paper, we propose a flexible but efficient NPU architecture for a Samsung flagship mobile system-on-chip (SoC). To implement an efficient NPU, we design an energy-efficient inner-product engine that utilizes the input feature map sparsity. We propose a re-configurable MAC array to enhance the flexibility of the proposed NPU, dynamic internal memory port assignment to maximize on-chip memory bandwidth utilization, and efficient architecture to support mixed-precision arithmetic. We implement the proposed NPU using the Samsung 5nm library. Our silicon measurement experiments demonstrate that the proposed NPU achieves 290.7 FPS and 13.6 TOPS/W, when executing an 8-bit quantized Inception-v3 model [1] with a single NPU core. In addition, we analyze the proposed zero-skipping architecture in detail. Finally, we present the findings and lessons learned when implementing the commercial mobile NPU and interesting avenues for future work.
C1 [Jang, Jun-Woo; Lee, Sehwan; Kim, Dongyoung; Park, Hyunsun; Choi, Yeongjae; Kim, Channoh; Kim, Yoojin; Yu, Hyeongseok; Kim, Myeong Woo; Jung, Hanwoong; Nam, Heewoo; Lim, Dongguen; Lee, Seungwon; Song, Joon-Ho; Choi, Changkyu] Samsung Adv Inst Technol, Suwon, South Korea.
   [Ardestani, Ali Shafiee; Abdel-Aziz, Hamzah; Hassoun, Joseph] Samsung Semicond Inc, San Jose, CA USA.
   [Park, Jun-Seok; Lee, Heonsoo; Lee, Dongwoo; Kwon, Suknam; Lim, SukHwan] Samsung Elect, Hwaseong, South Korea.
RP Jang, JW (corresponding author), Samsung Adv Inst Technol, Suwon, South Korea.
EM junwoo.jang@samsung.com; sehwan.b.lee@samsung.com;
   dong-y.kim@samsung.com; h-s.park@samsung.com; ali.shafiee@samsung.com;
   yj90.choi@samsung.com; channoh.kim@samsung.com;
   yoojin73.kim@samsung.com; hs617.yu@samsung.com; hamzah.a@samsung.com;
   js.june.park@samsung.com; heonsoo.lee@samsung.com; dw88.lee@samsung.com;
   k.myeong-woo@samsung.com; hw7884.jung@samsung.com;
   hee-woo.nam@samsung.com; dongguen.lim@samsung.com;
   seungw.lee@samsung.com; joonho71.song@samsung.com;
   suknam.kwon@samsung.com; j.hassoun@samsung.com; sh19.lim@samsung.com;
   changkyu_choi@samsung.com
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   Banner R, 2019, ADV NEUR IN, V32
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Chen LL, 2017, PROCEEDINGS OF THE THEMATIC WORKSHOPS OF ACM MULTIMEDIA 2017 (THEMATIC WORKSHOPS'17), P349, DOI 10.1145/3126686.3126723
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi Y, 2017, IEEE T CIRCUITS-II, V64, P1332, DOI 10.1109/TCSII.2017.2691771
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Devlin J., 2018, PREPRINT
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   Han S, 2015, ADV NEUR IN, V28
   Howard A. G., 2017, ARXIV
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Judd P, 2016, INT SYMP MICROARCH
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim D, 2018, IEEE DES TEST, V35, P39, DOI 10.1109/MDAT.2017.2741463
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee J, 2018, 2018 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING (EMNLP 2018), P1173
   Lin SH, 2019, PROC CVPR IEEE, P2785, DOI 10.1109/CVPR.2019.00290
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Park JS, 2021, ISSCC DIG TECH PAP I, V64, P152, DOI 10.1109/ISSCC42613.2021.9365928
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rosset C, 2020, MICROSOFT BLOG, V1, P2
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Wen W, 2016, ADV NEUR IN, V29
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhao R, 2019, PR MACH LEARN RES, V97
NR 39
TC 26
Z9 26
U1 1
U2 5
PY 2021
BP 15
EP 28
DI 10.1109/ISCA52012.2021.00011
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Graeff, C
   Volz, L
   Durante, M
AF Graeff, Christian
   Volz, Lennart
   Durante, Marco
TI Emerging technologies for cancer therapy using accelerated particles
SO PROGRESS IN PARTICLE AND NUCLEAR PHYSICS
DT Review
DE Particle therapy; Medical accelerators; Gantry; FLASH; Moving targets;
   Radioactive ions
ID MODULATED PROTON THERAPY; MONTE-CARLO SIMULATIONS; ION-BEAM THERAPY;
   RADIATION-THERAPY; MOTION MITIGATION; LUNG-CANCER; BRAGG PEAK;
   COST-EFFECTIVENESS; RADIOTHERAPY; ENERGY
AB Cancer therapy with accelerated charged particles is one of the most valuable biomedical applications of nuclear physics. The technology has vastly evolved in the past 50 years, the number of clinical centers is exponentially growing, and recent clinical results support the physics and radiobiology rationale that particles should be less toxic and more effective than conventional X-rays for many cancer patients. Charged particles are also the most mature technology for clinical translation of ultra-high dose rate (FLASH) radiotherapy. However, the fraction of patients treated with accelerated particles is still very small and the therapy is only applied to a few solid cancer indications. The growth of particle therapy strongly depends on technological innovations aiming to make the therapy cheaper, more conformal and faster. The most promising solutions to reach these goals are superconductive magnets to build compact accelerators; gantryless beam delivery; online image-guidance and adaptive therapy with the support of machine learning algorithms; and high-intensity accelerators coupled to online imaging. Large international collaborations are needed to hasten the clinical translation of the research results.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Graeff, Christian; Volz, Lennart; Durante, Marco] GSI Helmholtzzentrum Schwerionenforsch, Biophys Dept, Planckstr 1, D-64291 Darmstadt, Germany.
   [Graeff, Christian; Durante, Marco] Tech Univ Darmstadt, Darmstadt, Germany.
   [Durante, Marco] Univ Federico II, Dipartimento Fis Ettore Pancini, Naples, Italy.
RP Durante, M (corresponding author), GSI Helmholtzzentrum Schwerionenforsch, Biophys Dept, Planckstr 1, D-64291 Darmstadt, Germany.
EM M.Durante@gsi.de
CR Ageev A, 2021, NUCL INSTRUM METH A, V1000, DOI 10.1016/j.nima.2021.165223
   Alonso J.R., 2013, REV ACCEL SCI TECHNO, P227, DOI [10.1142/9789814449953_0009, DOI 10.1142/9789814449953_0009]
   Amaldi U, 2010, NUCL INSTRUM METH A, V620, P563, DOI 10.1016/j.nima.2010.03.130
   Amaldi U, 2009, REV ACCEL SCI TECH, V2, P111, DOI 10.1142/S179362680900020X
   Antoine S, 2009, NUCL INSTRUM METH A, V602, P293, DOI 10.1016/j.nima.2009.01.025
   Badziak J, 2018, J PHYS CONF SER, V959, DOI 10.1088/1742-6596/959/1/012001
   Baird YTE, 2020, IEEE T APPL SUPERCON, V30, DOI 10.1109/TASC.2019.2954681
   Balakin VE, 2018, KNE ENERGY, V3, P45, DOI [10.18502/ken.v3i2.1790, DOI 10.18502/KEN.V3I2.1790]
   Bär E, 2017, MED PHYS, V44, P2332, DOI 10.1002/mp.12215
   Barden MM, 2023, CANCER-AM CANCER SOC, V129, P1467, DOI 10.1002/cncr.34711
   Baumann BC, 2020, BRIT J CANCER, V123, P869, DOI 10.1038/s41416-020-0919-2
   Baumann BC, 2020, JAMA ONCOL, V6, P237, DOI 10.1001/jamaoncol.2019.4889
   Bayouth JE, 2019, MED PHYS, V46, P3753, DOI 10.1002/mp.13657
   Benedetti S, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.040101
   Bernstein D, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abe029
   Bert C, 2011, PHYS MED BIOL, V56, pR113, DOI 10.1088/0031-9155/56/16/R01
   Berthold J, 2021, INT J RADIAT ONCOL, V111, P1033, DOI 10.1016/j.ijrobp.2021.06.036
   Besemer A, 2013, PHYS MED BIOL, V58, P887, DOI 10.1088/0031-9155/58/4/887
   Bichsel H, 2013, ADV QUANTUM CHEM, V65, P1, DOI 10.1016/B978-0-12-396455-7.00001-7
   Boisbouvier S, 2022, Tech Innov Patient Support Radiat Oncol, V24, P124, DOI 10.1016/j.tipsro.2022.11.003
   Bortfeld TR, 2017, NATURE, V549, P451, DOI 10.1038/549451a
   Borys D, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac944c
   Boscolo D, 2022, NUCL INSTRUM METH A, V1043, DOI 10.1016/j.nima.2022.167464
   Boscolo D, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.737050
   Bottura L, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.566679
   Brock KK, 2019, SEMIN RADIAT ONCOL, V29, P181, DOI 10.1016/j.semradonc.2019.02.011
   Buchner T, 2020, P IEEE RAS-EMBS INT, P981, DOI 10.1109/BioRob49111.2020.9224389
   Buitenhuis HJT, 2017, PHYS MED BIOL, V62, P4654, DOI 10.1088/1361-6560/aa6b8c
   Caporaso GJ, 2009, REV ACCEL SCI TECH, V2, P253, DOI 10.1142/S1793626809000235
   Chandra RA, 2021, LANCET, V398, P171, DOI 10.1016/S0140-6736(21)00233-6
   Chang CW, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac9663
   Chang JY, 2017, INT J RADIAT ONCOL, V99, P41, DOI 10.1016/j.ijrobp.2017.05.014
   Chaudhary P, 2023, PHYS MED BIOL, V68, DOI 10.1088/1361-6560/aca387
   Chaudhary P, 2022, RADIAT ONCOL, V17, DOI 10.1186/s13014-022-02024-3
   Chaudhary P, 2021, FRONT PHYS-LAUSANNE, V9, DOI 10.3389/fphy.2021.624963
   Chevalier F., 2022, Nuclear Physics News, V32, P27, DOI 10.1080/10619127.2022.2063002
   Collings EW, 2022, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.737837
   Contreras J, 2017, PRACT RADIAT ONCOL, V7, pE71, DOI 10.1016/j.prro.2016.07.003
   Coutrakon GB, 2007, TECHNOL CANCER RES T, V6, P49, DOI 10.1177/15330346070060S408
   Czerska K, 2021, PHYS MEDICA, V82, P54, DOI 10.1016/j.ejmp.2020.12.013
   Deasy J., 1994, MED PHYS, V21, P709, DOI DOI 10.1118/1.597176
   Degiovanni A, 2018, P 9 INT PART ACC C I, P425
   Diffenderfer ES, 2022, MED PHYS, V49, P2039, DOI 10.1002/mp.15276
   Draguet C, 2022, RADIOTHER ONCOL, V176, P101, DOI 10.1016/j.radonc.2022.08.031
   Dueck J, 2016, INT J RADIAT ONCOL, V95, P534, DOI 10.1016/j.ijrobp.2015.11.015
   Durante M, 2021, NAT REV PHYS, V3, P777, DOI 10.1038/s42254-021-00368-5
   Durante M, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.00326
   Durante M, 2019, SEMIN ONCOL, V46, P219, DOI 10.1053/j.seminoncol.2019.07.007
   Durante M, 2019, PHYS REP, V800, P1, DOI 10.1016/j.physrep.2019.01.004
   Durante M, 2017, NAT REV CLIN ONCOL, V14, P483, DOI 10.1038/nrclinonc.2017.30
   Durante M, 2016, REP PROG PHYS, V79, DOI 10.1088/0034-4885/79/9/096702
   El Naqa I, 2022, MED PHYS, V49, P4109, DOI 10.1002/mp.15662
   Faddegon B, 2020, PHYS MEDICA, V72, P114, DOI 10.1016/j.ejmp.2020.03.019
   Farace P, 2016, PHYS MED BIOL, V61, P4078, DOI 10.1088/0031-9155/61/11/4078
   Fattori G., 2022, Z MED PHYS, V32
   Favaudon V, 2014, SCI TRANSL MED, V6, DOI 10.1126/scitranslmed.3008973
   Felcini E, 2022, IEEE T APPL SUPERCON, V32, DOI 10.1109/TASC.2022.3160380
   Gaide O, 2022, RADIOTHER ONCOL, V174, P87, DOI 10.1016/j.radonc.2021.12.045
   Gao F, 2022, RADIOTHER ONCOL, V166, P44, DOI 10.1016/j.radonc.2021.11.004
   Ge SP, 2019, CANCERS, V11, DOI 10.3390/cancers11010035
   Glide-Hurst CK, 2021, INT J RADIAT ONCOL, V109, P1054, DOI 10.1016/j.ijrobp.2020.10.021
   *GLOB BURD DIS CAN, 2019, JAMA ONCOL, V5, P1749, DOI DOI 10.1001/JAMAONCOL.2019.2996
   GOITEIN M, 1985, MED PHYS, V12, P608, DOI 10.1118/1.595762
   Graeff C, 2014, PHYS MEDICA, V30, P570, DOI 10.1016/j.ejmp.2014.03.011
   Graeff C, 2013, RADIOTHER ONCOL, V109, P419, DOI 10.1016/j.radonc.2013.09.018
   Grassberger C, 2015, MED PHYS, V42, P2462, DOI 10.1118/1.4916662
   Grégoire V, 2020, MOL ONCOL, V14, P1470, DOI 10.1002/1878-0261.12751
   Guiot J, 2022, MED RES REV, V42, P426, DOI 10.1002/med.21846
   Heeg P., 2002, 20021 GSI, P166
   Higginson A., NATURE COMMUN, V9 (
   Howard FM, 2020, JAMA NETW OPEN, V3, DOI 10.1001/jamanetworkopen.2020.25881
   Hu ZS, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab9707
   Hueso-González F, 2015, PHYS MED BIOL, V60, P6247, DOI 10.1088/0031-9155/60/16/6247
   Huynh E, 2020, NAT REV CLIN ONCOL, V17, P771, DOI 10.1038/s41571-020-0417-8
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Iwata Y, 2010, NUCL INSTRUM METH A, V624, P33, DOI 10.1016/j.nima.2010.09.016
   Jiang ZR, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac9881
   Johnson RP, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aa8b1d
   Jolly S, 2020, PHYS MEDICA, V78, P71, DOI 10.1016/j.ejmp.2020.08.005
   Jongen Y., NUCL INSTRUM METHODS
   Kamada T, 1999, RADIOTHER ONCOL, V50, P235, DOI 10.1016/S0167-8140(99)00005-5
   Kamakura S, 2006, J APPL PHYS, V100, DOI 10.1063/1.2345478
   Kang ML, 2022, INT J RADIAT ONCOL, V113, P203, DOI 10.1016/j.ijrobp.2022.01.009
   Kang YX, 2007, INT J RADIAT ONCOL, V67, P906, DOI 10.1016/j.ijrobp.2006.10.045
   Karsch L, 2017, ACTA ONCOL, V56, P1359, DOI 10.1080/0284186X.2017.1355111
   Kerstiens J, 2018, J AM COLL RADIOL, V15, P1704, DOI 10.1016/j.jacr.2018.07.020
   Kim J, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101601
   Knopf A.-C., RADIOTHER ONCOL, V169, P2022
   Kostyleva D, 2023, PHYS MED BIOL, V68, DOI 10.1088/1361-6560/aca5e8
   Kraan AC, 2015, FRONT ONCOL, V5, DOI 10.3389/fonc.2015.00150
   Kraft G, 2000, PROG PART NUCL PHYS, V45, pS473, DOI 10.1016/S0146-6410(00)00112-5
   Krämer M, 2000, PHYS MED BIOL, V45, P3299, DOI 10.1088/0031-9155/45/11/313
   Krieger M, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abcde6
   Krimmer J, 2018, NUCL INSTRUM METH A, V878, P58, DOI 10.1016/j.nima.2017.07.063
   Kroll F, 2022, NAT PHYS, V18, P316, DOI 10.1038/s41567-022-01520-3
   Kurz C, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab4d8c
   Larbalestier DC, 2014, NAT MATER, V13, P375, DOI [10.1038/NMAT3887, 10.1038/nmat3887]
   Lawler M, 2023, LANCET ONCOL, V24, pE11, DOI 10.1016/S1470-2045(22)00540-X
   Li X., 2021, THE OPEN, V4
   Li Y, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.819905
   Lievens Y, 2013, SEMIN RADIAT ONCOL, V23, P134, DOI 10.1016/j.semradonc.2012.11.005
   Lin LY, 2017, MED PHYS, V44, P703, DOI 10.1002/mp.12040
   Lin SH, 2020, J CLIN ONCOL, V38, P1569, DOI 10.1200/JCO.19.02503
   Linz U, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.124802
   Lis M, 2020, PHYS MEDICA, V76, P307, DOI 10.1016/j.ejmp.2020.07.029
   Liu CC, 2020, PHYS MEDICA, V69, P110, DOI 10.1016/j.ejmp.2019.12.006
   Liu W, 2016, INT J RADIAT ONCOL, V95, P523, DOI 10.1016/j.ijrobp.2015.11.002
   Llacer J, 1984, IEEE Trans Med Imaging, V3, P80, DOI 10.1109/TMI.1984.4307660
   Lomax AJ, 2001, MED PHYS, V28, P317, DOI 10.1118/1.1350587
   Lomax AJ, 2009, CANCER J, V15, P285, DOI 10.1097/PPO.0b013e3181af5cc7
   Lomax AJ, 2020, BRIT J RADIOL, V93, DOI 10.1259/bjr.20190582
   Luoni F, 2020, FRONT PHYS-LAUSANNE, V8, DOI 10.3389/fphy.2020.568145
   Luumlchtenborg R, 2011, MED PHYS, V38, P5448, DOI 10.1118/1.3633891
   MacKay R, 2021, RADIOTHER ONCOL, V164, P122, DOI 10.1016/j.radonc.2021.09.011
   Mascia AE, 2023, JAMA ONCOL, V9, P62, DOI 10.1001/jamaoncol.2022.5843
   Mazzucconi D, 2018, MED PHYS, V45, P5234, DOI 10.1002/mp.13219
   McCarroll RE, 2017, J APPL CLIN MED PHYS, V18, P223, DOI 10.1002/acm2.12024
   McIntosh C, 2021, NAT MED, V27, P999, DOI 10.1038/s41591-021-01359-w
   Mijnheer B, 2013, MED PHYS, V40, DOI 10.1118/1.4811216
   Mitin T, 2014, J CLIN ONCOL, V32, P2855, DOI 10.1200/JCO.2014.55.1945
   Mizushima K, 2017, NUCL INSTRUM METH B, V406, P347, DOI 10.1016/j.nimb.2017.03.051
   Moglioni M, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.929949
   Molinelli S., RADIOTHER ONCOL, V120
   Montay-Gruel P, 2018, RADIOTHER ONCOL, V129, P582, DOI 10.1016/j.radonc.2018.08.016
   Mori S, 2009, J RADIAT RES, V50, P513, DOI 10.1269/jrr.09032
   Moteabbed M, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac1ef2
   Mustapha B, 2019, AIP CONF PROC, V2160, DOI 10.1063/1.5127701
   Nesteruk KP, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abe02b
   Newhauser WD, 2015, PHYS MED BIOL, V60, pR155, DOI 10.1088/0031-9155/60/8/R155
   Niepel KB, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abbd14
   NN, 2010, J ICRU, DOI [10.1093/jicru/10.1.Report83, DOI 10.1093/JICRU/10.1.REPORT83]
   Noda K., 2019, Journal of Physics: Conference Series, V1154, DOI 10.1088/1742-6596/1154/1/012019
   Noda K, 2017, NUCL INSTRUM METH B, V406, P374, DOI 10.1016/j.nimb.2017.04.021
   Nogueira LM, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.9025
   Olaciregui-Ruiz I, 2020, PHYS IMAG RADIAT ONC, V15, P108, DOI 10.1016/j.phro.2020.08.003
   Oria CS, 2021, MED PHYS, DOI 10.1002/mp.15020
   Owen H, 2014, INT J MOD PHYS A, V29, DOI 10.1142/S0217751X14410024
   Paganetti H., 2019, PROTON THERAPY PHYS
   Paganetti H, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac344f
   Paganetti H, 2012, PHYS MED BIOL, V57, pR99, DOI 10.1088/0031-9155/57/11/R99
   Pakela JM, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.806153
   Pan ZY, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-28662-w
   Parodi K, 2023, Z MED PHYS, V33, P22, DOI 10.1016/j.zemedi.2022.11.001
   Parodi K, 2015, MED PHYS, V42, P7153, DOI 10.1118/1.4935869
   Pastor-Serrano O, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac692e
   Paul H, 2013, ADV QUANTUM CHEM, V65, P39, DOI 10.1016/B978-0-12-396455-7.00002-9
   Peters N, 2022, RADIOTHER ONCOL, V166, P71, DOI 10.1016/j.radonc.2021.11.002
   Piersanti L., PHYS MED BIOL
   Polf JC, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.838273
   Poludniowski G, 2015, BRIT J RADIOL, V88, DOI 10.1259/bjr.20150134
   Pönisch F, 2004, PHYS MED BIOL, V49, P5217, DOI 10.1088/0031-9155/49/23/002
   Primakov SP, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-30841-3
   Prunaretty J, 2019, REP PRACT ONCOL RADI, V24, P97, DOI 10.1016/j.rpor.2018.11.003
   PTCOG, 2022, US
   Raaymakers BW, 2017, PHYS MED BIOL, V62, pL41, DOI 10.1088/1361-6560/aa9517
   Rahim S, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00213
   Rahman AU, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac8af5
   Ramesh P, 2022, MED PHYS, V49, P7826, DOI 10.1002/mp.16009
   Riboldi M, 2012, LANCET ONCOL, V13, pE383, DOI 10.1016/S1470-2045(12)70243-7
   Richter D, 2013, MED PHYS, V40, DOI 10.1118/1.4800802
   Rossi L, 2022, IEEE T APPL SUPERCON, V32, DOI 10.1109/TASC.2022.3147433
   Sawakuchi GO, 2008, PHYS MED BIOL, V53, P4605, DOI 10.1088/0031-9155/53/17/010
   Saxena S, 2022, CANCERS, V14, DOI 10.3390/cancers14122860
   Schardt D, 2010, REV MOD PHYS, V82, P383, DOI 10.1103/RevModPhys.82.383
   Schreuder N., 2020, TECHNOLOGICAL DEV AL
   Schwarz M, 2022, MED PHYS, V49, P2861, DOI 10.1002/mp.15579
   Segedin B, 2016, RADIOL ONCOL, V50, P254, DOI 10.1515/raon-2016-0023
   Shah A, 2016, LANCET ONCOL, V17, P559, DOI 10.1016/S1470-2045(16)00171-6
   Shah AP, 2009, MED DOSIM, V34, P82, DOI 10.1016/j.meddos.2008.05.004
   Shen YR, 2020, FRONT PHYSIOL, V10, DOI 10.3389/fphys.2019.01580
   Simeonov Y, 2022, BIOMED PHYS ENG EXPR, V8, DOI 10.1088/2057-1976/ac5937
   Simeonov Y, 2021, Z MED PHYS, V31, P203, DOI 10.1016/j.zemedi.2020.06.008
   Simeonov Y, 2017, PHYS MED BIOL, V62, P7075, DOI 10.1088/1361-6560/aa81f4
   Singer DS, 2022, NAT MED, V28, P1345, DOI 10.1038/s41591-022-01881-5
   Smith AR, 2009, MED PHYS, V36, P556, DOI 10.1118/1.3058485
   Sokol O, 2022, SCI REP-UK, V12, DOI 10.1038/s41598-022-26290-z
   Steidl P, 2013, PHYS MED BIOL, V58, pN295, DOI 10.1088/0031-9155/58/21/N295
   Steinsberger T, 2023, INT J RADIAT ONCOL, V115, P1257, DOI 10.1016/j.ijrobp.2022.11.034
   Tashima H, 2016, PHYS MED BIOL, V61, P1795, DOI 10.1088/0031-9155/61/4/1795
   Tattenberg S, 2021, MED PHYS, V48, P5356, DOI 10.1002/mp.15097
   Tessonnier T, 2021, INT J RADIAT ONCOL, V111, P1011, DOI 10.1016/j.ijrobp.2021.07.1703
   Thariat J, 2013, NAT REV CLIN ONCOL, V10, P52, DOI 10.1038/nrclinonc.2012.203
   Thummerer A, 2022, MED PHYS, V49, P6824, DOI 10.1002/mp.15930
   Thummerer A, 2021, MED PHYS, V48, P7673, DOI 10.1002/mp.15333
   Tinganelli W, 2022, RADIOTHER ONCOL, V175, P185, DOI 10.1016/j.radonc.2022.05.003
   Tommasino F, 2019, PHYS MEDICA, V58, P99, DOI 10.1016/j.ejmp.2019.02.001
   Toppi M, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.601784
   Pham TT, 2022, RADIOTHER ONCOL, V170, P37, DOI 10.1016/j.radonc.2022.02.031
   Trbojevic D., 2011, P IPAC 2011 SAN SEB
   Unkelbach J, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae659
   Unkelbach J, 2018, SEMIN RADIAT ONCOL, V28, P88, DOI 10.1016/j.semradonc.2017.11.005
   URIE M, 1986, PHYS MED BIOL, V31, P1, DOI 10.1088/0031-9155/31/1/001
   van den Berg CAT, 2022, SEMIN RADIAT ONCOL, V32, P304, DOI 10.1016/j.semradonc.2022.06.001
   Van Herk M., 2000, International Journal of Radiation Oncology Biology Physics, V47, P1121, DOI 10.1016/S0360-3016(00)00518-6
   Verma V, 2016, CANCER-AM CANCER SOC, V122, P1483, DOI 10.1002/cncr.29882
   Volz L, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac33ec
   Volz L, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab6e52
   Volz L, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.930850
   Vozenin MC, 2022, NAT REV CLIN ONCOL, V19, P791, DOI 10.1038/s41571-022-00697-z
   Waddle MR, 2017, INT J RADIAT ONCOL, V99, P1078, DOI 10.1016/j.ijrobp.2017.07.042
   Wan WS, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.103501
   Wang KD, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.111302
   Weber UA, 2022, MED PHYS, V49, P1974, DOI 10.1002/mp.15135
   Wieser HP, 2017, MED PHYS, V44, P2556, DOI 10.1002/mp.12251
   Wijetunga N.A., 2022, CLIN CANCER RES, pOF1, DOI [10.1158/1078, DOI 10.1158/1078]
   Xiaorong Wang, 2019, Instruments, V3, DOI 10.3390/instruments3040062
   Yabe T, 2020, MED PHYS, V47, P3882, DOI 10.1002/mp.14372
   Yamada Y, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-73240-8
   Yang JZ, 2014, PRACT RADIAT ONCOL, V4, pE53, DOI 10.1016/j.prro.2013.04.005
   Yang JT, 2022, J CLIN ONCOL, V40, P3858, DOI 10.1200/JCO.22.01148
   Yock TI, 2016, LANCET ONCOL, V17, P287, DOI 10.1016/S1470-2045(15)00167-9
   Younkin JE, 2018, ADV RADIAT ONCOL, V3, P412, DOI 10.1016/j.adro.2018.02.006
   Youssef I, 2022, JAMA NETW OPEN, V5, DOI 10.1001/jamanetworkopen.2022.41538
   Zelefsky MJ, 2021, INT J RADIAT ONCOL, V110, P672, DOI 10.1016/j.ijrobp.2021.01.004
   Zhang GL, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/aca517
   Zhang GL, 2022, PHYS MEDICA, V103, P18, DOI 10.1016/j.ejmp.2022.09.018
   Zhang XK, 2021, MED PHYS, V48, P2646, DOI 10.1002/mp.14781
   Zhao W, 2021, QUANT IMAG MED SURG, V11, P4881, DOI 10.21037/qims-21-199
   Zhou Y, 2021, FRONT ONCOL, V11, DOI 10.3389/fonc.2021.715025
   Zhu Xuping, 2013, Theranostics, V3, P731, DOI 10.7150/thno.5162
NR 220
TC 1
Z9 1
U1 13
U2 13
PD JUL
PY 2023
VL 131
AR 104046
DI 10.1016/j.ppnp.2023.104046
EA MAY 2023
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Ollivier, S
   Li, S
   Tang, Y
   Cahoon, S
   Caginalp, R
   Chaudhuri, C
   Zhou, PP
   Tang, XL
   Hu, JT
   Jones, AK
AF Ollivier, Sebastien
   Li, Sheng
   Tang, Yue
   Cahoon, Stephen
   Caginalp, Ryan
   Chaudhuri, Chayanika
   Zhou, Peipei
   Tang, Xulong
   Hu, Jingtong
   Jones, Alex K.
TI Sustainable AI Processing at the Edge
SO IEEE MICRO
DT Article
DE Artificial intelligence; Edge computing; Memory management; Sustainable
   development; Measurement; Fabrication; Costs
ID PERFORMANCE; ENERGY
AB Edge computing is a popular paradigm for accelerating light- to medium-weight machine learning algorithms initiated from mobile devices without requiring the long communication latencies to send them to remote datacenters in the cloud. Edge servers primarily consider traditional concerns, such as size, weight, and power constraints for their installations. However, such metrics are not entirely sufficient to consider environmental impacts from computing given the significant contributions from embodied energy and carbon. In this article we explore the tradeoffs of hardware strategies for convolutional neural network acceleration engines considering inference and online training. In particular, we explore the use of mobile graphics processing unit (GPU) accelerators, recently released edge-class field-programmable gate arrays, and novel processing in memory (PIM) using dynamic random-access memory (DRAM) and emerging Racetrack memory. Given edge servers already employ DRAM and sometimes GPU accelerators, we consider the sustainability implications using breakeven analysis of replacing or augmenting DDR3 with Racetrack memory. We also consider the implications for provisioning edge servers with different accelerators using indifference analysis. While mobile GPUs are typically much more energy efficient, their significant embodied energy can make them less sustainable than PIM solutions in certain scenarios that consider activity time and compute effort.
C1 [Ollivier, Sebastien] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
   [Li, Sheng; Tang, Xulong] Univ Pittsburgh, Dept Comp Sci, Pittsburgh, PA 15260 USA.
   [Tang, Yue; Caginalp, Ryan; Chaudhuri, Chayanika] Univ Pittsburgh, Elect & Comp Engn, Pittsburgh, PA 15260 USA.
   [Cahoon, Stephen] Univ Pittsburgh, Comp Engn, Pittsburgh, PA 15260 USA.
   [Zhou, Peipei; Hu, Jingtong] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15260 USA.
   [Jones, Alex K.] Univ Pittsburgh, Elect & Comp Engn & Comp Sci, Pittsburgh, PA 15260 USA.
RP Ollivier, S (corresponding author), Univ Pittsburgh, Pittsburgh, PA 15260 USA.
EM sbo15@pitt.edu; shl188@pitt.edu; yut51@pitt.edu; stc127@pitt.edu;
   rlc113@pitt.edu; roc74@pitt.edu; peipei.zhou@pitt.edu;
   xulongtang@pitt.edu; jthu@pitt.edu; akjones@pitt.edu
CR [Anonymous], 2012, P 2012 ACMIEEE INT S
   Bardon MG, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372004
   Bayram I., 2016, PROC 7 INT GREEN SUS, P1
   Bennis R., 2019, LIFE CYCLE ASSESSMEN
   Blasing R, 2020, P IEEE, V108, P1303, DOI 10.1109/JPROC.2020.2975719
   Boyd S.B., 2011, LIFE CYCLE ASSESSMEN
   Brundermann E., 2018, 2018 9 INT GREEN SUS, P1, DOI DOI 10.1109/IGCC.2018.8752110
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Higgs T., 2009, IEEE INT S SUSTAINAB, DOI [10.1109/ISSST.2009.5156786, DOI 10.1109/ISSST.2009.5156786]
   ISO, 2006, 14044 ISO, DOI DOI 10.1007/S11367-015-0897-4
   Jones AK, 2013, ICCAD-IEEE ACM INT, P206, DOI 10.1109/ICCAD.2013.6691120
   Kline D, 2019, SUSTAIN COMPUT-INFOR, V22, P322, DOI 10.1016/j.suscom.2017.10.001
   Mai T., NRELTP6A20524091
   Ollivier S., IEEE ACM T NETWORK, V42, P9
   Ollivier S, 2022, INT SYMP MICROARCH, P784, DOI 10.1109/MICRO56248.2022.00060
   Popovich N., 2020, NY TIMES OCT
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Tang Y, 2022, ACM T DES AUTOMAT EL, V27, DOI 10.1145/3505633
   Venkatesan R, 2013, DES AUT TEST EUROPE, P1825
   Vetter JS, 2015, COMPUT SCI ENG, V17, P73, DOI 10.1109/MCSE.2015.4
   Xin X, 2020, INT S HIGH PERF COMP, P303, DOI 10.1109/HPCA47549.2020.00033
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
   Zhang Y, 2012, J APPL PHYS, V111, DOI 10.1063/1.4716460
NR 23
TC 0
Z9 0
U1 0
U2 0
PD JAN 1
PY 2023
VL 43
IS 1
BP 19
EP 28
DI 10.1109/MM.2022.3220399
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Lee, KJ
   Kim, B
   Mun, HG
   Moon, S
   Sim, JY
AF Lee, Kyeong-Jun
   Kim, ByungJun
   Mun, Han-Gyeol
   Moon, Seunghyun
   Sim, Jae-Yoon
GP IEEE
TI Joint Optimization of Cache Management and Graph Reordering for GCN
   Acceleration
SO 2023 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN, ISLPED
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY AUG 07-08, 2023
CL Vienna, AUSTRIA
DE cache; graph convolutional network; graph reordering; hardware
   accelerator; machine learning
AB Graph Convolutional Networks (GCNs) have demonstrated their efficacy in various real-world applications such as social networks and recommendation systems. Accelerating GCNs presents unique challenges due to their large number of nodes, sparse and heavily skewed connections. The reordering of the adjacency matrix has been the main strategy to effectively reduce the amount of re-access. Existing techniques of the reordering are categorized into i) degree-based sorting to identify high-degree nodes so that their data could be stored in the cache and ii) graph partitioning to maximally reuse the clustered data. However, as connections among the nodes vary significantly, processing various GCNs with a single strategy would cause performance degradation. This paper presents a software/hardware cooptimized platform for processing of general GCNs. We propose a hybrid scheme in the graph reordering that combines a sorting and a clustering in an adaptively optimized two-way partitioning. The two-way partitioning enables an efficient allocation of the on-chip cache memory space to reduce off-chip memory access by 4-to-12%. The implemented accelerator in 28nm demonstrates full functionalities with improved energy-efficiency by 2.2-to-3.7 x compared to the previous GCN accelerators.
C1 [Lee, Kyeong-Jun; Mun, Han-Gyeol; Moon, Seunghyun; Sim, Jae-Yoon] Pohang Univ Sci & Technol, Dept Convergence IT Engn, Pohang, South Korea.
   [Kim, ByungJun; Sim, Jae-Yoon] Pohang Univ Sci & Technol, Dept Elect Engn, Pohang, South Korea.
RP Lee, KJ (corresponding author), Pohang Univ Sci & Technol, Dept Convergence IT Engn, Pohang, South Korea.
EM leekj9444@postech.ac.kr; kbj1213@postech.ac.kr; oxigen2@postech.ac.kr;
   thearth@postech.ac.kr; jysim@postech.ac.kr
CR ALLEN JR, 1984, SIGPLAN NOTICES, V19, P233, DOI 10.1145/502949.502897
   Faldu P, 2019, I S WORKL CHAR PROC, P1, DOI 10.1109/IISWC47752.2019.9041948
   Geng T., 2021, MICRO 54 54 ANN IEEE
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Hwang R, 2022, Arxiv, DOI arXiv:2203.00158
   Jiang B, 2019, PROC CVPR IEEE, P11305, DOI 10.1109/CVPR.2019.01157
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Lee K.-J., 2022, IEEE T CIRCUITS-II, P1
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Park JS, 2021, ISSCC DIG TECH PAP I, V64, P152, DOI 10.1109/ISSCC42613.2021.9365928
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   You HR, 2022, INT S HIGH PERF COMP, P460, DOI 10.1109/HPCA53966.2022.00041
   Zeng Hanqing, 2020, 8 INT C LEARN REPR I
   Zhang Y., 2021, 2021 IEEE ACM INT C, P1
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/ISLPED58423.2023.10244423
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Hickmann, B
   Bradford, D
AF Hickmann, Brian
   Bradford, Dennis
BE Takagi, N
   Boldo, S
   Langhammer, M
TI Experimental Analysis of Matrix Multiplication Functional Units
SO 2019 IEEE 26TH SYMPOSIUM ON COMPUTER ARITHMETIC (ARITH)
SE Proceedings Symposium on Computer Arithmetic
DT Proceedings Paper
CT 26th IEEE Symposium on Computer Arithmetic (ARITH)
CY JUN 10-12, 2019
CL Kyoto, JAPAN
DE Machine learning; deep learning; tensor; half precision; single
   precision; Volta; matrix multiplication
AB The rapid growth of AI has led to the introduction of several new hardware designs to accelerate the matrix multiplication operation at the heart of AI applications. Examples include NVIDIA's Tensor Core*, Google's TPU*, and Intel's Neural Compute Stick*. However, the IEEE 754 standard gives significant implementation-specific flexibility in the definition of the matrix multiplication operation and the precision and compatibility of these new accelerators is not well documented. This paper describes a method exploiting the rounding modes and other features of the IEEE 754 standard in order to gain deeper insight into the design and functionality of matrix multiplication units. We apply this method to the NVIDIA V100 GPU Tensor Core* units and report our findings on the design properties and micro-architecture.
C1 [Hickmann, Brian] Intel Corp, Hillsboro, OR 97124 USA.
   [Bradford, Dennis] Intel Corp, Portland, OR USA.
RP Hickmann, B (corresponding author), Intel Corp, Hillsboro, OR 97124 USA.
EM brian.j.hickmann@intel.com; dennis.bradford@intel.com
CR [Anonymous], 2017, NVIDIA TESLA V100 GP
   [Anonymous], 2008, 7542008 IEEE, DOI 10.1109/IEEESTD.2008.4610935
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
NR 3
TC 6
Z9 6
U1 1
U2 3
PY 2019
BP 116
EP 119
DI 10.1109/ARITH.2019.00031
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Information Systems; Computer Science,
   Software Engineering; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Cong, J
   Fang, ZM
   Huang, MH
   Wei, P
   Wu, D
   Yu, CH
AF Cong, Jason
   Fang, Zhenman
   Huang, Muhuan
   Wei, Peng
   Wu, Di
   Yu, Cody Hao
TI Customizable Computing-From Single Chip to Datacenters
SO PROCEEDINGS OF THE IEEE
DT Article
DE Accelerator-rich architecture; CPU-FPGA; customizable computing; FPGA
   cloud; specialized acceleration
ID COPROCESSOR; PROCESSOR
AB Since its establishment in 2009, the Center for Domain-Specific Computing (CDSC) has focused on customizable computing. We believe that future computing systems will be customizable with extensive use of accelerators, as custom-designed accelerators often provide 10-100X performance/energy efficiency over the general-purpose processors. Such an accelerator-rich architecture presents a fundamental departure from the classical von Neumann architecture, which emphasizes efficient sharing of the executions of different instructions on a common pipeline, providing an elegant solution when the computing resource is scarce. In contrast, the accelerator-rich architecture features heterogeneity and customization for energy efficiency; this is better suited for energy-constrained designs where the silicon resource is abundant and spatial computing is favored-which has been the case with the end of Dennard scaling. Currently, customizable computing has garnered great interest; for example, this is evident by Intel's $17 billion acquisition of Altera in 2015 and Amazon's introduction of field-programmable gate-arrays (FPGAs) in its AWS public cloud. In this paper, we present an overview of the research programs and accomplishments of CDSC on customizable computing, from single chip to server node and to datacenters, with extensive use of composable accelerators and FPGAs. We highlight our successes in several application domains, such as medical imaging, machine learning, and computational genomics. In addition to architecture innovations, an equally important research dimension enables automation for customized computing. This includes automated compilation for combining source-code-level transformation for high-level synthesis with efficient parameterized architecture template generations, and efficient runtime support for scheduling and transparent resource management for integration of FPGAs for datacenter-scale acceleration with support to the existing programming interfaces, such as MapReduce, Hadoop, and Spark, for large-scale distributed computation. We will present the latest progress in these areas, and also discuss the challenges and opportunities ahead.
C1 [Cong, Jason; Fang, Zhenman; Huang, Muhuan; Wei, Peng; Wu, Di; Yu, Cody Hao] Univ Calif Los Angeles, Ctr Domain Specif Comp, Los Angeles, CA 90095 USA.
RP Cong, J (corresponding author), Univ Calif Los Angeles, Ctr Domain Specif Comp, Los Angeles, CA 90095 USA.
EM cong@cs.ucla.edu
CR [Anonymous], COMPUTER
   [Anonymous], P 8 INT C WIR COMM S
   [Anonymous], 2016, FPGAS SOFTWARE PROGR
   [Anonymous], P 51 ANN DES AUT C D
   [Anonymous], 2015, IBM DATA ENGINE NOSQ
   [Anonymous], AZURE SMARTNIC
   [Anonymous], ALGORITHMS VLSI PROC
   [Anonymous], IEEE DESIGN TEST
   [Anonymous], 2018, KUBERNETES
   [Anonymous], P 53 ANN DES AUT C D
   [Anonymous], ALIGNING SEQUENCE RE
   [Anonymous], HUAWEI FPGA ACCELERA
   [Anonymous], P HIGH THROUGHP SEQ
   [Anonymous], P 26 ACM SIGDA INT S
   [Anonymous], ALIBABA F2 INSTANCE
   [Anonymous], LECT NOTES COMPUTER
   [Anonymous], P 51 ANN DES AUT C D
   [Anonymous], 2018, P 55 ANN DESIGN AUTO, DOI DOI 10.1145/3195970.3195999
   [Anonymous], 2017, AMAZON EC2 F1 INSTAN
   [Anonymous], P ISCA
   [Anonymous], P IEEE HOT CHIPS 29
   [Anonymous], 2014, IEEE HOT CHIP SYMP
   [Anonymous], P 2012 ACM IEEE INT
   [Anonymous], P TODAES
   [Anonymous], 2012, P ACM IEEE INT S LOW
   [Anonymous], ADM PCIE 7V3 DAT REV
   [Anonymous], 2014, PROC ACM SIGDA INT S
   [Anonymous], 2016, P ICCAD
   [Anonymous], 2014, 2014 IEEE HOT CHIPS, DOI DOI 10.1109/H0TCHIPS.2014.7478821
   [Anonymous], HDB SIGNAL PROCESSIN
   [Anonymous], 2012, P 9 USENIX C NETW SY, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   [Anonymous], INTEL START SHIPPING
   [Anonymous], P DAC
   [Anonymous], P DAC
   [Anonymous], P TCAD
   [Anonymous], TECH REP
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Borkar S, 2011, COMMUN ACM, V54, P67, DOI 10.1145/1941487.1941507
   Brewer TM, 2010, IEEE MICRO, V30, P70, DOI 10.1109/MM.2010.36
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chandramoorthy N, 2015, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2015.7056017
   Chang MF, 2008, INT S HIGH PERF COMP, P174
   Chang MCF, 2016, ANN IEEE SYM FIELD P, P32, DOI 10.1109/FCCM.2016.21
   Chen Y, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0127957
   Chen YL, 2016, PROCEEDINGS OF THE FIFTEENTH INTERNATIONAL SYMPOSIUM - MANAGEMENT SCIENCE AND ENGINEERING (2016), P64
   Chen YT, 2015, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2015.27
   Chen YT, 2012, DES AUT TEST EUROPE, P45
   Clark NT, 2005, IEEE T COMPUT, V54, P1258, DOI 10.1109/TC.2005.156
   Cong J., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P67, DOI 10.1109/ISLPED.2011.5993609
   Cong JS, 2016, I SYMPOS LOW POWER E, P154, DOI 10.1145/2934583.2953984
   Cong JS, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P3, DOI 10.1145/3132402.3132406
   Cong J, 2017, INT S HIGH PERF COMP, P37, DOI 10.1109/HPCA.2017.19
   Cong J, 2016, ASIA S PACIF DES AUT, P503, DOI 10.1109/ASPDAC.2016.7428062
   Cong J, 2015, DES AUT CON, DOI 10.1145/2744769.2744879
   Cong JS, 2015, ICCAD-IEEE ACM INT, P380, DOI 10.1109/ICCAD.2015.7372595
   Cong J, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584664
   Cong J, 2013, I SYMPOS LOW POWER E, P305, DOI 10.1109/ISLPED.2013.6629314
   Cong J, 2012, DES AUT CON, P843
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Cong J, 2011, IEEE DES TEST COMPUT, V28, P6, DOI 10.1109/MDT.2010.141
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fajardo CF, 2011, DES AUT CON, P966
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Govindaraju V, 2012, IEEE MICRO, V32, P38, DOI 10.1109/MM.2012.51
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Hindman Benjamin, 2011, P 8 USENIX C NETW SY
   Huang MH, 2016, PROCEEDINGS OF THE SEVENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC 2016), P456, DOI 10.1145/2987550.2987569
   Hyunchul Park, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P370
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lyons MJ, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086727
   Oliver N., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P80, DOI 10.1109/ReConFig.2011.4
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pu J, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3107953
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Ruan ZY, 2018, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2018.00011
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   SMITH TF, 1981, J MOL BIOL, V147, P195, DOI 10.1016/0022-2836(81)90087-5
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Vavilapalli Vinod Kumar, 2013, SOCC, P1
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Wei X., 2017, P DAC, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang P., 2015, P DAC, P1
   Zhou PP, 2018, INT SYM PERFORM ANAL, P22, DOI 10.1109/ISPASS.2018.00011
   Zuo Wei, 2013, CODES ISSS, P1
NR 92
TC 10
Z9 10
U1 5
U2 10
PD JAN
PY 2019
VL 107
IS 1
SI SI
BP 185
EP 203
DI 10.1109/JPROC.2018.2876372
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Reddi, VJ
   Cheng, C
   Kanter, D
   Mattson, P
   Schmuelling, G
   Wu, CJ
AF Reddi, Vijay Janapa
   Cheng, Christine
   Kanter, David
   Mattson, Peter
   Schmuelling, Guenther
   Wu, Carole-Jean
TI The Vision Behind MLPerf: Understanding AI Inference Performance
SO IEEE MICRO
DT Article
AB Deep learning has sparked a renaissance in computer systems and architecture. Despite the breakneck pace of innovation, there is a crucial issue concerning the research and industry communities at large: how to enable neutral and useful performance assessment for machine learning (ML) software frameworks, ML hardware accelerators, and ML systems comprising both the software stack and the hardware. The ML field needs systematic methods for evaluating performance that represents real-world use cases and useful for making comparisons across different software and hardware implementations. MLPerf answers the call. MLPerf is an ML benchmark standard driven by academia and industry (70+ organizations). Built out of the expertise of multiple organizations, MLPerf establishes a standard benchmark suite with proper metrics and benchmarking methodologies to level the playing field for ML system performance measurement of different ML inference hardware, software, and services.
C1 [Reddi, Vijay Janapa] Harvard Univ, Cambridge, MA 02138 USA.
   [Cheng, Christine] Intel, Santa Clara, CA 95054 USA.
   [Kanter, David] MLCommons, Mountain View, CA 94105 USA.
   [Mattson, Peter] Google, ML Metr, Mountain View, CA 94043 USA.
   [Schmuelling, Guenther] Microsoft Corp, Redmond, WA 98052 USA.
   [Wu, Carole-Jean] Facebook Inc, Menlo Pk, CA 94025 USA.
RP Reddi, VJ (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM vj@ece.utexas.edu; christine.cheng@intel.com; dkanter@gmail.com;
   petermattson@google.com; guschmue@microsoft.com; carolejeanwu@fb.com
CR [Anonymous], 2020, NEW VERSION PTDAEMON
   [Anonymous], 2020, MLCOMMONS MACHINE LE
   [Anonymous], 2017, CORR
   Banbury C.R., 2020, MLSYS WORKSH BENCH M
   Devlin J., 2018, PREPRINT
   googleblog, 2019, INTRO NEXT GENERATIO
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Isensee F, 2021, NAT METHODS, V18, P203, DOI 10.1038/s41592-020-01008-z
   Johnson M., 2017, ARXIV161104558
   Mattson P., 2020, P 3 C MACH LEARN SYS
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Naumov Maxim, 2019, ARXIV190600091
   Reddi V. J., 2020, ARXIV201202328
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Sun Z., 2020, ARXIV200402984
   Wu Carole-Jean, 2020, ARXIV200307336
NR 16
TC 2
Z9 2
U1 0
U2 2
PD MAY-JUN
PY 2021
VL 41
IS 3
BP 10
EP 18
DI 10.1109/MM.2021.3066343
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Abadal, S
   Jain, A
   Guirado, R
   López-Alonso, J
   Alarcón, E
AF Abadal, Sergi
   Jain, Akshay
   Guirado, Robert
   Lopez-Alonso, Jorge
   Alarcon, Eduard
TI Computing Graph Neural Networks: A Survey from Algorithms to
   Accelerators
SO ACM COMPUTING SURVEYS
DT Article
DE Graph neural networks; GNN algorithms; accelerators; graph embeddings
ID KERNELS
AB Graph Neural Networks (GNNs) have exploded onto the machine learning scene in recent years owing to their capability to model and learn from graph-structured data. Such an ability has strong implications in a wide variety of fields whose data are inherently relational, for which conventional neural networks do not perform well. Indeed, as recent reviews can attest, research in the area of GNNs has grown rapidly and has lead to the development of a variety of GNN algorithm variants as well as to the exploration of ground-breaking applications in chemistry, neurology, electronics, or communication networks, among others. At the current stage research, however, the efficient processing of GNNs is still an open challenge for several reasons. Besides of their novelty, GNNs are hard to compute due to their dependence on the input graph, their combination of dense and very sparse operations, or the need to scale to huge graphs in some applications. In this context, this article aims to make two main contributions. On the one hand, a review of the field of GNNs is presented from the perspective of computing. This includes a brief tutorial on the GNN fundamentals, an overview of the evolution of the field in the last decade, and a summary of operations carried out in the multiple phases of different GNN algorithm variants. On the other hand, an in-depth analysis of current software and hardware acceleration schemes is provided, from which a hardware-software, graph-aware, and communication-centric vision for GNN accelerators is distilled.
C1 [Abadal, Sergi; Jain, Akshay; Guirado, Robert; Lopez-Alonso, Jorge; Alarcon, Eduard] Univ Politecn Cataluna, Barcelona, Spain.
RP Abadal, S (corresponding author), Univ Politecn Cataluna, Barcelona, Spain.
EM abadal@ac.upc.edu; akshay.jain@upc.edu; roberto.guirado.linan@upc.edu;
   jorlopezalonso@gmail.com; eduard.alarcon@upc.edu
CR Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   AdamAuten MatthewTomei, 2020, P DES AUT C
   [Anonymous], 2019, BUILD GRAPH NETS TEN
   [Anonymous], 2018, ACM COMPUT SURV, DOI DOI 10.1145/3154524
   [Anonymous], 2020, PADDLEPADDLE PGL
   [Anonymous], 1990, ARTIFICIAL NEURAL NE, DOI DOI 10.5555/104134.104145
   [Anonymous], 1968, NAUCHNO TECHNICHESKA
   [Anonymous], 2019, FOOD DISCOVERY UBER
   Atwood J., 2016, P 30 INT C NEURAL IN, DOI DOI 10.5555/3157096.3157320
   Balog M., 2019, CORR
   Bandinelli N, 2010, IEEE IJCNN
   Baruah Trinayan, P IEEE INT S PERF AN, P13
   Battaglia P. W., 2018, ARXIV PREPRINT ARXIV
   Battaglia Peter, 2016, ADV NEURAL INFORM PR, P4502
   Bianchini M, 2005, NEURAL NETWORKS, V18, P1040, DOI 10.1016/j.neunet.2005.07.003
   Botvinick M, 2019, TRENDS COGN SCI, V23, P408, DOI 10.1016/j.tics.2019.02.006
   Bresson X., 2017, ARXIV171107553 CORR
   Bronstein MM, 2017, IEEE SIGNAL PROC MAG, V34, P18, DOI 10.1109/MSP.2017.2693418
   Bruna J., 2019, P INT C LEARN REPR, P1
   Chami Ines, 2020, ARXIV200503675
   Chen Jianfei, 2018, INT C MACH LEARN, P942, DOI DOI 10.48550/ARXIV.1710.10568
   Chen M., 2020, ICML
   Chen X., 2021, IEEE T COMPUT AID D
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cheng JH, 2018, CHI 2018: EXTENDED ABSTRACTS OF THE 2018 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3170427.3188467
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Cho K, 2014, ARXIV, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Chu Xiaowen, 2020, ARXIV200306307
   Cui P, 2019, IEEE T KNOWL DATA EN, V31, P833, DOI 10.1109/TKDE.2018.2849727
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Das Rajarshi, 2018, P INT C LEARN REPR
   Dave S., 2020, ARXIV200700864
   De Cao Nicola, 2018, ICML 2018 WORKSH THE
   Dean J, 2008, COMMUN ACM, V51, P107, DOI 10.1145/1327452.1327492
   Defferrard M., 2016, ADV NEURAL INFORM PR, V29, P3844
   Di Massa V, 2006, IEEE IJCNN, P778
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Fan WQ, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P417, DOI 10.1145/3308558.3313488
   Fey M., ARXIV190302428, V2019
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Fout A, 2017, ADV NEUR IN, V30
   Gao HY, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1416, DOI 10.1145/3219819.3219947
   Garcia V., 2018, P 6 INT C LEARN REPR
   Garcia-Duran Alberto, 2017, ADV NEURAL INFORM PR, V30, P5119
   Garg Raveesh, ARXIV210307977
   Gärtner T, 2003, LECT NOTES ARTIF INT, V2777, P129, DOI 10.1007/978-3-540-45167-9_11
   Geng X, 2019, AAAI CONF ARTIF INTE, P3656
   Ghosh S, 2018, COMPUT SCI REV, V27, P88, DOI 10.1016/j.cosrev.2017.11.002
   Gilmer J, 2017, PR MACH LEARN RES, V70
   Gómez-Bombarelli R, 2018, ACS CENTRAL SCI, V4, P268, DOI 10.1021/acscentsci.7b00572
   Gori M, 2005, IEEE IJCNN, P729
   Grattarola D, 2021, IEEE COMPUT INTELL M, V16, P99, DOI 10.1109/MCI.2020.3039072
   Gui CY, 2019, J COMPUT SCI TECH-CH, V34, P339, DOI 10.1007/s11390-019-1914-z
   Guirado R, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401612
   Guo SN, 2019, AAAI CONF ARTIF INTE, P922
   Guresen E, 2011, EXPERT SYST APPL, V38, P10389, DOI 10.1016/j.eswa.2011.02.068
   Ham TJ, 2016, INT SYMP MICROARCH
   Hamaguchi T, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1802
   Hamilton William L., 2017, IEEE DATA ENG B, V40, P52
   Hamilton WL., 2017, ADV NEURAL INFORM PR, V2017, P1025, DOI DOI 10.48550/ARXIV.1706.02216
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Henaff M., 2015, ARXIV150605163
   Horvath Tamas, 2004, P 10 ACM SIGKDD INT, P158, DOI DOI 10.1145/1014052.1014072
   Hu Fenyu., 2019, IJCAI
   Hu W., 2020, NEURIPS
   Hu YW, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00075
   Huang GY, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00076
   James M, 2020, PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'20), P145, DOI 10.1145/3372780.3380846
   Jia ZH, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P997, DOI 10.1145/3394486.3403142
   Jia Zhihao, 2020, P MACH LEARN SYST ML, V2, P187
   Jia Zhihao, 2019, SYSML, V1, P1
   Jiang XD, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2656
   Jiyang Gao, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P11522, DOI 10.1109/CVPR42600.2020.01154
   John Peter C. St., 2019, J CHEM PHYS, V150, P23
   Ju Xiangyang, 2019, P 2 WORKSH MACH LEAR
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kawamoto T, 2018, ADV NEUR IN, V31
   Kim BH, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00630
   Kiningham Kevin, 2020, P WORKSH RES CONSTR
   Kiningham Kevin, 2022, IEEE T COMPUT
   Kipf T., 2017, P ICLR, P1, DOI DOI 10.48550/ARXIV.1609.02907
   Kipf T. N., 2016, ARXIV161107308
   Kojima Ryosuke, 2019, IEEE ACM INT SYMP, P231, DOI DOI 10.1109/CCGRID.2019.00037
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2018, IEEE MICRO, V38, P25, DOI 10.1109/MM.2018.2877289
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lamb Luis C., 2020, GRAPH NEURAL NETWORK, P4877
   LeCun, 2014, C TRACK P
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JB, 2019, ACM T KNOWL DISCOV D, V13, DOI 10.1145/3363574
   Lerer Adam, 2019, PYTORCH BIGGRAPH LAR
   Li GH, 2019, IEEE I CONF COMP VIS, P9266, DOI 10.1109/ICCV.2019.00936
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Li QM, 2018, AAAI CONF ARTIF INTE, P3538
   Li RY, 2017, IEEE I CONF COMP VIS, P4183, DOI 10.1109/ICCV.2017.448
   Li RY, 2018, AAAI CONF ARTIF INTE, P3546
   Li Xiaoxiao, 2020, Med Image Comput Comput Assist Interv, V12267, P625, DOI 10.1007/978-3-030-59728-3_61
   Li Y., 2015, P 4 INT C LEARNING R
   Li Y., 2018, LEARNING DEEP GENERA, P1
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Liao M., 2018, PROC INT C LEARN REP
   Liu HS, 2020, PROC VLDB ENDOW, V13, P2813, DOI 10.14778/3415478.3415482
   Ma LX, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P443
   Ma TL, 2019, AAAI CONF ARTIF INTE, P1069
   Ma Y., 2019, FRONT DATA COMPUT, V1, P105, DOI [DOI 10.11871/JFDC.ISSN.2096.742X.2019.01.011, 10.11871/jfdc.issn.2096.742X.2019.01.011]
   Ma YZ, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317838
   Malliaros FD, 2013, PHYS REP, V533, P95, DOI 10.1016/j.physrep.2013.08.002
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Monfardini G, 2006, FR ART INT, V141, P665
   Monti F, 2017, ADV NEUR IN, V30
   Myska V, 2019, 2019 42ND INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P216, DOI [10.1109/TSP.2019.8769036, 10.1109/tsp.2019.8769036]
   Nettleton DF, 2013, COMPUT SCI REV, V7, P1, DOI 10.1016/j.cosrev.2012.12.001
   Nickel M, 2016, P IEEE, V104, P11, DOI 10.1109/JPROC.2015.2483592
   Niepert M, 2016, PR MACH LEARN RES, V48
   Onoro-Rubio Daniel, 2017, P ANN C AUT KNOWL BA
   Pareja A, 2020, AAAI CONF ARTIF INTE, V34, P5363
   Park H, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3223
   PINEDA FJ, 1987, PHYS REV LETT, V59, P2229, DOI 10.1103/PhysRevLett.59.2229
   PrakashDwivedi Vijay, 2020, P ICML WORKSH GRAPH
   Qiu JZ, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2110, DOI 10.1145/3219819.3220077
   Rahimi A, 2018, PROCEEDINGS OF THE 56TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL), VOL 1, P2009
   Rusek K, 2019, SOSR '19: PROCEEDINGS OF THE 2019 ACM SYMPOSIUM ON SDN RESEARCH, P140, DOI 10.1145/3314148.3314357
   Rusek K, 2019, IEEE COMMUN LETT, V23, P274, DOI 10.1109/LCOMM.2018.2886259
   Salha G., 2019, ARXIV PREPRINT ARXIV
   Sanchez-Gonzalez A, 2018, PR MACH LEARN RES, V80
   Sanchez-Lengeling B., 2019, ARXIV, V1910, P10685
   Scarselli F, 2005, 2005 IEEE/WIC/ACM International Conference on Web Intelligence, Proceedings, P666, DOI 10.1109/WI.2005.67
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P81, DOI 10.1109/TNN.2008.2005141
   Schlichtkrull M., 2018, EUR SEM WEB C, V10843, P593, DOI DOI 10.1007/978-3-319-93417-4_38
   Shi W., 2020, P IEEE CVF C COMP VI, P1711, DOI DOI 10.1109/CVPR42600.2020.00178
   Son H.T., 2019, GRAPH NEURAL NETWORK
   Sukhbaatar S., 2016, ADV NEURAL INFORM PR, P2244, DOI DOI 10.5555/3157096.3157348
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Thekumparampil K. K., 2018, CORR
   Tian C, 2020, INT PARALL DISTRIB P, P936, DOI 10.1109/IPDPS47924.2020.00100
   Tkaczyk D, 2015, INT J DOC ANAL RECOG, V18, P317, DOI 10.1007/s10032-015-0249-8
   Tong Geng, 2020, 2020 53rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P922, DOI 10.1109/MICRO50266.2020.00079
   Tran DV, 2018, 2018 IEEE SYMPOSIUM SERIES ON COMPUTATIONAL INTELLIGENCE (IEEE SSCI), P1534, DOI 10.1109/SSCI.2018.8628758
   Tripathy Alok, P INT C HIGH PERF CO, P987
   Vaswani A, 2017, ADV NEUR IN, V30
   Velickovic P., 2017, INT C LEARN REPR, V1050, P10, DOI DOI 10.48550/ARXIV.1710.10903
   Verma M, 2019, PROCEEDINGS OF THE 42ND INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL (SIGIR '19), P1281, DOI 10.1145/3331184.3331377
   Verma S, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1539, DOI 10.1145/3292500.3330956
   Wang J, 2016, PROC CVPR IEEE, P2285, DOI 10.1109/CVPR.2016.251
   Wang L, 2021, PROCEEDINGS OF THE SIXTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '21), P67, DOI 10.1145/3447786.3456229
   Wang MX, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P803
   Wang XL, 2018, PROC CVPR IEEE, P7794, DOI 10.1109/CVPR.2018.00813
   Wang XH, 2021, INT CONF MANAGE DATA, P2628, DOI 10.1145/3448016.3457564
   Wang YZH, 2016, ACM SIGPLAN NOTICES, V51, P123, DOI [10.1145/2851141.2851145, 10.1145/3016078.2851145]
   Wang Yuke, P USENIX S OP SYST D
   Webber J, 2012, P 3 ANN C SYSTEMS PR, P217, DOI DOI 10.1145/2384716.2384777
   Wu F, 2019, PR MACH LEARN RES, V97
   Wu J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P406, DOI 10.1145/3292500.3330950
   Wu L., 2020, CORR
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Xie ZP, 2020, IEEE ACCESS, V8, P63349, DOI 10.1109/ACCESS.2019.2915364
   Xu K, 2019, BIOMED CIRC SYST C, DOI [10.1109/biocas.2019.8918711, 10.1109/vtcfall.2019.8891597]
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yan MY, 2020, IEEE COMPUT ARCHIT L, V19, P22, DOI 10.1109/LCA.2020.2970395
   Yan SJ, 2018, AAAI CONF ARTIF INTE, P7444
   Yang YD, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4099
   Ying Rex, 2019, Adv Neural Inf Process Syst, V32, P9240
   Ying R, 2018, ADV NEUR IN, V31
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yong Sweah Liang, 2006, P 5 INT WORKSH IN EV, P458
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Yu B, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3634
   Yu WC, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2663, DOI 10.1145/3219819.3220000
   Zayats Victoria, 2018, T ASSOC COMPUT LING, V6, P121, DOI [10.1162/tacl_a_00009, DOI 10.1162/TACL_A_00009]
   Zeng H., 2019, ARXIV PREPRINT ARXIV
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang DL, 2020, PROC VLDB ENDOW, V13, P3125, DOI 10.14778/3415478.3415539
   Zhang L, 2020, PROC CVPR IEEE, P3723, DOI 10.1109/CVPR42600.2020.00378
   Zhang MH, 2018, ADV NEUR IN, V31
   Zhang ZH, 2020, IEEE COMPUT ARCHIT L, V19, P59, DOI 10.1109/LCA.2020.2988991
   Zhang Ziwei, 2020, IEEE T KNOWL DATA EN, V14, P8
   Zhang Ziwei, 2020, ARXIV200902562
   Zheng D, 2020, PROCEEDINGS OF IA3 2020: 2020 IEEE/ACM 10TH WORKSHOP ON IRREGULAR APPLICATIONS: ARCHITECTURES AND ALGORITHMS (IA3), P36, DOI 10.1109/IA351965.2020.00011
   Zhou J., 2018, ARXIV181208434, DOI [10.1016/j.aiopen.2021.01.001, DOI 10.1016/J.AIOPEN.2021.01.001]
   Zhu Di, 2018, LEIBNIZ INT P INF, V114
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
   Zugner D., 2019, ARXIV190208412
NR 187
TC 48
Z9 48
U1 27
U2 145
PD DEC
PY 2022
VL 54
IS 9
AR 191
DI 10.1145/3477141
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Koliogeorgi, K
   Zervakis, G
   Anagnostos, D
   Zompakis, N
   Siozios, K
AF Koliogeorgi, Konstantina
   Zervakis, Georgios
   Anagnostos, Dimitrios
   Zompakis, Nikolaos
   Siozios, Kostas
GP IEEE
TI Optimizing SVM Classifier through Approximate and High Level Synthesis
   Techniques
SO 2019 8TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS
   TECHNOLOGIES (MOCAST)
DT Proceedings Paper
CT 8th International Conference on Modern Circuit and System Technologies
   (MOCAST)
CY MAY 13-15, 2019
CL Thessaloniki, GREECE
AB Leveraging the inherent error resilience of a large number of application domains, approximate computing is established as an efficient design alternative to improve their performance. Support Vector Machine (SVM) classifier is a widely adopted machine learning algorithm, that exhibits high error resilience and requires real-time execution. In this paper, we propose a highly optimized approximate SVM FPGA accelerator, utilizing arrhythmia detection in ECG signals as a case study. The proposed methodology applies two algorithmic approximation techniques, i.e., precision scaling and loop perforation, implemented in a coordinated manner in High-Level Synthesis (HLS). As a second level of performance enhancement, an exploration of the in-build optimization techniques of the HLS tool, with respect to the applied approximation, is also performed. Experimental evaluation shows that the proposed approximate SVM classifier attains a 15x speedup, while maintaining an accuracy of 96.7%.
C1 [Koliogeorgi, Konstantina; Zervakis, Georgios; Anagnostos, Dimitrios; Zompakis, Nikolaos] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
   [Siozios, Kostas] Aristotle Univ Thessaloniki, Dept Phys, Thessaloniki, Greece.
RP Koliogeorgi, K (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
EM konstantina@microlab.ntua.gr; zervakis@microlab.ntua.gr;
   anagnostos.d@microlab.ntua.gr; nzompaki@microlab.ntua.gr; ksiop@auth.gr
CR Almurib HAF, 2016, DES AUT TEST EUROPE, P660
   [Anonymous], ACM T EMBED COMPUT S
   Azariadi D, 2016, 2016 5TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   CORTES C, 1995, MACH LEARN, V20, P273, DOI 10.1023/A:1022627411411
   Feist T., 2012, CISC VIS NETW IND GL, V5
   Li CF, 2015, DES AUT CON, DOI 10.1145/2744769.2744863
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Shafique M., 2015, DES AUT C JUN
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Tang Y., 2013, ARXIV13060239
   Tsoutsouras V, 2017, J SIGNAL PROCESS SYS, V88, P127, DOI 10.1007/s11265-017-1230-1
   Wei LH, 2013, PLOS ONE, V8, DOI 10.1371/journal.pone.0070195
   Wu YF, 2016, IEEE J-STARS, V9, P5806, DOI 10.1109/JSTARS.2016.2539282
   Zervakis G., 2018, IEEE T CIRCUITS SYST, VII, P1
   Zervakis G, 2016, IEEE T VLSI SYST, V24, P3105, DOI 10.1109/TVLSI.2016.2535398
   Zervakis G, 2015, I SYMPOS LOW POWER E, P79, DOI 10.1109/ISLPED.2015.7273494
   Zhou YC, 2017, INT CONF ASIC, P1045, DOI 10.1109/ASICON.2017.8252658
NR 18
TC 3
Z9 3
U1 0
U2 1
PY 2019
DI 10.1109/mocast.2019.8742064
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Thomadakis, P
   Angelopoulos, A
   Gavalian, G
   Chrisochoides, N
AF Thomadakis, Polykarpos
   Angelopoulos, Angelos
   Gavalian, Gagik
   Chrisochoides, Nikos
TI De-noising drift chambers in CLAS12 using convolutional auto encoders
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Machine learning; Jefferson Lab; Tracking; Drift chambers; CLAS12;
   Particle accelerators
AB Modern Nuclear Physics experimental setups run experiments with higher beam intensity resulting in increased noise in detector components used for particle track reconstruction. Increased uncorrelated signals (noise) result in decreased particle reconstruction efficiency. In this paper, we investigate the usage of Machine Learning, specifically Convolutional Neural Network Auto-Encoders (CAE), for de-noising raw hits from drift chambers in the CLAS12 detector. To the best of our knowledge, this is the first time CAE is employed to perform such an operation in this field.
   During the de-noising phase, it is important to remove as much noise as possible while retaining the valid hits to avoid losing crucial information about the experiment. We show that using CAE, it is possible to remove noise hits while retaining up to 94% of valid tracks for a beam current of 110 nA while for lower beam currents (45 - 55 nA), we get up to 98% efficiency. Studies on experimental conditions with increasing noise show that CAE performs better than conventional tracking algorithms in isolating hits belonging to tracks. Specifically, the de-noising algorithm results in tracking efficiency improvements greater than 15%, in real data production procedures with nominal conditions, and up to two times better efficiency in synthetically generated data with high luminosity conditions (90 - 110 nA), indicating that machine learning can lead to significantly shorter times for conducting physics experiments. (C) 2021 Elsevier B.V. All rights reserved.
C1 [Thomadakis, Polykarpos; Angelopoulos, Angelos; Chrisochoides, Nikos] Old Dominion Univ, Dept Comp Sci, CRTC, Norfolk, VA 23529 USA.
   [Gavalian, Gagik] Jefferson Lab, Newport News, VA USA.
RP Thomadakis, P (corresponding author), Old Dominion Univ, Dept Comp Sci, CRTC, Norfolk, VA 23529 USA.
EM pthom001@odu.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2020, ANACONDA SOFTWARE DI
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Burkert V., NUCL INSTRUM METH A, V959
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chollet F., 2015, KERAS
   Dozat T, 2016, INCORPORATING NESTER
   Gavalian G., 2020, ARXIV200905144
   Gavalian G., 2020, ARXIV200812860
   Han J, 1995, LECT NOTES COMPUT SC, V930, P195
   Jolliffe I. T., 1990, Weather, V45, P375, DOI 10.1002/j.1477-8696.1990.tb05558.x
   Kingma DP, 2019, FOUND TRENDS MACH LE, V12, P4, DOI 10.1561/2200000056
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Krizhevsky Alex, 2011, ESANN, P489
   Mestayer M., NUCL INSTRUM METH A, V959
   Murtagh F., 1991, NEUROCOMPUTING, V2, P183, DOI DOI 10.1016/0925-2312(91)90023-5
   Nair V., 2010, ICML, P807
   Ng A, 2011, ELGAR LAW TECH SOC, P1
   Rifai S, 2011, INT C MACH LEARN, DOI DOI 10.5555/3104482.3104587
   Rumelhart David E., 1986, PARALLEL DISTRIBUTED, V1, DOI 10.1016/b978-1-4832-1446-7.50035-2
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sakurada M., 2014, P MLSDA 2014 2 WORKS, P4, DOI [10.1145/2689746.2689747, 10.1145/2689746, DOI 10.1145/2689746.2689747]
   Stepanyan S., 2020, 2020005 CLAS12, P2020
   Wang W, 2014, IEEE COMPUT SOC CONF, P496, DOI 10.1109/CVPRW.2014.79
   Xie J, 2012, ADV NEURAL INFORM PR, V25, P341, DOI DOI 10.1109/AGRO-GEOINFORMATICS.2012.6311605
   Ziegler V., NUCL INSTRUM METH A, V959
NR 26
TC 5
Z9 5
U1 0
U2 6
PD FEB
PY 2022
VL 271
AR 108201
DI 10.1016/j.cpc.2021.108201
EA OCT 2021
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
DA 2023-11-11
ER

PT J
AU Zhang, CL
   Yu, MC
   Wang, W
   Yan, F
AF Zhang, Chengliang
   Yu, Minchen
   Wang, Wei
   Yan, Feng
TI Enabling Cost-Effective, SLO-Aware Machine Learning Inference Serving on
   Public Cloud
SO IEEE TRANSACTIONS ON CLOUD COMPUTING
DT Article
DE Machine-learning-as-a-service; inference serving; SLO awareness; cost
   minimization; cloud computing
ID PREDICTION
AB The remarkable advances of Machine Learning (Mt) have spurred an increasing demand for ML- as-a-Service on public cloud: developers train and publish ML models as online services to provide low-latency inference for dynamic queries. The primary challenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizing serving cost. In this article, we proposes MArk (Model Ark), a general-purpose inference serving system, to tackle the dual challenge of SLO compliance and cost effectiveness. MArk employs three design choices tailored to inference workload. First, MArk dynamically batches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-cost ratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow or too expensive, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature of inference serving, MArk exploits the flexible, yet costly serverless instances to cover occasional load spikes that are hard to predict. We evaluated the performance of MArk using several state-of-the-art ML models trained in TensorFlow, MXNet, and Keras. Compared with the premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7.8 x while achieving even better latency performance.
C1 [Zhang, Chengliang; Yu, Minchen; Wang, Wei] Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
   [Yan, Feng] Univ Nevada, Dept Comp Sci & Engn, Reno, NV 89557 USA.
RP Wang, W (corresponding author), Hong Kong Univ Sci & Technol, Dept Comp Sci & Engn, Kowloon, Hong Kong, Peoples R China.
EM czhangbn@ust.hk; myuaj@ust.hk; weiwa@ust.hk; fyan@unr.edu
CR Ali-Eldin A., 2012, P 3 WORKSH SCI CLOUD, P31, DOI DOI 10.1145/2287036.2287044
   Ali-Eldin A, 2012, IEEE IFIP NETW OPER, P204, DOI 10.1109/NOMS.2012.6211900
   *AM, 2018, AMAZON WEB SERVICES
   Amazon, 2018, BUILD TRAIN DEPL MAC
   Amazon, 2018, DYN SCAL AM EC2 AUT
   Amazon, 2018, AWS AUT
   Amazon, 2019, US EL INF MXNET
   Amazon, 2018, LOAD TEST VAR AUT SC
   Amazon, 2018, CONF LAMBD FUNCT
   Amazon, 2018, TARG TRACK SCAL POL
   Amazon ECS, 2018, US
   Aniello Leonardo, 2014, Networked Systems. Second International Conference, NETYS 2014. Revised Selected Papers. LNCS: 8593, P122, DOI 10.1007/978-3-319-09581-3_9
   [Anonymous], 2019, EDGE TPU RUN INFEREN
   [Anonymous], 2019, NPU CAMBRICON
   [Anonymous], 2018, NEW AM EC2 SPOT PRIC
   [Anonymous], 2018, GOOGLE KUBERNETES EN
   [Anonymous], 2017, INT SHIPP NERV NEUR
   [Anonymous], 2018, AMAZON EC2
   [Anonymous], 2019, MXNET INFERENCE BENC
   [Anonymous], 2018, GOOGLE CLOUD FUNCTIO
   [Anonymous], 2019, AWS ELASTIC INFERENC
   ArchiveTeam, 2017, TWITT STREAM TRAC
   AWS, 2018, BURST PERF INST
   AWS, 2018, AM EC2 RES INST
   AWS, 2018, RIGHT SIZ PROV INST
   AWS, 2019, NEW AWS LAMBD PRED S
   AWS Inferentia, 2019, US
   AWS Lambda, 2018, US
   Awslabs, 2018, MXNET MOD SERV
   Azure, 2019, ANN AZ FUNCT PREM PL
   Barrett E, 2013, CONCURR COMP-PRACT E, V25, P1656, DOI 10.1002/cpe.2864
   Bergstra J., 2011, J MACH LEARN RES, V3, P1
   Casale G, 2010, PERFORM EVALUATION, V67, P61, DOI 10.1016/j.peva.2009.09.003
   Chollet F., 2015, KERAS DEEP LEARNING
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Cui Y., 2018, LONG DOES AWS LAMBDA
   Cui Y., 2018, IM AFRAID YOURE THIN
   Docker, 2018, US
   Doyle R. P., 2003, P 4 C USENIX S INTER, V5
   Fidel, SERV WARM PLUG
   FISCHER W, 1993, PERFORM EVALUATION, V18, P149, DOI 10.1016/0166-5316(93)90035-S
   Fox A., 2009, HOTCLOUD, V9, P12
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Google, 2018, KUB HOR SCAL
   Google, 2019, CLOUD TPU PERF GUID
   Google, 2018, GOOGL CLOUD AUT
   Google, 2018, GOOGL CLOUD PLATF
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Han R, 2014, FUTURE GENER COMP SY, V32, P82, DOI 10.1016/j.future.2012.05.018
   Harlap A, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P589, DOI 10.1145/3064176.3064182
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He X., 2015, P 24 INT S HIGH PERF, P207
   Hunt P, 2010, P USENIX ATC BOST MA, P11, DOI 10.5555/1855840.1855851
   Klein G, 2017, Arxiv, DOI arXiv:1701.02810
   Lee H, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P442, DOI 10.1109/CLOUD.2018.00062
   Lee Y, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P611
   Leitner P, 2015, INT CONF UTIL CLOUD, P227, DOI 10.1109/UCC.2015.39
   Merity S, 2017, Arxiv, DOI arXiv:1708.02182
   Microsoft, 2018, MICR AZ CLOUD COMP P
   Nikravesh AY, 2015, 2015 IEEE/ACM 10TH INTERNATIONAL SYMPOSIUM ON SOFTWARE ENGINEERING FOR ADAPTIVE AND SELF-MANAGING SYSTEMS, P35, DOI 10.1109/SEAMS.2015.22
   Nvidia, 2017, NVIDIA TENSORRT PROG
   Olston C, 2017, Arxiv, DOI arXiv:1712.06139
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   PredictionIO, 2018, US
   Prodan R, 2009, FUTURE GENER COMP SY, V25, P785, DOI 10.1016/j.future.2008.11.002
   Qian Junjie, 2018, MULTITENANT GPU CLUS
   Qu CH, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148149
   Qu CH, 2016, J NETW COMPUT APPL, V65, P167, DOI 10.1016/j.jnca.2016.03.001
   Rajabi A., 2012, 2012 IEEE 20th International Symposium on Modelling, Analysis & Simulation of Computer and Telecommunication Systems (MASCOTS), P107, DOI 10.1109/MASCOTS.2012.22
   RedisML, 2018, US
   Roy Nilabja, 2011, 2011 IEEE 4 INT C CL, P500, DOI DOI 10.1109/CLOUD.2011.42
   Sanders J., 2010, CUDA EXAMPLE INTRO G
   Sharma P, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901319
   Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658
   Shi XJ, 2015, ADV NEUR IN, V28
   Song BB, 2018, J SUPERCOMPUT, V74, P6554, DOI 10.1007/s11227-017-2044-4
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TensorFlow, 2018, TENSORFLOW SERV BATC
   Tu Zhucheng, 2018, P 2018 C N AM CHAPTE, P6, DOI DOI 10.18653/V1/N18-5002
   Urgaonkar B, 2008, ACM T AUTON ADAP SYS, V3, DOI 10.1145/1342171.1342172
   Wang C, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P620, DOI 10.1145/3064176.3064220
   Wang W, 2018, Arxiv, DOI arXiv:1804.06087
   Wei Fang, 2012, 2012 IEEE International Conference on Services Computing (SCC), P609, DOI 10.1109/SCC.2012.47
   Yan F, 2017, IEEE INT CONF CLOUD, P278, DOI 10.1109/CLOUD.2017.43
   Yan F, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P300, DOI 10.1109/SC.2016.25
   Yi J, 2020, POLYM J, V52, P823, DOI 10.1038/s41428-020-0350-9
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang HY, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC '17), P390, DOI 10.1145/3127479.3127490
   Zoph B, 2018, Arxiv, DOI [arXiv:1707.07012, DOI 10.48550/ARXIV.1707.07012]
NR 90
TC 8
Z9 8
U1 1
U2 7
PD JUL-SEP
PY 2022
VL 10
IS 3
BP 1765
EP 1779
DI 10.1109/TCC.2020.3006751
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Cordeiro, AS
   dos Santos, SR
   Moreira, FB
   Santos, PC
   Carro, L
   Alves, MAZ
AF Cordeiro, Aline S.
   dos Santos, Sairo R.
   Moreira, Francis B.
   Santos, Paulo C.
   Carro, Luigi
   Alves, Marco A. Z.
TI Efficient Machine Learning execution with Near-Data Processing
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Near-Data processing; Vector processing; Machine Learning
AB A myriad of Machine Learning (ML) algorithms has emerged as a basis for many applications due to the facility in obtaining satisfactory solutions to a wide range of problems. Programs such as K-Nearest Neighbors (KNN), Multi-layer Perceptron (MLP), and Convolutional Neural Network (CNN) are commonly applied on Artificial Intelligence (AI) to process and analyze the ever-increasing amount of data. Nowadays, multi-core general-purpose systems are adopted due to their high processing capacity. However, energy consumption tends to scale together with the number of used cores. In order to achieve performance and energy efficiency, many Near-Data Processing (NDP) architectures have been proposed mainly tackling data movement reduction by placing computing units as close as possible to the data, such as specific accelerators, full-stack General Purpose Processor (GPP) and Graphics Processing Unit (GPU), and vector units. In this work, we present the benefits of exploring Vector-In-Memory Architecture (VIMA), a general-purpose vector-based NDP architecture for varied ML algorithms. Our work directly compares VIMA and x86 multi-core AVX-512 GPP. The presented approach can overcome the x86 single-core in up to 11.3x while improving energy efficiency by up to 8x. Also, our study shows that nearly 16 cores are necessary to match the NDP's single-thread performance for KNN and MLP algorithms, while it is necessary 32 cores for convolution. Nevertheless, VIMA still overcomes x86 32 cores by 2.1x on average when considering energy results.
C1 [Cordeiro, Aline S.; dos Santos, Sairo R.; Moreira, Francis B.; Alves, Marco A. Z.] Univ Fed Parana, Dept Informat, Curitiba, Parana, Brazil.
   [dos Santos, Sairo R.] Fed Rural Univ Semiarid, Dept Exact Sci & Informat Technol, Angicos, RN, Brazil.
   [Santos, Paulo C.; Carro, Luigi] Univ Fed Rio Grande do Sul, Informat Inst, Porto Alegre, RS, Brazil.
RP Cordeiro, AS (corresponding author), Univ Fed Parana, Dept Informat, Curitiba, Parana, Brazil.
EM ascordeiro@inf.ufpr.br; sairo.santos@ufersa.edu.br; fbm@inf.ufpr.br;
   pcssjunior@inf.ufrgs.br; carro@inf.ufrgs.br; mazalves@inf.ufpr.br
CR Afonso S., 2017, INT C ALG ARCH PAR P
   Ahn J., 2016, ACM SIGARCH COMPUT A, V43
   Alves MAZ, 2016, DES AUT TEST EUROPE, P1249
   Alves MAZ, 2015, IEEE I C EMBED SOFTW, P605, DOI 10.1109/HPCC-CSS-ICESS.2015.166
   AMD, 2015, DDR5 HBM COMP
   Ando K., 2017, J SOLID STATE CIRCUI
   Azarkhish E., 2018, IEEE T PARALL DISTR
   Bishop C.M., 1995, NEURAL NETWORKS PATT
   Boroumand A., 2016, INT C ARCH SUPP PROG
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Cheng M, 2017, DES AUT CON, DOI 10.1145/3061639.3062326
   Chi P., 2016, ACM SIGARCH COMPUT A
   Coorporation I, 2009, INT 64 IA 32 ARCH OP
   Cordeiro A.S., 2017, SIMP SIST COMP ALT D
   Cordeiro AS, 2021, EUROMICRO WORKSHOP P, P212, DOI 10.1109/PDP52278.2021.00041
   de Lima J.P.C., 2019, INT S APPL REC COMP
   Deng Q., 2018, DESIGN AUTOMATION C
   Deng Q., 2019, DESIGN AUTOMATION C
   Dietterich T.G., 2000, INT WORKSHOP MULTIPL
   Drebes A., 2020, PROC 10 INT WORKSHOP
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Elliott D.G., 1999, IEEE DES TEST COMPUT, V16
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Ganguly A, 2018, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS (MEMSYS 2018), P291, DOI 10.1145/3240302.3240427
   Gao D, 2018, 2018 ACM/IEEE INTERNATIONAL WORKSHOP ON SYSTEM LEVEL INTERCONNECT PREDICTION (SLIP), DOI 10.1145/3225209.3225213
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Gron A., 2019, HANDS ON MACHINE LEA, V2nd
   Hashemi M, 2016, CONF PROC INT SYMP C, P444, DOI 10.1109/ISCA.2016.46
   Hennessy J.L., 2014, COMPUTER ORG DESIGN, V4
   Hrusca J., 2015, PIM COMP
   Hybrid Memory Cube Consortium, 2013, HYBRID MEMORY CUBE S
   Hybrid Memory Cube Consortium, 2014, HYBRID MEMORY CUBE S
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee VT, 2018, INT PARALL DISTRIB P, P896, DOI 10.1109/IPDPS.2018.00099
   Lima Joao Paulo, 2018, P COMP FRONT C
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lomont C., 2011, INTRO INTEL ADV VECT
   Long Y, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218737
   Majumdar A, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2133382.2133388
   McDanel B., 2017, EWSN, P168
   Min C., 2019, AS S PAC DES AUT C A
   Mitchell TM, 1997, ENG MATH
   Moore G. E., 1975, 1975 International Electron Devices Meeting. (Technical digest), P11
   Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Oliveira Geraldo F., 2017, INT S APPL REC COMP
   Patterson D., 1997, IEEE MICRO, P17
   Pawlowski J, 2011, HOT CHIPS, V23
   Peterson LE., 2009, SCHOLARPEDIA, V4, P1883, DOI 10.4249/scholarpedia.1883
   Qiu J., 2016, I C FIELD PROG LOGIC
   Qureshi MK, 2007, INT S HIGH PERF COMP, P250
   Qureshi MK, 2007, CONF PROC INT SYMP C, P381, DOI 10.1145/1273440.1250709
   Rakotomamonjy A., 2003, Journal of Machine Learning Research, V3, P1357, DOI 10.1162/153244303322753706
   Ramanathan A.K, 2020, INT S MICR MICRO 202
   Russell Stuart, 1995, ARTIF INTELL
   Santos PC, 2018, DES AUT TEST EUROPE, P897, DOI 10.23919/DATE.2018.8342135
   Santos PC, 2017, DES AUT TEST EUROPE, P710, DOI 10.23919/DATE.2017.7927081
   Saulsbury A, 1996, 23RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, PROCEEDINGS, P90, DOI 10.1145/232974.232984
   Schuiki F., 2018, ARXIV 180304783
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Sim J, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240831
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Sudarshan C, 2019, IEEE INT SYMP CIRC S
   Thottethodi M., 2018, INT PAR DISTR PROC S
   Tian Y., P 40 INT C SOFTWARE, P303
   Transcend, 2014, DDR COMP
   Van Olmen J, 2008, INT EL DEVICES MEET, P603
   Wang X., 2019, INT S HIGH PERFORMAN
   Wulf W.A., 1995, ACM SIGARCH COMPUT A, V23
   Xu L., 2015, WORKSH NEAR DAT PROC
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
   Yin S., 2019, IEEE T VLSI SYST
NR 80
TC 2
Z9 2
U1 1
U2 7
PD APR
PY 2022
VL 90
AR 104435
DI 10.1016/j.micpro.2022.104435
EA FEB 2022
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shea, C
   Page, A
   Mohsenin, T
AF Shea, Colin
   Page, Adam
   Mohsenin, Tinoosh
GP ACM
TI SCALENet: A SCalable Low power AccELerator for Real-time Embedded Deep
   Neural Networks
SO PROCEEDINGS OF THE 2018 GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI'18)
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 23-25, 2018
CL Chicago, IL
DE Lowpower; programmable hardware accelerator; convolutional neural
   network; machine learning; FPGA; scalable; embedded systems
AB As deep learning networks mature and improve classification performance, a significant challenge is their deployment in embedded settings. Modern network typologies, such as convolutional neural networks, can be very deep and impose considerable complexity that is often not feasible in resource bound, real-time systems. Processing of these networks requires high levels of parallelization, maximizing data throughput, and support for different network types, while minimizing power and resource consumption. In response to these requirements, in this paper, we present a low power FPGA based neural network accelerator named SCALENet: a SCalable Low power AccELerator for real-time deep neural Networks. Key features include optimization for power with coarse and fine grain scheduler, implementation flexibility with hardware only or hardware/software co-design, and acceleration for both fully connected and convolutional layers. The experimental results evaluate SCALENet against two different neural network applications: image processing, and biomedical seizure detection. The image processing networks, implemented on SCALENet, trained on the CIFAR-10 and ImageNet datasets with eight different networks, are implemented on an Arty A7 and Zedboard (TM) FPGA platforms. The highest improvement came with the Inception network on an ImageNet dataset with a throughput of 22x and decrease in energy consumption of 13x compared to the ARM processor implementation. We then implement SCALENet for time series EEG seizure detection using both a Direct Convolution and FFT Convolution method to show its design versatility with a 99.7% reduction in execution time and a 97.9% improvement in energy consumption compared to the ARM. Finally, we demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU System on Chip (SoC) and with a 4x power savings in a power envelope of 2.07 Watts.
C1 [Shea, Colin; Page, Adam; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA.
RP Shea, C (corresponding author), Univ Maryland Baltimore Cty, Baltimore, MD 21228 USA.
EM cshea3@umbc.edu; apage2@umbc.edu; tinoosh@umbc.edu
CR Abtahi T., 2017, 2017 IEEE INT S CIRC, P1
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   [Anonymous], POW METH GUID
   [Anonymous], CVPRW
   [Anonymous], 2016, SQUEEZENET ALEXNET L
   [Anonymous], FPGA FPGA 15
   [Anonymous], IEEE T VERY LARGE SC
   [Anonymous], ISCAS
   [Anonymous], COMPUTER METHODS PRO
   [Anonymous], FCCM
   [Anonymous], 2016, ISSCC
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Sim J., 2016, ISSCC
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song L., 2016, P 53 ANN DES AUT C D
NR 16
TC 7
Z9 7
U1 0
U2 5
PY 2018
BP 129
EP 134
DI 10.1145/3194554.3194601
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ayele, WY
   Juell-Skielse, G
AF Ayele, Workneh Y.
   Juell-Skielse, Gustaf
BE Ko, A
   Francesconi, E
   Kotsis, G
   Tjoa, AM
   Khalil, I
TI A Process Model for Generating and Evaluating Ideas: The Use of Machine
   Learning and Visual Analytics to Support Idea Mining
SO ELECTRONIC GOVERNMENT AND THE INFORMATION SYSTEMS PERSPECTIVE, EGOVIS
   2020
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 9th International Conference on Electronic Government and the
   Information Systems Perspective (EGOVIS)
CY SEP 14-17, 2020
CL ELECTR NETWORK
DE Idea mining; Idea generation; Idea evaluation; Text mining; Machine
   learning; Dynamic topic modeling
AB The significance and possibilities of idea generation and evaluation are increasing due to the increasing demands for digital innovation and the abundance of textual data. Textual data such as social media, publications, patents, documents, etc. are used to generate ideas, yet manual analysis is affected by bias and subjectivity. Machine learning and visual analytics tools could be used to support idea generation and evaluation, referred to as idea mining, to unlock the potential of voluminous textual data. Idea mining is applied to support the extraction of useful information from textual data. However, existing literature merely focuses on the outcome and overlooks structuring and standardizing the process itself. In this paper, to support idea mining, we designed a model following design science research, which overlaps with the Cross-Industry-Standard-Process for Data Mining (CRISP-DM) process and adapts well-established models for technology scouting. The proposed model separates the duties of actors in idea mining into two layers. The first layer presents the business layer, where tasks performed by technology scouts, incubators, accelerators, consultants, and contest managers are detailed. The second layer presents the technical layer where tasks performed by data scientists, data engineers, and similar experts are detailed overlapping with CRISP-DM. For future research, we suggest an ex-post evaluation and customization of the model to other techniques of idea mining.
C1 [Ayele, Workneh Y.; Juell-Skielse, Gustaf] Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
RP Ayele, WY (corresponding author), Stockholm Univ, Dept Comp & Syst Sci, Stockholm, Sweden.
CR Aggarwal V., 2018, 39 INT C INF SYST
   Aghaei Chadegani A., 2013, ASIAN SOC SCI, V9, P18, DOI DOI 10.5539/ASS.V9N5P18
   Alksher MA, 2016, INT CONF INFORM RETR, P88, DOI 10.1109/INFRKM.2016.7806341
   Alksher MA, 2017, FRONT ARTIF INTEL AP, V297, P550, DOI 10.3233/978-1-61499-800-6-550
   AlSumait L, 2008, IEEE DATA MINING, P3, DOI 10.1109/ICDM.2008.140
   [Anonymous], 2017, ARE IDEAS GETTING HA
   Asamoah D.A., 2015, ADAPTING CRISP DM PR
   Ayele Workneh Y., 2020, Advances in Information and Communication. Proceedings of the 2020 Future of Information and Communication Conference (FICC). Advances in Intelligent Systems and Computing (AISC 1129), P488, DOI 10.1007/978-3-030-39445-5_37
   Ayele WY, 2020, INT J ADV COMPUT SC, V11, P20
   Ayele WY., 2019, CVC 2019, V2019, P355
   Bird S., 2009, NATURAL LANGUAGE PRO
   Björk J, 2009, J PROD INNOVAT MANAG, V26, P662, DOI 10.1111/j.1540-5885.2009.00691.x
   Blei D.M., 2009, TEXT MINING THEORY A, P101, DOI [10.1145/1143844.1143859, DOI 10.1201/9781420059458.CH4]
   Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Blei DM, 2006, INT C MACHINE LEARNI, P113, DOI 10.1145/1143844.1143859
   Braun V., 2006, QUAL RES PSYCHOL, V3, P77, DOI [DOI 10.1191/1478088706QP063OA, 10.1191/1478088706qp063oa]
   Brijs K, 2017, CEREAL FOOD WORLD, V62, P264, DOI 10.1094/CFW-62-6-0264
   Chen CM, 2012, EXPERT OPIN BIOL TH, V12, P593, DOI 10.1517/14712598.2012.674507
   Dean DL, 2006, J ASSOC INF SYST, V7, P646, DOI 10.17705/1jais.00106
   Debortoli S, 2016, COMMUN ASSOC INF SYS, V39, P110, DOI 10.17705/1CAIS.03907
   Dellermann D., 2018, MULTIKONFERENZ WIRTS
   Feldman R., 2007, TEXT MINING HDB ADV
   Hope T, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P5274
   Hope T, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P235, DOI 10.1145/3097983.3098038
   Hu X., 2012, MINING TEXT DATA, P385, DOI DOI 10.1007/978-1-4614-3223-4
   Kao S.C., 2018, 5 MISNC
   Keim D, 2008, LECT NOTES COMPUT SC, V4950, P154, DOI 10.1007/978-3-540-70956-5
   Kornish LJ, 2017, PROD OPER MANAG, V26, P633, DOI 10.1111/poms.12664
   Kruse P., 2013, AMCIS
   Liu HX, 2015, LECT NOTES ARTIF INT, V9285, P541, DOI 10.1007/978-3-319-23525-7_33
   McIntosh T, 2021, PSYCHOL AESTHET CREA, V15, P111, DOI 10.1037/aca0000237
   Ogawa T, 2017, TECHNOL FORECAST SOC, V120, P41, DOI 10.1016/j.techfore.2017.04.004
   Peffers K, 2007, J MANAGE INFORM SYST, V24, P45, DOI 10.2753/MIS0742-1222240302
   Puccio GJ, 2012, HANDBOOK OF ORGANIZATIONAL CREATIVITY, P189, DOI 10.1016/B978-0-12-374714-3.00009-4
   Rhyn M, 2017, P 38 INT C INF SYST
   Rohrbeck R., 2007, ISPIM AS C
   Rohrbeck R., 2014, MANAGEMENT FUZZY FRO, P59, DOI [DOI 10.1007/978-3-319-01056-4, DOI 10.1007/978-3-319-01056-4_5]
   Saaty T.L., 2012, MODELS METHODS CONCE, V175, DOI [10.1007/978-1-4614-3597-6, DOI 10.1007/978-1-4614-3597-6]
   Salatino AA, 2018, ACM-IEEE J CONF DIG, P303, DOI 10.1145/3197026.3197052
   Sandberg AB, 2017, 2017 IEEE/ACM 39TH INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING: SOFTWARE ENGINEERING IN PRACTICE TRACK (ICSE-SEIP 2017), P73, DOI 10.1109/ICSE-SEIP.2017.20
   Sidorov G, 2014, EXPERT SYST APPL, V41, P853, DOI 10.1016/j.eswa.2013.08.015
   Small H, 2014, RES POLICY, V43, P1450, DOI 10.1016/j.respol.2014.02.005
   Smith GF, 1998, J CREATIVE BEHAV, V32, P107, DOI 10.1002/j.2162-6057.1998.tb00810.x
   Steingrimsson B., 2018, SAE TECHNICAL PAPER
   Stevanovic M., 2015, DS 80 8 P 20 INT C E, V80, P193
   Thorleuchter D, 2015, FUTURES, V66, P25, DOI 10.1016/j.futures.2014.12.007
   Thorleuchter D, 2010, EXPERT SYST APPL, V37, P7182, DOI 10.1016/j.eswa.2010.04.013
   Wirth R., 2000, Proceedings of the Fourth International Conference on the Practical Application of Knowledge Discovery and Data Mining, P29
   You HL, 2017, SCIENTOMETRICS, V111, P297, DOI 10.1007/s11192-017-2252-y
   Yusuff R., 2010, INT J INNOV MANAG, V1, P511, DOI DOI 10.7763/IJIMT.2010.V1.89
NR 51
TC 0
Z9 0
U1 0
U2 2
PY 2020
VL 12394
BP 189
EP 203
DI 10.1007/978-3-030-58957-8_14
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods;
   Information Science & Library Science; Public Administration
DA 2023-11-11
ER

PT C
AU Rao, N
   Ramachandran, A
   Shah, A
AF Rao, Nishant
   Ramachandran, Akshay
   Shah, Amish
GP IEEE
TI MLNoC: A Machine Learning based approach to NoC design
SO 2018 30TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH
   PERFORMANCE COMPUTING (SBAC-PAD 2018)
SE International Symposium on Computer Architecture and High Performance
   Computing
DT Proceedings Paper
CT 30th International Symposium on Computer Architecture and High
   Performance Computing (SBAC-PAD)
CY SEP 24-27, 2018
CL Lyon, FRANCE
DE Network-on-chip; Machine learning; Interconnect; System-on-Chip;
   Architecture
AB Modern System on Chips (SoCs) are becoming increasingly complex with a growing number of CPUs, caches, accelerators, memory and I/O subsystems. For such designs, a packet based distributed networks-on-chip (NoCs) interconnect can provide scalability, performance and efficiency. However, the design of such a NoC involves optimizing a large number of variables such as topology, routing choices, arbitration and quality of service (QoS) policies, buffer sizes, and deadlock avoidance policies. Widely varying die sizes, power, floorplan and performance constraints across a variety of different market segments, ranging from high-end servers to low-end IoT devices, impose additional design challenges.
   In this paper we demonstrate that there is a strong correlation between SoC characteristics and good NoC design practices. However this correlation is highly non-linear and multidimensional, with dimensions indicative of the features of the SoC, design goals and properties of the NoC. This results in a high-dimensional NoC design space and complex search process which is inefficient to solve with classic algorithms. Using a variety of real SoCs and training data sets, we demonstrate that a machine learning (ML) based approach yields near-optimal NoC designs quickly. We determine a number of SoC and NoC features, describe reduction methods, and also show that a multi-model approach yields better designs. We demonstrate that for a wide variety of SoCs, ML based NoC designs are far superior to those designed and optimized manually over years on almost all quality metrics.
C1 [Rao, Nishant; Ramachandran, Akshay; Shah, Amish] NetSpeed Syst, San Jose, CA 95134 USA.
RP Rao, N (corresponding author), NetSpeed Syst, San Jose, CA 95134 USA.
EM nishant@netspeedsystems.com; akshay@netspeedsystems.com;
   amish@netspeedsystems.com
CR Abd El ghany M.A, 2009, ICECS
   Anirudh G.S., 2017, INIS
   [Anonymous], 2009, MICRO
   [Anonymous], P 3 INT
   [Anonymous], DES AUT C
   Benini L, 2002, COMPUTER, V35, P70, DOI 10.1109/2.976921
   Bertozzi D, 2007, VLSI DES, DOI 10.1155/2007/26454
   Bottou L., 1994, P 12 IAPR INT C PATT
   Bykov S.O., 2013, E W DES TEST S
   Dai J., 2017, MCSOC
   Ho TK, 1998, IEEE T PATTERN ANAL, V20, P832, DOI 10.1109/34.709601
   HO TK, 1994, IEEE T PATTERN ANAL, V16, P66, DOI 10.1109/34.273716
   Huang Y.S., 1994, P 12 IAPR INT C PATT
   Khichar J., 2017, I2C2
   Leary G., 2009, P 7 INT C HARDW SOFT
   Mitra S., 1995, IEEE T SYSTEMS MAN C, V24
   Offori-Attah E., 2017, COMP C
   PEDRYCZ W, 1992, IEEE T NEURAL NETWOR, V3, P770, DOI 10.1109/72.159065
   Rajamanikkam C., 2016, ICCAD
   Sahu S., 2013, ICT
   Sariga S., 2017, ICEICE
   Simunic T., 2002, P DES AUT TEST EUR C
   Sun J., 2017, PIC
   Touati H.C., 2017, EDIS
   Udipi A. N., 2010, HPCA
   Uebele V., 1995, IEEE T SYSTEMS MAN C, V25
   Yang B., 2010, DDECS
   Yoon Y. J, 2017, NOCS
NR 28
TC 12
Z9 12
U1 0
U2 3
PY 2018
BP 1
EP 8
DI 10.1109/SBAC-PAD.2018.00015
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU de Aguiar, ASP
   dos Santos, FBN
   dos Santos, LCF
   Filipe, VMD
   de Sousa, AJM
AF Pinto de Aguiar, Andre Silva
   Neves dos Santos, Filipe Baptista
   Feliz dos Santos, Luis Carlos
   de Jesus Filipe, Vitor Manuel
   Miranda de Sousa, Armando Jorge
TI Vineyard trunk detection using deep learning - An experimental device
   benchmark
SO COMPUTERS AND ELECTRONICS IN AGRICULTURE
DT Article
DE Deep learning; Object detection; Agricultural robots
ID NEURAL-NETWORKS; AGRICULTURE
AB Research and development in mobile robotics are continuously growing. The ability of a human-made machine to navigate safely in a given environment is a challenging task. In agricultural environments, robot navigation can achieve high levels of complexity due to the harsh conditions that they present. Thus, the presence of a reliable map where the robot can localize itself is crucial, and feature extraction becomes a vital step of the navigation process. In this work, the feature extraction issue in the vineyard context is solved using Deep Learning to detect high-level features - the vine trunks. An experimental performance benchmark between two devices is performed: NVIDIA's Jetson Nano and Google's USB Accelerator. Several models were retrained and deployed on both devices, using a Transfer Learning approach. Specifically, MobileNets, Inception, and lite version of You Only Look Once are used to detect vine trunks in real-time. The models were retrained in a built in-house dataset, that is publicly available. The training dataset contains approximately 1600 annotated vine trunks in 336 different images. Results show that NVIDIA's Jetson Nano provides compatibility with a wider variety of Deep Learning architectures, while Google's USB Accelerator is limited to a unique family of architectures to perform object detection. On the other hand, the Google device showed an overall Average precision higher than Jetson Nano, with a better runtime performance. The best result obtained in this work was an average precision of 52.98% with a runtime performance of 23.14 ms per image, for MobileNet-V2. Recent experiments showed that the detectors are suitable for the use in the Localization and Mapping context.
C1 [Pinto de Aguiar, Andre Silva; Neves dos Santos, Filipe Baptista; Feliz dos Santos, Luis Carlos; de Jesus Filipe, Vitor Manuel; Miranda de Sousa, Armando Jorge] INESC TEC INESC Technol & Sci, P-4200465 Porto, Portugal.
   [Pinto de Aguiar, Andre Silva; Feliz dos Santos, Luis Carlos; de Jesus Filipe, Vitor Manuel] Univ Tras Os Montes & Alto Douro, Sch Sci & Technol, P-5000801 Vila Real, Portugal.
   [Miranda de Sousa, Armando Jorge] Univ Porto, Fac Engn, P-4200465 Porto, Portugal.
RP de Aguiar, ASP (corresponding author), INESC TEC INESC Technol & Sci, P-4200465 Porto, Portugal.; de Aguiar, ASP (corresponding author), Univ Tras Os Montes & Alto Douro, Sch Sci & Technol, P-5000801 Vila Real, Portugal.
EM andre.s.aguiar@inesctec.pt; fbsantos@inectec.pt;
   luis.c.santos@inesctec.pt; vfilipe@utad.pt; asousa@fe.up.pt
CR Aguiar A, 2019, LECT NOTES ARTIF INT, V11805, P319, DOI 10.1007/978-3-030-30244-3_27
   Andresen T, 2004, LANDSCAPE URBAN PLAN, V68, P289, DOI 10.1016/S0169-2046(03)00156-7
   Cheein FA, 2011, COMPUT ELECTRON AGR, V78, P195, DOI 10.1016/j.compag.2011.07.007
   Bai YT, 2019, COMPLEXITY, V2019, DOI 10.1155/2019/9107167
   Bargoti Suchet, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3626, DOI 10.1109/ICRA.2017.7989417
   Dai JF, 2016, ADV NEUR IN, V29
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dias PA, 2018, COMPUT IND, V99, P17, DOI 10.1016/j.compind.2018.03.010
   Ding WG, 2016, COMPUT ELECTRON AGR, V123, P17, DOI 10.1016/j.compag.2016.02.003
   dos Santos FN, 2016, J INTELL ROBOT SYST, V83, P429, DOI 10.1007/s10846-016-0340-5
   dos Santos FN, 2015, IEEE INT CONF AUTON, P37, DOI 10.1109/ICARSC.2015.21
   Duckett T., 2018, AGR ROBOTICS FUTURE
   Everingham M, 2010, INT J COMPUT VISION, V88, P303, DOI 10.1007/s11263-009-0275-4
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google, 2020, USB ACC
   He K., 2017, P IEEE INT C COMPUTE, DOI 10.1109/ICCV.2017.322
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jin P., 2018, ARXIV180703284
   Jin XB, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8020214
   Kamilaris A, 2018, J AGR SCI-CAMBRIDGE, V156, P312, DOI 10.1017/S0021859618000436
   Kamilaris A, 2018, COMPUT ELECTRON AGR, V147, P70, DOI 10.1016/j.compag.2018.02.016
   Kirk R, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010275
   Koirala A, 2019, PRECIS AGRIC, V20, P1107, DOI 10.1007/s11119-019-09642-0
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W., ABS151202325 CORR
   Lu J, 2015, KNOWL-BASED SYST, V80, P14, DOI 10.1016/j.knosys.2015.01.010
   NVIDIA Corporation, 2020, JETS NAN DEV KIT
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Qin JC, 2018, J SENSORS, V2018, DOI 10.1155/2018/6908760
   Redmon J., 2018, TECH REPORT, P1
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Redmon Joseph Chet, 2020, YOLO REAL TIME OBJEC
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Roldan J.J., 2018, SERV ROBOT, DOI [10.5772/intechopen.69874, DOI 10.5772/INTECHOPEN.69874]
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sa I, 2016, SENSORS-BASEL, V16, DOI 10.3390/s16081222
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Santos L, 2020, ADV INTELL SYST COMP, V1092, P139, DOI 10.1007/978-3-030-35990-4_12
   Santos L, 2020, ROBOTICA, V38, P684, DOI 10.1017/S0263574719000961
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Shao L, 2015, IEEE T NEUR NET LEAR, V26, P1019, DOI 10.1109/TNNLS.2014.2330900
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Steen KA, 2016, J IMAGING, V2, DOI 10.3390/jimaging2010006
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tian YN, 2019, COMPUT ELECTRON AGR, V157, P417, DOI 10.1016/j.compag.2019.01.012
   Torrey L., 2010, HDB RES MACHINE LEAR, DOI [10.4018/978-1-60566-766-9.ch011., DOI 10.4018/978-1-60566-766-9.CH011]
   Weiss Karl, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0043-6
   Zhao Z Q, 2019, IEEE T NEUR NET LEAR, V30, P3212, DOI [DOI 10.1109/TNNLS.2018.2876865, 10.11091NNES.2018.2876865.]
   Zheng YY, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051058
NR 52
TC 36
Z9 36
U1 5
U2 35
PD AUG
PY 2020
VL 175
AR 105535
DI 10.1016/j.compag.2020.105535
WC Agriculture, Multidisciplinary; Computer Science, Interdisciplinary
   Applications
DA 2023-11-11
ER

PT C
AU Stevens, JR
   Ranjan, A
   Das, D
   Kaul, B
   Raghunathan, A
AF Stevens, Jacob R.
   Ranjan, Ashish
   Das, Dipankar
   Kaul, Bharat
   Raghunathan, Anand
GP Assoc Comp Machinery
TI Manna: An Accelerator for Memory-Augmented Neural Networks
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE Memory Networks; Memory-Augmented Neural Networks; Hardware
   Accelerators; System Architecture
AB Memory-augmented neural networks (MANNs)- which augment a traditional Deep Neural Network (DNN) with an external, differentiable memory- are emerging as a promising direction in machine learning. MANNs have been shown to achieve one-shot learning and complex cognitive capabilities that are well beyond those of classical DNNs. We analyze the computational characteristics of MANNs and observe that they present a unique challenge due to soft reads and writes to the differentiable memory, each of which requires access to all the memory locations. This results in poor performance of MANNs on modern CPUs, GPUs, and other accelerators. To address this, we present Manna, a specialized hardware inference accelerator for MANNs. Manna is a memory-centric design that focuses on maximizing performance in an extremely low FLOPS/Byte context. The key architectural features from which Manna derives efficiency are: (i) investing most of the die area and power in highly banked on-chip memories that provide ample bandwidth rather than large matrix-multiply units that would be underutilized due to the low reuse (ii) a hardware-assisted transpose mechanism for accommodating the diverse memory access patterns observed in MANNs, (iii) a specialized processing tile that is equipped to handle the nearly-equal mix of MAC and non-MAC computations present in MANNs, and (iv) methods to map MANNs to Manna that minimize data movement while fully exploiting the little reuse present. We evaluate Manna by developing a detailed architectural simulator with timing and power models calibrated by synthesis to the 15 nm Nangate Open Cell library. Across a suite of 10 benchmarks, Manna demonstrates average speedups of 39x with average energy improvements of 122x over an NVIDIA 1080-Ti Pascal GPU and average speedups of 24x with average energy improvements of 86x over a state-of-the-art NVIDIA 2080-Ti Turing GPU.
C1 [Stevens, Jacob R.; Ranjan, Ashish; Raghunathan, Anand] Purdue Univ, Sch ECE, W Lafayette, IN 47907 USA.
   [Das, Dipankar; Kaul, Bharat] Intel Corp, Parallel Comp Lab, Santa Clara, CA 95051 USA.
RP Stevens, JR (corresponding author), Purdue Univ, Sch ECE, W Lafayette, IN 47907 USA.
EM steven69@purdue.edu; aranjan@purdue.edu; dipankar.das@intel.com;
   bharat.kaul@intel.com; raghunathan@purdue.edu
CR [Anonymous], 2013, INT CONF ACOUST SPEE, DOI 10.1109/ICASSP.2013.6638947
   [Anonymous], HIGH BANDW MEM REINV
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chang Andre Xian Ming, 2017, P INT S CIRC SYST IS
   Chang Andre Xian Ming, 2015, ARXIV151105552
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y.-H., 2018, ARXIV180707928
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cho K, 2014, ARXIV, DOI [10.3115/v1/w14-4012, DOI 10.3115/V1/W14-4012]
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Gokhale V., 2017, ARXIV170802579
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A., 2014, NEURAL TURING MACHIN, DOI DOI 10.3389/NEUR0.12.006.2007
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Grefenstette E, 2015, ADV NEUR IN, V28
   Han S., 2015, ARXIV151000149
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hannun A., 2014, DEEP SPEECH SCALING
   He K., 2016, P IEEE C COMPUTER VI
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kumar A, 2016, PR MACH LEARN RES, V48
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Li Sicheng, 2015, P INT S FIELD PROGR
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Park S, 2019, DES AUT TEST EUROPE, P1587, DOI [10.23919/date.2019.8715013, 10.23919/DATE.2019.8715013]
   Ranjan A, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317935
   Ruetsch Greg, 2009, 18 NIV CUDA SDK
   Sharma H., 2018, 2018 ACM IEEE 45 ANN
   Sukhbaatar S, 2015, ADV NEUR IN, V28
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Wayne G, 2018, UNSUPERVISED PREDICT
   Weston Jason, 2014, ARXIV14103916
   Wu, 2016, ARXIV160908144
   Xiong CM, 2016, PR MACH LEARN RES, V48
   Yeh TT, 2017, ACM SIGPLAN NOTICES, V52, P221, DOI [10.1145/3155284.3018754, 10.1145/3018743.3018754]
   Zhang X., 2015, ARXIV150201710
NR 41
TC 13
Z9 13
U1 2
U2 7
PY 2019
BP 794
EP 806
DI 10.1145/3352460.3358304
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Fang, SD
   Du, ZD
   Fang, YT
   Huang, YJ
   Chen, Y
   Eeckhout, L
   Temam, O
   Li, HW
   Chen, YJ
   Wu, CY
AF Fang, Shuangde
   Du, Zidong
   Fang, Yuntan
   Huang, Yuanjie
   Chen, Yang
   Eeckhout, Lieven
   Temam, Olivier
   Li, Huawei
   Chen, Yunji
   Wu, Chengyong
TI Performance Portability Across Heterogeneous SoCs Using a Generalized
   Library-Based Approach
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Design; Performance; Languages; Experimentation; SoC; heterogeneity;
   performance portability; library-based programming; approximate
   computing
ID COMPONENT-BASED DESIGN; POWER; LANGUAGE; MODEL
AB Because of tight power and energy constraints, industry is progressively shifting toward heterogeneous system-on-chip (SoC) architectures composed of a mix of general-purpose cores along with a number of accelerators. However, such SoC architectures can be very challenging to efficiently program for the vast majority of programmers, due to numerous programming approaches and languages. Libraries, on the other hand, provide a simple way to let programmers take advantage of complex architectures, which does not require programmers to acquire new accelerator-specific or domain-specific languages. Increasingly, library-based, also called algorithm-centric, programming approaches propose to generalize the usage of libraries and to compose programs around these libraries, instead of using libraries as mere complements.
   In this article, we present a software framework for achieving performance portability by leveraging a generalized library-based approach. Inspired by the notion of a component, as employed in software engineering and HW/SW codesign, we advocate nonexpert programmers to write simple wrapper code around existing libraries to provide simple but necessary semantic information to the runtime. To achieve performance portability, the runtime employs machine learning (simulated annealing) to select the most appropriate accelerator and its parameters for a given algorithm. This selection factors in the possibly complex composition of algorithms used in the application, the communication among the various accelerators, and the tradeoff between different objectives (i.e., accuracy, performance, and energy).
   Using a set of benchmarks run on a real heterogeneous SoC composed of a multicore processor and a GPU, we show that the runtime overhead is fairly small at 5.1% for the GPU and 6.4% for the multi-core. We then apply our accelerator selection approach to a simulated SoC platform containing multiple inexact accelerators. We show that accelerator selection together with hardware parameter tuning achieves an average 46.2% energy reduction and a speedup of 2.1 x while meeting the desired application error target.
C1 [Fang, Shuangde; Du, Zidong; Fang, Yuntan; Huang, Yuanjie; Li, Huawei; Chen, Yunji; Wu, Chengyong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Chen, Yunji] Microsoft Res, Beijing, Peoples R China.
   [Eeckhout, Lieven] Univ Ghent, Dept Elect & Informat Syst, B-9000 Ghent, Belgium.
   [Temam, Olivier] INRIA, Saclay, France.
   [Fang, Shuangde; Du, Zidong; Fang, Yuntan; Huang, Yuanjie; Li, Huawei; Chen, Yunji; Wu, Chengyong] Chinese Acad Sci, ICT, SKL Comp Architecture, Beijing, Peoples R China.
   [Fang, Shuangde; Du, Zidong; Fang, Yuntan; Huang, Yuanjie] Chinese Acad Sci, Grad Sch, Beijing, Peoples R China.
RP Fang, SD (corresponding author), Chinese Acad Sci, Inst Comp Technol, 6 Kexueyuan South Rd, Beijing, Peoples R China.
EM fangshuangde@ict.ac.cn
CR Agarwal Anant, 2009, TECHNICAL REPORT
   Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Amigó E, 2009, INFORM RETRIEVAL, V12, P461, DOI 10.1007/s10791-008-9066-8
   [Anonymous], 2012, P 17 C EL POW DISTR
   [Anonymous], 2009, ENG MECH
   [Anonymous], 2009, TECHNICAL REPORT
   [Anonymous], P C PAR DISTR COMP S
   [Anonymous], P 39 ANN INT S COMP
   [Anonymous], P LOS AL COMP SCI I
   [Anonymous], P ACM IEEE C SUP SC
   [Anonymous], 2007, GPGPU WORKSHOP OCTOB
   [Anonymous], PROGRAMMING MODELS E
   [Anonymous], P 3 INT C SOFTW ENG
   [Anonymous], 2008, CASES
   [Anonymous], INTEL64 IA 32 ARCH S
   [Anonymous], 2011, DESIGN AUTOMATION TE
   Ansel J, 2011, INT SYM CODE GENER, P85, DOI 10.1109/CGO.2011.5764677
   Ansel J, 2009, ACM SIGPLAN NOTICES, V44, P38, DOI 10.1145/1543135.1542481
   Arató P, 2005, SCI COMPUT PROGRAM, V56, P23, DOI 10.1016/j.scico.2004.11.003
   Augonnet C, 2009, LECT NOTES COMPUT SC, V5704, P863, DOI 10.1007/978-3-642-03869-3_80
   Barba FRJ, 2007, P IEEE RAP SYST PROT, P17
   Becchi M, 2010, SPAA '10: PROCEEDINGS OF THE TWENTY-SECOND ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P82
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Brown KM, 2011, NOBLE POWER IN SCOTLAND FROM THE REFORMATION TO THE REVOLUTION, P89
   Carter NP, 2013, INT S HIGH PERF COMP, P198, DOI 10.1109/HPCA.2013.6522319
   Cesário W, 2002, DES AUT CON, P789, DOI 10.1109/DAC.2002.1012730
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen Y, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P49
   Cheung PH, 2007, DSD 2007: 10TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN ARCHITECTURES, METHODS AND TOOLS, PROCEEDINGS, P265, DOI 10.1109/DSD.2007.4341479
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   de Kruijf M, 2010, CONF PROC INT SYMP C, P497, DOI 10.1145/1816038.1816026
   Diamos Gregory F., 2008, P 17 INT S HIGH PERF, P197, DOI DOI 10.1145/1383422.1383447
   Dubach C, 2012, ACM SIGPLAN NOTICES, V47, P1, DOI 10.1145/2345156.2254066
   Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Grewe D., 2013, P IEEEACM INT S CODE, P1
   Heineman George T., 2001, COMPONENT BASED SOFT
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Hong S, 2010, CONF PROC INT SYMP C, P280, DOI 10.1145/1816038.1815998
   Huang Y., 2013, FPGA, P171
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Kahng AB, 2009, DES AUT TEST EUROPE, P423
   KALE LV, 1993, SIGPLAN NOTICES, V28, P91, DOI 10.1145/167962.165874
   Kessler C, 2012, DES AUT TEST EUROPE, P1403
   Lee SH, 2010, IUTAM BOOKSER, V22, P1, DOI [10.1073/pnas.1003572107, 10.1007/978-90-481-9631-9_1]
   Li HJ, 2012, IEEE MICRO, V32, P54, DOI 10.1109/MM.2012.53
   Lin FX, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P13
   Linderman MD, 2008, ACM SIGPLAN NOTICES, V43, P287, DOI 10.1145/1353536.1346318
   Lu K, 2012, DES AUT TEST EUROPE, P135
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Maggio M, 2013, IEEE T CONTR SYST T, V21, P239, DOI 10.1109/TCST.2011.2177499
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Misailovic S., 2010, P 32 ACMIEEE INT C S, V1, P25, DOI DOI 10.1145/1806799.1806808
   Phothilimthana PM, 2013, ACM SIGPLAN NOTICES, V48, P431, DOI 10.1145/2499368.2451162
   Rinard M., 2006, P 20 ANN INT C SUPER, P324
   Roop P. S., 2000, VLSI Design 2000. Wireless and Digital Imaging in the Millennium. Proceedings of 13th International Conference on VLSI Design, P64, DOI 10.1109/ICVD.2000.812586
   Sampson A, 2011, ACM SIGPLAN NOTICES, V46, P164, DOI 10.1145/1993316.1993518
   Sgroi M, 2001, DES AUT CON, P667, DOI 10.1109/DAC.2001.935591
   Sidelnik A, 2012, INT PARALL DISTRIB P, P582, DOI 10.1109/IPDPS.2012.60
   Sorber J, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P161
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Zhang T, 2001, DESIGN, AUTOMATION AND TEST IN EUROPE, CONFERENCE AND EXHIBITION 2001, PROCEEDINGS, P40, DOI 10.1109/DATE.2001.914999
NR 62
TC 2
Z9 2
U1 1
U2 11
PD JUN
PY 2014
VL 11
IS 2
BP 165
EP 189
DI 10.1145/2608253
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Lestyán, S
   Acs, G
   Biczók, G
   Szalay, Z
AF Lestyan, Szilvia
   Acs, Gergely
   Biczok, Gergely
   Szalay, Zsolt
BE Mori, P
   Furnell, S
   Camp, O
TI Extracting Vehicle Sensor Signals from CAN Logs for Driver
   Re-identification
SO PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON INFORMATION SYSTEMS
   SECURITY AND PRIVACY (ICISSP)
DT Proceedings Paper
CT 5th International Conference on Information Systems Security and Privacy
   (ICISSP)
CY FEB 23-25, 2019
CL Prague, CZECH REPUBLIC
DE Driver Re-identification; CAN Bus; Sensor Signals; Privacy; Reverse
   Engineering; Machine Learning; Time Series Data
AB Data is the new oil for the car industry. Cars generate data about how they are used and who's behind the wheel which gives rise to a novel way of profiling individuals. Several prior works have successfully demonstrated the feasibility of driver re-identification using the in-vehicle network data captured on the vehicle's CAN (Controller Area Network) bus. However, all of them used signals (e.g., velocity, brake pedal or accelerator position) that have already been extracted from the CAN log which is itself not a straightforward process. Indeed, car manufacturers intentionally do not reveal the exact signal location within CAN logs. Nevertheless, we show that signals can be efficiently extracted from CAN logs using machine learning techniques. We exploit that signals have several distinguishing statistical features which can be learnt and effectively used to identify them across different vehicles, that is, to quasi "reverse-engineer" the CAN protocol. We also demonstrate that the extracted signals can be successfully used to re-identify individuals in a dataset of 33 drivers. Therefore, not revealing signal locations in CAN logs per se does not prevent them to be regarded as personal data of drivers.
C1 [Lestyan, Szilvia; Acs, Gergely; Biczok, Gergely] Budapest Univ Technol & Econ, Dept Networked Syst & Serv, CrySyS Lab, Budapest, Hungary.
   [Szalay, Zsolt] Budapest Univ Technol & Econ, Dept Automot Technol, Budapest, Hungary.
RP Lestyán, S (corresponding author), Budapest Univ Technol & Econ, Dept Networked Syst & Serv, CrySyS Lab, Budapest, Hungary.
CR Enev M., 2016, P PRIVACY ENHANCING, V2016, P34, DOI DOI 10.1515/POPETS-2015-0029
   Fugiglando U., 2018, IEEE T INTELLIGENT T
   Fugiglando U, 2017, CARSYS'17: PROCEEDINGS OF THE 2ND ACM INTERNATIONAL WORKSHOP ON SMART, AUTONOMOUS, AND CONNECTED VEHICULAR SYSTEMS AND SERVICES, P37, DOI 10.1145/3131944.3133939
   Geurts P, 2001, PRINCIPLES DATA MINI, P115
   Hallac D, 2016, 2016 IEEE 19TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P953, DOI 10.1109/ITSC.2016.7795670
   Lines J., 2016, GREAT TIME SERIES CL
   Markovitz M, 2017, VEH COMMUN, V9, P43, DOI 10.1016/j.vehcom.2017.02.005
   Miyajima C, 2007, P IEEE, V95, P427, DOI 10.1109/JPROC.2006.888405
   Salvadora S, 2007, INTELL DATA ANAL, V11, P561, DOI 10.3233/IDA-2007-11508
   Sija BD, 2018, SECUR COMMUN NETW, DOI 10.1155/2018/8370341
   Szalay Z, 2015, 2015 INTERNATIONAL CONFERENCE ON MODELS AND TECHNOLOGIES FOR INTELLIGENT TRANSPORTATION SYSTEMS (MT-ITS), P469, DOI 10.1109/MTITS.2015.7223296
   Voss W., 2008, COMPREHENSIBLE GUIDE
NR 12
TC 8
Z9 8
U1 0
U2 1
PY 2019
BP 136
EP 145
DI 10.5220/0007389501360145
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Rodriguez, MJ
AF Rodriguez, Manuel J.
CA DUNE Collaboration
BE Doglioni, C
   Kim, D
   Stewart, GA
   Silvestris, L
   Jackson, P
   Kamleh, W
TI Fast inference using FPGAs for DUNE data reconstruction
SO 24TH INTERNATIONAL CONFERENCE ON COMPUTING IN HIGH ENERGY AND NUCLEAR
   PHYSICS (CHEP 2019)
SE EPJ Web of Conferences
DT Proceedings Paper
CT 24th International Conference on Computing in High Energy and Nuclear
   Physics (CHEP)
CY NOV 04-08, 2019
CL Univ Adelaide, Adelaide, AUSTRALIA
HO Univ Adelaide
AB The Deep Underground Neutrino Experiment (DUNE) will be a world-class neutrino observatory and nucleon decay detector aiming to address some of the most fundamental questions in particle physics. With a modular liquid argon time-projection chamber (LArTPC) of 40 kt fiducial mass, the DUNE far detector will be able to reconstruct neutrino interactions with an unprecedented resolution. With no triggering and no zero suppression or compression, the total raw data volume would be of order 145 EB/year. Consequently, fast and affordable reconstruction methods are needed. Several state-of-the-art methods are focused on machine learning (ML) approaches to identify the signal within the raw data or to classify the neutrino interaction during the reconstruction. One of the main advantages of using those techniques is that they will reduce the computational cost and time compared to classical strategies. Our plan aims to go a bit further and test the implementation of those techniques on an accelerator board. In this work, we present the accelerator board used, a commercial off-the-shelf (COTS) hardware for fast deep learning (DL) inference based on an FPGA, and the experimental results obtained outperforming more traditional processing units. The FPGA-based approach is planned to be eventually used for online reconstruction.
C1 [Rodriguez, Manuel J.] CERN, Geneva, Switzerland.
RP Rodriguez, MJ (corresponding author), CERN, Geneva, Switzerland.
EM mjrodrig@cern.ch
CR Abi B., 2020, DUNE DEEP UNDERGROUN, V1
   Abi B., 2020, DUNE NEUTRINO INTERA
   Abi B., 2020, DEEP UNDERGROUND NEU, VII
   Adam-Bourdarios C., 2015, NIPS 2014 WORKSH HIG, P19, DOI DOI 10.1088/1742-6596/664/7/072015
   Aurisano A, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/09/P09001
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Carminati F, 2017, CALORIMETRY DEEP LEA
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hertel L., 2017, CONVOLUTIONAL NEURAL
   Martin G, 2009, IEEE DES TEST COMPUT, V26, P18, DOI 10.1109/MDT.2009.83
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Strigl D, 2010, EUROMICRO WORKSHOP P, P317, DOI 10.1109/PDP.2010.43
   Trimberger SM, 2015, P IEEE, V103, P318, DOI 10.1109/JPROC.2015.2392104
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2020
VL 245
AR 01030
DI 10.1051/epjconf/202024501030
WC Computer Science, Interdisciplinary Applications; Physics, Nuclear;
   Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Datta, S
   Rabaey, JM
AF Datta, Sohum
   Rabaey, Jan M.
GP IEEE
TI A probability-inspired normalization for fixed-precision
   Hyper-Dimensional Computing
SO 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS
   AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC
   ERA
DT Proceedings Paper
CT IEEE International Conference on Artificial Intelligence Circuits and
   Systems (AICAS) - Intelligent Technology in the Post-Pandemic Era
CY JUN 13-15, 2022
CL Incheon, SOUTH KOREA
DE Hyper-dimensional computing; energy efficiency; Internet-of-Things;
   probability; machine learning
AB Hyper-Dimensional Computing (HDC), a promising nano-scalable paradigm for low-energy predictions and lightweight learned models, has seen a surge of interest from the hardware accelerator community. However, the classical single-bit per vector element approach for HDC seldom achieves higher classification accuracy than multi-hit alternatives, and is inadequate to support the rapidly growing application space. A great challenge for multi-bit HDC hardware is to negotiate the enormous increase in logic vis-a-vis the single-bit hardware. Key to minimizing this cost is to limit bits per vector element, which is potentially unbounded without transformation, and can be very large for some applications. This work proposes a hardware-friendly numerical transformation on a HDC vector where the result has fixed bits per element. Under a reasonable assumption on the vector's distribution, it is proven that the transformation guarantees at most a small, known error in associative search. Verification experiments indicate the theoretical guarantee is very pessimistic; the actual error is less than 18% of the theoretical upper bound. Estimates predict 3.8X hardware savings with a 0.04e/c accuracy drop. We believe emerging stochastic approaches like HDC offer exciting new opportunities of employing high-dimensional probability theory for accelerator design.
C1 [Datta, Sohum; Rabaey, Jan M.] Univ Calif Berkeley, Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
RP Datta, S (corresponding author), Univ Calif Berkeley, Elect Engn & Comp Sci, Berkeley, CA 94720 USA.
EM sohumdatta@berkeley.edu; jan_rabaey@berkeley.edu
CR Anderson A. G, 2018, INT C LEARNING REPRE
   Datta S, 2019, IEEE J EM SEL TOP C, V9, P439, DOI 10.1109/JETCAS.2019.2935464
   Frady EP, 2018, NEURAL COMPUT, V30, P1449, DOI 10.1162/neco_a_01084
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Imani M, 2019, ANN IEEE SYM FIELD P, P190, DOI 10.1109/FCCM.2019.00034
   Joshi A, 2017, LECT NOTES COMPUT SC, V10106, P265, DOI 10.1007/978-3-319-52289-0_21
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Kent SJ, 2020, NEURAL COMPUT, V32, P2332, DOI 10.1162/neco_a_01329
   Kleyko D, 2021, Arxiv, DOI arXiv:2106.05268
   Rabaey J. M, 2003, DIGITAL INTEGRATED C, V2nd, P578
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   SHANNON CE, 1948, BELL SYST TECH J, V27, P379, DOI 10.1002/j.1538-7305.1948.tb01338.x
   Wainwright MJ, 2019, CA ST PR MA, P1, DOI 10.1017/9781108627771
   Zhuo Cheng, 2021, P 2021 GREAT LAK S V, P397, DOI DOI 10.1145/3453688.3461749
NR 14
TC 0
Z9 0
U1 0
U2 2
PY 2022
BP 21
EP 24
DI 10.1109/AICAS54282.2022.9869986
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Otoshi, T
   Nagano, T
   Izumi, S
   Hazama, D
   Katsurada, N
   Yamamoto, M
   Tachihara, M
   Kobayashi, K
   Nishimura, Y
AF Otoshi, Takehiro
   Nagano, Tatsuya
   Izumi, Shintaro
   Hazama, Daisuke
   Katsurada, Naoko
   Yamamoto, Masatsugu
   Tachihara, Motoko
   Kobayashi, Kazuyuki
   Nishimura, Yoshihiro
TI A novel automatic cough frequency monitoring system combining a triaxial
   accelerometer and a stretchable strain sensor
SO SCIENTIFIC REPORTS
DT Article
ID OBJECTIVE ASSESSMENT
AB Objective evaluations of cough frequency are considered important for assessing the clinical state of patients with respiratory diseases. However, cough monitors with audio recordings are rarely used in clinical settings. Issues regarding privacy and background noise with audio recordings are barriers to the wide use of these monitors; to solve these problems, we developed a novel automatic cough frequency monitoring system combining a triaxial accelerator and a stretchable strain sensor. Eleven healthy adult volunteers and 10 adult patients with cough were enrolled. The participants wore two devices for 30 min for the cough measurements. An accelerator was attached to the epigastric region, and a stretchable strain sensor was worn around their neck. When the subjects coughed, these devices displayed specific waveforms. The data from all the participants were categorized into a training dataset and a test dataset. Using a variational autoencoder, a machine learning algorithm with deep learning, the components of the test dataset were automatically judged as being a "cough unit" or "non-cough unit". The sensitivity and specificity in detecting coughs were 92% and 96%, respectively. Our cough monitoring system has the potential to be widely used in clinical settings without any concerns regarding privacy or background noise.
C1 [Otoshi, Takehiro; Nagano, Tatsuya; Hazama, Daisuke; Katsurada, Naoko; Yamamoto, Masatsugu; Tachihara, Motoko; Kobayashi, Kazuyuki; Nishimura, Yoshihiro] Kobe Univ, Dept Internal Med, Div Resp Med,Grad Sch Med, Chuo Ku, 7-5-1 Kusunokicho, Kobe, Hyogo 6500017, Japan.
   [Izumi, Shintaro] Kobe Univ, Grad Sch Syst Informat, Nada Ku, 1-1 Rokkodaicho, Kobe, Hyogo 6570013, Japan.
RP Nagano, T (corresponding author), Kobe Univ, Dept Internal Med, Div Resp Med,Grad Sch Med, Chuo Ku, 7-5-1 Kusunokicho, Kobe, Hyogo 6500017, Japan.
EM tnagano@med.kobe-u.ac.jp
CR [Anonymous], 1999, VITAL HLTH STAT
   Birring SS, 2008, EUR RESPIR J, V31, P1013, DOI 10.1183/09031936.00057407
   Birring SS, 2006, RESP MED, V100, P1105, DOI 10.1016/j.rmed.2005.09.023
   Birring SS, 2015, CURR OPIN PHARMACOL, V22, P37, DOI 10.1016/j.coph.2015.03.003
   Chamberlain SAF, 2015, LUNG, V193, P401, DOI 10.1007/s00408-015-9701-2
   Cho PSP, 2019, J ALLER CL IMM-PRACT, V7, P1715, DOI 10.1016/j.jaip.2019.01.049
   Chummun D, 2011, ALLERGY ASTHMA PROC, V32, P193, DOI 10.2500/aap.2011.32.3432
   Crooks MG, 2017, LUNG, V195, P289, DOI 10.1007/s00408-017-9996-2
   Dicpinigaitis PV, 2006, CHEST, V130, P1839, DOI 10.1378/chest.130.6.1839
   Kohno S, 2006, RESPIROLOGY, V11, pS135, DOI 10.1111/j.1400-1843.2006.00920.x
   Kuzniar TJ, 2007, MAYO CLIN PROC, V82, P56
   Leconte S, 2011, RESPIRATION, V81, P161, DOI 10.1159/000321231
   Lee KK, 2013, AM J RESP CRIT CARE, V187, P991, DOI 10.1164/rccm.201209-1686OC
   Marsden PA, 2016, CHEST, V149, P1460, DOI 10.1016/j.chest.2016.02.676
   Otoshi T, 2019, IN VIVO, V33, P543, DOI 10.21873/invivo.11508
   Proaño A, 2017, CLIN INFECT DIS, V64, P1174, DOI 10.1093/cid/cix039
   Smith J, 2008, LUNG, V186, pS48, DOI 10.1007/s00408-007-9059-1
   Spinou A, 2017, LUNG, V195, P575, DOI 10.1007/s00408-017-0038-x
   Yamamoto A, 2019, MED BIOL ENG COMPUT, V57, P2741, DOI 10.1007/s11517-019-02062-2
NR 19
TC 7
Z9 8
U1 3
U2 6
PD MAY 11
PY 2021
VL 11
IS 1
AR 9973
DI 10.1038/s41598-021-89457-0
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Roorda, E
   Rasoulinezhad, S
   Leong, PHW
   Wilton, SJE
AF Roorda, Esther
   Rasoulinezhad, Seyedramin
   Leong, Philip H. W.
   Wilton, Steven J. E.
TI FPGA Architecture Exploration for DNN Acceleration
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA architecture; neural networks; benchmarking; hardware acceleration
ID GENERATION; BENCHMARK
AB Recent years have seen an explosion of machine learning applications implemented on Field-Programmable Gate Arrays (FPGAs). FPGA vendors and researchers have responded by updating their fabrics to more efficiently implement machine learning accelerators, including innovations such as enhanced Digital Signal Processing (DSP) blocks and hardened systolic arrays. Evaluating architectural proposals is difficult, however, due to the lack of publicly available benchmark circuits.
   This paper addresses this problem by presenting an open-source benchmark circuit generator that creates realistic DNN-oriented circuits for use in FPGA architecture studies. Unlike previous generators, which create circuits that are agnostic of the underlying FPGA, our circuits explicitly instantiate embedded blocks, allowing for meaningful comparison of recent architectural proposals without the need for a complete inference computer-aided design (CAD) flow. Our circuits are compatible with the VTR CAD suite, allowing for architecture studies that investigate routing congestion and other low-level architectural implications.
   In addition to addressing the lack ofmachine learning benchmark circuits, the architecture exploration flow that we propose allows for a more comprehensive evaluation of FPGA architectures than traditional static benchmark suites. We demonstrate this through three case studies which illustrate how realistic benchmark circuits can be generated to target different heterogeneous FPGAs.
C1 [Roorda, Esther; Wilton, Steven J. E.] Univ British Columbia, Dept Elect & Comp Engn, 2332 Main Mall, Vancouver, BC V6T 1Z4, Canada.
   [Rasoulinezhad, Seyedramin; Leong, Philip H. W.] Univ Sydney, Sch Elect & Informat Engn, Sydney, NSW 2006, Australia.
RP Roorda, E (corresponding author), Univ British Columbia, Dept Elect & Comp Engn, 2332 Main Mall, Vancouver, BC V6T 1Z4, Canada.
EM estherr@ece.ubc.ca; seyedramin.rasoulinezhad@sydney.edu.au;
   philip.leong@sydney.edu.au; stevew@ece.ubc.ca
CR Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2016, MICRO
   [Anonymous], 1985, INT COMMUN HEAT MASS, DOI DOI 10.1016/0735-1933(85)90003-X
   Arora A, 2020, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP49362.2020.00018
   Arora Aman, 2020, P 2020 ACMSIGDA INT
   Azizimazreah A, 2019, INT S HIGH PERF COMP, P94, DOI 10.1109/HPCA.2019.00030
   Betz V., 2012, ARCHITECTURE CAD DEE, V497
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P10, DOI 10.1109/ICFPT51103.2020.00011
   Boutros A, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P94, DOI 10.1145/3289602.3293912
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Das J, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P181
   Eldafrawy M, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3393668
   Firuzan A, 2018, INT SYMP NETW CHIP
   Ghosh D, 1998, DESIGN, AUTOMATION AND TEST IN EUROPE, PROCEEDINGS, P656, DOI 10.1109/DATE.1998.655928
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Grant David, 2009, ACM T RECONFIG TECHN, V1, P1
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hutton MD, 2002, IEEE T COMPUT AID D, V21, P928, DOI 10.1109/TCAD.2002.800456
   Intel Corporation, 2020, AVALON INTERFACE SPE
   Jiang SN, 2020, IEEE MICRO, V40, P58, DOI 10.1109/MM.2020.2997638
   Kim JH, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P217, DOI 10.1109/FPT.2018.00039
   Kundarewich PD, 2004, IEEE T COMPUT AID D, V23, P869, DOI 10.1109/TCAD.2004.828132
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Langhammer Martin, 2020, P 2020 ACMSIGDA INT
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Mark C, 2012, ACM T EMBED COMPUT S, V11, DOI 10.1145/2331147.2331152
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2629579
   Parashar Angshuman, 2017, ARXIVCSNE170804485
   Pistorius J, 2000, IEEE T COMPUT AID D, V19, P1314, DOI 10.1109/43.892855
   Rasoulinezhad S, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P161, DOI 10.1145/3373087.3375303
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Samajdar A, 2019, I C FIELD PROG LOGIC, P342, DOI 10.1109/FPL.2019.00061
   Sharma H, 2016, INT SYMP MICROARCH
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Sohrabizadeh A, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P133, DOI 10.1145/3373087.3375321
   Stroobandt D, 1999, INTEGRATION, V27, P113, DOI 10.1016/S0167-9260(99)00002-4
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Tom M, 2005, DES AUT CON, P726
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Verplaetse D. S. P., 2002, INT C VLSI, P31
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   YAN A, 2002, P ACM INT S FIELD PR, P147
   Yang S., 1991, LOGIC SYNTHESIS OPTI
   Yang Xuan, 2016, ARXIV160604209
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 50
TC 0
Z9 0
U1 4
U2 10
PD SEP
PY 2022
VL 15
IS 3
SI SI
AR 33
DI 10.1145/3503465
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Marks, LB
   Light, KL
   Hubbs, JL
   Georgas, DL
   Jones, EL
   Wright, MC
   Willett, CG
   Yin, FF
AF Marks, Lawrence B.
   Light, Kim L.
   Hubbs, Jessica L.
   Georgas, Debra L.
   Jones, Ellen L.
   Wright, Melanie C.
   Willett, Christopher G.
   Yin, Fang Fang
TI The impact of advanced technologies on treatment deviations in radiation
   treatment delivery
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
DT Article
DE deviations; radiation therapy; quality assurance; technology
ID IN-VIVO DOSIMETRY; QUALITY-ASSURANCE; COMPUTERIZED RECORD; VERIFY
   SYSTEM; ERRORS; RADIOTHERAPY
AB Purpose: To assess the impact of new technologies on deviation rates in radiation therapy (RT).
   Methods and Materials: Treatment delivery deviations in RT were prospectively monitored during a time of technology upgrade. In January 2003, our department had three accelerators, none with "modern" technologies (e.g., without multileaf collimators [MLC]). In 2003 to 2004, we upgraded to five new accelerators, four with MLC, and associated advanced capabilities. The deviation rates among patients treated on "high-technology" versus "low-technology" machines (defined as those with vs. without MLC) were compared over time using the two-tailed Fisher's exact test.
   Results: In 2003, there was no significant difference between the deviation rate in the "high-technology" versus "low-technology" groups (0.16 % vs. 0.11 %,p = 0.45). In 2005 to 2006, the deviation rate for the "high-technology" groups was lower than the "low-technology" (0.083 % vs. 0.21 %,p = 0.009). This difference was caused by a decline in deviations on the "high-technology" machines over time (p = 0.053), as well as an unexpected trend toward an increase in deviations over time on the "low-technology" machines (p = 0.15).
   Conclusions: Advances in RT delivery systems appear to reduce the rate of treatment deviations. Deviation rates on "high-technology" machines with MLC decline over time, suggesting a learning curve after the introduction of new technologies. Associated with the adoption of "high-technology" was an unexpected increase in the deviation rate with "low-technology" approaches, which may reflect an over-reliance on tools inherent to "high-technology" machines. With the introduction of new technologies, continued diligence is needed to ensure that staff remain proficient with "low-technology" approaches. (c) 2007 Elsevier Inc.
C1 [Marks, Lawrence B.; Light, Kim L.; Hubbs, Jessica L.; Georgas, Debra L.; Jones, Ellen L.; Willett, Christopher G.; Yin, Fang Fang] Duke Univ, Med Ctr, Dept Radiat Oncol, Durham, NC 27710 USA.
   [Wright, Melanie C.] Duke Univ, Med Ctr, Dept Anesthesiol, Durham, NC 27706 USA.
RP Marks, LB (corresponding author), Duke Univ, Med Ctr, Dept Radiat Oncol, Box 3085, Durham, NC 27710 USA.
EM lawrence.marks@duke.edu
CR Barthelemy-Brichant N, 1999, RADIOTHER ONCOL, V53, P149, DOI 10.1016/S0167-8140(99)00141-3
   Calandrino R, 1997, RADIOTHER ONCOL, V45, P271, DOI 10.1016/S0167-8140(97)00095-9
   Fiorino C, 2000, RADIOTHER ONCOL, V56, P85, DOI 10.1016/S0167-8140(00)00195-X
   Fraass BA, 1998, INT J RADIAT ONCOL, V42, P651, DOI 10.1016/S0360-3016(98)00244-2
   Goldwein JW, 2003, INT J RADIAT ONCOL, V57, P1509, DOI 10.1016/S0360-3016(03)01436-6
   Huang G, 2005, INT J RADIAT ONCOL, V61, P1590, DOI 10.1016/j.ijrobp.2004.10.017
   Klein EE, 1998, INT J RADIAT ONCOL, V42, P1163, DOI 10.1016/S0360-3016(98)00252-1
   Koppel R, 2005, JAMA-J AM MED ASSOC, V293, P1197, DOI 10.1001/jama.293.10.1197
   Macklis RM, 1998, J CLIN ONCOL, V16, P551, DOI 10.1200/JCO.1998.16.2.551
   NOEL A, 1995, RADIOTHER ONCOL, V34, P144, DOI 10.1016/0167-8140(94)01503-U
   Patton GA, 2003, INT J RADIAT ONCOL, V56, P50, DOI 10.1016/S0360-3016(02)04418-8
   Yeung TK, 2005, RADIOTHER ONCOL, V74, P283, DOI 10.1016/j.radonc.2004.12.003
NR 12
TC 66
Z9 68
U1 0
U2 4
PD DEC 1
PY 2007
VL 69
IS 5
BP 1579
EP 1586
DI 10.1016/j.ijrobp.2007.08.017
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Li, WZ
   Chu, HM
   Huang, BM
   Huan, YX
   Zheng, LR
   Zou, Z
AF Li, Wenzhuo
   Chu, Haoming
   Huang, Boming
   Huan, Yuxiang
   Zheng, Lirong
   Zou, Zhuo
TI Enabling on-device classification of ECG with compressed learning for
   health IoT
SO MICROELECTRONICS JOURNAL
DT Article
DE Compressed sensing; Compressed learning; Automated machine learning;
   Energy-efficient accelerators
AB In this paper, an on-device classification of electrocardiography (ECG) with Compressed Learning (CL) for health Internet of Things (IoT) is proposed. A CL algorithm combining with one-dimensional (1-D) Convolutional Neural Network (CNN) that directly learns on ECG signals in the compression domain without expanded normalization is proposed. Such an approach bypasses the reconstruction step and minimizes the raw input data dimension that significantly reduces the processing power. An automatic network optimization framework with Automatic Machine Learning (AutoML) tool Neural Network Intelligence (NNI) is suggested to adapt to the network structure search problem introduced by input dimension reduction with Compression Ratios (CRs). That ensures the minimized model size and operation number under a guaranteed classification accuracy. To implement the resized 1-D CL classifier in hardware, which has different kernel sizes, strides, and output channels under different CRs, a flexible architecture is proposed to further lower power consumption. Evaluated on the MIT-BIH database, the specific 1-D CNN network selected under CR = 0.2 achieves a Macro-F1 of 0.9214 on 5-class ECG signal classification, with a 6.4x reduction in FLOPs and a 2.6x decrease in model size with an only 0.028 loss in Macro-F1 compared with the uncompressed situation. Synthesized in UMC 40 nm Low Power process, the hardware architecture with the 1-D CL classifier achieves an energy efficiency of 0.83 mu J/Classification under a 1.1-V power supply at a frequency of 5 MHz.
C1 [Li, Wenzhuo; Chu, Haoming; Huang, Boming; Huan, Yuxiang; Zheng, Lirong; Zou, Zhuo] Fudan Univ, Sch Informat Sci & Technol, State Key Lab ASIC & Syst, Shanghai 200433, Peoples R China.
RP Huan, YX; Zou, Z (corresponding author), Fudan Univ, Sch Informat Sci & Technol, State Key Lab ASIC & Syst, Shanghai 200433, Peoples R China.
EM yxhuan@fudan.edu.cn; zhuo@fudan.edu.cn
CR Abdelhalim K, 2013, IEEE J SOLID-ST CIRC, V48, P2478, DOI 10.1109/JSSC.2013.2272849
   Calderbank R., 2009, COMPRESSED LEARNING, P10
   Castro JM, 2018, 2018 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen ZJ, 2018, IEEE T CIRCUITS-II, V65, P948, DOI 10.1109/TCSII.2017.2747596
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Hollis Brayden, 2018, IEEE Robotics and Automation Letters, V3, P1616, DOI 10.1109/LRA.2018.2800791
   Hsueh JC, 2019, MICROELECTRON J, V87, P55, DOI 10.1016/j.mejo.2019.03.013
   Hua J, 2020, J SYST ARCHITECT, V104, DOI 10.1016/j.sysarc.2019.101687
   Hua J, 2018, J CIRCUIT SYST COMP, V27, DOI 10.1142/S0218126618500883
   Ieong CI, 2017, IEEE T VLSI SYST, V25, P1307, DOI 10.1109/TVLSI.2016.2638826
   Ji N, 2021, IEEE J BIOMED HEALTH, V25, P903, DOI 10.1109/JBHI.2021.3059883
   Khalil K, 2020, IEEE T CIRCUITS-I, V67, P3880, DOI 10.1109/TCSI.2020.3010743
   Khalil K, 2020, IEEE T BIOMED CIRC S, V14, P852, DOI 10.1109/TBCAS.2020.2995784
   Khalil K, 2019, IEEE T CIRCUITS-II, V66, P1885, DOI 10.1109/TCSII.2019.2924663
   Kiranyaz S, 2016, IEEE T BIO-MED ENG, V63, P664, DOI 10.1109/TBME.2015.2468589
   Li HT, 2019, IEEE T CIRCUITS-I, V66, P4699, DOI 10.1109/TCSI.2019.2940642
   Li TY, 2016, ENTROPY-SWITZ, V18, DOI 10.3390/e18080285
   Li Z, 2020, J ELECTROCARDIOL, V58, P105, DOI 10.1016/j.jelectrocard.2019.11.046
   Lin YJ, 2019, BIOMED CIRC SYST C, DOI [10.1109/biocas.2019.8919141, 10.1109/BIOCAS.2019.8919138, 10.1109/biocas.2019.8919138]
   Lohit S, 2016, IEEE IMAGE PROC, P1913, DOI 10.1109/ICIP.2016.7532691
   Luz EJD, 2016, COMPUT METH PROG BIO, V127, P144, DOI 10.1016/j.cmpb.2015.12.008
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Pei ZJ, 2017, 2017 4TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE), P1492, DOI 10.1109/ICISCE.2017.311
   Saadatnejad S, 2020, IEEE J BIOMED HEALTH, V24, P515, DOI 10.1109/JBHI.2019.2911367
   Tsai M., 2017, P 2017 PORTLAND INT, P1, DOI 10.1109/SiPS.2017.8110016
   Wang HR, 2019, J MED SYST, V44, DOI 10.1007/s10916-019-1511-2
   Wu YC, 2020, MICROELECTRON J, V98, DOI 10.1016/j.mejo.2020.104737
   Zhang J, 2015, IEEE J BIOMED HEALTH, V19, P520, DOI 10.1109/JBHI.2014.2312374
   Zhang ZM, 2016, COMPUT CARDIOL CONF, V43, P401
   Zhao Y, 2020, IEEE T BIOMED CIRC S, V14, P186, DOI 10.1109/TBCAS.2019.2954479
   Zibulevsky M., 2016, ARXIV161009615V1CSCV
   Zubair M, 2016, INT CONF IT CONVERGE, P335
NR 33
TC 9
Z9 9
U1 5
U2 26
PD SEP
PY 2021
VL 115
AR 105188
DI 10.1016/j.mejo.2021.105188
EA AUG 2021
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Blaiech, AG
   Ben Khalifa, K
   Valderrama, C
   Fernandes, MAC
   Bedoui, MH
AF Blaiech, Ahmed Ghazi
   Ben Khalifa, Khaled
   Valderrama, Carlos
   Fernandes, Marcelo A. C.
   Bedoui, Mohamed Hedi
TI A Survey and Taxonomy of FPGA-based Deep Learning Accelerators
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Deep learning; Framework; Optimized implementation; FPGA
ID NETWORKS
AB Deep learning, the fastest growing segment of Artificial Neural Network (ANN), has led to the emergence of many machine learning applications and their implementation across multiple platforms such as CPUs, GPUs and reconfigurable hardware (Field-Programmable Gate Arrays or FPGAs). However, inspired by the structure and function of ANNs, large-scale deep learning topologies require a considerable amount of parallel processing, memory resources, high throughput and significant processing power. Consequently, in the context of real time hardware systems, it is crucial to find the right trade-off between performance, energy efficiency, fast development, and cost. Although limited in size and resources, several approaches have showed that FPGAs provide a good starting point for the development of future deep learning implementation architectures. Through this paper, we briefly review recent work related to the implementation of deep learning algorithms in FPGAs. We will analyze and compare the design requirements and features of existing topologies to finally propose development strategies and implementation architectures for better use of FPGA-based deep learning topologies. In this context, we will examine the frameworks used in these studies, which will allow testing a lot of topologies to finally arrive at the best implementation alternatives in terms of performance and energy efficiency.
C1 [Blaiech, Ahmed Ghazi; Ben Khalifa, Khaled] Univ Sousse, Inst Super Sci Appl & Technol Sousse, Sousse 4003, Tunisia.
   [Blaiech, Ahmed Ghazi; Ben Khalifa, Khaled; Bedoui, Mohamed Hedi] Univ Monastir, Fac Med Monastir, Lab Technol & Imagerie Med, Monastir 5019, Tunisia.
   [Valderrama, Carlos] Univ Mons, Fac Polytech, Dept Microelect & Elect, Mons, Belgium.
   [Fernandes, Marcelo A. C.] Fed Univ Rio Grande Norte UFRN, Dept Comp Engn & Automat, BR-59078970 Natal, RN, Brazil.
RP Blaiech, AG (corresponding author), Univ Sousse, Inst Super Sci Appl & Technol Sousse, Sousse 4003, Tunisia.; Blaiech, AG (corresponding author), Univ Monastir, Fac Med Monastir, Lab Technol & Imagerie Med, Monastir 5019, Tunisia.
EM ahmedghaziblaiech@yahoo.fr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Ait Skourt B, 2018, PROCEDIA COMPUT SCI, V127, P109, DOI 10.1016/j.procs.2018.01.104
   [Anonymous], 2017, ARXIV170203410
   [Anonymous], P ACM SIGDA INT S FI
   [Anonymous], 2016, MICRO
   [Anonymous], 2018, TVM AUTOMATED END EN
   [Anonymous], CNNLAB NOVEL PARALLE
   [Anonymous], 2012, P 26 ANN C NEUR PROC, DOI DOI 10.1002/2014GB005021
   [Anonymous], 2015, CORR
   [Anonymous], P WORKSH APPR COMP A
   [Anonymous], P INT C FIELD PROGR
   [Anonymous], 2016, ARXIV160305027
   [Anonymous], 2012, P IBM CORP REDB
   [Anonymous], 2018, SURVEY FPGA BASED NE
   [Anonymous], 2016, AUTOMATED MELANOMA S
   [Anonymous], P 26 IEEE INT S FIEL
   [Anonymous], 2022, ENERGY, DOI DOI 10.1016/J.ENERGY.2022.125025
   [Anonymous], 2014, HIGH PERFORMANCE EXT
   [Anonymous], 2016, ARXIV160204283
   [Anonymous], 2011, BIGL NIPS WORKSH
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2014, 2 INT C LEARN REPR I
   [Anonymous], 2011, P NIPS WORKSHOP DEEP
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2017, P CVPR
   [Anonymous], 2013, INT C LEARN REPR ICL
   [Anonymous], P 13 INT C PATT REC
   [Anonymous], P 22 ACM INT C MULTI
   [Anonymous], CONVNET BENCHMARKS
   [Anonymous], 2018, ACCELERATING CNN INF
   [Anonymous], 2015, ICLR
   [Anonymous], P 49 ANN IEEE ACM IN
   Byeon W, 2015, PATTERN RECOGN LETT, V63, P23, DOI 10.1016/j.patrec.2015.06.003
   Canis A, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2514740
   Carneiro G, 2017, ELS MIC SOC BOOK SER, P321, DOI 10.1016/B978-0-12-810408-8.00019-5
   Daugman J, 2004, IEEE T CIRC SYST VID, V14, P21, DOI 10.1109/TCSVT.2003.818350
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding W, 2019, J SYST ARCHITECT, V97, P278, DOI 10.1016/j.sysarc.2018.12.008
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Fujii T, 2017, LECT NOTES COMPUT SC, V10216, P268, DOI 10.1007/978-3-319-56258-2_23
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Han J, 2016, PROCEEDINGS OF THE 23RD INTERNATIONAL BUSINESS ANNUAL CONFERENCE (2016), BKS ONE AND TWO, P234
   Han S., 2015, ARXIV151000149
   Hartwig Adam, ARXIV170404861
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hofbauer H, 2016, IET BIOMETRICS, V5, P200, DOI 10.1049/iet-bmt.2015.0069
   Jarrett K, 2009, IEEE I CONF COMP VIS, P2146, DOI 10.1109/ICCV.2009.5459469
   Judd P, 2018, PARALLEL COMPUT, V73, P40, DOI 10.1016/j.parco.2017.05.003
   Jung DJ, 2011, IEEE ANTENNAS PROP, P5, DOI 10.1109/APS.2011.5996367
   Krizhevsky A, 2014, ARXIV
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li YX, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3154839
   Li Z, 2017, FRONT COMPUT SCI-CHI, V11, P746, DOI 10.1007/s11704-016-6159-1
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Morcel R, 2017, ANN IEEE SYM FIELD P, P196, DOI 10.1109/FCCM.2017.62
   Noronha DH, 2018, IEEE SYM PARA DISTR, P178, DOI 10.1109/IPDPSW.2018.00034
   Ortega-Zamorano F, 2016, ADV INTELL SYST, V474, P79, DOI 10.1007/978-3-319-40162-1_9
   Posewsky T, 2018, LECT NOTES COMPUT SC, V10793, P311, DOI 10.1007/978-3-319-77610-1_23
   Razzak MI, 2018, L N COMPUT VIS BIOME, V26, P323, DOI 10.1007/978-3-319-65981-7_12
   Solazzo A, 2016, IEEE COMP SOC ANN, P224, DOI 10.1109/ISVLSI.2016.101
   Sutskever I., 2014, ADV NEUR IN, P3104
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wu JJ, 2016, ADV NEUR IN, V29
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xu J, 2017, ADV COMPUT VIS PATT, P73, DOI 10.1007/978-3-319-42999-1_6
   Yan ZN, 2017, ELS MIC SOC BOOK SER, P83, DOI 10.1016/B978-0-12-810408-8.00006-7
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang W, 2018, J SYST ARCHITECT, V88, P13, DOI 10.1016/j.sysarc.2018.05.005
NR 75
TC 34
Z9 35
U1 4
U2 41
PD SEP
PY 2019
VL 98
BP 331
EP 345
DI 10.1016/j.sysarc.2019.01.007
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU He, TJ
   Huo, HY
   Bartel, CJ
   Wang, ZR
   Cruse, K
   Ceder, G
AF He, Tanjin
   Huo, Haoyan
   Bartel, Christopher J.
   Wang, Zheren
   Cruse, Kevin
   Ceder, Gerbrand
TI Precursor recommendation for inorganic synthesis by machine learning
   materials similarity from scientific literature
SO SCIENCE ADVANCES
DT Article
ID X-RAY-DIFFRACTION; CRYSTAL-STRUCTURE; MECHANISM; CATHODE;
   PHOTOLUMINESCENCE; PERFORMANCE
AB Synthesis prediction is a key accelerator for the rapid design of advanced materials. However, determining synthesis variables such as the choice of precursor materials is challenging for inorganic materials because the sequence of reactions during heating is not well understood. In this work, we use a knowledge base of 29,900 solid-state synthesis recipes, text-mined from the scientific literature, to automatically learn which precursors to recommend for the synthesis of a novel target material. The data-driven approach learns chemical similarity of materials and refers the synthesis of a new target to precedent synthesis procedures of similar materials, mimicking human synthesis design. When proposing five precursor sets for each of 2654 unseen test target materials, the recommendation strategy achieves a success rate of at least 82%. Our approach captures decades of heuristic synthesis data in a mathematical form, making it accessible for use in recommendation engines and autonomous laboratories.
C1 [He, Tanjin; Huo, Haoyan; Bartel, Christopher J.; Wang, Zheren; Cruse, Kevin; Ceder, Gerbrand] Univ Calif Berkeley, Dept Mat Sci & Engn, Berkeley, CA 94720 USA.
   [He, Tanjin; Huo, Haoyan; Bartel, Christopher J.; Wang, Zheren; Cruse, Kevin; Ceder, Gerbrand] Lawrence Berkeley Natl Lab, Mat Sci Div, Berkeley, CA 94720 USA.
   [Bartel, Christopher J.] Univ Minnesota, Dept Chem Engn & Mat Sci, Minneapolis, MN 55455 USA.
RP Ceder, G (corresponding author), Univ Calif Berkeley, Dept Mat Sci & Engn, Berkeley, CA 94720 USA.; Ceder, G (corresponding author), Lawrence Berkeley Natl Lab, Mat Sci Div, Berkeley, CA 94720 USA.
EM gceder@berkeley.edu
CR Alcántara R, 1999, J POWER SOURCES, V81, P547, DOI 10.1016/S0378-7753(99)00213-X
   Aykol M, 2021, J AM CHEM SOC, V143, P9244, DOI 10.1021/jacs.1c04888
   Bengio Y, 2013, IEEE T PATTERN ANAL, V35, P1798, DOI 10.1109/TPAMI.2013.50
   Bianchini M, 2020, NAT MATER, V19, P1088, DOI 10.1038/s41563-020-0688-6
   Bojanowski P., 2017, T ASSOC COMPUT LING, V5, P135, DOI [DOI 10.1162/TACL_A_00051, 10.1162/tacl_a_00051]
   Chamorro JR, 2018, ACCOUNTS CHEM RES, V51, P2918, DOI 10.1021/acs.accounts.8b00382
   Chen CJ, 2020, NANO ENERGY, V68, DOI 10.1016/j.nanoen.2019.104329
   Coley CW, 2017, ACS CENTRAL SCI, V3, P1237, DOI 10.1021/acscentsci.7b00355
   COREY EJ, 1988, CHEM SOC REV, V17, P111, DOI 10.1039/cs9881700111
   Cruse K, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01321-6
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Dorbakov NG, 2019, J ALLOY COMPD, V793, P56, DOI 10.1016/j.jallcom.2019.03.365
   Duan CJ, 2009, CHEM MATER, V21, P1010, DOI 10.1021/cm801990r
   Fang YJ, 2015, ADV MATER, V27, P5895, DOI 10.1002/adma.201502018
   Feng PY, 2017, J MATER CHEM A, V5, P10261, DOI 10.1039/c7ta01946g
   Goodall REA, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19964-7
   He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553
   Hemminger J. C., 2015, CHALLENGES FRONTIERS
   Herrera F., 2016, MULTILABEL CLASSIFIC, P17, DOI [DOI 10.1007/978-3-319-41111-8, 10.1007/978-3-319-41111-8_2]
   Heymann G, 2017, DALTON T, V46, P12663, DOI 10.1039/c7dt02663c
   Hinton GE, 2006, SCIENCE, V313, P504, DOI 10.1126/science.1127647
   Hiszpanski AM, 2020, J CHEM INF MODEL, V60, P2876, DOI 10.1021/acs.jcim.0c00199
   Huo HY, 2022, CHEM MATER, V34, P7323, DOI 10.1021/acs.chemmater.2c01293
   Jia XW, 2019, NATURE, V573, P251, DOI 10.1038/s41586-019-1540-5
   Jiang ZL, 2017, J MATER CHEM C, V5, P5709, DOI 10.1039/c6tc04931a
   Kageyama H, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-02838-4
   Kendall A, 2018, PROC CVPR IEEE, P7482, DOI 10.1109/CVPR.2018.00781
   Kim E, 2020, J CHEM INF MODEL, V60, P1194, DOI 10.1021/acs.jcim.9b00995
   Kim E, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.127
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kitagawa Y, 2018, OPT MATER, V83, P111, DOI 10.1016/j.optmat.2018.05.039
   Kohlmann H, 2019, EUR J INORG CHEM, V2019, P4174, DOI 10.1002/epc.201900733
   Kononova O, 2019, SCI DATA, V6, DOI 10.1038/s41597-019-0224-1
   Lalère F, 2018, J MATER CHEM A, V6, P6654, DOI 10.1039/c7ta10689k
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Luan JF, 2011, SOLID STATE SCI, V13, P185, DOI 10.1016/j.solidstatesciences.2010.11.011
   Lv SC, 2018, ADV OPT MATER, V6, DOI 10.1002/adom.201800881
   Mao ZY, 2011, J LUMIN, V131, P1048, DOI 10.1016/j.jlumin.2011.01.020
   Markina MM, 2017, PHYS REV B, V96, DOI 10.1103/PhysRevB.96.134422
   McDermott MJ, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-23339-x
   Mendoza-Mendoza E, 2012, J MATER SCI, V47, P6076, DOI 10.1007/s10853-012-6520-1
   Mikolov T., 2013, NIPS, P3111
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Miura A, 2021, ADV MATER, V33, DOI 10.1002/adma.202100312
   Ndzila JS, 2020, J SOLID STATE CHEM, V288, DOI 10.1016/j.jssc.2020.121415
   Park KW, 2015, CHEM PHYS LETT, V636, P141, DOI 10.1016/j.cplett.2015.07.032
   Pearson K, 1901, PHILOS MAG, V2, P559, DOI 10.1080/14786440109462720
   Pei Zongrui, 2023, Nat Commun, V14, P54, DOI 10.1038/s41467-022-35766-5
   Peng HJ, 2017, J ELECTROCHEM SOC, V164, pA1192, DOI 10.1149/2.1181706jes
   Prechelt L, 2002, NEURAL NETWORKS TRIC, P55
   Radosavljevic I, 2000, J MATER CHEM, V10, P2091, DOI 10.1039/b002857f
   Rogers D, 2010, J CHEM INF MODEL, V50, P742, DOI 10.1021/ci100050t
   SCHAFER H, 1971, ANGEW CHEM INT EDIT, V10, P43, DOI 10.1002/anie.197100431
   Segler MHS, 2018, NATURE, V555, P604, DOI 10.1038/nature25978
   STEIN A, 1993, SCIENCE, V259, P1558, DOI 10.1126/science.259.5101.1558
   Sun YF, 2020, Arxiv, DOI arXiv:2002.10857
   Swain MC, 2016, J CHEM INF MODEL, V56, P1894, DOI 10.1021/acs.jcim.6b00207
   Szymanski NJ, 2021, MATER HORIZ, V8, P2169, DOI 10.1039/d1mh00495f
   Thirumalai J, 2013, J MATER SCI-MATER EL, V24, P253, DOI 10.1007/s10854-012-0725-6
   Tschannen M, 2018, Arxiv, DOI arXiv:1812.05069
   Tshitoyan V, 2019, NATURE, V571, P95, DOI 10.1038/s41586-019-1335-8
   van Wüllen L, 2007, PHYS CHEM CHEM PHYS, V9, P3298, DOI 10.1039/b703179c
   Vaswani A, 2017, ADV NEUR IN, V30
   Wang AYT, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00545-1
   Wang B, 2018, MATER RES BULL, V100, P97, DOI 10.1016/j.materresbull.2017.12.004
   Wang L, 2020, J ALLOY COMPD, V839, DOI 10.1016/j.jallcom.2020.155653
   Wang ZR, 2022, SCI DATA, V9, DOI 10.1038/s41597-022-01317-2
   Ward L, 2018, COMP MATER SCI, V152, P60, DOI 10.1016/j.commatsci.2018.05.018
   Ward L, 2016, NPJ COMPUT MATER, V2, DOI 10.1038/npjcompumats.2016.28
   Yasunaga T, 2019, J SOLID STATE CHEM, V276, P266, DOI 10.1016/j.jssc.2019.05.012
   Yi HH, 2011, ELECTROCHIM ACTA, V56, P4052, DOI 10.1016/j.electacta.2011.01.121
   Zhang D, 2010, INORG CHEM, V49, P9683, DOI 10.1021/ic101431g
   Zhu Y, 2009, APPL SURF SCI, V255, P7580, DOI 10.1016/j.apsusc.2009.04.031
   Zhuang H, 2019, ELECTROCHIM ACTA, V314, P102, DOI 10.1016/j.electacta.2019.05.066
   Zou QQ, 2012, J POWER SOURCES, V206, P222, DOI 10.1016/j.jpowsour.2011.12.050
   Zvereva EA, 2013, DALTON T, V42, P1550, DOI 10.1039/c2dt31938a
NR 76
TC 5
Z9 5
U1 11
U2 11
PD JUN 7
PY 2023
VL 9
IS 23
AR eadg8180
DI 10.1126/sciadv.adg8180
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Passalis, N
   Mourgias-Alexandris, G
   Pleros, N
   Tefas, A
AF Passalis, Nikolaos
   Mourgias-Alexandris, George
   Pleros, Nikos
   Tefas, Anastasios
TI Initializing photonic feed-forward neural networks using auxiliary tasks
SO NEURAL NETWORKS
DT Article
DE Photonic deep learning; Neural network initialization; Photonic
   activation functions
ID LEARNING ALGORITHMS; MACHINE
AB Photonics is among the most promising emerging technologies for providing fast and energy-efficient Deep Learning (DL) implementations. Despite their advantages, these photonic DL accelerators also come with certain important limitations. For example, the majority of existing photonic accelerators do not currently support many of the activation functions that are commonly used in DL, such as the ReLU activation function. Instead, sinusoidal and sigmoidal nonlinearities are usually employed, rendering the training process unstable and difficult to tune, mainly due to vanishing gradient phenomena. Thus, photonic DL models usually require carefully fine-tuning all their training hyper-parameters in order to ensure that the training process will proceed smoothly. Despite the recent advances in initialization schemes, as well as in optimization algorithms, training photonic DL models is still especially challenging. To overcome these limitations, we propose a novel adaptive initialization method that employs auxiliary tasks to estimate the optimal initialization variance for each layer of a network. The effectiveness of the proposed approach is demonstrated using two different datasets, as well as two recently proposed photonic activation functions and three different initialization methods. Apart from significantly increasing the stability of the training process, the proposed method can be directly used with any photonic activation function, without further requiring any other kind of fine-tuning, as also demonstrated through the conducted experiments. (C) 2020 Elsevier Ltd. All rights reserved.
C1 [Passalis, Nikolaos; Tefas, Anastasios] Aristotle Univ Thessaloniki, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
   [Mourgias-Alexandris, George; Pleros, Nikos] Aristotle Univ Thessaloniki, Dept Informat, Photon Syst & Networks Res Grp, Thessaloniki, Greece.
RP Passalis, N (corresponding author), Aristotle Univ Thessaloniki, Artificial Intelligence & Informat Anal Lab, Thessaloniki, Greece.
EM passalis@csd.auth.gr
CR Gao DL, 2020, PROCEEDINGS OF THE ASME INTERNATIONAL DESIGN ENGINEERING TECHNICAL CONFERENCES AND COMPUTERS AND INFORMATION IN ENGINEERING CONFERENCE, 2019, VOL 5B
   Glorot X., 2010, P JMLR WORKSH C P 13, P249, DOI DOI 10.1177/1753193409103364.
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang GB, 2012, IEEE T SYST MAN CY B, V42, P513, DOI 10.1109/TSMCB.2011.2168604
   Kasabov N, 2016, NEURAL NETWORKS, V78, P1, DOI 10.1016/j.neunet.2015.09.011
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lange S, 2018, J LIGHTWAVE TECHNOL, V36, P97, DOI 10.1109/JLT.2017.2743211
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mourgias-Alexandris G, 2019, OPT EXPRESS, V27, P9620, DOI 10.1364/OE.27.009620
   Pantone RD, 2018, NEURAL NETWORKS, V106, P144, DOI 10.1016/j.neunet.2018.07.002
   Passalis N., 2019, IEEE T EMERGING TOPI
   Rahimi A., 2007, ADV NEURAL INFORM PR, V20, DOI DOI 10.5555/2981562.2981710
   Runge P., 2018, 2018 C LAS EL, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tieleman T., 2012, COURSERA NEURAL NETW, V4, P26, DOI DOI 10.1007/S12654-012-0173-1
   Walter F, 2015, NEURAL NETWORKS, V72, P152, DOI 10.1016/j.neunet.2015.07.004
   Wang CC, 2018, NEURAL COMPUT, V30, P1673, DOI 10.1162/neco_a_01088
   Xiao H., 2017, ARXIV170807747
NR 23
TC 7
Z9 7
U1 1
U2 6
PD SEP
PY 2020
VL 129
BP 103
EP 108
DI 10.1016/j.neunet.2020.05.024
WC Computer Science, Artificial Intelligence; Neurosciences
DA 2023-11-11
ER

PT C
AU Kim, SK
   McMahon, PL
   Olukotun, K
AF Kim, Sang Kyun
   McMahon, Peter L.
   Olukotun, Kunle
BE Sass, R
   Tessier, R
TI A Large-scale Architecture for Restricted Boltzmann Machines
SO 2010 18TH IEEE ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2010)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 18th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 02-04, 2010
CL Charlotte, NC
DE Accelerators; Neural network hardware; Computer architecture;
   Large-scale systems; Field programmable gate arrays; Parallel
   processing; Boltzmann machines
AB Deep Belief Nets (DBNs) are an emerging application in the machine learning domain, which use Restricted Boltzmann Machines (RBMs) as their basic building block. Although small scale DBNs have shown great potential, the computational cost of RBM training has been a major challenge in scaling to large networks. In this paper we present a highly scalable architecture for Deep Belief Net processing on hardware systems that can handle hundreds of boards, if not more, of customized logic with near linear performance increase. We elucidate tradeoffs between flexibility in the neuron connections, and the hardware resources, such as memory and communication bandwidth, required to build a custom processor design that has optimal efficiency. We illustrate how our architecture can easily support sparse networks with dense regions of connections between neighboring sets of neurons, which is relevant to applications where there are obvious spatial correlations in the data, such as in image processing. We demonstrate the feasibility of our approach by implementing a multi-FPGA system. We show that a speedup of 46X-112X over an optimized single core CPU implementation can be achieved for a four-FPGA implementation.
C1 [Kim, Sang Kyun; McMahon, Peter L.; Olukotun, Kunle] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
RP Kim, SK (corresponding author), Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
EM skkim38@stanford.edu; pmcmahon@stanford.edu; kunle@stanford.edu
CR [Anonymous], 2009, ADV NEURAL INFORM PR
   [Anonymous], 2009, LARGE SCALE DEEP UNS
   [Anonymous], 2009, P ACMSIGDA INT S FIE
   COX CE, 1992, IEEE J SOLID-ST CIRC, V27, P288, DOI 10.1109/4.121550
   Goto K, 2008, ACM T MATH SOFTWARE, V35, DOI 10.1145/1377603.1377607
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Kim S. K., 2009, FIELD PROGR LOG APPL
   Lee H., 2009, ICML, P609, DOI 10.1145/1553374.1553453
   Ly D. L., 2009, FIELD PROGR LOG APPL
   Lysaght P., 1994, Field-Programmable Logic Architectures, Synthesis and Applications. 4th International Workshop on Field-Programmable Logic and Applications, FPL '94. Proceedings, P421
   Taylor GW, 2007, ADV NEURAL INFORM PR, P1345, DOI DOI 10.7551/MITPRESS/7503.003.0173
   ZHANG D, 2002, NEURAL NETWORKS SYST
   Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062
NR 13
TC 28
Z9 42
U1 0
U2 2
PY 2010
BP 201
EP 208
DI 10.1109/FCCM.2010.38
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Hestness, J
   Ardalani, N
   Diamos, G
AF Hestness, Joel
   Ardalani, Newsha
   Diamos, Gregory
GP ACM
TI Beyond Human-Level Accuracy: Computational Challenges in Deep Learning
SO PROCEEDINGS OF THE 24TH SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL
   PROGRAMMING (PPOPP '19)
DT Proceedings Paper
CT 24th ACM SIGPLAN Symposium on Principles and Practice of Parallel
   Programming (PPoPP)
CY FEB 16-20, 2019
CL Washington, DC
DE deep learning; neural networks; compute graph; compute requirements;
   data parallelism; model parallelism
AB Deep learning (DL) research yields accuracy and product improvements from both model architecture changes and scale: larger data sets and models, and more computation. For hardware design, it is difficult to predict DL model changes. However, recent prior work shows that as dataset sizes grow, DL model accuracy and model size grow predictably. This paper leverages the prior work to project the dataset and model size growth required to advance DL accuracy beyond human-level, to frontier targets defined by machine learning experts. Datasets will need to grow 33-971x, while models will need to grow 6.6-456x to achieve target accuracies.
   We further characterize and project the computational requirements to train these applications at scale. Our characterization reveals an important segmentation of DL training challenges for recurrent neural networks (RNNs) that contrasts with prior studies of deep convolutional networks. RNNs will have comparatively moderate operational intensities and very large memory footprint requirements. In contrast to emerging accelerator designs, large-scale RNN training characteristics suggest designs with significantly larger memory capacity and on-chip caches.
C1 [Hestness, Joel; Ardalani, Newsha; Diamos, Gregory] Baidu Res, Sunnyvale, CA 94089 USA.
RP Hestness, J (corresponding author), Baidu Res, Sunnyvale, CA 94089 USA.
EM joel@baidu.com; newsha@baidu.com; gregdiamos@baidu.com
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alistarh D, 2017, ADV NEUR IN, V30
   Amodei D, 2016, PR MACH LEARN RES, V48
   [Anonymous], 2016, ARXIV160202410V2
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2018, DAWNBENCH
   [Anonymous], 2017, EMPIRICALLY
   [Anonymous], 2018, DEEPBENCH
   [Anonymous], 2018, AI AND COMPUTE
   Banko Michele, 2001, ASS COMPUTATIONAL LI
   Battenberg E, 2017, 2017 IEEE AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING WORKSHOP (ASRU), P206, DOI 10.1109/ASRU.2017.8268937
   CHENG Y, 2018, IEEE SIGNAL PROCESSI, V35
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Coleman S., 1995, SIGPLAN Notices, V30, P279, DOI 10.1145/223428.207162
   Dean Jeff, 2017, ML SYST WORKSH NEUR
   Goyal P., 2017, ARXIV170602677
   Han B, 2018, ADV NEUR IN, V31, DOI 10.5555/3327757.3327944
   Hannun A., 2014, DEEP SPEECH SCALING
   Harvey N., 2017, C LEARN THEOR, P1064
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Lin YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3756
   Luong M.-T., 2015, P 2015 C EMPIRICAL M, P1412, DOI DOI 10.18653/V1/D15-1166
   Maleki S, 2018, INT PARALL DISTRIB P, P224, DOI 10.1109/IPDPS.2018.00032
   MLPerf, 2018, MLPERF BROAD ML BENC
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Puri R, 2018, INT SYM COMP ARCHIT, P290, DOI [10.1109/CAHPC.2018.8645935, 10.1109/SBAC-PAD.2018.00055]
   Qi H., 2017, P 5 INT C LEARN REPR
   Recht B., 2011, ADV NEURAL INFORM PR, P693
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sak H, 2014, INTERSPEECH, P338
   SHANNON CE, 1951, BELL SYST TECH J, V30, P50, DOI 10.1002/j.1538-7305.1951.tb01366.x
   Shazeer Noam, 2017, ARXIV170106538V1
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shen Yongming, 2017, IEEE INT S FIELD PRO
   Smith Samuel L., 2017, ARXIV171006451V2
   Sun C, 2017, IEEE I CONF COMP VIS, P843, DOI 10.1109/ICCV.2017.97
   Wen W., 2017, ARXIV170507878, DOI DOI 10.1109/ICC.2017.7997306
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Xiong W, 2017, MOBISYS'17: PROCEEDINGS OF THE 15TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P172, DOI 10.1145/3081333.3089316
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Zilly JG, 2017, PR MACH LEARN RES, V70
NR 41
TC 24
Z9 25
U1 0
U2 0
PY 2019
BP 1
EP 14
DI 10.1145/3293883.3295710
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT J
AU Song, LL
   Wang, Y
   Han, YH
   Li, HW
   Cheng, YQ
   Li, XW
AF Song, Lili
   Wang, Ying
   Han, Yinhe
   Li, Huawei
   Cheng, Yuanqing
   Li, Xiaowei
TI STT-RAM Buffer Design for Precision-Tunable General-Purpose Neural
   Network Accelerator
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Approximate computing; machine learning; neural network; spin toque
   transfer RAM (STT-RAM)
ID ENERGY; MEMORY
AB Multilevel spin toque transfer RAM (STT-RAM) is a suitable storage device for energy-efficient neural network accelerators (NNAs), which relies on large-capacity on-chip memory to support brain-inspired large-scale learning models from conventional artificial neural networks to current popular deep convolutional neural networks. In this paper, we investigate the application of multilevel STT-RAM to general-purpose NNAs. First, the error-resilience feature of neural networks is leveraged to tolerate the read/write reliability issue in multilevel cell STT-RAM using approximate computing. The induced read/write failures at the expense of higher storage density can be effectively masked by a wide spectrum of NN applications with intrinsic forgiveness. Second, we present a precision-tunable STT-RAM buffer for the popular general-purpose NNA. The targeted STT-RAM memory design is able to transform between multiple working modes and adaptable to meet the varying quality constraint of approximate applications. Lastly, the reconfigurable STT-RAM buffer not only enables precision scaling in NNA but also provides adaptiveness to the demand for different learning models with distinct working-set sizes. Particularly, we demonstrate the concept of capacity/precision-tunable STT-RAM memory with the emerging reconfigurable deep NNA and elaborate on the data mapping and storage mode switching policy in STT-RAM memory to achieve the best energy efficiency of approximate computing.
C1 [Song, Lili; Wang, Ying; Han, Yinhe; Li, Huawei; Cheng, Yuanqing; Li, Xiaowei] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Song, Lili; Wang, Ying; Han, Yinhe; Li, Huawei; Cheng, Yuanqing; Li, Xiaowei] Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
RP Wang, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.; Wang, Y (corresponding author), Univ Chinese Acad Sci, Beijing 100190, Peoples R China.
EM wangying2009@ict.ac.cn; yinhes@ict.ac.cn
CR [Anonymous], 2014, PROC 2 INT C LEARN R
   [Anonymous], P IEEE INT EL DEV M
   [Anonymous], 2014, P 51 ACM EDAC IEEE D
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], 2009, 001 U TOR DEP COMP S
   [Anonymous], 2012, J WOMENS MED
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Chakradhar ST, 2010, DES AUT CON, P865
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Esmaeilzadeh H, 2013, IEEE MICRO, V33, P16, DOI 10.1109/MM.2013.28
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jog A, 2012, DES AUT CON, P243
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li BX, 2013, I SYMPOS LOW POWER E, P242, DOI 10.1109/ISLPED.2013.6629302
   Meena JS, 2014, NANOSCALE RES LETT, V9, DOI 10.1186/1556-276X-9-526
   Mitra S, 2009, IEEE T BIOMED CIRC S, V3, P32, DOI 10.1109/TBCAS.2008.2005781
   Ohsawa T., 2012, 2012 IEEE Symposium on VLSI Circuits, P46, DOI 10.1109/VLSIC.2012.6243782
   Park SP, 2012, DES AUT CON, P492
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Song L., 2016, P DAC
   Suzuki K, 2011, ARTIFICIAL NEURAL NETWORKS - METHODOLOGICAL ADVANCES AND BIOMEDICAL APPLICATIONS, P1, DOI 10.5772/644
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Vincent AF, 2015, IEEE T BIOMED CIRC S, V9, P166, DOI 10.1109/TBCAS.2015.2414423
   Wang P, 2013, IEEE INT SYMP CIRC S, P1244, DOI 10.1109/ISCAS.2013.6572078
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang YJ, 2012, ICCAD-IEEE ACM INT, P526
NR 33
TC 9
Z9 9
U1 0
U2 11
PD APR
PY 2017
VL 25
IS 4
BP 1285
EP 1296
DI 10.1109/TVLSI.2016.2644279
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Shao, SJ
   Tsai, J
   Mysior, M
   Luk, W
   Chau, T
   Warren, A
   Jeppesen, B
AF Shao, Shengjia
   Tsai, Jason
   Mysior, Michal
   Luk, Wayne
   Chau, Thomas
   Warren, Alexander
   Jeppesen, Ben
GP IEEE
TI Towards Hardware Accelerated Reinforcement Learning for
   Application-Specific Robotic Control
SO 2018 IEEE 29TH INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 29th Annual IEEE International Conference on Application-Specific
   Systems, Architectures and Processors (ASAP)
CY JUL 10-12, 2018
CL Milan, ITALY
AB Reinforcement Learning (RL) is an area of machine learning in which an agent interacts with the environment by making sequential decisions. The agent receives reward from the environment based on how good the decisions are and tries to find an optimal decision-making policy that maximises its long-term cumulative reward. This paper presents a novel approach which has shown promise in applying accelerated simulation of RL policy training to automating the control of a real robot arm for specific applications. The approach has two steps. First, design space exploration techniques are developed to enhance performance of an FPGA accelerator for RL policy training based on Trust Region Policy Optimisation (TRPO), which results in a 43% speed improvement over a previous FPGA implementation, while achieving 4.65 times speed up against deep learning libraries running on GPU and 19.29 times speed up against CPU. Second, the trained RL policy is transferred to a real robot arm. Our experiments show that the trained arm can successfully reach to and pick up predefined objects, demonstrating the feasibility of our approach.
C1 [Shao, Shengjia; Tsai, Jason; Mysior, Michal; Luk, Wayne] Imperial Coll London, London, England.
   [Chau, Thomas; Warren, Alexander; Jeppesen, Ben] Intel Corp, Swindon, Wilts, England.
RP Shao, SJ (corresponding author), Imperial Coll London, London, England.
EM ss13412@imperial.ac.uk; jt2815@imperial.ac.uk; mjm215@imperial.ac.uk;
   w.luk@imperial.ac.uk; thomas.chau@intel.com; alexander.warren@intel.com;
   ben.jeppesen@intel.com
CR Brockman G., 2016, ARXIV160601540, P1
   Houthooft R., 2016, P INT C MACH LEARN N, P1329
   Jeppesen BP, 2017, PROC IEEE INT SYMP, P1067, DOI 10.1109/ISIE.2017.8001394
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   PEARLMUTTER BA, 1994, NEURAL COMPUT, V6, P147, DOI 10.1162/neco.1994.6.1.147
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Shaozhen Song, 2017, 2017 IEEE International Ultrasonics Symposium (IUS), DOI 10.1109/ULTSYM.2017.8092353
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Su Jiang, 2017, ACM SIGARCH COMPUTER, V44, P68, DOI 10.1145/3039902.3039915
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
NR 11
TC 10
Z9 10
U1 0
U2 4
PY 2018
BP 135
EP 142
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Lass, M
   Kühne, TD
   Plessl, C
AF Lass, Michael
   Kuhne, Thomas D.
   Plessl, Christian
TI Using Approximate Computing for the Calculation of Inverse Matrix
   <i>p</i>th Roots
SO IEEE EMBEDDED SYSTEMS LETTERS
DT Article
DE Approximate computing; iterative methods; linear algebra; scientific
   computing
AB Approximate computing has shown to provide new ways to improve performance and power consumption of error-resilient applications. While many of these applications can be found in image processing, data classification, or machine learning, we demonstrate its suitability to a problem from scientific computing. Utilizing the self-correcting behavior of iterative algorithms, we show that approximate computing can be applied to the calculation of inverse matrix pth roots which are required in many applications in scientific computing. Results show great opportunities to reduce the computational effort and bandwidth required for the execution of the discussed algorithm, especially when targeting special accelerator hardware.
C1 [Lass, Michael; Plessl, Christian] Paderborn Univ, Dept Comp Sci, D-33098 Paderborn, Germany.
   [Lass, Michael; Kuhne, Thomas D.; Plessl, Christian] Paderborn Univ, Paderborn Ctr Parallel Comp, D-33098 Paderborn, Germany.
   [Kuhne, Thomas D.] Paderborn Univ, Dept Chem, D-33098 Paderborn, Germany.
RP Lass, M (corresponding author), Paderborn Univ, Dept Comp Sci, D-33098 Paderborn, Germany.; Lass, M (corresponding author), Paderborn Univ, Paderborn Ctr Parallel Comp, D-33098 Paderborn, Germany.
EM michael.lass@uni-paderborn.de; tdkuehne@mail.uni-paderborn.de;
   christian.plessl@uni-paderborn.de
CR Behnel S, 2011, COMPUT SCI ENG, V13, P31, DOI 10.1109/MCSE.2010.118
   Bini D, 2005, NUMER ALGORITHMS, V39, P349, DOI 10.1007/s11075-004-6709-8
   Callaway TK, 1997, P S COMP ARITHM, P26, DOI 10.1109/ARITH.1997.614876
   Ceriotti M, 2008, J CHEM PHYS, V129, DOI 10.1063/1.2949515
   Chippa V. K., 2013, P 50 ANN DESIGN AUTO, P1, DOI DOI 10.1145/2463209.2488873
   Klavík P, 2014, PHILOS T R SOC A, V372, DOI 10.1098/rsta.2013.0278
   Mohr S, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4871876
   NVIDIA Corporation, 2016, TESL P100 DAT SHEET
   Peterson P, 2001, SCIPY OPEN SOURCE SC
   Prodan E, 2005, P NATL ACAD SCI USA, V102, P11635, DOI 10.1073/pnas.0505436102
   Richters D., 2017, GEN ALGORITHM CALCUL
   Richters D, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4869865
   Schöll A, 2016, 2016 IEEE INTERNATIONAL SYMPOSIUM ON DEFECT AND FAULT TOLERANCE IN VLSI AND NANOTECHNOLOGY SYSTEMS (DFT), P21, DOI 10.1109/DFT.2016.7684063
   Schöll A, 2015, INT SYM DEFEC FAU TO, P60, DOI 10.1109/DFT.2015.7315136
   Schulz G., 1933, Z ANGEW MATH MECH, V13, P57, DOI DOI 10.1002/ZAMM.19330130111
NR 15
TC 2
Z9 2
U1 0
U2 4
PD JUN
PY 2018
VL 10
IS 2
BP 33
EP 36
DI 10.1109/LES.2017.2760923
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Waris, H
   Wang, CH
   Liu, WQ
AF Waris, Haroon
   Wang, Chenghua
   Liu, Weiqiang
GP IEEE
TI Architectural-Space Exploration of Energy-Efficient Approximate
   Arithmetic Units for Error-Tolerant Applications
SO 2022 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2022)
SE IEEE Computer Society Annual Symposium on VLSI Proceedings
DT Proceedings Paper
CT IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 04-06, 2022
CL Pafos, CYPRUS
DE Approximate Computing; Accuracy-Energy Trade-off; Low-Power Adders;
   Recursive Multipliers; Booth Multipliers; Logic Gates; Systolic Arrays;
   Processing Elements
AB The performance and power efficiency of integrated circuits have improved continuously in the past few decades due to the reduction of transistor size. However, with the soon end of technology node scaling, it is becoming difficult to meet the per-transistor performance/energy efficiency in the design of integrated circuits. Moreover, an unprecedented challenge has arisen with the increase in importance of artificial intelligence as it require massive amounts of data and complex computations. Meanwhile, it has been reported in the technical literature that many applications, such as multimedia, recognition, classification, and machine learning, exhibit error-tolerant features. For instance, in image processing applications due to the perceptual limitations of humans, the use of approximate techniques do not impose a noticeable degradation in the output quality of image. Similarly, the machine learning applications can compensate the effects of small errors, as they are based on iterative refinement. Therefore, this relaxed error requirement can be exploited to design high-performance and energy-efficient hardware accelerators for error-tolerant applications. Arithmetic units are the most power-hungry modules in these special purpose hardware accelerators; thus, the design of approximate arithmetic units is a promising area for research. This thesis investigates several novel approaches for the design of approximate arithmetic units and their applicability has been verified by using them in practical error-tolerant applications. To encourage and help further research in this direction the synthesizable Verilog files are provided as open-source libraries at https://sourceforge.net/projects/approxarithmeticlib/, https://sourceforge.net/projects/approxrecursivemul/ and at https://sourceforge.net/projects/approxsolutionfinder/.
C1 [Waris, Haroon; Wang, Chenghua; Liu, Weiqiang] Nanjing Univ Aeronaut & Astronaut Nanjing, Nanjing, Peoples R China.
RP Waris, H (corresponding author), Nanjing Univ Aeronaut & Astronaut Nanjing, Nanjing, Peoples R China.
EM haroonwaris@nuaa.edu.cn; chwang@nuaa.edu.cn; liuweiqiang@nuaa.edu.cn
CR Liu WQ, 2020, P IEEE, V108, P394, DOI 10.1109/JPROC.2020.2975695
   Ometov A, 2022, DES AUT TEST EUROPE, P632, DOI 10.23919/DATE54114.2022.9774538
   Wang C., 2018, PROC 23 INT C DIGITA, P1
   Waris H., 2022, APPROXIMATE COMPUTIN
   Waris H, 2022, IEEE T EMERG TOP COM, V10, P1229, DOI 10.1109/TETC.2021.3096515
   Waris H, 2022, IEEE T EMERG TOP COM, V10, P507, DOI 10.1109/TETC.2020.3013977
   Waris H, 2021, IEEE T CIRCUITS-II, V68, P1566, DOI 10.1109/TCSII.2021.3065333
   Waris H, 2021, J SIGNAL PROCESS SYS, V93, P605, DOI 10.1007/s11265-020-01582-7
   Waris H, 2020, IEEE T CIRCUITS-II, V67, P3367, DOI 10.1109/TCSII.2020.2975094
   Waris H, 2019, IEEE WRK SIG PRO SYS, P13, DOI [10.1109/sips47522.2019.9020404, 10.1109/SiPS47522.2019.9020404]
   Waris H, 2019, IEICE ELECTRON EXPR, V16, DOI 10.1587/elex.16.20190043
NR 11
TC 0
Z9 0
U1 2
U2 2
PY 2022
BP 440
EP 445
DI 10.1109/ISVLSI54635.2022.00098
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Lübeck, K
   Bringmann, O
AF Luebeck, Konstantin
   Bringmann, Oliver
BE Schoeberl, M
   Hochberger, C
   Uhrig, S
   Brehm, J
   Pionteck, T
TI A Heterogeneous and Reconfigurable Embedded Architecture for
   Energy-Efficient Execution of Convolutional Neural Networks
SO ARCHITECTURE OF COMPUTING SYSTEMS - ARCS 2019
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 32nd International Conference on Computer Architecture (ARCS)
CY MAY 20-23, 2019
CL Tech Univ Denmark, Copenhagen, DENMARK
HO Tech Univ Denmark
ID ACCELERATOR
AB Machine learning based convolutional neural networks (CNN) are becoming increasingly popular for identification tasks like image classification or speech recognition. However, CNNs have high memory and computational demands which makes it challenging to implement them on cost-efficient and energy-autonomous hardware. To cope with this challenge we present a heterogeneous and reconfigurable embedded architecture implemented on an inexpensive and widely available entry-level system on chip (SoC). Our architecture combines an ARM CPU and a coarse-grained reconfigurable architecture (CGRA) which execute a CNN in parallel to reach a higher energy-efficiency. Our results show up to 130% higher performance and 78% better energy-efficiency compared with an embedded Nvidia GPU.
C1 [Luebeck, Konstantin; Bringmann, Oliver] Univ Tubingen, Dept Comp Sci, Tubingen, Germany.
RP Lübeck, K (corresponding author), Univ Tubingen, Dept Comp Sci, Tubingen, Germany.
EM konstantin.luebeck@uni-tuebingen.de; oliver.bringmann@uni-tuebingen.de
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Fan XT, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577309
   Gokhale V, 2017, 2017 15TH IEEE INTERNATIONAL SYMPOSIUM ON HAPTIC, AUDIO AND VISUAL ENVIRONMENTS AND GAMES (HAVE), P59
   Hartenstein R, 2001, DESIGN, AUTOMATION AND TEST IN EUROPE, CONFERENCE AND EXHIBITION 2001, PROCEEDINGS, P642, DOI 10.1109/DATE.2001.915091
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Jafri SMAH, 2017, INT PARALL DISTRIB P, P276, DOI 10.1109/IPDPS.2017.59
   Jia Y.:, TRAINING LENET MNIST
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., MNIST HANDWRITTEN DI
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lubeck K, 2016, 19 WORKSH METH BESCH, P46, DOI [10.6094/UNIFR/10617, DOI 10.6094/UNIFR/10617]
   Nvidia, 2013, WHIT NVIDIA TEGR K1
   Oppold T, 2007, IT-INF TECHNOL, V49, P157, DOI 10.1524/itit.2007.49.3.157
   Paszke A., 2017, NEURIPS
   Patterson D. A., 2012, COMPUTER ARCHITECTUR
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Shi RB, 2015, 2015 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P591, DOI 10.1109/DSD.2015.70
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   System Management Interface Forum, 2010, PMBUS POW SYST MAN 2
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   Xilinx, 2017, UG1085 XIL
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao BY, 2017, IEICE ELECTRON EXPR, V14, DOI 10.1587/elex.14.20170595
NR 31
TC 1
Z9 1
U1 0
U2 4
PY 2019
VL 11479
BP 267
EP 280
DI 10.1007/978-3-030-18656-2_20
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Raman, SRS
   Xie, SS
   Kulkarni, JP
AF Raman, Siddhartha Raman Sundara
   Xie, Shanshan
   Kulkarni, Jaydeep P.
GP IEEE
TI Compute-in-eDRAM with Backend Integrated Indium Gallium Zinc Oxide
   Transistors
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 22-28, 2021
CL Daegu, SOUTH KOREA
DE Accelerators; Compute in memory; Embedded DRAM; Indium Gallium Zinc
   Oxide; Multi-level cell
ID DRAM
AB With rapid growth in data intensive applications, there is an ever-increasing need for energy efficient machine learning/AI hardware accelerators. The performance and the energy efficiency of such accelerators are primarily limited due of massive amount of data movement between processing engines and the off-chip memory. This memory wall bottleneck can be mitigated by performing accelerator specific computations in the memory (CIM) array embedded with the rest of the logic blocks. Multiple embedded memory technologies are being explored to advance CIM designs. Among these, embedded Dynamic Random Access Memory (eDRAM) using backend of the line (BEOL) integrated C-Axis Aligned Crystalline ( CAAC) Indium Gallium Zinc Oxide (IGZO) transistors is a promising candidate. IGZO transistor having extremely low leakage when used as an access transistor of the eDRAM bitcell can enable multi-level cell (MLC) eDRAM functionality. Moreover, higher bandwidth can be achieved by 3D stacking multiple layers of BEOL integrated IGZO devices in a monolithic manner improving the CIM performance. In this paper, we analyze various IGZO based eDRAM bitcell topologies and present an IGZO eDRAM CIM architecture. It supports 8-bit inputs/activations and 8-bit signed weights. 2-bit Flash Analog to Digital converter (ADC) is used for MLC weight bit read sensing. A representative neural network model using IGZO eDRAM and peripheral 8-b A/D converters based CIM design achieves 80% Top-1 inference accuracy for the CIFAR-10 dataset, which is within 3% of ideal software accuracy.
C1 [Raman, Siddhartha Raman Sundara; Xie, Shanshan; Kulkarni, Jaydeep P.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Raman, SRS (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM s.siddhartharaman@utexas.edu; jaydeep@austin.utexas.edu
CR Aga S, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P506, DOI 10.1145/3357526.3357532
   [Anonymous], 2012, P 4 IEEE INT MEM WOR
   Belmonte A., 2020, 2020 IEEE INT EL DEV
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chauhan Y. S., 2015, FINFET MODELING IC S
   Fang YP, 2009, 2009 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM, VOLS 1 AND 2, P925, DOI 10.1109/IRPS.2009.5173382
   Fredeman G, 2015, ISSCC DIG TECH PAP I, V58, P316, DOI 10.1109/ISSCC.2015.7063053
   FURUYAMA T, 1989, IEEE J SOLID-ST CIRC, V24, P388, DOI 10.1109/4.18599
   Hamzaoglu F, 2015, IEEE J SOLID-ST CIRC, V50, P150, DOI 10.1109/JSSC.2014.2353793
   Kurd N, 2015, IEEE J SOLID-ST CIRC, V50, P49, DOI [10.1109/JSSC.2014.2368126, 10.1109/ISSCC.2014.6757361]
   Kurokawa Y, 2020, JPN J APPL PHYS, V59, DOI 10.7567/1347-4065/ab650c
   Meinerzhagen P., GAIN CELL EMBEDDED D
   Mittal S, 2015, IEEE T PARALL DISTR, V26, P1524, DOI 10.1109/TPDS.2014.2324563
   Murakami M, 2012, 2012 19TH INTERNATIONAL WORKSHOP ON ACTIVE-MATRIX FLATPANEL DISPLAYS AND DEVICES (AM-FPD): TFT TECHNOLOGIES AND FPD MATERIALS, P171
   Oota M, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993506
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Xie S, IEEE INT SOLID STATE, P2021
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 18
TC 5
Z9 5
U1 3
U2 19
PY 2021
DI 10.1109/ISCAS51556.2021.9401798
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Burns, R
   Lawson, J
   McBain, D
   Soutar, D
AF Burns, Rod
   Lawson, John
   McBain, Duncan
   Soutar, Daniel
GP ACM
TI Accelerated Neural Networks on OpenCL Devices Using SYCL-DNN
SO PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19)
DT Proceedings Paper
CT 8th International Workshop on OpenCL (IWOCL)
CY MAY 13-15, 2019
CL NE Univ, Boston, MA
HO NE Univ
DE SYCL; OpenCL; neural networks; GPGPU; machine learning
AB Over the past few years machine learning has seen a renewed explosion of interest, following a number of studies showing the effectiveness of neural networks in a range of tasks which had previously been considered incredibly hard. Neural networks' effectiveness in the fields of image recognition and natural language processing stems primarily from the vast amounts of data available to companies and researchers, coupled with the huge amounts of compute power available in modern accelerators such as GPUs, FPGAs and ASICs. There are a number of approaches available to developers for utilizing GPGPU technologies such as SYCL, OpenCL and CUDA, however many applications require the same low level mathematical routines. Libraries dedicated to accelerating these common routines allow developers to easily make full use of the available hardware without requiring low level knowledge of the hardware themselves, however such libraries are often provided by hardware manufacturers for specific hardware such as cuDNN [9] for Nvidia hardware or MIOpen [5] for AMD hardware.
   SYCL-DNN is a new open-source library dedicated to providing accelerated routines for neural network operations which are hardware and vendor agnostic. Built on top of the SYCL open standard and written entirely in standard C++, SYCL-DNN allows a user to easily accelerate neural network code for a wide range of hardware using a modern C++ interface. The library is tested on AMD's OpenCL for GPU, Intel's OpenCL for CPU and GPU, ARM's OpenCL for Mali GPUs as well as ComputeAorta's OpenCL for R-Car CV engine and host CPU. In this talk we will present performance figures for SYCL-DNN on this range of hardware, and discuss how high performance was achieved on such a varied set of accelerators with such different hardware features.
C1 [Burns, Rod; Lawson, John; McBain, Duncan; Soutar, Daniel] Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
RP Burns, R (corresponding author), Codeplay Software Ltd, Edinburgh, Midlothian, Scotland.
EM rod@codeplay.com; john@codeplay.com; duncan@codeplay.com;
   daniel.soutar@codeplay.com
CR [Anonymous], ABS151203385 CORR
   [Anonymous], 2014, CUDNN EFFICIENT PRIM
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
NR 7
TC 8
Z9 9
U1 1
U2 1
PY 2019
DI 10.1145/3318170.3318183
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Krzywaniak, A
   Czarnul, P
   Proficz, J
AF Krzywaniak, Adam
   Czarnul, Pawel
   Proficz, Jerzy
TI Dynamic GPU power capping with online performance tracing for energy
   efficient GPU computing using DEPO tool
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
DT Article
DE Energy-aware computing; High-performance computing; Green computing;
   Machine learning; GPU energy optimization
AB GPU accelerators have become essential to the recent advance in computational power of high-performance computing (HPC) systems. Current HPC systems' reaching an approximately 20-30 mega-watt power demand has resulted in increasing CO2 emissions, energy costs and necessitate increasingly complex cooling systems. This is a very real challenge. To address this, new mechanisms of software power control could be employed. In this paper, a dynamic new method of limiting software power is introduced on one of the latest NVIDIA GPUs: a software tool called the Dynamic Energy -Performance Optimiser (DEPO). DEPO minimizes the energy consumption of the CUDA based GPU workloads, with respect to one of the three given metrics: minimum of energy (E), Energy-Delay product (EDP) and Energy-Delay sum (EDS).The tool gathers power measurements from NVIDIA Management Library (NVML). Measuring the application progress at runtime is based on CUDA Profiling Tools Interface (CUPTI) kernel-counting. We have evaluated the DEPO tool on the NVIDIA RTX A4500 and A100 GPUs with machine learning workloads. Depending on the application (training of neural networks: Resnet152, Densenet161, VGG-19 or a GEMM benchmark) for the E target metric, we were able to obtain energy savings exceeding 22% for both NVIDIA A100 and RTX A4500 GPUs while the performance drop has never been higher than 20%. Using one of the bi-objective EDP or EDS metrics allowed finding configurations resulting in 15% or 18% of energy saved with only 8% of performance loss. For most of the experiments the percentage-wise performance penalty is lower than the energy savings. This demonstrates its potential for energy consumption reduction in HPC systems with GPU accelerators.(c) 2023 Elsevier B.V. All rights reserved.
C1 [Krzywaniak, Adam; Czarnul, Pawel] Gdansk Univ Technol, Dept Comp Architecture, Fac Elect Telecommun & Informat, Narutowicza 11-12, PL-80233 Gdansk, Poland.
   [Proficz, Jerzy] Ctr Informat Tricity Acad Supercomp & NetworK CI T, Narutowicza 11-12, PL-80233 Gdansk, Poland.
RP Krzywaniak, A (corresponding author), Gdansk Univ Technol, Dept Comp Architecture, Fac Elect Telecommun & Informat, Narutowicza 11-12, PL-80233 Gdansk, Poland.
EM adam.krzywaniak@pg.edu.pl; pczarnul@eti.pg.edu.pl; jerp@task.gda.pl
CR Advanced Micro Devices Inc, 2022, ROCPR US GUID, V5.1
   Arafa Yehia, 2020, 17 ACM INT C COMP FR
   Cebrián JM, 2012, IEEE SYM PARA DISTR, P1014, DOI 10.1109/IPDPSW.2012.124
   Czarnul P, 2018, PARALLEL PROGRAMMING
   Czarnul P, 2020, SCI PROGRAMMING-NETH, V2020, DOI 10.1155/2020/4176794
   Czarnul P, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/8348791
   Czarnul P, 2014, LECT NOTES COMPUT SC, V8314, P66, DOI 10.1007/978-3-642-45249-9_5
   Daher AW, 2022, COMPUTING, V104, P2453, DOI 10.1007/s00607-022-01096-z
   Daher AW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196526
   Dongarra Jack, 2022, PARALLEL PROCESSING
   DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170
   Gajger T, 2020, SCALABLE COMPUT-PRAC, V21, P689, DOI 10.12694/scpe.v21i4.1807
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Kai Ma, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P48, DOI 10.1109/ICPP.2012.31
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kinghorn Donald, 2022, NVIDIA GPU POWER LIM
   Krzywaniak Adam, 2020, Parallel Processing and Applied Mathematics. 13th International Conference, PPAM 2019. Revised Selected Papers. Lecture Notes in Computer Science (LNCS 12044), P123, DOI 10.1007/978-3-030-43222-5_11
   Krzywaniak A, 2022, SOFTWARE PRACT EXPER, V52, P2598, DOI 10.1002/spe.3139
   Krzywaniak Adam, 2022, LECT NOTES COMPUT SC
   Laccetti G, 2022, INT SYMP PARA DISTR, P78, DOI 10.1109/ISPDC55340.2022.00020
   Lapegna Marco, 2021, SENSORS-BASEL, V21
   Maza Marc Moreno, 2019, KLARAPTOR TOOL DYNAM
   McDonald Joseph, 2022, GREAT POWER GREAT RE
   NVIDIA, 2022, CUPTI CUDA PROF TOOL
   NVIDIA Corporation, 2007, NVML API REF GUID
   NVIDIA Corporation, 2022, NSIGHT COMP
   NVIDIA Corporation, 2022, PROF US GUID
   Patki T, 2019, PROCEEDINGS OF WORKS19: THE 2019 14TH IEEE/ACM WORKFLOWS IN SUPPORT OF LARGE-SCALE SCIENCE (WORKS), P31, DOI 10.1109/WORKS49585.2019.00009
   Rethinagiri Santhosh Kumar, 2015, 2015 28 IEEE INT SYS, P209
   Sachan A, 2022, MICROPROCESS MICROSY, V94, DOI 10.1016/j.micpro.2022.104664
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Villa O, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P372, DOI 10.1145/3352460.3358307
   Volkov V, 2008, INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P499
   Wang FR, 2022, IEEE T PARALL DISTR, V33, P2943, DOI 10.1109/TPDS.2021.3137867
   Yang C, 2020, CONCURR COMP-PRACT E, V32, DOI 10.1002/cpe.5547
   Yang Charlene, 2020, HIERARCHICAL ROOFLIN
   Yokogawa Meters Instruments Corporation, 2016, WT310WT310HCWT332WT3, V3rd
   You Jie, 2022, ZEUS UNDERSTANDING O
   Yousefpour A, 2019, J SYST ARCHITECT, V98, P289, DOI 10.1016/j.sysarc.2019.02.009
   Zhang H, 2019, PROCEEDINGS OF PROTOOLS 2019: 2019 IEEE/ACM INTERNATIONAL WORKSHOP ON PROGRAMMING AND PERFORMANCE VISUALIZATION TOOLS (PROTOOLS), P1, DOI 10.1109/ProTools49597.2019.00006
   Zhou KR, 2021, PARALLEL COMPUT, V108, DOI 10.1016/j.parco.2021.102837
   Zhou KR, 2021, INT SYM CODE GENER, P115, DOI 10.1109/CGO51591.2021.9370339
   Zhou KR, 2020, PROCEEDINGS OF THE 25TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '20), P415, DOI 10.1145/3332466.3374534
NR 43
TC 1
Z9 1
U1 2
U2 2
PD AUG
PY 2023
VL 145
BP 396
EP 414
DI 10.1016/j.future.2023.03.041
EA APR 2023
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU He, Q
   Cheng, XH
   Zhuang, FZ
   Shi, ZZ
AF He, Qing
   Cheng, Xiaohu
   Zhuang, Fuzhen
   Shi, Zhongzhi
GP IEEE
TI Parallel Feature Selection Using Positive Approximation Based on
   MapReduce
SO 2014 11TH INTERNATIONAL CONFERENCE ON FUZZY SYSTEMS AND KNOWLEDGE
   DISCOVERY (FSKD)
DT Proceedings Paper
CT 11th International Conference on Fuzzy Systems and Knowledge Discovery
   (FSKD)
CY AUG 19-21, 2014
CL Xiamen, PEOPLES R CHINA
AB Over the last few decades, feature selection has been a hot research area in pattern recognition and machine learning, and many famous feature selection algorithms have been proposed. Among them, feature selection using positive approximation(FSPA) is an accelerator for traditional rough set based feature selection algorithms, which can significantly reduce the running time. However, FSPA still cannot handle large scale and high dimension dataset due to the memory constraints. In this paper, we propose a parallel implementation of FSPA using MapReduce framework, which is a programming model for processing large scale datasets. The experimental results demonstrate that the proposed algorithm can process large scale and high dimension dataset efficiently on commodity computers.
C1 [He, Qing; Cheng, Xiaohu; Zhuang, Fuzhen; Shi, Zhongzhi] Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
   [Cheng, Xiaohu] Univ Chinese Acad Sci, Beijing 100049, Peoples R China.
RP He, Q (corresponding author), Chinese Acad Sci, Inst Comp Technol, Key Lab Intelligent Informat Proc, Beijing 100190, Peoples R China.
CR [Anonymous], HIGH PERFORMANCE DAT
   [Anonymous], 2007, NIPS
   Dash M, 2000, LECT NOTES ARTIF INT, V1805, P98
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   He Q, 2010, LECT NOTES ARTIF INT, V6401, P646
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   KIRA K, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P129
   Kohavi R, 1997, ARTIF INTELL, V97, P273, DOI 10.1016/S0004-3702(97)00043-X
   Lee CK, 2006, INFORM PROCESS MANAG, V42, P155, DOI 10.1016/j.ipm.2004.08.006
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   PAWLAK Z, 1982, INT J COMPUT INF SCI, V11, P341, DOI 10.1007/BF01001956
   Qian YH, 2008, FUZZY SET SYST, V159, P2353, DOI 10.1016/j.fss.2007.12.016
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Qing He, 2010, 2010 3rd International Symposium on Knowledge Acquisition and Modeling (KAM 2010), P338, DOI 10.1109/KAM.2010.5646172
   Reunanen J., 2003, Journal of Machine Learning Research, V3, P1371, DOI 10.1162/153244303322753715
   Shankland Stephen, 2008, CNET NEWS BLOG  0530
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
NR 18
TC 8
Z9 8
U1 0
U2 4
PY 2014
BP 397
EP 402
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Srikanth, S
   Jain, A
   Conte, TM
   Debenedictis, EP
   Cook, J
AF Srikanth, Sriseshan
   Jain, Anirudh
   Conte, Thomas M.
   Debenedictis, Erik P.
   Cook, Jeanine
TI SortCache: Intelligent Cache Management for Accelerating Sparse Data
   Workloads
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE Sparse matrix; intelligent cache; graph analytics; spgemm; pruned
   convolutions
ID MATRIX MULTIPLICATION; PERFORMANCE; ALGORITHMS; LOOP
AB Sparse data applications have irregular access patterns that stymie modern memory architectures. Although hyper-sparse workloads have received considerable attention in the past, moderately-sparse workloads prevalent in machine learning applications, graph processing and HPC have not. Where the former can bypass the cache hierarchy, the latter fit in the cache. This article makes the observation that intelligent, near-processor cache management can improve bandwidth utilization for data-irregular accesses, thereby accelerating moderately-sparse workloads. We propose SortCache, a processor-centric approach to accelerating sparse workloads by introducing accelerators that leverage the on-chip cache subsystem, with minimal programmer intervention.
C1 [Srikanth, Sriseshan; Jain, Anirudh; Conte, Thomas M.] Georgia Inst Technol, Sch Comp Sci, 266 Ferst Dr, Atlanta, GA 30332 USA.
   [Debenedictis, Erik P.] Zettaflops LLC, 1415 Canyon Rim Dr NE, Albuquerque, NM 87112 USA.
   [Cook, Jeanine] Sandia Natl Labs, POB 5800, Albuquerque, NM 87185 USA.
RP Srikanth, S (corresponding author), Georgia Inst Technol, Sch Comp Sci, 266 Ferst Dr, Atlanta, GA 30332 USA.
EM seshu6392@gmail.com; anirudh.j@gatech.edu; conte@gatech.edu;
   erikdebenedictis@gmail.com; jeacook@sandia.gov
CR Abel A, 2014, INT SYM PERFORM ANAL, P141, DOI 10.1109/ISPASS.2014.6844475
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Anderson Karl, 2015, FIREHOSE STREAMING B
   [Anonymous], 2003, AUTOMATIC PERFORMANC
   [Anonymous], 2002, P ACM SIGMOD INT C M
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Barredo A, 2019, INT CONFER PARA, P482, DOI 10.1109/PACT.2019.00056
   Besta M, 2017, HPDC'17: PROCEEDINGS OF THE 26TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P93, DOI 10.1145/3078597.3078616
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Buluç A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P1876
   Chan TM, 2010, SIAM J COMPUT, V39, P2075, DOI 10.1137/08071990X
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   DeBenedictis EP, 2017, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC.2017.8091044
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Ding C, 1999, ACM SIGPLAN NOTICES, V34, P229, DOI 10.1145/301631.301670
   Duarte F, 2010, IEEE T COMPUT, V59, P1494, DOI 10.1109/TC.2010.41
   Duff I. S., 1979, ACM Transactions on Mathematical Software, V5, P18, DOI 10.1145/355815.355817
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Duff IS., 2017, DIRECT METHODS SPARS, V2nd edition
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fujiki D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P397, DOI 10.1145/3307650.3322257
   Gilbert JR, 2007, LECT NOTES COMPUT SC, V4699, P260
   GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Guowei Zhang, 2021, ASPLOS 2021: Proceedings of the 26th International Conference on Architectural Support for Programming Languages and Operating Systems, P687, DOI 10.1145/3445814.3446702
   Gustavson F. G., 1978, ACM Transactions on Mathematical Software, V4, P250, DOI 10.1145/355791.355796
   Gustavson F. G., 1972, SPARSE MATRICES THEI, P41
   Hammarlund P, 2014, IEEE MICRO, V34, P6, DOI 10.1109/MM.2014.10
   Han S., 2015, ARXIV151000149
   Hapla V, 2013, LECT NOTES COMPUT SC, V7782, P192, DOI 10.1007/978-3-642-36803-5_14
   Intel, 2019, INTEL 64 IA 32 ARCHI
   Intel Labs, SKIMCAFFE
   ITOH S, 1995, COMPUT PHYS COMMUN, V88, P173, DOI 10.1016/0010-4655(95)00031-A
   Jain A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P231
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jun SW, 2018, CONF PROC INT SYMP C, P411, DOI 10.1109/ISCA.2018.00042
   Kandemir M, 1999, IEEE T COMPUT, V48, P159, DOI 10.1109/12.752657
   Kang MG, 2015, IEEE INT SYMP CIRC S, P2505, DOI 10.1109/ISCAS.2015.7169194
   Kepner J, 2011, SOFTW ENVIRON TOOLS, V22, P1, DOI 10.1137/1.9780898719918
   Kharbutli M, 2004, 10TH INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER ARCHITECTURE, PROCEEDINGS, P288, DOI 10.1109/HPCA.2004.10015
   Kocberber Onur, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P468, DOI 10.1145/2540708.2540748
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   La Fratta Patrick A., 2009, P WORKSH CHIP MULT M, V1
   Li YA, 2009, PROC INT CONF DATA, P1303, DOI 10.1109/ICDE.2009.226
   Melsted P, 2011, BMC BIOINFORMATICS, V12, DOI 10.1186/1471-2105-12-333
   Moazeni M, 2009, 2009 IEEE 7TH SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS (SASP 2009), P43, DOI 10.1109/SASP.2009.5226334
   Mukkara Anurag, 2019, MICR 52 ANN IEEEACM, DOI DOI 10.1145/3352460.3358254
   North Carolina State University, FREEPDK
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Park Jongsoo, 2016, ARXIV PREPRINT ARXIV
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Saule E, 2014, LECT NOTES COMPUT SC, V8384, P559, DOI 10.1007/978-3-642-55224-3_52
   Srikanth S, 2019, ACM T ARCHIT CODE OP, V16, DOI 10.1145/3355396
   Srikanth S, 2018, INT S HIGH PERF COMP, P696, DOI 10.1109/HPCA.2018.00065
   Srikanth S, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P220
   Suhendra V, 2005, REAL TIM SYST SYMP P, P223
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Venkat A, 2015, ACM SIGPLAN NOTICES, V50, P521, DOI [10.1145/2737924.2738003, 10.1145/2813885.2738003]
   Zhang GW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P440, DOI 10.1145/3352460.3358272
   Zhou Tong, 2020, INTREPYDD PERFORMANC, P65, DOI [10.1145/3426428.3426915, DOI 10.1145/3426428.3426915]
   Zhu QL, 2013, IEEE HIGH PERF EXTR
NR 67
TC 0
Z9 0
U1 0
U2 0
PD DEC
PY 2021
VL 18
IS 4
AR 56
DI 10.1145/3473332
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Grünhagen, A
   Branlard, J
   Eichler, A
   Martino, G
   Fey, G
   Tropmann-Frick, M
AF Gruenhagen, Arne
   Branlard, Julien
   Eichler, Annika
   Martino, Gianluca
   Fey, Goerschwin
   Tropmann-Frick, Marina
GP IEEE Comp Soc
TI Fault Analysis of the Beam Acceleration Control System at the European
   XFEL using Data Mining
SO 2021 IEEE 30TH ASIAN TEST SYMPOSIUM (ATS 2021)
SE Asian Test Symposium Proceedings
DT Proceedings Paper
CT IEEE 30th Asian Test Symposium (ATS)
CY NOV 22-24, 2021
CL ELECTR NETWORK
DE fault analysis; anomaly detection; clustering; feature extraction;
   sensor data
AB The European X-Ray Free-Electron Laser (EuXFEL) relies like other high integrity systems on several sub systems. The Low Level Radio Frequency (LLRF) sub system of the EuXFEL is responsible for the correct acceleration of electron bunches. The LLRF system comprises several embedded components that are directly connected to the accelerator hard- ware. Due to the high complexity of the LLRF system, unforeseen machine trips occur regularly.
   In this work we built the basis for a mechanism that automatically identities faulty behavior of the embedded components. To achieve that, we performed two different experiments, where a faulty behavior was artificially injected to the system. We analyzed the experiment data, performed a feature extraction and applied different machine learning methods. We used basic anomaly detection and basic clustering methods for identifying the faulty data elements. Additionally, we used a support vector machine for modelling the systems behavior. The selected algorithms are compared with respect to their ability to classify LLRF data correctly.
C1 [Gruenhagen, Arne; Martino, Gianluca; Fey, Goerschwin] Hamburg Univ Technol TUHH, Hamburg, Germany.
   [Gruenhagen, Arne; Branlard, Julien; Eichler, Annika; Martino, Gianluca] German Electron Synchrotron DESY, Hamburg, Germany.
   [Gruenhagen, Arne; Tropmann-Frick, Marina] Hamburg Univ Appl Sci HAW, Hamburg, Germany.
RP Grünhagen, A (corresponding author), Hamburg Univ Technol TUHH, Hamburg, Germany.; Grünhagen, A (corresponding author), German Electron Synchrotron DESY, Hamburg, Germany.; Grünhagen, A (corresponding author), Hamburg Univ Appl Sci HAW, Hamburg, Germany.
CR Abela R., 2006, XFEL EUROPEAN X RAY
   [Anonymous], 2005, SUPPORT VECTOR MACHI
   Benesty J, 2009, SPRINGER TOP SIGN PR, V2, P37, DOI 10.1007/978-3-642-00296-0_5
   Branlard J., 2012, EUROPEAN XFEL LLRF S
   Brownlee J., 2018, MACHINE LEARNING MAS, V2019
   Calaga R, 2004, PHYS REV SPEC TOP-AC, V7, DOI 10.1103/PhysRevSTAB.7.042801
   Fol E., 2019, UNSUPERVISED MACHINE
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Liu FT, 2008, IEEE DATA MINING, P413, DOI 10.1109/ICDM.2008.17
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Martino G., 2021, 2021 24 EUR C DIG SY
   Reynolds D, 2009, ENCY BIOMETRICS, P827
   Wilkin T., 2017, 2017 IEEE INT C FUZZ, V2017, P1
NR 13
TC 2
Z9 2
U1 0
U2 1
PY 2021
BP 61
EP 66
DI 10.1109/ATS52891.2021.00023
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Frost, J
   Stechele, W
   Maehle, E
AF Frost, Jan
   Stechele, Walter
   Maehle, Erik
TI Self-reconfigurable control architecture for complex mobile robots
SO IT-INFORMATION TECHNOLOGY
DT Article
DE Organic computing; self-reconfigurable architecture; FPGA; mobile robot;
   SLAM
AB Advanced mobile robot systems need to accomplish increasingly complex task sets. However, to solve demanding problems, they are typically optimized to a very restricted set of tasks and environments. This work will therefore propose a self-reconfigurable software and hardware architecture to allow the dynamic optimization of a robot system depending on the current situation, i.e. the current task, the robot inner state, and the environment. The proposed framework is based on organic computing principles and unsupervised machine learning techniques. It further uses dynamically reconfigurable Field Programmable Gate Arrays (FPGA) as hardware accelerators. Preliminary results will be presented, which demonstrate the feasibility of the self-reconfiguration approach.
C1 [Frost, Jan; Maehle, Erik] Univ Lubeck, Inst Comp Engn, D-23562 Lubeck, Germany.
   [Stechele, Walter] Tech Univ Munich, Inst Integrated Syst, D-80290 Munich, Germany.
RP Frost, J (corresponding author), Univ Lubeck, Lubeck, Germany.
EM frost@iti.uni-luebeck.de; walter.stechele@tum.de;
   maehle@iti.uni-luebeck.de
CR Al-Homsy A, 2012, ADAPTIVE MOBILE ROBOTICS, P173
   Al-Homsy A, 2013, NATURE INSPIRED MOBILE ROBOTICS, P215
   Al-Homsy A., 2012, P IEEE INT S ROB SEN, P43
   Albiez J., 2002, P 7 INT C SIM AD BEH, P118
   Auf AES, 2008, INT FED INFO PROC, V268, P115
   Bohren Jonathan, 2011, IEEE International Conference on Robotics and Automation, P5568
   Brockmann W, 2011, AUTON SYST, P385, DOI 10.1007/978-3-0348-0130-0_25
   Brun Y., 2009, ENG SELF ADAPTIVE SY, P48, DOI [10.1007/978-3-642-02161-9_3, DOI 10.1007/978-3-642-02161-9_3]
   Endres F, 2012, IEEE INT CONF ROBOT, P1691, DOI 10.1109/ICRA.2012.6225199
   Hartmann J., 2013, LNI, V220, P2742
   Hartmann J, 2013, LECT NOTES COMPUT SC, V7767, P232, DOI 10.1007/978-3-642-36424-2_20
   Hutter Frank, 2011, Learning and Intelligent Optimization. 5th International Conference, LION 5. Selected Papers, P507, DOI 10.1007/978-3-642-25566-3_40
   Jakimovski B, 2010, CLIMBING WALKING ROB
   Lange AB, 2013, IEEE INT C INT ROBOT, P3899, DOI 10.1109/IROS.2013.6696914
   Maas R., 2011, P INT C ARCH COMP SY, P58
   Maehle E, 2011, AUTON SYST, P517, DOI 10.1007/978-3-0348-0130-0_34
   Strasdat H, 2011, IEEE I CONF COMP VIS, P2352, DOI 10.1109/ICCV.2011.6126517
   Sturm J, 2012, IEEE INT C INT ROBOT, P573, DOI 10.1109/IROS.2012.6385773
   Wilson SW, 1995, EVOL COMPUT, V3, P149, DOI 10.1162/evco.1995.3.2.149
   Zeppenfeld J., 2008, INFORMATIK 2008 BEHE, V134, P771
NR 20
TC 0
Z9 0
U1 0
U2 0
PD APR
PY 2015
VL 57
IS 2
SI SI
BP 122
EP 129
DI 10.1515/itit-2014-1063
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Ditzel, DR
AF Ditzel, David R.
CA Esperanto Team
TI Accelerating ML Recommendation With Over 1,000 RISC-V/Tensor Processors
   on Esperanto's ET-SoC-1 Chip
SO IEEE MICRO
DT Article
DE Low voltage; Tensors; Memory management; Energy efficiency; Servers;
   Hardware; Pipelines
AB Machine learning (ML) recommendation workloads have demanding performance and memory requirements and, to date, have largely been run on servers with x86 processors. To accelerate these workloads (and others), Esperanto Technologies has implemented over 1,000 low-power RISC-V processors on a single chip along with a distributed on-die memory system. The ET-SoC-1 chip is designed to compute at peak rates between 100 and 200 TOPS and to be able to run ML recommendation workloads while consuming less than 20 W of power. Preliminary data presented at the Hot Chips 33 Conference projected over a hundred times better performance per watt for an Esperanto-based accelerator card versus a standard server platform for the MLPerf Deep Learning Recommendation Model benchmark.
C1 [Ditzel, David R.; Esperanto Team] Esperanto Technol Inc, Mountain View, CA 94040 USA.
RP Ditzel, DR (corresponding author), Esperanto Technol Inc, Mountain View, CA 94040 USA.
EM dave@esperanto.ai
CR Anderson M., ARXIV210704140V1, P2021
   [Anonymous], 2012, CASE INFINITE DATA C
   [Anonymous], 2018, MICROPROCESSOR REP, P1
   [Anonymous], MLPERF DLRM INFERENC
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Park J., 2018, ARXIV181109886V2
   Smelyanskiy M., 2019, PROC LINLEY FALL PRO
   Smelyanskiy M., 2019, PROC HARDWARE SUMMIT
   Taylor MB, 2012, DES AUT CON, P1131
   Xekalakis P., 2018, PROC RISC V SUMMIT P
NR 10
TC 1
Z9 1
U1 1
U2 5
PD MAY-JUN
PY 2022
VL 42
IS 3
BP 31
EP 38
DI 10.1109/MM.2022.3140674
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Liu, YQ
   Derman, CE
   Calderoni, G
   Bahar, RI
AF Liu, Yanqi
   Derman, Can Eren
   Calderoni, Giuseppe
   Bahar, R. Iris
GP IEEE
TI Hardware Acceleration of Robot Scene Perception Algorithms
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
DE robotics; Monte -Carlo sampling; low-power
AB Hybrid machine learning algorithms that combine deep learning with probabilistic inference techniques provide highly accurate scene perception for robot manipulation. In particular, a 2 -stage approach that combines object detection using convolutional neural networks with Moide-Carlo sampling for pose estimation has been shown to perform particularly well under adversarial scenarios. Unfortunately, this accuracy comes at the cost of high computational complexity, which affects runtime, resource utilization, and energy consumption. This paper describes various challenges in developing complexity-aware techniques for robust robot perception and presents a novel hardware accelerator that addresses these challenge. Experimental results show our design is at least 30% faster and consumes 97% less energy compared to an implementation on a high-end GPU. Compared to a low-power CIPU implementation, our design is 95% faster while consuming 96% less energy, demonstrating that accurate, energy -efficient scene perception is possible in real time with targeted hardware acceleration.
C1 [Liu, Yanqi] Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
   [Derman, Can Eren] Brown Univ, Sch Engn, Providence, RI 02912 USA.
   [Calderoni, Giuseppe] Politecn Torino, Dept Elect & Telecommun, Turin, Italy.
   [Bahar, R. Iris] Brown Univ, Sch Engn, Dept Comp Sci, Providence, RI 02912 USA.
   [Calderoni, Giuseppe] Brown Univ, Providence, RI 02912 USA.
RP Liu, YQ (corresponding author), Brown Univ, Dept Comp Sci, Providence, RI 02912 USA.
EM yanqi_liu@brown.edu; can_derman@alumni.brown.edu; iris_bahar@brown.edu
CR [Anonymous], 2018, CORL
   Bach S, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0130140
   Chen XT, 2019, IEEE INT C INT ROBOT, P3988, DOI [10.1109/iros40897.2019.8967983, 10.1109/IROS40897.2019.8967983]
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gualtieri Marcus, 2017, ABS170705615 ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Kalos M. H., 1986, MONTE CARLO METHODS
   Kosuge A, 2019, ANN IEEE SYM FIELD P, P331, DOI 10.1109/FCCM.2019.00072
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Laird JE, 2017, IEEE INTELL SYST, V32, P6, DOI 10.1109/MIS.2017.3121552
   Liu Y., 2020, IEEE ACM INT C FIELD
   Liu YQ, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243493
   Montavon G., 2019, EXPLAINABLE INTERPRE, V11700, P193, DOI [10.1007/978-3-030-28954-6_10/COVER, DOI 10.1007/978-3-030-28954-6_10]
   Murai Riku, 2019, VISUAL ODOMETRY USIN
   Pineda J., 1988, Computer Graphics, V22, P17, DOI 10.1145/378456.378457
   Redmon J., 2016, ARXIV160207360, P779
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Schaeferling M, 2012, INT J RECONFIGURABLE, V2012, DOI 10.1155/2012/368351
   Schäffer L, 2018, I S INTELL SYST INFO, P149
   Schwiegelshohn Fynn, 2015, Applied Reconfigurable Computing. 11th International Symposium, ARC 2015. Proceedings: LNCS 9040, P91, DOI 10.1007/978-3-319-16214-0_8
   Sileshi BG, 2016, IEEE COMP SOC ANN, P591, DOI 10.1109/ISVLSI.2016.66
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smilkov Daniel, 2017, ABS170603825 ARXIV
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
   Sui ZQ, 2017, IEEE INT C INT ROBOT, P3281, DOI 10.1109/IROS.2017.8206164
   Sui Zhiqiang, 2018, ARXIV180804969
   ten Pas A, 2016, SPRINGER TRAC ADV RO, V109, P623, DOI 10.1007/978-3-319-23778-7_41
   Varley J, 2015, IEEE INT C INT ROBOT, P4415, DOI 10.1109/IROS.2015.7354004
   Xiang Y, 2018, ROBOTICS: SCIENCE AND SYSTEMS XIV
   Zintgraf Luisa M., 2017, INT C LEARN REPR ICL
NR 30
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1145/3400302.3415766
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering,
   Manufacturing; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ghielmetti, N
   Loncar, V
   Pierini, M
   Roed, M
   Summers, S
   Aarrestad, T
   Petersson, C
   Linander, H
   Ngadiuba, J
   Lin, KL
   Harris, P
AF Ghielmetti, Nicolo
   Loncar, Vladimir
   Pierini, Maurizio
   Roed, Marcel
   Summers, Sioni
   Aarrestad, Thea
   Petersson, Christoffer
   Linander, Hampus
   Ngadiuba, Jennifer
   Lin, Kelvin
   Harris, Philip
TI Real-time semantic segmentation on FPGAs for autonomous vehicles with
   hls4ml
SO MACHINE LEARNING-SCIENCE AND TECHNOLOGY
DT Article
DE FPGA; computer vision; deep learning; hls4ml; machine learning;
   autonomous vehicles; semantic segmentation
AB In this paper, we investigate how field programmable gate arrays can serve as hardware accelerators for real-time semantic segmentation tasks relevant for autonomous driving. Considering compressed versions of the ENet convolutional neural network architecture, we demonstrate a fully-on-chip deployment with a latency of 4.9 ms per image, using less than 30% of the available resources on a Xilinx ZCU102 evaluation board. The latency is reduced to 3 ms per image when increasing the batch size to ten, corresponding to the use case where the autonomous vehicle receives inputs from multiple cameras simultaneously. We show, through aggressive filter reduction and heterogeneous quantization-aware training, and an optimized implementation of convolutional layers, that the power consumption and resource utilization can be significantly reduced while maintaining accuracy on the Cityscapes dataset.
C1 [Ghielmetti, Nicolo; Loncar, Vladimir; Pierini, Maurizio; Roed, Marcel; Summers, Sioni] European Org Nucl Res CERN, CH-1211 Geneva 23, Switzerland.
   [Aarrestad, Thea] Swiss Fed Inst Technol, Inst Particle Phys & Astrophys, CH-8093 Zurich, Switzerland.
   [Petersson, Christoffer] Zenseact, S-41756 Gothenburg, Sweden.
   [Linander, Hampus] Univ Gothenburg, S-40530 Gothenburg, Sweden.
   [Ngadiuba, Jennifer] Fermilab Natl Accelerator Lab, Batavia, IL 60510 USA.
   [Lin, Kelvin] Univ Washington, Seattle, WA 98195 USA.
   [Harris, Philip] MIT, Cambridge, MA 02139 USA.
   [Ghielmetti, Nicolo] Politecn Milan, Milan, Italy.
   [Loncar, Vladimir] Inst Phys Belgrade, Belgrade, Serbia.
   [Roed, Marcel] Univ Oxford, Oxford, England.
   [Petersson, Christoffer] Chalmers Univ Technol, Gothenburg, Sweden.
   [Lin, Kelvin] Amazon, Seattle, WA USA.
RP Harris, P (corresponding author), MIT, Cambridge, MA 02139 USA.
EM pcharris@mit.edu
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   [Anonymous], ZCU102 EV BOARD
   [Anonymous], 2009, LARGE SCALE DEEP UNS
   Apollinari G., 2017, TECH REP CERN2017 00, DOI [10.23731/CYRM-2017-004, DOI 10.23731/CYRM-2017-004]
   Banbury Colby R., 2020, BENCHMARKING TINYML
   Coelho C., 2019, QKERAS
   Coelho CN, 2021, NAT MACH INTELL, V3, P675, DOI 10.1038/s42256-021-00356-5
   Cordts M, 2016, Arxiv, DOI arXiv:1604.01685
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Fahim F., 2021, TINYML RES S 2021
   Francescato S, 2021, EUR PHYS J C, V81, DOI 10.1140/epjc/s10052-021-09875-2
   Garrett M A, ARXIV
   Gholami Amir, 2021, arXiv
   Girshick R, 2013, ARXIV, DOI DOI 10.48550/ARXIV.1311.2524
   Heintz A., 2020, 3 MACHINE LEARNING P, V12
   Iiyama Y, 2021, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.598927
   Holder CJ, 2022, Arxiv, DOI arXiv:2206.08605
   Ngadiuba J, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/aba042
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Summers S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/P05026
   Sun C, 2022, Arxiv, DOI arXiv:2202.04976
   Weisheng Jia, 2021, ICCAI 2021: 2021 7th International Conference on Computing and Artificial Intelligence, P321, DOI 10.1145/3467707.3467756
   Whetton B., 2016, KERAS SURG
NR 23
TC 1
Z9 1
U1 2
U2 11
PD DEC 1
PY 2022
VL 3
IS 4
AR 045011
DI 10.1088/2632-2153/ac9cb5
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Kong, YB
   Lee, EJ
   Hur, MG
   Park, JH
   Park, YD
   Yang, SD
AF Kong, Young Bae
   Lee, Eun Je
   Hur, Min Goo
   Park, Jeong Hoon
   Park, Yong Dae
   Yang, Seung Dae
TI Support vector machine based fault detection approach for RFT-30
   cyclotron
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE Cyclotron; Fault detection; Support vector machine; Principal component
   analysis
AB An RFT-30 is a 30 MeV cyclotron used for radioisotope applications and radiopharmaceutical researches. The RFT-30 cyclotron is highly complex and includes many signals for control and monitoring of the system. It is quite difficult to detect and monitor the system failure in real time. Moreover, continuous monitoring of the system is hard and time-consuming work for human operators. In this paper, we propose a support vector machine (SVM) based fault detection approach for the RFT-30 cyclotron. The proposed approach performs SVM learning with training samples to construct the classification model. To compensate the system complexity due to the large-scale accelerator, we utilize the principal component analysis (PCA) for transformation of the original data. After training procedure, the proposed approach detects the system faults in real time. We analyzed the performance of the Proposed approach utilizing the experimental data of the RFT-30 cyclotron. The performance results show that the proposed SVM approach can provide an efficient way to control the cyclotron system. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Kong, Young Bae; Lee, Eun Je; Hur, Min Goo; Park, Jeong Hoon; Park, Yong Dae; Yang, Seung Dae] Korea Atom Energy Res Inst, Radiat Instrument Res Div, Jeollabuk Do 580185, South Korea.
RP Kong, YB (corresponding author), Korea Atom Energy Res Inst, Radiat Instrument Res Div, Jeollabuk Do 580185, South Korea.
EM ybkong@kaeri.re.kr
CR Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Canu S., 2005, PERCEPTION SYSTEMS I
   Gustafsson J, 1997, NUCL INSTRUM METH A, V385, P189, DOI 10.1016/S0168-9002(96)00922-9
   Jolliffe I. T., 2002, PRINCIPAL COMPONENTS
   KOLVO HN, 1994, CONTROL ENG PRACT, V2, P89
   Lee JW, 1998, NUCL INSTRUM METH A, V402, P14, DOI 10.1016/S0168-9002(97)01063-2
   SORSA T, 1993, AUTOMATICA, V29, P843, DOI 10.1016/0005-1098(93)90090-G
   Swarup K. S., 1991, Proceedings of the First International Forum on Applications of Neural Networks to Power Systems (Cat. No.91TH0374-9), P102, DOI 10.1109/ANN.1991.213505
   Vapnik VN, 1999, IEEE T NEURAL NETWOR, V10, P988, DOI 10.1109/72.788640
NR 9
TC 2
Z9 3
U1 0
U2 6
PD OCT 21
PY 2016
VL 834
BP 143
EP 148
DI 10.1016/j.nima.2016.07.054
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU André, J
   Strati, F
   Klimovic, A
AF Andre, Joel
   Strati, Foteini
   Klimovic, Ana
GP ASSOC COMPUTING MACHINERY
TI Exploring Learning Rate Scaling Rules for Distributed ML Training on
   Transient Resources
SO PROCEEDINGS OF THE 3RD INTERNATIONAL WORKSHOP ON DISTRIBUTED MACHINE
   LEARNING, DISTRIBUTEDML 2022
DT Proceedings Paper
CT 3rd International Workshop on Distributed Machine Learning
   (DistributedML) Part of 18th International Conference on Emerging
   Networking Experiments and Technologies (CoNEXT)
CY DEC09, 2022
CL Rome, ITALY
DE Elastic Deep Learning; Distributed Training; Spot Instances
AB Training Machine Learning (ML) models to convergence is a longrunning and expensive procedure, as it requires large clusters of high-end accelerators such as GPUs and TPUs. Many ML frame-works have proposed elastic distributed training, which enables using transient resources such as spot VMs in the cloud, reducing the overall cost. However, the availability of transient resources varies over time, creating an inherently dynamic environment that requires special handling of training hyperparameters. Techniques such as gradient accumulation enable using the same hyper-parameters upon resource preemptions, however sequentially accumulating gradients stalls synchronous distributed training. On the other hand, scaling the batch size according to the available resources requires tuning of other hyperparameters, such as the learning rate. In this work, we study how learning rate scaling rules perform under dynamic environments when the batch size changes frequently and drastically, as we observed in real cloud clusters. We build a PyTorch-based system to evaluate Stochastic Gradient Descent on Image Recognition and Object Detection tasks under various learning rate scaling rules and resource availability traces. We observe minor or no degradation in model convergence when choosing the correct learning rate scaling rule. Identifying the appropriate scaling rule for a given model is non-trivial. Automating this decision remains an open question.
C1 [Andre, Joel; Strati, Foteini; Klimovic, Ana] Swiss Fed Inst Technol, Zurich, Switzerland.
RP André, J (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM joel.andre@inf.ethz.ch; foteini.strati@inf.ethz.ch; aklimovic@ethz.ch
CR [Anonymous], NVID DEEP LEARN EX S
   [Anonymous], FAIRSC
   [Anonymous], AM EC2 SPOT
   [Anonymous], AZ SPOT VIRT MACH
   [Anonymous], MET WORKS NVID BUILD
   [Anonymous], GKE NODE POOLS
   [Anonymous], TROUBL TENS TPU
   [Anonymous], PYT VGG BN IMPL
   [Anonymous], WIKIP DAT
   [Anonymous], TORCH DISTR EL
   [Anonymous], PYT XLA PACK
   [Anonymous], HOR EL
   [Anonymous], GOOGL CLOUD SPOT VMS
   Athlur S, 2022, PROCEEDINGS OF THE SEVENTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '22), P472, DOI 10.1145/3492321.3519584
   Johnson TB, 2020, Arxiv, DOI arXiv:2007.05105
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   github, PYT VGG PRETR REC
   Goyal P, 2018, Arxiv, DOI [arXiv:1706.02677, DOI 10.48550/ARXIV.1706.02677]
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   Hoffer E, 2017, ADV NEUR IN, V30
   Hwang CH, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P721
   J. Shallue Christopher, 2019, Arxiv, DOI arXiv:1811.03600
   Jeon M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P947
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A, 2014, Arxiv, DOI [arXiv:1404.5997, DOI 10.48550/ARXIV.1404.5997]
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Li MZ, 2022, Arxiv, DOI arXiv:2208.14228
   Lin HB, 2019, Arxiv, DOI arXiv:1904.12043
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mathuriya A., 2018, ARXIV
   Or Andrew, 2022, P MACH LEARN SYST 20, P126
   Paszke A, 2019, ADV NEUR IN, V32
   Peng C, 2018, Arxiv, DOI arXiv:1711.07240
   Qiao A, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P1
   Sergeev A, 2018, Arxiv, DOI [arXiv:1802.05799, DOI 10.48550/ARXIV.1802.05799]
   Sharir O, 2020, Arxiv, DOI arXiv:2004.08900
   Sharma P, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303945
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Thorpe J., 2022, CORR, DOI DOI 10.48550/ARXIV.2204.12013
   Tong Wang, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12366), P481, DOI 10.1007/978-3-030-58589-1_29
   Wang TY, 2018, Arxiv, DOI arXiv:1809.00193
   Weng QZ, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P945
   Wu YX, 2018, Arxiv, DOI [arXiv:1803.08494, DOI 10.48550/ARXIV.1803.08494]
   You Y, 2020, Arxiv, DOI [arXiv:1904.00962, DOI 10.48550/ARXIV:1904.00962]
   You Y, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356137
   Zhang G., 2019, WHICH ALGORITHMIC CH
NR 47
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1
EP 8
DI 10.1145/3565010.3569067
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Nagarajan, M
   Sasikumar, A
   Muralidharan, D
   Rajappa, M
AF Nagarajan, Manikandan
   Sasikumar, A.
   Muralidharan, D.
   Rajappa, Muthaiah
TI Fixed point multi-bit approximate adder based convolutional neural
   network accelerator for digit classification inference
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
DT Article
DE Approximate adders; multi-bit adders; CNN accelerator; digit
   classification; deep learning
ID ARCHITECTURE
AB Approximate computing is a rapidly growing technique to speed up applications with less computational effort while maintaining the accuracy of error-resilient applications such as machine learning and deep learning. Inheritance properties of the machine and deep learning process give freedom for the designer to simplify the circuitry to speed up the computation process at the expense of accuracy of computational results. Fundamental blocks of any computation are adders. In order to optimize it for better performance, 2-bit multi-bit approximate adders (MAPX) are proposed in this work which breaks the lengthy carry chain. In contrast with other approximate larger width adders, instead of using accurate adders for the most significant part, here proposed 2-bit MAPX-1 and MAPX-2 adders are arranged in various ways to compose most and least significant parts. Designed 8-bit and 16-bit adders are evaluated for their performance and error characteristics. Proposed 2-bit MAPX-2 shows better error characteristics whose MED is 0.250 while occupying less area and MAPX-1 consumes less power and delay at the cost of accuracy. Among the extended adders, MAPX 8-bit adder design1 outperforms the best performing APX based 8-bit adder design1. The error performance of it is improved by 14%, 42.1% and 50.4% compared to the existing well-performing APX 8-bit Design1, Design2 and Design3 respectively. Similarly, proposed MAPX 16-bit Design1 exhibits overwhelming performance compared to best performing APX 16-bit Design1, and its error performance is improved by 24.3%, 34.9% and 50.3% compared to APX 16-bit Design1, Design2 and Design3 respectively. In order to evaluate the proposed adder for a real application, extended MAPX 16-bit Design1 is fit in the convolution layer of Low Weights Digit Detector (LWDD) convolutional neural network-based digit classification system. Our modified system accelerates the computation process by 1.25 factors while exhibiting the accuracy of 91% and it best fits error-tolerant real applications. All the adders are synthesized and implemented in the Intel Cyclone IV EP4CE22F17C6N FPGA.
C1 [Nagarajan, Manikandan; Sasikumar, A.; Muralidharan, D.; Rajappa, Muthaiah] SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
RP Muralidharan, D (corresponding author), SASTRA Deemed Univ, Sch Comp, Thanjavur, India.
EM murali@core.sastra.edu
CR Algredo-Badillo I, 2019, J INTELL FUZZY SYST, V36, P4425, DOI 10.3233/JIFS-169997
   Almaslukh B, 2018, J INTELL FUZZY SYST, V35, P1609, DOI 10.3233/JIFS-169699
   Almurib HAF, 2016, DES AUT TEST EUROPE, P660
   [Anonymous], 2016, ACM COMPUT SURV
   [Anonymous], 2018, ACCELERATING CNN INF
   Dutt S, 2018, IET COMPUT DIGIT TEC, V12, P206, DOI 10.1049/iet-cdt.2017.0171
   Faraone J, 2020, IEEE T VLSI SYST, V28, P115, DOI 10.1109/TVLSI.2019.2939429
   Gong Y, 2019, MICROELECTRON J, V87, P33, DOI 10.1016/j.mejo.2019.03.011
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Han RJ, 2015, PROCEEDINGS OF 2015 INTERNATIONAL SYMPOSIUM - SAFETY AND HIGH EFFICIENCY MINING IN COAL, P343
   Helwan A, 2018, J INTELL FUZZY SYST, V35, P2215, DOI 10.3233/JIFS-172261
   Kyriakos A, 2019, INT WORKS POW TIM, P135, DOI [10.1109/PATMOS.2019.8862166, 10.1109/patmos.2019.8862166]
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Luo L, 2019, MICROELECTRON J, V87, P45, DOI 10.1016/j.mejo.2019.03.007
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Shafique M., 2015, P DES AUT C
   Shang JW, 2020, IEEE ACCESS, V8, P6045, DOI 10.1109/ACCESS.2019.2962746
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Solovyev R.A., 2018, ARXIV180809945, P1
   Tajasob S, 2019, MICROELECTRON J, V89, P41, DOI 10.1016/j.mejo.2019.04.002
   Wu Y, 2019, IEEE T COMPUT, V68, P21, DOI 10.1109/TC.2018.2859960
   Yang ZX, 2013, 2013 13TH IEEE CONFERENCE ON NANOTECHNOLOGY (IEEE-NANO), P690, DOI 10.1109/NANO.2013.6720793
NR 23
TC 2
Z9 2
U1 1
U2 10
PY 2020
VL 39
IS 6
BP 8521
EP 8528
DI 10.3233/JIFS-189169
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Khudia, DS
   Zamirai, B
   Samadi, M
   Mahlke, S
AF Khudia, Daya S.
   Zamirai, Babak
   Samadi, Mehrzad
   Mahlke, Scott
GP IEEE
TI Rumba: An Online Quality Management System for Approximate Computing
SO 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
DT Proceedings Paper
CT ACM/IEEE 42nd Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 13-17, 2015
CL Portland, OR
AB Approximate computing can be employed for an emerging class of applications from various domains such as multimedia, machine learning and computer vision. The approximated output of such applications, even though not 100% numerically correct, is often either useful or the difference is unnoticeable to the end user. This opens up a new design dimension to trade off application performance and energy consumption with output correctness. However, a largely unaddressed challenge is quality control:" how to ensure the user experience meets a prescribed level of quality. Current approaches either do not monitor output quality or use sampling approaches to check a small subset of the output assuming that it is representative. While these approaches have been shown to produce average errors that are acceptable, they often miss large errors without any means to take corrective actions. To overcome this challenge, we propose Rumba for online detection and correction of large approximation errors in an approximate accelerator-based computing environment. Rumba employs continuous lightweight checks in the accelerator to detect large approximation errors and then fixes these errors by exact re-computation on the host processor: Rumba employs computationally inexpensive output error prediction models for efficient detection. Computing patterns amenable for approximation (e.g., map and stencil) are usually data parallel in nature and Rumba exploits this property for selective correction. Overall, Rumba is able to achieve 2.1x reduction in output error for an unchecked approximation accelerator while maintaining the accelerator performance gains at the cost of reducing the energy savings from 3.2x to 2.2x for a set of applications from different approximate computing domains.
C1 [Khudia, Daya S.; Zamirai, Babak; Samadi, Mehrzad; Mahlke, Scott] Univ Michigan, Ann Arbor, MI 48109 USA.
RP Khudia, DS (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM dskhudia@umich.edu; zamirai@umich.edu; mehrzads@umich.edu;
   mahlke@umich.edu
CR Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Martínez CA, 2012, IEEE T COMPUT, V61, P650, DOI 10.1109/TC.2011.79
   [Anonymous], MITCSAILTR2009042
   [Anonymous], P 41 ANN INT S COMP
   Ansel J, 2011, INT SYM CODE GENER, P85, DOI 10.1109/CGO.2011.5764677
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Bornholt J, 2014, ACM SIGPLAN NOTICES, V49, P51, DOI 10.1145/2541940.2541958
   Carbin M, 2013, ACM SIGPLAN NOTICES, V48, P33, DOI [10.1145/2544173.2509546, 10.1145/2509136.2509546]
   Carbin M, 2012, ACM SIGPLAN NOTICES, V47, P169, DOI 10.1145/2345156.2254086
   Chaudhuri S, 2011, P 19 ACM SIGSOFT S 1, P102
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   de Kruijf M, 2010, CONF PROC INT SYMP C, P497, DOI 10.1145/1816038.1816026
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Esmaeilzadeh H, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P301
   Feng SG, 2011, INT SYMP MICROARCH, P398
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Khudia DS, 2014, INT SYMP MICROARCH, P319, DOI 10.1109/MICRO.2014.33
   Kruijf M., 2012, C PROGR LANG DES IMP
   Li X., 2006, WORKSH ARCH SUPP GIG
   Liu S, 2011, ACM SIGPLAN NOTICES, V46, P213, DOI 10.1145/1961296.1950391
   Mazaika, SOFTW SOL PHOT MOS
   Misailovic S, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465790
   Misailovic S, 2011, LECT NOTES COMPUT SC, V6887, P316, DOI 10.1007/978-3-642-23702-7_24
   Rinaldi M., 2012, P IEEE INT FREQ CONT, P1
   Rinard M., 2006, P 20 ANN INT C SUPER, P324
   Rinard M., 2011, 20 ACM SIGPLAN WORKS, P79, DOI DOI 10.1145/1929501.1929517
   Rinard M, 2010, ACM SIGPLAN NOTICES, V45, P806, DOI 10.1145/1932682.1869525
   RINARD MC, 2007, P 22 ANN ACM C OB OR, P369
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Samadi M, 2014, ACM SIGPLAN NOTICES, V49, P35, DOI 10.1145/2541940.2541948
   Samadi Mehrzad, 2014, P WORKSHOP APPROXIMA, P1
   Sampson A., 2013, MICRO, P25, DOI DOI 10.1145/2540708.2540712
   Sampson A, 2011, ACM SIGPLAN NOTICES, V46, P164, DOI 10.1145/1993316.1993518
   Sartori J, 2012, INT CONFER PARA, P427
   Schaul T, 2010, J MACH LEARN RES, V11, P743
   Suyi Li, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P469, DOI 10.1109/CSIE.2009.999
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Thomas A, 2013, I C DEPEND SYS NETWO
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
NR 41
TC 78
Z9 78
U1 0
U2 3
PY 2015
BP 554
EP 566
DI 10.1145/2749469.2750371
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ortiz, F
   Baeza, VM
   Garces-Socarras, LM
   Vasquez-Peralvo, JA
   Gonzalez, JL
   Fontanesi, G
   Lagunas, E
   Querol, J
   Chatzinotas, S
AF Ortiz, Flor
   Monzon Baeza, Victor
   Garces-Socarras, Luis M.
   Vasquez-Peralvo, Juan A.
   Gonzalez, Jorge L.
   Fontanesi, Gianluca
   Lagunas, Eva
   Querol, Jorge
   Chatzinotas, Symeon
TI Onboard Processing in Satellite Communications Using AI Accelerators
SO AEROSPACE
DT Article
DE satellite communications; artificial intelligence; onboard process; AI
   chipset
AB Satellite communication (SatCom) systems operations centers currently require high human intervention, which leads to increased operational expenditure (OPEX) and implicit latency in human action that causes degradation in the quality of service (QoS). Consequently, new SatCom systems leverage artificial intelligence and machine learning (AI/ML) to provide higher levels of autonomy and control. Onboard processing for advanced AI/ML algorithms, especially deep learning algorithms, requires an improvement of several magnitudes in computing power compared to what is available with legacy, radiation-tolerant, space-grade processors in space vehicles today. The next generation of onboard AI/ML space processors will likely include a diverse landscape of heterogeneous systems. This manuscript identifies the key requirements for onboard AI/ML processing, defines a reference architecture, evaluates different use case scenarios, and assesses the hardware landscape for current and next-generation space AI processors.
C1 [Ortiz, Flor; Monzon Baeza, Victor; Garces-Socarras, Luis M.; Vasquez-Peralvo, Juan A.; Gonzalez, Jorge L.; Fontanesi, Gianluca; Lagunas, Eva; Querol, Jorge; Chatzinotas, Symeon] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, L-1855 Luxembourg, Luxembourg.
RP Ortiz, F (corresponding author), Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, L-1855 Luxembourg, Luxembourg.
EM flor.ortiz@uni.lu
CR AMD AMD Instinct&TRADE, 2021, MI250 ACC
   AMD Inc, 2022, 1 SPAC GRAD VERS AI
   AMD XILINX Inc, 2021, 5G BEAMF VERS AI COR
   AMD XILINX Inc, 2022, AI INF VERS AI COR S
   AMD XILINX Inc, 2022, XQR VERS SPAC 2 0 AP
   [Anonymous], 2022, NVIDIA JETSON MODULE
   Baeza VM, 2022, IEEE VTS VEH TECHNOL, DOI 10.1109/VTC2022-Fall57202.2022.10012693
   Cornejo A, 2022, NEURAL PROCESS LETT, V54, P2959, DOI 10.1007/s11063-022-10749-1
   Deng BY, 2020, IEEE WIREL COMMUN, V27, P105, DOI 10.1109/MWC.001.1900178
   Glenn Research Center|NASA, 2020, COGNITIVE COMMUNICAT
   Intel Intel&REG; Movidius&TRADE, 2019, INT MOV MYR 10 VIS P
   Jalali M., 2022, P IEEE INT S PERSONA
   Jiang CX, 2017, IEEE WIREL COMMUN, V24, P98, DOI 10.1109/MWC.2016.1500356WC
   Kato N, 2019, IEEE WIREL COMMUN, V26, P140, DOI 10.1109/MWC.2018.1800365
   Kodheli O, 2021, IEEE COMMUN SURV TUT, V23, P70, DOI 10.1109/COMST.2020.3028247
   Kosmidis L., 2021, P EUROPEAN WORKSHOP, P1
   Kosmidis L, 2020, MICROPROCESS MICROSY, V77, DOI 10.1016/j.micpro.2020.103143
   Kosmidis L, 2019, 2019 22ND EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P399, DOI 10.1109/DSD.2019.00064
   Lei L, 2020, IEEE ACCESS, V8, P136655, DOI 10.1109/ACCESS.2020.3011746
   Liao XL, 2020, IEEE COMMUN LETT, V24, P2785, DOI 10.1109/LCOMM.2020.3019437
   Liu SJ, 2020, INT J SATELL COMM N, V38, P74, DOI 10.1002/sat.1310
   Liu SJ, 2018, IEEE ACCESS, V6, P15733, DOI 10.1109/ACCESS.2018.2809581
   Luis JJG, 2019, 2019 IEEE COGNITIVE COMMUNICATIONS FOR AEROSPACE APPLICATIONS WORKSHOP (CCAAW), DOI 10.1109/ccaaw.2019.8904901
   Marques H., 2021, P ESA WORKSHOP AVION, P1
   Mei F, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21113884
   MLSAT | ESA TIA, PROJ MLSAT
   Monzon Baeza V., 2022, P 39 INT COMMUNICATI
   Morocho-Cayamcela ME, 2019, IEEE ACCESS, V7, P137184, DOI 10.1109/ACCESS.2019.2942390
   Nachmani E, 2016, ANN ALLERTON CONF, P341, DOI 10.1109/ALLERTON.2016.7852251
   NVIDIA Corp, 2022, NVIDIA JETS ROADM
   Ortiz F., 2022, P 39 INT COMMUNICATI
   Ortiz-Gomez FG, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11070992
   Ortiz-Gomez FG, 2022, IEEE T COGN COMMUN, V8, P335, DOI 10.1109/TCCN.2021.3087586
   Pang GS, 2022, IEEE INTELL SYST, V37, P111, DOI 10.1109/MIS.2022.3165668
   Politis C, 2016, IEEE INT WORK SIGN P
   Politis C, 2017, INT CONF ACOUST SPEE, P6289, DOI 10.1109/ICASSP.2017.7953366
   Prakash Chandra, 2014, 2014 International Conference on Communications and Signal Processing (ICCSP), P1394, DOI 10.1109/ICCSP.2014.6950078
   Qualcomm, 2019, QUALC CLOUD AL 100 P
   Regenerative Payload, 2018, US END TO END FEC PR
   Ferreira PVR, 2018, IEEE J SEL AREA COMM, V36, P1030, DOI 10.1109/JSAC.2018.2832820
   Rodriguez I., 2019, DESIGN IMPLEMENTATIO, P1
   Rodriguez I, 2020, DES AUT TEST EUROPE, P1718, DOI 10.23919/DATE48585.2020.9116538
   SATAI | ESA TIA, PROJ SAT
   Steenari D., 2021, P EUROPEAN WORKSHOP, P14
   Steenari D., 2021, P EUROPEAN WORKSHOP, P28
   Vázquez MA, 2021, IEEE COMMUN MAG, V59, P22, DOI 10.1109/MCOM.001.2000367
   Wang A., 2021, P IEEE GLOBECOM 2021
   Wang X., 2019, P IEEE WIRELESS COMM, DOI [10.1109/WCNC.2019.8885616, DOI 10.1109/WCNC.2019.8885616]
   Xilinx, 2021, VERS AI COR SER PROD
   XILINX Inc, 2021, BEAMF IMPL AI ENG
NR 50
TC 4
Z9 4
U1 2
U2 4
PD FEB
PY 2023
VL 10
IS 2
AR 101
DI 10.3390/aerospace10020101
WC Engineering, Aerospace
DA 2023-11-11
ER

PT J
AU Kim, M
   Seo, JS
AF Kim, Minkyu
   Seo, Jae-Sun
TI An Energy-Efficient Deep Convolutional Neural Network Accelerator
   Featuring Conditional Computing and Low External Memory Access
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Application-specific integrated circuit (ASIC); approximate computing;
   conditional computing; deep convolutional neural network (DCNN); deep
   learning; energy-efficient accelerator
ID PROCESSOR
AB With its algorithmic success in many machine learning tasks and applications, deep convolutional neural networks (DCNNs) have been implemented with custom hardware in a number of prior works. However, such works have not exploited conditional/approximate computing to the utmost toward eliminating redundant computations of CNNs. This article presents a DCNN accelerator featuring a novel conditional computing scheme that synergistically combines precision cascading (PC) with zero skipping (ZS). To reduce many redundant convolutions that are followed by max-pooling operations, we propose precision cascading, where the input features are divided into a number of low-precision groups and approximate convolutions with only the most significant bits (MSBs) are performed first. Based on this approximate computation, the full-precision convolution is performed only on the maximum pooling output that is found. This way, the total number of bit-wise convolutions can be reduced by similar to 2x with <0.8% degradation in ImageNet accuracy. PC provides the added benefit of increased sparsity per low-precision group, which we exploit with ZS to eliminate the clock cycles and external memory accesses. The proposed conditional computing scheme has been implemented with custom architecture in a 40-nm prototype chip, which achieves a peak energy efficiency of 24.97 TOPS/W at 0.6-V supply and a low external memory access of 0.0018 access/MAC with VGG-16 CNN for ImageNet classification and a peak energy efficiency of 28.51 TOPS/W at 0.9-V supply with FlowNet for Flying Chair data set.
C1 [Kim, Minkyu; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
   [Kim, Minkyu] Qualcomm, San Diego, CA 92121 USA.
RP Kim, M (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.; Kim, M (corresponding author), Qualcomm, San Diego, CA 92121 USA.
EM minkkim@qti.qualcomm.com; jaesun.seo@asu.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Alyamkin S, 2019, IEEE J EM SEL TOP C, V9, P411, DOI 10.1109/JETCAS.2019.2911899
   BACON DF, 1994, ACM COMPUT SURV, V26, P345, DOI 10.1145/197405.197406
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Chen CX, 2019, IEEE J EM SEL TOP C, V9, P346, DOI 10.1109/JETCAS.2019.2914355
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dosovitskiy A, 2015, IEEE I CONF COMP VIS, P2758, DOI 10.1109/ICCV.2015.316
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hannun AY, 2019, NAT MED, V25, P65, DOI 10.1038/s41591-018-0268-3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hwang S, 2015, PROC SPIE, V9785, DOI 10.1117/12.2216198
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Integrated Silicon Solution Inc, MOB SDRAM CHIP 256MB
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Kim M, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Lane Nicholas D, 2016, P 15 INT C INFORM PR, P1
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mathur A, 2017, MOBISYS'17: PROCEEDINGS OF THE 15TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P68, DOI 10.1145/3081333.3081359
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Rakin Adnan Siraj, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P13195, DOI 10.1109/CVPR42600.2020.01321
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sim J, 2020, IEEE T VLSI SYST, V28, P87, DOI 10.1109/TVLSI.2019.2935251
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song J, 2019, ISSCC DIG TECH PAP I, V62, P130, DOI 10.1109/ISSCC.2019.8662476
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Ueyoshi K, 2019, IEEE J SOLID-ST CIRC, V54, P186, DOI 10.1109/JSSC.2018.2871623
   Wu HS, 2018, PROC EUR SOLID-STATE, P162, DOI 10.1109/ESSCIRC.2018.8494279
   Xiong W, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P5934, DOI 10.1109/ICASSP.2018.8461870
   Yang T, 2019, 2019 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), DOI 10.1109/bhi.2019.8834598
   Yuan Z, 2018, SYMP VLSI CIRCUITS, P33, DOI 10.1109/VLSIC.2018.8502404
   Yue JS, 2019, ISSCC DIG TECH PAP I, V62, P138
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 35
TC 8
Z9 8
U1 0
U2 12
PD MAR
PY 2021
VL 56
IS 3
BP 803
EP 813
DI 10.1109/JSSC.2020.3029235
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Balaiah, T
   Parthasarathi, R
AF Balaiah, Thanasekhar
   Parthasarathi, Ranjani
TI Autotuning of configuration for program execution in GPUs
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE autotuning; block size; GPU parameter space; profiler metrics;
   regression tree
AB Graphics Processing Units (GPUs) are used as accelerators for improving performance while executing highly data parallel applications. The GPUs are characterized by a number of Streaming Multiprocessors (SM) and a large number of cores within each SM. In addition to this, a hierarchy of memories with different latencies and sizes is present in the GPUs. The program execution in GPUs is thus dependent on a number of parameter values, both at compile time and runtime. To obtain the optimal performance with these GPU resources, a large parameter space is to be explored, and this leads to a number of unproductive program executions. To alleviate this difficulty, machine learning-based autotuning systems are proposed to predict the right configuration using a limited set of compile-time parameters. In this paper, we propose a two-stage machine learning-based autotuning framework using an expanded set of attributes. The important parameters such as block size, occupancy, eligible warps, and execution time are predicted. The mean relative error in prediction of different parameters ranges from of 16% to 6.5%. Dimensionality reduction for the features set reduces the features by up to 50% with further increase in prediction accuracy.
C1 [Balaiah, Thanasekhar] Anna Univ, Dept Comp Technol, Chennai 600044, Tamil Nadu, India.
   [Parthasarathi, Ranjani] Anna Univ, Dept Informat Sci & Technol, Chennai, Tamil Nadu, India.
RP Balaiah, T (corresponding author), Anna Univ, Dept Comp Technol, Chennai 600044, Tamil Nadu, India.
EM thanasekhar@annauniv.edu
CR [Anonymous], 2017, CONCURRENCY COMPUTAT
   [Anonymous], 2009, IEEE INT S WORKL CHA
   Balaiah T, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4267
   Che S., 2010, IISWC, DOI DOI 10.1109/IISWC.2010.5650274
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1
   Guerreiro J, 2015, 23 EUR INT C PAR DIS
   Gupta R, 2015, INT C HIGH PERF COMP
   KNIME, KNIME TOOLK
   Lim RV, 2017, 46 INT C PAR PROC BR
   Liu Y, 2009, IEEE INT S PAR DISTR
   Lutz T, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400718
   NVIDIA Corporation, CUDA DEV TOOLK
   NVIDIA Corporation, CUDA TOOLK DOC
   NVIDIA Corporation . NVIDIA Data Center, NVIDIA DAT CTR
   Ren LY, 2016, IEEE TOPIC CONF BIOM, P18, DOI 10.1109/BIOWIRELESS.2016.7445550
   Sethia A, 2014, 47 ANN IEEE ACM INT
   Tang WT, 2013, IEEE 27 INT S PAR DI
NR 17
TC 0
Z9 0
U1 0
U2 2
PD MAY 10
PY 2020
VL 32
IS 9
AR e5635
DI 10.1002/cpe.5635
EA DEC 2019
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Leemann, SC
   Liu, S
   Hexemer, A
   Marcus, MA
   Melton, CN
   Nishimura, H
   Sun, C
AF Leemann, S. C.
   Liu, S.
   Hexemer, A.
   Marcus, M. A.
   Melton, C. N.
   Nishimura, H.
   Sun, C.
TI Demonstration of Machine Learning-Based Model-Independent Stabilization
   of Source Properties in Synchrotron Light Sources
SO PHYSICAL REVIEW LETTERS
DT Article
ID RAY; MICROSCOPY; NETWORKS
AB Synchrotron light sources, arguably among the most powerful tools of modern scientific discovery, are presently undergoing a major transformation to provide orders of magnitude higher brightness and transverse coherence enabling the most demanding experiments. In these experiments, overall source stability will soon be limited by achievable levels of electron beam size stability, presently on the order of several microns, which is still 1-2 orders of magnitude larger than already demonstrated stability of source position and current. Until now source size stabilization has been achieved through corrections based on a combination of static predetermined physics models and lengthy calibration measurements, periodically repeated to counteract drift in the accelerator and instrumentation. We now demonstrate for the first time how the application of machine learning allows for a physics- and model-independent stabilization of source size relying only on previously existing instrumentation. Such feed-forward correction based on a neural network that can be continuously online retrained achieves source size stability as low as 0.2 mu m (0.4%) rms, which results in overall source stability approaching the subpercent noise floor of the most sensitive experiments.
C1 [Leemann, S. C.; Hexemer, A.; Marcus, M. A.; Melton, C. N.; Nishimura, H.; Sun, C.] Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
   [Liu, S.] Univ Calif Berkeley, Dept Chem, Berkeley, CA 94720 USA.
RP Leemann, SC (corresponding author), Lawrence Berkeley Natl Lab, Berkeley, CA 94720 USA.
EM SCLeemann@lbl.gov; liushuai10000@berkeley.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Ade H, 2008, POLYMER, V49, P643, DOI 10.1016/j.polymer.2007.10.030
   Bahrdt J., 2008, P 11 EUR PART ACC C, P2222
   Benabderrahmane C., 2007, P PAC07 ALB NEW MEX, P929
   Bertwistle D., 2015, P 12 INT C SYNCHR RA
   Borland M., 2016, P NAPAC16 CHIC US, P877, DOI [10.18429/JACoW-NAPAC2016-WEPOB01, DOI 10.18429/JACOW-NAPAC2016-WEPOB01]
   Breunlin J, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.060701
   Chen SW, 2013, PHYS REV LETT, V110, DOI 10.1103/PhysRevLett.110.217201
   Chrin J, 2008, NUCL INSTRUM METH A, V592, P141, DOI 10.1016/j.nima.2008.04.016
   Decker G., 2005, P DIPAC 2005 LYON FR, P233
   Emery L., 1999, Proceedings of the 1999 Particle Accelerator Conference (Cat. No.99CH36366), P200, DOI 10.1109/PAC.1999.795663
   Falcone R, 2011, CONTEMP PHYS, V52, P293, DOI 10.1080/00107514.2011.589662
   Franchi A, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.034002
   Hettel R, 2014, J SYNCHROTRON RADIAT, V21, P843, DOI 10.1107/S1600577514011515
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Kilcoyne ALD, 2003, J SYNCHROTRON RADIAT, V10, P125, DOI 10.1107/S0909049502017739
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leemann SC, 2018, NUCL INSTRUM METH A, V883, P33, DOI 10.1016/j.nima.2017.11.072
   Leemann S. C., 2015, P IPAC RICHM US 2015, P1696
   Martin I. P. S., 2014, P 5 INT PART ACC C I, P1760
   Martin I. P. S., 2013, P IPAC2013 SHANGH CH, P249
   Montag C., 2007, P 22 PART ACC C PAC, P4375
   Nair V., 2010, ICML, P807
   Namkung W., 2010, P IPAC 10, P2411
   Ohkuma H., 2008, TOP OPERATION LIGHT
   Plouviez E., 2011, P IPAC2011 SAN SEB S, P478
   Raimondi P., 2016, P 7 INT PART ACC C I, P2023
   Rehm G, 2013, J PHYS CONF SER, V425, DOI 10.1088/1742-6596/425/4/042001
   Renner TR, 1996, REV SCI INSTRUM, V67, P3368, DOI [10.1063/1.1147369, DOI 10.1063/1.1147369]
   Rodrigues A. R. D., 2018, P IPAC2018 VANC BC C, P2886
   SASAKI S, 1994, NUCL INSTRUM METH A, V347, P83, DOI 10.1016/0168-9002(94)91859-7
   Shapiro DA, 2014, NAT PHOTONICS, V8, P765, DOI [10.1038/NPHOTON.2014.207, 10.1038/nphoton.2014.207]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Steier C, 2003, PROCEEDINGS OF THE 2003 PARTICLE ACCELERATOR CONFERENCE, VOLS 1-5, P3213
   Steier C., 2004, P 2004 EUR PART ACC, P479
   Steier C., 2018, P 9 INT PART ACC C V, DOI [10.18429/JACoW-IPAC2018-THPMF036, DOI 10.18429/JACOW-IPAC2018-THPMF036]
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Streun A., 2018, P IPAC2018 VANC BC C, P4358
   Wallen E., 2011, P 2011 PART ACC C NE, P1262
   Warwick T, 2002, J SYNCHROTRON RADIAT, V9, P254, DOI 10.1107/S0909049502005502
   Wu Y., 2000, P EPAC 2000 VIENN AU, P1098
   Wurtz WA, 2018, NUCL INSTRUM METH A, V892, P1, DOI 10.1016/j.nima.2018.02.082
NR 44
TC 34
Z9 38
U1 1
U2 16
PD NOV 6
PY 2019
VL 123
IS 19
AR 194801
DI 10.1103/PhysRevLett.123.194801
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Rella, L
AF Rella, Ludovico
TI Close to the metal: Towards a material political economy of the
   epistemology of computation
SO SOCIAL STUDIES OF SCIENCE
DT Article; Early Access
DE materiality; artificial intelligence; blockchain; cryptocurrency;
   hardware; GPU; ASIC; TPU
ID BITCOIN
AB This paper investigates the role of the materiality of computation in two domains: blockchain technologies and artificial intelligence (AI). Although historically designed as parallel computing accelerators for image rendering and videogames, graphics processing units (GPUs) have been instrumental in the explosion of both cryptoasset mining and machine learning models. The political economy associated with video games and Bitcoin and Ethereum mining provided a staggering growth in performance and energy efficiency and this, in turn, fostered a change in the epistemological understanding of AI: from rules-based or symbolic AI towards the matrix multiplications underpinning connectionism, machine learning and neural nets. Combining a material political economy of markets with a material epistemology of science, the article shows that there is no clear-cut division between software and hardware, between instructions and tools, and between frameworks of thought and the material and economic conditions of possibility of thought itself. As the microchip shortage and the growing geopolitical relevance of the hardware and semiconductor supply chain come to the fore, the paper invites social scientists to engage more closely with the materialities and hardware architectures of 'virtual' algorithms and software.
C1 [Rella, Ludovico] Univ Durham, Geog, Durham, England.
   [Rella, Ludovico] Dept Geog, South Rd, Durham DH1 3LE, England.
RP Rella, L (corresponding author), Dept Geog, South Rd, Durham DH1 3LE, England.
EM ludovico.rella@durham.ac.uk
CR Akhtar T., 2022, BLOOMBERG 0517
   Aldrich EM, 2011, J ECON DYN CONTROL, V35, P386, DOI 10.1016/j.jedc.2010.10.001
   AMD, 2010, PROGR GUID ATI STREA
   Amoore L., 2020, CLOUD ETHICS ALGORIT, DOI 10.2307/j.ctv11g97wm
   Amoore L, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517231166887
   Amoore L, 2018, PROG HUM GEOG, V42, P4, DOI 10.1177/0309132516662147
   [Anonymous], 2006, ATI CTM GUID TECHN R
   [Anonymous], 2006, HAL
   [Anonymous], 1998, PARALLEL COMPUTER AR
   Aslop T., 2021, COMPUTE GRAPHICS MAR
   Aslop T., 2021, NUMBER GPU SUPPLIERS
   Aslop T., 2021, GAMING PC COMPUTER G
   Athey S., 2019, EC ARTIFICIAL INTELL, P507
   Atkins E, 2021, GEOFORUM, V122, P63, DOI 10.1016/j.geoforum.2020.12.019
   Azar M, 2021, AI SOC, V36, P1093, DOI 10.1007/s00146-020-01124-6
   Bengio Y, 2006, ADV NEURAL INFORM PR, P19, DOI DOI 10.7551/MITPRESS/7503.003.0024
   Blanchette JF, 2011, J AM SOC INF SCI TEC, V62, P1042, DOI 10.1002/asi.21542
   Blum Andrew., 2012, TUBES JOURNEY CTR IN
   Brock DC, 2012, TECHNOL CULT, V53, P561, DOI 10.1353/tech.2012.0122
   Bruschi Francesco, 2018, ACM SIGMETRICS Performance Evaluation Review, V46, P127, DOI 10.1145/3308897.3308954
   Bureau of Industry and Security, 2022, COMM IMPL NEW EXP CO
   Burrell J, 2016, BIG DATA SOC, V3, P1, DOI 10.1177/2053951715622512
   Cambridge Centre for Alternative Finance, 2022, CAMBR BITC EL CONS I
   CLARK A, 1990, BRIT J PHILOS SCI, V41, P195, DOI 10.1093/bjps/41.2.195
   CNW Group, 2007, AMD COMPL ATI ACQ CR
   CompaniesMarketCap.com, 2022, CO RANK MARK CAP
   Crain Matthew, 2021, PROFIT PRIVACY SURVE
   Crary J., 1992, TECHNIQUES OBSERVER
   Crawford K., 2022, ATLAS POWER POLITICS
   Daston L., 2007, OBJECTIVITY
   Deepmind, 2019, ALPHASTAR MASTERING
   Dennett D. C., 1987, MINDS MACHINES EVOLU, P129
   Diamond A, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00491
   Dourish, 2017, STUFF BITS ESSAY MAT
   Duarte V, 2020, J ECON DYN CONTROL, V111, DOI 10.1016/j.jedc.2019.103796
   Dufrechou E., 2021, CLEI ELECT J, V24, P6, DOI [10.19153/cleiej.24.1.6, DOI 10.19153/CLEIEJ.24.1.6]
   Easterling K., 2014, EXTRASTATECRAFT POWE
   Edwards P. N., 2013, KNOWLEDGE INFRASTRUC
   Edwards PN, 2010, VAST MACHINE: COMPUTER MODELS, CLIMATE DATA, AND THE POLITICS OF GLOBAL WARMING, P1
   Egan M., 2021, CNN BUSINESS 1202
   Fazi MB, 2019, AI SOC, V34, P813, DOI 10.1007/s00146-018-0821-0
   FLYNN MJ, 1972, IEEE T COMPUT, VC 21, P948, DOI 10.1109/TC.1972.5009071
   Fok KL, 2007, IEEE INTELL SYST, V22, P69, DOI 10.1109/MIS.2007.28
   Fuchs A, 2019, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2019.00023
   Gaboury Jacob, 2021, IMAGE OBJECTS ARCHAE
   Gabrys J, 2011, DIGITAL RUBBISH: A NATURAL HISTORY OF ELECTRONICS, P1, DOI 10.3998/dcbooks.9380304.0001.001
   Gabrys J., 2016, PROGRAM EARTH ENV SE
   GALISON Peter, 1997, IMAGE LOGIC MAT CULT
   Galison Peter, 2003, EINSTEINS CLOCKS POI
   Gershgorn D., 2017, QUARTZ 0726
   Giles P, 2019, J CULT ECON-UK, V12, P612, DOI 10.1080/17530350.2019.1639068
   Gkritsi E., 2022, GPUS GET CHEAPER ETH
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Google Finance, 2023, NVIDIA CORP NVDA STO
   GOV.UK, 2022, NVIDIA ABANDONS TAKE
   Grosman J, 2019, BIG DATA SOC, V6, DOI 10.1177/2053951719858742
   Hayes AS, 2017, TELEMAT INFORM, V34, P1308, DOI 10.1016/j.tele.2016.05.005
   Hayles N. K., 2020, POSTPRINT BOOKS BECO
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hern A., 2023, THE GUARDIAN 0326
   Hinton G., 2019, DEEP LEARNING REVOLU
   Hu Tung-Hui, 2015, PREHISTORY CLOUD
   Jacobsen BN, 2023, BIG DATA SOC, V10, DOI 10.1177/20539517221145372
   Jones Matthew L., 2016, RECKONING MATTER CAL
   Kanellos M., 2002, NVIDIA BUYS OUT 3DFX
   Khan MM, 2008, IEEE IJCNN, P2849, DOI 10.1109/IJCNN.2008.4634199
   Kinsley S, 2014, PROG HUM GEOG, V38, P364, DOI 10.1177/0309132513506270
   Kirk D., 2013, PROGRAMMING MASSIVEL
   Kornberger M., 2019, THINKING INFRASTRUCT
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lally N, 2022, ENVIRON PLAN E-NAT, V5, P18, DOI 10.1177/2514848619867608
   Langley P, 2021, NEW POLIT ECON, V26, P376, DOI 10.1080/13563467.2020.1766432
   LeCun Y., 2021, MNIST HANDWRITTEN DI
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lécuyer C, 2022, ENTERP SOC, V23, P133, DOI 10.1017/eso.2020.38
   Lecuyer Christophe, 2010, MAKERS MICROCHIP DOC
   Lezar E., 2011, GPU ACCELERATION MAT
   MacKenzie A, 2019, THEOR CULT SOC, V36, P3, DOI 10.1177/0263276419847508
   MacKenzie D, 2021, TRADING AT THE SPEED OF LIGHT, P1
   MacKenzie Donald, 2006, ENGINE NOT CAMERA FI
   Mahony AO, 2019, 2019 30TH IRISH SIGNALS AND SYSTEMS CONFERENCE (ISSC)
   Mattern S., 2020, CASE LOGICS MAKING C
   McFarland P., 2021, OPENCL MINER BITCOIN
   Menabrea L. F., 1843, SCI MEMOIRS, V3, P666
   Miller B, 2021, SCI TECHNOL HUM VAL, V46, P53, DOI 10.1177/0162243919900965
   Mirowski Philip, 2002, MACHINE DREAMS EC BE
   Mühlhoff R, 2020, NEW MEDIA SOC, V22, P1868, DOI 10.1177/1461444819885334
   Munn L, 2022, NEW MEDIA SOC, V24, P1399, DOI 10.1177/1461444820977197
   Munn L, 2022, INFORM COMMUN SOC, V25, P975, DOI 10.1080/1369118X.2020.1808043
   Nageswaran Jayram Moorkanikara, 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P2145, DOI 10.1109/IJCNN.2009.5179043
   Nakamoto S, 2008, PEER TO PEER ELECT C
   Narayan D, 2022, ENVIRON PLANN A, V54, P911, DOI 10.1177/0308518X221094028
   Nast C., 2021, WIRED UK
   Nellis S., 2022, REUTERS 0901
   NEWELL A, 1976, COMMUN ACM, V19, P113, DOI 10.1145/360018.360022
   Newquist H. P., 2020, BRAIN MAKERS HIST AR, V2nd ed.
   NVIDIA, 1999, NVIDIA LAUNCHES WORL
   NVIDIA Corporation, 2017, NVIDIA TESL V100 GPU
   Oh KS, 2004, PATTERN RECOGN, V37, P1311, DOI 10.1016/j.patcog.2004.01.013
   Orender J., 2020, IS ETHEREUMS PROGPOW
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Jouppi NP, 2017, Arxiv, DOI arXiv:1704.04760
   Pias Marcelo, 2019, 2019 32nd SIBGRAPI Conference on Graphics, Patterns and Images Tutorials (SIBGRAPI-T). Proceedings, P8, DOI 10.1109/SIBGRAPI-T.2019.00007
   Pickering A., 1995, MANGLE PRACTICE TIME
   Pickren G., 2017, IMAGINATIONS J CROSS, V8, P22, DOI [10.17742/IMAGE.LD.8.2.3, DOI 10.17742/IMAGE.LD.8.2.3]
   Pickren G, 2018, PROG HUM GEOG, V42, P225, DOI 10.1177/0309132516673241
   Pound J., 2022, BAIRD DOWNGRADES NVI
   Prytkova E, 2022, IND CORP CHANGE, V31, P1031, DOI 10.1093/icc/dtab077
   Raina Rajat, 2009, INT C MACHINE LEARNI, P873, DOI DOI 10.1145/1553374.1553486
   Rella L., 2020, INT ENCY HUMAN GEOGR, P351, DOI [10.1016/B978-0-08-102295-5.10514-1, DOI 10.1016/B978-0-08-102295-5.10514-1]
   Reuther A, 2022, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC55821.2022.9926331
   Rieder B., 2020, ENGINES ORDER MECHAN
   Roberge J., 2021, CULTURAL LIFE MACHIN, P1, DOI DOI 10.1007/978-3-030-56286-1_1
   ROSENBLATT F, 1958, PSYCHOL REV, V65, P386, DOI 10.1037/h0042519
   Sadowski J, 2019, BIG DATA SOC, V6, DOI 10.1177/2053951718820549
   Saleem R., 2022, WCCFTECH
   SEC, 2022, SEC CHARG NVIDIA COR
   Shaolin Xie, 2018, ACM SIGOPS Operating Systems Review, V52, P96, DOI 10.1145/3273982.3273991
   Siegert B, 2015, MEAN SYST, P1, DOI 10.5422/fordham/9780823263752.001.0001
   Starosielski Nicole, 2015, THE UNDERSEA NETWORK
   Steinhoff J, 2022, NEW MEDIA SOC, DOI 10.1177/14614448221099217
   Steinkraus D, 2005, PROC INT CONF DOC, P1115, DOI 10.1109/ICDAR.2005.251
   Straube T, 2016, BIG DATA SOC, V3, DOI 10.1177/2053951716642456
   Taffel S, 2023, NEW MEDIA SOC, V25, P980, DOI 10.1177/14614448211017887
   Taylor M. B., 2013, COMPILERS ARCHITECTU, P1, DOI 10.1109/CASES.2013.6662520
   Taylor MB, 2013, IEEE MICRO, V33, P8, DOI 10.1109/MM.2013.90
   Taylor MB, 2017, COMPUTER, V50, P58, DOI 10.1109/MC.2017.3571056
   Thambawita V, 2014, Arxiv, DOI arXiv:1412.7789
   The Business Research Company, 2021, MICR GPU GLOB MARK R
   Thylstrup NB, 2019, BIG DATA SOC, V6, DOI 10.1177/2053951719875479
   Tidy J., 2021, BBC NEWS 1013
   TOP500, 2020, DEV TIM TOP500
   Turing AM, 1937, P LOND MATH SOC, V42, P230, DOI 10.1112/plms/s2-42.1.230
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   von Neumann J., 1958, COMPUTER BRAIN
   Vranken H, 2017, CURR OPIN ENV SUST, V28, P1, DOI 10.1016/j.cosust.2017.04.011
   Walton J., 2022, GPU PRICES TRACKING
   Walton J., 2022, BEST MINING GPUS BEN
   Ward C., 2020, ETHASH
   Wyeth R., 2023, AAG ANN M
   Yeung H. W.-C., 2022, INTERCONNECTED WORLD
   Zakaria F., 2022, CNN 0731
NR 143
TC 0
Z9 0
U1 5
U2 5
PD 2023 JUL 10
PY 2023
DI 10.1177/03063127231185095
EA JUL 2023
WC History & Philosophy Of Science
DA 2023-11-11
ER

PT J
AU Chen, ZG
   Zheng, DD
   Lin, ZR
   Zhang, CY
   Wei, C
   Deng, XD
   Yan, P
   Zheng, CH
   Lan, CL
   Qin, CJ
   Wei, XL
   Qin, DL
   Wu, YF
   Peng, J
   Miao, CF
   Lu, LX
   Xia, Y
   Luo, QS
AF Chen, Zigui
   Zheng, Dandan
   Lin, Ziren
   Zhang, Chunyuan
   Wei, Cheng
   Deng, Xiandong
   Yan, Peng
   Zheng, Chuanhua
   Lan, Chuanliu
   Qin, Chengjian
   Wei, Xuanlei
   Qin, Deling
   Wu, Yongfang
   Peng, Jun
   Miao, Changfeng
   Lu, Liuxue
   Xia, Ying
   Luo, Qisheng
TI GPX8 regulates pan-apoptosis in gliomas to promote microglial migration
   and mediate immunotherapy responses
SO FRONTIERS IN IMMUNOLOGY
DT Article
DE machine learning; non-apoptotic cell death; immunotherapy; glioma;
   pan-apoptosis
ID CANCER; METASTASIS; PANOPTOSIS
AB IntroductionGliomas have emerged as the predominant brain tumor type in recent decades, yet the exploration of non-apoptotic cell death regulated by the pan-optosome complex, known as pan-apoptosis, remains largely unexplored in this context. This study aims to illuminate the molecular properties of pan-apoptosis-related genes in glioma patients, classifying them and developing a signature using machine learning techniques.MethodsThe prognostic significance, mutation features, immunological characteristics, and pharmaceutical prediction performance of this signature were comprehensively investigated. Furthermore, GPX8, a gene of interest, was extensively examined for its prognostic value, immunological characteristics, medication prediction performance, and immunotherapy prediction potential.ResultsExperimental techniques such as CCK-8, Transwell, and EdU investigations revealed that GPX8 acts as a tumor accelerator in gliomas. At the single-cell RNA sequencing level, GPX8 appeared to facilitate cell contact between tumor cells and macrophages, potentially enhancing microglial migration.ConclusionsThe incorporation of pan-apoptosis-related features shows promising potential for clinical applications in predicting tumor progression and advancing immunotherapeutic strategies. However, further in vitro and in vivo investigations are necessary to validate the tumorigenic and immunogenic processes associated with GPX8 in gliomas.
C1 [Chen, Zigui; Peng, Jun; Xia, Ying] Cent South Univ, Haikou Affiliated Hosp, Xiangya Sch Med, Dept Neurosurg, Haikou, Hainan, Peoples R China.
   [Zheng, Dandan] Zhejiang Univ, Affiliated Hosp 1, Dept Radiat Oncol, Hangzhou, Peoples R China.
   [Lin, Ziren; Wu, Yongfang] Peoples Hosp Baise, Dept Wound Repair Surg, Baise, Guangxi, Peoples R China.
   [Zhang, Chunyuan] Youjiang Med Univ Nationalities, Life Sci & Clin Res Ctr, Affiliated Hosp, Baise, Guangxi, Peoples R China.
   [Wei, Cheng; Deng, Xiandong; Yan, Peng; Zheng, Chuanhua; Lan, Chuanliu; Qin, Chengjian; Wei, Xuanlei; Qin, Deling; Luo, Qisheng] YouJiang Med Univ Nationalities, Dept Neurosurg, Affiliated Hosp, Baise, Guangxi, Peoples R China.
   [Miao, Changfeng] Hunan Normal Univ, Dept Lab Med, Affiliated Hosp 1, Neurosurg Branche 2, Changsha, Hunan, Peoples R China.
   [Lu, Liuxue] Youjiang Med Univ Nationalities, Dept Med, Affiliated Hosp, Baise, Guangxi, Peoples R China.
RP Xia, Y (corresponding author), Cent South Univ, Haikou Affiliated Hosp, Xiangya Sch Med, Dept Neurosurg, Haikou, Hainan, Peoples R China.; Luo, QS (corresponding author), YouJiang Med Univ Nationalities, Dept Neurosurg, Affiliated Hosp, Baise, Guangxi, Peoples R China.; Miao, CF (corresponding author), Hunan Normal Univ, Dept Lab Med, Affiliated Hosp 1, Neurosurg Branche 2, Changsha, Hunan, Peoples R China.; Lu, LX (corresponding author), Youjiang Med Univ Nationalities, Dept Med, Affiliated Hosp, Baise, Guangxi, Peoples R China.
EM m13574100644@163.com; LLX13517764336@163.com; xiaying008@163.com;
   1917@ymcn.edu.cn
CR Ayers M, 2017, J CLIN INVEST, V127, P2930, DOI 10.1172/JCI91190
   Becht E, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-1070-5
   Charoentong P, 2017, CELL REP, V18, P248, DOI 10.1016/j.celrep.2016.12.019
   Chen H, 2020, CANCER CELL INT, V20, DOI 10.1186/s12935-020-01692-z
   Chen X, 2023, EPIGENETICS-US, V18, DOI 10.1080/15592294.2023.2208707
   Deng Q, 2018, CELL DEATH DIS, V9, DOI 10.1038/s41419-018-1082-z
   Dong R, 2018, INT J MOL MED, V41, P599, DOI 10.3892/ijmm.2017.3311
   Eskilsson E, 2018, NEURO-ONCOLOGY, V20, P743, DOI 10.1093/neuonc/nox191
   Gao L, 2020, CELL DEATH DIS, V11, DOI 10.1038/s41419-020-2693-8
   Ghouzlani A, 2021, FRONT IMMUNOL, V12, DOI 10.3389/fimmu.2021.679425
   Hoshida Y, 2007, PLOS ONE, V2, DOI 10.1371/journal.pone.0001195
   Karki R, 2021, CELL REP, V37, DOI 10.1016/j.celrep.2021.109858
   Karki R, 2020, JCI INSIGHT, V5, DOI 10.1172/jci.insight.136720
   Kaur A, 2016, NATURE, V532, P250, DOI 10.1038/nature17392
   Khatib A, 2020, P NATL ACAD SCI USA, V117, P21420, DOI 10.1073/pnas.2010275117
   Li TW, 2017, CANCER RES, V77, pE108, DOI 10.1158/0008-5472.CAN-17-0307
   Lin JF, 2022, SIGNAL TRANSDUCT TAR, V7, DOI 10.1038/s41392-022-00889-0
   Ma JH, 2019, CANCER CELL, V35, P504, DOI [10.1016/j.ccell.2019.01.020, 10.1016/j.ccell.2019.04.011]
   Ma QQ, 2018, FRONT IMMUNOL, V9, DOI 10.3389/fimmu.2018.02924
   Maeser D, 2021, BRIEF BIOINFORM, V22, DOI 10.1093/bib/bbab260
   Murnyak B, 2021, CELLS-BASEL, V10, DOI 10.3390/cells10082116
   Nguyen TTM, 2023, J EXP CLIN CANC RES, V42, DOI 10.1186/s13046-023-02607-2
   Ostrom QT, 2014, NEURO-ONCOLOGY, V16, P896, DOI 10.1093/neuonc/nou087
   Pan HD, 2022, CLIN IMMUNOL, V238, DOI 10.1016/j.clim.2022.109019
   Pandian N, 2022, J IMMUNOL, V209, P1625, DOI 10.4049/jimmunol.2200508
   Place DE, 2021, CURR OPIN MICROBIOL, V59, P42, DOI 10.1016/j.mib.2020.07.012
   Ramírez-Cosmes A, 2021, AM J CANCER RES, V11, P4127
   Roh W, 2017, SCI TRANSL MED, V9, DOI 10.1126/scitranslmed.aah3560
   Senbabaoglu Y, 2016, GENOME BIOL, V17, DOI 10.1186/s13059-016-1092-z
   Shin H, 2020, CANCER RES TREAT, V52, P41, DOI 10.4143/crt.2019.036
   Singh N, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-26901-9
   Thakur A, 2023, BRAIN SCI, V13, DOI 10.3390/brainsci13050762
   Turkalp Z, 2014, JAMA NEUROL, V71, P1319, DOI 10.1001/jamaneurol.2014.1205
   Wang YQ, 2021, COMPUT STRUCT BIOTEC, V19, P4641, DOI 10.1016/j.csbj.2021.07.038
   Yang KY, 2022, MOL CANCER, V21, DOI 10.1186/s12943-022-01513-z
   Yoshihara K, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3612
   Zan XY, 2022, FRONT ONCOL, V12, DOI 10.3389/fonc.2022.707525
   Zhang CY, 2020, THERANOSTICS, V10, P6561, DOI 10.7150/thno.44868
   Zhang F, 2023, CNS NEUROSCI THER, DOI 10.1111/cns.14264
   Zhang K, 2023, FRONT PHARMACOL, V14, DOI 10.3389/fphar.2023.1227996
   Zhang K, 2018, CELL DEATH DIS, V9, DOI 10.1038/s41419-018-1086-8
NR 41
TC 0
Z9 0
U1 1
U2 1
PD SEP 19
PY 2023
VL 14
AR 1260169
DI 10.3389/fimmu.2023.1260169
WC Immunology
DA 2023-11-11
ER

PT J
AU Bao, H
   Zhou, HJ
   Li, JC
   Pei, HZ
   Tian, J
   Yang, L
   Ren, SG
   Tong, SQ
   Li, Y
   He, YH
   Chen, J
   Cai, YM
   Wu, HQ
   Liu, Q
   Wan, Q
   Miao, XS
AF Bao, Han
   Zhou, Houji
   Li, Jiancong
   Pei, Huaizhi
   Tian, Jing
   Yang, Ling
   Ren, Shengguang
   Tong, Shaoqin
   Li, Yi
   He, Yuhui
   Chen, Jia
   Cai, Yimao
   Wu, Huaqiang
   Liu, Qi
   Wan, Qing
   Miao, Xiangshui
TI Toward memristive in-memory computing: principles and applications
SO FRONTIERS OF OPTOELECTRONICS
DT Review
DE Memristor; In-memory computing; Matrix-vector multiplication; Machine
   learning; Scientific computing; Digital image processing
ID CONVOLUTIONAL NEURAL-NETWORKS; ACCELERATOR; EFFICIENT; BACKPROPAGATION;
   CLASSIFICATION; TRENDS; FUTURE; SENSOR; SIGNAL; ARRAY
AB With the rapid growth of computer science and big data, the traditional von Neumann architecture suffers the aggravating data communication costs due to the separated structure of the processing units and memories. Memristive in-memory computing paradigm is considered as a prominent candidate to address these issues, and plentiful applications have been demonstrated and verified. These applications can be broadly categorized into two major types: soft computing that can tolerant uncertain and imprecise results, and hard computing that emphasizes explicit and precise numerical results for each task, leading to different requirements on the computational accuracies and the corresponding hardware solutions. In this review, we conduct a thorough survey of the recent advances of memristive in-memory computing applications, both on the soft computing type that focuses on artificial neural networks and other machine learning algorithms, and the hard computing type that includes scientific computing and digital image processing. At the end of the review, we discuss the remaining challenges and future opportunities of memristive in-memory computing in the incoming Artificial Intelligence of Things era.
C1 [Bao, Han; Zhou, Houji; Li, Jiancong; Pei, Huaizhi; Tian, Jing; Yang, Ling; Ren, Shengguang; Tong, Shaoqin; Li, Yi; He, Yuhui; Miao, Xiangshui] Huazhong Univ Sci & Technol, Sch Integrated Circuits, Sch Opt & Elect Informat, Wuhan Natl Lab Optoelect,Opt Valley Lab, Wuhan 430074, Peoples R China.
   [Li, Yi; He, Yuhui; Miao, Xiangshui] Hubei Yangtze Memory Labs, Wuhan 430205, Peoples R China.
   [Chen, Jia] Hong Kong Sci Pk, InnoHK Ctr, AI Chip Ctr Emerging Smart Syst, Hong Kong, Peoples R China.
   [Cai, Yimao] Peking Univ, Sch Integrated Circuits, Beijing 100871, Peoples R China.
   [Wu, Huaqiang] Tsinghua Univ, Beijing Natl Res Ctr Informat Sci & Technol BNRis, Sch Integrated Circuits, Beijing 100084, Peoples R China.
   [Liu, Qi] Fudan Univ, Frontier Inst Chip & Syst, Shanghai 200433, Peoples R China.
   [Wan, Qing] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210093, Peoples R China.
   [Wan, Qing] Nanjing Univ, Collaborat Innovat Ctr Adv Microstruct, Nanjing 210093, Peoples R China.
RP Li, Y; Miao, XS (corresponding author), Huazhong Univ Sci & Technol, Sch Integrated Circuits, Sch Opt & Elect Informat, Wuhan Natl Lab Optoelect,Opt Valley Lab, Wuhan 430074, Peoples R China.; Li, Y; Miao, XS (corresponding author), Hubei Yangtze Memory Labs, Wuhan 430205, Peoples R China.
EM d201880662@hust.edu.cn; liyi@hust.edu.cn; miaoxs@hust.edu.cn
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Amirsoleimani A, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000115
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   [Anonymous], 2014, MEMRISTORS MEMRISTIV
   Baboulin M, 2009, COMPUT PHYS COMMUN, V180, P2526, DOI 10.1016/j.cpc.2008.11.005
   Baraniuk RG., 2007, COMPRESSIVE SENSING, V24, P121, DOI [10.1109/MSP.2007.4286571, DOI 10.1109/MSP.2007.4286571]
   Bayat FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04482-4
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Buluc A., 2008, P 2008 37 INT C PAR
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Cai Y, 2020, IEEE T COMPUT AID D, V39, P1414, DOI 10.1109/TCAD.2019.2917852
   CANNY J, 1986, IEEE T PATTERN ANAL, V8, P679, DOI 10.1109/TPAMI.1986.4767851
   Chai Y, 2020, NATURE, V579, P32, DOI 10.1038/d41586-020-00592-6
   Chakraborty I, 2020, APPL PHYS REV, V7, DOI 10.1063/1.5113536
   Chen J, 2021, J SEMICOND, V42, DOI 10.1088/1674-4926/42/1/013104
   Chen J, 2020, IEEE ELECTR DEVICE L, V41, P353, DOI 10.1109/LED.2020.2968388
   Chen J, 2019, IEEE ELECTR DEVICE L, V40, P542, DOI 10.1109/LED.2019.2898443
   CHEN LN, 1995, NEURAL NETWORKS, V8, P915, DOI 10.1016/0893-6080(95)00033-V
   Chen P.Y., 2017, P 2017 IEEE INT EL D
   Cheng L, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201905660
   Choi S, 2017, NANO LETT, V17, P3113, DOI 10.1021/acs.nanolett.7b00552
   Christensen D. V., 2021, ARXIV PREPRINT ARXIV
   Chua L, 2018, NAT ELECTRON, V1, P322, DOI 10.1038/s41928-018-0074-4
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Dalgaty T, 2021, NAT ELECTRON, V4, P151, DOI 10.1038/s41928-020-00523-3
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Fahimi Z, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-78944-5
   Feinberg B., 2018, P 2018 ACMIEEE 45 AN
   Feng Y, 2020, IEEE SILICON NANOELE, P27, DOI [10.1109/SNW50361.2020.9131425, 10.1109/snw50361.2020.9131425]
   Geng Y., 2021, P 2021 DES AUT TEST
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Graves CE, 2020, ADV MATER, V32, DOI 10.1002/adma.202003437
   Guo X, 2017, INT EL DEVICES MEET
   Halawani Y, 2018, IEEE T VLSI SYST, V26, P2749, DOI 10.1109/TVLSI.2018.2835572
   He K., 2015, ARXIV
   He YL, 2021, J APPL PHYS, V130, DOI 10.1063/5.0069456
   Hong QH, 2020, NEURAL COMPUT APPL, V32, P8175, DOI 10.1007/s00521-019-04305-7
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hubara I., 2017, J MACH LEARN RES, V18, P6869, DOI DOI 10.5555/3122009.3242044
   Hung JM, 2020, IEEE T ELECTRON DEV, V67, P1444, DOI 10.1109/TED.2020.2976115
   Huo Q, 2020, IEEE ELECTR DEVICE L, V41, P497, DOI 10.1109/LED.2020.2970536
   Ibrahim D, 2016, PROCEDIA COMPUT SCI, V102, P34, DOI 10.1016/j.procs.2016.09.366
   Iwata T., 2019, P 2019 IEEE SENS, P14
   Jeong Y, 2018, NANO LETT, V18, P4447, DOI 10.1021/acs.nanolett.8b01526
   Jiang HW, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/iscas45731.2020.9181020
   Jiang YN, 2017, SCI REP-UK, V7, DOI 10.1038/srep45233
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   Jung S, 2022, NATURE, V601, P211, DOI 10.1038/s41586-021-04196-6
   Junsangsri P., 2012, P GREAT LAK S VLSI A
   Kalantzis V., 2021, ARXIV PREPRINT ARXIV
   Karunaratne G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22364-0
   Karunaratne G, 2020, NAT ELECTRON, V3, P327, DOI 10.1038/s41928-020-0410-3
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25455-0
   Kim SG, 2018, ADV MATER TECHNOL-US, V3, DOI 10.1002/admt.201800457
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuznetsova A, 2020, INT J COMPUT VISION, V128, P1956, DOI 10.1007/s11263-020-01316-z
   Le Gallo M, 2017, INT EL DEVICES MEET
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   LeCun Y., 2015, NATURE, V521, P444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Lee J, 2018, ADV MATER, V30, DOI 10.1002/adma.201702770
   Li C, 2019, NAT MACH INTELL, V1, P49, DOI 10.1038/s42256-018-0001-4
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Li T, 2021, INFORMATION, V12, DOI 10.3390/info12020054
   Li XY, 2020, NAT NANOTECHNOL, V15, P776, DOI 10.1038/s41565-020-0722-5
   Lillicrap TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13276
   Lim S, 2019, NEURAL COMPUT APPL, V31, P8101, DOI 10.1007/s00521-018-3659-y
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   Liu S., 2017, P 2017 IEEE INT C AC
   Lu J, 2020, IEEE ELECTR DEVICE L, V41, P1688, DOI 10.1109/LED.2020.3021593
   Lu Y., 2020, P 2020 IEEE INT ELEC
   Lu YF, 2020, IEEE ELECTR DEVICE L, V41, P1245, DOI 10.1109/LED.2020.3006581
   Luo YD, 2020, IEEE T ELECTRON DEV, V67, P4621, DOI 10.1109/TED.2020.3015940
   Mahmoodi MR, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13103-7
   Mennel L, 2020, NATURE, V579, P62, DOI 10.1038/s41586-020-2038-x
   Milo V, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405119
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Negrov D, 2017, NEUROCOMPUTING, V237, P193, DOI 10.1016/j.neucom.2016.10.061
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Ovaska SJ, 2002, IEEE T SYST MAN CY C, V32, P72, DOI 10.1109/TSMCC.2002.801354
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Pan WQ, 2020, IEEE T ELECTRON DEV, V67, P895, DOI 10.1109/TED.2019.2963323
   Pedretti G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05480-0
   Pitas I., 2000, DIGITAL IMAGE PROCES
   Qian FY, 2016, IEEE INT SYMP NANO, P109, DOI 10.1145/2950067.2950081
   Qin YF, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000114
   Qin YF, 2020, IEEE T ELECTRON DEV, V67, P3435, DOI 10.1109/TED.2020.2998457
   Ran HH, 2021, IEEE T COMPUT AID D, V40, P1701, DOI 10.1109/TCAD.2020.3022970
   Roy K, 2019, NATURE, V575, P607, DOI 10.1038/s41586-019-1677-2
   Sainath TN, 2015, NEURAL NETWORKS, V64, P39, DOI 10.1016/j.neunet.2014.08.005
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shi T, 2021, SMALL STRUCT, V2, DOI 10.1002/sstr.202000109
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun L, 2018, NANO LETT, V18, P3229, DOI 10.1021/acs.nanolett.8b00994
   Sun W, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11411-6
   Sun Z, 2021, IEEE T CIRCUITS-II, V68, P2785, DOI 10.1109/TCSII.2021.3068764
   Sun Z, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000042
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P2945, DOI 10.1109/TED.2020.2992435
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sung C, 2018, J APPL PHYS, V124, DOI 10.1063/1.5037835
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tong L, 2021, SCIENCE, V373, P1353, DOI 10.1126/science.abg3161
   Upadhyay NK, 2019, ADV MATER TECHNOL-US, V4, DOI 10.1002/admt.201800589
   Wan TQ, 2021, IEEE ELECTR DEVICE L, V42, P613, DOI 10.1109/LED.2021.3061620
   Wang C, 2021, NAT NANOTECHNOL, V16, P1079, DOI 10.1038/s41565-021-00943-y
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wang ZR, 2019, NAT ELECTRON, V2, P115, DOI 10.1038/s41928-019-0221-6
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
   Xi Y, 2021, P IEEE, V109, P14, DOI 10.1109/JPROC.2020.3004543
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xue CX, 2021, NAT ELECTRON, V4, P81, DOI 10.1038/s41928-020-00505-5
   Yan BA, 2019, ADV INTELL SYST-GER, V1, DOI 10.1002/aisy.201900068
   Yang K, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aba9901
   Yang L, 2021, ADV ELECTRON MATER, V7, DOI 10.1002/aelm.202001182
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yin SH, 2020, IEEE T ELECTRON DEV, V67, P4185, DOI 10.1109/TED.2020.3015178
   Yu S., 2016, P 2016 IEEE INT ELEC
   Yu S, 2014, P 2014 IEEE INT S CI
   Zhang BG, 2020, DES AUT TEST EUROPE, P1594, DOI 10.23919/DATE48585.2020.9116255
   Zhang QT, 2018, NEURAL NETWORKS, V108, P217, DOI 10.1016/j.neunet.2018.08.012
   Zhang T, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201900029
   Zhang W., 2021, INFORM SCIENCES, V64, P1, DOI [10.1016/j.ins.2021.01.079, DOI 10.1016/J.INS.2021.01.079]
   Zhang WQ, 2020, NAT ELECTRON, V3, P371, DOI 10.1038/s41928-020-0435-7
   Zhao H, 2022, TSINGHUA SCI TECHNOL, V27, P455, DOI 10.26599/TST.2021.9010043
   Zhou FC, 2020, NAT ELECTRON, V3, P664, DOI 10.1038/s41928-020-00501-9
   Zhou FC, 2019, NAT NANOTECHNOL, V14, P776, DOI 10.1038/s41565-019-0501-3
   Zhou H., 2022, INFORM SCIENCES, V65
   Zhou HJ, 2021, ADV INTELL SYST-GER, V3, DOI 10.1002/aisy.202100114
   Zhou Y., 2021, IEEE T NEUR NET LEAR
   Zhu RH, 2021, IEEE T ELECTRON DEV, V68, P602, DOI 10.1109/TED.2020.3045684
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 143
TC 4
Z9 4
U1 16
U2 157
PD DEC
PY 2022
VL 15
IS 1
AR 23
DI 10.1007/s12200-022-00025-4
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Bulusu, SS
   Vasudevan, S
AF Bulusu, Satya S.
   Vasudevan, Srivathsan
TI FPGA Accelerator for Machine Learning Interatomic Potential-Based
   Molecular Dynamics of Gold Nanoparticles
SO IEEE ACCESS
DT Article
DE Field programmable gate arrays; Hardware; Servers; Computational
   modeling; Codes; Atomic layer deposition; Nanoparticles; FPGA
   accelerator; high performance computing; molecular dynamics
AB Molecular dynamics (MD) simulations involve computations of forces between atoms and the total energy of the chemical systems. The scientific community is dependent on high-end servers for such computations that are generally sequential and highly power hungry, thereby restricting these computations in reaching experimentally relevant large systems. This work explores the concept of parallelization of the code and accelerating them by exploring the usage of high level synthesis (HLS) based Field Programmable Gate Array (FPGA). This work proposes a hardware and software based interface to implement parallel algorithms in an FPGA framework and communication between the software and hardware interface is implemented. The forces of Au 147 obtained through the ANN based interatomic potentials in the proposed model shows an acceleration of 1.5 times compared with an expensive server with several nodes. Taking this work forward can result in a lab-on-a-chip application and this would potentially be applied onto several large experimentally relevant chemical systems.
C1 [Bulusu, Satya S.] Indian Inst Technol Indore, Dept Chem, Indore 453552, India.
   [Vasudevan, Srivathsan] Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, India.
RP Vasudevan, S (corresponding author), Indian Inst Technol Indore, Dept Elect Engn, Indore 453552, India.
EM svasudevan@iiti.ac.in
CR [Anonymous], 2010, P IEEE INT S PAR DIS
   [Anonymous], 2019, XILINX VIVADO DESIGN
   Behler J, 2016, J CHEM PHYS, V145, DOI 10.1063/1.4966192
   DeBardeleben N, 2014, LECT NOTES COMPUT SC, V8374, P680, DOI 10.1007/978-3-642-54420-0_66
   Dimond R, 2011, P S COMP ARITHM, P191, DOI 10.1109/ARITH.2011.34
   Habboush M., 2022, MICROPROCESSORS MICR, V90
   Herbordt MC, 2007, COMPUTER, V40, P50, DOI 10.1109/MC.2007.79
   Jamro E, 2007, I C FIELD PROG LOGIC, P718, DOI 10.1109/FPL.2007.4380753
   Jindal S, 2017, J CHEM PHYS, V146, DOI 10.1063/1.4983392
   Jovanovic Z, 2012, IET COMPUT DIGIT TEC, V6, P249, DOI 10.1049/iet-cdt.2011.0132
   Kashino R., 2022, P INT C HIGH PERF CO, P84
   Kondratyuk N, 2021, INT J HIGH PERFORM C, V35, P312, DOI 10.1177/10943420211008288
   Li LY, 2021, IEEE T COMPUT, V70, P581, DOI 10.1109/TC.2020.2991177
   Maeda Y, 2005, IEEE T NEURAL NETWOR, V16, P1664, DOI 10.1109/TNN.2005.852237
   Mater AC, 2019, J CHEM INF MODEL, V59, P2545, DOI 10.1021/acs.jcim.9b00266
   Pascoe C., 2020, P IEEE HIGH PERF EXT, P1
   Restrepo HF, 2000, ANN IEEE SYM FIELD P, P337, DOI 10.1109/FPGA.2000.903443
   Shen J., 2017, ARXIV170701217
   Shi L, 2012, IEEE T COMPUT, V61, P804, DOI 10.1109/TC.2011.112
   Vestias M., 2014, 2014 24 INT C FIELD, P1
   Xilinx, 2019, KC705 EVALUATION BOA
   Xilinx, 2017, XILINX DMA BRIDGE SU
   Xilinx, 2019, VIVADO DESIGN SUITE
   Yang C, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356179
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Zohouri HR, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P409, DOI 10.1109/SC.2016.34
NR 26
TC 0
Z9 0
U1 0
U2 6
PY 2022
VL 10
BP 40338
EP 40347
DI 10.1109/ACCESS.2022.3165650
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Goel, B
   Dey, AK
   Bharti, P
   Ben Ahmed, K
   Chellappan, S
AF Goel, Bharti
   Dey, Arup Kanti
   Bharti, Pratool
   Ben Ahmed, Kaoutar
   Chellappan, Sriram
GP IEEE
TI Detecting Distracted Driving Using a Wrist-Worn Wearable
SO 2018 IEEE INTERNATIONAL CONFERENCE ON PERVASIVE COMPUTING AND
   COMMUNICATIONS WORKSHOPS (PERCOM WORKSHOPS)
SE International Conference on Pervasive Computing and Communications
DT Proceedings Paper
CT IEEE International Conference on Pervasive Computing and Communications
   (PerCom)
CY MAR 19-23, 2018
CL Athens, GREECE
DE wearable sensing; intelligent transportation systems; distracted
   driving; machine learning; wrist-worn wearables; road safety
AB In this paper, we attempt to detect instances of distracted driving using a wrist-worn wearable embedded with an accelerometer and a gyroscope. In our experimental study, 16 adult participants were asked to drive a driving simulator that is equipped with realistic driving conditions like brakes, accelerator, steering wheel and a large screen for road scene visualization. The simulator is also programmed for drivers to experience different environmental scenarios like day time, night time, fog and rain/ snow. While driving, participants engaged in a randomized sequence of calling, texting and reading from a phone while simultaneously driving. Throughout the experiment, each subject wore a wearable watch on the wrist which recorded the resulting acceleration and rotation of the wrist via an embedded accelerometer and gyroscope. Subsequently, we extracted a selected number of features from the sensory data, and designed machine learning techniques for detecting instances of distracted driving. Our performance evaluations reveal very good Precision, Recall, and F1-Scores. We believe that our paper introduces a new and potentially important application of wrist-worn wearables to enhance road safety.
C1 [Goel, Bharti; Dey, Arup Kanti; Bharti, Pratool; Ben Ahmed, Kaoutar; Chellappan, Sriram] Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
RP Goel, B (corresponding author), Univ S Florida, Dept Comp Sci & Engn, Tampa, FL 33620 USA.
EM bharti@mail.usf.edu; arupkantidey@mail.usf.edu; pratool@mail.usf.edu;
   kbenahmed@mail.usf.edu; sriramc@usf.edu
CR Almuallim H., 1991, AAAI-91. Proceedings Ninth National Conference on Artificial Intelligence, P547
   [Anonymous], 2013, P 11 ANN INT C MOBIL
   Banos O, 2014, SENSORS-BASEL, V14, P6474, DOI 10.3390/s140406474
   Bo C., 2013, P 19 ANN INT C MOB C, P199, DOI DOI 10.1145/2500423.2504575
   Breiman L., 2001, MACHINE LEARNING
   Fazeen M, 2012, IEEE T INTELL TRANSP, V13, P1462, DOI 10.1109/TITS.2012.2187640
   Montillo A, 2009, LECT STAT FDN DATA A
   National Safety Council, 2016, DISTR DRIV PUBL OP P
   Shabeer HA, 2012, PROCEDIA ENGINEER, V30, P623, DOI 10.1016/j.proeng.2012.01.907
   Simons DJ, 1999, PERCEPTION, V28, P1059, DOI 10.1068/p2952
   Singh P., 2013, P 3 ACM S COMP DEV N
   Tudor S., 2015, P 8 ACM INT C PERV T
   Yang J, 2011, MOBICOM, P97, DOI 10.1145/2030613.2030625
NR 13
TC 1
Z9 1
U1 0
U2 4
PY 2018
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
DA 2023-11-11
ER

PT C
AU Forti, AC
   Heinrich, L
   Guth, M
AF Forti, A. C.
   Heinrich, L.
   Guth, M.
GP IOP Publishing
TI Hardware Accelerated ATLAS Workloads on the WLCG Grid
SO 19TH INTERNATIONAL WORKSHOP ON ADVANCED COMPUTING AND ANALYSIS
   TECHNIQUES IN PHYSICS RESEARCH
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 19th International Workshop on Advanced Computing and Analysis
   Techniques in Physics Research (ACAT)
CY MAR 11-15, 2019
CL Saas Fee, SWITZERLAND
AB In recent years the usage of machine learning techniques within data-intensive sciences in general and high-energy physics in particular has rapidly increased, in part due to the availability of large datasets on which such algorithms can be trained, as well as suitable hardware, such as graphic or tensor processing units, which greatly accelerate the training and execution of such algorithms. Within the HEP domain, the development of these techniques has so far relied on resources external to the primary computing infrastructure of the WLCG (Worldwide LHC Computing Grid). In this paper we present an integration of hardware-accelerated workloads into the Grid through the declaration of dedicated queues with access to hardware accelerators and the use of Linux container images holding a modern data science software stack. A frequent use-case in the development of machine learning algorithms is the optimization of neural networks through the tuning of their Hyper Parameters (HP). For this often a large range of network variations must be trained and compared, which for some optimization schemes can be performed in parallel - a workload well suited for Grid computing. An example of such a hyper-parameter scan on Grid resources for the case of flavor tagging within ATLAS is presented.
C1 [Forti, A. C.] Univ Manchester, Sch Phys & Astron, Oxford Rd, Manchester M13 9PL, Lancs, England.
   [Heinrich, L.] CERN European Lab Particle Phys, Rue Geneve 23, CH-1211 Geneva, Switzerland.
   [Guth, M.] Albert Ludwigs Univ Freiburg, Friedrichstr 39, D-79085 Freiburg, Germany.
RP Forti, AC (corresponding author), Univ Manchester, Sch Phys & Astron, Oxford Rd, Manchester M13 9PL, Lancs, England.
CR Abadi M., 2016, ARXIV160304467
   Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   ATLAS Collaboration, 2017, ATLPHYSPUB2017013 AT
   ATLAS Collaboration, 2019, HYP PAR SCAN DEEP LE
   Heinrich L, 2019, CONTINUOUS ANAL ATLA
   Kurtzer GM, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0177459
   Paganini M, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/4/042031
   Salamani D, 2018, P IEEE INT C E-SCI, P348, DOI 10.1109/eScience.2018.00091
NR 8
TC 0
Z9 0
U1 0
U2 1
PY 2020
VL 1525
AR 012059
DI 10.1088/1742-6596/1525/1/012059
WC Computer Science, Interdisciplinary Applications; Physics,
   Multidisciplinary
DA 2023-11-11
ER

PT J
AU Heinz, C
   Hofmann, J
   Korinth, J
   Sommer, L
   Weber, L
   Koch, A
AF Heinz, Carsten
   Hofmann, Jaco
   Korinth, Jens
   Sommer, Lukas
   Weber, Lukas
   Koch, Andreas
TI The TaPaSCo Open-Source Toolflow for the Automated Composition of
   Task-Based Parallel Reconfigurable Computing Systems
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE FPGA; Reconfigurable computing; Design space exploration; System-on-Chip
   design; Design automation; High-level synthesis; Scalability;
   Portability; TaPaSCo; Heterogeneous computing; Parallel computing;
   RISC-V
AB The integration of FPGA-based accelerators into a complete heterogeneous system is a challenging task faced by many researchers and engineers, especially now that FPGAs enjoy increasing popularity as implementation platforms for efficient, application-specific accelerators for domains such as signal processing, machine learning and intelligent storage. To lighten the burden of system integration from the developers of accelerators, the open-source TaPaSCo framework presented in this work provides an automated toolflow for the construction of heterogeneous many-core architectures from custom processing elements, and a simple, uniform programming interface to utilize spatially distributed, parallel computation on FPGAs. TaPaSCo aims to increase the scalability and portability of FPGA designs through automated design space exploration, greatly simplifying the scaling of hardware designs and facilitating iterative growth and portability across FPGA devices and families. This work describes TaPaSCo with its primary design abstractions and shows how TaPaSCo addresses portability and extensibility of FPGA hardware designs for systems-on-chip. A study of successful projects using TaPaSCo shows its versatility and can serve as inspiration and reference for future users, with more details on the usage of TaPaSCo presented in an in-depth case study and a short overview of the workflow.
C1 [Heinz, Carsten; Hofmann, Jaco; Korinth, Jens; Sommer, Lukas; Weber, Lukas; Koch, Andreas] Tech Univ Darmstadt, Darmstadt, Germany.
RP Heinz, C (corresponding author), Tech Univ Darmstadt, Darmstadt, Germany.
EM heinz@esa.tu-darmstadt.de; korinth@esa.tu-darmstadt.de;
   sommer@esa.tu-darmstadt.de; weber@esa.tu-darmstadt.de;
   koch@esa.tu-darmstadt.de
CR ADLER M, 2011, P INT S FIELD PROGR, P25
   Aldinucci M., 2017, PROGRAMMING MULTICOR
   Amid A, 2020, IEEE MICRO, V40, P10, DOI 10.1109/MM.2020.2996616
   [Anonymous], 2013, 2013 8 INT WORKSHOP, DOI DOI 10.1109/RECOSOC.2013.6581538
   Asanovic K., 2016, ROCKET CHIP GENERATO
   Baaij C., 2010, 2010 13 EUR C DIG SY
   Bachrach J, 2012, DES AUT CON, P1212
   BlueSpec Inc, 2003, BLUESPEC SYSTEMVERIL
   Brugnoni S., 2016, 3 INT WORKSH FPGAS S
   Callahan TJ, 2000, COMPUTER, V33, P62, DOI 10.1109/2.839323
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Charles P, 2005, ACM SIGPLAN NOTICES, V40, P519, DOI 10.1145/1103845.1094852
   Chen YT, 2015, INT SYM PERFORM ANAL, P157, DOI 10.1109/ISPASS.2015.7095795
   de la Chevallerie D, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P314, DOI 10.1109/FPT.2014.7082807
   Digilent Inc, 2015, ZEDBOARD
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Embedded Systems and Applications Group, 2020, TU DARMST TAPASCO CO
   Fleming K., 2016, FPGAS SOFTWARE PROGR, P245
   Frigo J., 2001, P 2001 ACM SIGDA 9 I, P134, DOI DOI 10.1145/360276.360326
   Gadke H., 2007, DESIGN AUTOMATION TE
   Gerstlauer A, 2009, IEEE T COMPUT AID D, V28, P1517, DOI 10.1109/TCAD.2009.2026356
   Gill A, 2009, LECT NOTES COMPUT SC, V6041, P18
   Gokhale M, 2000, ANN IEEE SYM FIELD P, P49, DOI 10.1109/FPGA.2000.903392
   Guo Z, 2005, DES AUT TEST EUROPE, P112
   Heinz C, 2019, 2019 INT C RECONFIGU, P1
   Heinz C, 2020, PROCEEDINGS OF 2020 10TH IEEE/ACM INTERNATIONAL WORKSHOP ON RUNTIME AND OPERATING SYSTEMS FOR SUPERCOMPUTERS (ROSS 2020), P22, DOI 10.1109/ROSS51935.2020.00008
   Hofmann J., 2019, INT WORKSH ACC AN DA
   Hofmann J, 2016, PROC INT CONF RECON
   Hofmann J, 2016, IEEE COMPUT SOC CONF, P845, DOI 10.1109/CVPRW.2016.110
   Huang SS, 2008, LECT NOTES COMPUT SC, V5142, P76, DOI 10.1007/978-3-540-70592-5_5
   IEEE Standards Association, 2014, 16852014 IEEE
   Intel Corporation, OP PROGR ACCL ENG
   Intel Inc, 2016, INT FPGA SDK OPENCL
   Ismail A, 2011, ANN IEEE SYM FIELD P, P170, DOI 10.1109/FCCM.2011.48
   Kapre Nachiket, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293942
   Kapre N, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3027486
   Karandikar S, 2018, CONF PROC INT SYMP C, P29, DOI 10.1109/ISCA.2018.00014
   King M., 2015, P 2015 ACM SIGDA INT, P13, DOI DOI 10.1145/2684746.2689064
   Koch A, 2019, INT S APPL REC COMP
   Koch D, 2008, I C FIELD PROG LOGIC, P119, DOI 10.1109/FPL.2008.4629918
   Korinth J, 2015, ANN IEEE SYM FIELD P, P195, DOI 10.1109/FCCM.2015.22
   Kurth A., 2017, ARXIV171206497
   Lange H., 2000, Field-Programmable Logic and Applications. Roadmap to Reconfigurable Computing. 10th International Conference, FPL 2000. Proceedings (Lecture Notes in Computer Science Vol.1896), P615
   Lo C, 2018, I C FIELD PROG LOGIC, P272, DOI 10.1109/FPL.2018.00054
   Lübbers E, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596540
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Minhas Umar Ibrahim, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P334, DOI 10.1007/978-3-030-17227-5_24
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Ober M, 2019, PROCEEDINGS OF H2RC 2019: 2019 FIFTH IEEE/ACM INTERNATIONAL WORKSHOP ON HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC), P26, DOI 10.1109/H2RC49586.2019.00009
   Oppermann J, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P36, DOI 10.1109/ICFPT47387.2019.00013
   Oppermann J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3317670
   PECK W, 2006, 2006 INT C FIELD PRO, P1
   Peck W, 2006, I C FIELD PROG LOGIC, P885
   Pengfei Zhang, 2015, 2015 IEEE Tenth International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), P1, DOI 10.1109/ISSNIP.2015.7106972
   Pilato C, 2013, I C FIELD PROG LOGIC
   REPARA Project Consortium, 2016, WORK PACK 5 DEL
   Rodríguez A, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061877
   Skalicky S., 2014, ARXIV14084725
   So Hayden Kwok-Hay, 2007, BORPH OPERATING SYST
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Sommer L, 2017, PROC INT CONF RECON
   Sommer L, 2017, IEEE INT CONF ASAP, P201, DOI 10.1109/ASAP.2017.7995280
   Sotiriou-Xanthopoulos E., 2016, ACM T EMBED COMPUT S, V15, P1, DOI DOI 10.1145/2866578
   Weber L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P251, DOI 10.1109/ICFPT47387.2019.00040
   Weber S.J., 2001, CORAM COMBINATIONAL, V9, P805
   Wenzel J, 2016, P IEEE RAP SYST PROT, P86, DOI 10.1145/2990299.2990314
   Xilinx Inc, 2018, VIV HIGH LEV SYNTH
   Xilinx Inc, 2020, VIT PLATF
   Xu C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P157, DOI 10.1145/3020078.3021747
   Yang HJ, 2014, ANN IEEE SYM FIELD P, P117, DOI 10.1109/FCCM.2014.43
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
NR 72
TC 10
Z9 10
U1 0
U2 0
PD MAY
PY 2021
VL 93
IS 5
SI SI
BP 545
EP 563
DI 10.1007/s11265-021-01640-8
EA MAY 2021
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Gruson, D
   Bernardini, S
   Dabla, PK
   Gouget, B
   Stankovic, S
AF Gruson, Damien
   Bernardini, Sergio
   Dabla, Pradeep Kumar
   Gouget, Bernard
   Stankovic, Sanja
TI Collaborative AI and Laboratory Medicine integration in precision
   cardiovascular medicine
SO CLINICA CHIMICA ACTA
DT Article
DE Artificial intelligence; Cardiology; Laboratory; Biomarkers; Data;
   Machine learning; Personalized
ID EUROPEAN-SOCIETY; MACHINE; PREDICTION; DISEASES
AB Artificial Intelligence (AI) is a broad term that combines computation with sophisticated mathematical models and in turn allows the development of complex algorithms which are capable to simulate human intelligence such as problem solving and learning. It is devised to promote a significant paradigm shift in the most diverse areas of medical knowledge. On the other hand, Cardiology is a vast field dealing with diseases relating to the heart, the circulatory system, and includes coronary heart disease, cerebrovascular disease, rheumatic heart disease and other conditions. AI has emerged as a promising tool in cardiovascular medicine which is aimed in augmenting the effectiveness of the cardiologist and to extend better quality to patients. It has the ability to support decision-making and improve diagnostic and prognostic performance. Attempt has also been made to explore novel genotypes and phenotypes in existing cardiovascular diseases, improve the quality of patient care, to enable cost-effectiveness with reduce readmission and mortality rates. Our review addresses the integration of AI and laboratory medicine as an accelerator of personalization care associated with the precision and the need of value creation services in cardiovascular medicine.
C1 [Gruson, Damien] Clin Univ St Luc, Dept Clin Biochem, 10 Ave Hippocrate, B-1200 Brussels, Belgium.
   [Gruson, Damien] Catholic Univ Louvain, 10 Ave Hippocrate, B-1200 Brussels, Belgium.
   [Gruson, Damien] Clin Univ St Luc, Pole Rech Endocrinol Diabet & Nutr, Inst Rech Expt & Clin, Brussels, Belgium.
   [Bernardini, Sergio] Univ Tor Vergata, Dept Expt Med, Rome, Italy.
   [Dabla, Pradeep Kumar] Maulana Azad Med Coll, Dept Biochem, GB Pant Inst Postgrad Med Educ & Res, New Delhi, India.
   [Gouget, Bernard] Com Francais Accreditat Cofrac, President Healthcare Div Comm, F-75012 Paris, France.
   [Stankovic, Sanja] Clin Ctr Serbia, Ctr Med Biochem, Belgrade, Serbia.
   [Gruson, Damien; Bernardini, Sergio; Dabla, Pradeep Kumar; Gouget, Bernard; Stankovic, Sanja] Int Federat Clin Chem & Lab Med IFCC, Emerging Technol Div MHBLM Comm, Rome, Italy.
RP Gruson, D (corresponding author), Clin Univ St Luc, Dept Clin Biochem, 10 Ave Hippocrate, B-1200 Brussels, Belgium.; Gruson, D (corresponding author), Catholic Univ Louvain, 10 Ave Hippocrate, B-1200 Brussels, Belgium.
EM damien.gruson@uclouvain.be
CR Ambale-Venkatesh B, 2017, CIRC RES, V121, P1092, DOI 10.1161/CIRCRESAHA.117.311312
   [Anonymous], 2019, BMJ OPEN QUAL, DOI DOI 10.3390/PATHOGENS8020060
   Berikol GB, 2016, J MED SYST, V40, DOI 10.1007/s10916-016-0432-6
   Brahmbhatt Darshan H, 2019, Card Fail Rev, V5, P86, DOI 10.15420/cfr.2019.5.3
   Burns DJP, 2020, JACC-HEART FAIL, V8, P212, DOI 10.1016/j.jchf.2019.09.007
   Chua W, 2019, EUR HEART J, V40, P1268, DOI 10.1093/eurheartj/ehy815
   Cikes M, 2019, EUR J HEART FAIL, V21, P74, DOI 10.1002/ejhf.1333
   Cowie MR, 2019, EUR HEART J, V40, P2283, DOI 10.1093/eurheartj/ehz490
   Cowie MR, 2016, EUR HEART J, V37, P63, DOI 10.1093/eurheartj/ehv416
   de Anda-Jáuregui G, 2020, FRONT ONCOL, V10, DOI 10.3389/fonc.2020.00423
   Dogan MV, 2018, GENES-BASEL, V9, DOI 10.3390/genes9120641
   Fleuren LM, 2020, INTENS CARE MED, V46, P383, DOI 10.1007/s00134-019-05872-y
   Frederix I, 2019, EUR J PREV CARDIOL, V26, P1166, DOI 10.1177/2047487319832394
   Greaves RF, 2019, CLIN CHIM ACTA, V495, P570, DOI 10.1016/j.cca.2019.05.021
   Gruson D, 2019, CLIN BIOCHEM, V69, P1, DOI 10.1016/j.clinbiochem.2019.04.013
   Hathaway QA, 2019, CARDIOVASC DIABETOL, V18, DOI 10.1186/s12933-019-0879-0
   Hedman A.K., 2020, HEART
   Hure A, 2019, PATHOLOGY, V51, P621, DOI 10.1016/j.pathol.2019.06.003
   Mach F, 2020, EUR HEART J, V41, P111, DOI [10.1093/eurheartj/ehz455, 10.15829/1560-4071-2020-3826]
   Marc M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-63018-3
   Matkovich SJ, 2019, CURR OPIN CARDIOL, V34, DOI 10.1097/HCO.0000000000000611
   McNamara RL, 2015, J AM HEART ASSOC, V4, DOI 10.1161/JAHA.115.001767
   Mezzatesta S, 2019, COMPUT METH PROG BIO, V177, P9, DOI 10.1016/j.cmpb.2019.05.005
   Niederer SA, 2019, NAT REV CARDIOL, V16, P100, DOI 10.1038/s41569-018-0104-y
   Ponikowski P, 2016, EUR HEART J, V37, P2129, DOI 10.1093/eurheartj/ehw128
   Poss A.M., 2020, J CLIN INVEST
   QUIGLEY HA, 1994, ARCH OPHTHALMOL-CHIC, V112, P644, DOI 10.1001/archopht.1994.01090170088028
   Rosamond W, 2008, CIRCULATION, V117, pE25, DOI 10.1161/CIRCULATIONAHA.107.187998
   Shameer K, 2017, BIOCOMPUT-PAC SYM, P276, DOI 10.1142/9789813207813_0027
   Siegersma KR, 2019, NETH HEART J, V27, P403, DOI 10.1007/s12471-019-01311-1
   Than MP, 2019, CIRCULATION, V140, P899, DOI 10.1161/CIRCULATIONAHA.119.041980
   Thygesen K, 2007, J AM COLL CARDIOL, V50, P2173, DOI [10.1161/CIRCULATIONAHA.107.187397, 10.1016/j.jacc.2007.09.011]
   Vernon ST, 2019, MICROCIRCULATION, V26, DOI 10.1111/micc.12488
   Weng SF, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0174944
   Wu CC, 2019, COMPUT METH PROG BIO, V173, P109, DOI 10.1016/j.cmpb.2019.01.013
   Yan Y, 2019, J GERIATR CARDIOL, V16, P585, DOI 10.11909/j.issn.1671-5411.2019.08.010
NR 36
TC 14
Z9 15
U1 2
U2 20
PD OCT
PY 2020
VL 509
BP 67
EP 71
DI 10.1016/j.cca.2020.06.001
WC Medical Laboratory Technology
DA 2023-11-11
ER

PT C
AU Srinivasa, S
   Ramanathan, AK
   Sundaram, J
   Kurian, D
   Gopal, S
   Jain, N
   Srinivasan, A
   Iyer, R
   Narayanan, V
   Karnik, T
AF Srinivasa, Srivatsa
   Ramanathan, Akshay Krishna
   Sundaram, Jainaveen
   Kurian, Dileep
   Gopal, Srinivasan
   Jain, Nilesh
   Srinivasan, Anuradha
   Iyer, Ravi
   Narayanan, Vijaykrishnan
   Karnik, Tanay
GP IEEE
TI Trends and Opportunities for SRAM Based In-Memory and Near-Memory
   Computation
SO PROCEEDINGS OF THE 2021 TWENTY SECOND INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2021)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 22nd International Symposium on Quality Electronic Design (ISQED)
CY APR 07-09, 2021
CL ELECTR NETWORK
DE In-Memory Computation; Near-memory Computation; SRAM
AB Changes in application trends along with increasing number of connected devices have led to explosion in the amount of data being generated every single day. Computing systems need to efficiently process these huge amounts of data and generate results, classify objects, stream high quality videos and so on. In-Memory Computing and Near-Memory Computing have been emerged as the popular design choices to address the challenges in executing the above-mentioned tasks. Through In-Memory Computing, SRAM Banks can be repurposed as compute engines while performing Bulk Boolean operations. Near-Memory techniques have shown promise in improving the performance of Machine learning tasks. By carefully understanding the design we describe the opportunities towards amalgamating both these design techniques for obtaining further performance enhancement and achieving lower power budget while executing fundamental Machine Learning primitives. In this work, we take the example of Sparse Matrix Multiplication, and design an I-NMC accelerator which speeds up the index handling by 10x-60x and 10x-70x energy efficiency based on the workload dimensions as compared with non I-NMC solution occupying just 1% of the overall hardware area.
C1 [Srinivasa, Srivatsa; Sundaram, Jainaveen; Kurian, Dileep; Gopal, Srinivasan; Jain, Nilesh; Srinivasan, Anuradha; Iyer, Ravi; Karnik, Tanay] Intel Corp, Santa Clara, CA 95051 USA.
   [Ramanathan, Akshay Krishna; Narayanan, Vijaykrishnan] Penn State Univ, University Pk, PA 16802 USA.
RP Srinivasa, S (corresponding author), Intel Corp, Santa Clara, CA 95051 USA.
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   [Anonymous], 2020 53 ANN IEEE ACM
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chongala SRSS, 2020, IEEE T COMPUT AID D, V39, P3881, DOI 10.1109/TCAD.2020.3012789
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Fujiki D., 2019 ACM IEEE 46 ISC
   George Sumitha, 2018, 2018 51 ANN IEEE ACM
   Hsueh F.-K., 2017, INT EL DEVICES MEET
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Kim S., IEEE 28 EPEPS
   Ku AKA, 2008, EUC 2008: PROCEEDINGS OF THE 5TH INTERNATIONAL CONFERENCE ON EMBEDDED AND UBIQUITOUS COMPUTING, VOL 1, MAIN CONFERENCE, P37, DOI 10.1109/EUC.2008.154
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Parveen F, 2018, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2018.8297350
   Ramanathan A.K., 2020 IEDM
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Srinivasa S, 2019, S VLSI TECH, pT32, DOI 10.23919/VLSIT.2019.8776506
   Srinivasa Srivatsa, 2019 IEEE ISCAS
   Thirumala SK, 2019, I SYMPOS LOW POWER E
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 20
TC 1
Z9 1
U1 0
U2 6
PY 2021
BP 547
EP 552
DI 10.1109/ISQED51717.2021.9424263
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Saggese, A
   Vento, M
   Vigilante, V
AF Saggese, Alessia
   Vento, Mario
   Vigilante, Vincenzo
BE Vento, M
   Percannella, G
TI MIVIABot: A Cognitive Robot for Smart Museum
SO COMPUTER ANALYSIS OF IMAGES AND PATTERNS, CAIP 2019, PT I
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 18th international Conference on Computer Analysis of Images and
   Patterns (CAIP)
CY SEP 03-05, 2019
CL Salerno, ITALY
DE Cognitive robotics; Machine learning; Cultural heritage
AB Cognitive robots are robots provided with artificial intelligence capabilities, able to properly interact with people and with the objects in an a priori unknown environment, using advanced artificial intelligence algorithms. For instance, a humanoid robot can be perceived as a plausible tourist guide in a museum. Within this context, in this work we present how the latest findings in the field of machine learning and pattern recognition can be applied to equip a robot with sufficiently advanced perception capabilities in order to successfully guide visitors through the halls and the attraction in a museum.
   The challenge of running all those algorithms on a mobile, embedded platform in real time is tackled on an architectural level, where all the artificial intelligence features are tuned to run with a low computational burden and a Neural Network accelerator is included in the hardware setup. Improved robustness and predictable latency is obtained avoiding the use of cloud services in the system.
   Our robot, that we call MIVIABot, is able to decode and understand speech as well as extract soft biometrics from its interlocutor such as age, gender and emotional status. The robot can integrate all those elements in a dialog, using basic Natural Language Processing capabilities.
C1 [Saggese, Alessia; Vento, Mario; Vigilante, Vincenzo] Univ Salerno, I-84084 Salerno, SA, Italy.
RP Vigilante, V (corresponding author), Univ Salerno, I-84084 Salerno, SA, Italy.
EM asaggese@unisa.it; mvento@unisa.it; vvigilante@unisa.it
CR Amert T, 2017, REAL TIM SYST SYMP P, P104, DOI 10.1109/RTSS.2017.00017
   [Anonymous], 2015, BMVC
   [Anonymous], 2001, P 2001 IEEE COMPUTER
   Bruce A, 2002, 2002 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND AUTOMATION, VOLS I-IV, PROCEEDINGS, P4138, DOI 10.1109/ROBOT.2002.1014396
   Collobert R, 2016, WAV2LETTER END TO EN
   Duffy BR, 2003, ROBOT AUTON SYST, V42, P177, DOI 10.1016/S0921-8890(02)00374-3
   Flacco F, 2012, IEEE INT CONF ROBOT, P338, DOI 10.1109/ICRA.2012.6225245
   Foggia P, 2019, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON APPLICATIONS OF INTELLIGENT SYSTEMS (APPIS 2019), DOI 10.1145/3309772.3309781
   Fulgenzi C, 2007, IEEE INT CONF ROBOT, P1610, DOI 10.1109/ROBOT.2007.363554
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   Hannun A. Y., 2014, ARXIV14082873
   Huang Gary B., 2008, LABELED FACES WILD D
   Kemp CC, 2007, IEEE ROBOT AUTOM MAG, V14, P20, DOI 10.1109/MRA.2007.339604
   Kunze J., 2017, ARXIV170600290
   Liao Shengcai, 2016, IEEE Trans Pattern Anal Mach Intell, V38, P211, DOI 10.1109/TPAMI.2015.2448075
   Mollahosseini A, 2019, IEEE T AFFECT COMPUT, V10, P18, DOI 10.1109/TAFFC.2017.2740923
   Mori M, 2012, IEEE ROBOT AUTOM MAG, V19, P98, DOI 10.1109/MRA.2012.2192811
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Savchenko A.V., 2018, ARXIV180707718
   Voxforge, 2019, IT DAT
NR 20
TC 4
Z9 4
U1 0
U2 4
PY 2019
VL 11678
BP 15
EP 25
DI 10.1007/978-3-030-29888-3_2
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Jin, H
   Chen, D
   Zheng, L
   Huang, Y
   Yao, PC
   Zhao, J
   Liao, XF
   Jiang, WB
AF Jin, Hai
   Chen, Dan
   Zheng, Long
   Huang, Yu
   Yao, Pengcheng
   Zhao, Jin
   Liao, Xiaofei
   Jiang, Wenbin
TI Accelerating Graph Convolutional Networks Through a PIM-Accelerated
   Approach
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Accelerators; graph convolutional networks; processing-in-memory
AB Graph convolutional networks (GCNs) are promising to enable machine learning on graph data. GCNs show potential vertex-level and intra-vertex parallelism for GPU acceleration, but their irregular memory accesses arising in aggregation operations and the inherent sparsity for vertex features of graphs cause inefficiencies on the GPU. In this paper, we present gPIM, which aims to accelerate GCNs inference through a processing-in-memory (PIM) enabled architecture. gPIM is expected to perform compute-intensive combination on the GPU while aggregation and memory-bound combination are offloaded to the PIM-featured hybrid memory cubes (HMCs). To maximize the efficiency of such GPU-HMC architecture, gPIM is novel with two key designs: 1) A GCN-induced graph partitioning that minimizes communication overheads between cubes, 2) A programmer-transparent performance estimation mechanism that predicts the performance bound of operations accurately for workload offloading. Experimental results show that gPIM significantly outperforms Intel Xeon E5-2680v3 CPU (8,979.52x), NVIDIA Tesla V100 GPU (96.01x), and a state-of-the-art GCN accelerator AWB-GCN (4.18x).
C1 [Jin, Hai; Chen, Dan; Zheng, Long; Huang, Yu; Yao, Pengcheng; Zhao, Jin; Liao, Xiaofei; Jiang, Wenbin] Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Clusters & Grid Comp, Wuhan 430074, Hubei, Peoples R China.
RP Chen, D (corresponding author), Huazhong Univ Sci & Technol, Natl Engn Res Ctr Big Data Technol & Syst, Sch Comp Sci & Technol, Serv Comp Technol & Syst Lab,Clusters & Grid Comp, Wuhan 430074, Hubei, Peoples R China.
EM hjin@mail.hust.edu.cn; cdhust@hust.edu.cn; longzh@hust.edu.cn;
   yuh@hust.edu.cn; pcyao@hust.edu.cn; zjin@hust.edu.cn;
   xfliao@hust.edu.cn; wenbinjiang@hust.edu.cn
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   [Anonymous], 2010, NVID PROF
   [Anonymous], 2018, GAT LEV SIM METH
   ark intel, 2014, INT XEON E5 2680 V3
   Chen D., 2022, PROC INT C HIGH PERF, P632
   Chen D, 2022, INT PARALL DISTRIB P, P246, DOI 10.1109/IPDPS53621.2022.00032
   Dai HJ, 2018, PR MACH LEARN RES, V80
   deepmind, 2018, GRAPH NETS LIB
   developer nvidia, 2007, NVID SMI
   docs dgl, 2019, ABOUT US
   Duvenaud David K., 2015, P 28 INT C NEUR INF, P2224, DOI [DOI 10.48550/ARXIV.1509.09292, DOI 10.5555/2969442.2969488]
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, 10.48550/arxiv.1903.02428]
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Gonzalez Joseph E, 2012, 10 USENIX S OP SYST, P17, DOI DOI 10.1145/74850.74870
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Kersting K., 2016, BENCHMARK DATA SETS
   Kim G, 2013, INT CONFER PARA, P145, DOI 10.1109/PACT.2013.6618812
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1706.02216, DOI 10.48550/ARXIV.1706.02216]
   Leidel John D., 2014, 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P1465, DOI 10.1109/IPDPSW.2014.164
   Lerer A, 2019, Arxiv, DOI arXiv:1903.12287
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Ma LX, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P443
   Micron Technology Inc., 2015, HYBRID MEMORY CUBE S
   Kipf TN, 2017, Arxiv, DOI [arXiv:1609.02907, DOI 10.48550/ARXIV.1609.02907]
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   pytorch, PYTORCH PROF
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Tian C, 2020, INT PARALL DISTRIB P, P936, DOI 10.1109/IPDPS47924.2020.00100
   Tsai PA, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P641, DOI [10.1109/MICRO.2018.00058, 10.1109/MICR0.2018.00058]
   Wang YK, 2021, Arxiv, DOI arXiv:2006.06608
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Xu K., 2018, INT C LEARN REPR ICL, DOI DOI 10.48550/ARXIV.1810.00826
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 41
TC 0
Z9 0
U1 4
U2 4
PD SEPT 1
PY 2023
VL 72
IS 9
BP 2628
EP 2640
DI 10.1109/TC.2023.3257514
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Das, P
   Kapoor, HK
AF Das, Palash
   Kapoor, Hemangee K.
TI nZESPA: A Near-3D-Memory Zero Skipping Parallel Accelerator for CNNs
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Accelerator architecture; convolutional neural network (CNN);
   near-memory processing (NMP); sparsity
AB Convolutional neural networks (CNNs) are one of the most popular machine learning tools for computer vision. The ubiquitous use in several applications with its high computation-cost has made it lucrative for optimization through accelerated architecture. State-of-the-art has either exploited the parallelism of CNNs, or eliminated computations through sparsity or used near-memory processing (NMP) to accelerate the CNNs. We introduce NMP-fully sparse architecture, which acquires all three capabilities. The proposed architecture is parallel and hence processes the independent CNN tasks concurrently. To exploit the sparsity, the proposed system employs a dataflow, namely, Near-3D-Memory Zero Skipping Parallel dataflow or nZESPA dataflow. This dataflow maintains the compressed-sparse encoding of data that skips all ineffectual zero-valued computations of CNNs. We design a custom accelerator which employs the nZESPA dataflow. The grids of nZESPA modules are integrated into the logic layer of the hybrid memory cube. This integration saves a significant amount of off-chip communications while implementing the concept of NMP. We compare the proposed architecture with three other architectures which either do not exploit sparsity (NMP-dense) or do not employ NMP (traditional-fully sparse) or do not include both (traditional-dense). The proposed system outperforms the baselines in terms of performance and energy consumption while executing CNN inference.
C1 [Das, Palash; Kapoor, Hemangee K.] Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
RP Das, P (corresponding author), Indian Inst Technol Guwahati, Dept Comp Sci & Engn, Gauhati 781039, India.
EM palash.das@iitg.ac.in; hemangee@iitg.ac.in
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Angizi S, 2018, DES AUT CON, DOI 10.1145/3195970.3196009
   [Anonymous], 2013, PROC 30 INT C MACH L
   Azarkhish E, 2018, IEEE T PARALL DISTR, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Das P, 2018, I CONF VLSI DESIGN, P380, DOI 10.1109/VLSID.2018.94
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Eckert Y., 2014, WONDP, P1
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   GeSI (Global e-Sustainability Initiative), 2015, SMARTER2030 ICT SOL
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Jin XX, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901353
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Li JJ, 2018, DES AUT TEST EUROPE, P343, DOI 10.23919/DATE.2018.8342033
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park H, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2968476
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Rhu M, 2016, INT SYMP MICROARCH
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suyi Li, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P469, DOI 10.1109/CSIE.2009.999
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Vuduc R. W., 2003, AUTOMATIC PERFORMANC
   Xu L., 2015, 2015 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2015.7157594
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 41
TC 2
Z9 2
U1 0
U2 1
PD AUG
PY 2021
VL 40
IS 8
BP 1573
EP 1585
DI 10.1109/TCAD.2020.3022330
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, YJ
   Liu, IJ
   Yuan, YF
   Chen, DM
   Schwing, A
   Huang, J
AF Li, Youjie
   Liu, Iou-Jen
   Yuan, Yifan
   Chen, Deming
   Schwing, Alexander
   Huang, Jian
GP ACM
TI Accelerating Distributed Reinforcement Learning with In-Switch Computing
SO PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA '19)
DT Proceedings Paper
CT 46th International Symposium on Computer Architecture (ISCA) / Workshop
   on Computer Architecture Education (WCAE)
CY JUN 22-26, 2019
CL Phoenix, AZ
DE distributed machine learning; reinforcement learning; in-switch
   accelerator; in-network computing
AB Reinforcement learning (RL) has attracted much attention recently, as new and emerging AI-based applications are demanding the capabilities to intelligently react to environment changes. Unlike distributed deep neural network (DNN) training, the distributed RL training has its unique workload characteristics - it generates orders of magnitude more iterations with much smaller sized but more frequent gradient aggregations. More specifically, our study with typicalRLalgorithms showsthat their distributed training is latency critical and that the network communication for gradient aggregation occupies up to 83.2% of the execution time of each training iteration.
   In this paper, we present iSwitch, an in-switch acceleration solution that moves the gradient aggregation from server nodes into the network switches, thus we can reduce the number of network hops for gradient aggregation. This not only reduces the end-to-end network latency for synchronous training, but also improves the convergence with faster weight updates for asynchronous training. Upon the in-switch accelerator, we further reduce the synchronization overhead by conducting on-the-fly gradient aggregation at the granularity of network packets rather than gradient vectors. Moreover, we rethink the distributed RL training algorithms and also propose a hierarchical aggregation mechanism to further increase the parallelism and scalability of the distributed RL training at rack scale.
   We implement iSwitch using a real-world programmable switch NetFPGA board. We extend the control and data plane of the programmable switch to support iSwitch without affecting its regular network functions. Compared with state-of-the-art distributed training approaches, iSwitch offers a system-level speedup of up to 3.66x for synchronous distributed training and 3.71x for asynchronous distributed training, while achieving better scalability.
C1 [Li, Youjie; Liu, Iou-Jen; Yuan, Yifan; Chen, Deming; Schwing, Alexander; Huang, Jian] UIUC, Champaign, IL 61820 USA.
RP Li, YJ (corresponding author), UIUC, Champaign, IL 61820 USA.
EM li238@illinois.edu; iliu3@illinois.edu; yifany3@illinois.edu;
   dchen@illinois.edu; aschwing@illinois.edu; jianh@illinois.edu
CR Andreyev A, 2014, INTRO DATA CTR FABRI
   [Anonymous], P 30 INT C NEUR INF
   Arimilli L. Baba, 2010, P 18 IEEE S HIGH PER
   Bosshart P, 2014, ACM SIGCOMM COMP COM, V44, P87, DOI 10.1145/2656877.2656890
   Chen D., 2011, P 2011 INT C HIGH PE, P1, DOI 10.1145/2063384.2063419
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Gauci Jason, 2018, ARXIV181100260
   Goyal P., 2017, ARXIV170602677
   Han J, 2017, ELECTRON J STRUCT EN, V17, P27, DOI 10.56748/ejse.17216
   He K., 2016, P IEEE C COMPUTER VI
   Hesse C., OPENAI BASELINES
   Ho Qirong, 2013, P 26 INT C NEUR INF
   Intel Corporation, 2017, XEON CPU E5
   Intel Corporation, 2017, INT X540
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kostrikov Ilya, 2018, DDPG NAF
   Kostrikov Ilya, 2018, PYTORCH A2C PPO ACKT
   Langford J., 2009, P 22 INT C NEUR INF
   Leiserson Charles E., 1996, J PARALLEL DISTRIB C, V33
   Li Mu, 2014, P 27 INT C NEUR INF
   Li Y, 2018, TALANTA, V180, P32, DOI 10.1016/j.talanta.2017.11.061
   Li YK, 2018, ARCH FOUNDRY ENG, V18, P51, DOI 10.24425/122502
   Lian Xiangru, 2017, ARXIV171006952V3
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Mahajan Divya, 2016, P 2016 IEEE INT S HI
   Maltz, 2010, P 10 ACM SIGCOMM C I, P267, DOI DOI 10.1145/1879141.1879175
   Mnih V., 2013, ARXIV, DOI DOI 10.1038/NATURE14236
   Mnih V, 2016, PR MACH LEARN RES, V48
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moritz P., 2018, P 13 USENIX S OP SYS
   Nair A., 2015, ARXIV150704296
   NetFPGA SUME Team, 2019, NETFPGA SUME WIK
   NETGEAR Corporation, 2017, PROSAFE XS712T SWITC
   Network Working Group, 2001, REQ COMM 3168, V3168
   Nishihara R, 2017, PROCEEDINGS OF THE 16TH WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS 2017), P106, DOI 10.1145/3102980.3102998
   NVIDIA Corporation, 2018, NVIDIA CUDA C PROGR
   NVIDIA Corporation, 2018, NVIDIA CUDNN
   NVIDIA Corporation, 2019, NVID TIT RTX
   OpenAI, 2017, OPENAI BASELINES
   OpenMPI Community, 2017, OPENMPI HIGH PERF ME
   Park Jongse, 2017, P 50 IEEE ACM INT S
   Recht Benjamin, 2011, P 24 INT C NEUR INF
   Roy A, 2015, ACM SIGCOMM COMP COM, V45, P123, DOI 10.1145/2829988.2787472
   Schulman J., 2017, ARXIV, DOI DOI 10.1016/J.JDEVECO.2016.04.001
   Shahbaz M, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P525, DOI 10.1145/2934872.2934886
   Singh A, 2015, ACM SIGCOMM COMP COM, V45, P183, DOI 10.1145/2829988.2787508
   Thakur R, 2005, INT J HIGH PERFORM C, V19, P49, DOI 10.1177/1094342005051521
   Todorov Emanuel, 2015, IEEE RSJ INT C INT R
   Varshavskaya Paulina, 2008, P 9 INT S DISTR AUT
   Wang Qian, 2016, P IEEE INT S CIRC SY
   Wang Qian, 2017, NEUROCOMPUTING, V221
   Yerzat Dulat, 2018, DQN ADVENTURE
   Yu Mingchao, 2018, P 32 C NEUR INF PROC
   Yu YC, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0205182
   Zhang X., 2018, 2018 IEEEACM INT C C, P56
NR 55
TC 49
Z9 49
U1 0
U2 7
PY 2019
BP 279
EP 291
DI 10.1145/3307650.3322259
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Tang, TQ
   Xia, LX
   Li, BX
   Wang, Y
   Yang, HZ
AF Tang, Tianqi
   Xia, Lixue
   Li, Boxun
   Wang, Yu
   Yang, Huazhong
GP IEEE
TI Binary Convolutional Neural Network on RRAM
SO 2017 22ND ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 22nd Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 16-19, 2017
CL Tokyo, JAPAN
AB Recent progress in the machine learning field makes low bit-level Convolutional Neural Networks (CNNs), even CNNs with binary weights and binary neurons, achieve satisfying recognition accuracy on ImageNet dataset. Binary CNNs (BCNNs) make it possible for introducing low bit-level RRAM devices and low bit-level ADC/DAC interfaces in RRAM-based Computing System (RCS) design, which leads to faster read-and-write operations and better energy efficiency than before. However, some design challenges still exist: (1) how to make matrix splitting when one crossbar is not large enough to hold all parameters of one layer; (2) how to design the pipeline to accelerate the whole CNN forward process.
   In this paper, an RRAM crossbar-based accelerator is proposed for BCNN forward process. Moreover, the special design for BCNN is well discussed, especially the matrix splitting problem and the pipeline implementation. In our experiment, BCNNs on RRAM show much smaller accuracy loss than multi-bit CNNs for LeNet on MNIST when considering device variation. For AlexNet on ImageNet, the RRAM-based BCNN accelerator saves 58.2% energy consumption and 56.8% area compared with multi-bit CNN structure.
C1 [Tang, Tianqi; Xia, Lixue; Li, Boxun; Wang, Yu; Yang, Huazhong] Tsinghua Univ, Dept EE, TNList, Beijing, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, Dept EE, TNList, Beijing, Peoples R China.
EM yu-wang@mail.tsinghua.edu.cn
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], 2016, P ISCA
   [Anonymous], 2014, CONF PROC INT SYMP C
   [Anonymous], ISCA
   [Anonymous], 2015, INT J ANTENN PROPAG
   Chauhan S. S., 2011, INT J VLSI DESIGN CO, V2
   Chen S. Y.-S., 2011, 2011 S VLSI CIRC
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YY, 2012, 2012 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Degraeve R, 2015, MICROELECTRON ENG, V147, P171, DOI 10.1016/j.mee.2015.04.025
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Fan JL, 2010, IEEE T NEURAL NETWOR, V21, P1610, DOI 10.1109/TNN.2010.2066286
   Gupta S., SIMULATION ANAL SENS
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Karpathy A, 2015, PROC CVPR IEEE, P3128, DOI 10.1109/CVPR.2015.7298932
   Proesel J., 2010, P IEEE CUST INT CIRC, P1
   Qiu J., 2016, I C FIELD PROG LOGIC
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Seung Ryul Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P71, DOI 10.1109/VLSIT.2012.6242466
   Sheu S. S., 2011, ISSCC
   Siddharth, 2014, J ENG RES APPL, V4, P64
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Xia L., 2016, DAC
NR 25
TC 120
Z9 125
U1 0
U2 20
PY 2017
BP 782
EP 787
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Grech, C
   Buzio, M
   Pentella, M
   Sammut, N
AF Grech, Christian
   Buzio, Marco
   Pentella, Mariano
   Sammut, Nicholas
TI Dynamic Ferromagnetic Hysteresis Modelling Using a Preisach-Recurrent
   Neural Network Model
SO MATERIALS
DT Article
DE ARMCO pure iron; dynamic hysteresis loop; machine learning; magnetic
   properties; particle accelerators; Preisach; recurrent neural networks
ID MAGNETIC HYSTERESIS; IDENTIFICATION; COMPENSATION
AB In this work, a Preisach-recurrent neural network model is proposed to predict the dynamic hysteresis in ARMCO pure iron, an important soft magnetic material in particle accelerator magnets. A recurrent neural network coupled with Preisach play operators is proposed, along with a novel validation method for the identification of the model's parameters. The proposed model is found to predict the magnetic flux density of ARMCO pure iron with a Normalised Root Mean Square Error (NRMSE) better than 0.7%, when trained with just six different hysteresis loops. The model is evaluated using ramp-rates not used in the training procedure, which shows the ability of the model to predict data which has not been measured. The results demonstrate that the Preisach model based on a recurrent neural network can accurately describe ferromagnetic dynamic hysteresis when trained with a limited amount of data, showing the model's potential in the field of materials science.
C1 [Grech, Christian; Sammut, Nicholas] Univ Malta, Fac Informat & Commun Technol, MSD-2080 Msida, Malta.
   [Grech, Christian; Buzio, Marco; Pentella, Mariano; Sammut, Nicholas] CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.
   [Pentella, Mariano] Politecn Torino, Dept Appl Sci & Technol, I-10129 Turin, Italy.
RP Grech, C (corresponding author), Univ Malta, Fac Informat & Commun Technol, MSD-2080 Msida, Malta.; Grech, C (corresponding author), CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.
EM christian.grech.12@um.edu.mt; Marco.Buzio@cern.ch;
   mariano.pentella@cern.ch; nicholas.sammut@um.edu.mt
CR Adly AA, 1998, IEEE T MAGN, V34, P629, DOI 10.1109/20.668057
   Akbarzadeh V, 2008, IEEE INT C EMERG, P1267, DOI 10.1109/ETFA.2008.4638563
   Anglada J., 2020, P 2020 IEEE INSTR ME
   Arpaia P., 2010, 2010 IEEE International Instrumentation & Measurement Technology Conference - I2MTC 2010, P58, DOI 10.1109/IMTC.2010.5488003
   Arpaia P, 2020, IEEE T INSTRUM MEAS, V69, P4200, DOI 10.1109/TIM.2019.2945552
   Ben Mrad R, 2001, IEEE ASME INT C ADV, P510, DOI 10.1109/AIM.2001.936515
   BIORCI G, 1958, NUOVO CIMENTO, V7, P829, DOI 10.1007/BF02745588
   BROKATE M, 1989, IEEE T MAGN, V25, P2922, DOI 10.1109/20.34325
   Data M.I.T.C., 2016, 2 ANAL ELECT HLTH RE, P263, DOI DOI 10.1007/978-3-319-43742-2_17
   Firouzi M., 2010, P 2010 18 IR C EL EN, DOI [10.1109/iraniancee.2010.5506985, DOI 10.1109/IRANIANCEE.2010.5506985]
   Füzi J, 1999, COMPEL, V18, P445, DOI 10.1108/03321649910275080
   Grössinger R, 2012, IEEE T MAGN, V48, P3076, DOI 10.1109/TMAG.2012.2202097
   HAGAN MT, 1994, IEEE T NEURAL NETWOR, V5, P989, DOI 10.1109/72.329697
   Hergli K, 2019, J KING SAUD UNIV SCI, V31, P746, DOI 10.1016/j.jksus.2017.11.005
   Hitec, 2016, HITEC MACC 2 PLUS
   Iyer RV, 2009, IEEE CONTR SYST MAG, V29, P83, DOI 10.1109/MCS.2008.930924
   Kozek M., 2005, INT J ONLINE BIOMED
   Krejci P., 1989, Aplikace Matematiky, V34, P364
   Kuczmann M, 2014, COMPEL, V33, P2043, DOI 10.1108/COMPEL-11-2013-0368
   Liu Z. P., 1999, IJCNN'99. International Joint Conference on Neural Networks. Proceedings (Cat. No.99CH36339), P1788, DOI 10.1109/IJCNN.1999.832649
   Makaveev D, 2003, J MAGN MAGN MATER, V254, P256, DOI 10.1016/S0304-8853(02)00785-0
   MARQUARDT DW, 1963, J SOC IND APPL MATH, V11, P431, DOI 10.1137/0111030
   MATLAB, 2019, DEEP LEARNING TOOLBO
   Mayergoyz I., 2003, MATH MODELS HYSTERES, P1, DOI DOI 10.1016/B978-012480873-7/50002-5
   MAYERGOYZ ID, 1988, IEEE T MAGN, V24, P2925, DOI 10.1109/20.92290
   Namjoshi KV, 1998, IEEE T MAGN, V34, P636, DOI 10.1109/20.668058
   Natale C, 2001, PHYSICA B, V306, P161, DOI 10.1016/S0921-4526(01)00997-8
   National Instruments, 2008, NI 446X SPEC
   Parrella A, 2019, IEEE T MAGN, V55, DOI 10.1109/TMAG.2018.2872163
   Prechelt L, 1998, LECT NOTES COMPUT SC, V1524, P55
   ROUVE LL, 1995, IEEE T MAGN, V31, P3557, DOI 10.1109/20.489568
   Ruderman M, 2012, IEEE T MAGN, V48, P1281, DOI 10.1109/TMAG.2011.2172931
   Saghafifar M, 2001, INT J APPL ELECTROM, V13, P209
   Saliah HH, 1997, PHYSICA B, V233, P318, DOI 10.1016/S0921-4526(97)00316-5
   Saliah HH, 1997, IEEE T MAGN, V33, P4146, DOI 10.1109/20.619691
   Schäfer AM, 2007, INT J NEURAL SYST, V17, P253, DOI 10.1142/S0129065707001111
   Serpico C, 1998, IEEE T MAGN, V34, P623, DOI 10.1109/20.668055
   Sgobba S., 2009, P CERN ACC SCH CAS 2, DOI [10.5170/CERN-2010-004.39, DOI 10.5170/CERN-2010-004.39]
   Song DW, 1999, MECHATRONICS, V9, P391, DOI 10.1016/S0957-4158(99)00005-7
   Stakvik J., 2014, THESIS NORWEGIAN U S
   Sutor A, 2010, APPL PHYS A-MATER, V100, P425, DOI 10.1007/s00339-010-5884-9
   Tan XB, 2004, AUTOMATICA, V40, P1469, DOI 10.1016/j.automatica.2004.04.006
   Wang Q., 2005, ACTA AUTOM SIN, DOI [10.16383/j.aas.2005.01.010, DOI 10.16383/J.AAS.2005.01.010]
   Xu R, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2700479
   Yao Y, 2007, CONSTR APPROX, V26, P289, DOI 10.1007/s00365-006-0663-2
   Zhou ML, 2015, IEEE T MAGN, V51, DOI 10.1109/TMAG.2015.2434933
NR 46
TC 15
Z9 15
U1 3
U2 20
PD JUN
PY 2020
VL 13
IS 11
AR 2561
DI 10.3390/ma13112561
WC Chemistry, Physical; Materials Science, Multidisciplinary; Metallurgy &
   Metallurgical Engineering; Physics, Applied; Physics, Condensed Matter
DA 2023-11-11
ER

PT C
AU Oroutzoglou, I
   Masouros, D
   Koliogeorgi, K
   Xydis, S
   Soudris, D
AF Oroutzoglou, Ioannis
   Masouros, Dimosthenis
   Koliogeorgi, Konstantina
   Xydis, Sotirios
   Soudris, Dimitrios
BE Stuijk, S
TI Exploration of GPU sharing policies under GEMM workloads
SO PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS
   FOR EMBEDDED SYSTEMS (SCOPES 2020)
DT Proceedings Paper
CT 23rd International Workshop on Software and Compilers for Embedded
   Systems (SCOPES)
CY MAY 25-26, 2020
CL ELECTR NETWORK
DE GPGPU sharing; native CUDA queues; CUDA MPS; Vinetalk; interference
   analysis; cloud computing
AB Lately, cloud computing has seen explosive growth, due to the flexibility and scalability it offers. The ever-increasing computational demands, especially from the machine learning domain, have forced cloud operators to enhance their infrastructure with acceleration devices, such as General-Purpose (GP)GPUs or FPGAs. Even though multi-tenancy has been widely examined for conventional CPUs, this is not the case for accelerators. Current solutions support "one accelerator per user" schemes, which can lead to both under-utilization and starvation of available resources.
   In this work, we analyze the potentials of GPU sharing inside data-center environments. We investigate how several architectural features affect the performance of GPUs under different multitenant stressing scenarios. We compare CUDA MPS with the native, default CUDA scheduler and also with Vinetalk, a research framework providing GPU sharing capabilities. Experimental results show that NVIDIA's MPS achieves the best performance in multi-application scenarios, specifically up to x4.5 and x11.2 compared to native CUDA scheduler and Vinetalk respectively.
C1 [Oroutzoglou, Ioannis; Masouros, Dimosthenis; Koliogeorgi, Konstantina; Soudris, Dimitrios] Natl Tech Univ Athens, Athens, Greece.
   [Xydis, Sotirios] Harokopio Univ Athens, Athens, Greece.
RP Oroutzoglou, I (corresponding author), Natl Tech Univ Athens, Athens, Greece.
EM ioroutzoglou@microlab.ntua.gr; demo.masouros@microlab.ntua.gr;
   konstantina@microlab.ntua.gr; sxydis@hua.gr; dsoudris@microlab.ntua.gr
CR [Anonymous], 2015, OPENCL OP STAND PAR
   [Anonymous], 2008, COMP UN
   [Anonymous], 2016, FOR METH 2016 2021, V1
   [Anonymous], 2012, GPGPU SIM 3 X MANUAL
   Kim J, 2019, IEEE COMPUT ARCHIT L, V18, P1, DOI 10.1109/LCA.2018.2889042
   Margiolas C, 2016, INT SYM CODE GENER, P82, DOI 10.1145/2854038.2854040
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Park JJK, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P527, DOI 10.1145/3037697.3037707
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 66
EP 69
DI 10.1145/3378678.3391887
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Xu, XY
   Tan, MX
   Corcoran, B
   Wu, JY
   Boes, A
   Nguyen, TG
   Chu, ST
   Little, BE
   Hicks, DG
   Morandotti, R
   Mitchell, A
   Moss, DJ
AF Xu, Xingyuan
   Tan, Mengxi
   Corcoran, Bill
   Wu, Jiayang
   Boes, Andreas
   Nguyen, Thach G.
   Chu, Sai T.
   Little, Brent E.
   Hicks, Damien G.
   Morandotti, Roberto
   Mitchell, Arnan
   Moss, David J.
TI 11 TOPS photonic convolutional accelerator for optical neural networks
SO NATURE
DT Article
ID CLASSIFICATION
AB Convolutional neural networks, inspired by biological visual cortex systems, are a powerful category of artificial neural networks that can extract the hierarchical features of raw data to provide greatly reduced parametric complexity and to enhance the accuracy of prediction. They are of great interest for machine learning tasks such as computer vision, speech recognition, playing board games and medical diagnosis(1-7). Optical neural networks offer the promise of dramatically accelerating computing speed using the broad optical bandwidths available. Here we demonstrate a universal optical vector convolutional accelerator operating at more than ten TOPS (trillions (10(12)) of operations per second, or tera-ops per second), generating convolutions of images with 250,000 pixels-sufficiently large for facial image recognition. We use the same hardware to sequentially form an optical convolutional neural network with ten output neurons, achieving successful recognition of handwritten digit images at 88 per cent accuracy. Our results are based on simultaneously interleaving temporal, wavelength and spatial dimensions enabled by an integrated microcomb source. This approach is scalable and trainable to much more complex networks for demanding applications such as autonomous vehicles and real-time video recognition.
C1 [Xu, Xingyuan; Tan, Mengxi; Wu, Jiayang; Hicks, Damien G.; Moss, David J.] Swinburne Univ Technol, Opt Sci Ctr, Hawthorn, Vic, Australia.
   [Corcoran, Bill] Monash Univ, Dept Elect & Comp Syst Engn, Clayton, Vic, Australia.
   [Boes, Andreas; Nguyen, Thach G.; Mitchell, Arnan] RMIT Univ, Sch Engn, Melbourne, Vic, Australia.
   [Chu, Sai T.] City Univ Hong Kong, Dept Phys, Tat Chee Ave, Hong Kong, Peoples R China.
   [Little, Brent E.] Chinese Acad Sci, Xian Inst Opt & Precis Mech, Xian, Peoples R China.
   [Hicks, Damien G.] Walter & Eliza Hall Inst Med Res, Bioinformat Div, Parkville, Vic, Australia.
   [Morandotti, Roberto] INRS Energie Mat & Telecommun, Varennes, PQ, Canada.
   [Morandotti, Roberto] Univ Elect Sci & Technol China, Inst Fundamental & Frontier Sci, Chengdu, Peoples R China.
   [Xu, Xingyuan] Monash Univ, Dept Elect & Comp Syst Engn, Electrophoton Lab, Clayton, Vic, Australia.
RP Moss, DJ (corresponding author), Swinburne Univ Technol, Opt Sci Ctr, Hawthorn, Vic, Australia.
EM dmoss@swin.edu.au
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Appeltant L, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1476
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Capper D, 2018, NATURE, V555, P469, DOI 10.1038/nature26000
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Cole DC, 2017, NAT PHOTONICS, V11, P671, DOI 10.1038/s41566-017-0009-z
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Kippenberg TJ, 2018, SCIENCE, V361, DOI 10.1126/science.aan8083
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kues M, 2019, NAT PHOTONICS, V13, P170, DOI 10.1038/s41566-019-0363-0
   Larger L, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.011015
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   LeCun Y., MNIST DATABASE HANDW
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Marin-Palomo P, 2017, NATURE, V546, P274, DOI 10.1038/nature22387
   Metcalf AJ, 2016, OPT EXPRESS, V24, P23925, DOI 10.1364/OE.24.023925
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Moss DJ, 2013, NAT PHOTONICS, V7, P597, DOI [10.1038/nphoton.2013.183, 10.1038/NPHOTON.2013.183]
   NVIDIA Corporation, 2018, COMP CONV METH GPUS
   Pasquazi A, 2018, PHYS REP, V729, P1, DOI 10.1016/j.physrep.2017.08.004
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Roeloffzen CGH, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2793945
   Sahin E, 2017, APPL PHYS LETT, V110, DOI 10.1063/1.4982157
   Savchenkov AA, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.093902
   Schalkoff R. J., 2007, PATTERN RECOGN, DOI DOI 10.1002/9780470050118.ECSE302
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Spencer DT, 2018, NATURE, V557, P81, DOI 10.1038/s41586-018-0065-7
   Stern B, 2018, NATURE, V562, P401, DOI 10.1038/s41586-018-0598-9
   Tait AN, 2015, OPT EXPRESS, V23, P12758, DOI 10.1364/OE.23.012758
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Wang C, 2018, NATURE, V562, P101, DOI 10.1038/s41586-018-0551-y
   Wu JY, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2805814
   Xu XY, 2020, LASER PHOTONICS REV, V14, DOI 10.1002/lpor.202000070
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
NR 40
TC 326
Z9 347
U1 49
U2 438
PD JAN 7
PY 2021
VL 589
IS 7840
BP 44
EP +
DI 10.1038/s41586-020-03063-0
WC Multidisciplinary Sciences
HC Y
HP N
DA 2023-11-11
ER

PT J
AU Zhu, J
   Wang, LZ
   Liu, HL
   Tian, SJ
   Deng, QY
   Li, JQ
AF Zhu, Jiang
   Wang, Lizan
   Liu, Haolin
   Tian, Shujuan
   Deng, Qingyong
   Li, Jianqi
TI An Efficient Task Assignment Framework to Accelerate DPU-Based
   Convolutional Neural Network Inference on FPGAs
SO IEEE ACCESS
DT Article
DE Task analysis; Acceleration; Schedules; Field programmable gate arrays;
   Convolutional neural networks; Machine learning; Hardware; Field
   programmable gate array (FPGA); deep learning processor unit (DPU);
   convolutional neural network~(CNN) accelerator; schedule efficiency
AB Field Programmable Gate Array (FPGA) has become an efficient accelerator for convolutional neural network (CNN) inference due to its high performance and flexibility. To further improve the performance of CNN inference on FPGAs, an Intellectual Property core (IP core) called Deep Learning Processor Unit (DPU) is released by Xilinx. Unlike previous FPGA-based hardware designs focusing on specific functions or CNNs, the DPU IP supports ample basic functions of deep learning, and the developers can take advantage of DPUs to accelerate CNN inference conveniently. In DPU-based CNN acceleration platform, an encapsulated scheduler plays a crucial role in task scheduling between heterogeneous ARM and multiple DPUs. However, the current scheduler is unsatisfactory because its low schedule efficiency. This paper thus presents a high performance task assignment framework built upon Xilinx hybrid CPU-FPGA MPSoC devices. We first evaluate the main causes of low schedule efficiency problem. Then, we explore the scheduler rules and improve shedule efficiency through purposeful observations and analysis. Finally, we integrate our optimizations, and propose an efficient task assignment framework to maximize performance on DPU-based CNN acceleration platform. Experimental results on Xilinx Zynq UltraScale & x002B; MPSoC zcu104 show that our efficient task assignment framework significantly boosts schedule efficiency for small-scale CNNs (from 36 & x0025; to 70 & x0025;), medium-scale CNNs (from 65 & x0025; to 95 & x0025;), and large-scale CNNs (from 77 & x0025; to 99 & x0025;) compared with original schedule strategy.
C1 [Zhu, Jiang; Wang, Lizan; Li, Jianqi] Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.
   [Zhu, Jiang; Wang, Lizan; Liu, Haolin; Tian, Shujuan; Deng, Qingyong] Xiangtan Univ, Key Lab Hunan Prov Internet Things & Informat Sec, Xiangtan 411105, Peoples R China.
   [Deng, Qingyong] Sci & Technol Parallel & Distributed Proc Lab, Xiangtan, Peoples R China.
   [Li, Jianqi] Hunan Univ Arts & Sci, Hunan Prov Cooperat Innovat Ctr Construct & Dev D, Changde 415000, Peoples R China.
RP Li, JQ (corresponding author), Xiangtan Univ, Sch Automat & Elect Informat, Xiangtan 411105, Peoples R China.; Li, JQ (corresponding author), Hunan Univ Arts & Sci, Hunan Prov Cooperat Innovat Ctr Construct & Dev D, Changde 415000, Peoples R China.
EM jianqi_li@126.com
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2019, DNNDK US GUID UG1327
   [Anonymous], 2019, DPU CONV NEUR NETW V
   Chang XP, 2019, PROC IEEE INT SYMP, P2137, DOI 10.1109/ISIE.2019.8781162
   Hao C, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL CONFERENCE ON E-BUSINESS, INFORMATION MANAGEMENT AND COMPUTER SCIENCE, P1, DOI 10.1145/3210506.3210507
   Delaye E, 2017, ICCAD-IEEE ACM INT, P908, DOI 10.1109/ICCAD.2017.8203877
   Ding R., 2019, P 2019 IEEE INT C EL, P1
   Fang SX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P392, DOI 10.1109/FPT.2018.00081
   Farrukh FUD, 2018, PROCEEDINGS OF 2018 IEEE INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS, TECHNOLOGIES AND APPLICATIONS (ICTA 2018), P88, DOI 10.1109/CICTA.2018.8706067
   Feng G, 2016, 2016 13TH IEEE INTERNATIONAL CONFERENCE ON SOLID-STATE AND INTEGRATED CIRCUIT TECHNOLOGY (ICSICT), P624, DOI 10.1109/ICSICT.2016.7998996
   Gao MC, 2018, COMP M BIO BIO E-IV, V6, P1, DOI 10.1080/21681163.2015.1124249
   Guo JX, 2017, ANN IEEE SYM FIELD P, P31, DOI 10.1109/FCCM.2017.13
   Hailesellasie M., 2018, P IEEE INT S CIRC SY, P1
   Hegde G, 2016, ANN IEEE SYM FIELD P, P25, DOI 10.1109/FCCM.2016.14
   Huang C, 2017, INT CONF ASIC, P1037, DOI 10.1109/ASICON.2017.8252656
   Jinguji A, 2019, I C FIELD PROG LOGIC, P424, DOI 10.1109/FPL.2019.00078
   Li X, 2017, INT CONF ASIC, P944, DOI 10.1109/ASICON.2017.8252633
   Li XL, 2017, PROCEEDINGS OF 2017 IEEE 2ND INFORMATION TECHNOLOGY, NETWORKING, ELECTRONIC AND AUTOMATION CONTROL CONFERENCE (ITNEC), P837, DOI 10.1109/ITNEC.2017.8284852
   Li ZL, 2019, PROCEEDINGS OF 2019 IEEE 8TH JOINT INTERNATIONAL INFORMATION TECHNOLOGY AND ARTIFICIAL INTELLIGENCE CONFERENCE (ITAIC 2019), P1521, DOI [10.1109/ITAIC.2019.8785800, 10.1109/itaic.2019.8785800]
   Liang Y, 2020, IEEE T COMPUT AID D, V39, P857, DOI 10.1109/TCAD.2019.2897701
   Lin ZY, 2018, IEEE INT VEH SYM, P1197, DOI 10.1109/IVS.2018.8500685
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Shan Y, 2018, I C FIELD PROG LOGIC, P465, DOI 10.1109/FPL.2018.00092
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shimoda M, 2019, I C FIELD PROG LOGIC, P413, DOI 10.1109/FPL.2019.00072
   Stornaiuolo L, 2018, IEEE COMP SOC ANN, P587, DOI 10.1109/ISVLSI.2018.00112
   Huynh TV, 2017, 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS), P254, DOI 10.1109/NAFOSTED.2017.8108073
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wu D, 2019, I C FIELD PROG LOGIC, P136, DOI 10.1109/FPL.2019.00030
   Xiao QC, 2020, IEEE DES TEST, V37, P46, DOI 10.1109/MDAT.2019.2908549
   Yu BS, 2018, IEEE WRK SIG PRO SYS, P88, DOI 10.1109/SiPS.2018.8598428
   Yu Q, 2015, IEEE ACM INT SYMP, P1159, DOI 10.1109/CCGrid.2015.114
   Zhang J, 2019, IEEE GLOB COMM CONF, DOI [10.1109/globecom38437.2019.9014069, 10.1109/pcs48520.2019.8954503, 10.1080/02726351.2019.1571542, 10.1109/edssc.2019.8753994]
   Zhao YQ, 2019, 2019 ELEVENTH INTERNATIONAL CONFERENCE ON ADVANCED COMPUTATIONAL INTELLIGENCE (ICACI 2019), P13, DOI [10.1109/ICACI.2019.8778613, 10.1109/icaci.2019.8778613]
NR 34
TC 21
Z9 21
U1 3
U2 30
PY 2020
VL 8
BP 83224
EP 83237
DI 10.1109/ACCESS.2020.2988311
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Liu, ZG
   Whatmough, PN
   Zhu, YH
   Mattina, M
AF Liu, Zhi-Gang
   Whatmough, Paul N.
   Zhu, Yuhao
   Mattina, Matthew
GP IEEE Comp Soc
TI S2TA: Exploiting Structured Sparsity for Energy-Efficient Mobile CNN
   Acceleration
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Machine Learning; Acceleration; Matrix Multiplication; Sparsity;
   Systolic; Architecture
AB Exploiting sparsity is a key technique in accelerating quantized convolutional neural network (CNN) inference on mobile devices. Prior sparse CNN accelerators largely exploit unstructured sparsity and achieve significant speedups. Due to the unbounded, largely unpredictable sparsity patterns, however, exploiting unstructured sparsity requires complicated hardware design with significant energy and area overhead, which is particularly detrimental to mobile/IoT inference scenarios where energy and area efficiency are crucial.
   We propose to exploit structured sparsity, more specifically, Density Bound Block (DBB) sparsity for both weights and activations. DBB block tensors bound the maximum number of non-zeros per block. DBB thus exposes statically predictable sparsity patterns that enable lean sparsity-exploiting hardware and efficient memory access. We propose new hardware primitives to implement DBB sparsity for (static) weights and (dynamic) activations, respectively, with very low overheads.
   Building on top of the primitives, we describe S2TA, a systolic array-based CNN accelerator that exploits joint weight and activation DBB sparsity and new dimensions of data reuse unavailable on the traditional systolic array. S2TA in 16nm achieves more than 2x speedup and energy reduction compared to a strong baseline of a systolic array with zero-value clock gating, over five popular CNN benchmarks. Compared to two recent non-systolic sparse accelerators, Eyeriss v2 (65nm) and SparTen (45nm), S2TA in 65nm uses about 2.2x and 3.1x less energy per inference, respectively.
C1 [Liu, Zhi-Gang; Whatmough, Paul N.; Mattina, Matthew] Arm ML Res, Boston, MA 02115 USA.
   [Zhu, Yuhao] Univ Rochester, Rochester, NY USA.
RP Liu, ZG (corresponding author), Arm ML Res, Boston, MA 02115 USA.
EM zhi-gang.liu@arm.com; paul.whatmough@arm.com; yzhu@rochester.edu;
   matthew.mattina@arm.com
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2018, P 1 C SYST MACH LEAR
   [Anonymous], ARMV8 M ARCHITECTURE
   [Anonymous], ARM CORTEX M33
   Banbury C., 2021, P MACHINE LEARNING S, V3, P517
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Dally W. J., MLSYS KEYNOTE TALK, P2021
   Fedorov I., 2020, TINYLSTMS EFFICIENT
   Fedorov I., 2019, ADV NEUR IN, V32, P4978, DOI DOI 10.5555/3454287.3454735
   Feng Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P643, DOI 10.1145/3352460.3358253
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Gupta U, 2019, INT CONFER PARA, P1, DOI 10.1109/PACT.2019.00009
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hansen P., 2020, INT C PATTERN RECOGN
   Jouppi N. P., 2017, 44 ANN INT S COMP
   Kang HJ, 2020, IEEE T CIRC SYST VID, V30, P2093, DOI 10.1109/TCSVT.2019.2911674
   Kim S, 2021, ARXIV
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee SH, 2022, INT J PR ENG MAN-GT, V9, P409, DOI [10.1007/s40684-021-00342-7, 10.1109/ICME51207.2021.9428381]
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Liu ZG, 2020, IEEE COMPUT ARCHIT L, V19, P34, DOI 10.1109/LCA.2020.2979965
   Mahmoud M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P781, DOI 10.1109/MICRO50266.2020.00069
   Nvidia, A100 GPU DAT
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pool J., ACCELERATING SPARSIT
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samajdar Ananda, 2018, ARXIV
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Shomron Gil, 2019, IEEE Computer Architecture Letters, V18, P99, DOI 10.1109/LCA.2019.2924007
   Shomron G, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P256, DOI 10.1109/MICRO50266.2020.00032
   Thakker U., 2021, PROC MACH LEARN SYST, V3, P533
   Wang Alex., 2018, P 2018 EMNLP WORKSH, DOI [DOI 10.18653/V1/W18-5446, 10.18653/v1/W18-5446]
   Warden P, WHY ARE 8 BITS ENOUG
   Whatmough Paul N., 2019, P 2 SYSML C PAL ALT
   Whatrnough PN, 2019, SYMP VLSI CIRCUITS, pC34, DOI 10.23919/VLSIC.2019.8778002
   Zhang ZK, 2020, INT S HIGH PERF COMP, P261, DOI 10.1109/HPCA47549.2020.00030
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
   Zhu Michael, 2017, ARXIV171001878
   Zhu YH, 2018, CONF PROC INT SYMP C, P547, DOI 10.1109/ISCA.2018.00052
NR 47
TC 10
Z9 10
U1 1
U2 4
PY 2022
BP 573
EP 586
DI 10.1109/HPCA53966.2022.00049
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Achararit, P
   Hanif, MA
   Putra, RVW
   Shafique, M
   Hara-Azumi, Y
AF Achararit, Paniti
   Hanif, Muhammad Abdullah
   Putra, Rachmad Vidya Wicaksana
   Shafique, Muhammad
   Hara-Azumi, Yuko
TI APNAS: Accuracy-and-Performance-Aware Neural Architecture Search for
   Neural Hardware Accelerators
SO IEEE ACCESS
DT Article
DE Hardware; Computer architecture; Parallel processing; Graphics
   processing units; Analytical models; Task analysis; Performance
   evaluation; Neural architecture search; neural processing arrays;
   embedded systems; accelerator; performance; accuracy; efficiency;
   machine learning; deep learning; DNN; deep neural networks; CNN;
   convolutional neural network
ID COPROCESSOR; NETWORK; TRENDS
AB Designing resource-efficient deep neural networks (DNNs) is a challenging task due to the enormous diversity of applications as well as their time-consuming design, training, optimization, and evaluation cycles, especially the resource-constrained embedded systems. To address these challenges, we propose a novel DNN design framework called accuracy-and-performance-aware neural architecture search (APNAS), which can generate DNNs efficiently, as it does not require hardware devices or simulators while searching for optimized DNN model configurations that offer both inference accuracy and high execution performance. In addition, to accelerate the process of DNN generation, APNAS is built on a weight sharing and reinforcement learning-based exploration methodology, which is composed of a recurrent neural network controller as its core to generate sample DNN configurations. The reward in reinforcement learning is formulated as a configurable function to consider the sample DNNs' accuracy and cycle count required to run on a target hardware architecture. To further expedite the DNN generation process, we devise analytical models for cycle count estimation instead of running millions of DNN configurations on real hardware. We demonstrate that these analytical models are highly accurate and provide cycle count estimates identical to those of a cycle-accurate hardware simulator. Experiments that involve quantitatively varying hardware constraints demonstrate that APNAS requires only 0.55 graphics processing unit (GPU) days on a single Nvidia GTX 1080Ti GPU to generate DNNs that offer an average of 53% fewer cycles with negligible accuracy degradation (on average 3%) for image classification compared to state-of-the-art techniques.
C1 [Achararit, Paniti; Hara-Azumi, Yuko] Tokyo Inst Technol, Dept Informat & Commun, Tokyo 1528550, Japan.
   [Hanif, Muhammad Abdullah; Putra, Rachmad Vidya Wicaksana] Vienna Univ Technol, Inst Comp Engn, Fac Informat, A-1040 Vienna, Austria.
   [Shafique, Muhammad] New York Univ Abu Dhabi NYU AD, Div Engn, Abu Dhabi 129188, U Arab Emirates.
RP Achararit, P (corresponding author), Tokyo Inst Technol, Dept Informat & Commun, Tokyo 1528550, Japan.
EM paniti@cad.ict.e.titech.ac.jp
CR Abbas Q, 2019, ARTIF INTELL REV, V52, P39, DOI 10.1007/s10462-018-9633-3
   [Anonymous], ARXIV190207638
   [Anonymous], 2017, P MACH LEARN HPC ENV
   [Anonymous], 2016, BRIT MACHINE VISION
   [Anonymous], ARXIV181200332
   [Anonymous], ARXIV171100436
   [Anonymous], 2018, 35 INT C MACH LEARN
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Gal Y., 2016, THESIS
   Girshick R, 2014, PROC CVPR IEEE, P580, DOI 10.1109/CVPR.2014.81
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gordon A, 2018, PROC CVPR IEEE, P1586, DOI 10.1109/CVPR.2018.00171
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hanif M. A., 2018, CORR, P1
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jain A, 2005, PATTERN RECOGN, V38, P2270, DOI 10.1016/j.patcog.2005.01.012
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khalid F, 2019, IEEE INT ON LINE, P182, DOI [10.1109/iolts.2019.8854377, 10.1109/IOLTS.2019.8854377]
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu Hanxiao, 2018, INT C LEARNING REPRE
   Liu XL, 2019, ARTIF INTELL REV, V52, P1089, DOI 10.1007/s10462-018-9641-3
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Marchioni A, 2018, BIOMED CIRC SYST C, P203
   Marchisio A, 2019, IEEE COMP SOC ANN, P555, DOI 10.1109/ISVLSI.2019.00105
   Miotto R, 2018, BRIEF BIOINFORM, V19, P1236, DOI 10.1093/bib/bbx044
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park SK, 2015, IEEE INT MEM WORKSH, P1
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Prabakaran B. S., 2020, ARXIV200410491
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Shafique M, 2018, DES AUT TEST EUROPE, P827, DOI 10.23919/DATE.2018.8342120
   Shi XJ, 2015, ADV NEUR IN, V28
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sriram V., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P273, DOI 10.1109/FPT.2010.5681487
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   von Zitzewitz G., 2017, TECH REP
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Zhang J, 2019, IEEE GLOB COMM CONF, DOI [10.1109/globecom38437.2019.9014069, 10.1109/pcs48520.2019.8954503, 10.1080/02726351.2019.1571542, 10.1109/edssc.2019.8753994]
   Zhang QR, 2019, NEUROCOMPUTING, V323, P37, DOI 10.1016/j.neucom.2018.09.038
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zoph B, ARXIV161101578
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 57
TC 17
Z9 17
U1 0
U2 7
PY 2020
VL 8
BP 165319
EP 165334
DI 10.1109/ACCESS.2020.3022327
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Pan, YJ
   Yu, JC
   Lukefahr, A
   Das, R
   Mahlke, S
AF Pan, Yunjie
   Yu, Jiecao
   Lukefahr, Andrew
   Das, Reetuparna
   Mahlke, Scott
TI BitSET: Bit-Serial Early Termination for Computation Reduction in
   Convolutional Neural Networks
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Convolutional neural networks; CNN; deep neural networks; DNN;
   accelerator; approximate computing; early termination; software-hardware
   co-design
AB Convolutional Neural Networks (CNNs) have demonstrated remarkable performance across a wide range of machine learning tasks. However, the high accuracy usually comes at the cost of substantial computation and energy consumption, making it difficult to be deployed on mobile and embedded devices. In CNNs, the compute-intensive convolutional layers are usually followed by a ReLU activation layer, which clamps negative outputs to zeros, resulting in large activation sparsity. By exploiting such sparsity in CNN models, we propose a software-hardware co-design BitSET, that aggressively saves energy during CNN inference. The bit-serial BitSET accelerator adopts a prediction-based bit-level early termination technique that terminates the ineffectual computation of negative outputs early. To assist the algorithm, we propose a novel weight encoding that allows more accurate predictions with fewer bits. BitSET leverages the bit-level computation reduction both in the predictive early termination algorithm and in the non-predictive, energy-efficient bit-serial architecture. Compared to UNPU, an energy-efficient bit-serial CNN accelerator, BitSET yields an average 1.5x speedup and 1.4x energy efficiency improvement with no accuracy loss due to a 48% reduction in bit-level computations. Relaxing the allowed accuracy loss to 1% increases the gains to an average of 1.6x speedup and 1.4x energy efficiency improvement.
C1 [Pan, Yunjie; Das, Reetuparna; Mahlke, Scott] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Yu, Jiecao] Facebook Inc, Boston, MA USA.
   [Lukefahr, Andrew] Indiana Univ, Indiana, PA USA.
RP Pan, YJ (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM panyj@umich.edu; jiecaoyu@fb.com; lukefahr@iu.edu; reetudas@umich.edu;
   mahlke@umich.edu
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Baccouche Moez, 2011, Human Behavior Unterstanding. Proceedings Second International Workshop, HBU 2011, P29, DOI 10.1007/978-3-642-25446-8_4
   Bolukbasi T, 2017, PR MACH LEARN RES, V70
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Courbariaux M, 2016, Arxiv, DOI [arXiv:1602.02830, DOI 10.48550/ARXIV.1602.02830]
   Dong XY, 2017, PROC CVPR IEEE, P1895, DOI 10.1109/CVPR.2017.205
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gysel P., 2016, ARXIV, DOI [10.48550/ARXIV.1604.03168, DOI 10.48550/ARXIV.1604.03168]
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Judd P, 2016, INT SYMP MICROARCH
   Kirillov A, 2019, PROC CVPR IEEE, P6392, DOI 10.1109/CVPR.2019.00656
   Krishnamoorthi R, 2018, Arxiv, DOI arXiv:1806.08342
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P139, DOI 10.1145/3205289.3205295
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lin Y, 2017, IEEE INT CONF COMMUN, P782
   Liu L, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P738, DOI 10.1109/MICRO50266.2020.00066
   Molchanov P, 2017, Arxiv, DOI arXiv:1611.06440
   Nair V., 2010, ICML, P807
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke A, 2019, ADV NEUR IN, V32
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Ramachandran P, 2017, Arxiv, DOI [arXiv:1710.05941, DOI 10.48550/ARXIV.1710.05941]
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Redmon J., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang Xiaohu, 2021, P MACHINE LEARNING S, V3, P21
   Springenberg JT, 2015, Arxiv, DOI [arXiv:1412.6806, DOI 10.48550/ARXIV.1412.6806]
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Zhou  A., 2017, ARXIV170203044
   Zhou S, 2016, ARXIV
NR 42
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 22
IS 5
SU S
AR 98
DI 10.1145/3609093
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Hoisak, JD
   Kim, GYG
   Atwood, TF
   Pawlicki, T
AF Hoisak, Jeremy D.
   Kim, Gwe-Ya G.
   Atwood, Todd F.
   Pawlicki, Todd
TI Operational Insights From the Longitudinal Analysis of a Linear
   Accelerator Machine Log
SO CUREUS JOURNAL OF MEDICAL SCIENCE
DT Article
DE halcyon; linear accelerator; machine log; quality management; fault
   recovery; incident learning systems
ID RADIATION; TECHNOLOGIES
AB Purpose
   This study aimed to perform a longitudinal analysis of linear accelerator (linac) technical faults reported with a cloud-based Machine Log system in use in a busy academic clinic and derive operational insights related to linac reliability, clinical utilization, and performance.
   Methods
   We queried the Machine Log system for the following parameters: linac type, number of reported technical faults, types of fault, number of faults where the linac was disabled, and estimated clinical downtime. The number of fractions treated and monitor units (MU) delivered were obtained from the record and verify system as metrics of linac utilization and to normalize the number of reported linac faults, facilitating inter-comparison. Two Varian TrueBeam C-arm linacs (Varian Medical Systems, Palo Alto, CA), one Varian 21iX C-arm linac (Varian Medical Systems, Palo Alto, CA), and one newly installed Varian Halcyon ring gantry linac (Varian Medical Systems, Palo Alto, CA) were evaluated. The linacs were studied over a 30-month period from September 2017 to March 2020.
   Results
   Over 30 months, comprising 677 clinical days, 1234 faults were reported from all linacs, including 153 "linac down" events requiring rescheduling or cancellation of treatments. The TrueBeam linacs reported nearly twice as many imaging, multileaf collimator (MLC), and beam generation faults per fraction, and MU as the Halcyon. Halcyon experienced fewer beam generation/steering, accessory, and cooling-related faults than the other linacs but reported more computer and networking issues. Although it employs a relatively new MLC design compared to the C-arm linacs and delivers primarily intensity-modulated treatments, Halcyon reported fewer MLC faults than the other linacs. The 21iX linac had the fewest software-related faults but was subject to the most cooling-related faults, which we attributed to extensive use of this linac for treatment techniques with extended beam-on times.
   Conclusions
   A longitudinal analysis of a cloud-based Machine Log system yielded operational insights into the utilization, performance, and technical reliability of the linacs in use at our institution. Several trends in linac sub-system reliability were identified and could be attributed to either age, design, clinical use, or operational demands. The results of this analysis will be used as a basis for designing linac quality assurance schedules that reflect actual linac usage and observed sub-system reliability. Such a practice may contribute to a clinic workflow subject to fewer disruptions from linac faults, ultimately improving efficiency and patient safety.
C1 [Hoisak, Jeremy D.; Kim, Gwe-Ya G.; Atwood, Todd F.; Pawlicki, Todd] Univ Calif San Diego, Radiat Med & Appl Sci, La Jolla, CA 92093 USA.
RP Hoisak, JD (corresponding author), Univ Calif San Diego, Radiat Med & Appl Sci, La Jolla, CA 92093 USA.
EM jhoisak@health.ucsd.edu
CR Able CM, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0602-1
   [Anonymous], 2020, HALCYON EFFICIENCY S
   Arthasartsri S, 2009, PROCEEDINGS OF 2009 8TH INTERNATIONAL CONFERENCE ON RELIABILITY, MAINTAINABILITY AND SAFETY, VOLS I AND II, P1356, DOI 10.1109/ICRMS.2009.5270030
   Atwood TF, 2018, INT J RADIAT ONCOL, V102, P635, DOI 10.1016/j.ijrobp.2018.06.040
   De Los Santos J, 2013, INT J RADIAT ONCOL, V87, P33, DOI 10.1016/j.ijrobp.2013.02.021
   Flores-Martinez E, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12772
   Hoisak JDP, 2014, J APPL CLIN MED PHYS, V15, P257, DOI 10.1120/jacmp.v15i5.4807
   Huq MS, 2016, MED PHYS, V43, P4209, DOI 10.1118/1.4947547
   Ion RA, 2006, P REL MAINT S, P368
   Jaffray DA, 2005, SEMIN RADIAT ONCOL, V15, P208, DOI 10.1016/j.semradonc.2005.01.003
   Kapur A, 2017, PRACT RADIAT ONCOL, V7, pE499, DOI 10.1016/j.prro.2017.06.004
   Kim G, 2018, MED PHYS, V45, pE545
   Lim TY, 2019, J APPL CLIN MED PHYS, V20, P106, DOI 10.1002/acm2.12568
   Lim-Reinders S, 2017, INT J RADIAT ONCOL, V99, P994, DOI 10.1016/j.ijrobp.2017.04.023
   Lloyd SAM, 2018, MED PHYS, V45, pE315
   Lloyd SAM, 2018, J APPL CLIN MED PHYS, V19, P98, DOI 10.1002/acm2.12349
   Malajovich I, 2019, FRONT ONCOL, V9, DOI 10.3389/fonc.2019.00496
   Netherton T, 2019, MED PHYS, V46, P4304, DOI 10.1002/mp.13723
   Pan HY, 2016, INT J RADIAT ONCOL, V96, P493, DOI 10.1016/j.ijrobp.2016.02.064
   Pawlicki T, 2005, MED PHYS, V32, P2777, DOI 10.1118/1.2001209
   Pawlicki T, 2019, MED PHYS, V46, P4340, DOI 10.1002/mp.13736
   Ragheb A., 2010, NUCL RENEWABLE ENERG, P1
   Samei E, 2018, J APPL CLIN MED PHYS, V19, P4, DOI 10.1002/acm2.12484
   Sezdi M, 2016, J HEALTHC ENG, V2016, DOI 10.1155/2016/7267983
   Swanson L, 2001, INT J PROD ECON, V70, P237, DOI 10.1016/S0925-5273(00)00067-0
   Teo PT, 2019, MED PHYS, V46, P1341, DOI 10.1002/mp.13378
   Van Dyk J, 2000, MED PHYS, V27, P626, DOI [10.1118/1.598908, DOI 10.1118/1.598908]
   Wang RX, 2020, PHYS MEDICA, V71, P14, DOI 10.1016/j.ejmp.2020.01.023
   Weigl M, 2012, BMJ QUAL SAF, V21, P399, DOI 10.1136/bmjqs-2011-000188
   Wroe LM, 2020, CLIN ONCOL-UK, V32, pE111, DOI 10.1016/j.clon.2019.10.010
NR 30
TC 1
Z9 1
U1 0
U2 4
PD JUN 29
PY 2021
VL 13
IS 6
AR e16038
DI 10.7759/cureus.16038
WC Medicine, General & Internal
DA 2023-11-11
ER

PT J
AU Lee, SK
   Whatmough, PN
   Brooks, D
   Wei, GY
AF Lee, Sae Kyu
   Whatmough, Paul N.
   Brooks, David
   Wei, Gu-Yeon
TI A 16-nm Always-On DNN Processor With Adaptive Clocking and Multi-Cycle
   Banked SRAMs
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Adaptive clocking; deep neural networks (DNNs); hardware accelerators;
   Internet of Things (IoT); machine learning (ML); razor; system-on-chip
   (SoC)
ID CIRCUIT; NETWORK; SYSTEM; CHIP
AB Always-on subsystems in mobile/Internet of Things (IoT) SoCs process a variety of real-time sensor data deep neural network (DNN) classification workloads in a heavily constrained energy budget. This can be achieved with robust, low-voltage circuits, and specialized hardware accelerators. We present a 16-nm always-on DNN processor, which consists primarily of a microcontroller and a DNN accelerator with on-chip SRAM for the model weights. The design operates robustly from 0.4 to 1-V, with calibration-free automatic voltage/frequency tuning provided by tracking small non-zero razor timing error rates. A novel timing error-driven synchronization-free adaptive clocking scheme significantly reduces the adaptation latency to provide resilience to fast on-chip supply noise and reduce margins. To accommodate the tight energy constraints of always-on IoT workloads, we implement a multi-cycle SRAM read scheme that allows the memory voltage to scale at iso-throughput, improving energy efficiency across the entire operating range. The wide operating range allows for high performance at 1.36 GHz, low-power consumption downs to 750 mu W, and state-of-the-art raw efficiency at 16-bit precision of 750 GOPS/W dense or 1.81 TOPS/W sparse.
C1 [Lee, Sae Kyu; Whatmough, Paul N.; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lee, Sae Kyu] IBM TJ Watson Res Ctr, New York, NY 10598 USA.
   [Whatmough, Paul N.] Arm Res, Boston, MA 02451 USA.
RP Lee, SK (corresponding author), IBM TJ Watson Res Ctr, New York, NY 10598 USA.
EM saekyu.lee@ibm.com; paul.whatmough@arm.com; dbrooks@eecs.harvard.edu;
   gywei@g.harvard.edu
CR Alon E, 2008, IEEE J SOLID-ST CIRC, V43, P1795, DOI 10.1109/JSSC.2008.925403
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], PATTERN RECOGNIT LET
   [Anonymous], 2016, WACV
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Bowman KA, 2016, IEEE J SOLID-ST CIRC, V51, P8, DOI 10.1109/JSSC.2015.2473655
   Bowman KA, 2011, IEEE J SOLID-ST CIRC, V46, P194, DOI 10.1109/JSSC.2010.2089657
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Bull David, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P284, DOI 10.1109/ISSCC.2010.5433919
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Das S, 2014, IEEE T CIRCUITS-I, V61, P2290, DOI 10.1109/TCSI.2014.2333332
   Floyd MS, 2017, ISSCC DIG TECH PAP I, P444, DOI 10.1109/ISSCC.2017.7870452
   Hashimoto T, 2018, IEEE J SOLID-ST CIRC, V53, P1028, DOI 10.1109/JSSC.2017.2777101
   Huang G. B., 2008, WORKSHOP FACES INREA, P1
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Kurd N, 2009, IEEE J SOLID-ST CIRC, V44, P1121, DOI 10.1109/JSSC.2009.2014023
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee SB, 2012, EMERGING TECHNOLOGIES IN NON-DESTRUCTIVE TESTING V, P373
   Lee SK, 2018, PROC EUR SOLID-STATE, P158, DOI 10.1109/ESSCIRC.2018.8494245
   Lee SK, 2017, IEEE T VLSI SYST, V25, P1271, DOI 10.1109/TVLSI.2016.2633805
   Lefurgy CR, 2011, INT SYMP MICROARCH, P1
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Price P., 1988, ICASSP 88: 1988 International Conference on Acoustics, Speech, and Signal Processing (Cat. No.88CH2561-9), P651, DOI 10.1109/ICASSP.1988.196669
   Ravezzi L, 2015, IEEE J SOLID-ST CIRC, V50, P1702, DOI 10.1109/JSSC.2015.2402222
   Reddi V. J., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P77, DOI 10.1109/MICRO.2010.35
   Reyes-Ortiz JL, 2016, NEUROCOMPUTING, V171, P754, DOI 10.1016/j.neucom.2015.07.085
   Tong T, 2016, IEEE J SOLID-ST CIRC, V51, P2142, DOI 10.1109/JSSC.2016.2580598
   Tschanz James, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P282, DOI 10.1109/ISSCC.2010.5433922
   Whatmough PN, 2018, IEEE J SOLID-ST CIRC, V53, P2722, DOI 10.1109/JSSC.2018.2841824
   Whatmough PN, 2017, IEEE J SOLID-ST CIRC, V52, P1643, DOI 10.1109/JSSC.2017.2669025
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Whatmough PN, 2015, I SYMPOS LOW POWER E, P128, DOI 10.1109/ISLPED.2015.7273502
   Whatmough PN, 2013, IEEE T VLSI SYST, V21, P989, DOI 10.1109/TVLSI.2012.2202930
   Wilcox K, 2015, IEEE J SOLID-ST CIRC, V50, P24, DOI 10.1109/JSSC.2014.2357428
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang X, 2017, IEEE J SOLID-ST CIRC, V52, P2374, DOI 10.1109/JSSC.2017.2705170
NR 40
TC 19
Z9 19
U1 0
U2 3
PD JUL
PY 2019
VL 54
IS 7
BP 1982
EP 1992
DI 10.1109/JSSC.2019.2913098
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Stan, M
   Hall, M
   Ibrahim, M
   Betz, V
AF Stan, Marius
   Hall, Mathew
   Ibrahim, Mohamed
   Betz, Vaughn
GP IEEE
TI HPIPE NX: Boosting CNN Inference Acceleration Performance with
   AI-Optimized FPGAs
SO 2022 21ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY
   (ICFPT 2022)
DT Proceedings Paper
CT 21st International Conference on Field-Programmable Technology (ICFPT)
CY DEC 05-09, 2022
CL Hong Kong Univ Sci & Technol, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol
AB With the ever-increasing compute demands of artificial intelligence (AI) workloads, there is extensive interest in leveraging field-programmable gate-arrays (FPGAs) to quickly deploy hardware accelerators for the latest convolutional neural networks (CNNs). Recent FPGA architectures are also evolving to better serve the needs of AI, but accelerators need extensive re-design to leverage these new features. The Stratix 10 NX chip by Intel is a new FPGA that replaces traditional DSP blocks with in-fabric AI tensor blocks that provide 15x more multipliers and up to 143 TOPS of performance, at the cost of lower precision (INT8) and significant restrictions on how many operands can be fed to the multipliers from the programmable routing. In this paper, we explore different CNN accelerator structures to leverage the tensor blocks, considering the various tensor block modes, operand bandwidth restrictions, and on-chip memory restrictions. We incorporate the most performant techniques into HPIPE, a layer-pipelined and sparse-aware CNN accelerator for FPGAs. We enhance HPIPE's software compiler to restructure the CNN computations and on-chip memory layout to take advantage of the additional multipliers offered by the new tensor block architecture, while also avoiding stalls due to data loading restrictions. We achieve cycle-by-cycle speedups in tensor mode of up to 8.3x for Mobilenet-v1 versus the original HPIPE design using conventional DSPs. On the FPGA, we achieve a throughput of 28,541 and 29,429 images/s on Mobilenet-v1 and Mobilenet-v2 respectively, outperforming all previous FPGA accelerators by at least 4.0x, including one on an AI-optimized Xilinx chip. We also outperform NVIDIA's V100 GPU, a machine learning targeted GPU on a similar process node with a 1.7x larger die size, by up to 17x with a batch size of one and 1.3x with NVIDIA's largest reported batch size of 128.
C1 [Stan, Marius; Hall, Mathew; Ibrahim, Mohamed; Betz, Vaughn] Univ Toronto, Toronto, ON, Canada.
RP Stan, M (corresponding author), Univ Toronto, Toronto, ON, Canada.
EM marius.stan@mail.utoronto.ca; mathew.hall@mail.utoronto.ca;
   mohamedabdelfattah.ibrahim@mail.utoronto.ca; vaughn@ece.utoronto.ca
CR Ahmad Sagheer, 2019, 2019 15 INT C EL COM, P1
   [Anonymous], 2018, INT STRAT 10 VAR PRE
   [Anonymous], 2021, HIGH BANDW MEM HBM2
   [Anonymous], 2020, INT STRAT 10 NX AI T
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P10, DOI 10.1109/ICFPT51103.2020.00011
   Boutros A, 2021, IEEE CIRC SYST MAG, V21, P4, DOI 10.1109/MCAS.2021.3071607
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Colangelo P, 2018, ANN IEEE SYM FIELD P, P73, DOI 10.1109/FCCM.2018.00020
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Hall M. K., 2020, THESIS U TORONTO
   Hall M, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P56, DOI 10.1109/ICFPT51103.2020.00017
   Hall V., 2020, P ACMSIGDA INT S FIE
   Khan A, 2019, PHYS LETT B, V795, P248, DOI 10.1016/j.physletb.2019.06.009
   Langhammer M, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3520197
   Meng J, 2021, I C FIELD PROG LOGIC, P9, DOI 10.1109/FPL53798.2021.00010
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   NVIDIA Corporation, 2020, NVID A100 TENS COR G
   NVIDIA Corporation, 2019, NVID TESL DEEP LEARN
   Stan M.O., 2022, THESIS U TORONTO
   Szanto T. K. P., 2022, 2022 11 MEDITERRANEA, P1
   Tschannen M, 2018, PR MACH LEARN RES, V80
   Wang LD, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-76550-z
   Wu D, 2019, I C FIELD PROG LOGIC, P136, DOI 10.1109/FPL.2019.00030
   Zhou AJ, 2017, Arxiv, DOI arXiv:1702.03044
NR 24
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 140
EP 148
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT C
AU Panda, DK
   Lu, XY
AF Panda, Dhabaleswar K.
   Lu, Xiaoyi
GP ACM
TI HPC Meets Cloud: Building Efficient Clouds for HPC, Big Data, and Deep
   Learning Middleware and Applications
SO PROCEEDINGS OF THE 10TH INTERNATIONAL CONFERENCE ON UTILITY AND CLOUD
   COMPUTING (UCC' 17)
DT Proceedings Paper
CT 10th International Conference on Utility and Cloud Computing (UCC) / 4th
   International Conference on Big Data Computing, Applications and
   Technologies (BDCAT)
CY DEC 05-08, 2017
CL Austin, TX
DE HPC Clouds; Virtual Machine; Container; InfiniBand; MPI; Big Data; Deep
   Learning
AB Significant growth has been witnessed during the last few years in HPC clusters with multi-/many-core processors, accelerators, and high-performance interconnects (such as InfiniBand, Omni-Path, iWARP, and RoCE). To alleviate the cost burden, sharing HPC cluster resources to end users through virtualization for both scientific computing and Big Data processing is becoming more and more attractive. In this tutorial, we first provide an overview of popular virtualization system software on HPC cloud environments, such as hypervisors (e.g., KVM), containers (e.g., Docker, Singularity), OpenStack, Slurm, etc. Then we provide an overview of high-performance interconnects and communication mechanisms on HPC clouds, such as InfiniBand, RDMA, SR-IOV, IVShmem, etc. We further discuss the opportunities and technical challenges of designing high-performance MPI runtime over these environments. Next, we introduce our proposed novel approaches to enhance MPI library design over SR-IOV enabled InfiniBand clusters with both virtual machines and containers. We also discuss how to integrate these designs into popular cloud management systems like OpenStack and HPC cluster resource managers like Slurm. Not only for HPC middleware and applications, we will demonstrate how high-performance solutions can be designed to run Big Data and Deep Learning workloads (like Hadoop, Spark, TensorFlow, CNTK, Caffe) in HPC cloud environments.
C1 [Panda, Dhabaleswar K.; Lu, Xiaoyi] Ohio State Univ, Columbus, OH 43210 USA.
RP Panda, DK (corresponding author), Ohio State Univ, Columbus, OH 43210 USA.
EM panda@cse.ohio-state.edu; luxi@cse.ohio-state.edu
CR Gugnani S, 2016, INT CONF CLOUD COMP, P152, DOI [10.1109/CloudCom.2016.34, 10.1109/CloudCom.2016.0037]
   Lu X., 2016, P 8 IEEE INT C CLOUD, P152
   Lu X., 2017, RES ADV CLOUD COMPUT
   Yu CC, 2016, J OPT-INDIA, V45, P16, DOI 10.1007/s12596-016-0317-6
   Zhang J, 2014, INT C HIGH PERFORM
   Zhang J, 2016, LECT NOTES COMPUT SC, V9833, P349, DOI 10.1007/978-3-319-43659-3_26
   Zhang J, 2015, IEEE ACM INT SYMP, P71, DOI 10.1109/CCGrid.2015.166
   Zhang J, 2017, PROTEOMICS, V17, DOI 10.1002/pmic.201700103
   Zhang J, 2017, INT CONF ASIAN LANG, P172, DOI 10.1109/IALP.2017.8300572
NR 9
TC 2
Z9 2
U1 0
U2 4
PY 2017
BP 189
EP 190
DI 10.1145/3147213.3149455
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Liu, SQ
   Canan, TF
   Chenji, H
   Laha, S
   Kaya, S
   Karanth, A
AF Liu, Siqin
   Canan, Talha Furkan
   Chenji, Harshavardhan
   Laha, Soumyasanta
   Kaya, Savas
   Karanth, Avinash
TI Exploiting Wireless Technology for Energy-Efficient Accelerators With
   Multiple Dataflows and Precision
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Wireless communication; Transceivers; Integrated circuit
   interconnections; Hardware acceleration; Costs; Throughput; Multicast
   communication; Wireless technology; transceiver design; dataflows;
   precision
ID DEEP NEURAL-NETWORKS; DESIGN; ARCHITECTURE
AB As model size and the number of layers increase, Deep Neural Networks (DNNs) demand enormous computational power and throughput to meet exceedingly high prediction accuracy's of today's machine learning (ML) applications. Spatial hardware accelerators have been proposed that optimize the dataflow and exploit sparsity to provide a significant decrease in power consumption. As spatial architectures are traditionally designed with metallic interconnects, significant power is expended for data movement for different dataflows. In this paper, we exploit extended wireless technology to design a power-efficient and high-throughput DNN accelerator, e-WiNN, that can be configured for all representative dataflows and arithmetic precisions. We leverage novel circuit design by utilizing Dadda-algorithm based Multiply-and-Accumulate (MAC) circuits for 4-bit, 8-bit and 16-bit inputs to reduce area, power and delay constraints in 14 nm predictive technology. Our novel wireless transmitter integrates on-off keying (OOK) modulator with power amplifier that results in significant energy savings. To reduce the area overhead, we cluster wireless transceivers into groups of four such that both weights and input features can be effectively multicast to reduce the data movement. The energy efficient transceiver circuit is implemented in state-of-the-art BSIM 32 nm FinFET technology model and our link budget considers required RF power for different frequencies and inter-PE distance at three different antenna directivities including isotropic. Our detailed RTL modeling and cycle-accurate simulation results show that e-WiNN achieves 36.3% latency reduction and 76.1% energy saving when compared to state-of-art wire interconnected accelerators; 70.3% area reduction and 41.6% energy saving at the cost of 11% latency increase when compared to prior wireless accelerators on various neural networks (AlexNet, VGG16, and ResNet-9/50).
C1 [Liu, Siqin; Canan, Talha Furkan; Chenji, Harshavardhan; Kaya, Savas; Karanth, Avinash] Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
   [Laha, Soumyasanta] Calif State Univ Fresno, Dept Elect & Comp Engn, Fresno, CA 93740 USA.
RP Karanth, A (corresponding author), Ohio Univ, Sch Elect Engn & Comp Sci, Athens, OH 45701 USA.
EM ls847719@ohio.edu; tc675716@ohio.edu; chenji@ohio.edu;
   laha@csufresno.edu; kaya@ohio.edu; karanth@ohio.edu
CR Abdelgawad A, 2007, IEEE INT SYMP CIRC S, P3199, DOI 10.1109/ISCAS.2007.378152
   Alibakhshikenari M, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-61099-8
   [Anonymous], 2021, BSIM CMG BSIM GROUP
   Ascia G., 2020, P IEEEACM INT S NETW, P1
   Ashokkumar N, 2020, LECT NOTE NETW SYST, V89, P113, DOI 10.1007/978-981-15-0146-3_12
   Awad M, 2018, INT CONF ULTI INTEGR, P129
   Bahrami B, 2018, J PARALLEL DISTR COM, V120, P307, DOI 10.1016/j.jpdc.2018.02.032
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   Dave S, 2020, INT CONF ACOUST SPEE, P1544, DOI [10.1109/ICASSP40776.2020.9054275, 10.1109/icassp40776.2020.9054275]
   Deb S, 2013, IEEE T COMPUT, V62, P2382, DOI 10.1109/TC.2012.224
   DiTomaso D, 2015, IEEE T PARALL DISTR, V26, P3289, DOI 10.1109/TPDS.2014.2383384
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Gholami Amir, 2021, ARXIV210313630
   Gudaparthi S, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P1, DOI 10.1145/3352460.3358316
   Guirado R, 2021, ASIA S PACIF DES AUT, P806, DOI 10.1145/3394885.3431537
   Guirado R, 2019, IEEE I C ELECT CIRC, P85, DOI [10.1109/icecs46596.2019.8964858, 10.1109/ICECS46596.2019.8964858]
   Hubara I, 2016, ADV NEUR IN, V29
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kodi A, 2018, INT PARALL DISTRIB P, P1010, DOI 10.1109/IPDPS.2018.00110
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2017, 11 IEEE ACM INT S NE, V2017, P1, DOI [10.1145/3130218.3130230, DOI 10.1145/3130218.3130230]
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Latotzke C, 2021, IEEE ACCESS, V9, P9785, DOI 10.1109/ACCESS.2021.3050670
   Linan R. G., 2019, THESIS U POLITECNICA
   Liu SQ, 2021, PR IEEE COMP DESIGN, P277, DOI 10.1109/ICCD53106.2021.00052
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Norrie T., 2020, 08 2020 HOT CHIPS S, P1
   Rahaman MM, 2020, ADV INTELL SYST COMP, V1120, P325, DOI 10.1007/978-981-15-2449-3_28
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sinha M, 2018, IEEE INT CONF ASAP, P101
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Timoneda X, 2020, IEEE T COMMUN, V68, P3247, DOI 10.1109/TCOMM.2020.2973988
   Tiwari B., 2021, ARXIV210802569
   Townsend WJ, 2003, PROC SPIE, V5205, P552, DOI 10.1117/12.507012
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wu JQ, 2017, IEEE T ANTENN PROPAG, V65, P6838, DOI 10.1109/TAP.2017.2758400
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yexi Song, 2015, 2015 IEEE MTT-S International Microwave Workshop Series on Advanced Materials and Processes for RF and THz Applications (IMWS-AMP). Proceedings, P1, DOI 10.1109/IMWS-AMP.2015.7324967
   Zhang H, 2020, IEEE T COMPUT, V69, P26, DOI 10.1109/TC.2019.2936192
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 48
TC 2
Z9 2
U1 0
U2 0
PD JUL
PY 2022
VL 69
IS 7
BP 2742
EP 2755
DI 10.1109/TCSI.2022.3166752
EA APR 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Singh, S
   Ghazal, O
   Jha, CK
   Rana, V
   Drechsler, R
   Shafik, R
   Yakovlev, A
   Patkar, S
   Merchant, F
AF Singh, Simranjeet
   Ghazal, Omar
   Jha, Chandan Kumar
   Rana, Vikas
   Drechsler, Rolf
   Shafik, Rishad
   Yakovlev, Alex
   Patkar, Sachin
   Merchant, Farhad
GP IEEE
TI Finite State Automata Design using 1T1R ReRAM Crossbar
SO 2023 21ST IEEE INTERREGIONAL NEWCAS CONFERENCE, NEWCAS
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 21st IEEE Interregional NEWCAS Conference (NEWCAS)
CY JUN 26-28, 2023
CL Edinburgh, SCOTLAND
DE FSA; Machine Learning; ReRAM; Memristors; In-Memory Computing
AB Data movement costs constitute a significant bottleneck in modern machine learning (ML) systems. When combined with the computational complexity of algorithms, such as neural networks, designing hardware accelerators with low energy foot-print remains challenging. Finite state automata (FSA) constitute a type of computation model used as a low-complexity learning unit in ML systems. The implementation of FSA consists of a number of memory states. However, FSA can be in one of the states at a given time. It switches to another state based on the present state and input to the FSA. Due to its natural synergy with memory, it is a promising candidate for in-memory computing for reduced data movement costs. This work focuses on a novel FSA implementation using resistive RAM (ReRAM) for state storage in series with a CMOS transistor for biasing controls. We propose using multi-level ReRAM technology capable of transitioning between states depending on bias pulse amplitude and duration. We use an asynchronous control circuit for writing each ReRAM-transistor cell for the on-demand switching of the FSA. We investigate the impact of the device-to-device and cycle-to-cycle variations on the cell and show that FSA transitions can be seamlessly achieved without degradation of performance. Through extensive experimental evaluation, we demonstrate the implementation of FSA on 1T1R ReRAM crossbar.
C1 [Singh, Simranjeet; Patkar, Sachin] Indian Inst Technol, Mumbai, Maharashtra, India.
   [Ghazal, Omar; Shafik, Rishad; Yakovlev, Alex; Merchant, Farhad] Newcastle Univ, Newcastle Upon Tyne, England.
   [Jha, Chandan Kumar; Drechsler, Rolf] Univ Bremen, Bremen, Germany.
   [Drechsler, Rolf] DFKI GmbH, Kaiserslautern, Germany.
   [Singh, Simranjeet; Rana, Vikas] Forschungszentrum Julich, Julich, Germany.
RP Singh, S (corresponding author), Indian Inst Technol, Mumbai, Maharashtra, India.; Singh, S (corresponding author), Forschungszentrum Julich, Julich, Germany.
EM simranjeet@ee.iitb.ac.in; O.G.G.Awf2@newcastle.ac.uk;
   chajha@uni-bremen.de; rana@fz-juelich.de; drechsler@uni-bremen.de;
   rishad.shafik@newcastle.ac.uk; alex.yakovlev@newcastle.ac.uk;
   patkar@ee.iitb.ac.in; farhad.merchant@newcastle.ac.uk
CR Aziza H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10182222
   Bengel C, 2020, IEEE T CIRCUITS-I, V67, P4618, DOI 10.1109/TCSI.2020.3018502
   Froehlich S, 2022, IT-INF TECHNOL, V64, P99, DOI 10.1515/itit-2021-0042
   Granmo OC, 2021, Arxiv, DOI arXiv:1804.01508
   Halawani Y, 2019, IEEE J EM SEL TOP C, V9, P388, DOI 10.1109/JETCAS.2019.2909317
   Iraji R, 2006, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL CONFERENCE ON COGNITIVE INFORMATICS, VOLS 1 AND 2, P617
   Jha CK, 2022, IEEE J EXPLOR SOLID-, V8, P68, DOI 10.1109/JXCDC.2022.3222015
   Luo KL, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P1814
   Pedretti G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091063
   Poliakov I, 2009, LECT NOTES COMPUT SC, V5606, P333, DOI 10.1007/978-3-642-02424-5_21
   RABIN MO, 1959, IBM J RES DEV, V3, P114, DOI 10.1147/rd.32.0114
   Rezvanian A, 2019, STUD COMPUT INTELL, V820, P1, DOI 10.1007/978-3-030-10767-3_1
   Rosenblum L. Y., 1985, International Workshop on Timed Petri Nets (Cat. No. 2187-3), P199
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Siemon A, 2019, IEEE INT SYMP CIRC S
   Staudigl F, 2022, IEEE DES TEST, V39, P90, DOI 10.1109/MDAT.2021.3102013
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Wheeldon A, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0593
   Yu SQ, 2020, DES AUT TEST EUROPE, P638, DOI 10.23919/DATE48585.2020.9116417
   Zhang M., 2017, FINITE STATE MACHINE, V10
NR 20
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/NEWCAS57931.2023.10198206
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mittal, R
   Prince, AA
   Fredo, ARJ
AF Mittal, Rakshit
   Prince, A. Amalin
   Fredo, Agastinose Ronickom Jac
TI Time-Sliced Architecture for Efficient Accelerator to Detrend
   High-Definition Electroencephalograms
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
DT Article
DE Electroencephalography; Computer architecture; Hardware acceleration;
   Registers; Time division multiplexing; Random access memory; Signal
   processing algorithms; Detrending; electroencephalograms (EEGs);
   field-programmable gate array; power efficiency; resource efficiency
ID REMOVAL; DESIGN
AB Measuring electroencephalography (EEG) signals has a variety of important applications. Most processing systems use statistical machine learning algorithms. To increase accuracy of such systems, more data are measured in the form of increased channel count, called high-definition EEG (HD-EEG). EEG processing is hampered by noise from different instruments. While traditional detrending algorithms are highly resource-intensive, the problem is compounded for HD-EEG detrending. The generic-compounding architecture is not scalable. In such an architecture, one instance of the hardware accelerator is used for each channel. This is unsuitable for wearable devices which have limited computational and energy resources. In this article, we propose a time-sliced architecture to optimize resource and power utilization for a multi-channeled system. This is accomplished using time-division multiplexers and demultiplexers to share resources between different channels. The adaptive maximum-mean-minimum (AMaMeMi) filter is a computationally efficient algorithm, reported earlier for detrending EEGs. We apply guidelines of the proposed architecture, on the AMaMeMi filter, to design an efficient HD-EEG detrending hardware accelerator. The proposed accelerator is implemented for various channel counts. We use the Xilinx field-programmable gate array with part number XC7VX980T-1FFG1930 for implementation. We verify the correctness of the proposed architecture by comparing its output with that of the generic-compounding architecture. For a 1024-channeled system, the proposed time-sliced architecture provides 99% reduction in lookup table utilization, 70% in flip-flop utilization, 95% in area utilization, and 70% in estimated power utilization.
C1 [Mittal, Rakshit] Inst Polytech Paris, Dept INFRES, LTCI Lab, Telecom Paris, F-91120 Palaiseau, France.
   [Mittal, Rakshit; Prince, A. Amalin] Birla Inst Technol & Sci, Dept Elect & Elect Engn, Sancoale 403726, Goa, India.
   [Fredo, Agastinose Ronickom Jac] Indian Inst Technol BHU, Sch Biomed Engn, Varanasi 221005, Uttar Pradesh, India.
RP Prince, AA (corresponding author), Birla Inst Technol & Sci, Dept Elect & Elect Engn, Sancoale 403726, Goa, India.
EM amalinprince@goa.bits-pilani.ac.in
CR Acharyya A, 2018, COMPUT METH PROG BIO, V158, P123, DOI 10.1016/j.cmpb.2018.02.009
   Akhtar MT, 2012, SIGNAL PROCESS, V92, P401, DOI 10.1016/j.sigpro.2011.08.005
   Bajpai R, 2021, COMPUT BIOL MED, V133, DOI 10.1016/j.compbiomed.2021.104434
   Castells-Rufas D, 2015, BIOMED SIGNAL PROCES, V21, P137, DOI 10.1016/j.bspc.2015.06.001
   Chowdhury D, 2020, IEEE T INSTRUM MEAS, V69, P7522, DOI 10.1109/TIM.2020.2984142
   Dutande PV, 2018, PROCEEDINGS OF THE 2018 SECOND INTERNATIONAL CONFERENCE ON INTELLIGENT COMPUTING AND CONTROL SYSTEMS (ICICCS), P728, DOI 10.1109/ICCONS.2018.8662998
   George GC, 2019, MEASUREMENT, V139, P482, DOI 10.1016/j.measurement.2019.03.028
   Ghani U., 2018, BIOMED RES INT, P1
   Hosseini MP, 2021, IEEE REV BIOMED ENG, V14, P204, DOI 10.1109/RBME.2020.2969915
   Lei C, 2022, IEEE T INSTRUM MEAS, V71, DOI 10.1109/TIM.2021.3137159
   Maddirala AK, 2018, IEEE T INSTRUM MEAS, V67, P382, DOI 10.1109/TIM.2017.2775358
   Mittal R, 2021, BIOMED SIGNAL PROCES, V69, DOI 10.1016/j.bspc.2021.102927
   Mittal R, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3018235
   Mumtaz W, 2021, BIOMED SIGNAL PROCES, V68, DOI 10.1016/j.bspc.2021.102741
   Musk E, 2019, J MED INTERNET RES, V21, DOI 10.2196/16194
   Oikonomou P. V., 2016, ARXIV160200904, DOI [10.48550/arxiv.1602.00904, DOI 10.48550/ARXIV.1602.00904]
   Prince A. Amalin, 2015, 2015 10th International Symposium on Reconfigurable Communication-Centric Systems-on-Chip (ReCoSoC), P1, DOI 10.1109/ReCoSoC.2015.7238091
   Prince AA, 2016, IEEE IND ELEC, P895, DOI 10.1109/IECON.2016.7793218
   Reinders J, 2012, STRUCTURED PARALLEL PROGRAMMING: PATTERNS FOR EFFICIENT COMPUTATION, P39, DOI 10.1016/B978-0-12-415993-8.00002-5
   Shih Y.-H., 2012, PROC ASIA PACIFIC SI, P1
   Song Y., 2021, IEEE T INSTRUM MEAS, V70, P1
   Sreekrishna RR, 2016, 2016 INTERNATIONAL CONFERENCE ON COMMUNICATION AND SIGNAL PROCESSING (ICCSP), VOL. 1, P745, DOI 10.1109/ICCSP.2016.7754244
   Valentin O, 2019, IEEE T BIOMED CIRC S, V13, P103, DOI 10.1109/TBCAS.2018.2876240
   Vipin Kizheppatt, 2012, Reconfigurable Computing: Architectures, Tools and Applications. Proceedings of the 8th International Symposium, ARC 2012, P13, DOI 10.1007/978-3-642-28365-9_2
   Wang YH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3047488
   Yu X., 2021, IEEE T INSTRUM MEAS, V70, P1, DOI DOI 10.1109/TIM.2021.3069026
NR 26
TC 0
Z9 0
U1 1
U2 3
PY 2022
VL 71
AR 2003509
DI 10.1109/TIM.2022.3180418
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Ono, T
   Waidyasooriya, HM
   Hariyama, M
   Ishigaki, T
AF Ono, Taisuke
   Waidyasooriya, Hasitha Muthumala
   Hariyama, Masanori
   Ishigaki, Tsukasa
BE Hochin, T
   Hirata, H
   Hiroki, N
TI Architecture of an FPGA Accelerator for LDA-Based Inference
SO 2017 18TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING,
   ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING
   (SNDP 2017)
DT Proceedings Paper
CT 18th IEEE/ACIS International Conference on Software Engineering,
   Artificial Intelligence, Networking and Parallel/Distributed Computing
   (SNPD)
CY JUN 26-28, 2017
CL Kanazawa, JAPAN
DE Latent Dirichlet allocation; Gibbs sampling; data classification; OpenCL
   for FPGA; machine learning
AB Latent Dirichlet allocation (LDA) based topic inference is a data classification method, that is used efficiently for extremely large data sets. However, the processing time is very large due to the serial computational behavior of the Markov Chain Monte Carlo method used for the topic inference. We propose a pipelined hardware architecture and memory allocation scheme to accelerate LDA using parallel processing. The proposed architecture is implemented on a reconfigurable hardware called FPGA (field programmable gate array), using OpenCL design environment. According to the experimental results, we achieved maximum speed-up of 2.38 times, while maintaining the same quality compared to the conventional CPU-based implementation.
C1 [Ono, Taisuke; Waidyasooriya, Hasitha Muthumala; Hariyama, Masanori] Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
   [Ishigaki, Tsukasa] Tohoku Univ, Grad Sch Econ & Management, Aoba Ku, 27-1 Kawauchi, Sendai, Miyagi 9808576, Japan.
RP Ono, T (corresponding author), Tohoku Univ, Grad Sch Informat Sci, Aoba Ku, 6-3-09 Aramaki Aza Aoba, Sendai, Miyagi 9808579, Japan.
EM ono52@dc.tohoku.ac.jp; hasitha@tohoku.ac.jp; hariyama@tohoku.ac.jp;
   isgk@econ.tohoku.ac.jp
CR Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Wang C, 2009, PROC CVPR IEEE, P1903, DOI [10.1109/CVPR.2009.5206800, 10.1109/CVPRW.2009.5206800]
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gilks W., 1995, MARKOV CHAIN MONTE C, DOI DOI 10.1201/B14835
   Griffiths TL, 2004, P NATL ACAD SCI USA, V101, P5228, DOI 10.1073/pnas.0307752101
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mizoguchi S., 2017, SERVICEOLOGY SMART S, P19
   Newman D., 2007, ADV NEURAL INFORM PR, V20, P1081
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2017
BP 357
EP 362
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Kim, S
   Gokmen, T
   Lee, HM
   Haensch, WE
AF Kim, Seyoung
   Gokmen, Tayfun
   Lee, Hyung-Min
   Haensch, Wilfried E.
GP IEEE
TI Analog CMOS-based Resistive Processing Unit for Deep Neural Network
   Training
SO 2017 IEEE 60TH INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT 60th IEEE International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY AUG 06-09, 2017
CL Tufts Univ, Medford Somerville Campus, Boston, MA
HO Tufts Univ, Medford Somerville Campus
DE resistive processing unit; RPU; deep neural network; machine learning
   accelerator; resistive memory
AB Recently we have shown that an architecture based resistive processing unit (RPU) devices has potential to achieve significant acceleration in deep neural network (DNN) training compared to today's software-based DNN implementations running on CPU/GPU. However, currently available device candidates based on non-volatile memory technologies do not satisfy all the requirements to realize the RPU concept. Here, we propose an analog CMOS-based RPU design (CMOS RPU) which can store and process data locally and can be operated in a massively parallel manner. We analyze various properties of the CMOS RPU to evaluate the functionality and feasibility for acceleration of DNN training.
C1 [Kim, Seyoung; Gokmen, Tayfun; Haensch, Wilfried E.] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Lee, Hyung-Min] Korea Univ, Sch Elect Engn, Seoul, South Korea.
RP Kim, S (corresponding author), IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM sykim@us.ibm.com
CR Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Gokmen T., TRAINING DEEP CONVOL
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gupta S, 2016, IEEE DATA MINING, P171, DOI [10.1109/ICDM.2016.0028, 10.1109/ICDM.2016.122]
   Le QV, 2013, INT CONF ACOUST SPEE, P8595, DOI 10.1109/ICASSP.2013.6639343
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
NR 8
TC 30
Z9 32
U1 0
U2 1
PY 2017
BP 422
EP 425
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Arredondo-Velázquez, M
   Diaz-Carmona, J
   Torres-Huitzil, C
   Padilla-Medina, A
   Prado-Olivarez, J
AF Arredondo-Velazquez, Moises
   Diaz-Carmona, Javier
   Torres-Huitzil, Cesar
   Padilla-Medina, Alfredo
   Prado-Olivarez, Juan
TI A streaming architecture for Convolutional Neural Networks based on
   layer operations chaining
SO JOURNAL OF REAL-TIME IMAGE PROCESSING
DT Article
DE Convolutional Neural Networks; Streaming architecture; Layer operation
   chaining
ID ACCELERATOR
AB Convolutional Neural Networks (CNN) have become one of the best algorithms in machine learning for content classification of digital images. The CNN computational complexity is much larger than traditional algorithms, that is why the use of Graphical Processor Units (GPU) and online servers to achieve operations acceleration is a common solution. However, there is a growing demand for real-time processing solutions in the object recognition field mainly implemented on embedded systems, which are limited both in resources and energy consumption. Recently, reported works are focused on minimizing the required resources through two design strategies. The first one is by implementing one accelerator that can be adapted to the operations of the whole CNN. The CNN architecture proposals with one accelerator for each convolution layer belong to the second design strategy, where higher performance is achieved in multiple image processing. A new design strategy is proposed in this paper, which is based on multiple accelerators using a layer operation chaining scheme for computing in parallel the operations corresponding to multiple CNN layers. Three types of parallel data processing are adopted in the proposed architecture, where the parallelism level for convolution layers is determined by defined cost-function-based algorithms. The proposed design strategy is shown by implementing three naive CNNs on a De2i-150 board, in which a peak acceleration of 18.04x was achieved in contrast with state-of-the-art design methods without layer operation chaining. Furthermore, the design results of one modified Alexnet CNN were obtained. According to the obtained results, the proposed design strategy allows to achieve a smaller processing time than that obtained by reported works using the other two design strategies. In addition, a competitive result in resources utilization is obtained for naive CNNs.
C1 [Arredondo-Velazquez, Moises; Diaz-Carmona, Javier; Padilla-Medina, Alfredo; Prado-Olivarez, Juan] Technol Inst Celaya, Elect Engn Dept, Av Tecnol & G Cubas S-N, Celaya 38010, Gto, Mexico.
   [Torres-Huitzil, Cesar] Tecnol Monterrey, Sch Engn & Sci, Campus Puebla,Av Atlixcayotl 5718, Puebla 72453, Puebla, Mexico.
RP Arredondo-Velázquez, M (corresponding author), Technol Inst Celaya, Elect Engn Dept, Av Tecnol & G Cubas S-N, Celaya 38010, Gto, Mexico.
EM moises.arredondo@hotmail.com; javier.diaz@itcelaya.edu.mx;
   torresc@tec.mx
CR Abdelouahab K, 2017, IEEE EMBED SYST LETT, V9, P113, DOI 10.1109/LES.2017.2743247
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chang J, 2017, IEICE ELECTRON EXPR, V14, DOI 10.1587/elex.13.20161134
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   DENIL M, 2013, P 26 INT C NEUR INF, V2
   Du L, 2018, IEEE T CIRCUITS-I, V65, P198, DOI 10.1109/TCSI.2017.2735490
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   DUNDAR A, 2017, IEEE T NEURAL NETWOR
   FU Y, 2016, DEEP LEARNING INT8 O
   Gong Y., 2014, ARXIV14126115
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Han S, 2015, ADV NEUR IN, V28
   Hu H., 2016, ARXIV160703250
   Hu J, 2018, PROC CVPR IEEE, P7132, DOI [10.1109/TPAMI.2019.2913372, 10.1109/CVPR.2018.00745]
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LACEY G, 2016, ARXIVABS160204283 CO
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 2013, ARXIV PREPRINT ARXIV
   Li HY, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/6786184
   Li N, 2016, IEEE SW SYMP IMAG, P165, DOI 10.1109/SSIAI.2016.7459201
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Nakahara Hiroki, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293933
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Song LL, 2016, DES AUT CON, DOI 10.1145/2897937.2897995
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Sullivan GJ, 1996, IEEE T INFORM THEORY, V42, P1365, DOI 10.1109/18.532878
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tu FB, 2017, IEEE T VLSI SYST, V25, P2220, DOI 10.1109/TVLSI.2017.2688340
   Wen W, 2016, ADV NEUR IN, V29
   Winograd Shmuel, 1980, ARITHMETIC COMPLEXIT, DOI [10.1137/1.9781611970364, DOI 10.1137/1.9781611970364]
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang CF, 2016, J SENSORS, V2016, DOI 10.1155/2016/9307560
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
NR 42
TC 8
Z9 8
U1 1
U2 11
PD OCT
PY 2020
VL 17
IS 5
BP 1715
EP 1733
DI 10.1007/s11554-019-00938-y
EA JAN 2020
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT C
AU Ma, XH
   Si, C
   Wang, Y
   Liu, C
   Zhang, L
AF Ma, Xiaohan
   Si, Chang
   Wang, Ying
   Liu, Cheng
   Zhang, Lei
GP IEEE Comp Soc
TI NASA: Accelerating Neural Network Design with a NAS Processor
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
AB Neural network search (NAS) projects a promising direction to automate the design process of efficient and powerful neural network architectures. Nevertheless, the NAS techniques have to dynamically generate a large number of candidate neural networks, and iteratively train and evaluate these on-line generated network architectures, thus they are extremely time-consuming even when deployed on large GPU clusters, which dramatically hinders the adoption of NAS. Though recently there are many specialized architectures proposed to accelerate the training or inference of neural networks, we observe that existing neural network accelerators are typically targeted at static neural network architectures, and they are not suitable to accelerate the evaluation of the dynamical neural network candidates evolving during the NAS process, which cannot be deployed onto current accelerators via the off-line compilation.
   To enable rapid and energy-efficient NAS in compact single-chip solutions, we propose NASA, a specialized architecture for one-shot based NAS acceleration. It is able to generate, schedule, and evaluate the candidate neural network architectures for the target machine learning workload with high speed, significantly alleviating the processing bottleneck of one-shot NAS. Motivated by the observation that there are considerable computation sharing opportunities among the different neural network candidates generated in one-shot NAS, NASA is equipped with an onchip network fusion unit to remove the redundant computation during the network mapping stage. In addition, the NASA accelerator can partition and re-schedule the candidate neural network architectures at fine-granularity to maximize the chance of data reuse and improve the utilization of the accelerator arrays integrated to accelerate network evaluation. According to our experiments on multiple one-shot NAS tasks, NASA achieves 33.52 x performance speedup and 214.33 x energy consumption reduction on average when compared to a CPU-GPU system.
C1 [Ma, Xiaohan; Si, Chang; Wang, Ying; Liu, Cheng; Zhang, Lei] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Wang, Ying; Liu, Cheng] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Ma, Xiaohan; Si, Chang] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Wang, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.; Wang, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
EM maxiaohan@ict.ac.cn; sichang19g@ict.ac.cn; wangying2009@ict.ac.cn;
   liucheng@ict.ac.cn; zlei@ict.ac.cn
CR Alwani M, 2016, INT SYMP MICROARCH
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   Baker B., 2017, ARXIV PREPRINT ARXIV
   Baker B., 2016, ARXIV161102167
   Bello I, 2017, PR MACH LEARN RES, V70
   Bender Gabriel, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P14311, DOI 10.1109/CVPR42600.2020.01433
   Bender G., 2018, P MACHINE LEARNING R, P550
   Brock Andrew, 2018, P INT C LEARN REPR
   Cai H., 2019, 7 INT C LEARN REPR I
   Cai H., 2018, INT C MACH LEARN, P678
   Cai H., 2020, P INT C LEARN REPR, P1
   Chen LC, 2018, ADV NEUR IN, V31
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y., 2019, ARXIV190310979
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YK, 2019, PROC CVPR IEEE, P4782, DOI 10.1109/CVPR.2019.00492
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chu X., 2021, ARXIV190701845, P12239, DOI DOI 10.1109/ICCV48922.2021.01202
   Chu Xiangxiang, 2021, INT C LEARN REPR
   Chu Xiangxiang, 2020, EUR C COMP VIS, P465, DOI DOI 10.1007/978-3-030-58555-6_28
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XY, 2019, IEEE I CONF COMP VIS, P3680, DOI 10.1109/ICCV.2019.00378
   Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hinton G, 2009, LEARNING MULTIPLE LA
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hutter F, 2019, P INT C LEARN REPR
   Intel Corporation Intel<(R), 2011, INT 64 IA 32 ARCH SO
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Li L, 2020, PR MACH LEARN RES, V115, P367
   Li S, 2020, IEEE COMPUT ARCHIT L, V19, P106, DOI 10.1109/LCA.2020.2973991
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Liu CX, 2019, PROC CVPR IEEE, P82, DOI 10.1109/CVPR.2019.00017
   Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Lu ZC, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P419, DOI 10.1145/3321707.3321729
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Miller B. L., 1995, Complex Systems, V9, P193
   NVIDIA Corporation, 2017, NVIDIA DEEP LEARN AC
   NVIDIA Corporation, 2019, CUD TOOLK DOC V10 1
   NVIDIA Corporation, 2018, NVID DEEP LEARN SDK
   Paszke A, 2019, ADV NEUR IN, V32
   Pham H, 2018, PR MACH LEARN RES, V80
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Samajdar A, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P855, DOI [10.1109/MICR0.2018.00074, 10.1109/MICRO.2018.00074]
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Suganuma M, 2017, PROCEEDINGS OF THE 2017 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'17), P497, DOI 10.1145/3071178.3071229
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   TinyImageNet, 2020, TIN IM VIS REC CHALL
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wan Alvin, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P12962, DOI 10.1109/CVPR42600.2020.01298
   Wei T., 2016, INT C MACHINE LEARNI, P564
   Xie L., 2020, ARXIV200801475
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   You S, 2020, PROC CVPR IEEE, P1996, DOI 10.1109/CVPR42600.2020.00207
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang M, 2020, PROCEEDINGS OF THE TWENTY-NINTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3188
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhichao Lu, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P35, DOI 10.1007/978-3-030-58452-8_3
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zoph Barret, 2017, INT C LEARNING REPRE
NR 71
TC 1
Z9 1
U1 0
U2 2
PY 2021
BP 790
EP 803
DI 10.1109/ISCA52012.2021.00067
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Khandelwal, S
   Walsh, A
   Shreejith, S
AF Khandelwal, Shashwat
   Walsh, Anneliese
   Shreejith, Shanker
BE IEEE
TI Quantised Neural Network Accelerators for Low-Power IDS in Automotive
   Networks
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE Controller Area Network; Intrusion Detection System; Machine Learning;
   Field Programmable Gate Arrays
ID INTRUSION DETECTION SYSTEM
AB In this paper, we explore low-power custom quantised Multi-Layer Perceptrons (MLPs) as an Intrusion Detection System (IDS) for automotive controller area network (CAN). We utilise the FINN framework from AMD/Xilinx to quantise, train and generate hardware IP of our MLP to detect denial of service (DoS) and fuzzying attacks on CAN network, using ZCU104 (XCZU7EV) FPGA as our target ECU architecture with integrated IDS capabilities. Our approach achieves significant improvements in latency (0.12 ms per-message processing latency) and inference energy consumption (0.25mJ per inference) while achieving similar classification performance as state-of-the-art approaches in the literature.
C1 [Khandelwal, Shashwat; Walsh, Anneliese; Shreejith, Shanker] Trinity Coll Dublin, Reconfigurable Comp Syst Lab, Elect & Elect Engn, Dublin, Ireland.
RP Khandelwal, S (corresponding author), Trinity Coll Dublin, Reconfigurable Comp Syst Lab, Elect & Elect Engn, Dublin, Ireland.
EM khandels@tcd.ie; walsh61@tcd.ie; shankers@tcd.ie
CR Agrawal K, 2022, IEEE T INTELL TRANSP, V23, P22596, DOI 10.1109/TITS.2022.3146024
   Cheng PZ, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020310
   Desta AK, 2020, AUSTRA TELEC N A C, P54, DOI 10.1109/ITNAC50341.2020.93151024
   Khandelwal S, 2022, I C FIELD PROG LOGIC, P425, DOI 10.1109/FPL57034.2022.00070
   Khandelwal S, 2022, IEEE INT CONF ASAP, P88, DOI 10.1109/ASAP54787.2022.00023
   Ma H., 2022, SECUR COMMUN NETW, V2022
   Miller C., 2015, BLACK HAT US, V2015, P91
   Pappalardo A., 2021, XILINX BREVITAS
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Yang L, 2022, IEEE INTERNET THINGS, V9, P616, DOI 10.1109/JIOT.2021.3084796
NR 11
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT C
AU Abraham, M
   Aithal, H
   Mohan, K
AF Abraham, Misha
   Aithal, Himajit
   Mohan, Krishnan
GP IEEE
TI Blockchain and Collaborative Intelligence based next generation Smart
   Toll Application
SO 2020 2ND CONFERENCE ON BLOCKCHAIN RESEARCH & APPLICATIONS FOR INNOVATIVE
   NETWORKS AND SERVICES (BRAINS)
DT Proceedings Paper
CT 2nd Conference on Blockchain Research and Applications for Innovative
   Networks and Services (BRAINS)
CY SEP 28-30, 2020
CL ELECTR NETWORK
DE Blockchain; IoT; Machine Economy; Real-time Smart contracts; Multi-Agent
   Systems; collaborative AI
AB The confluence of Internet of Things(IoT), Blockchain(BC) and Artificial Intelligence(AI) acts as a key accelerator for enabling Machine Economy. To be ready for future businesses these technologies needs to be adapted by extending the IoT capabilities to Economy of Things (EoT) capabilities. In this paper we focus on one such implementation experience for Smart Toll Transaction application in the domain of mobility. Our paper showcases a possible solution by leveraging negotiations, decision making, distributed learning capabilities at the devices level using AI-enabled Multi-Agent Systems and the real-time smart contracts between the Cars and Tolls using Blockchain. This solution also showcases the monetization of real time data coming from various IoT devices which are part of vehicles and infrastructure. While blockchain secures the privacy of the participants it also acts as an economic transactional layer and governance layer between the devices in the network.
C1 [Abraham, Misha; Aithal, Himajit; Mohan, Krishnan] Robert Bosch Engn & Business Solut Private Ltd, Bangalore, Karnataka, India.
RP Abraham, M (corresponding author), Robert Bosch Engn & Business Solut Private Ltd, Bangalore, Karnataka, India.
EM Abraham.Misha@in.bosch.com; Himajit.Aithal@in.bosch.com;
   Krishnan.Mohan@bosch.com
CR [Anonymous], ADEEPT 4WD SMART CAR
   [Anonymous], CROSS BORDER PAYMENT
   [Anonymous], TRANSPORT EUROPEAN U
   Debyser Ariane., REVISION EUROPEAN EL
NR 4
TC 4
Z9 4
U1 0
U2 1
PY 2020
BP 206
EP 207
DI 10.1109/brains49436.2020.9223296
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Westfall, C
AF Westfall, Catherine
TI Retooling for the Future: Launching the Advanced Light Source at
   Lawrence's Laboratory, 1980-1986
SO HISTORICAL STUDIES IN THE NATURAL SCIENCES
DT Review
DE National laboratories; Lawrence Berkeley Laboratory; Department of
   Energy; particle accelerators; synchrotron light source; David Shirley;
   David Attwood; materials science
ID UNITED-STATES; BIG SCIENCE; POLITICS; TALE
AB In the early 1980s, David Shirley tried to launch a new synchrotron light source for materials science at Lawrence Berkeley Laboratory (LBL). Building accelerators was LBL's stock-in-trade. Yet with the Advanced Light Source (ALS) nothing proceeded as in the past. Whereas nuclear and high energy physicists had been happy when funding was procured for new machines, materials scientists were irritated to learn that Shirley had brokered a deal with Presidential Science Advisor George Keyworth to fund the ALS. Materials scientists valued accelerators less because materials science had benefitted less from large-scale devices; such devices were therefore uncommon in their field. The project also faced competition and the criticism that LBL managers wanted it only to help their laboratory weather the threatening times that came with Ronald Reagan and his promise to cut the size of government ( and in fact that was a part of the rationale). The ALS also suffered because Shirley's deal was ill-suited for Washington in the 1980s. Scientists were less influential than in previous decades and a more robust federal bureaucracy controlled funding. Other ALS advocates eventually crafted a convincing scientific justification, recruited potential users, and guided the proposal through materials science reviews and the proper Washington channels. Although one-on-one deal making la Ernest Lawrence was a relic of the past, Shirley did bargain collectively with other directors, paving the way for ALS funding and a retooling of the national laboratories and materials science: in the 1990s and 2000s the largest Department of Energy accelerators were devoted to materials science, not nuclear or high-energy physics.
C1 Michigan State Univ, Lyman Briggs Coll, E Lansing, MI 48864 USA.
RP Westfall, C (corresponding author), Michigan State Univ, Lyman Briggs Coll, E Lansing, MI 48864 USA.
EM westfar2@msu.edu
CR *AAAS, R D FUND UPD R D FUN
   *AD HOC PLANN GROU, 1984, DIR SHIRL BRIEF
   ALTANELLI M, 2004, EUROPHYSICS, V35
   ANDERSON PW, 1984, COMMUNICATION   0214
   [Anonymous], 1992, CODE CODESCI SOCIA
   ATTWOOD D, 1985, SCIENCE, V228, P1265, DOI 10.1126/science.228.4705.1265
   ATTWOOD D, 1983, COMMUNICATION   1026
   ATTWOOD D, 1983, COMMUNICATION   1011
   ATTWOOD D, 1996, COMMUNICATION   0318
   ATTWOOD D, 1996, COMMUNICATION   0814
   Bensaude-Vincent B, 2001, HIST STUD PHYS BIOL, V31, P223, DOI 10.1525/hsps.2001.31.2.223
   BERKNER K, 1997, COMMUNICATION   0108
   BERKNER K, 1986, ADV LIGHT SOURCE OVE
   BERKNER K, 1985, PROGR REPORT
   BLUME M, 1985, PHYS TODAY, V38, P68, DOI 10.1063/1.881006
   BUCK AL, 1977, PHYS TODAY, V39, P110
   BUCK AL, 1982, DOEES0001, P2
   CLERY D, 1995, SCIENCE, V267, P952, DOI 10.1126/science.267.5200.952
   COLEMAN J, 1983, COMMUNICATION   0909
   CORNACCHIA M, 1997, P 1987 IEEE PART ACC, V1, P410
   CORNACCHIA M, 1997, COMMUNICATION   0109
   CREASE R, 2008, PHYS PERSPECTIVE, V10, P1
   CREASE R, 2007, PHYS PERSPECTIVE, V9, P1
   CREASE R, 2001, HSPS, V21, P41
   *DEP EN, 1983, CONSTR PROJ DAT SHEE
   *DEP EN, 1985, CONSTR PROJ DAT SHEE
   Doing P, 2004, SOC STUD SCI, V34, P299, DOI 10.1177/0306312704043677
   EASTMAN DE, ADV MAT RES, P336
   EISENBERGER P, 1983, COMMUNICATION   1114
   *ERAB, 1984, REV NAT RES COUNC RE
   *ERAB, 1984, REV
   GRUNDER H, 1995, COMMUNICATION   0303
   HALBACH K, 1983, J PHYSIQUE C, V1, P211
   HALBACH K, 1996, COMMUNICATION   0821
   HEILBRON John, 1989, LAWRENCE HIS LAB HIS, VI
   HODDESON L, FERMILAB PHYS FRONTI
   HOLL J, 1997, ARGONNE NATL LAB 194, P401
   HURLEY C, 1983, COMMUNICATION   0511
   IANNIELLO L, 1996, COMMUNICATION   118
   IANNIELLO L, 1983, COMMUNICATION   0928
   IANNIELLO L, 1996, COMMUNICATION   0424
   IANNIELLO L, 1996, COMMUNICATION   1118
   JACKSON A, 20329 LBL
   JOHNSON H, 1987, ADV MAT RES, P321
   JOHNSON R, 1997, COMMUNICATION   0815
   JOHNSON R, 1996, COMMUNICATION   0820
   JOHNSON R, 1996, COMMUNICATION   0815
   JOHNSON R, 1985, COMMUNICATION   1213
   Kevles D, 1997, HIST STUD PHYS BIOL, V27, P269, DOI 10.2307/27757780
   KNOTEK M, 1996, COMMUNICATION   1219
   KREBS M, 1984, COMMUNICATION   0201
   KREBS M, 1996, COMMUNICATION   1120
   KREBS M, 1984, ALS FACT SHEET
   KREBS M, 1985, COMMUNICATION   0812
   *L BERK LAB, 1985, PRES BUDG PROP ADV L
   *L BERK LAB, 1985, REP
   *L BERK LAB, 1985, REP WORKSH ADV SOFT
   *L BERK LAB, 1983, FIN REP ALS TECHN RE
   LANDER G, 2006, COMMUNICATION   0122
   Lawler A, 1998, SCIENCE, V279, P470, DOI 10.1126/science.279.5350.470
   *LAWR BERK LAB, 1983, US PART DEV ALS BEAM
   *LBNL, 1999, CURRENT         0312, P7
   LEHMAN D, 2001, COMMUNICATION   0124
   LEHMAN D, 2001, COMMUNICATION   0129
   LIVINGSTON MS, 1969, PART ACCEL, P44
   LUBKIN G, 1983, PHYS TODAY, V36, P46
   LUBKIN GB, 1983, PHYS TODAY, V36, P21
   LUBKIN GB, 1983, PHYS TODAY, V36, P17, DOI 10.1063/1.2915566
   Margaritondo G, 2008, PHYS TODAY, V61, P37, DOI 10.1063/1.2930734
   MARX J, 1986, COMMUNICATION   0107
   MOTZ H, 1951, J APPL PHYS, V22, P527, DOI 10.1063/1.1700002
   MOTZ H, 1953, J APPL PHYS, V24, P826, DOI 10.1063/1.1721389
   NARATH A, 1983, REPORT AD HOC PANEL
   NARATH A, 1983, COMMUNICATION   0618
   *NCAM, 1983, REP AD HOC PAN REV L
   NORMAN C, 1983, SCIENCE, V222, P529
   *OSTP, 1983, OSTP PRES
   *OSTP, 1983, REP WHIT HOUS SCI CO
   Reagan Ronald, 1986, STATE UNION ADDRESS
   Riordan M, 2001, HIST STUD PHYS BIOL, V32, P125, DOI 10.1525/hsps.2001.32.1.125
   ROBINSON AL, 1981, SCIENCE, V211, P259, DOI 10.1126/science.211.4479.259
   SEITZ F, 1984, COMMUNICATION   0217
   SHIRLEY D, 1982, NCAM NATL RESOURCE
   SHIRLEY D, 1984, COMMUNICATION   0514
   SHIRLEY D, 1983, COMMUNICATION   0930
   SHIRLEY D, 1984, COMMUNICATION   0914
   SHIRLEY D, 1996, COMMUNICATION   0827
   SHIRLEY D, 1983, COMMUNICATION   1223
   SHIRLEY D, 1984, LOU IANNIELLO
   SHIRLEY D, 1983, COMMUNICATION   0315
   SHIRLEY D, COMMUNICATION   0315
   SHIRLEY D, 1986, CURRENTS        0207
   SHIRLEY D, 1996, E COMMUNICATION 0827
   SHIRLEY D, 1997, E COMMUNICATION 0815
   SHIRLEY D, 1986, GO AHEAD
   SHIRLEY D, 1984, COMMUNICATION   0820
   SLOAM PR, 2000, CONTROLLING OUR DEST
   SMITH RW, 1989, SPACE TELESCOPE STUD, P385
   STEHLI F, 1985, COMMUNICATION   0130
   SWEET W, 1987, PHYS TODAY, V40, P71
   TRIVELPIECE A, 2005, HIST PHYS NEWSLETTER, V9, P14
   TRIVELPIECE A, 1983, COMMUNICATIOLN  0331
   TRIVELPIECE A, 2005, E COMMUNICATION 1006
   TRIVELPIECE AW, 1983, SUBCOMMITTEE ENERGY
   Westfall C, 2003, ISIS, V94, P30, DOI 10.1086/376098
   Westfall C, 2002, HIST STUD PHYS BIOL, V32, P369, DOI 10.1525/hsps.2002.32.2.369
   WESTWICK P, 2003, NATL LABS SCI AM SYS, P287
   YARRIS L, 1995, LBNL CURRENTS, P1
   1984, PLANNING STUDY ADV N
   1983, NCAM MONTHLY PROGR R
   1986, REPORT DOE REV COMMI
   1984, PLANNING STUDY
   1985, DAVID SHIRLEY NOTES
NR 113
TC 14
Z9 14
U1 0
U2 4
PD FAL
PY 2008
VL 38
IS 4
BP 569
EP 609
DI 10.1525/hsns.2008.38.4.569
WC History & Philosophy Of Science
DA 2023-11-11
ER

PT C
AU Erdeljan, A
   Vukobratovic, B
   Struharik, R
AF Erdeljan, Andrea
   Vukobratovic, Bogdan
   Struharik, Rastislav
GP IEEE
TI IP Core for Efficient Zero-Run Length Compression of CNN Feature Maps
SO 2017 25TH TELECOMMUNICATION FORUM (TELFOR)
DT Proceedings Paper
CT 25th Telecommunication Forum (TELFOR)
CY NOV 21-22, 2017
CL Belgrade, SERBIA
DE Convolutional Neural Networks; FPGA; computer vision; zero run-length
   encoding; Zynq-7000; SystemVerilog
AB Convolutional Neural Networks (CNNs) are becoming a fundamental tool for machine learning. High performance and energy efficiency are of great importance for deployments of CNNs in many embedded applications. Energy consumption during CNN processing is dominated by memory access and since large networks do not fit on on-chip storage, they require expensive DRAM access. This paper introduces an universal Output Stream Manager (OSM) which can be used to compress and format data coming from a CNN accelerator and reduce external memory access. The OSM exploits the sparsity of data and implements two Zero-Run Length encoding algorithms and can be easily reconfigured to optimize usage for different CNN layers.
C1 [Erdeljan, Andrea; Struharik, Rastislav] Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
   [Vukobratovic, Bogdan] Frobas GmbH, Gebruder Eicher Ring 45, Forstern, Germany.
RP Erdeljan, A (corresponding author), Univ Novi Sad, Fac Tech Sci, Trg Dositeja Obradovica 6, Novi Sad 21000, Serbia.
EM andrea.erdeljan@uns.ac.rs; bogdan.vukobratovic@gmail.com;
   rasti@uns.ac.rs
CR [Anonymous], 2016, FPGA
   [Anonymous], 2016, FPGA
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Han S., 2015, ARXIV151000149
   Horowitz M., ENERGY TABLE 45NM PR
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu Z., 2017, TRETS, V10
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Struharik R., 2017, 2017 IEEE E W DES TE
   Struharik R., 2017, INTERNAL REPORT
   Zisserman A., 2014, 14091556 ARXIV
NR 12
TC 1
Z9 1
U1 0
U2 0
PY 2017
BP 510
EP 513
WC Telecommunications
DA 2023-11-11
ER

PT J
AU Carrazza, S
   Cruz-Martinez, JM
   Rossi, M
AF Carrazza, Stefano
   Cruz-Martinez, Juan M.
   Rossi, Marco
TI PDFFlow: Parton distribution functions on GPU
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Parton distributions; Graphs; Machine learning; Hardware acceleration
AB We present PDFFlow, a new software for fast evaluation of parton distribution functions (PDFs) designed for platforms with hardware accelerators. PDFs are essential for the calculation of particle physics observables through Monte Carlo simulation techniques. The evaluation of a generic set of PDFs for quarks and gluon at a given momentum fraction and energy scale requires the implementation of interpolation algorithms as introduced for the first time by the LHAPDF project. PDFFlow extends and implements these interpolation algorithms using Google's Tensor Flow library providing the capabilities to perform PDF evaluations taking fully advantage of multi-threading CPU and GPU setups. We benchmark the performance of this library on multiple scenarios relevant for the particle physics community.
C1 [Carrazza, Stefano; Cruz-Martinez, Juan M.; Rossi, Marco] Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.
   [Carrazza, Stefano; Cruz-Martinez, Juan M.; Rossi, Marco] Ist Nazl Fis Nucl, Sez One Milano, Via Celoria 16, I-20133 Milan, Italy.
   [Rossi, Marco] CERN Openlab, CH-1211 Geneva 23, Switzerland.
RP Carrazza, S (corresponding author), Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.; Carrazza, S (corresponding author), Ist Nazl Fis Nucl, Sez One Milano, Via Celoria 16, I-20133 Milan, Italy.
EM stefano.carrazza@unimi.it
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alwall J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2014)079
   Amoroso S., LHC, V4, P2020
   Ball RD, 2017, EUR PHYS J C, V77, DOI 10.1140/epjc/s10052-017-5199-5
   Bertone V, 2017, COMPUT PHYS COMMUN, V212, P205, DOI 10.1016/j.cpc.2016.10.006
   Buckley A., 2019, 19 INT WORKSH ADV CO
   Buckley A, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3318-8
   Campbell J, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2019)034
   Carrazza S., 2019, INT C STR INT PHOT 2
   Carrazza S, 2020, COMPUT PHYS COMMUN, V254, DOI 10.1016/j.cpc.2020.107376
   Carrazza S, 2019, EUR PHYS J C, V79, DOI 10.1140/epjc/s10052-019-7197-2
   Cruz-Martinez J, 2018, PHYS LETT B, V781, P672, DOI 10.1016/j.physletb.2018.04.046
   Cruz-Martinez J., 2020, N3PDFVEGASFLOW VEGAS, DOI [10.5281/zenodo.3691926, DOI 10.5281/ZENODO.3691926]
   Cruz-Martinez J., 2020, N3PDF PDFFLOW, DOI [10.5281/zenodo.3964191, DOI 10.5281/ZENODO.3964191]
   Currie J, 2013, J HIGH ENERGY PHYS, DOI 10.1007/JHEP04(2013)066
   Gehrmann T., 2018, RADCOR2017 POS, DOI [10.22323/1.290.0074, DOI 10.22323/1.290.0074]
   Gehrmann-De Ridder A, 2005, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2005/09/056
   Harland-Lang LA, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3397-6
   Hou T.-J., 2019, ARXIV190811238
   Whalley M.R., 2005, ARXIVHEPPH0508110
NR 20
TC 5
Z9 5
U1 0
U2 1
PD JUL
PY 2021
VL 264
AR 107995
DI 10.1016/j.cpc.2021.107995
EA APR 2021
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
DA 2023-11-11
ER

PT J
AU Umesh, S
   Mittal, S
AF Umesh, Sumanth
   Mittal, Sparsh
TI A survey of spintronic architectures for processing-in-memory and neural
   networks
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Review; Spin transfer torque RAM; Spin orbit torque; Domain wall memory;
   Processing-in-memory; Machine learning; Neural networks
ID DOMAIN-WALL MOTION; SPIN; CIRCUIT; STT
AB The rising overheads of data-movement and limitations of general-purpose processing architectures have led to a huge surge in the interest in "processing-in-memory" (PIM) approach and "neural networks" (NN) architectures. Spintronic memories facilitate efficient implementation of PIM approach and NN accelerators, and offer several advantages over conventional memories. In this paper, we present a survey of spintronic-architectures for PIM and NNs. We organize the works based on main attributes to underscore their similarities and differences. This paper will be useful for researchers in the area of artificial intelligence, hardware architecture, chip design and memory system.
C1 [Umesh, Sumanth] IIT Jodhpur, Jodhpur, Rajasthan, India.
   [Umesh, Sumanth; Mittal, Sparsh] IIT Hyderabad, C-113-A Sangareddy, Hyderabad 502285, Telangana, India.
RP Mittal, S (corresponding author), IIT Hyderabad, C-113-A Sangareddy, Hyderabad 502285, Telangana, India.
EM sumanth.2@iitj.ac.in; sparsh@iith.ac.in
CR Ahmed I, 2017, IEEE J EXPLOR SOLID-, V3, P74, DOI 10.1109/JXCDC.2017.2762699
   An Q, 2017, IEEE INT NEW CIRC, P317, DOI 10.1109/NEWCAS.2017.8010169
   An Q, 2015, IEEE INT SYMP NANO, P163, DOI 10.1109/NANOARCH.2015.7180606
   Angizi S., 2017, IEEE T COMPUT AIDED
   Angizi S, 2018, ASIA S PACIF DES AUT, P111, DOI 10.1109/ASPDAC.2018.8297291
   Angizi S, 2017, INT SYM QUAL ELECT, P391, DOI 10.1109/ISQED.2017.7918347
   [Anonymous], 2014, NANOSCALE
   [Anonymous], ELECT LETT
   [Anonymous], EL DEV M IEDM 2012 I
   [Anonymous], 2015, 2015 IEEE 13 INT NEW
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Cai H, 2016, IEEE INT SYMP NANO, P203, DOI 10.1145/2950067.2950101
   Chang L, 2017, IEEE INT SYMP NANO, P95, DOI 10.1109/NANOARCH.2017.8053713
   Chen XZ, 2016, J SYST ARCHITECT, V68, P51, DOI 10.1016/j.sysarc.2016.05.004
   Chen X, 2018, NANOSCALE, V10, P6139, DOI [10.1039/c7nr09722k, 10.1039/C7NR09722K]
   Chung J, 2016, I SYMPOS LOW POWER E, P332, DOI 10.1145/2934583.2934602
   Deb S, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P281, DOI 10.1109/SAMOS.2016.7818359
   Deng E., 2015, IEEE T MAGN, V51, P1
   Fan D., 2017, VLSI ISVLSI 2017 IEE, P683
   Fan D, 2017, PR IEEE COMP DESIGN, P609, DOI 10.1109/ICCD.2017.107
   Fan DL, 2017, MIDWEST SYMP CIRCUIT, P1109, DOI 10.1109/MWSCAS.2017.8053122
   Fan DL, 2015, IEEE T NANOTECHNOL, V14, P1013, DOI 10.1109/TNANO.2015.2437902
   Guo Q., 2013, P 40 ANN INT S COMPU, V41, P189, DOI [10.1145/2508148.2485939, DOI 10.1145/2485922.2485939]
   Hanyu T., 2014, EL DEV M IEDM 2014 I, P28
   Hanyu T, 2015, DES AUT TEST EUROPE, P1006
   He ZZ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P83, DOI 10.1145/3060403.3060460
   He ZZ, 2017, PR IEEE COMP DESIGN, P439, DOI 10.1109/ICCD.2017.78
   Huang KJ, 2016, IEEE T VLSI SYST, V24, P2861, DOI 10.1109/TVLSI.2016.2523124
   Huang KJ, 2015, IEEE T CIRCUITS-I, V62, P1109, DOI 10.1109/TCSI.2015.2388833
   Huang YQ, 2017, NANOTECHNOLOGY, V28, DOI 10.1088/1361-6528/aa5838
   Jain S, 2018, DES AUT TEST EUROPE, P1640, DOI 10.23919/DATE.2018.8342277
   Jaiswal A, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-23886-2
   Kang W, 2017, IEEE T MAGN, V53, DOI 10.1109/TMAG.2017.2703863
   Kang W, 2016, P IEEE, V104, P2040, DOI 10.1109/JPROC.2016.2591578
   Kang W, 2017, INT C INTEL HUM MACH, P290, DOI 10.1109/IHMSC.2017.177
   Kumar D., 2013, ELECTRON J DIFFER EQ, V2013, P1
   Lent CS, 2006, NANOTECHNOLOGY, V17, P4240, DOI 10.1088/0957-4484/17/16/040
   Li S, 2017, NANOTECHNOLOGY, V28, DOI 10.1088/1361-6528/aa7af5
   Lokesh B., 2013, IND C INDICON 2013 A, P1
   Luo T, 2016, ASIA S PACIF DES AUT, P286, DOI 10.1109/ASPDAC.2016.7428025
   Mahmoudi H, 2014, INT CONF ULTI INTEGR, P117, DOI 10.1109/ULIS.2014.6813912
   Mahmoudi H, 2013, PROCEEDINGS OF THE 2013 IEEE/ACM INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURES (NANOARCH), P26, DOI 10.1109/NanoArch.2013.6623033
   Matsunaga S, 2009, DES AUT TEST EUROPE, P433
   Mittal Sparsh, 2017, Journal of Low Power Electronics and Applications, V7, DOI 10.3390/jlpea7030023
   Mittal S., 2016, ACM J EMERG TECHNOL
   Mittal S., 2018, J HARDW SYST SECUR
   Mittal S., 2016, ACM COMPUT SURV
   Mittal S, 2019, J SYST ARCHITECT, V97, P373, DOI 10.1016/j.sysarc.2018.11.001
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Mittal S, 2018, J SYST ARCHITECT, V91, P11, DOI 10.1016/j.sysarc.2018.09.004
   Mittal S, 2017, IEEE COMPUT ARCHIT L, V16, P94, DOI 10.1109/LCA.2016.2645207
   Mittal S, 2017, COMPUTERS, V6, DOI 10.3390/computers6010008
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mittal S, 2015, IEEE T PARALL DISTR, V26, P1524, DOI 10.1109/TPDS.2014.2324563
   Natsui M, 2015, IEEE J SOLID-ST CIRC, V50, P476, DOI 10.1109/JSSC.2014.2362853
   Parveen F., 2017, PROC IEEEACM INT S L, P1
   Parveen F, 2018, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2018.8297350
   Patil S. R., 2008, P ACM INT C COMP FRO, P171
   Peng SL, 2014, ELEC COMP C, P1, DOI 10.1109/ECTC.2014.6897258
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Ren FB, 2010, IEEE T ELECTRON DEV, V57, P1023, DOI 10.1109/TED.2010.2043389
   Roohi A, 2017, IEEE T COMPUT AID D, V36, P2134, DOI 10.1109/TCAD.2017.2661800
   Roohi A, 2016, IEEE T MAGN, V52, DOI 10.1109/TMAG.2016.2540600
   Roy K, 2013, ICCAD-IEEE ACM INT, P576, DOI 10.1109/ICCAD.2013.6691174
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Sengupta A, 2016, IEEE T CIRCUITS-I, V63, P2267, DOI 10.1109/TCSI.2016.2615312
   Sharad M, 2012, IEEE T NANOTECHNOL, V11, P843, DOI 10.1109/TNANO.2012.2202125
   Tian H, 2013, CURR APPL PHYS, V13, P1, DOI 10.1016/j.cap.2012.05.045
   Trinh HP, 2012, ELECTRON LETT, V48, P1049, DOI 10.1049/el.2012.1577
   Vincent AF, 2015, IEEE T BIOMED CIRC S, V9, P166, DOI 10.1109/TBCAS.2015.2414423
   Wang LZ, 2018, IEEE ELECTR DEVICE L, V39, P440, DOI 10.1109/LED.2018.2791510
   Wang MX, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03140-z
   Wang Y., 2014, P C DES AUT TEST EUR, P183
   Wang Y, 2016, IEEE INT SYMP NANO, P123, DOI 10.1145/2950067.2950108
   Wang YH, 2016, IEEE T INF FOREN SEC, V11, P2426, DOI 10.1109/TIFS.2016.2576903
   Wang ZH, 2018, IEEE ELECTR DEVICE L, V39, P343, DOI 10.1109/LED.2018.2795039
   Yao XF, 2012, IEEE T NANOTECHNOL, V11, P120, DOI 10.1109/TNANO.2011.2158848
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
   Zhang H, 2017, IEEE T ELECTRON DEV, V64, P4295, DOI 10.1109/TED.2017.2726544
   Zhang XC, 2015, SCI REP-UK, V5, DOI 10.1038/srep09400
NR 82
TC 35
Z9 35
U1 1
U2 17
PD AUG
PY 2019
VL 97
BP 349
EP 372
DI 10.1016/j.sysarc.2018.11.005
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Shalf, J
AF Shalf, John
GP IEEE
TI HPC Interconnects at the End of Moore's Law
SO 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
DT Proceedings Paper
CT Optical Fiber Communications Conference and Exhibition (OFC)
CY MAR 03-07, 2019
CL San Diego, CA
AB The tapering of lithography advances that have been associated with Moore's Law will substantially change requirements for future interconnect architectures for large-scale datacenters and HPC systems. Architectural specialization is creating new datacenter requirements such as emerging accelerator technologies for machine learning workloads and rack disaggregation strategies will push the limits of current interconnect technologies. Whereas photonic technologies are often sold on the basis of higher bandwidth and energy efficiency (e.g. lower picojoules per bit), these emerging workloads and technology trends will shift the emphasis to other metrics such as bandwidth density (as opposed to bandwidth alone) and reduced latency, and performance consistency. Such metrics cannot be accomplished with device improvements alone, but require a systems view of photonics in datacenters.
C1 [Shalf, John] Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
RP Shalf, J (corresponding author), Lawrence Berkeley Natl Lab, 1 Cyclotron Rd, Berkeley, CA 94720 USA.
EM jshalf@lbl.gov
CR [Anonymous], ELECTRONICS
   [Anonymous], 2005, P ACMIEEE SC2005 C H
   Jouppi N. P., 2017, ISCA 17
   Lavin A., 2015, FAST ALGORITHMS CONV, Vabs/1509.09308
   Putnam A., 2017, GLSVLSI 17
   Shalf JM, 2015, COMPUTER, V48, P14, DOI 10.1109/MC.2015.374
   Wan YT, 2018, PHOTONICS RES, V6, P776, DOI 10.1364/PRJ.6.000776
   Wen K, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P166, DOI 10.1109/SC.2016.14
NR 8
TC 15
Z9 15
U1 0
U2 3
PY 2019
WC Engineering, Electrical & Electronic; Optics; Telecommunications
DA 2023-11-11
ER

PT J
AU Hu, RL
   Pierce, D
   Shafi, Y
   Boral, A
   Anisimov, V
   Nevo, S
   Chen, YF
AF Hu, R. Lily
   Pierce, Damien
   Shafi, Yusef
   Boral, Anudhyan
   Anisimov, Vladimir
   Nevo, Sella
   Chen, Yi-fan
TI Accelerating physics simulations with tensor processing units: An
   inundation modeling example
SO INTERNATIONAL JOURNAL OF HIGH PERFORMANCE COMPUTING APPLICATIONS
DT Article
DE CFD; computational fluid dynamics; distributed computing; flood
   forecasting; flood modeling; inundation modeling; large scale
   simulations; parallel computing; tensor processing units
AB Recent advancements in hardware accelerators such as Tensor Processing Units (TPUs) speed up computation time relative to Central Processing Units (CPUs) not only for machine learning but, as demonstrated here, also for scientific modeling and computer simulations. To study TPU hardware for distributed scientific computing, we solve partial differential equations (PDEs) for the physics simulation of fluids to model riverine floods. We demonstrate that TPUs achieve a two orders of magnitude speedup over CPUs. Running physics simulations on TPUs is publicly accessible via the Google Cloud Platform, and we release a Python interactive notebook version of the simulation.
C1 [Hu, R. Lily; Pierce, Damien; Shafi, Yusef; Boral, Anudhyan; Anisimov, Vladimir; Nevo, Sella; Chen, Yi-fan] Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
RP Hu, RL; Pierce, D (corresponding author), Google Res, 1600 Amphitheatre Pkwy, Mountain View, CA 94043 USA.
EM rlhu@google.com; dmpierce@google.com
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Afshari S, 2018, J HYDROL, V556, P539, DOI 10.1016/j.jhydrol.2017.11.036
   Akan A.O., 2011, OPEN CHANNEL HYDRAUL
   [Anonymous], 2019, SUSTAIN DEV GOALS RE
   Bates PD, 2010, J HYDROL, V387, P33, DOI 10.1016/j.jhydrol.2010.03.027
   Bates PD, 2000, J HYDROL, V236, P54, DOI 10.1016/S0022-1694(00)00278-X
   Belletti F., 2019, P 2020 SIAM C PARALL
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   CRED, 2017, NAT DIS 2017
   de Almeida GAM, 2012, WATER RESOUR RES, V48, DOI 10.1029/2011WR011570
   Guennebaud G., 2010, EIGEN V3
   Jonkman SN, 2005, NAT HAZARDS, V34, P151, DOI 10.1007/s11069-004-8891-3
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kundzewicz ZW, 2014, HYDROLOG SCI J, V59, P1, DOI 10.1080/02626667.2013.857411
   Lewis JM., 2019, PEAK STREAMFLOW STAG
   Lu T., 2020, PREPRINT
   LU T, 2021, 18 INT S BIOMED IMAG
   Lu TJ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286192
   Meesuk V, 2015, ADV WATER RESOUR, V75, P105, DOI 10.1016/j.advwatres.2014.11.008
   Microway, DET SPEC CAS LAK SP
   Nevo S., 2019, ARXIV PREPRINT ARXIV
   Pilon P. J., 2002, GUIDELINES REDUCING
   Rogers D, 2010, GLOBAL ASSESSMENT RE
   Shastry A, 2019, FRONT EARTH SC-SWITZ, V6, DOI 10.3389/feart.2018.00243
   Smith B. F., 1997, PARALLEL NUMERICAL A, P225, DOI [DOI 10.1007/978-94-011-5412-3_8, DOI 10.1007/978-94-011-5412-38]
   Teng J, 2017, ENVIRON MODELL SOFTW, V90, P201, DOI 10.1016/j.envsoft.2017.01.006
   UNISDR and Centre for Research on the Epidemiology of Disasters, 2015, HUM COST WEATH REL D
   USGS, 2017, 3DEP DOWNL DIG EL MO
   Vreugdenhil C.B., 1994, NUMERICAL METHODS SH
   WHO, 2014, GLOB REP DROWN PREV, DOI DOI 10.3390/IJERPH140808755
   Yang K, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356149
   Zhang JQ, 2018, J AM WATER RESOUR AS, V54, P820, DOI 10.1111/1752-1688.12623
NR 32
TC 2
Z9 2
U1 0
U2 4
PD JUL
PY 2022
VL 36
IS 4
BP 510
EP 523
AR 10943420221102873
DI 10.1177/10943420221102873
EA JUN 2022
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Minarik, M
   Sekanina, L
AF Minarik, Milos
   Sekanina, Lukas
BE McDermott, J
   Castelli, M
   Sekanina, L
   Haasdijk, E
   GarciaSanchez, P
TI On Evolutionary Approximation of Sigmoid Function for HW/SW Embedded
   Systems
SO GENETIC PROGRAMMING, EUROGP 2017
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 20th European Conference on Genetic Programming (EuroGP)
CY APR 19-21, 2017
CL Amsterdam, NETHERLANDS
DE Sigmoid; Linear genetic programming; HW/SW co-design
ID HARDWARE-SOFTWARE COSYNTHESIS
AB Providing machine learning capabilities on low cost electronic devices is a challenging goal especially in the context of the Internet of Things paradigm. In order to deliver high performance machine intelligence on low power devices, suitable hardware accelerators have to be introduced. In this paper, we developed a method enabling to evolve a hardware implementation together with a corresponding software controller for key components of smart embedded systems. The proposed approach is based on a multi-objective design space exploration conducted by means of extended linear genetic programming. The approach was evaluated in the task of approximate sigmoid function design which is an important component of hardware implementations of neural networks. During these experiments, we automatically re-discovered some approximate sigmoid functions known from the literature. The method was implemented as an extension of an existing platform supporting concurrent evolution of hardware and software of embedded systems.
C1 [Minarik, Milos; Sekanina, Lukas] Brno Univ Technol, Ctr Excellence IT4Innovat, Fac Informat Technol, Brno, Czech Republic.
RP Minarik, M (corresponding author), Brno Univ Technol, Ctr Excellence IT4Innovat, Fac Informat Technol, Brno, Czech Republic.
EM iminarikm@fit.vutbr.cz; sekanina@fit.vutbr.cz
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   [Anonymous], 2007, LINEAR GENETIC PROGR
   [Anonymous], 6 TURK AI NN S TAINN
   Cheang SM, 2006, EVOL COMPUT, V14, P129, DOI 10.1162/evco.2006.14.2.129
   Deniziak S, 2008, LECT NOTES COMPUT SC, V5216, P83
   Dick RP, 1998, IEEE T COMPUT AID D, V17, P920, DOI 10.1109/43.728914
   Koza JR, 1994, GENETIC PROGRAMMING
   Leung KS, 2003, LECT NOTES COMPUT SC, V2610, P107
   MCCLUSKEY EJ, 1956, BELL SYST TECH J, V35, P1417, DOI 10.1002/j.1538-7305.1956.tb03835.x
   Minarik Milos, 2014, Genetic Programming. 17th European Conference (EuroGP 2014). Revised Selected Papers: LNCS 8599, P112, DOI 10.1007/978-3-662-44303-3_10
   Minarik M, 2013, PROCEEDINGS OF THE 2013 IEEE INTERNATIONAL CONFERENCE ON EVOLVABLE SYSTEMS (ICES), P43, DOI 10.1109/ICES.2013.6613281
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Parhami B., 2010, COMPUTER ARITHMETIC
   Poli R, 1999, FROM ANIM ANIMAT, P301
   Shang L, 2007, IEEE T COMPUT AID D, V26, P508, DOI 10.1109/TCAD.2006.883909
   Tempesti G, 2006, AHS 2006: FIRST NASA/ESA CONFERENCE ON ADAPTIVE HARDWARE AND SYSTEMS, PROCEEDINGS, P129
   Tommiska MT, 2003, IEE P-COMPUT DIG T, V150, P403, DOI 10.1049/ip-cdt:20030965
   Zhang M, 1996, IEEE T COMPUT, V45, P1045, DOI 10.1109/12.537127
NR 18
TC 0
Z9 0
U1 0
U2 1
PY 2017
VL 10196
BP 343
EP 358
DI 10.1007/978-3-319-55696-3_22
WC Computer Science, Artificial Intelligence; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Han, W
   Heo, J
   Kim, J
   Lim, S
   Kim, JY
AF Han, Wontak
   Heo, Jaehoon
   Kim, Junsoo
   Lim, Sukbin
   Kim, Joo-Young
TI Design of Processing-in-Memory With Triple Computational Path and
   Sparsity Handling for Energy-Efficient DNN Training
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Training; Computational modeling; Computer architecture; Deep learning;
   Circuits and systems; Power demand; Neurons; Accelerator architecture;
   machine learning; processing-in-memory architecture; bit-serial
   operation; inference; training; sparsity handling; SRAM;
   energy-efficient architecture
ID DEEP NEURAL-NETWORKS; SRAM; ACCELERATOR; MACRO
AB As machine learning (ML) and artificial intelligence (AI) have become mainstream technologies, many accelerators have been proposed to cope with their computation kernels. However, they access the external memory frequently due to the large size of deep neural network model, suffering from the von Neumann bottleneck. Moreover, as privacy issue is becoming more critical, on-device training is emerging as its solution. However, on-device training is challenging because it should perform the training under a limited power budget, which requires a lot more computations and memory accesses than the inference. In this paper, we present an energy-efficient processing-in-memory (PIM) architecture supporting end-to-end on-device training named T-PIM. Its macro design includes an 8T-SRAM cell-based PIM block to compute in-memory AND operation and three computational datapaths for end-to-end training. Each of three computational paths integrates arithmetic units for forward propagation, backward propagation, and gradient calculation and weight update, respectively, allowing the weight data stored in the memory stationary. T-PIM also supports variable bit precision to cover various ML scenarios. It can use fully variable input bit precision and 2-bit, 4-bit, 8-bit, and 16-bit weight bit precision for the forward propagation and the same input bit precision and 16-bit weight bit precision for the backward propagation. In addition, T-PIM implements sparsity handling schemes that skip the computation for input data and turn off the arithmetic units for weight data to reduce both unnecessary computations and leakage power. Finally, we fabricate the T-PIM chip on a 5.04mm(2) die in a 28-nm CMOS logic process. It operates at 50-280MHz with the supply voltage of 0.75-1.05V, dissipating 5.25-51.23mW power in inference and 6.10-37.75mW in training. As a result, it achieves 17.90-161.08TOPS/W energy efficiency for the inference of 1-bit activation and 2-bit weight data, and 0.84-7.59TOPS/W for the training of 8-bit activation/error and 16-bit weight data. In conclusion, T-PIM is the first PIM chip that supports end-to-end training, demonstrating 2.02 times performance improvement over the latest PIM that partially supports training.
C1 [Han, Wontak; Heo, Jaehoon; Kim, Junsoo; Lim, Sukbin; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea.
RP Han, W; Kim, JY (corresponding author), Korea Adv Inst Sci & Technol, Dept Elect Engn, Daejeon 34141, South Korea.
EM 11tak@kaist.ac.kr; jooyoung1203@kaist.ac.kr
CR Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Choi S, 2020, IEEE J SOLID-ST CIRC, V55, P2691, DOI 10.1109/JSSC.2020.3005786
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Jiang HW, 2020, IEEE T COMPUT, V69, P944, DOI 10.1109/TC.2020.2980533
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim JH, 2021, IEEE J SOLID-ST CIRC, V56, P1093, DOI 10.1109/JSSC.2020.3039206
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Lawrence S, 1997, IEEE T NEURAL NETWOR, V8, P98, DOI 10.1109/72.554195
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2019, IEEE I CONF COMP VIS, P10142, DOI 10.1109/ICCV.2019.01024
   Lee J, 2022, IEEE MICRO, V42, P99, DOI 10.1109/MM.2021.3096236
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   LING H, 1981, IBM J RES DEV, V25, P156, DOI 10.1147/rd.252.0156
   Qin XL, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON PROGNOSTICS AND HEALTH MANAGEMENT (ICPHM), P1, DOI [10.1109/ATNAC.2017.8215431, 10.1109/ICPHM.2017.7998297]
   Ruck D. W., 1990, J NEURAL NETWORK COM, V2, P40
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Sünderhauf N, 2018, INT J ROBOT RES, V37, P405, DOI 10.1177/0278364918770733
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yuan Z, 2020, IEEE J SOLID-ST CIRC, V55, P465, DOI 10.1109/JSSC.2019.2946771
   Yue JS, 2021, ISSCC DIG TECH PAP I, V64, P238, DOI 10.1109/ISSCC42613.2021.9365958
   Yue JS, 2020, ISSCC DIG TECH PAP I, P234, DOI [10.1109/ECICE50847.2020.9301937, 10.1109/ISSCC19947.2020.9062958]
   Zhang X, 2020, P IEEECVF C COMPUTER, P2330
NR 37
TC 1
Z9 1
U1 1
U2 5
PD JUN
PY 2022
VL 12
IS 2
BP 354
EP 366
DI 10.1109/JETCAS.2022.3168852
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kunas, CA
   Serpa, MS
   Bez, JL
   Padoin, EL
   Navaux, POA
AF Kunas, Cristiano A.
   Serpa, Matheus S.
   Bez, Jean Luca
   Padoin, Edson L.
   Navaux, Philippe O. A.
GP IEEE COMP SOC
TI Offloading the Training of an I/O Access Pattern Detector to the Cloud
SO 2021 IEEE 33RD INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE AND HIGH
   PERFORMANCE COMPUTING WORKSHOPS (SBAC-PADW 2021)
DT Proceedings Paper
CT 33rd IEEE International Symposium on Computer Architecture and High
   Performance Computing (SBAC-PAD)
CY OCT 26-29, 2021
CL ELECTR NETWORK
DE high-performance computing; access pattern detection; classification;
   TPU; cloud
ID NORMALITY
AB I/O operations are a bottleneck for numerous applications, so optimizing the performance of these operations is of paramount importance. Many techniques explore and apply optimizations to different layers of the I/O stack to improve performance. The difficulty that arises is that the workload changes constantly. So detecting access patterns correctly, at run-time, becomes essential for systems that seek to self-adjust their parameters. Furthermore, the I/O pattern detection techniques should represent minimal overhead and should be able to perform detection as quickly as possible. This paper approaches a machine learning technique for detecting the I/O access patterns and proposes offloading the local training workload to the cloud using a TPU accelerator. Such an approach does not interfere with classifier accuracy (reaching up to 99% accuracy). Still, it allows the training to be asynchronous, enabling the local machine to allocate its computing resources to scientific applications while the model is trained or updated in the cloud.
C1 [Kunas, Cristiano A.; Serpa, Matheus S.; Navaux, Philippe O. A.] Fed Univ Rio Grande do Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
   [Padoin, Edson L.] Reg Univ Northwestern Rio Grande do Sul UNIJUI, Ijui, Brazil.
   [Bez, Jean Luca] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
RP Kunas, CA (corresponding author), Fed Univ Rio Grande do Sul UFRGS, Inst Informat, Porto Alegre, RS, Brazil.
EM cakunas@inf.ufrgs.br; msserpa@inf.ufrgs.br; jlbez@lbl.gov;
   padoin@unijui.edu.br; navaux@inf.ufrgs.br
CR Abadi M., 2016, ARXIV160304467
   [Anonymous], 2014, P 12 USENIX C FILE S
   Bez JL, 2019, INT SYM COMP ARCHIT, P80, DOI 10.1109/SBAC-PAD.2019.00025
   Boito FZ, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3152891
   Boito FZ, 2016, CONCURR COMP-PRACT E, V28, P2457, DOI 10.1002/cpe.3606
   BOX GEP, 1964, J ROY STAT SOC B, V26, P211, DOI 10.1111/j.2517-6161.1964.tb00553.x
   Carns PH, 2000, USENIX ASSOCIATION PROCEEDINGS OF THE 4TH ANNUAL LINUX SHOWCASE AND CONFERENCE, ATLANTA, P317
   Congiu G, 2016, IEEE INT C CL COMP, P120, DOI 10.1109/CLUSTER.2016.37
   Dorier M, 2014, INT CONF HIGH PERFOR, P623, DOI 10.1109/SC.2014.56
   Google, 2021, CLOUD TPU PERF GUID
   Google, 2021, CLOUD TPU SYST ARCH
   Hahnloser RHR, 2000, NATURE, V405, P947, DOI 10.1038/35016072
   Kim TK, 2015, KOREAN J ANESTHESIOL, V68, P540, DOI 10.4097/kjae.2015.68.6.540
   Kumar S, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503252
   LILLIEFORS HW, 1967, J AM STAT ASSOC, V62, P399, DOI 10.2307/2283970
   Microsystem S., 2007, LUSTR FIL SYST HIGH
   Moolayil J., 2019, LEARN KERAS DEEP NEU, P1
   Pedregosa F., 2011, J MACH LEARN RES, V12, P2825
   Rong Ge, 2012, Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2012), P204, DOI 10.1109/CCGrid.2012.39
   Song HM, 2011, HPDC 11: PROCEEDINGS OF THE 20TH INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P37
   Spearman C, 1904, AM J PSYCHOL, V15, P72, DOI 10.2307/1412159
   Tang HJ, 2014, LECT NOTES COMPUT SC, V8632, P246, DOI 10.1007/978-3-319-09873-9_21
   Tessier F, 2017, IEEE INT C CL COMP, P70, DOI 10.1109/CLUSTER.2017.80
   Wang Y E, 2019, ARXIV190710701
   Wang ZX, 2014, IEEE ACM INT SYMP, P287, DOI 10.1109/CCGrid.2014.61
   Yeo IK, 2000, BIOMETRIKA, V87, P954, DOI 10.1093/biomet/87.4.954
   You Y, 2019, IEEE T PARALL DISTR, V30, P2449, DOI 10.1109/TPDS.2019.2913833
NR 27
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 15
EP 19
DI 10.1109/SBAC-PADW53941.2021.00013
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Bennett, CH
   Parmar, V
   Calvet, LE
   Klein, JO
   Suri, M
   Marinella, MJ
   Querlioz, AD
AF Bennett, Christopher H.
   Parmar, Vivek
   Calvet, Laurie E.
   Klein, Jacques-Olivier
   Suri, Manan
   Marinella, Matthew J.
   Querlioz, And Damien
TI Contrasting Advantages of Learning With Random Weights and
   Backpropagation in Non-Volatile Memory Neural Networks
SO IEEE ACCESS
DT Article
DE Hardware neural networks; memristive devices; online learning; edge
   computing
ID REPRESENTATIONS; ALGORITHM; SYNAPSES; CIRCUITS; CROSSBAR; MACHINE;
   ONLINE; DEVICE
AB Recently, a Cambrian explosion of a novel, non-volatile memory (NVM) devices known as memristive devices have inspired effort in building hardware neural networks that learn like the brain. Early experimental prototypes built simple perceptrons from nanosynapses, and recently, fully-connected multi-layer perceptron (MLP) learning systems have been realized. However, while backpropagating learning systems pair well with high-precision computer memories and achieve state-of-the-art performances, this typically comes with a massive energy budget. For future Internet of Things/peripheral use cases, system energy footprint will be a major constraint, and emerging NVM devices may fill the gap by sacrificing high bit precision for lower energy. In this paper, we contrast the well-known MLP approach with the extreme learning machine (ELM) or NoProp approach, which uses a large layer of random weights to improve the separability of high-dimensional tasks, and is usually considered inferior in a software context. However, we find that when taking the device non-linearity into account, NoProp manages to equal hardware MLP system in terms of accuracy. While also using a sign-based adaptation of the delta rule for energy-savings, we find that NoProp can learn effectively with four to six 'bits' of device analog capacity, while MLP requires eight-bit capacity with the same rule. This may allow the requirements for memristive devices to be relaxed in the context of online learning. By comparing the energy footprint of these systems for several candidate nanosynapses and realistic peripherals, we confirm that memristive NoProp systems save energy compared with MLP systems. Lastly, we show that ELM/NoProp systems can achieve better generalization abilities than nanosynaptic MLP systems when paired with pre-processing layers (which do not require backpropagated error). Collectively, these advantages make such systems worthy of consideration in future accelerators or embedded hardware.
C1 [Bennett, Christopher H.; Calvet, Laurie E.; Klein, Jacques-Olivier; Querlioz, And Damien] Univ Paris Saclay, Univ Paris Sud, Ctr Nanosci & Nanotechnol, F-91120 Palaiseau, France.
   [Parmar, Vivek; Suri, Manan] IIT Delhi, Dept Elect Engn, New Delhi 110016, India.
   [Bennett, Christopher H.; Marinella, Matthew J.] Sandia Natl Labs, Albuquerque, NM 87185 USA.
RP Bennett, CH (corresponding author), Univ Paris Saclay, Univ Paris Sud, Ctr Nanosci & Nanotechnol, F-91120 Palaiseau, France.; Bennett, CH (corresponding author), Sandia Natl Labs, Albuquerque, NM 87185 USA.
EM cbennett10@gmail.com
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Agarwal S, 2017, S VLSI TECH, pT174, DOI 10.23919/VLSIT.2017.7998164
   Agarwal S, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00484
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2015, ARXIV150502495
   [Anonymous], 2015, 2015 INT JOINT C NEU, DOI DOI 10.1109/IJCNN.2015.7280669
   Bennett CH, 2016, IEEE IJCNN, P947, DOI 10.1109/IJCNN.2016.7727300
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Chabi D, 2015, IEEE T NANOTECHNOL, V14, P954, DOI 10.1109/TNANO.2015.2448554
   Chabi D, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2629503
   Chanthbouala A, 2012, NAT MATER, V11, P860, DOI [10.1038/nmat3415, 10.1038/NMAT3415]
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Elfadel IM, 1994, ADV NEURAL INFORMATI, V6, P882
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Gao LG, 2012, IEEE INT CONF VLSI, P87, DOI 10.1109/VLSI-SoC.2012.6379011
   Hasler J, 2013, FRONT NEUROSCI-SWITZ, V7, DOI 10.3389/fnins.2013.00118
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jiang H, 2016, SCI REP-UK, V6, DOI 10.1038/srep19547
   Jo S.H., 2014, IEDM
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Joost M, 1998, INT J UNCERTAIN FUZZ, V6, P117, DOI 10.1142/S0218488598000100
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kavehei O., 2011, Proceedings of the 2011 Seventh International Conference on Intelligent Sensors, Sensor Networks and Information Processing (ISSNIP), P137, DOI 10.1109/ISSNIP.2011.6146610
   Keene ST, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aabe70
   Khodabandehloo G, 2012, IEEE T VLSI SYST, V20, P750, DOI 10.1109/TVLSI.2011.2109404
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li Y, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P25, DOI 10.1109/VLSIT.2018.8510648
   Li Y, 2013, SCI REP-UK, V3, DOI 10.1038/srep01619
   Lin YP, 2016, SCI REP-UK, V6, DOI 10.1038/srep31932
   Liu CC, 2017, ASIA S PACIF DES AUT, P647, DOI 10.1109/ASPDAC.2017.7858397
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Negrov D, 2017, NEUROCOMPUTING, V237, P193, DOI 10.1016/j.neucom.2016.10.061
   Park S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10123
   Parmar V, 2018, PR GR LAK SYMP VLSI, P391, DOI 10.1145/3194554.3194614
   Pershin YV, 2010, IEEE T CIRCUITS-I, V57, P1857, DOI 10.1109/TCSI.2009.2038539
   Pfeil T, 2012, FRONT NEUROSCI-SWITZ, V6, DOI 10.3389/fnins.2012.00090
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Querlioz D., 2011, 2011 IEEE/ACM International Symposium on Nanoscale Architectures (NANOARCH), P150, DOI 10.1109/NANOARCH.2011.5941497
   Rajendran B, 2015, I CONF VLSI DESIGN, P1, DOI 10.1109/VLSID.2015.109
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saïghi S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00051
   Salakhutdinov R., 2009, ARTIF INTELL, P448, DOI DOI 10.1109/CVPRW.2009.5206577
   SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0
   Seung HS, 2003, NEURON, V40, P1063, DOI 10.1016/S0896-6273(03)00761-X
   Shamsi J, 2015, IEEE INT SYMP CIRC S, P581, DOI 10.1109/ISCAS.2015.7168700
   Shelby RM, 2015, INT RELIAB PHY SYM
   Sidler S, 2016, PROC EUR S-STATE DEV, P440, DOI 10.1109/ESSDERC.2016.7599680
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   Stathopoulos S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-17785-1
   Strachan JP, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/50/505402
   Sun XL, 2020, INT J OCCUP SAF ERGO, V26, P740, DOI 10.1080/10803548.2018.1486528
   Suri M, 2015, IEEE T NANOTECHNOL, V14, P963, DOI 10.1109/TNANO.2015.2441112
   Suri M, 2012, J APPL PHYS, V112, DOI 10.1063/1.4749411
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tang JX, 2016, IEEE T NEUR NET LEAR, V27, P809, DOI 10.1109/TNNLS.2015.2424995
   Tsodyks M, 1998, NEURAL COMPUT, V10, P821, DOI 10.1162/089976698300017502
   Ueda M, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0112659
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/nmat4856, 10.1038/NMAT4856]
   van Schaik A, 2015, NEUROCOMPUTING, V149, P233, DOI 10.1016/j.neucom.2014.01.071
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Vincent P, 2010, J MACH LEARN RES, V11, P3371
   Wang WJ, 2012, SCI REP-UK, V2, DOI 10.1038/srep00360
   Wang YH, 2015, IEEE T NANOTECHNOL, V14, P998, DOI 10.1109/TNANO.2015.2447531
   Widrow B, 2013, NEURAL NETWORKS, V37, P180, DOI 10.1016/j.neunet.2012.09.020
   Woo J, 2016, IEEE ELECTR DEVICE L, V37, P994, DOI 10.1109/LED.2016.2582859
   Woods W, 2015, IEEE T NANOTECHNOL, V14, P945, DOI 10.1109/TNANO.2015.2449835
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhang QT, 2018, NEURAL NETWORKS, V108, P217, DOI 10.1016/j.neunet.2018.08.012
   Zunino RF, 2002, 2002 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, PROCEEDINGS, P117
NR 78
TC 7
Z9 7
U1 0
U2 5
PY 2019
VL 7
BP 73938
EP 73953
DI 10.1109/ACCESS.2019.2920076
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Esmaeilzadeh, H
   Sampson, A
   Ceze, L
   Burger, D
AF Esmaeilzadeh, Hadi
   Sampson, Adrian
   Ceze, Luis
   Burger, Doug
TI Neural Acceleration for General-Purpose Approximate Programs
SO COMMUNICATIONS OF THE ACM
DT Article
AB As improvements in per-transistor speed and energy efficiency diminish, radical departures from conventional approaches are needed to continue improvements in the performance and energy efficiency of general-purpose processors. One such departure is approximate computing, where error in computation is acceptable and the traditional robust digital abstraction of near-perfect accuracy is relaxed. Conventional techniques in energy-efficient computing navigate a design space defined by the two dimensions of performance and energy, and traditionally trade one for the other. General-purpose approximate computing explores a third dimension-error-and trades the accuracy of computation for gains in both energy and performance. Techniques to harvest large savings from small errors have proven elusive. This paper describes a new approach that uses machine learning-based transformations to accelerate approximation-tolerant programs. The core idea is to train a learning model how an approximable region of code-code that can produce imprecise but acceptable results-behaves and replace the original code region with an efficient computation of the learned model. We use neural networks to learn code behavior and approximate it. We describe the Parrot algorithmic transformation, which leverages a simple programmer annotation ("approximable") to transform a code region from a von Neumann model to a neural model. After the learning phase, the compiler replaces the original code with an invocation of a low-power accelerator called a neural processing unit (NPU). The NPU is tightly coupled to the processor pipeline to permit profitable acceleration even when small regions of code are transformed. Offloading approximable code regions to NPUs is faster and more energy efficient than executing the original code. For a set of diverse applications, NPU acceleration provides whole-application speedup of 2.3x and energy savings of 3.0x on average with average quality loss of at most 9.6%. NPUs form a new class of accelerators and show that significant gains in both performance and efficiency are achievable when the traditional abstraction of near-perfect accuracy is relaxed in general-purpose computing.
C1 [Esmaeilzadeh, Hadi] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Sampson, Adrian; Ceze, Luis] Univ Washington, Seattle, WA 98195 USA.
   [Burger, Doug] Microsoft Res, Redmond, WA USA.
RP Esmaeilzadeh, H (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM hadi@cc.gatech.edu; asampson@cs.washington.edu;
   luisceze@cs.washington.edu; dburger@microsoft.com
CR [Anonymous], 2010, ISCA
   [Anonymous], 2009, MICRO
   [Anonymous], 2012, INT S MICR MICRO
   [Anonymous], 2010, PLDI
   Chakrapani Lakshmi N., 2006, DATE
   Chen T., 2012, IISWC
   de Kruijf M., 2010, ISCA
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Esmaeilzadeh H., 2006, ISCAS
   Esmaeilzadeh H., 2012, ASPLOS
   Esmaeilzadeh H, 2013, COMMUN ACM, V56, P93, DOI 10.1145/2408776.2408797
   Galal S, 2011, IEEE T COMPUT, V60, P913, DOI 10.1109/TC.2010.121
   Govindaraju V., 2011, HPCA
   Gupta Shantanu, 2011, MICRO
   Guzhva A., 2009, ICANN
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Hashmi A., 2011, ISCA
   Joubert A., 2012, IJCNN
   Liu S., 2011, ASPLOS
   Muralimanohar N., 2007, MICRO
   Narayanan S., 2010, DATE
   Patel A., 2011, DAC
   Putnam Andrew R., 2008, FPGA
   Razdan R., 1994, MICRO
   Rumelhart G.E., 1986, PARALLEL DISTRIBUTED, P318, DOI DOI 10.1016/B978-1-4832-1446-7.50035-2
   Sampson A., 2011, PLDI
   Sidiroglou-Douskos  S., 2011, FSE
   Temam O., 2012, ISCA
   Venkatesh G., 2010, ASPLOS
   Zhu J., 2003, FPL
NR 30
TC 25
Z9 27
U1 1
U2 12
PD JAN
PY 2015
VL 58
IS 1
BP 105
EP 115
DI 10.1145/2589750
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Sivabhaskar, S
   Li, RQ
   Roy, A
   Kirby, N
   Fakhreddine, M
   Papanikolaou, N
AF Sivabhaskar, Sruthi
   Li, Ruiqi
   Roy, Arkajyoti
   Kirby, Neil
   Fakhreddine, Mohamad
   Papanikolaou, Nikos
TI Machine learning models to predict the delivered positions of Elekta
   multileaf collimator leaves for volumetric modulated arc therapy
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE Elekta; log files; machine learning; MLC positional deviations; VMAT
ID MLC LEAF POSITION; IMRT DELIVERY; ERRORS; PLANS; PERFORMANCE;
   COMPLEXITY; ACCURACY; IMPACT; ANGLE
AB Purpose Accurate positioning of multileaf collimator (MLC) leaves during volumetric modulated arc therapy (VMAT) is essential for accurate treatment delivery. We developed a linear regression, support vector machine, random forest, extreme gradient boosting (XGBoost), and an artificial neural network (ANN) for predicting the delivered leaf positions for VMAT plans. Methods For this study, 160 MLC log files from 80 VMAT plans were obtained from a single institution treated on 3 Elekta Versa HD linear accelerators. The gravity vector, X1 and X2 jaw positions, leaf gap, leaf position, leaf velocity, and leaf acceleration were extracted and used as model inputs. The models were trained using 70% of the log files and tested on the remaining 30%. Mean absolute error (MAE), root mean square error (RMSE), the coefficient of determination R-2, and fitted line plots showing the relationship between delivered and predicted leaf positions were used to evaluate model performance. Results The models achieved the following errors: linear regression (MAE = 0.158 mm, RMSE = 0.225 mm), support vector machine (MAE = 0.141 mm, RMSE = 0.199 mm), random forest (MAE = 0.161 mm, RMSE = 0.229 mm), XGBoost (MAE = 0.185 mm, RMSE = 0.273 mm), and ANN (MAE = 0.361 mm, RMSE = 0.521 mm). A significant correlation between a plan's gamma passing rate (GPR) and the prediction errors of linear regression, support vector machine, and random forest is seen (p < 0.045). Conclusions We examined various models to predict the delivered MLC positions for VMAT plans treated with Elekta linacs. Linear regression, support vector machine, random forest, and XGBoost achieved lower errors than ANN. Models that can accurately predict the individual leaf positions during treatment can help identify leaves that are deviating from the planned position, which can improve a plan's GPR.
C1 [Sivabhaskar, Sruthi; Li, Ruiqi; Kirby, Neil; Fakhreddine, Mohamad; Papanikolaou, Nikos] Univ Texas Hlth Sci Ctr San Antonio, Dept Radiat Oncol, 7979 Wurzbach Rd, San Antonio, TX 78229 USA.
   [Roy, Arkajyoti] Univ Texas Hlth Sci Ctr San Antonio, Dept Management Sci & Stat, San Antonio, TX 78229 USA.
RP Papanikolaou, N (corresponding author), Univ Texas Hlth Sci Ctr San Antonio, Dept Radiat Oncol, 7979 Wurzbach Rd, San Antonio, TX 78229 USA.
EM papanikolaou@uthscsa.edu
CR Alexopoulos EC, 2010, HIPPOKRATIA, V14, P23
   Awad M., 2015, SUPPORT VECTOR REGRE, P67, DOI DOI 10.1007/978-1-4302-5990-9_4
   Bai S, 2013, MED DOSIM, V38, P143, DOI 10.1016/j.meddos.2012.10.002
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Brown G, 2010, ENCY MACHINE LEARNIN, V312, DOI [DOI 10.1007/978-0-387-30164-8_252, 10.1007/978-0-387-30164-8_252]
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chuang KC, 2021, MED PHYS, V48, P978, DOI 10.1002/mp.14670
   Chuang KC, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abc86c
   El Naqa I, 2018, MED PHYS, V45, pE834, DOI 10.1002/mp.12811
   Galvin J., 2001, BASIC APPL MULTILEAF
   Galvin J. M., 1999, P AAPM ANN M NASHV T
   Huq MS, 2002, PHYS MED BIOL, V47, pN159, DOI 10.1088/0031-9155/47/12/401
   Ju S, 2014, MED PHYS, V41, P267, DOI 10.1118/1.4888525
   Kabat CN, 2019, MED PHYS, V46, P1397, DOI 10.1002/mp.13374
   Kamperis E, 2020, INT J RADIAT ONCOL, V106, P182, DOI 10.1016/j.ijrobp.2019.09.003
   Kimura Y, 2021, MED PHYS, V48, P4769, DOI 10.1002/mp.15031
   Krenker A, 2011, ARTIFICIAL NEURAL NETWORKS - METHODOLOGICAL ADVANCES AND BIOMEDICAL APPLICATIONS, P3, DOI 10.5772/15751
   Kumari K., 2018, J PRACT CARDIOVASC S, V4, P33, DOI [DOI 10.4103/JPCS.JPCS_8_18, 10.4103/jpcs.jpcs_8_18]
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Ling CC, 2008, INT J RADIAT ONCOL, V72, P575, DOI 10.1016/j.ijrobp.2008.05.060
   Liu C, 2008, INT J RADIAT ONCOL, V71, pS89, DOI 10.1016/j.ijrobp.2007.07.2392
   Losasso T, 2008, INT J RADIAT ONCOL, V71, pS85, DOI 10.1016/j.ijrobp.2007.06.082
   Mu G, 2008, PHYS MED BIOL, V53, P77, DOI 10.1088/0031-9155/53/1/005
   Nithiyanantham K, 2015, J APPL CLIN MED PHYS, V16, P296, DOI 10.1120/jacmp.v16i5.5515
   Oliver M, 2010, RADIOTHER ONCOL, V97, P554, DOI 10.1016/j.radonc.2010.06.013
   Osman AFI, 2020, MED PHYS, V47, P1421, DOI 10.1002/mp.14014
   Park JM, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1441-7
   Potter NJ, 2020, MED PHYS, V47, P4711, DOI 10.1002/mp.14416
   Probst P, 2019, WIRES DATA MIN KNOWL, V9, DOI 10.1002/widm.1301
   Puchades-Puchades V, 2015, J RADIOTHER PRACT, V14, P323, DOI 10.1017/S1460396915000217
   Rangel A, 2009, MED PHYS, V36, P3304, DOI 10.1118/1.3134244
   Schneider A, 2010, DTSCH ARZTEBL INT, V107, P776, DOI [10.3238/arztebl.2010.0776, 10.3238/arztebl.2010.0799]
   Tatsumi D, 2011, PHYS MED BIOL, V56, pN237, DOI 10.1088/0031-9155/56/20/N03
   Tripepi G, 2008, KIDNEY INT, V73, P806, DOI 10.1038/sj.ki.5002787
   Wijesooriya K, 2012, MED PHYS, V39, P1846, DOI 10.1118/1.3690464
   Xu ZZ, 2016, RADIOL ONCOL, V50, P121, DOI 10.1515/raon-2016-0008
   Younge KC, 2016, J APPL CLIN MED PHYS, V17, P124, DOI 10.1120/jacmp.v17i4.6241
NR 38
TC 1
Z9 1
U1 1
U2 5
PD AUG
PY 2022
VL 23
IS 8
AR e13667
DI 10.1002/acm2.13667
EA JUN 2022
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Chen, Y
   Long, X
   He, J
   Chen, YH
   Tan, HS
   Zhang, ZX
   Winslett, M
   Chen, DM
AF Chen, Yao
   Long, Xin
   He, Jiong
   Chen, Yuhang
   Tan, Hongshi
   Zhang, Zhenxiang
   Winslett, Marianne
   Chen, Deming
GP IEEE Comp Soc
TI HaoCL: Harnessing Large-scale Heterogeneous Processors Made Easy
SO 2020 IEEE 40TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 40th IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY NOV 29-DEC 01, 2020
CL ELECTR NETWORK
DE heterogeneous cluster; distributed computing; OpenCL; machine learning;
   deep learning
AB The pervasive adoption of Deep Learning (DL) and Graph Processing (GP) makes it a de facto requirement to build large-scale clusters of heterogeneous accelerators including GPUs and FPGAs. The OpenCL programming framework can be used on the individual nodes of such clusters but is not intended for deployment in a distributed manner. Fortunately, the original OpenCL semantics naturally fit into the programming environment of heterogeneous clusters. In this paper, we propose a heterogeneity-aware OpenCL-like (HaoCL) programming framework to facilitate the programming of a wide range of scientific applications including DL and GP workloads on large-scale heterogeneous clusters. With HaoCL, existing applications can be directly deployed on heterogeneous clusters without any modifications to the original OpenCL source code and without awareness of the underlying hardware topologies and configurations. Our experiments show that HaoCL imposes a negligible overhead in a distributed environment, and provides near-liner speedups on standard benchmarks when computation or data size exceeds the capacity of a single node. The system design and the evaluations are presented in this demo paper.
C1 [Chen, Yao; Chen, Yuhang; Winslett, Marianne] Adv Digital Sci Ctr, Singapore, Singapore.
   [Long, Xin; Zhang, Zhenxiang] Alibaba Grp, Shenzhen, Guangdong, Peoples R China.
   [He, Jiong] ASTAR, Inst High Performance Comp, Singapore, Singapore.
   [Tan, Hongshi] Natl Univ Singapore, Singapore, Singapore.
   [Winslett, Marianne; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Chen, Y (corresponding author), Adv Digital Sci Ctr, Singapore, Singapore.
CR [Anonymous], 2010, GPGPU
   [Anonymous], 2003, BOOST C LIB
   [Anonymous], 2009, IISWC
   [Anonymous], 2009, 2009 IEEE 7 S APPL S, DOI DOI 10.1109/SASP.2009.5226333
   Barak A., 2010, CLUST WORKSH
   Chen D., 2010, IEEE T VERY LARGE SC, P564
   CHEN W, 2005, SRC TECHCON, V5, DOI DOI 10.1166/JNN.2005.301
   Chen X., 2019, FPL
   Duato J., 2009, EURO PAR
   eral Y. Chcn, 2019, FPGA
   He J., 2018, ICDCS
   Kim J., 2016, PLDI
   Kim J., 2012, ICS
NR 13
TC 1
Z9 1
U1 0
U2 1
PY 2020
BP 1231
EP 1234
DI 10.1109/ICDCS47774.2020.00120
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Zheng, SZ
   Liang, Y
   Wang, S
   Chen, RZ
   Sheng, KW
AF Zheng, Size
   Liang, Yun
   Wang, Shuo
   Chen, Renze
   Sheng, Kaiwen
GP ACM
TI FlexTensor: An Automatic Schedule Exploration and Optimization Framework
   for Tensor Computation on Heterogeneous System
SO TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR
   PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV)
DT Proceedings Paper
CT 25th International Conference on Architectural Support for Programming
   Languages and Operating Systems (ASPLOS)
CY MAR 16-20, 2020
CL Lausanne, SWITZERLAND
DE code generation; compiler optimization; heterogeneous systems; machine
   learning
AB Tensor computation plays a paramount role in a broad range of domains, including machine learning, data analytics, and scientific computing. The wide adoption of tensor computation and its huge computation cost has led to high demand for flexible, portable, and high-performance library implementation on heterogeneous hardware accelerators such as GPUs and FPGAs. However, the current tensor library implementation mainly requires programmers to manually design low-level implementation and optimize from the algorithm, architecture, and compilation perspectives. Such a manual development process often takes months or even years, which falls far behind the rapid evolution of the application algorithms.
   In this paper, we introduce FlexTensor, which is a schedule exploration and optimization framework for tensor computation on heterogeneous systems. FlexTensor can optimize tensor computation programs without human interference, allowing programmers to only work on high-level programming abstraction without considering the hardware platform details. FlexTensor systematically explores the optimization design spaces that are composed of many different schedules for different hardware. Then, FlexTensor combines different exploration techniques, including heuristic method and machine learning method to find the optimized schedule configuration. Finally, based on the results of exploration, customized schedules are automatically generated for different hardware. In the experiments, we test 12 different kinds of tensor computations with totally hundreds of test cases and FlexTensor achieves average 1.83x performance speedup on NVIDIA V100 GPU compared to cuDNN; 1.72x performance speedup on Intel Xeon CPU compared to MKL-DNN for 2D convolution; 1.5x performance speedup on Xilinx VU9P FPGA compared to OpenCL baselines; 2.21x speedup on NVIDIA V100 GPU compared to the state-of-the-art.
C1 [Zheng, Size; Liang, Yun; Wang, Shuo; Chen, Renze; Sheng, Kaiwen] Peking Univ, Dept CS, CECA, Beijing, Peoples R China.
RP Liang, Y (corresponding author), Peking Univ, Dept CS, CECA, Beijing, Peoples R China.
EM zhengsz@pku.edu.cn; ericlyun@pku.edu.cn; shvowang@pku.edu.cn;
   crz@pku.edu.cn; sheng_kaiwen@pku.edu.cn
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Agarap A. F., 2018, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1803.08375, DOI 10.48550/ARXIV.1803.08375]
   [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   Belter G, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Bondhugula U, 2008, PLDI'08: PROCEEDINGS OF THE 2008 SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN & IMPLEMENTATION, P101, DOI 10.1145/1375581.1375595
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TQ, 2018, ADV NEUR IN, V31
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cong J, 2011, IEEE T COMPUT AID D, V30, P939, DOI 10.1109/TCAD.2011.2106370
   Dagum Leonardo, 1988, COMPUTATIONAL SCI EN, V5, P1
   De Matteis Tiziano, 2019, ABS190707929 CORR
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Farooqui Naila, 2014, 2014 C TIM RES OP SY
   Frigo M, 1998, INT CONF ACOUST SPEE, P1381, DOI 10.1109/ICASSP.1998.681704
   Georganas E, 2018, SC18 INT C HIGH PERF, P830
   Hara K, 2017, IEEE INT CONF COMP V, P3154, DOI 10.1109/ICCVW.2017.373
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Karmani RK., 2011, ENCY PARALLEL COMPUT, P95
   Kim DaeGon, 2007, SC 07 P 2007 ACMIEEE, DOI 10.1145/1362622.1362691
   Kim Y., 2014, ARXIV, DOI 10.3115/v1/D14-1181
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Kjolstad F, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3133901
   Lai YH, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P242, DOI 10.1145/3289602.3293910
   Lavin A., 2015, FAST ALGORITHMS CONV, Vabs/1509.09308
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   LeCun Y., 2013, ARXIV PREPRINT ARXIV
   Li B, 2018, PR IEEE SEN ARRAY, P578, DOI 10.1109/SAM.2018.8448770
   Li XQ, 2019, ADV MATER SCI ENG, V2019, DOI 10.1155/2019/6384360
   Liang Y, 2018, IEEE T COMPUT, V67, P1750, DOI 10.1109/TC.2018.2840686
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2694344.2694364, 10.1145/2775054.2694364]
   Nakatsuji M, 2017, IEEE T COMPUT SOC SY, V4, P207, DOI 10.1109/TCSS.2017.2732685
   NVIDIA(R), CUBLAS LIB
   Papalexakis EE, 2017, ACM T INTEL SYST TEC, V8, DOI 10.1145/2915921
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J., 2016, YOU ONLY LOOK ONCE U, DOI DOI 10.1109/CVPR.2016.91
   Roesch Jared, 2019, ABS190408368 CORR
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sermanet P., 2013, ARXIV13126229
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Vasilache N., 2018, CORR
   Vasilache Nicolas, 2015, P INT C LEARN REPR, P1
   Venkat A, 2019, INT J HIGH PERFORM C, V33, P1275, DOI 10.1177/1094342019866247
   Verdoolaege Sven, 2013, ACM T ARCHIT CODE OP, V9, DOI [DOI 10.1145/2400682.2400713, 10.1145/2400682.2400713]
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xie XL, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P195, DOI 10.1145/3307681.3325407
   Xie XL, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P395, DOI 10.1145/2830772.2830813
   Zeiler, 2012, ARXIV
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang KX, 2018, DESTECH TRANS ECON, P32
NR 62
TC 64
Z9 68
U1 1
U2 7
PY 2020
BP 859
EP 873
DI 10.1145/3373376.3378508
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Amiraski, M
   Werner, D
   Hankin, A
   Sebot, J
   Vaidyanathan, K
   Hempstead, M
AF Amiraski, Maziar
   Werner, David
   Hankin, Alexander
   Sebot, Julien
   Vaidyanathan, Kaushik
   Hempstead, Mark
GP IEEE
TI Boreas: A Cost-Effective Mitigation Method for Advanced Hotspots using
   Machine Learning and Hardware Telemetry
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
ID MANAGEMENT
AB Managing advanced hotspots on modern microprocessors is a critical and worsening issue, affecting performance, product reliability, and device lifetime. Many thermal management techniques focus primarily on remaining below a critical temperature, and while they are successful to that end, they come with a significant performance cost. This cost stems from the large temperature guardbands that are needed to ensure device safety and correct IC operation. These guardbands must be sized to account for multiple factors including 1) control-loop latency, 2) thermal sensor delay, 3) thermal gradients inside timing paths that could result in timing violations, and 4) the instantaneous temperature delta between a temperature sensor and the true peak temperature on the IC.
   This work demonstrates the need for novel hotspot avoidance techniques that can react quickly and simultaneously account for each of these concerns in order to safely maximize performance. Recently introduced hotspot metrics-Hotspot-Severity and Maximum Local Temperature Difference (MLTD)-are used in order to allow model designers to have a single optimization target that accounts for each of these thermal concerns simultaneously. We present Boreas, a novel hotspot mitigation technique that uses a Machine Learning model implemented in an on-chip specialized hardware accelerator that leverages micro-architectural performance counters. Boreas outperforms existing thermal management techniques while remaining lightweight and well-suited for implementation in hardware. Even with a conservative thermal sensor delay, Boreas is able to predict severity with high precision, resulting in effective hotspot mitigation on unseen workloads. These machine learning models were, therefore, able to select a frequency that was 4.5% better than thermal only models on average, and up to 9.6% higher in the best case, while having the same reliability budget as the thermal models.
C1 [Amiraski, Maziar; Werner, David; Hempstead, Mark] Tufts Univ, Medford, MA 02155 USA.
   [Sebot, Julien] Intel Corp, Hillsboro, OR USA.
   [Vaidyanathan, Kaushik] Google Inc, Sunnyvale, CA USA.
   [Hankin, Alexander] Harvard Univ, Cambridge, MA 02138 USA.
   [Hankin, Alexander] Intel Labs, Hillsboro, OR USA.
RP Amiraski, M (corresponding author), Tufts Univ, Medford, MA 02155 USA.
EM maziar.mehdizadehamiraski@tufts.edu; david.werner@tufts.edu
CR [Anonymous], 2015, P ACM GREAT LAKES S
   Bakhshalipour M, 2019, INT S HIGH PERF COMP, P399, DOI 10.1109/HPCA.2019.00053
   Bar-Cohen A, 2006, P IEEE, V94, P1549, DOI 10.1109/JPROC.2006.879791
   Bartolini A, 2011, DES AUT TEST EUROPE, P830
   Bartolini A, 2013, IEEE T PARALL DISTR, V24, P170, DOI 10.1109/TPDS.2012.117
   Bera R., 2021, MICRO54 54 ANN IEEEA, P1121
   Cao LP, 1998, IEEE T COMPON PACK A, V21, P113, DOI 10.1109/95.679040
   Ching-Han Tsai, 1999, Proceedings. 1999 International Symposium on Physical Design, P179, DOI 10.1145/299996.300067
   Cochran R, 2010, DES AUT CON, P62
   Das A, 2014, DES AUT CON, DOI 10.1145/2593069.2593199
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Hankin A, 2021, I S WORKL CHAR PROC, P163, DOI 10.1109/IISWC53511.2021.00025
   Iranfar A, 2015, I SYMPOS LOW POWER E, P291, DOI 10.1109/ISLPED.2015.7273529
   Jiménez DA, 2001, HPCA: SEVENTH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTING ARCHITECTURE, PROCEEDINGS, P197, DOI 10.1109/HPCA.2001.903263
   Jung-Chang Wang, 2009, 2009 4th International Microsystems, Packaging, Assembly and Circuits Technology Conference (IMPACT), P364, DOI 10.1109/IMPACT.2009.5382193
   Kondguli S, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3170433
   Lee PS, 2005, HEAT TRANSF DIV ASME, V376-1, P643
   Lee YJ, 2013, IEEE T COMP PACK MAN, V3, P1332, DOI 10.1109/TCPMT.2013.2244164
   Lo D, 2014, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2014.6835969
   Lyons MJ, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086727
   Mukherjee R, 2005, DES AUT CON, P196
   Pagani S, 2020, IEEE T COMPUT AID D, V39, P101, DOI 10.1109/TCAD.2018.2878168
   Schafer BC, 2009, IET COMPUT DIGIT TEC, V3, P62, DOI 10.1049/iet-cdt:20070159
   Schafer BC, 2008, IEEE T VLSI SYST, V16, P1475, DOI 10.1109/TVLSI.2008.2001140
   Shi Z, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P413, DOI 10.1145/3352460.3358319
   Teran E, 2016, INT SYMP MICROARCH
   wikichip, M1 APPLE
   Wu Q, 2005, INT SYMP MICROARCH, P271
   Ye R, 2012, ASIA S PACIF DES AUT, P115, DOI 10.1109/ASPDAC.2012.6164929
   Yu SJ, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0188428
NR 30
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 295
EP 305
DI 10.1109/ISPASS57527.2023.00036
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Naito, YI
   Yamane, M
   Kitagawa, H
AF Naito, Yuichi I.
   Yamane, Masako
   Kitagawa, Hiroyuki
TI A protocol for using attenuated total reflection Fourier-transform
   infrared spectroscopy for pre-screening ancient bone collagen prior to
   radiocarbon dating
SO RAPID COMMUNICATIONS IN MASS SPECTROMETRY
DT Article
ID PRESERVATION; EXTRACTION; INDICATORS; DIAGENESIS; SURFACES; SAMPLES;
   RATIOS; CARBON; AGE
AB Rationale Pre-screening of bone collagen quality is important to reduce the cost for analyses such as radiocarbon (C-14) dating with accelerator mass spectrometry in archaeological studies. We developed a pre-screening protocol based on attenuated total reflection (ATR) Fourier-transform infrared spectroscopy (FTIR) for assessing the chemical composition and mineralogy of ancient bone samples.
   Methods ATR-FTIR measurements were performed on bulk bones of diverse origin and age before collagen extraction. The percentage nitrogen of bulk bones, as well as the weight percentage, and the percentage carbon and nitrogen of extracted organic matter were noted. Several machine learning algorithms were applied to the spectral data and compared for their efficacy in screening for well preserved collagen.
   Results The results showed that (a) the first derivative of the spectral data was better suited to screening than the raw FTIR data, especially for a wider spectral range and (b) certain classification algorithms [e.g. gradient boosting machine (GBM)] were able to efficiently predict the degree of preservation in bone samples.
   Conclusions This pre-screening protocol can serve as a fast, concise and inexpensive pre-screening tool for determining relative degrees of preservation before collagen extraction and subsequent C-14 dating. The screening power based on the machine learning techniques can be further improved by accumulating the FTIR spectral data of bones.
C1 [Naito, Yuichi I.] Nagoya Univ, Nagoya Univ Museum, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
   [Yamane, Masako; Kitagawa, Hiroyuki] Nagoya Univ, Inst Space Earth Environm Res ISEE, Chikusa Ku, Furo Cho, Nagoya, Aichi, Japan.
RP Naito, YI (corresponding author), Nagoya Univ, Nagoya Univ Museum, Chikusa Ku, Furo Cho, Nagoya, Aichi 4648601, Japan.
EM ynaito@num.nagoya-u.ac.jp
CR ABE Y, 1972, BIOPOLYMERS, V11, P1817, DOI 10.1002/bip.1972.360110905
   AMBROSE SH, 1990, J ARCHAEOL SCI, V17, P431, DOI 10.1016/0305-4403(90)90007-R
   [Anonymous], 2006, MACLA
   [Anonymous], R LANG ENV STAT COMP
   [Anonymous], 2016, KDD16 P 22 ACM, DOI DOI 10.1145/2939672.2939785
   Bocherens H, 1997, QUATERNARY RES, V48, P370, DOI 10.1006/qres.1997.1927
   Bocherens H, 2005, ANTHROPOLOGIE, V109, P557, DOI 10.1016/j.anthro.2005.06.005
   Bocherens H, 2008, PALAEOGEOGR PALAEOCL, V266, P220, DOI 10.1016/j.palaeo.2008.03.023
   Brock F, 2010, J ARCHAEOL SCI, V37, P855, DOI 10.1016/j.jas.2009.11.015
   Brock F, 2012, RADIOCARBON, V54, P879, DOI 10.1017/S0033822200047524
   Cersoy S, 2017, RADIOCARBON, V59, P679, DOI 10.1017/RDC.2016.82
   Crann CA, 2019, J ARCHAEOL SCI-REP, V24, P1059, DOI 10.1016/j.jasrep.2019.03.023
   DENIRO MJ, 1988, GEOCHIM COSMOCHIM AC, V52, P2197, DOI 10.1016/0016-7037(88)90122-6
   DENIRO MJ, 1985, NATURE, V317, P806, DOI 10.1038/317806a0
   Grunenwald A, 2014, ANAL BIOANAL CHEM, V406, P4691, DOI 10.1007/s00216-014-7863-z
   Harvey VL, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0150650
   HEDGES REM, 1995, J ARCHAEOL SCI, V22, P201, DOI 10.1006/jasc.1995.0022
   Higham T, 2014, NATURE, V512, P306, DOI 10.1038/nature13621
   KITAGAWA H, 1993, RADIOCARBON, V35, P295, DOI 10.1017/S0033822200064973
   Kuhn M., 2013, APPL PREDICTIVE MODE, V1st
   Kuhn M, 2008, J STAT SOFTW, V28, P1, DOI 10.18637/jss.v028.i05
   Lebon M, 2016, RADIOCARBON, V58, P131, DOI 10.1017/RDC.2015.11
   Lebon M, 2014, PALAEOGEOGR PALAEOCL, V416, P110, DOI 10.1016/j.palaeo.2014.08.001
   Lebon M, 2011, J ANAL ATOM SPECTROM, V26, P922, DOI 10.1039/c0ja00250j
   LONGIN R, 1971, NATURE, V230, P241, DOI 10.1038/230241a0
   Nakamura T, 2016, QUATERN INT, V397, P250, DOI 10.1016/j.quaint.2015.04.014
   Nielsen-Marsh CM, 2000, J ARCHAEOL SCI, V27, P1139, DOI 10.1006/jasc.1999.0537
   Pestle WJ, 2015, J ARCHAEOL SCI, V58, P113, DOI 10.1016/j.jas.2015.03.027
   Seelenbinder J, 2011, SPECTROSCOPY-US, P10
   Sponheimer M, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-50443-2
   Trueman CNG, 2004, J ARCHAEOL SCI, V31, P721, DOI 10.1016/j.jas.2003.11.003
   Vaiglova P, 2014, RAPID COMMUN MASS SP, V28, P2497, DOI 10.1002/rcm.7044
   Van Klinken GJ, 1999, J ARCHAEOL SCI, V26, P687, DOI 10.1006/jasc.1998.0385
   Vincke D, 2014, TALANTA, V125, P181, DOI 10.1016/j.talanta.2014.02.044
   WEINER S, 1990, J ARCHAEOL SCI, V17, P187, DOI 10.1016/0305-4403(90)90058-D
NR 35
TC 4
Z9 4
U1 1
U2 10
PD MAY 30
PY 2020
VL 34
IS 10
AR e8720
DI 10.1002/rcm.8720
WC Biochemical Research Methods; Chemistry, Analytical; Spectroscopy
DA 2023-11-11
ER

PT J
AU Gokmen, T
   Vlasov, Y
AF Gokmen, Tayfun
   Vlasov, Yurii
TI Acceleration of Deep Neural Network Training with Resistive Cross-Point
   Devices: Design Considerations
SO FRONTIERS IN NEUROSCIENCE
DT Article
DE deep neural network training; synaptic device; machine learning;
   artificial neural networks; nanotechnology; materials engineering;
   electronic devices; memristive devices
ID ON-CHIP; ARRAY
AB In recent years, deep neural networks (DNN) have demonstrated significant business impact in large scale analysis and classification tasks such as speech recognition, visual object detection, pattern extraction, etc. Training of large DNNs, however, is universally considered as time consuming and computationally intensive task that demands datacenter-scale computational resources recruited for many days. Here we propose a concept of resistive processing unit (RPU) devices that can potentially accelerate DNN training by orders of magnitude while using much less power. The proposed RPU device can store and update the weight values locally thus minimizing data movement during training and allowing to fully exploit the locality and the parallelism of the training algorithm. We evaluate the effect of various RPU device features/non-idealities and system parameters on performance in order to derive the device and system level specifications for implementation of an accelerator chip for DNN training in a realistic CMOS-compatible technology. For large DNNs with about 1 billion weights this massively parallel RPU architecture can achieve acceleration factors of 30, 000x compared to state-of-the-art microprocessors while providing power efficiency of 84, 000 GigaOps/s/W. Problems that currently require days of training on a datacenter-size cluster with thousands of machines can be addressed within hours on a single RPU accelerator. A system consisting of a cluster of RPU accelerators will be able to tackle Big Data problems with trillions of parameters that is impossible to address today like, for example, natural speech recognition and translation between all world languages, real-time analytics on large streams of business and scientific data, integration, and analysis of multimodal sensory data flows from a massive number of IoT (Internet of Things) sensors.
C1 [Gokmen, Tayfun; Vlasov, Yurii] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
   [Vlasov, Yurii] Univ Illinois, Dept Elect & Comp Engn, Urbana, IL USA.
RP Gokmen, T (corresponding author), IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
EM tgokmen@us.ibm.com
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], 2012, NVIDIAS NEXT GEN CUD
   [Anonymous], DEEP LEARNING COTS H
   [Anonymous], ARXIV150102876CSCV
   Arima Y., 1991, IEEE J SOLID-ST CIRC, V26, P1637
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   Burr G., 2015, IEDM INT EL DEV M WA
   Burr G. W., 2014, 2014 IEEE INT EL DEV
   Chen G, 2014, ISSCC DIG TECH PAP I, V57, P276, DOI 10.1109/ISSCC.2014.6757432
   Chen Y., 2014, 2014 47 ANN IEEE ACM, P609
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Gaines B. R., 1967, PROC AFIPS SPRING JO, P149, DOI [10.1145/1465482.1465505, DOI 10.1145/1465482.1465505]
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gupta S., 2015, ARXIV150202551CSLG
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Indiveri G, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/384010
   Jackson BL, 2013, ACM J EMERG TECH COM, V9, DOI 10.1145/2463585.2463588
   Jensen K., 2013, INT C NOIS FLUCT MON
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jonsson B. E., 2011, 2011 European Conference on Circuit Theory and Design (ECCTD 2011), P560, DOI 10.1109/ECCTD.2011.6043595
   Jonsson B.E., 2011, PROC 2011 IMEKO IWAD, P132
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuzum D, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/382001
   Le Le Q.V. Q.V., 2012, ICML, P507
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   LEHMANN C, 1993, IEEE T NEURAL NETWOR, V4, P400, DOI 10.1109/72.217181
   Li B., 2014, 19 AS S PAC DES AUT
   Merkel C, 2014, IEEE INT SOC CONF, P359, DOI 10.1109/SOCC.2014.6948954
   Poppelbaum W., 1967, P NOV 14 16 1967 FAL
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Saïghi S, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00051
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Simonyan K, 2015, P 3 INT C LEARN REPR
   Soudry D, 2015, IEEE T NEUR NET LEAR, V26, P2408, DOI 10.1109/TNNLS.2014.2383395
   STEINBUCH K, 1961, KYBERNETIK, V1, P36, DOI 10.1007/BF00293853
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Stuecheli J, 2013, HOT CHIPS C PAL ALT
   Szegedy C., 2015, 2015 IEEE C COMPUTER
   Welling M., 2016, ARXIV160208323CSNE
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
   Yu S., 2015, IEDM, P451, DOI 10.1109/IEDM.2015.7409718
   Yu SM, 2013, ADV MATER, V25, P1774, DOI 10.1002/adma.201203680
NR 44
TC 296
Z9 335
U1 4
U2 122
PD JUL 21
PY 2016
VL 10
AR 333
DI 10.3389/fnins.2016.00333
WC Neurosciences
DA 2023-11-11
ER

PT C
AU Pal, S
   Beaumont, J
   Park, DH
   Amarnath, A
   Feng, SY
   Chakrabarti, C
   Kim, HS
   Blaauw, D
   Mudge, T
   Dreslinski, R
AF Pal, Subhankar
   Beaumont, Jonathan
   Park, Dong-Hyeon
   Amarnath, Aporva
   Feng, Siying
   Chakrabarti, Chaitali
   Kim, Hun-Seok
   Blaauw, David
   Mudge, Trevor
   Dreslinski, Ronald
GP IEEE
TI OuterSPACE: An Outer Product based Sparse Matrix Multiplication
   Accelerator
SO 2018 24TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 24th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 24-28, 2018
CL Vienna, AUSTRIA
DE Sparse matrix processing; application-specific hardware; parallel
   computer architecture; hardware-software codesign; hardware accelerators
ID ALGEBRA; PERFORMANCE
AB Sparse matrices are widely used in graph and data analytics, machine learning, engineering and scientific applications. This paper describes and analyzes OuterSPACE, an accelerator targeted at applications that involve large sparse matrices. OuterSPACE is a highly-scalable, energy-efficient, reconfigurable design, consisting of massively parallel Single Program, Multiple Data (SPMD)style processing units, distributed memories, high-speed crossbars and High Bandwidth Memory (HBM).
   We identify redundant memory accesses to non-zeros as a key bottleneck in traditional sparse matrix-matrix multiplication algorithms. To ameliorate this, we implement an outer product based matrix multiplication technique that eliminates redundant accesses by decoupling multiplication from accumulation. We demonstrate that traditional architectures, due to limitations in their memory hierarchies and ability to harness parallelism in the algorithm, are unable to take advantage of this reduction without incurring significant overheads. OuterSPACE is designed to specifically overcome these challenges.
   We simulate the key components of our architecture using gem5 on a diverse set of matrices from the University of Florida's SuiteSparse collection and the Stanford Network Analysis Project and show a mean speedup of 7.9x over Intel Math Kernel Library on a Xeon CPU, 13.0x against cuSPARSE and 14.0x against CUSP when run on an NVIDIA K40 GPU, while achieving an average throughput of 2.9 GFLOPS within a 24 W power budget in an area of 87 mm2.
C1 [Pal, Subhankar; Beaumont, Jonathan; Park, Dong-Hyeon; Amarnath, Aporva; Feng, Siying; Kim, Hun-Seok; Blaauw, David; Mudge, Trevor; Dreslinski, Ronald] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Chakrabarti, Chaitali] Arizona State Univ, Tempe, AZ USA.
RP Pal, S (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM subh@umich.edu; jbbeau@umich.edu; dohypark@umich.edu; aporvaa@umich.edu;
   fengsy@umich.edu; chaitali@asu.edu; hunseok@umich.edu; blaauw@umich.edu;
   tnm@umich.edu; rdreslin@umich.edu
CR A. Tech, 2013, NVIDIA LAUNCH TESL K
   Acer S., 2016, PARALLEL COMPUTING, V59
   Akbudak K., 2017, EXPLOITING LOCALITY
   Alfano M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2624284
   Alvarez L, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P720, DOI 10.1145/2749469.2750411
   [Anonymous], 2013, 2013 IEEE HIGH PERFO
   [Anonymous], CACTI 6 0 TOOL MODEL
   [Anonymous], 2016, 7 GREEN GRAPH 500 LI
   [Anonymous], 2016, JEDEC PUBLISHES HBM2
   [Anonymous], 2019, 6 NEW FACTS FACEBOOK
   [Anonymous], 2012, NVIDIAS NEXT GEN CUD
   [Anonymous], CORR
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Bell N., 2008, NVR2008004 NVIDIA CO
   Bell N., 2011, SIAM J SCI COMPUT
   Bender MA, 2010, THEOR COMPUT SYST, V47, P934, DOI 10.1007/s00224-010-9285-4
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Brin S., 1998, 7 INT WWW C
   Buluc A., INT J HIGH PERFORMAN
   Buluç A, 2008, 2008 IEEE INTERNATIONAL SYMPOSIUM ON PARALLEL & DISTRIBUTED PROCESSING, VOLS 1-8, P1876
   Byn Choi, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P155, DOI 10.1109/PACT.2011.21
   Chapanond A., 2005, Computational & Mathematical Organization Theory, V11, P265, DOI 10.1007/s10588-005-5381-4
   Dalton S, 2015, CUSP GENERIC PARALLE
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Gilbert J. R., COMPUTING SCI ENG, V10, P20
   Gilbert J. R., 2006, P INT WORKSH APPL PA
   Goumas G., 2008, PDP 08
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Hapla V., 2013, USE DIRECT SOLVERS T, P192
   Heinecke A. F., 2008, THESIS
   Intel Corporation, 2011, INT 64 IA 32 ARCH OP
   ITOH S, 1995, COMPUT PHYS COMMUN, V88, P173, DOI 10.1016/0010-4655(95)00031-A
   JOHNSON RW, 1991, J SUPERCOMPUT, V5, P189, DOI 10.1007/BF00127843
   Jouppi N. P., 1990, ISCA 90
   Kaplan H., 2006, Proceedings of the Twenty-Second Annual Symposium on Computational Geometry (SCG'06), P52, DOI 10.1145/1137856.1137866
   Karypis G., 1994, Proceedings Supercomputing '94 (Cat. No.94CH34819), P204, DOI 10.1109/SUPERC.1994.344280
   Kaxiras S., 2012, 2012 IEEE 25th International SOC Conference (SOCC), P230, DOI 10.1109/SOCC.2012.6398353
   Kaxiras S, 2010, IEEE MICRO, V30, P54, DOI 10.1109/MM.2010.82
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Lee E, 2016, IEEE T COMPUT, V65, P1145, DOI 10.1109/TC.2014.2349525
   Leskovec J., SNAP DATASETS STANFO
   Lin C. Y., 2010, P INT C FIELD PROGR, P369
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu WF, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.47
   Matam K., 2012, HIGH PERFORMANCE COM, P1
   Mishra AK, 2017, ASIA S PACIF DES AUT, P635, DOI 10.1109/ASPDAC.2017.7858395
   Murphy Richard C, 2010, INTRO GRAPH 500, V19, P45
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   Penn G, 2006, THEOR COMPUT SCI, V354, P72, DOI 10.1016/j.tcs.2005.11.008
   RABIN MO, 1989, J ALGORITHM, V10, P557, DOI 10.1016/0196-6774(89)90005-9
   Rupp K, 2016, SIAM J SCI COMPUT, V38, pS412, DOI 10.1137/15M1026419
   Satish N, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P979, DOI 10.1145/2588555.2610518
   Sewell K, 2012, IEEE J EM SEL TOP C, V2, P278, DOI 10.1109/JETCAS.2012.2193936
   Shah V, 2007, THESIS
   Sulatycke PD, 1998, FIRST MERGED INTERNATIONAL PARALLEL PROCESSING SYMPOSIUM & SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, P117, DOI 10.1109/IPPS.1998.669899
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Van De Geijn R. A., SUMMA SCALABLE UNIVE
   Van Dongen S., 2000, THESIS
   Vuduc RW., 2005, FAST SPARSE MATRIX V
   Yamazaki I, 2011, LECT NOTES COMPUT SC, V6449, P421, DOI 10.1007/978-3-642-19328-6_38
   Yavits Leonid, 2017, CORR
   Yuster R., 2004, SODA 04, V4, P254
NR 64
TC 109
Z9 110
U1 1
U2 4
PY 2018
BP 724
EP 736
DI 10.1109/HPCA.2018.00067
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Gulfidan, G
   Beklen, H
   Arga, KY
AF Gulfidan, Gizem
   Beklen, Hande
   Arga, Kazim Yalcin
TI Artificial Intelligence as Accelerator for Genomic Medicine and
   Planetary Health
SO OMICS-A JOURNAL OF INTEGRATIVE BIOLOGY
DT Review
DE artificial intelligence; machine learning; deep learning; genomic
   medicine; planetary health; One Health; ecology
ID INTERNET; THINGS; DISCOVERY; GUIDE; OMICS
AB Genomic medicine has made important strides over the past several decades, but as new insights and technologies emerge, the applications of genomics in medicine and planetary health continue to evolve and expand. An important grand challenge is harnessing and making sense of the genomic big data in ways that best serve public and planetary health. Because human health is inextricably intertwined with the health of planetary ecosystems and nonhuman animals, genomic medicine is in need of high throughput bioinformatics analyses to harness and integrate human and ecological multiomics big data. It is in this overarching context that artificial intelligence (AI), particularly machine learning and deep learning, offers enormous potentials to advance genomic medicine in a spirit of One Health. This expert review offers an analysis of the rapidly emerging role of AI in genomic medicine, including its current drivers, levers, opportunities, and challenges. The scope of AI applications in genomic medicine is broad, ranging from efficient and automated data analysis to drug repurposing and precision medicine, as with its challenges such as veracity of the big data that AI sorely depends on, social biases that the AI-driven algorithms can introduce, and how best to incorporate AI with human intelligence. The road ahead for AI in genomic medicine is complex and arduous and yet worthy of cautious optimism as we face future pandemics and ecological crises in the 21st century. Now is a good time to think about the role of AI in genomic medicine and planetary health.
C1 [Gulfidan, Gizem; Beklen, Hande; Arga, Kazim Yalcin] Marmara Univ, Dept Bioengn, Istanbul, Turkey.
RP Arga, KY (corresponding author), Marmara Univ, Fac Engn, Dept Bioengn, Bldg D,Off 405, TR-34722 Istanbul, Turkey.
EM kazim.arga@marmara.edu.tr
CR Arga KY, 2021, J PERS MED, V11, DOI 10.3390/jpm11040271
   Arga KY, 2020, OMICS, V24, P512, DOI 10.1089/omi.2020.0093
   Arga KY, 2019, OMICS, V23, P460, DOI 10.1089/omi.2019.0131
   Baldoni J., 2020, J COMMERCIAL BIOTECH, V25, P42
   Char DS, 2018, NEW ENGL J MED, V378, P981, DOI 10.1056/NEJMp1714229
   Crandall SG, 2020, PLOS ONE, V15, DOI 10.1371/journal.pone.0237975
   Demirci DK, 2021, OMICS, V25, P431, DOI 10.1089/omi.2021.0081
   Dias R, 2019, GENOME MED, V11, DOI 10.1186/s13073-019-0689-8
   Ekins S, 2019, NAT MATER, V18, P435, DOI 10.1038/s41563-019-0338-z
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Gov E, 2016, IET SYST BIOL, V10, P219, DOI 10.1049/iet-syb.2016.0001
   Gulfidan G, 2021, OMICS, V25, P495, DOI 10.1089/omi.2021.0085
   Hasin Y, 2017, GENOME BIOL, V18, DOI 10.1186/s13059-017-1215-1
   Ho DSW, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00267
   Hutson M, 2018, SCIENCE, V359, P725, DOI 10.1126/science.359.6377.725
   Karczewski KJ, 2018, NAT REV GENET, V19, P299, DOI 10.1038/nrg.2018.4
   Kim HK, 2018, NAT BIOTECHNOL, V36, P239, DOI 10.1038/nbt.4061
   Ko Gunhwan, 2020, Genomics & Informatics, V18, pe8, DOI 10.5808/GI.2020.18.1.e8
   Koh EJ, 2019, MOL CELL TOXICOL, V15, P1, DOI 10.1007/s13273-019-0001-4
   Koromina M, 2019, OMICS, V23, P539, DOI 10.1089/omi.2019.0151
   Leenay RT, 2019, NAT BIOTECHNOL, V37, P1034, DOI 10.1038/s41587-019-0203-2
   Leung MKK, 2016, P IEEE, V104, P176, DOI 10.1109/JPROC.2015.2494198
   Lin BY, 2022, OMICS, V26, P77, DOI 10.1089/omi.2021.0037
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Norgeot B, 2019, NAT MED, V25, P14, DOI 10.1038/s41591-018-0320-3
   OIE, 2020, ONE HEALTH-AMSTERDAM, V1
   Özdemir V, 2020, TRANSL APPL GENOM, P275, DOI 10.1016/B978-0-12-813695-9.00015-7
   Özdemir V, 2019, OMICS, V23, P308, DOI 10.1089/omi.2019.0069
   Özdemir V, 2019, OMICS, V23, P67, DOI 10.1089/omi.2019.0003
   Özdemir V, 2018, OMICS, V22, P65, DOI 10.1089/omi.2017.0194
   Ozer ME, 2020, OMICS, V24, P241, DOI 10.1089/omi.2020.0001
   Sahraeian SME, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09027-x
   Shen MW, 2018, NATURE, V563, P646, DOI 10.1038/s41586-018-0686-x
   Shendure J, 2019, CELL, V177, P45, DOI 10.1016/j.cell.2019.02.003
   Sundaram L, 2018, NAT GENET, V50, P1161, DOI 10.1038/s41588-018-0167-z
   Topol EJ, 2019, NAT MED, V25, P44, DOI 10.1038/s41591-018-0300-7
   Turanli B, 2021, SEMIN CANCER BIOL, V68, P47, DOI 10.1016/j.semcancer.2019.09.020
   Turanli B, 2019, FRONT GENET, V10, DOI 10.3389/fgene.2019.00420
   Turanli B, 2018, CURR PHARM DESIGN, V24, P3778, DOI 10.2174/1381612824666181106095959
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Way GP, 2018, NAT METHODS, V15, P1009, DOI 10.1038/s41592-018-0230-9
   Zafeiris D, 2018, COMPUT STRUCT BIOTEC, V16, P77, DOI 10.1016/j.csbj.2018.02.001
   Zitnik M, 2019, INFORM FUSION, V50, P71, DOI 10.1016/j.inffus.2018.09.012
NR 43
TC 5
Z9 5
U1 3
U2 18
PD DEC 21
PY 2021
VL 25
IS 12
BP 745
EP 749
DI 10.1089/omi.2021.0170
EA NOV 2021
WC Biotechnology & Applied Microbiology; Genetics & Heredity
DA 2023-11-11
ER

PT C
AU Dev, S
   Lo, D
   Cheng, LQ
   Ranganathan, P
AF Dev, Sundar
   Lo, David
   Cheng, Liqun
   Ranganathan, Parthasarathy
GP IEEE
TI Autonomous Warehouse-Scale Computers
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE WSC; heterogeneity; machine learning; automation
AB Modern Warehouse-Scale Computers (WSCs), composed of many generations of servers and a myriad of domain specific accelerators, are becoming increasingly heterogeneous. Meanwhile, WSC workloads are also becoming incredibly diverse with different communication patterns, latency requirements, and service level objectives (SLOs). Insufficient understanding of the interactions between workload characteristics and the underlying machine architecture leads to resource over-provisioning, thereby significantly impacting the utilization of WSCs.
   We present Autonomous Warehouse-Scale Computers, a new WSC design that leverages machine learning techniques and automation to improve job scheduling, resource management, and hardware-software co-optimization to address the increasing heterogeneity in WSC hardware and workloads. Our new design introduces two new layers in the WSC stack, namely: (a) a Software-Defined Server (SDS) Abstraction Layer which redefines the hardware-software boundary and provides greater control of the hardware to higher layers of the software stack through stable abstractions; and (b) a WSC Efficiency Layer which regularly monitors the resource usage of workloads on different hardware types, autonomously quantifies the performance sensitivity of workloads to key system configurations, and continuously improves scheduling decisions and hardware resource QoS policies to maximize cluster level performance. Our new WSC design has been successfully deployed across all WSCs at Google for several years now. The new WSC design improves throughput of workloads (by 7-10%, on average), increases utilization of hardware resources (up to 2x), and reduces performance variance for critical workloads (up to 25%).
C1 [Dev, Sundar; Lo, David; Cheng, Liqun; Ranganathan, Parthasarathy] Google, Mountain View, CA 94043 USA.
RP Dev, S (corresponding author), Google, Mountain View, CA 94043 USA.
EM sundarjdev@google.com; davidlo@google.com; liquncheng@google.com;
   parthas@google.com
CR [Anonymous], 2018, SYNTHESIS LECT COMPU
   Asanovic K, 2009, COMMUN ACM, V52, P56, DOI 10.1145/1562764.1562783
   Ayers G, 2018, INT S HIGH PERF COMP, P643, DOI 10.1109/HPCA.2018.00061
   Delimitrou C, 2018, COMMUN ACM, V61, P65, DOI 10.1145/3232559
   Delimitrou C, 2013, ACM T COMPUT SYST, V31, DOI 10.1145/2556583
   Haque ME, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P625, DOI 10.1145/3123939.3123956
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Kasture H, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P598, DOI 10.1145/2830772.2830797
   Lo D, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P450, DOI 10.1145/2749469.2749475
   Lo D, 2014, CONF PROC INT SYMP C, P301, DOI 10.1109/ISCA.2014.6853237
   Lottarini A, 2018, ACM SIGPLAN NOTICES, V53, P797, DOI [10.1145/3296957.3173207, 10.1145/3173162.3173207]
   Prekas G, 2015, ACM SOCC'15: PROCEEDINGS OF THE SIXTH ACM SYMPOSIUM ON CLOUD COMPUTING, P342, DOI 10.1145/2806777.2806848
   Sriraman A, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P513, DOI 10.1145/3307650.3322227
   Volos S, 2017, IEEE MICRO, V37, P90, DOI 10.1109/MM.2017.32
   Weaver V., PERF EVENT PROGRAMMI
NR 16
TC 1
Z9 1
U1 0
U2 0
PY 2020
AR 76.1
DI 10.1109/dac18072.2020.9218509
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Langguth, J
   Cai, X
   Sourouri, M
AF Langguth, Johannes
   Cai, Xing
   Sourouri, Mohammed
GP IEEE
TI Memory Bandwidth Contention: Communication vs Computation Tradeoffs in
   Supercomputers with Multicore Architectures
SO 2018 IEEE 24TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED
   SYSTEMS (ICPADS 2018)
SE International Conference on Parallel and Distributed Systems -
   Proceedings
DT Proceedings Paper
CT 24th IEEE International Conference on Parallel and Distributed Systems
   (ICPADS)
CY DEC 11-13, 2018
CL Singapore, SINGAPORE
ID PERFORMANCE-MODEL; ROOFLINE
AB We study the problem of contention for memory bandwidth between computation and communication in super-computers that feature multicore CPUs. The problem arises when communication and computation are overlapped, and both operations compete for the same memory bandwidth. This contention is most visible at the limits of scalability, when communication and computation take similar amounts of time, and thus must be taken into account in order to reach maximum scalability in memory bandwidth bound applications. Typical examples of codes affected by the memory bandwidth contention problem are sparse matrix-vector computations, graph algorithms, and many machine learning problems, as they typically exhibit a high demand for both memory bandwidth and inter-node communication, while performing a relatively low number of arithmetic operations.
   The problem is even more relevant in truly heterogeneous computations where CPUs and accelerators are used in concert. In that case it can lead to mispredictions of expected performance and consequently to suboptimal load balancing between CPU and accelerator, which in turn can lead to idling of powerful accelerators and thus to a large decrease in performance.
   We propose a simple benchmark in order to quantify the loss of performance due to memory bandwidth contention. Based on that, we derive a theoretical model to determine the impact of the phenomenon on parallel memory-bound applications. We test the model on scientific computations, discuss the practical relevance of the problem and suggest possible techniques to remedy it.
C1 [Langguth, Johannes; Cai, Xing] Simula Res Lab, Dept High Performance Comp, Oslo, Norway.
   [Sourouri, Mohammed] Acando Norway, Oslo, Norway.
RP Langguth, J (corresponding author), Simula Res Lab, Dept High Performance Comp, Oslo, Norway.
EM langguth@simula.no; xingca@simula.no; mohammed.sourouri@acando.no
CR Bardhan S, 2015, IEEE T COMPUT, V64, P2279, DOI 10.1109/TC.2014.2361511
   Catalyurek U. V., 1995, P INT C HIGH PERF CO
   Choi J., 2014, P WORKSH GEN PURP PR
   Dauwe D, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P434, DOI 10.1109/IPDPSW.2015.38
   Doerfler D, 2016, LECT NOTES COMPUT SC, V9945, P339, DOI 10.1007/978-3-319-46079-6_24
   Kaiser T. H., 2001, Scientific Programming, V9, P73
   Langguth J, 2015, J PARALLEL DISTR COM, V76, P120, DOI 10.1016/j.jpdc.2014.10.005
   Langguth J, 2015, IEEE MICRO, V35, P6, DOI 10.1109/MM.2015.70
   Langguth J, 2014, INT C PAR DISTRIB SY, P191, DOI 10.1109/PADSW.2014.7097808
   Liu JX, 2004, IEEE MICRO, V24, P42, DOI 10.1109/MM.2004.1268994
   McCalpin John D., 1995, IEEE COMPUTER SOC TE, P19
   Pfister G., 2001, INTRO INFINIBAND ARC
   Putigny B, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P943, DOI 10.1109/HPCSim.2014.6903790
   Rupp K., CPU GPU MIC HARDWARE
   Sanders Peter, 2013, Experimental Algorithms 12th International Symposium, SEA 2013. Proceedings, P164, DOI 10.1007/978-3-642-38527-8_16
   Shimokawabe T., 2011, P 2011 INT C HIGH PE, P3, DOI 10.1145/2063384.2063388
   Si M, 2015, INT PARALL DISTRIB P, P665, DOI 10.1109/IPDPS.2015.35
   Sourouri M, 2017, INT J PARALLEL PROG, V45, P711, DOI 10.1007/s10766-016-0454-1
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wu XF, 2013, J COMPUT SYST SCI, V79, P1256, DOI 10.1016/j.jcss.2013.02.005
   Zhou J, 2013, PROCEDIA COMPUT SCI, V18, P1255, DOI 10.1016/j.procs.2013.05.292
NR 21
TC 7
Z9 7
U1 1
U2 4
PY 2018
BP 497
EP 506
DI 10.1109/ICPADS.2018.00072
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Hasse, K
   Scholey, J
   Ziemer, BP
   Natsuaki, Y
   Morin, O
   Solberg, TD
   Hirata, E
   Valdes, G
   Witztum, A
AF Hasse, K.
   Scholey, J.
   Ziemer, B. P.
   Natsuaki, Y.
   Morin, O.
   Solberg, T. D.
   Hirata, E.
   Valdes, G.
   Witztum, A.
TI Use of Receiver Operating Curve Analysis and Machine Learning With an
   Independent Dose Calculation System Reduces the Number of Physical Dose
   Measurements Required for Patient-Specific Quality Assurance
SO INTERNATIONAL JOURNAL OF RADIATION ONCOLOGY BIOLOGY PHYSICS
DT Article
ID IMRT QA; RADIATION ONCOLOGY
AB Purpose: Our purpose was to assess the use of machine learning methods and Mobius 3D (M3D) dose calculation software to reduce the number of physical ion chamber (IC) dose measurements required for patient-specific quality assurance during corona virus disease 2019.
   Methods and Materials: In this study, 1464 inversely planned treatments using Pinnacle or Raystation treatment planning software (TPS) were delivered using Elekta Versa HD and Varian Truebeam and Truebeam STx linear accelerators between June 2018 and November 2019. For each plan, an independent dose calculation was performed using M3D, and an absolute dose measurement was taken using a Pinpoint IC inside the Mobius phantom. The point dose differences between the TPS and M3D calculation and between TPS and IC measurements were calculated. Agreement between the TPS and IC was used to define the ground truth plan failure. To reduce the on-site personnel during the pandemic, 2 methods of receiver operating characteristic analysis (n = 1464) and machine learning (n = 603) were used to identify patient plans that would require physical dose measurements.
   Results: In the receiver operating characteristic analysis, a predelivery M3D difference threshold of 3% identified plans that failed an IC measurement at a 4% threshold with 100% sensitivity and 76.3% specificity. This indicates that fewer than 25% of plans required a physical dose measurement. A threshold of 1% on a machine learning model was able to identify plans that failed an IC measurement at a 3% threshold with 100% sensitivity and 54.3% specificity, leading to fewer than 50% of plans that required a physical dose measurement.
   Conclusions: It is possible to identify plans that are more likely to fail IC patient-specific quality assurance measurements before delivery. This possibly allows for a reduction of physical measurements taken, freeing up significant clinical resources and reducing the required amount of on-site personnel while maintaining patient safety. Published by Elsevier Inc.
C1 [Hasse, K.; Scholey, J.; Ziemer, B. P.; Natsuaki, Y.; Morin, O.; Hirata, E.; Valdes, G.; Witztum, A.] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
   [Solberg, T. D.] US FDA, Washington, DC 20204 USA.
RP Hasse, K (corresponding author), Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA 94143 USA.
EM Katelyn.hasse@ucsf.edu
CR [Anonymous], 1984, CLASSIFICATION REGRE, DOI DOI 10.1201/9781315139470
   DeLuca PM, 2008, J ICRU, V8
   Dunn L, 2018, J APPL CLIN MED PHYS, V19, P739, DOI 10.1002/acm2.12396
   Friedman J, RULEFIT R
   Harris PA, 2009, J BIOMED INFORM, V42, P377, DOI 10.1016/j.jbi.2008.08.010
   Hernandez V, 2018, PHYS IMAG RADIAT ONC, V5, P37, DOI 10.1016/j.phro.2018.02.002
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Japkowicz N., 2015, MACHINE LEARNING RAD, DOI 10.1007/978-3-319-18305-3_4
   Kerns JR, 2017, INT J RADIAT ONCOL, V98, P1197, DOI 10.1016/j.ijrobp.2017.03.049
   Kry SF, 2019, MED PHYS, V46, P3700, DOI 10.1002/mp.13638
   KUTCHER GJ, 1994, MED PHYS, V21, P581, DOI 10.1118/1.597316
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Luna JM, 2019, P NATL ACAD SCI USA, V116, P19887, DOI 10.1073/pnas.1816748116
   Nakaguchi Y, 2019, RADIOL PHYS TECHNOL, V12, P126, DOI 10.1007/s12194-019-00499-6
   Potter NJ, 2020, MED PHYS, V47, P4711, DOI 10.1002/mp.14416
   Schroeder L.D., 1986, UNDERSTANDING REGRES
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Valdes G, 2016, SCI REP-UK, V6, DOI 10.1038/srep37854
NR 20
TC 5
Z9 5
U1 0
U2 9
PD MAR 15
PY 2021
VL 109
IS 4
BP 1086
EP 1095
DI 10.1016/j.ijrobp.2020.10.035
EA FEB 2021
WC Oncology; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Zhou, XY
   An, K
   Ma, WJ
AF Zhou, Xiangyu
   An, Kun
   Ma, Wanjing
TI Data-Driven Approach for Estimating Energy Consumption of Electric Buses
   under On-Road Operation Conditions
SO JOURNAL OF TRANSPORTATION ENGINEERING PART A-SYSTEMS
DT Article
DE Electric buses; Energy consumption; Four states; Instantaneous power
ID CARBON EMISSIONS; VEHICLE; SIMULATION; MODEL
AB The transformation of diesel buses into battery-powered electric buses for public transportation has become a global trend. The ability to evaluate the energy consumption of electric buses is critical in bus scheduling for alleviating range anxiety. In this study, an energy consumption estimation model for electric buses was proposed based on actual bus operation data. The operating states of an electric bus were categorized into four types: depressed accelerator pedal, depressed brake pedal, vehicle sliding, and vehicle idle states. Based on the bus state, two models were constructed to estimate the energy consumption. A multivariate linear model based on vehicle speed, accelerator pedal position, and instantaneous power was constructed to estimate the energy consumption of buses in the depressed accelerator pedal state. Combining that model with a long short-term memory (LSTM) algorithm, machine learning algorithms were calibrated to estimate bus energy consumption in the other three states over the four seasons. A comparative analysis was conducted for the different algorithms. The root-mean-square errors of the estimation results based on LSTM for vehicles in the depressed brake pedal, vehicle sliding, and vehicle idle states were 0.12%, 0.03%, and 27.27% lower than those of the artificial neural network, respectively. Accurate estimations of bus energy consumption during the four seasons allow bus operation companies to adjust the bus charging schedule to reduce the operating costs.
C1 [Zhou, Xiangyu; An, Kun; Ma, Wanjing] Tongji Univ, Key Lab Rd & Traff Engn, Minist Educ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
RP An, K (corresponding author), Tongji Univ, Key Lab Rd & Traff Engn, Minist Educ, 4800 Caoan Rd, Shanghai 201804, Peoples R China.
EM 2010796@tongji.edu.cn; kunan@tongji.edu.cn; mawanjing@tongji.edu.cn
CR Abdelaty H, 2021, TRANSPORT RES D-TR E, V96, DOI 10.1016/j.trd.2021.102868
   Al-Ogaili AS, 2020, APPL ENERG, V280, DOI 10.1016/j.apenergy.2020.115873
   Al-Wreikat Y, 2021, APPL ENERG, V297, DOI 10.1016/j.apenergy.2021.117096
   Badin F, 1996, SCI TOTAL ENVIRON, V189, P125, DOI 10.1016/0048-9697(96)05200-X
   Chen YC, 2021, TRANSPORT RES D-TR E, V98, DOI 10.1016/j.trd.2021.102969
   Duarte GO, 2015, ENERG CONVERS MANAGE, V92, P251, DOI 10.1016/j.enconman.2014.12.042
   Ercan T, 2022, TRANSPORT RES D-TR E, V112, DOI 10.1016/j.trd.2022.103472
   Gallet M, 2018, APPL ENERG, V230, P344, DOI 10.1016/j.apenergy.2018.08.086
   Gao ZM, 2017, ENERGY, V122, P588, DOI 10.1016/j.energy.2017.01.101
   Genikomsakis KN, 2017, TRANSPORT RES D-TR E, V50, P98, DOI 10.1016/j.trd.2016.10.014
   Hao X, 2020, J CLEAN PROD, V249, DOI 10.1016/j.jclepro.2019.119403
   Hjelkrem OA, 2021, TRANSPORT RES D-TR E, V94, DOI 10.1016/j.trd.2021.102804
   Hu XS, 2020, PROG ENERG COMBUST, V77, DOI 10.1016/j.pecs.2019.100806
   IEA (International Energy Agency), 2022, IMPR SUST PASS FREIG
   Jiang JY, 2023, ENERGY, V263, DOI 10.1016/j.energy.2022.125866
   Klingler AL, 2018, ENERGY, V161, P1064, DOI 10.1016/j.energy.2018.07.210
   Li PS, 2021, APPL ENERG, V298, DOI 10.1016/j.apenergy.2021.117204
   Liu K, 2018, APPL ENERG, V227, P324, DOI 10.1016/j.apenergy.2017.08.074
   Luna TF, 2020, TRANSPORT RES D-TR E, V79, DOI 10.1016/j.trd.2020.102226
   Ma XL, 2021, ENERGY, V216, DOI 10.1016/j.energy.2020.119196
   Mamarikas S, 2022, TRANSPORT RES D-TR E, V105, DOI 10.1016/j.trd.2022.103231
   McGrath T, 2022, TRANSPORT RES D-TR E, V109, DOI 10.1016/j.trd.2022.103373
   Mohamed M, 2017, ELECTR POW SYST RES, V142, P163, DOI 10.1016/j.epsr.2016.09.032
   Moro A, 2018, TRANSPORT RES D-TR E, V64, P5, DOI 10.1016/j.trd.2017.07.012
   Nan SR, 2022, ENERGY, V261, DOI 10.1016/j.energy.2022.125188
   Qi XW, 2018, TRANSPORT RES D-TR E, V64, P36, DOI 10.1016/j.trd.2017.08.008
   Ritter A, 2021, IEEE T VEH TECHNOL, V70, P5483, DOI 10.1109/TVT.2021.3077063
   Song YL, 2022, APPL ENERG, V305, DOI 10.1016/j.apenergy.2021.117830
   Sun J, 2021, TRANSPORT RES C-EMER, V128, DOI 10.1016/j.trc.2021.103114
   Szilassy PA, 2022, ENERGY, V261, DOI 10.1016/j.energy.2022.125080
   Wang H, 2020, TRANSPORT RES A-POL, V132, P30, DOI 10.1016/j.tra.2019.10.010
   Xie YK, 2020, APPL ENERG, V267, DOI 10.1016/j.apenergy.2020.115081
   Xu XD, 2019, TRANSPORT RES D-TR E, V75, P249, DOI 10.1016/j.trd.2019.09.001
   Yuan XM, 2017, ENERGY, V141, P1955, DOI 10.1016/j.energy.2017.11.134
   Zhang J, 2020, APPL ENERG, V275, DOI 10.1016/j.apenergy.2020.115408
   Zhang R, 2015, TRANSPORT RES D-TR E, V41, P177, DOI 10.1016/j.trd.2015.10.010
   Zhang ZQ, 2017, APPL THERM ENG, V125, P567, DOI 10.1016/j.applthermaleng.2017.07.032
NR 37
TC 0
Z9 0
U1 6
U2 6
PD SEP 1
PY 2023
VL 149
IS 9
AR 04023089
DI 10.1061/JTEPBS.TEENG-7901
WC Engineering, Civil; Transportation Science & Technology
DA 2023-11-11
ER

PT J
AU Kljucaric, L
   George, AD
AF Kljucaric, Luke
   George, Alan D.
TI Deep Learning Inferencing with High-performance Hardware Accelerators
SO ACM TRANSACTIONS ON INTELLIGENT SYSTEMS AND TECHNOLOGY
DT Article
DE Neural networks; machine learning; FPGA; inference
AB As computer architectures continue to integrate application-specific hardware, it is critical to understand the relative performance of devices for maximum app acceleration. The goal of benchmarking suites, such as MLPerf for analyzing machine learning (ML) hardware performance, is to standardize a fair comparison of different hardware architectures. However, there are many apps that are not well represented by these standards that require different workloads, such asMLmodels and datasets, to achieve similar goals. Additionally, many apps, like real-time video processing, are focused on latency of computations rather than strictly on throughput. This research analyzes multiple compute architectures that featureML-specific hardware on a case study of handwritten Chinese character recognition. Specifically, AlexNet and a custom version of GoogLeNet are benchmarked in terms of their streaming latency and maximum throughput for optical character recognition. Considering that these models are composed of fundamental neural network operations yet architecturally different from each other, these models can stress devices in different yet insightful ways that generalizations of the performance of other models can be drawn from. Many devices featuring ML-specific hardware and optimizations are analyzed including Intel and AMD CPUs, Xilinx and Intel FPGAs, NVIDIA GPUs, and Google TPUs. Overall, ML-oriented hardware added to the Intel Xeon CPUs helps to boost throughput by 3.7x and to reduce latency by up to 34.7x, which makes the latency of Intel Xeon CPUs competitive on more parallel models. The TPU devices were limited in terms of throughput due to large data transfer times and not competitive in terms of latency. The FPGA frameworks showcase the lowest latency on the Xilinx Alveo U200 FPGA achieving 0.48 ms on AlexNet using Mipsology Zebra and 0.39 ms on GoogLeNet using Vitis-AI. Through their custom acceleration datapaths coupled with high-performance SRAM, the FPGAs are able to keep critical model data closer to processing elements for lower latency. The massively parallel and high-memory GPU devices with Tensor Core accelerators achieve the best throughput. The NVIDIA Tesla A100 GPU showcases the highest throughput at 42,513 and 52,484 images/second for AlexNet and GoogLeNet, respectively.
C1 [Kljucaric, Luke; George, Alan D.] Univ Pittsburgh, ECE Dept, NSF SHREC Ctr, 4420 Bayard St,Suite 560, Pittsburgh, PA 15213 USA.
RP Kljucaric, L (corresponding author), Univ Pittsburgh, ECE Dept, NSF SHREC Ctr, 4420 Bayard St,Suite 560, Pittsburgh, PA 15213 USA.
EM kljucaricu@pitt.edu; alan.george@pitt.edu
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Abadi M., 2015, TENSORFLOW LARGE SCA
   AMD, 2022, 2 GEN AMD EPYC 7702
   Delaye Elliot, 2018, INTEGRATING AI YOUR
   Deng L, 2013, FOUND TRENDS SIGNAL, V7, pI, DOI 10.1561/2000000039
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Egmont-Petersen M, 2002, PATTERN RECOGN, V35, P2279, DOI 10.1016/S0031-3203(01)00178-9
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Fowers J., 2012, ACM SIGDA INT S FIEL
   Glorot X., 2011, INT C ART INT STAT P, V14
   Google, 2022, TROUBL TENSORFLOW TP
   Google Cloud, 2022, CLOUD TPU SYST ARCH
   Google Cloud, 2022, CLOUD TPU BREAKS SCA
   Intel, 2022, ONEDNN V2 7 0 DOC
   Intel, 2022, INT STRAT 10 NX 2100
   Intel, 2022, INT FPGA DEEP LEARN
   Intel, 2022, INT XEON PLAT 8180 P
   Intel, 2022, ENH ART INT AI WORKL
   Intel, 2022, INT PROGR ACC CARD P
   Intel, 2022, OPENVINO DOC
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Judd P, 2016, Arxiv, DOI arXiv:1511.05236
   Kljucaric L, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286209
   Kljucaric L, 2019, IEEE HIGH PERF EXTR
   Kochura Y, 2018, Arxiv, DOI arXiv:1812.11731
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lai SX, 2017, PATTERN RECOGN LETT, V89, P60, DOI 10.1016/j.patrec.2017.02.011
   Lane ND, 2017, IEEE PERVAS COMPUT, V16, P82, DOI 10.1109/MPRV.2017.2940968
   Langerman D, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286182
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee S, 2020, MULTIMED TOOLS APPL, V79, P34195, DOI 10.1007/s11042-020-09054-7
   Mattson P, 2020, IEEE MICRO, V40, P8, DOI 10.1109/MM.2020.2974843
   Mipsology, 2022, ZEBRA ACCELERATES MA
   Morgan T. P., 2018, TEASINGOUT BANG BUCK
   NVIDIA, 2022, DEEP LEARN FRAM DOC
   NVIDIA, 2022, NVIDIA TENSORRT DOC
   NVIDIA, 2022, NVIDIA TESL V100 GPU
   NVIDIA, 2022, NVIDIA A10 TENS COR
   NVIDIA, 2022, NVIDIA T4 TENS COR G
   NVIDIA, 2022, NVIDIA A100 TENS COR
   NVIDIA, 2022, NVIDIA AMP GPU ARCH
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Pang B, 2020, J EDUC BEHAV STAT, V45, P227, DOI 10.3102/1076998619872761
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TensorFlow, 2022, EST TPU SUPP
   Tsochatzidis L, 2019, J IMAGING, V5, DOI 10.3390/jimaging5030037
   Wang N., 2018, C NEURAL INFORM PROC
   Wang S., 2022, BFLOAT16 SECRET HIGH
   Wenfei Liu, 2020, 2020 IEEE International Conference on Advances in Electrical Engineering and Computer Applications (AEECA), P587, DOI 10.1109/AEECA49918.2020.9213482
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Xie XF, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3417709
   Xilinx, 2022, AI INF ACC
   Xilinx, 2022, ALV U200 U250 DAT CT
   Xilinx, 2022, XIL POW EST XPE
   Xilinx, 2022, VIT AI US GUID UG141
   Yang CT, 2021, J SUPERCOMPUT, V77, P2486, DOI 10.1007/s11227-020-03362-3
   Yip MYT, 2020, NPJ DIGIT MED, V3, DOI 10.1038/s41746-020-0247-1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhong ZY, 2015, PROC INT CONF DOC, P846, DOI 10.1109/ICDAR.2015.7333881
NR 63
TC 0
Z9 0
U1 0
U2 0
PD AUG
PY 2023
VL 14
IS 4
AR 68
DI 10.1145/3594221
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT C
AU Pan, ZX
   Mishra, P
AF Pan, Zhixin
   Mishra, Prabhat
BE Bolchini, C
   Verbauwhede, I
   Vatajelu, I
TI Hardware Acceleration of Explainable Machine Learning
SO PROCEEDINGS OF THE 2022 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2022)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 25th Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 14-23, 2022
CL ELECTR NETWORK
AB Machine learning (ML) is successful in achieving human-level performance in various fields. However, it lacks the ability to explain an outcome due to its black-box nature. While recent efforts on explainable ML has received significant attention, the existing solutions are not applicable in real-time systems since they map interpretability as an optimization problem, which leads to numerous iterations of time-consuming complex computations. To make matters worse, existing implementations are not amenable for hardware-based acceleration. In this paper, we propose an efficient framework to enable acceleration of explainable ML procedure with hardware accelerators. We explore the effectiveness of both Tensor Processing Unit (TPU) and Graphics Processing Unit (GPU) based architectures in accelerating explainable ML. Specifically, this paper makes three important contributions. (1) To the best of our knowledge, our proposed work is the first attempt in enabling hardware acceleration of explainable ML. (2) Our proposed solution exploits the synergy between matrix convolution and Fourier transform, and therefore, it takes full advantage of TPU's inherent ability in accelerating matrix computations. (3) Our proposed approach can lead to real-time outcome interpretation. Extensive experimental evaluation demonstrates that proposed approach deployed on TPU can provide drastic improvement in interpretation time (39x on average) as well as energy efficiency (69x on average) compared to existing acceleration techniques.
C1 [Pan, Zhixin; Mishra, Prabhat] Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
RP Pan, ZX (corresponding author), Univ Florida, Dept Comp & Informat Sci & Engn, Gainesville, FL 32611 USA.
CR [Anonymous], 2017, RESIDUAL SQUEEZE VGG
   Civit-Masot J, 2019, IEEE ACCESS, V7, P142379, DOI 10.1109/ACCESS.2019.2944692
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lu T., 2020, ACCELERATING MRI REC
   Lu T., 2020, LARGE SCALE DISCRETE
   Lu TJ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286192
   Pan Z., 2021, DESIGN AUTOMA TION T
   Pan Z., 2021, HOST
   Pan Z., 2020, 2020 IEEE INT C HIGH, P1
   Pan ZX, 2021, ASIA S PACIF DES AUT, P408, DOI 10.1145/3394885.3431595
   Pan ZX, 2020, PR IEEE COMP DESIGN, P663, DOI 10.1109/ICCD50377.2020.00113
   Paszke A, 2019, ADV NEUR IN, V32
   Sato K, 2017, IN DEPTH LOOK GOOGLE
   Sengupta J, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P134, DOI [10.1109/AICAS48895.2020.9073867, 10.1109/aicas48895.2020.9073867]
   Sidea D., 2021, IEEE ACCESS, V9
   Yazdanbakhsh A., 2021, ARXIV PREPRINT ARXIV
NR 17
TC 4
Z9 4
U1 0
U2 0
PY 2022
BP 1127
EP 1130
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Industrial;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tan, GM
   Liu, JH
   Li, JJ
AF Tan, Guangming
   Liu, Junhong
   Li, Jiajia
TI Design and Implementation of Adaptive SpMV Library for Multicore and
   Many-Core Architecture
SO ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE
DT Article
DE Sparse matrix vector multiplication; auto-tuning; multicore; machine
   learning
ID MATRIX-VECTOR MULTIPLICATION; OPTIMIZATION; FORMAT
AB Sparse matrix vector multiplication (SpMV) is an important computational kernel in traditional highperformance computing and emerging data-intensive applications. Previous SpMV libraries are optimized by either application-specific or architecture-specific approaches but present difficulties for use in real applications. In this work, we develop an auto-tuning system (SMATER) to bridge the gap between specific optimizations and general-purpose use. SMATER provides programmers a unified interface based on the compressed sparse row (CSR) sparse matrix format by implicitly choosing the best format and fastest implementation for any input sparse matrix during runtime. SMATER leverages a machine-learning model and retargetable back-end library to quickly predict the optimal combination. Performance parameters are extracted from 2,386 matrices in the SuiteSparse matrix collection. The experiments show that SMATER achieves good performance (up to 10 times that of the Intel Math Kernel Library (MKL) on Intel E5-2680 v3) while being portable on state-of-the-art x86 multicore processors, NVIDIA GPUs, and Intel Xeon Phi accelerators. Compared with the Intel MKL library, SMATER runs faster by more than 2.5 times on average. We further demonstrate its adaptivity in an algebraic multigrid solver from the Hypre library and report greater than 20% performance improvement.
C1 [Tan, Guangming; Liu, Junhong] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Li, Jiajia] Georgia Inst Technol, Computat Sci & Engn, Atlanta, GA 30332 USA.
   [Tan, Guangming; Liu, Junhong] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
RP Tan, GM (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
EM tgm@ict.ac.cn; liujunhong@ncic.ac.cn; jiajiali@gatech.edu
CR [Anonymous], 2012, P 26 ACM INT C SUP I
   [Anonymous], 1994, TECHNICAL REPORT
   [Anonymous], 2016, P 2016 INT C SUP SER
   Ansel J, 2009, PLDI'09 PROCEEDINGS OF THE 2009 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P38, DOI 10.1145/1542476.1542481
   Anzt H, 2014, UTEECS14727
   Armstrong W, 2008, IEEE INT C CL COMP, P411, DOI 10.1109/CLUSTR.2008.4663802
   Beamer S, 2017, INT PARALL DISTRIB P, P820, DOI 10.1109/IPDPS.2017.112
   Bell N., 2008, NVR2008004 NVIDIA CO
   Belter G., 2009, 2009 SC Conference on High Performance Computing Networking, Storage and Analysis, DOI 10.1145/1654059.1654119
   Brin S, 1998, COMPUT NETWORKS ISDN, V30, P107, DOI 10.1016/S0169-7552(98)00110-X
   Brown Jed, 2012, ANL9511
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Byun J.-H., 2012, TECHNICAL REPORT
   Choi JW, 2010, PPOPP 2010: PROCEEDINGS OF THE 2010 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P115, DOI 10.1145/1693453.1693471
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Falgout RD, 2002, LECT NOTES COMPUT SC, V2331, P632
   Falgout RD, 2006, COMPUT SCI ENG, V8, P24, DOI 10.1109/MCSE.2006.105
   Filippone S, 2017, ACM T MATH SOFTWARE, V43, DOI 10.1145/3017994
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Grewe D., 2011, GPGPU 4 P 4 WORKSHOP, P12
   Heroux MA, 2005, ACM T MATH SOFTWARE, V31, P397, DOI 10.1145/1089014.1089021
   Hill M. D. Adam, 2005, INT THERMONUCLEAR EX
   Hou K., 2017, ICS 17
   Im EJ, 2004, INT J HIGH PERFORM C, V18, P135, DOI 10.1177/1094342004041296
   Intel, 2017, INT MATH KERN LIB
   Khairoutdinov MF, 2001, GEOPHYS RES LETT, V28, P3617, DOI 10.1029/2001GL013552
   Kourtis K, 2011, ACM SIGPLAN NOTICES, V46, P247, DOI 10.1145/2038037.1941587
   Kreutzer M, 2014, SIAM J SCI COMPUT, V36, pC401, DOI 10.1137/130930352
   Li JJ, 2017, INT PARALL DISTRIB P, P1048, DOI 10.1109/IPDPS.2017.80
   Li JJ, 2013, ACM SIGPLAN NOTICES, V48, P117, DOI 10.1145/2499370.2462181
   Li JF, 2015, ACSR ADV COMPUT, V24, P76
   Liu CX, 2018, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2018), P363, DOI 10.1145/3205289.3205313
   Liu J., 2018, ACM T PARALLEL COMPU
   Liu JH, 2018, ACM SIGPLAN NOTICES, V53, P407, DOI 10.1145/3200691.3178529
   Liu WF, 2017, CONCURR COMP-PRACT E, V29, DOI 10.1002/cpe.4244
   Liu WF, 2015, PARALLEL COMPUT, V49, P179, DOI 10.1016/j.parco.2015.04.004
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Liu WF, 2015, J PARALLEL DISTR COM, V85, P47, DOI 10.1016/j.jpdc.2015.06.010
   Liu Weifeng, 2015, THESIS
   Liu Xing, 2013, P 27 INT ACM C INT C, P273, DOI DOI 10.1145/2464996.2465013
   Maggioni M, 2016, J PARALLEL DISTR COM, V93-94, P66, DOI 10.1016/j.jpdc.2016.03.011
   Monakov A, 2010, LECT NOTES COMPUT SC, V5952, P111, DOI 10.1007/978-3-642-11515-8_10
   Nagar KK, 2011, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2011.60
   Nagasaka Y, 2016, PROCEDIA COMPUT SCI, V80, P131, DOI 10.1016/j.procs.2016.05.304
   Neelima B., 2014, 2014 IEEE 28th International Parallel & Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P1427, DOI 10.1109/IPDPSW.2014.160
   Nikita S, 2011, ACM SIGKDD EXPLOR NE, V13, P50, DOI [DOI 10.1145/2207243.2207252, 10.1145/2207243.2207252]
   NVIDIA, 2010, CUDA CUSPARSE LIB
   Püschel M, 2005, P IEEE, V93, P232, DOI 10.1109/JPROC.2004.840306
   RuleQuest Research, 2012, DAT MIN TOOLS SEE5 C
   Sedaghati N, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P99, DOI 10.1145/2751205.2751244
   Srinivasa Avinash, 2012, P 2012 S HIGH PERF C
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Sun XZ, 2011, LECT NOTES COMPUT SC, V6853, P316, DOI 10.1007/978-3-642-23397-5_32
   Vuduc R, 2005, J PHYS CONF SER, V16, P521, DOI 10.1088/1742-6596/16/1/071
   Vuduc RW, 2005, LECT NOTES COMPUT SC, V3726, P807
   Wang XL, 2018, ACM SIGPLAN NOTICES, V53, P338, DOI 10.1145/3200691.3178513
   Whaley R Clinton, 1998, P 1998 ACMIEEE C SUP, P38, DOI [10.5555/509058.509096, DOI 10.1109/SC.1998.10004]
   Williams S, 2009, PARALLEL COMPUT, V35, P178, DOI 10.1016/j.parco.2008.12.006
   Xie BW, 2018, INT SYM CODE GENER, P149, DOI 10.1145/3168818
   Yan SG, 2014, ACM SIGPLAN NOTICES, V49, P107, DOI [10.1145/2692916.2555255, 10.1145/2555243.2555255]
   Yang XT, 2011, PROC VLDB ENDOW, V4, P231, DOI 10.14778/1938545.1938548
   Yotov K, 2005, P IEEE, V93, P358, DOI 10.1109/JPROC.2004.840444
   Zhao Y, 2018, ACM SIGPLAN NOTICES, V53, P94, DOI 10.1145/3200691.3178495
NR 63
TC 23
Z9 23
U1 1
U2 21
PD AUG
PY 2018
VL 44
IS 4
AR 46
DI 10.1145/3218823
WC Computer Science, Software Engineering; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Zhu, ZY
   Ulseth, J
   Li, GF
   Pang, S
AF Zhu, Zheyuan
   Ulseth, Joseph
   Li, Guifang
   Pang, Shuo
TI Training of Mixed-Signal Optical Convolutional Neural Networks With
   Reduced Quantization Levels
SO IEEE ACCESS
DT Article
DE Training; Tensors; Quantization (signal); Convolution; Computational
   modeling; Acceleration; Digital computers; Neural network; mixed-signal
   training; analog computation
AB Analog computing paradigms are promising solutions to the growing computational demands of machine learning applications. Despite being susceptible to errors, analog and mixed-signal platforms have the potential to achieve higher speed and power efficiency for artificial neural network (ANN) applications than digital computers. Driven by the development of digital fixed-point ANN accelerators, low-precision ANN models have proven to be successful in compressing the size of ANNs and conforming the models to the data format of digital accelerators. While the inputs and weights of these digital, fixed-point ANN models can have low bit widths, the intermediate results (e.g., activations) must be preserved in high precision. As a result, these digital fixed-point models and training algorithms cannot be migrated easily to analog accelerators, because the analog intermediate results typically suffer from reduced precision due to noises and device imperfections. Here, we report on a training method for mixed-signal ANNs that considers two types of analog impairments, namely, random noise and distortion (deterministic in nature). The results show that mixed-signal ANN trained with our method can achieve the same classification accuracy as the digital fixed-point model with noise levels up to 50% of the ideal quantization step size. We demonstrate our training method on a mixed-signal, convolutional neural network based on diffractive optics.
C1 [Zhu, Zheyuan; Ulseth, Joseph; Li, Guifang; Pang, Shuo] Univ Cent Florida, CREOL, Coll Opt & Photon, Orlando, FL 32816 USA.
RP Zhu, ZY (corresponding author), Univ Cent Florida, CREOL, Coll Opt & Photon, Orlando, FL 32816 USA.
EM zyzhu@knights.ucf.edu
CR [Anonymous], 2017, ARXIV170709870
   Bengio Yoshua, 2013, ESTIMATING PROPAGATI
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108
   Cai Y, 2018, ASIA S PACIF DES AUT, P117, DOI 10.1109/ASPDAC.2018.8297292
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Choi J., 2018, ARXIV180506085, P1, DOI DOI 10.23919/PANPACIFIC.2018.8319019
   Collobert R., 2008, P 25 ICML, P160, DOI [DOI 10.1145/1390156.1390177, 10.1145/1390156.1390177]
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Fan Angela, 2020, ARXIV200407320
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hubara I, 2018, J MACH LEARN RES, V18
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung S, 2019, PROC CVPR IEEE, P4345, DOI 10.1109/CVPR.2019.00448
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Mellempudi N., 2017, ARXIV170501462
   Mendlovic D, 1997, APPL OPTICS, V36, P8427, DOI 10.1364/AO.36.008427
   Moon S, 2019, IEEE T VLSI SYST, V27, P1455, DOI 10.1109/TVLSI.2019.2893256
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Saleh B., 2007, FUNDAMENTALS PHOTONI
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silver D, 2018, SCIENCE, V362, P1140, DOI 10.1126/science.aar6404
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Yan T, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.023901
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Zhou S., 2016, ARXIV160606160
   Zisserman A., 2014, 14091556 ARXIV
NR 33
TC 0
Z9 0
U1 0
U2 4
PY 2021
VL 9
BP 56645
EP 56652
DI 10.1109/ACCESS.2021.3072193
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Hayat, A
   Khalid, YN
   Rathore, MS
   Nadir, MN
AF Hayat, Asad
   Khalid, Yasir Noman
   Rathore, Muhammad Siraj
   Nadir, Muhammad Nadeem
TI A machine learning-based resource-efficient task scheduler for
   heterogeneous computer systems
SO JOURNAL OF SUPERCOMPUTING
DT Article
DE Heterogeneous computing; Machine learning; Gradient boosting; Work
   stealing; OpenCL
ID TIME
AB Heterogeneous computer systems are becoming mainstream due to their disparate processing and performance capabilities. These systems consist of different types of devices, i.e., central processing units (CPUs), accelerators, and graphics processing units (GPUs). In the heterogeneous computing environment, if one device is more powerful in terms of computing capability, the scheduling schemes generally favor the powerful device, and that device becomes overloaded, while the other device is underutilized. This load imbalance problem results in increased execution time. In this research, we propose load-balanced task scheduler combined with machine learning-based device predictor. The device predictor is used to predict execution time both on CPU and GPU devices, and a device with shorter predicted execution time is considered as a suitable device for that particular task. However, it may happen that a high fraction of tasks map only on one type of device since that device is considered as a suitable device for them. It is due to the fact that a task is mapped to one device (with lower predicted execution time), although it can be executed on the other device as well. In this context, one device may become overloaded, while the other device may be underutilized. To solve this problem of load imbalance, we use work-stealing-based task scheduler as part of our solution that allows an idle device to process tasks from the queue of another's device. In this way, we can avoid load imbalance, minimize the overall execution time of tasks, and maximize the device utilization and throughput. We evaluate the performance of our proposed solution into two stages. Firstly, we measure the error rate of our machine learning predictor using three different algorithms (i.e., random forest, gradient boosting, and multiple linear regression). We demonstrate that random forest performs better with marginal error rate. Secondly, we compare the performance of work-stealing task scheduler with other scheduling alternatives. Our results show that the proposed solution reduces execution time by 65.63%, increased resource utilization by 93.3%, and throughput by 65.5% in comparison with baseline scheduling schemes.
C1 [Rathore, Muhammad Siraj] Capital Univ Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
   [Nadir, Muhammad Nadeem] Univ Lahore, Dept Comp Sci, Lahore, Pakistan.
   [Khalid, Yasir Noman] Hitech Univ, Dept Comp Sci, Taxila, Pakistan.
   [Hayat, Asad] Lahore Leads Univ, Dept Comp Sci, Lahore, Pakistan.
RP Rathore, MS (corresponding author), Capital Univ Sci & Technol, Dept Comp Sci, Islamabad 44000, Pakistan.
EM asad.cs@leads.edu.pk; yasir.noman.khalid@hitecuni.edu.pk;
   muhammad.siraj@cust.edu.pk; nadeem.nadir@cs.uol.edu.pk
CR Agostini M, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404433
   Ahmed U, 2021, SOFT COMPUT, V25, P407, DOI 10.1007/s00500-020-05152-8
   Alsubaihi S, 2017, IEEE SYM PARA DISTR, P994, DOI 10.1109/IPDPSW.2017.19
   Becchi M, 2010, SPAA '10: PROCEEDINGS OF THE TWENTY-SECOND ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P82
   Belviranli ME, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400716
   Boyer M, 2013, LOAD BALANCING CHANG, DOI [10.1145/2482767.2482794, DOI 10.1145/2482767.2482794]
   Choi HJ, 2013, J SUPERCOMPUT, V65, P886, DOI 10.1007/s11227-013-0870-6
   Chose A, 2017, PARALLEL PROCESS LET, V27, DOI 10.1142/S0129626417500086
   Daga M., 2011, Proceedings of the 2011 Symposium on Application Accelerators in High-Performance Computing (SAAHPC 2011), P141, DOI 10.1109/SAAHPC.2011.29
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Huchant P, 2016, LECT NOTES COMPUT SC, V9833, P684, DOI 10.1007/978-3-319-43659-3_50
   Kaleem R, 2014, INT CONFER PARA, P151, DOI 10.1145/2628071.2628088
   Khalid YN, 2019, J PARALLEL DISTR COM, V132, P79, DOI 10.1016/j.jpdc.2019.05.015
   Khalid YN, 2018, J SUPERCOMPUT, V74, P5399, DOI 10.1007/s11227-018-2435-1
   Kreiliger Flavio, 2019, OSPERT, P23
   Kumar Varun, 2015, 2015 IEEE Sensors. Proceedings, P1, DOI 10.1109/ICSENS.2015.7370304
   Lee J, 2015, INT CONFER PARA, P355, DOI 10.1109/PACT.2015.14
   Lee J, 2015, ACM T COMPUT SYST, V33, DOI 10.1145/2798725
   Liu X, 2020, J AMB INTEL HUM COMP, V11, P2309, DOI 10.1007/s12652-019-01357-4
   Manathunga M, 2023, J CHEM INF MODEL, DOI 10.1021/acs.jcim.2c01505
   Memeti S, 2021, COMPUTING, V103, P2943, DOI 10.1007/s00607-021-01017-6
   Memeti S, 2018, IEEE INT C COMPUT, P138, DOI 10.1109/CSE.2018.00026
   Moren K, 2018, LECT NOTES COMPUT SC, V10861, P301, DOI 10.1007/978-3-319-93701-4_23
   Munshi A., 2009, 2009 IEEE HOT CHIPS, P1
   Noman Khalid Y, CONCURR COMP-PRACT E, DOI [10.1002/cpe.5606, DOI 10.1002/CPE.5606]
   Nozal R, 2020, FUTURE GENER COMP SY, V107, P522, DOI 10.1016/j.future.2020.02.016
   Öz I, 2022, J SUPERCOMPUT, V78, P4095, DOI 10.1007/s11227-021-04026-6
   Rahmani TA, 2022, 2022 INT C INN INT I, P674, DOI [10.1109/3ICT56508.2022.9990623, DOI 10.1109/3ICT56508.2022.9990623]
   Taylor B, 2017, ACM SIGPLAN NOTICES, V52, P11, DOI [10.1145/3078633.3081040, 10.1145/3140582.3081040]
   Tsog N, 2019, IEEE IND ELEC, P4516, DOI 10.1109/IECON.2019.8926767
   Wang Y, 2013, WORK STEALING SCHEDU, DOI [10.7873/date.2013.150, DOI 10.7873/DATE.2013.150]
   Wang YQ, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL WORKSHOP ON COMPUTER SCIENCE IN SPORTS, P103
   WANG Z, 2018, MACHINE LEARNING COM, DOI DOI 10.1109/JPROC.2018.2817118
   Weinhardt M, 2022, IEEE SYM PARA DISTR, P647, DOI 10.1109/IPDPSW55747.2022.00114
   Wen Y, 2014, SMART MULTI TASK SCH, DOI [10.1109/HiPC.2014.7116910, DOI 10.1109/HIPC.2014.7116910]
   Wen Y, 2017, PROCEEDINGS OF THE GENERAL PURPOSE GPUS (GPGPU-10), P22, DOI 10.1145/3038228.3038235
   Wenjie T, 2017, WORK STEALING BASED, DOI [10.1109/WSC.2017.8247833, DOI 10.1109/WSC.2017.8247833]
NR 37
TC 0
Z9 0
U1 0
U2 1
PD SEP
PY 2023
VL 79
IS 14
BP 15700
EP 15728
DI 10.1007/s11227-023-05266-4
EA APR 2023
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Yuan, YF
   Huang, JH
   Sun, Y
   Wang, TC
   Nelson, J
   Ports, DRK
   Wang, YP
   Wang, R
   Tai, C
   Kim, NS
AF Yuan, Yifan
   Huang, Jinghan
   Sun, Yan
   Wang, Tianchen
   Nelson, Jacob
   Ports, Dan R. K.
   Wang, Yipeng
   Wang, Ren
   Tai, Charlie
   Kim, Nam Sung
GP IEEE
TI RAMBDA: RDMA-driven Acceleration Framework for Memory-intensive
   <i>μ</i>s-scale Datacenter Applications
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
DE cache-coherent interconnects and accelerators; RDMA; heterogeneous and
   disaggregated memory; datacenters
AB Responding to the "datacenter tax" and "killer microseconds" problems for memory-intensive datacenter applications, diverse solutions including Smart NIC-based ones have been proposed. Nonetheless, they often suffer from high overhead of communications over network and/or PCIe links. To tackle the limitations of the current solutions, this paper proposes RAMBDA, a holistic network and architecture co-design solution that leverages current RDMA and emerging cache-coherent off-chip interconnect technologies. Specifically, RAMBDA consists of four hardware and software components: (1) unified abstraction of inter- and intra-machine communications synergistically managed by one-sided RDMA write and cache-coherent memory write; (2) efficient notification of requests to accelerators assisted by cache coherence; (3) cache-coherent accelerator architecture directly interacting with NIC; and (4) adaptive device-to-host data transfer for modern server memory systems comprising both DRAM and NVM exploiting state-of-the-art features in CPUs and PCIe. We prototype RAMBDA with a commercial system and evaluate three popular datacenter applications: (1) in-memory key-value store, (2) chain replication-based distributed transaction system, and (3) deep learning recommendation model inference. The evaluation shows that RAMBDA provides 30.1 similar to 69.1% lower latency, 0.2 similar to 2.5x throughput, and similar to 3x higher energy efficiency than the current state-of-the-art solutions, including Smart NIC. For those cases where RAMBDA performs poorly, we also envision future architecture to improve it.
C1 [Yuan, Yifan; Huang, Jinghan; Sun, Yan; Wang, Tianchen; Kim, Nam Sung] Univ Illinois, Champaign, IL 61820 USA.
   [Yuan, Yifan; Wang, Yipeng; Wang, Ren; Tai, Charlie] Intel Labs, Santa Clara, CA 95054 USA.
   [Nelson, Jacob; Ports, Dan R. K.] Microsoft Res, New York, NY USA.
RP Yuan, YF (corresponding author), Univ Illinois, Champaign, IL 61820 USA.; Yuan, YF (corresponding author), Intel Labs, Santa Clara, CA 95054 USA.
EM yifan.yuan@intel.com; jinghan4@illinois.edu; yans3@illinois.edu;
   tw12@illinois.edu; jacob.nelson@microsoft.com; dan.ports@microsoft.com;
   yipeng1.wang@intel.com; ren.wang@intel.com; charlie.tai@intel.com;
   nskim@illinois.edu
CR Acun B, 2021, INT S HIGH PERF COMP, P802, DOI 10.1109/HPCA51647.2021.00072
   Alian M, 2020, INT SYM PERFORM ANAL, P160, DOI 10.1109/ISPASS48437.2020.00031
   Alian M, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P699, DOI 10.1145/3352460.3358278
   Almeida S., 2013, P 8 ACM EUROPEAN C C
   Alshboul M, 2021, INT S HIGH PERF COMP, P111, DOI 10.1109/HPCA51647.2021.00019
   Amaro Emmanuel, 2020, HotNets '20: Proceedings of the 19th Workshop on Hot Topics in Networks, P38, DOI 10.1145/3422604.3425923
   Andersen DG, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P1
   [Anonymous], INT 64 IA 32 ARCH SO
   [Anonymous], 2021, COMMUNICATION
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   AWS, EL FABR AD RUN HPC M
   Bablani G., 2019, INTRO NEW PRODUCT IN
   Balakrishnan M, 2012, 9 USENIX S NETWORKED
   Barroso L, 2017, COMMUN ACM, V60, P47, DOI 10.1145/3015146
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Belay Adam, 2014, P USENIX S OP SYST D
   Blanas S., 2020, FLOPS IOPS NEW BOTTL
   Blott Michaela, 2013, 5 USENIX WORKSHOP HO
   Boden Nan, 2018, AVAILABLE 1 GOOGLE C
   Burke Matthew, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P228, DOI 10.1145/3477132.3483587
   Cai QZ, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P65, DOI 10.1145/3452296.3472888
   Calciu I, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P79, DOI 10.1145/3445814.3446713
   Calder B., 2011, P 23 ACM S OPERATING
   Caminal Y., 2022, P 49 ANN INT S COMPU
   Caulfield AM, 2016, INT SYMP MICROARCH
   CCIX Consortium, CCIX
   Chen SJ, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2900, DOI 10.1145/3394486.3403341
   Chen YZ, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901349
   Chen YM, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303968
   Choi YK, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3294054
   Cock D, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P434, DOI 10.1145/3503222.3507742
   Corporation, INT ARR 10 GX 1150 F
   Cutress I., 2021, INTEL LAUNCH NEXT GE
   Cutress I., 2021, USING PCIE SLOT INST
   CXL Consortium, COMP EXPR LINK CXL
   Daglis A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P35, DOI 10.1145/3297858.3304070
   Daglis A, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P567, DOI 10.1145/2749469.2750415
   Dang H. T., 2016, USIINFTR201603
   Dang H. T., 2018, USIINFTR201801
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Dragojevic Aleksandar, 2014, NSDI, P401
   Eisenman A., 2019, P 2 SYSML C SYSML 19
   Eran M., 2022, P 27 ACM INT C ARCHI
   Eryilmaz Z. F., 2021, INT C DAT ENG ICDE
   Escriva R, 2012, ACM SIGCOMM COMP COM, V42, P25, DOI 10.1145/2377677.2377681
   Facebook, ROCKSDB PERS KEY VAL
   Falsafi B, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P393
   Farshin A, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P673
   Farshin A, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303977
   Flajslik M., 2013, P 2013 USENIX ANN TE
   Gao Y., 2021, P 18 USENIX S NETWOR
   Geng Y., 2013, USENIX ATC
   Ghemawat S., 2003, Operating Systems Review, V37, P29, DOI 10.1145/1165389.945450
   Glasser S. D., 2013, US Patent, Patent No. [20130173837A1, 20130173837]
   Golestani H, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P337, DOI 10.1145/3357223.3362737
   Gope D, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P507, DOI 10.1145/3079856.3080234
   Gouk Donghyun, 2022, P 2022 USENIX ANN TE
   Guo CX, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P202
   Guo ZY, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P417, DOI 10.1145/3503222.3507762
   Gupta A, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P357, DOI 10.1145/3230543.3230555
   Gupta U., 2020, P 2020 IEEE INT S HI
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   He RN, 2016, PROCEEDINGS OF THE 25TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'16), P507, DOI 10.1145/2872427.2883037
   Hwang R, 2020, ANN I S COM, P968, DOI 10.1109/ISCA45697.2020.00083
   Ibanez S, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P239
   Intel Corporation, INT XEON GOLD 6138P
   Intel Corporation, INT STRAT 10 DX FPGA
   Intel Corporation, DAT PLAN DEV KIT DPD
   Intel Corporation, INT DAT DIR I O DDIO
   Intel Corporation, EADR NEW OPP PERS ME
   Intel Corporation, INT OPT PERS MEM
   Jeong E., 2014, 11 USENIX S NETW SYS, P489
   Jin X, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P35
   Jin X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P121, DOI 10.1145/3132747.3132764
   Jongyul Kim, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P756, DOI 10.1145/3477132.3483565
   Kalia Anuj, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P105, DOI 10.1145/3419111.3421294
   Kalia A, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P1
   Kalia A, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P185
   Kalia A, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P437
   Kalia A, 2014, SIGCOMM'14: PROCEEDINGS OF THE 2014 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P295, DOI [10.1145/2619239.2626299, 10.1145/2740070.2626299]
   Kanev S., 2015, P 42 IEEEACM INT S C
   Ke L., 2020, P ACMIEEE 47 ANN INT
   Kim D, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P90, DOI 10.1145/3387514.3405855
   Kim D, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P297, DOI 10.1145/3230543.3230572
   Kocberber Onur, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P468, DOI 10.1145/2540708.2540748
   Kung H. T., 1994, Computer Communication Review, V24, P101, DOI 10.1145/190809.190324
   Kurth M, 2020, P IEEE S SECUR PRIV, P20, DOI 10.1109/SP40000.2020.00082
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lazarev N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P36, DOI 10.1145/3445814.3446696
   Le Y., 2019, P 3 ASIA PACIC WORKS
   Lee S. -s., 2021, P ACM SIGOPS 28 S OP
   Lee Y., 2021, P 26 INT C ARCHITECT
   Lerner R. Hussein, 2019, P 9 BIENNIAL C INNOV
   Li BJ, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P137, DOI 10.1145/3132747.3132756
   Li JL, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P387
   Li JL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P104, DOI 10.1145/3132747.3132751
   Li JL, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P467
   Lim H., 2014, P 11 USENIX S NETW S
   Lim K., 2013, P 40 ANN INT S COMP
   Liu M., 2017, P 22 INT C ARCHITECT
   Liu M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P363
   Liu M, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P318, DOI 10.1145/3341302.3342079
   Lockerman E, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P417, DOI 10.1145/3373376.3378497
   Ma J., 2020, P 25 INT C ARCHITECT
   Manousis Antonis, 2020, P 2020 ACM SIGCOMM C, P270, DOI 10.1145/3387514.3405868
   Mellanox, MELL SCAL HIER AGGR
   Mellanox, MELL AD PROGR REF MA
   Memaripour A, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P499, DOI 10.1145/3064176.3064215
   Mirhosseini A, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P852, DOI 10.1109/MICRO50266.2020.00074
   Mirhosseini A, 2019, INT S HIGH PERF COMP, P185, DOI 10.1109/HPCA.2019.00037
   Mitchell C, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P451
   Monga Sumit Kumar, 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P212, DOI 10.1145/3477132.3483576
   mongoDB, MONGODB MAN MAN CHAI
   Naumov Maxim, 2019, ARXIV
   ndikar C., 2021, P 54 ANN IEEEACM INT
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Novakovic S, 2019, SYSTOR '19: PROCEEDINGS OF THE 12TH ACM INTERNATIONAL SYSTEMS AND STORAGE CONFERENCE, P97, DOI 10.1145/3319647.3325827
   Novakovic S, 2014, ACM SIGPLAN NOTICES, V49, P3, DOI 10.1145/2541940.2541965
   NVIDIA Corporation, NVIDIA BLUEFIELD 2 D
   NVIDIA Corporation, 2021, NVIDIA EXT DAT CTR I
   NVIDIA Corporation, RDMA AW NETW PROGR U
   Oboril F, 2012, I C DEPEND SYS NETWO
   Ohara H., 2014, REVISIT DCA PCIE TPH
   Ongaro D, 2011, SOSP 11: PROCEEDINGS OF THE TWENTY-THIRD ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P29
   Optocrypto, INT SAPPH RAP HBM2E
   Owaida M., P 2017 IEEE 25 ANN I, P201
   Pandruvada Srinivas, RUNNING AVERAGE POWE
   Park J., 2021, P 54 ANN IEEEACM INT
   Phanishayee A., 2012, P 2012 WORKSHOP MANA
   Phothilimthana PM, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P663
   Pismenny B, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P1130, DOI 10.1145/3503222.3507711
   PLDA, LIGHTW NOT
   Pontarelli S, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P531
   Ports D. R. K., 2015, P 12 USENIX S NETW S
   Pourhabibi A., 2021, P 54 ANN IEEEACM INT
   Reda W., 2022, P 19 USENIX S NETWOR
   Romanovsky L., MLX5DV LINUX MANUAL
   SAP, 2017, PERF SYST REPL SAP H
   Sapio A, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P785
   Sapio A, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P150, DOI 10.1145/3152434.3152461
   Schuh Henry N., 2021, SOSP '21: Proceedings of the ACM SIGOPS 28th Symposium on Operating Systems Principles CD-ROM, P740, DOI 10.1145/3477132.3483555
   Seemakhupt K., 2021, P 48 IEEEACM INT S C
   Shalev L, 2020, IEEE MICRO, V40, P67, DOI 10.1109/MM.2020.3016891
   Sidler D, 2020, PROCEEDINGS OF THE FIFTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS'20), DOI 10.1145/3342195.3387519
   Sidler D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P403, DOI 10.1145/3035918.3035954
   Singhvi A., 2020, P 2020 ACM SIGCOMM C
   Sriraman A, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P733, DOI 10.1145/3373376.3378450
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Sutherland M, 2020, ANN I S COM, P199, DOI 10.1109/ISCA45697.2020.00027
   Tai A, 2016, PROCEEDINGS OF USENIX ATC '16: 2016 USENIX ANNUAL TECHNICAL CONFERENCE, P337
   Talpey T., 2019, RDMA PERSISTENT MEOR
   Terrace Jeff, 2009, P 2009 USENIX ANN TE
   Tootoonchian A, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P283
   Tork M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P117, DOI 10.1145/3373376.3378528
   Tsai SY, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P306, DOI 10.1145/3132747.3132762
   van Renesse R, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P91
   Wang Q, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P277
   Wang ZK, 2020, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM48280.2020.00024
   Wang ZL, 2023, PROCEEDINGS OF THE 20TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, NSDI 2023, P1
   Wei X., 2021, P 2021 USENIX ANN TE
   Wei XD, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P233
   Wei XD, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P87, DOI 10.1145/2815400.2815419
   WikiChip, SKYLAKE SERV MICR IN
   Xilinx, ALVEO U280 DAT CTR A
   Xilinx, XILINX VIRT 7 FPGA V
   Xue JC, 2020, IEEE ACM T NETWORK, V28, P322, DOI 10.1109/TNET.2019.2961671
   Yang J, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P169
   Ye C., 2021, P 2021 IEEE INT S HI
   Yu Z., P 2020 ACM SIGCOMM C
   Yuan Y., 2021, P 2021 IEEE INT S HI
   Yuan YF, 2021, CONF PROC INT SYMP C, P112, DOI 10.1109/ISCA52012.2021.00018
   Zeng C., 2022, P 16 USENIX S OPERAT
   Zeng C., 2022, P 19 USENIX S NETWOR
   Zha Y, 2021, CONF PROC INT SYMP C, P470, DOI 10.1109/ISCA52012.2021.00044
   Zhao W., 2020, P 3 C MACHINE LEARNI
   Zhao WJ, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P319, DOI 10.1145/3357384.3358045
   Zhou D, 2013, PROCEEDINGS OF THE 2013 ACM INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES (CONEXT '13), P97, DOI 10.1145/2535372.2535379
   Zhou SY, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P687
   Zhu H, 2019, PROC VLDB ENDOW, V13, P376, DOI 10.14778/3368289.3368301
   Zhu YB, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P523, DOI 10.1145/2785956.2787484
NR 180
TC 0
Z9 0
U1 4
U2 4
PY 2023
BP 499
EP 515
DI 10.1109/HPCA56546.2023.10071127
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Tiemann, T
   Weissman, Z
   Eisenbarth, T
   Sunar, B
AF Tiemann, Thore
   Weissman, Zane
   Eisenbarth, Thomas
   Sunar, Berk
GP ACM
TI IOTLB-SC: An Accelerator-Independent Leakage Source in Modern Cloud
   Systems
SO PROCEEDINGS OF THE 2023 ACM ASIA CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY, ASIA CCS 2023
DT Proceedings Paper
CT 18th ACM ASIA Conference on Computer and Communications Security (ASIA
   CCS)
CY JUL 10-14, 2023
CL Melbourne, AUSTRALIA
DE cloud; FPGA; side-channel; peripheral; IOMMU
ID CACHE ATTACKS
AB Hardware peripherals such as GPUs and FPGAs are commonly available in server-grade computing to accelerate specific compute tasks, from database queries to machine learning. CSPs have integrated these accelerators into their infrastructure and let tenants combine and configure these components flexibly, based on their needs. Securing I/O interfaces is critical to ensure proper isolation between tenants in these highly complex, heterogeneous, yet shared server systems, especially in the cloud, where some peripherals may be under control of a malicious tenant.
   In this work, we investigate the interfaces that connect peripheral hardware components to each other and the rest of the system. We show that the I/O memory management units (IOMMUs) - intended to ensure proper isolation of peripherals - are the source of a new attack surface: the I/O translation look-aside buffer (IOTLB). We show that by using an FPGA accelerator card one can gain precise information over IOTLB activity. That information can be used for covert communication between peripherals without bothering CPU or to directly extract leakage from neighboring accelerated compute jobs such as GPU-accelerated databases. We present the first qualitative and quantitative analysis of this newly uncovered attack surface before fine-grained channels become widely viable with the introduction of CXL and PCIe 5.0. In addition, we propose possible countermeasures that software developers, hardware designers, and system administrators can use to suppress the observed side-channel leakages and analyze their implicit costs.
C1 [Tiemann, Thore; Eisenbarth, Thomas] Univ Lubeck, Lubeck, SH, Germany.
   [Weissman, Zane; Sunar, Berk] Worcester Polytech Inst, Worcester, MA USA.
RP Tiemann, T (corresponding author), Univ Lubeck, Lubeck, SH, Germany.
EM t.tiemann@uni-luebeck.de; zweissman@wpi.edu;
   thomas.eisenbarth@uni-luebeck.de; sunar@wpi.edu
CR Alibaba Cloud, 2019, FPGA BAS COMP OPT IN
   Alibaba Cloud ECS, 2020, INTR 6 GEN AL CLOUDS
   Almeida JB, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P53
   Amazon AWS, 2018, AWS NITR SYST
   Amazon AWS, 2017, AM EC2 F1 INST
   AMD, 2021, AMD I O VIRT TECHN I
   AMD, 2022, OFF UNM PERF LEAD EN
   [Anonymous], 2016, INT 64 IA 32 ARCH OP
   Barthe G, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1267, DOI 10.1145/2660267.2660283
   Blazy S, 2018, LECT NOTES COMPUT SC, V10492, P260, DOI 10.1007/978-3-319-66402-6_16
   Borrello P, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3917
   Chor B, 1998, J ACM, V45, P965, DOI 10.1145/293347.293350
   Cojocar L, 2019, P IEEE S SECUR PRIV, P55, DOI 10.1109/SP.2019.00089
   Disselkoen C, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P51
   Firestone D, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P51
   Frigo P, 2020, P IEEE S SECUR PRIV, P747, DOI 10.1109/SP40000.2020.00090
   Frigo P, 2018, P IEEE S SECUR PRIV, P195, DOI 10.1109/SP.2018.00022
   Gianelli Silvia E., 2017, XILINX ANNOUNCES GEN
   Gras B, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23271
   Gras B, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P955
   Gruss Daniel, 2016, Detection of Intrusions and Malware, and Vulnerability Assessment. 13th International Conference, DIMVA 2016. Proceedings: LNCS 9721, P279, DOI 10.1007/978-3-319-40667-1_14
   Gruss D, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P217
   Hayata Junichiro, 2020, Computer Security - ESORICS 2020. 25th European Symposium on Research in Computer Security, ESORICS 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12309), P674, DOI 10.1007/978-3-030-59013-0_33
   Hund R, 2013, P IEEE S SECUR PRIV, P191, DOI 10.1109/SP.2013.23
   Inci MS, 2016, LECT NOTES COMPUT SC, V9813, P368, DOI 10.1007/978-3-662-53140-2_18
   Inci MS, 2016, LECT NOTES COMPUT SC, V9689, P19, DOI 10.1007/978-3-319-43283-0_2
   Intel, 2012, INT DAT DIR I O TECH
   Intel Corporation, 2019, INTEL VIRTUALIZATION, V1
   Irazoqui G, 2015, 2015 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P629, DOI 10.1109/DSD.2015.56
   Khaliq SA, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622848
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Kurth M, 2020, P IEEE S SECUR PRIV, P20, DOI 10.1109/SP40000.2020.00082
   Kushilevitz E, 1997, ANN IEEE SYMP FOUND, P364
   Lipp M, 2018, PROCEEDINGS OF THE 27TH USENIX SECURITY SYMPOSIUM, P973
   Liu F, 2016, INT S HIGH PERF COMP, P406, DOI 10.1109/HPCA.2016.7446082
   Liu FF, 2015, P IEEE S SECUR PRIV, P605, DOI 10.1109/SP.2015.43
   Markettos AT, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23194
   Maurice C, 2017, 24TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2017), DOI 10.14722/ndss.2017.23294
   Mingtian Tan, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P322, DOI 10.1109/SP40001.2021.00059
   MITRE, 2018, CVE201812126
   MITRE, 2018, CVE201812127
   Morgan Benoit, 2018, Journal of the Brazilian Computer Society, V24, DOI 10.1186/s13173-017-0066-7
   Morgan B, 2016, LAT-AM SYMP DEP COMP, P145, DOI 10.1109/LADC.2016.31
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Nguyen K. T., 2016, USAGE MODELS CACHE A
   Oren Y, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1406, DOI 10.1145/2810103.2813708
   Osvik DA, 2006, LECT NOTES COMPUT SC, V3860, P1
   PCI-SIG, 2006, PCI EXPRESS BASE SPE
   PCI-SIG, 2009, ADDR TRANSL SERV
   Peglow Christoph, 2020, THESIS U LUBECK
   Pessl P, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P565
   Purnal A, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P3647
   Purnal A, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2906, DOI 10.1145/3460120.3484816
   RedHat Inc., 2014, SYS CLASS IOMM IOMM
   Ristenpart T, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P199
   Sanchez D, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P57, DOI 10.1145/2024723.2000073
   Schwarz Michael, 2019, CCS '19: Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security, P753, DOI 10.1145/3319535.3354252
   Sharma Debendra Das, 2019, COMPUTE EXPRESS LINK
   Shilov Anton, 2022, INTELS SAPPHIRE RAPI
   SIBERT O, 1995, P IEEE S SECUR PRIV, P211, DOI 10.1109/SECPRI.1995.398934
   Tatar A, 2022, PROCEEDINGS OF THE 31ST USENIX SECURITY SYMPOSIUM, P989
   van Schaik S, 2019, P IEEE S SECUR PRIV, P88, DOI 10.1109/SP.2019.00087
   Vila P, 2019, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2019.00042
   Weissman Z., 2020, IACR T CRYPTOGR HARD, P169, DOI DOI 10.13154/TCHES.V2020.I3.169-195
   Wichelmann J, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P161, DOI 10.1145/3274694.3274741
   Yarom Y, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P719
   Ye Y, 2014, INT CONFER PARA, P381, DOI 10.1145/2628071.2628104
   Zhang YQ, 2014, CCS'14: PROCEEDINGS OF THE 21ST ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P990, DOI 10.1145/2660267.2660356
NR 68
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 827
EP 840
DI 10.1145/3579856.3582838
WC Computer Science, Artificial Intelligence; Mathematics, Applied;
   Telecommunications
DA 2023-11-11
ER

PT C
AU Zhou, MX
   Xu, WH
   Kang, J
   Rosing, T
AF Zhou, Minxuan
   Xu, Weihong
   Kang, Jaeyoung
   Rosing, Tajana
GP IEEE Comp Soc
TI TransPIM: A Memory-based Acceleration via Software-Hardware Co-Design
   for Transformer
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Processing in-memory; Near-data processing; Transformer; Domain-specific
   acceleration; Software-hardware co-design
ID DRAM
AB Transformer-based models are state-of-the-art for many machine learning (ML) tasks. Executing Transformer usually requires a long execution time due to the large memory footprint and the low data reuse rate, stressing the memory system while under-utilizing the computing resources. Memory-based processing technologies, including processing in-memory (PIM) and near-memory computing (NMC), are promising to accelerate Transformer since they provide high memory bandwidth utilization and extensive computation parallelism. However, the previous memory-based ML accelerators mainly target at optimizing dataflow and hardware for compute-intensive ML models (e.g., CNNs), which do not fit the memory-intensive characteristics of Transformer. In this work, we propose TransPIM, a memory-based acceleration for Transformer using software and hardware co-design. In the software-level, TransPIM adopts a token-based dataflow to avoid the expensive inter-layer data movements introduced by previous layer-based dataflow. In the hardware-level, TransPIM introduces lightweight modifications in the conventional high bandwidth memory (HBM) architecture to support PIM-NMC hybrid processing and efficient data communication for accelerating Transformer-based models. Our experiments show that TransPIM is 3.7x to 9.1x faster than existing memory-based acceleration. As compared to conventional accelerators, TransPIM is 22.1x to 114.9x faster than GPUs and provides 2.0x more throughput than existing ASIC-based accelerators.
C1 [Zhou, Minxuan; Xu, Weihong; Kang, Jaeyoung; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Zhou, MX (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM miz087@ucsd.edu; wexu@ucsd.edu; j5kang@ucsd.edu; tajana@ucsd.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ali ME, 2020, IEEE T CIRCUITS-I, V67, P155, DOI 10.1109/TCSI.2019.2945617
   [Anonymous], 2013, JESD235 JEDEC
   BATCHER KE, 1982, IEEE T COMPUT, V31, P377, DOI 10.1109/TC.1982.1676015
   Beltagy I, 2020, Arxiv, DOI [arXiv:2004.05150, DOI 10.48550/ARXIV.2004.05150]
   Bertasius G., ARXIV210205095, V2, P813
   Lipton ZC, 2015, Arxiv, DOI [arXiv:1506.00019, DOI 10.48550/ARXIV.1506.00019]
   Carion Nicolas, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12346), P213, DOI 10.1007/978-3-030-58452-8_13
   Chen K, 2012, DES AUT TEST EUROPE, P33
   Choi Young-Kyu, 2021, FPGA, V2021, P116, DOI 10.1145/3431920.3439301
   Cohan A, 2018, P C N AM CHAPT ASS C, P615, DOI [10.18653/v1/n18-2097, DOI 10.18653/V1/N18-2097]
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Dosovitskiy A, 2021, Arxiv, DOI [arXiv:2010.11929, DOI 10.48550/ARXIV.2010.11929]
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Imani M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P356, DOI 10.1109/MICRO50266.2020.00039
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Jang H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P250, DOI 10.1145/3307650.3322214
   Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578
   Joshi M, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017), VOL 1, P1601, DOI 10.18653/v1/P17-1147
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kara K, 2020, I C FIELD PROG LOGIC, P1, DOI 10.1109/FPL50879.2020.00013
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kitaev N., 2020, INT C LEARNING REPRE, P1
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu YH, 2019, Arxiv, DOI [arXiv:1907.11692, DOI 10.48550/ARXIV.1907.11692]
   Maas A., 2011, P 49 ANN M ASS COMP, P142, DOI DOI 10.5555/2002472.2002491
   Minxuan Zhou, 2021, 2021 30th International Conference on Parallel Architectures and Compilation Techniques (PACT), DOI 10.1109/PACT52795.2021.00021
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Oh CS, 2020, ISSCC DIG TECH PAP I, P330, DOI 10.1109/isscc19947.2020.9063110
   Papailiopoulos D, 2020, ARXIV
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Radford A., 2019, OPENAI BLOG
   Ramanathan AK, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P88, DOI 10.1109/MICRO50266.2020.00020
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shin H, 2018, IEEE T COMPUT AID D, V37, P2613, DOI 10.1109/TCAD.2018.2857044
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zadeh AH, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P811, DOI 10.1109/MICRO50266.2020.00071
   Zaheer M, 2021, Arxiv, DOI arXiv:2007.14062
   Zhou MX, 2021, DES AUT CON, P25, DOI 10.1109/DAC18074.2021.9586212
   Zhou MX, 2021, INT CONFER PARA, P199, DOI 10.1109/PACT52795.2021.00022
   Zhou MX, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P591, DOI 10.1145/3287624.3287711
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 50
TC 8
Z9 8
U1 1
U2 5
PY 2022
BP 1071
EP 1085
DI 10.1109/HPCA53966.2022.00082
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Liu, XY
   Tyagin, I
   Ushijima-Mwesigwa, H
   Ghosh, I
   Safro, I
AF Liu, Xiaoyuan
   Tyagin, Ilya
   Ushijima-Mwesigwa, Hayato
   Ghosh, Indradeep
   Safro, Ilya
BE Candan, KS
   Dinh, TN
   Thai, MT
   Washio, T
TI Towards Practical Explainability with Cluster Descriptors
SO 2022 IEEE INTERNATIONAL CONFERENCE ON DATA MINING WORKSHOPS, ICDMW
SE International Conference on Data Mining Workshops
DT Proceedings Paper
CT 22nd IEEE International Conference on Data Mining (ICDM)
CY NOV 28-DEC 01, 2022
CL Orlando, FL
DE explainability; clustering; machine learning; Ising model; combinatorial
   optimization
ID OPTIMIZATION
AB With the rapid development of machine learning, improving its explainability has become a crucial research goal. We study the problem of making the clusters more explainable by investigating the cluster descriptors. Given a set of objects S, a clustering of these objects pi, and a set of tags T that have not participated in the clustering algorithm. Each object in S is associated with a subset of T. The goal is to find a representative set of tags for each cluster, referred to as the cluster descriptors, with the constraint that these descriptors we find are pairwise disjoint, and the total size of all the descriptors is minimized. In general, this problem is NP-hard. We propose a novel explainability model that reinforces the previous models in such a way that tags that do not contribute to explainability and do not sufficiently distinguish between clusters are not added to the optimal descriptors. The proposed model is formulated as a quadratic unconstrained binary optimization problem which makes it suitable for solving on modern optimization hardware accelerators. We experimentally demonstrate how a proposed explainability model can be solved on specialized hardware for accelerating combinatorial optimization, the Fujitsu Digital Annealer, and use real-life Twitter and PubMed datasets for use cases. Reproducibility materials: Link
C1 [Liu, Xiaoyuan; Ushijima-Mwesigwa, Hayato; Ghosh, Indradeep] Fujitsu Res Amer Inc, Sunnyvale, CA 94085 USA.
   [Tyagin, Ilya; Safro, Ilya] Univ Delaware, Newark, DE USA.
RP Liu, XY (corresponding author), Fujitsu Res Amer Inc, Sunnyvale, CA 94085 USA.
EM xliu@fujitsu.com; tyagin@udel.edu; hayato@fujitsu.com;
   ighosh@fujitsu.com; isafro@udel.edu
CR Aramon M, 2019, FRONT PHYS-LAUSANNE, V7, DOI 10.3389/fphy.2019.00048
   BARAHONA F, 1988, OPER RES, V36, P493, DOI 10.1287/opre.36.3.493
   Blei DM, 2003, J MACH LEARN RES, V3, P993, DOI 10.1162/jmlr.2003.3.4-5.993
   Boros E., 1991, Annals of Operations Research, V33, P151, DOI 10.1007/BF02115753
   Chen HH, 2020, CHAOS, V30, DOI 10.1063/5.0004983
   Coffrin C, 2019, LECT NOTES COMPUT SC, V11494, P163, DOI 10.1007/978-3-030-19212-9_11
   Comarela G., 2011, P WORKSHOP LANGUAGES, P58
   Davidson I., 2018, ADV NEURAL INFORM PR
   Farhi E, 2014, Arxiv, DOI [arXiv:1411.4028, DOI 10.48550/ARXIV.1411.4028]
   Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1023/A:1022852608280
   Fujitsu, 2022, FUJITSU DIGITAL ANNE
   GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5
   Glover F, 2019, Arxiv, DOI arXiv:1811.11538
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Johnson MW, 2011, NATURE, V473, P194, DOI 10.1038/nature10012
   Kochenberger G, 2014, J COMB OPTIM, V28, P58, DOI 10.1007/s10878-014-9734-0
   Langley P., 1996, ELEMENTS MACHINE LEA
   Liu XY, 2023, IEEE T VEH TECHNOL, V72, P747, DOI [10.1109/TIE.2022.3225860, 10.1109/TVT.2022.3204310, 10.1109/TQE.2021.3140190]
   Liu XY, 2022, COMPUT OPTIM APPL, V82, P1, DOI 10.1007/s10589-022-00354-2
   Lucas A, 2014, FRONT PHYS-LAUSANNE, V2, DOI 10.3389/fphy.2014.00005
   Newman MEJ, 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   PARDALOS PM, 1994, J GLOBAL OPTIM, V4, P301, DOI 10.1007/BF01098364
   Hoffman RR, 2019, Arxiv, DOI [arXiv:1812.04608, DOI 10.48550/ARXIV.1812.04608]
   Ramage Daniel, 2009, EMNLP, P248, DOI DOI 10.3115/1699510.1699543
   Rosenfeld Avi, 2021, P 20 INT C AUT AG MU, P45
   Sambaturu P, 2020, AAAI CONF ARTIF INTE, V34, P1636
   Schaller RR, 1997, IEEE SPECTRUM, V34, P52, DOI 10.1109/6.591665
   Shaydulin R., 2018, 3 INT WORKSHOP POSTM
   Shaydulin R, 2019, ADV QUANTUM TECHNOL, V2, DOI 10.1002/qute.201900029
   Shaydulin R, 2019, COMPUTER, V52, P18, DOI 10.1109/MC.2019.2908942
   Sybrandt J, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P2757, DOI 10.1145/3340531.3412684
   Sybrandt J, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1633, DOI 10.1145/3097983.3098057
   Ushijima-Mwesigwa H, 2021, ACM T QUANTUM COMPUT, V2, DOI 10.1145/3425607
   Ushijima-Mwesigwa H, 2017, PROCEEDINGS OF 2ND INTERNATIONAL WORKSHOP ON POST MOORE'S ERA SUPERCOMPUTING (PMES 2017), P22, DOI 10.1145/3149526.3149531
   Wang HJ, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0017243
NR 35
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 206
EP 215
DI 10.1109/ICDMW58026.2022.00036
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Yuan, Y
   Alama, O
   Fei, J
   Nelson, J
   Ports, DRK
   Sapio, A
   Canini, M
   Kim, NS
AF Yuan, Yifan
   Alama, Omar
   Fei, Jiawei
   Nelson, Jacob
   Ports, Dan R. K.
   Sapio, Amedeo
   Canini, Marco
   Kim, Nam Sung
GP USENIX ASSOC
TI Unlocking the Power of Inline Floating-Point Operations on Programmable
   Switches
SO PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND
   IMPLEMENTATION (NSDI '22)
DT Proceedings Paper
CT 19th USENIX Symposium on Networked Systems Design and Implementation
   (NSDI)
CY APR 04-06, 2022
CL Renton, WA
ID IMPLEMENTATION
AB The advent of switches with programmable dataplanes has enabled the rapid development of newnetwork functionality, as well as providing a platform for acceleration of a broad range of application-level functionality. However, existing switch hardware was not designed with application acceleration in mind, and thus applications requiring operations or datatypes not used in traditional network protocols must resort to expensive workarounds. Applications involving floating point data, including distributed training for machine learning and distributed query processing, are key examples.
   In this paper, we propose FPISA, a floating point representation designed to work efficiently in programmable switches. We first implement FPISA on an Intel Tofino switch, but find that it has limitations that impact throughput and accuracy. We then propose hardware changes to address these limitations based on the open-source Banzai switch architecture, and synthesize them in a 15-nm standard-cell library to demonstrate their feasibility. Finally, we use FPISA to implement accelerators for training for machine learning as an example application, and evaluate its performance on a switch implementing our changes using emulation. We find that FPISA allows distributed training to use one to three fewer CPU cores and provide up to 85.9% better throughput than SwitchML in a CPU-constrained environment.
C1 [Yuan, Yifan; Kim, Nam Sung] UIUC, Champaign, IL 61820 USA.
   [Alama, Omar; Fei, Jiawei; Canini, Marco] KAUST, Thuwal, Saudi Arabia.
   [Fei, Jiawei] NUDT, Changsha, Peoples R China.
   [Nelson, Jacob; Ports, Dan R. K.] Microsoft Res, Redmond, WA USA.
   [Sapio, Amedeo] Intel, Santa Clara, CA USA.
RP Yuan, Y (corresponding author), UIUC, Champaign, IL 61820 USA.
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Alachiotis N., 2010, P 2010 IEEE INT S PA
   Alizadeh M, 2014, ACM SIGCOMM COMP COM, V44, P503, DOI 10.1145/2740070.2626316
   [Anonymous], 2018, RFC
   [Anonymous], 2002, P ACM IEEE C SUP, DOI DOI 10.1109/SC.2002.10017
   [Anonymous], INTEL CORPORATION
   [Anonymous], 2007, THESIS STANFORD U
   Arista, 7130 FPGA ENABLED NE
   BARNETT M, 1994, PROCEEDINGS OF THE SCALABLE HIGH-PERFORMANCE COMPUTING CONFERENCE, P357, DOI 10.1109/SHPCC.1994.296665
   Ben Basat R., 2020, P 2020 ACM SIGMOD IN
   Ben Basat R, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P662, DOI 10.1145/3387514.3405894
   Bosshart P, 2014, ACM SIGCOMM COMP COM, V44, P87, DOI 10.1145/2656877.2656890
   Bosshart P, 2013, ACM SIGCOMM COMP COM, V43, P99, DOI 10.1145/2534169.2486011
   Broadcom, TRIDENT4 BCM56880 SE
   Broadcom, NPL OPEN HIGH LEVEL
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571, DOI DOI 10.1108/01439911111122716
   Chole S, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P1, DOI 10.1145/3098822.3098823
   Courbariaux M, 2015, Arxiv, DOI arXiv:1412.7024
   Cui PL, 2021, I C NETWORK PROTOCOL, DOI 10.1109/ICNP52444.2021.9651946
   Dang HT, 2020, IEEE ACM T NETWORK, V28, P1726, DOI 10.1109/TNET.2020.2992106
   De Sensi Daniele, 2021, ARXIV
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Deng W, 2021, Arxiv, DOI arXiv:2002.06987
   Devarakonda A., 2017, ARXIV
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Drumond M., 2018, ADV NEURAL INFORM PR
   Gebara N., 2021, P 4 MLSYS CONFRENCE
   Geng JJ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030280
   Google Cloud, USING BFLOAT16 TENSO
   Graham R. L., 2016, P 1 WORKSHOP OPTIMIZ
   Graham R. L., 2020, P 35 INT C HIGH PERF
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Gupta A, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P357, DOI 10.1145/3230543.3230555
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Hauser Frederik, 2021, SURVEY DATA PLANE PR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Ho Qirong, 2013, Adv Neural Inf Process Syst, V2013, P1223
   Horvath S, 2020, Arxiv, DOI arXiv:1905.10988
   Hwang CH, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P721
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Intel Corporation, INTEL TOFINO2
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jepsen T., 2018, P ACM SIGCOMM 2018 W
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Jiang YM, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P463
   Jin X, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P35
   Jin X, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P121, DOI 10.1145/3132747.3132764
   Johnson J, 2018, Arxiv, DOI arXiv:1811.01721
   Jose M, 2021, 2021 IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2021), P358
   Jozefowicz R, 2016, Arxiv, DOI arXiv:1602.02410
   Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, DOI 10.48550/ARXIV.1905.12322]
   Katabi D, 2002, ACM SIGCOMM COMP COM, V32, P89, DOI 10.1145/964725.633035
   Katta N, 2016, SYMPOSIUM ON SOFTWARE DEFINED NETWORKING (SDN) RESEARCH (SOSR'16), DOI 10.1145/2890955.2890968
   Kim D, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P90, DOI 10.1145/3387514.3405855
   Klenk B, 2020, ANN I S COM, P996, DOI 10.1109/ISCA45697.2020.00085
   Kreutz D, 2015, P IEEE, V103, P14, DOI 10.1109/JPROC.2014.2371999
   Krizhevsky A., THE CIFAR 10 DATASET
   Kundel R, 2018, 2018 IEEE CONFERENCE ON NETWORK FUNCTION VIRTUALIZATION AND SOFTWARE DEFINED NETWORKS (NFV-SDN)
   Lao ChonLam, 2021, P 18 USENIX S NETWOR
   Leon AS, 2007, IEEE J SOLID-ST CIRC, V42, P7, DOI 10.1109/JSSC.2006.885049
   Lerner, 2020, P 19 ACM WORKSH HOT
   Lerner A., 2019, P 9 BIENNIAL C INNOV
   Li JL, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P387
   Li JL, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P104, DOI 10.1145/3132747.3132751
   Li JL, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P467
   Li M., 2014, P 11 USENIX S OPERAT
   Li Y., 2019, P 46 INT S COMPUTER
   Li YM, 1997, 5TH ANNUAL IEEE SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM COMPUTING MACHINES, P226, DOI 10.1109/FPGA.1997.624623
   Li YJ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P175, DOI 10.1109/MICRO.2018.00023
   Liu ZX, 2019, PROCEEDINGS OF THE 17TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P143
   Lo D., 2020, ADV NEURAL INFORM PR
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   Mathew SK, 2005, IEEE J SOLID-ST CIRC, V40, P44, DOI 10.1109/JSSC.2004.838019
   Mellanox, QM8700 MELLANOX QUAN
   Mellanox, MELLANOX SCALABLE HI
   Menth M, 2019, FUTURE INTERNET, V11, DOI 10.3390/fi11070159
   Miao R, 2017, SIGCOMM '17: PROCEEDINGS OF THE 2017 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P15, DOI 10.1145/3098822.3098824
   Micikevicius P., 2017, MIXED PRECISION TRAI, DOI DOI 10.48550/ARXIV.1710.03740
   MLCommons, MLPERF BENCHMARK
   Moritz P, 2016, Arxiv, DOI arXiv:1511.06051
   Nemirovski A, 2009, SIAM J OPTIMIZ, V19, P1574, DOI 10.1137/070704277
   Nemirovskij Arkadij Semenovic, 1983, PROBLEM COMPLEXITY M
   NVIDIA, AP TOOLS EAS MIX PRE
   NVIDIA blog, TENSORFLOAT 32 A100
   Oberman SF, 1999, P S COMP ARITHM, P106, DOI 10.1109/ARITH.1999.762835
   OpenSwitch, CAVIUM XPLIANT FAMIL
   Paszke A, 2019, ADV NEUR IN, V32
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Peng YH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P16, DOI 10.1145/3341301.3359642
   Piasetzky Y., 2018, P 2018 IEEE 26 INT C
   Ports D. R. K., 2015, P 12 USENIX S NETWOR
   Ports DRK, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P209, DOI 10.1145/3317550.3321439
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Sa CD, 2018, Arxiv, DOI arXiv:1803.03383
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sapio A, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P785
   Sapio A, 2017, HOTNETS-XVI: PROCEEDINGS OF THE 16TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P150, DOI 10.1145/3152434.3152461
   Sharma N. K., 2018, P 15 USENIX S NETWOR
   Sharma NK, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P67
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sivaraman A, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P44, DOI 10.1145/2934872.2934899
   Sivaraman A, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P15, DOI 10.1145/2934872.2934900
   Soderquist P, 1996, ACM COMPUT SURV, V28, P518, DOI 10.1145/243439.243481
   Sonchack J, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190558
   Svyatkovskiy A., 2017, P MACHINE LEARNING H
   synopsys, DESIGN COMPILER GRAP
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   TANG PTP, 1990, ACM T MATH SOFTWARE, V16, P378, DOI 10.1145/98267.98294
   Tokusashi Y, 2018, Arxiv, DOI arXiv:1805.11344
   Tokusashi Y, 2019, PROCEEDINGS OF THE FOURTEENTH EUROSYS CONFERENCE 2019 (EUROSYS '19), DOI 10.1145/3302424.3303979
   Venkataraman S., 2013, P 8 ACM EUROPEAN C C
   Voogel M., 2020, HOTCHIPS 20 VIRTUAL
   Wang Naigang, 2018, ADV NEURAL INFORM PR
   Yangrui Chen, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P507, DOI 10.1145/3419111.3421307
   Yu ZL, 2021, SIGCOMM '21: PROCEEDINGS OF THE 2021 ACM SIGCOMM 2021 CONFERENCE, P179, DOI 10.1145/3452296.3472887
   Yu ZL, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P126, DOI 10.1145/3387514.3405857
   Zhen Zhang, 2020, NetAI '20: Proceedings of the Workshop on Network Meets AI & ML, P8, DOI 10.1145/3405671.3405810
   Zhou Y, 2020, SIGCOMM '20: PROCEEDINGS OF THE 2020 ANNUAL CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION ON THE APPLICATIONS, TECHNOLOGIES, ARCHITECTURES, AND PROTOCOLS FOR COMPUTER COMMUNICATION, P76, DOI 10.1145/3387514.3406214
   Zhu H, 2019, PROC VLDB ENDOW, V13, P376, DOI 10.14778/3368289.3368301
NR 120
TC 9
Z9 9
U1 0
U2 0
PY 2022
BP 683
EP 700
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
DA 2023-11-11
ER

PT J
AU Liao, YM
   Yu, NM
   Tian, D
   Wang, C
   Li, SJ
   Li, ZP
AF Liao, Yumin
   Yu, Ningmei
   Tian, Dian
   Wang, Chen
   Li, Shuaijun
   Li, Zhengpeng
TI An Intelligent Low-Power Low-Cost Mobile Lab-On-Chip Yeast Cell Culture
   Platform
SO IEEE ACCESS
DT Article
DE Microfluidics; Batteries; Monitoring; Machine learning; Neural networks;
   Optimization; Power demand; Microfluidic channel; yeast culture;
   portable cell culture platform; intelligent; low-power; lab-on-chip
ID CAPILLARY-ELECTROPHORESIS; MICROFLUIDIC PLATFORM; EXPRESSION; PHENOTYPE;
   INTEGRATION; MICROCHIP
AB Cells are the fundamental unit of life activities, and the basis of studying life phenomena. It is very important to observe the growth state of yeast cells for exploring the law of life movement, diagnosis and treatment of diseases, drug screening and so on. This study proposes a kind of intelligent low-cost portable cell culture platform using the microfluidic channel and the special machine learning circuit. The platform can independently complete the whole work of living cell culture and monitoring. For realizing the reusable and low-power deep learning circuit, a complement optimization neural network algorithm for hardware optimization and corresponding multi-clock-domain reusable multi-level precision neural network accelerator circuit were proposed, which can reduce the circuit area and power of convolution operation in all precisions by average 18.11% and 23.5% respectively. Besides, a dynamic multi-level precision control method based on the battery level is proposed to dynamically adjust the precision of machine learning operation, in order to balance the working time and segmentation accuracy of the culture platform. In addition, a microcolumns-based three-port input microfluidic structure was designed for better yeast culture effect. The experiment showed that the culture platform can realize yeast cell culture and achieve almost the same segmentation accuracy as the large biological laboratory with low-power and low-cost. Compared with the previous work, the cost of mass production was reduced by 88.95%, and the equipment volume was 27.1% smaller. At the same time, it can achieve the best balance of working time and working accuracy under the condition of limited power of equipment according to the needs of users.
C1 [Liao, Yumin; Yu, Ningmei; Tian, Dian; Wang, Chen; Li, Shuaijun; Li, Zhengpeng] Xian Univ Technol, Sch Automat & Informat Engn, Xian 710000, Peoples R China.
RP Yu, NM (corresponding author), Xian Univ Technol, Sch Automat & Informat Engn, Xian 710000, Peoples R China.
EM yunm@xaut.edu.cn
CR [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2016, ARXIV160305279
   [Anonymous], 2016, RISTRETTO HARDWARE O
   Applegate RW, 2006, LAB CHIP, V6, P422, DOI 10.1039/b512576f
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chiem N, 1997, ANAL CHEM, V69, P373, DOI 10.1021/ac9606620
   CHOWDHURY S, 1992, J CELL BIOL, V118, P561, DOI 10.1083/jcb.118.3.561
   Chuppa S, 1997, BIOTECHNOL BIOENG, V55, P328, DOI 10.1002/(SICI)1097-0290(19970720)55:2<328::AID-BIT10>3.0.CO;2-D
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Dannemiller K, 2015, INT CONF ELECTRO INF, P361, DOI 10.1109/EIT.2015.7293369
   Feizi A, 2016, LAB CHIP, V16, P4350, DOI 10.1039/c6lc00976j
   Göröcs Z, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0067-0
   Gourley PL, 2007, J BIOMED OPT, V12, DOI 10.1117/1.2799198
   Haab BB, 1999, ANAL CHEM, V71, P5137, DOI 10.1021/ac990644t
   Handfield LF, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003085
   Huang XW, 2015, IEEE DES TEST, V32, P32, DOI 10.1109/MDAT.2015.2424418
   Iyer VR, 2001, NATURE, V409, P533, DOI 10.1038/35054095
   Jung US, 1999, MOL MICROBIOL, V34, P1049, DOI 10.1046/j.1365-2958.1999.01667.x
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Li Nianzhen, 2003, Crit Rev Biomed Eng, V31, P423, DOI 10.1615/CritRevBiomedEng.v31.i56.20
   LORINCZ AT, 1984, NATURE, V307, P183, DOI 10.1038/307183a0
   Lu AX, 2019, BIOINFORMATICS, V35, P4525, DOI 10.1093/bioinformatics/btz402
   Marcoux N, 1998, MOL MICROBIOL, V29, P515, DOI 10.1046/j.1365-2958.1998.00944.x
   MUTOH E, 1995, J BACTERIOL, V177, P5383, DOI 10.1128/jb.177.18.5383-5386.1995
   Ng CL, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17040912
   Park TH, 2003, BIOTECHNOL PROGR, V19, P243, DOI 10.1021/bp020143k
   Price AK, 2004, ANAL CHEM, V76, P4849, DOI 10.1021/ac0495992
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rustici G, 2004, NAT GENET, V36, P809, DOI 10.1038/ng1377
   Schilling EA, 2002, ANAL CHEM, V74, P1798, DOI 10.1021/ac015640e
   Simon I, 2001, CELL, V106, P697, DOI 10.1016/S0092-8674(01)00494-9
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Taylor RJ, 2009, P NATL ACAD SCI USA, V106, P3758, DOI 10.1073/pnas.0813416106
   Tourovskaia A, 2005, LAB CHIP, V5, P14, DOI 10.1039/b405719h
   van der Putten P, 2007, PROC SPIE, V6506, DOI 10.1117/12.714072
   Vickerman V, 2008, LAB CHIP, V8, P1468, DOI 10.1039/b802395f
   Wang CC, 2011, LAB CHIP, V11, P695, DOI 10.1039/c0lc00155d
   Wang RY, 2019, EURASIP J ADV SIG PR, V2019, DOI 10.1186/s13634-019-0649-x
   Yang J, 1999, ANAL CHEM, V71, P911, DOI 10.1021/ac981250p
   Yang N., 2015, J ENG THERMOPHYS, V5, P1042
   Zabzdyr JL, 2001, TRAC-TREND ANAL CHEM, V20, P467, DOI 10.1016/S0165-9936(01)00051-6
NR 42
TC 5
Z9 6
U1 1
U2 16
PY 2020
VL 8
BP 70733
EP 70745
DI 10.1109/ACCESS.2020.2987206
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Gorgin, S
   Gholamrezaei, M
   Javaheri, D
   Lee, JA
AF Gorgin, Saeid
   Gholamrezaei, MohammadHosein
   Javaheri, Danial
   Lee, Jeong-A
GP IEEE
BE Sezer, S
   Buchner, T
   Becker, J
   Marshall, A
   Siddiqui, F
   Harbaum, T
   McLaughlin, K
TI <i>k</i>NN-MSDF: A Hardware Accelerator for <i>k</i>-Nearest Neighbors
   Using Most Significant Digit First Computation
SO 2022 IEEE 35TH INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (IEEE SOCC 2022)
SE IEEE International SOC Conference
DT Proceedings Paper
CT 35th IEEE International System-on-Chip Conference (SOCC)
CY SEP 05-08, 2022
CL Belfast, NORTH IRELAND
DE k-Nearest Neighbors; Most Significant Digit First; machine learning;
   early termination; FPGA
AB k-Nearest Neighbors (k-NN) is a well-established algorithm for classification widely used in various machine learning applications. Although k-NN has many advantages, it suffers severely from high latency and low throughput due to its computation-intensive nature. This paper suggests a novel, highly parallel approach based on Most Significant Digit First (MSDF) computing to accelerate k-NN algorithm where the Euclidean distance is used as the distance metric. The proposed method consists of three phases; in the first phase, subtract, and square functions are done on serially coming input data and provide the Most Significant Digit (MSD) of the distances. Then, the processed serially MSDF data are sorted, and finally, the label of test data is determined by majority voting. Having the value of MSD in advance provides the possibility of early termination of unnecessary computations. This approach leads to significantly higher performance and lower power consumption. Moreover, serial computation causes a lower area and memory footprint that paves the way to take advantage of the maximum number of parallel processing elements. The experimental results on an SoC platform indicate up to 88.3% improvement in terms of performance and energy consumption compared to the best previous designs.
C1 [Gorgin, Saeid; Gholamrezaei, MohammadHosein; Javaheri, Danial; Lee, Jeong-A] Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
RP Gorgin, S (corresponding author), Chosun Univ, Dept Comp Engn, Gwangju, South Korea.
EM gorgin@chosun.ac.kr; gholamrezaei@chosun.kr; javaheri@chosun.ac.kr;
   jalee@chosun.ac.kr
CR Ahmadzadeh Armin, 2014, 2014 Twelfth ACM/IEEE Conference on Formal Methods and Models for Codesign (MEMOCODE), P205, DOI 10.1109/MEMCOD.2014.6961863
   Ali M, 2020, EXPERT SYST APPL, V151, DOI 10.1016/j.eswa.2020.113374
   Avizienis A, 1961, IRE T ELECT COMPUTER, VEC-10, P389
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Chen YW, 2019, INFORM SCIENCES, V472, P145, DOI 10.1016/j.ins.2018.09.012
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   Ercegovac M.D., 2004, DIGITAL ARITHMETIC
   Ercegovac MD, 2020, CONF REC ASILOMAR C, P524, DOI 10.1109/IEEECONF51394.2020.9443576
   Ercegovac MD, 2017, CONF REC ASILOMAR C, P750, DOI 10.1109/ACSSC.2017.8335445
   Gao X, 2020, IEEE ACCESS, V8, P112922, DOI 10.1109/ACCESS.2020.3003086
   Gavahi M., 2015, 2015 INT S COMPUTER, P1, DOI [10.1109/CSICSSE.2015.7369240, DOI 10.1109/CSICSSE.2015.7369240]
   Jaberipur G, 2005, IEEE T CIRCUITS-I, V52, P1348, DOI 10.1109/TCSI.2005.851679
   Jamma D, 2017, INT C MICROELECTRON, P330
   Javaheri D, 2021, IEEE ACCESS, V9, P69951, DOI 10.1109/ACCESS.2021.3077295
   Lu A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P139, DOI 10.1109/ICFPT51103.2020.00027
   Saidi A, 2021, INTEGRATION, V81, P280, DOI 10.1016/j.vlsi.2021.08.004
   Uribe-Hurtado AL, 2020, COMPUT IND, V122, DOI 10.1016/j.compind.2020.103260
   Vieira J, 2019, IEEE ACCESS, V7, P170864, DOI 10.1109/ACCESS.2019.2955864
   Moreno JV, 2012, IEEE T COMPUT, V61, P790, DOI 10.1109/TC.2011.97
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Younes H, 2021, IEEE OPEN J CIRCUITS, V2, P534, DOI [10.1109/OJCAS.2021.3108835, 10.1109/OJCAS.20213108835]
   Zhang F, 2019, IEEE T IND INFORM, V15, P4362, DOI 10.1109/TII.2019.2891261
   Zhao Y, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P69, DOI 10.1109/FPT.2016.7929191
NR 23
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 65
EP 70
DI 10.1109/SOCC56010.2022.9908102
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Rahman, A
   Lee, J
   Choi, K
AF Rahman, Atul
   Lee, Jongeun
   Choi, Kiyoung
GP IEEE
TI Efficient FPGA Acceleration of Convolutional Neural Networks Using
   Logical-3D Compute Array
SO PROCEEDINGS OF THE 2016 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 14-18, 2016
CL Dresden, GERMANY
ID COPROCESSOR
AB Convolutional Deep Neural Networks (DNNs) are reported to show outstanding recognition performance in many image-related machine learning tasks. DNNs have a very high computational requirement, making accelerators a very attractive option. These DNNs have many convolutional layers with different parameters in terms of input/output/kernel sizes as well as input stride. Design constraints usually require a single design for all layers of a given DNN. Thus a key challenge is how to design a common architecture that can perform well for all convolutional layers of a DNN, which can be quite diverse and complex. In this paper we present a flexible yet highly efficient 3D neuron array architecture that is a natural fit for convolutional layers. We also present our technique to optimize its parameters including onchip buffer sizes for a given set of resource constraint for modern FPGAs. Our experimental results targeting a Virtex-7 FPGA demonstrate that our proposed technique can generate DNN accelerators that can outperform the state-of-the-art solutions, by 22% for 32-bit floating-point MAC implementations, and are far more scalable in terms of compute resources and DNN size.
C1 [Rahman, Atul; Lee, Jongeun] UNIST Ulsan Natl Inst Sci & Technol, Ulsan, South Korea.
   [Choi, Kiyoung] Seoul Natl Univ, Seoul, South Korea.
RP Lee, J (corresponding author), UNIST Ulsan Natl Inst Sci & Technol, Ulsan, South Korea.
EM jlee@unist.ac.kr
CR Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Ciresan D., 2011, P 22 INT JOINT C ART, V2, P1237
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Zhang C, 2015, PROCEEDINGS OF THE 2015 SYMPOSIUM ON PIEZOELECTRICITY, ACOUSTIC WAVES AND DEVICE APPLICATIONS, P161, DOI 10.1109/SPAWDA.2015.7364463
NR 8
TC 70
Z9 83
U1 0
U2 12
PY 2016
BP 1393
EP 1398
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Kim, SH
   Shin, SG
   Han, S
   Kim, MH
   Pyeon, CH
AF Kim, Song Hyun
   Shin, Sung Gyun
   Han, Sangsoo
   Kim, Moo Hwan
   Pyeon, Cheol Ho
TI Feasibility study on application of an artificial neural network for
   automatic design of a reactor core at the Kyoto University Critical
   Assembly
SO PROGRESS IN NUCLEAR ENERGY
DT Article
DE KUCA; Artificial neural network; Reactor core design; Research reactor;
   Optimization
ID ACCELERATOR-DRIVEN SYSTEM; NEUTRON SOURCE; PROTONS; RATES
AB Designing reactor cores by means of an artificial neural network is a difficult challenge, because there are many variables in the core configuration. Especially, for designing a new type of reactor core with an artificial neural network, little (if any) previous data exists, and the appropriate number of results, such as multiplication factors and neutron fluxes, which require a large computational time for a single calculation, should be previously obtained for training the machine learning of the artificial neural network. This paper presents a feasibility study on the automatic design of a research reactor core (a simplified core based on the Kyoto University Critical Assembly) using an artificial neural network. By imitating conventional design procedure, a way to design the core is developed by means of the artificial neural network and automatic machine learning. After setting a design goal of the reactor core, the fuel assembly and core are designed by the proposed method and compared with those designed by conventional design procedure. The results reveal that the reactor core designed by the proposed method performs well and will, therefore, provide a clue to innovation in future reactor design with artificial intelligence.
C1 [Kim, Song Hyun; Shin, Sung Gyun; Han, Sangsoo; Kim, Moo Hwan] Pohang Univ Sci & Technol, Div Adv Nucl Engn, Pohang 37673, South Korea.
   [Pyeon, Cheol Ho] Kyoto Univ, Res Reactor Inst, Nucl Engn Sci Div, Kumatori, Osaka 5900494, Japan.
RP Kim, SH (corresponding author), Pohang Univ Sci & Technol, Div Adv Nucl Engn, Pohang 37673, South Korea.
EM songhyunkim@postech.ac.kr; shinsg@postech.ac.kr;
   sshan1214@postech.ac.kr; mhkim@postech.ac.kr; pyeon@rri.kyoto-u.ac.jp
CR Bryson A.E., 1969, APPL OPTICAL CONTROL
   Filho L.P., 2013, 2013 INT NUCL ATL C
   Gencel O, 2009, INT J PHYS SCI, V4, P743
   JACOBS RA, 1988, NEURAL NETWORKS, V1, P295, DOI 10.1016/0893-6080(88)90003-2
   Kim S.H., 2018, T KOR NUCL SOC SPRIN
   Kim SH, 2017, ENRGY PROCED, V131, P77, DOI 10.1016/j.egypro.2017.09.478
   Kim SH, 2018, ANN NUCL ENERGY, V112, P337, DOI 10.1016/j.anucene.2017.10.030
   Kim SH, 2017, PROG NUCL ENERG, V100, P60, DOI 10.1016/j.pnucene.2017.05.029
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Montes J.L., 2007, JOINT INT TOP M MATH
   Nozaki N, 2017, FUJITSU SCI TECH J, V53, P43
   Pelowitz Denise B, 2013, MCNP6 USERS MANUAL V
   Persson CM, 2008, ANN NUCL ENERGY, V35, P2357, DOI 10.1016/j.anucene.2008.07.011
   Poteralski A, 2016, IOP CONF SER-MAT SCI, V161, DOI 10.1088/1757-899X/161/1/012040
   Pyeon CH, 2016, J NUCL SCI TECHNOL, V53, P602, DOI 10.1080/00223131.2015.1068716
   Pyeon CH, 2015, NUCL TECHNOL, V192, P181, DOI 10.13182/NT14-111
   Pyeon CH, 2012, ANN NUCL ENERGY, V40, P229, DOI 10.1016/j.anucene.2011.10.011
   Pyeon CH, 2009, J NUCL SCI TECHNOL, V46, P1091, DOI 10.3327/jnst.46.1091
   Ueki T., 2002, Transactions of the American Nuclear Society, V87, P156
   Yamanaka M, 2016, NUCL SCI ENG, V183, P96, DOI 10.13182/NSE15-51
   Ziver A.K., 2002, USE ARTIFICIAL NEURA, V2002
NR 21
TC 2
Z9 2
U1 0
U2 8
PD JAN
PY 2020
VL 119
AR 103183
DI 10.1016/j.pnucene.2019.103183
WC Nuclear Science & Technology
DA 2023-11-11
ER

PT C
AU Zhang, XY
   Bashizade, R
   LaBoda, C
   Dwyer, C
   Lebeck, AR
AF Zhang, Xiangyu
   Bashizade, Ramin
   LaBoda, Craig
   Dwyer, Chris
   Lebeck, Alvin R.
GP IEEE
TI Architecting a Stochastic Computing Unit with Molecular Optical Devices
SO 2018 ACM/IEEE 45TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 45th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 01-06, 2018
CL Los Angeles, CA
DE accelerator; machine learning; Bayesian Inference; Markov Chain Monte
   Carlo; Markov Random Field; emerging technology; Resonance Energy
   Transfer
ID IMAGE SENSOR; SEGMENTATION; NETWORK
AB The increasing difficulty in leveraging CMOS scaling for improved performance requires exploring alternative technologies. A promising technique is to exploit the physical properties of devices to specialize certain computations. A recently proposed approach uses molecular-scale optical devices to construct a Resonance Energy based Sampling Unit (RSU) to accelerate sampling from parameterized probability distributions. Sampling is an important component of many algorithms, including statistical machine learning.
   This paper explores the relationship between application result quality and RSU design. The previously proposed RSU-G focuses on Gibbs sampling using Markov Chain Monte Carlo (MCMC) solvers for Markov Random Field (MRF) Bayesian Inference. By quantitatively analyzing the result quality across three computer vision applications, we find that the previously proposed RSU-G lacks both sufficient precision and dynamic range in key design parameters, which limits the overall result quality compared to software-only MCMC implementations. Naively scaling the problematic parameters to increase precision and dynamic range consumes too much area and power. Therefore, we introduce a new RSU-G microarchitecture that exploits an alternative approach to increase precision that incurs 1.27 x power and equivalent area, while maintaining the significant speedups of the previous design and supporting a wider set of applications.
C1 [Zhang, Xiangyu; Bashizade, Ramin; LaBoda, Craig; Lebeck, Alvin R.] Duke Univ, Durham, NC 27706 USA.
   [Dwyer, Chris] Parabon Labs, Reston, VA USA.
RP Zhang, XY (corresponding author), Duke Univ, Durham, NC 27706 USA.
EM xiangyu.zhang@duke.edu; ramin.bashizade@duke.edu; craig.laboda@duke.edu;
   cdwyer@gmail.com; alvy@cs.duke.edu
CR Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   [Anonymous], HP LAB
   [Anonymous], 1994, MARKOV RANDOM FIELD
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], INT DIG RAND NUMB GE
   [Anonymous], IPSJ SIG NOTES
   [Anonymous], 2009, THESIS
   [Anonymous], 2014, ARXIV14024914
   [Anonymous], 2016, ACM COMPUT SURV, DOI DOI 10.1145/2893356
   [Anonymous], 2012, MACHINE LEARNING PRO
   Aono M, 2013, LANGMUIR, V29, P7557, DOI 10.1021/la400301p
   Assefa S, 2010, NATURE, V464, P80, DOI 10.1038/nature08813
   Baker S, 2011, INT J COMPUT VISION, V92, P1, DOI 10.1007/s11263-010-0390-2
   BARNARD ST, 1989, INT J COMPUT VISION, V3, P17, DOI 10.1007/BF00054836
   Boykov Y, 2001, IEEE T PATTERN ANAL, V23, P1222, DOI 10.1109/34.969114
   Chakrapani LN, 2006, DES AUT TEST EUROPE, P1110
   Chang-Yen DA, 2003, LAB CHIP, V3, P297, DOI 10.1039/b305358j
   Chen RL, 2012, IEEE T CIRCUITS-II, V59, P746, DOI 10.1109/TCSII.2012.2220696
   Cheng L, 2007, COMPUT VIS IMAGE UND, V106, P85, DOI 10.1016/j.cviu.2005.09.009
   Devroye L, 2006, HBK OPERAT RES MANAG, V13, P83, DOI 10.1016/S0927-0507(06)13004-2
   Field RM, 2014, IEEE J SOLID-ST CIRC, V49, P867, DOI 10.1109/JSSC.2013.2293777
   Grivas C, 2012, LASER PHOTONICS REV, V6, P419, DOI 10.1002/lpor.201100034
   Hill MT, 2014, NAT PHOTONICS, V8, P908, DOI 10.1038/nphoton.2014.239
   Ismail YI, 2000, IEEE T VLSI SYST, V8, P195, DOI 10.1109/92.831439
   Joshi A, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P124, DOI 10.1109/NOCS.2009.5071460
   Kanade T, 1996, PROC CVPR IEEE, P196, DOI 10.1109/CVPR.1996.517074
   Khasanvis S, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.367
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   KONRAD J, 1992, IEEE T PATTERN ANAL, V14, P910, DOI 10.1109/34.161350
   LaBoda C, 2014, ACCOUNTS CHEM RES, V47, P1816, DOI 10.1021/ar500054u
   Liu C., 2015, 2015 52 ACMEDACIEEE, P1
   Luan L, 2008, IEEE SENS J, V8, P628, DOI 10.1109/JSEN.2008.918717
   Luan L, 2012, IEEE SENS J, V12, P1794, DOI 10.1109/JSEN.2011.2179027
   Mandai S, 2012, OPT EXPRESS, V20, P5849, DOI 10.1364/OE.20.005849
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Martins M., 2015, P ISPD, P171, DOI DOI 10.1145/2717764.2717783
   Matsumoto M., 1998, ACM Transactions on Modeling and Computer Simulation, V8, P3, DOI 10.1145/272991.272995
   Mitzenmacher M, 2017, PROBABILITY COMPUTIN
   Naruse M, 2013, IEICE T COMMUN, VE96B, P2724, DOI 10.1587/transcom.E96.B.2724
   Niclass C, 2005, IEEE J SOLID-ST CIRC, V40, P1847, DOI 10.1109/JSSC.2005.848173
   Niclass C, 2008, IEEE J SOLID-ST CIRC, V43, P2977, DOI 10.1109/JSSC.2008.2006445
   Ow H, 2005, NANO LETT, V5, P113, DOI 10.1012/nl0482478
   Palem KV, 2005, IEEE T COMPUT, V54, P1123, DOI 10.1109/TC.2005.145
   Palubiak D, 2011, IEEE SENS J, V11, P2401, DOI 10.1109/JSEN.2011.2123090
   Pan Y., 2010, HPCA 16 2010 16 INT, P1
   Pang J, 2015, ACM SIGPLAN NOTICES, V50, P283, DOI 10.1145/2694344.2694377
   Pistol C, 2007, NANOTECHNOLOGY, V18, DOI 10.1088/0957-4484/18/12/125305
   Pistol C, 2010, IEEE MICRO, V30, P110, DOI 10.1109/MM.2010.9
   Scharstein D, 2002, INT J COMPUT VISION, V47, P7, DOI 10.1023/A:1014573219977
   Shambat G, 2012, IEEE J SEL TOP QUANT, V18, P1700, DOI 10.1109/JSTQE.2012.2193666
   Song T, 2014, ISSCC DIG TECH PAP I, V57, P232, DOI 10.1109/ISSCC.2014.6757413
   Stipcevic M, 2014, OPEN PROBLEMS MATH C, P275
   Szirányi T, 2000, REAL-TIME IMAGING, V6, P195, DOI 10.1006/rtim.1998.0159
   Valeur B., 2013, MOL FLUORESCENCE PRI
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wang SY, 2015, IEEE MICRO, V35, P72, DOI 10.1109/MM.2015.124
   Yang AY, 2008, COMPUT VIS IMAGE UND, V110, P212, DOI 10.1016/j.cviu.2007.07.005
NR 58
TC 5
Z9 5
U1 0
U2 0
PY 2018
BP 301
EP 314
DI 10.1109/ISCA.2018.00034
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Bogdan, P
   Chen, F
   Deshwal, A
   Doppa, JR
   Joardar, BK
   Li, H
   Nazarian, S
   Song, LH
   Xiao, Y
AF Bogdan, Paul
   Chen, Fan
   Deshwal, Aryan
   Doppa, Janardhan Rao
   Joardar, Biresh Kumar
   Li, Hai (Helen)
   Nazarian, Shahin
   Song, Linghao
   Xiao, Yao
GP ACM
TI Taming Extreme Heterogeneity via Machine Learning based Design of
   Autonomous Manycore Systems Special Session Paper
SO INTERNATIONAL CONFERENCE ON COMPILERS, ARCHITECTURE, AND SYNTHESIS FOR
   EMBEDDED SYSTEMS (CODES +ISSS) 2019
SE International Conference on Compilers Architecture and Synthesis for
   Embedded Systems
DT Proceedings Paper
CT Embedded Systems Week / Int Conf on Compilers, Architecture, and
   Synthesis for Embedded Systems (CASES) / International Conference on
   Hardware/Software Codesign and System Synthesis (CODES+ISSS) / Int Conf
   on Embedded Software (EMSOFT)
CY OCT 13-18, 2019
CL New York City, NY
DE Model of computation; self-programming computing architectures; manycore
   systems; machine learning; ReRAM; processing-in-memory; autonomous
   design optimization
ID ENERGY-EFFICIENT; SELF-AWARENESS; OPTIMIZATION; ACCELERATOR; ALGORITHM
AB To avoid rewriting software code for new computer architectures and to take advantage of the extreme heterogeneous processing, communication and storage technologies, there is an urgent need for determining the right amount and type of specialization while making a heterogeneous system as programmable and flexible as possible. To enable both programmability and flexibility in the heterogeneous computing era, we propose a novel complex network inspired model of computation and efficient optimization algorithms for determining the optimal degree of parallelization from old software code. This mathematical framework allows us to determine the required number and type of processing elements, the amount and type of deep memory hierarchy, and the degree of reconfiguration for the communication infrastructure, thus opening new avenues to performance and energy efficiency. Our framework enables heterogeneous manycore systems to autonomously adapt from traditional switching techniques to network coding strategies in order to sustain on-chip communication in the order of terabytes. While this new programming model enables the design of self-programmable autonomous heterogeneous manycore systems, a number of open challenges will be discussed.
C1 [Bogdan, Paul; Nazarian, Shahin; Xiao, Yao] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Deshwal, Aryan; Doppa, Janardhan Rao; Joardar, Biresh Kumar] Washington State Univ, Pullman, WA 99164 USA.
   [Chen, Fan; Li, Hai (Helen); Song, Linghao] Duke Univ, Durham, NC 27706 USA.
RP Bogdan, P (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM pbogdan@usc.edu; fan.chen@duke.edu; aryan.deshwal@wsu.edu;
   jana.doppa@wsu.edu; biresh.joardar@wsu.edu; hai.li@duke.edu;
   shahin@usc.edu; ls334@duke.edu; xiaoyao@usc.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2016, 2016 IEEE GLOB COMM
   Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Bandyopadhyay S, 2008, IEEE T EVOLUT COMPUT, V12, P269, DOI 10.1109/TEVC.2007.900837
   CHAN PK, 1994, IEEE T COMPUT AID D, V13, P1088, DOI 10.1109/43.310898
   Chen F, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240805
   Chen F, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317936
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Das S, 2017, PR IEEE COMP DESIGN, P233, DOI 10.1109/ICCD.2017.43
   Das S, 2017, IEEE T COMPUT AID D, V36, P719, DOI 10.1109/TCAD.2016.2604288
   Das S, 2015, ICCAD-IEEE ACM INT, P705, DOI 10.1109/ICCAD.2015.7372639
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Deshwal A, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358206
   Dutt N, 2016, ACM T EMBED COMPUT S, V15, DOI 10.1145/2872936
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fortunato S, 2010, PHYS REP, V486, P75, DOI 10.1016/j.physrep.2009.11.002
   Greer M, 2019, IEEE INT SYMP CIRC S
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Jantsch A, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2017.2757143
   Joardar BK, 2019, DES AUT TEST EUROPE, P138, DOI [10.23919/date.2019.8714832, 10.23919/DATE.2019.8714832]
   Joardar BK, 2019, DES AUT TEST EUROPE, P522, DOI [10.23919/date.2019.8714802, 10.23919/DATE.2019.8714802]
   Joardar BK, 2019, IEEE T COMPUT, V68, P852, DOI 10.1109/TC.2018.2889053
   Joardar Biresh Kumar, 2018, P INT C COMP AID DES, DOI [10.1145/3240765.3243480, DOI 10.1145/3240765.3243480]
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Kim RG, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243483
   Kim RG, 2018, COMPUTER, V51, P66, DOI 10.1109/MC.2018.3011040
   Kim RG, 2017, IEEE T VLSI SYST, V25, P2458, DOI 10.1109/TVLSI.2017.2700726
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Kumar V., 2002, INTRO PARALLEL COMPU
   Lee D, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3357158
   Lee D, 2018, ACM T DES AUTOMAT EL, V23, DOI 10.1145/3223046
   Li M., 2014, ADV NEURAL INFORM PR, P19
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   Lukasiewycz M, 2007, IEEE C EVOL COMPUTAT, P935, DOI 10.1109/CEC.2007.4424570
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Pandiyan D, 2014, I S WORKL CHAR PROC, P171, DOI 10.1109/IISWC.2014.6983056
   Panerati J., 2017, HDB HARDWARESOFTWARE, P189, DOI 10.1007/978-94-017-7267-97
   Preden JS, 2015, COMPUTER, V48, P37, DOI 10.1109/MC.2015.207
   Rabenseifner R, 2009, EUROMICRO WORKSHOP P, P427, DOI [10.1109/.42, 10.1109/PDP.2009.43]
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Schaal S, 1999, TRENDS COGN SCI, V3, P233, DOI 10.1016/S1364-6613(99)01327-3
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sia J, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-46079-x
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Xiao Y, 2017, ICCAD-IEEE ACM INT, P217, DOI 10.1109/ICCAD.2017.8203781
   Xiao Y, 2019, IEEE T VLSI SYST, V27, P1416, DOI 10.1109/TVLSI.2019.2897650
   Xiao Y, 2018, DES AUT TEST EUROPE, P1387, DOI 10.23919/DATE.2018.8342229
   Xue Y., 2015, P PCIM EUR 2015 INT, P1
   Xue YK, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-09774-x
   Xue YK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07209-5
   Xue YK, 2017, ACM T DES AUTOMAT EL, V22, DOI 10.1145/3001934
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
NR 63
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1145/3349567.3357376
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Metz, CA
   Goli, M
   Drechsler, R
AF Metz, Christopher A.
   Goli, Mehran
   Drechsler, Rolf
BE Kubatova, H
   Steininger, A
   Jenihhin, M
   Garbolino, T
   Fiser, P
   Belohoubek, J
   Borecky, J
TI ML-based Power Estimation of Convolutional Neural Networks on GPGPUs
SO 2022 25TH INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS AND SYSTEMS (DDECS)
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 25th International Symposium on Design and Diagnostics of Electronic
   Circuits and Systems (DDECS)
CY APR 06-08, 2022
CL Prague, CZECH REPUBLIC
ID MODEL
AB The increasing application of Machine Learning (ML) techniques on the Internet of Things (IoTs) has led to the leverage of ML accelerators like General Purpose Computing on Graphics Processing Units (GPGPUs) in such devices. However, selecting the most appropriate accelerator for IoT devices is very challenging as they commonly have tight constraints e.g., low power consumption, latency, and cost of the final product. Hence, the design of such application-specific IoT devices becomes a time-consuming and effort-hungry process, that poses the need for accurate and effective automated assisting methods.
   In this paper, we present a novel approach to estimate the power consumption of CUDA-based Convolutional Neural Networks (CNNs) on GPGPUs in the early design phases. The proposed approach takes advantage of a hybrid technique where static analysis is used for features extraction and the K-Nearest Neighbor (K-NN) regression analysis is utilized for power estimation model generation. Using K-NN analysis, the power estimation model can even be created with small training datasets. Experimental results demonstrate that the proposed approach is able to predict CNNs power consumption up to a Absolute Percentage Error of 0.0003% in comparison to the real hardware.
C1 [Metz, Christopher A.; Goli, Mehran; Drechsler, Rolf] Univ Bremen, Inst Comp Sci, D-28359 Bremen, Germany.
   [Goli, Mehran; Drechsler, Rolf] DFKI GmbH, Cyber Phys Syst, D-28359 Bremen, Germany.
RP Metz, CA (corresponding author), Univ Bremen, Inst Comp Sci, D-28359 Bremen, Germany.
EM cmetz@uni-bremen.de; mehran@uni-bremen.de; drechsler@uni-bremen.de
CR Arafa Y, 2019, IEEE COMPUT ARCHIT L, V18, P55, DOI 10.1109/LCA.2019.2904497
   Ardalani N, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P725, DOI 10.1145/2830772.2830780
   Baldini Ioana, 2014, 2014 IEEE 26th International Symposium on Computer Architecture and High-Performance Computing (SBAC-PAD), P254, DOI 10.1109/SBAC-PAD.2014.30
   Braun L, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3431731
   Busia P, 2021, IEEE ACCESS, V9, P133289, DOI 10.1109/ACCESS.2021.3115243
   Carroll TC, 2017, INT CONF PARA PROC, P113, DOI 10.1109/ICPPW.2017.28
   Chen J., 2011, P 2011 INT GREEN COM, P1, DOI 10.1109/IGCC.2011.6008582
   Cui LZ, 2018, INT J MACH LEARN CYB, V9, P1399, DOI 10.1007/s13042-018-0834-5
   Djenouri Y, 2021, IEEE T IND INFORM, V17, P2947, DOI 10.1109/TII.2020.3001493
   Fingeroff M, MACHINE LEARNING EDG
   Goli M, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3388140
   Goli M, 2018, P IEEE RAP SYST PROT, P97, DOI 10.1109/RSP.2018.8631997
   Guerreiro J, 2019, IEEE T PARALL DISTR, V30, P2494, DOI 10.1109/TPDS.2019.2917181
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Imandoust S.B., 2013, INT J ENG RES APPL, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Lechner M., 2021, IEEE ACCESS
   Metz C. A., 2021, ARXIV
   Metz CA, 2021, 2021 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS 2021), P29, DOI 10.1145/3478684.3479255
   Nagasaka H., 2010, 2010 International Conference on Green Computing (Green Comp), P115, DOI 10.1109/GREENCOMP.2010.5598315
   Nvidia, NVID TUR GPU ARCH
   nvidia, CUDA TOOLK DOC
   NVIDIA, 2017, NVIDIA TESLA V100 GP
   Qiang Wang, 2017, ACM SIGMETRICS Performance Evaluation Review, V45, P73, DOI 10.1145/3152042.3152066
   Song SW, 2013, INT PARALL DISTRIB P, P673, DOI 10.1109/IPDPS.2013.73
   Tensorflow, TENS GPU
   Wang Q, 2020, IEEE T PARALL DISTR, V31, P2865, DOI 10.1109/TPDS.2020.3004623
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
NR 27
TC 2
Z9 2
U1 0
U2 1
PY 2022
BP 166
EP 171
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, HM
   Fan, XT
   Jiao, L
   Cao, W
   Zhou, XG
   Wang, LL
AF Li, Huimin
   Fan, Xitian
   Jiao, Li
   Cao, Wei
   Zhou, Xuegong
   Wang, Lingli
GP IEEE
TI A High Performance FPGA-based Accelerator for Large-Scale Convolutional
   Neural Networks
SO 2016 26TH INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 26th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2016
CL Ecole Polytechnique Federale de Lausanne, Lausanne, SWITZERLAND
HO Ecole Polytechnique Federale de Lausanne
DE convolutional neural networks; pipeline; AlexNet; parallelism; memory
   bandwidth
ID COPROCESSOR
AB In recent years, convolutional neural networks (CNNs) based machine learning algorithms have been widely applied in computer vision applications. However, for large-scale CNNs, the computation-intensive, memory-intensive and resource-consuming features have brought many challenges to CNN implementations. This work proposes an end-to-end FPGA-based CNN accelerator with all the layers mapped on one chip so that different layers can work concurrently in a pipelined structure to increase the throughput. A methodology which can find the optimized parallelism strategy for each layer is proposed to achieve high throughput and high resource utilization. In addition, a batch-based computing method is implemented and applied on fully connected layers (FC layers) to increase the memory bandwidth utilization due to the memory-intensive feature. Further, by applying two different computing patterns on FC layers, the required on-chip buffers can be reduced significantly. As a case study, a state-of-the-art large-scale CNN, AlexNet, is implemented on Xilinx VC709. It can achieve a peak performance of 565.94 GOP/s and 391 FPS under 156MHz clock frequency which outperforms previous approaches.
C1 [Li, Huimin; Fan, Xitian; Jiao, Li; Cao, Wei; Zhou, Xuegong; Wang, Lingli] Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
RP Cao, W (corresponding author), Fudan Univ, State Key Lab ASIC & Syst, Shanghai, Peoples R China.
EM caow@fudan.edu.cn
CR Abdel-Hamid O., 2014, AUDIO SPEECH LANGUAG
   [Anonymous], 2015, ARXIV150202551
   [Anonymous], 2013, IEEE T PATTERN ANAL, DOI DOI 10.1109/TPAMI.2012.59
   [Anonymous], INT C LEARN REPR ICL
   [Anonymous], P IEEE
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Du Z., 2015, ACM INT S COMP ARCH
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiu J., 2016, ACM INT S FIELD PROG
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Simonyan K., 2014, EPRINT ARXIV
   Suda N., 2016, ACM INT S FIELD PROG
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Sun Yi, 2014, NEURIPS
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 23
TC 132
Z9 149
U1 3
U2 30
PY 2016
DI 10.1109/FPL.2016.7577308
WC Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU De, SYD
   Shafique, M
   Corporaal, H
AF De, Sayandip
   Shafique, Muhammad
   Corporaal, Henk
TI Delay Prediction for ASIC HLS: Comparing Graph-Based and Nongraph-Based
   Learning Models
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Delay timing prediction; electronic design automation (EDA); graph
   neural networks; high-level synthesis (HLS); logic synthesis (LS);
   machine learning (ML)
ID NEURAL-NETWORKS
AB While high-level synthesis (HLS) tools offer faster design of hardware accelerators with different area versus delay tradeoffs, HLS-based delay estimates often deviate significantly from results obtained from ASIC logic synthesis (LS) tools. Current HLS tools rely on simple additive delay models which fail to capture the downstream optimizations performed during LS and technology mapping. Inaccurate delay estimates prevent fast and accurate design-space exploration without performing timeconsuming LS tasks. In this work, we exploit different machine learning models which automatically learn to map the different downstream optimizations onto the HLS critical paths. In particular, we compare graph-based and nongraph-based learning models to investigate their efficacy, devise hybrid models to get the best of the both worlds. To carry out our learning-assisted methodology, we create a dataset of different HLS benchmarks and develop an automated framework, which extends a commercial HLS toolchain, to extract essential information from LS critical path and automatically matches this information to HLS path. This is a nontrivial task to perform manually due to difference in level of abstractions. Finally, we train the proposed hybrid models through inductive learning and integrate them in the commercial HLS toolchain to improve delay prediction accuracy. Experimental results demonstrate significant improvements in delay estimation accuracy across a wide variety of benchmark designs. We demonstrate that the graph-based models can infer essential structural features from the input design, while incorporating them into traditional nongraph-based models can significantly improve the model accuracy. Such "hybrid" models can improve delay prediction accuracy by 93% compared to simple additive models and provide 175x speedup compared to LS. Furthermore, we discuss key insights from our experiments, identifying the influence of different HLS features on model performance.
C1 [De, Sayandip; Corporaal, Henk] Eindhoven Univ Technol, Dept Elect Engn, NL-5600 MB Eindhoven, Netherlands.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Dept Elect & Comp Engn, Abu Dhabi, U Arab Emirates.
RP De, SYD (corresponding author), Eindhoven Univ Technol, Dept Elect Engn, NL-5600 MB Eindhoven, Netherlands.
EM sayandip.de@tue.nl; muhammad.shafique@nyu.edu; h.corporaal@tue.nl
CR Alawieh Mohamed Baker, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P26, DOI 10.1109/ASP-DAC47756.2020.9045178
   cadence, GEN SYNTH SOL
   cadence, STRAT HIGH LEV SYNTH
   Cong J, 2006, DES AUT CON, P433, DOI 10.1109/DAC.2006.229228
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Licht JD, 2021, IEEE T PARALL DISTR, V32, P1014, DOI 10.1109/TPDS.2020.3039409
   Ellouz S, 2006, INT TEST CONF P, P123
   Fey M, 2019, Arxiv, DOI [arXiv:1903.02428, 10.48550/arxiv.1903.02428]
   Haaswijk W, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351885
   Hamilton WL., 2017, ADV NEURAL INFORM PR, V2017, P1025, DOI DOI 10.48550/ARXIV.1706.02216
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   He ZL, 2020, PR IEEE COMP DESIGN, P324, DOI 10.1109/ICCD50377.2020.00061
   Hosny Abdelrahman, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P581, DOI 10.1109/ASP-DAC47756.2020.9045559
   Huang GY, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3451179
   Jiang DJ, 2021, J CHEMINFORMATICS, V13, DOI 10.1186/s13321-020-00479-8
   Katz Y, 2011, DES AUT CON, P848
   Liu ZY, 2019, INT TEST CONF P, DOI [10.1109/itc44170.2019.9000131, 10.1109/TKDE.2019.2891581]
   Lu YC, 2019, ICCAD-IEEE ACM INT, DOI [10.1109/iccad45719.2019.8942063, 10.1109/southeastcon42311.2019.9020657, 10.1145/3290605.3300430]
   Lundberg SM, 2017, ADV NEUR IN, V30
   Maarouf D, 2018, I C FIELD PROG LOGIC, P427, DOI 10.1109/FPL.2018.00079
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Mantovani P, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415753
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Neto WL, 2019, ICCAD-IEEE ACM INT
   networkx, NETW AN PYTH
   Pedregosa F., 2012, J MACH LEARNING RES, V12, P2825, DOI DOI 10.48550/ARXIV.1201.0490
   stanford, DEEPSN
   STONE M, 1974, J R STAT SOC B, V36, P111, DOI 10.1111/j.2517-6161.1974.tb00994.x
   Thost Veronika, 2021, INT C LEARN REPR
   Ustun E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415657
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Velickovic P., 2017, INT C LEARN REPR, V1050, P10, DOI DOI 10.48550/ARXIV.1710.10903
   Wang FC, 2018, PR GR LAK SYMP VLSI, P207, DOI 10.1145/3194554.3194561
   Welling M., 2016, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Wu N., 2021, P GREAT LAK S VLSI J, P39
   [谢志鹏 Xie Zhipeng], 2018, [高分子通报, Polymer Bulletin], P1
   xilinx, XIL VIV DES SUIT
   Yu CX, 2018, DES AUT CON, DOI 10.1145/3195970.3196026
NR 39
TC 1
Z9 1
U1 1
U2 1
PD APR
PY 2023
VL 42
IS 4
BP 1133
EP 1146
DI 10.1109/TCAD.2022.3197977
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Panchbhaiyye, V
   Ogunfunmi, T
AF Panchbhaiyye, Vineet
   Ogunfunmi, Tokunbo
GP IEEE
TI A FIFO BASED ACCELERATOR FOR CONVOLUTIONAL NEURAL NETWORKS
SO 2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
DT Proceedings Paper
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 04-08, 2020
CL Barcelona, SPAIN
DE Convolution Neural Networks; FPGA; Dataflow Processing; Hardware
   Implementation; Machine Learning
AB In recent years, Deep Neural Networks (DNNs) have achieved state-of-the-art results in various fields like Computer Vision, Natural Language Processing and Speech Recognition. Of all the DNN architectures, Convolutional Neural Networks (CNNs) have been most effective in tasks like image classification and object detection. The high performance of the CNNs comes at the cost of computational complexity. Currently Graphics Processing Units (GPUs) are used to accelerate CNN training and inference on workstations and data servers. Though popular, GPUs are not suitable for embedded applications because they are not energy efficient. ASIC and FPGA accelerators have the potential to run CNNs that are optimized for energy and performance.
   In this paper we present an architecture which takes a novel approach to compute convolution results using row-wise inputs as opposed to traditional tile-based processing. We are able to exceed the results of state of the art architectures when implemented on an inexpensive PYNQ Z1 board running at 100Mhz. The total latency to run the convolution layers in the VGG16 benchmark is nearly 1.5x lower for our architecture than state of the art architectures.
C1 [Panchbhaiyye, Vineet; Ogunfunmi, Tokunbo] Santa Clara Univ, Dept Elect Engn, Santa Clara, CA 95053 USA.
RP Panchbhaiyye, V (corresponding author), Santa Clara Univ, Dept Elect Engn, Santa Clara, CA 95053 USA.
CR Ansari A, 2017, CONF REC ASILOMAR C, P1337, DOI 10.1109/ACSSC.2017.8335571
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Digilent Inc, 2019, PYNQ Z1 REF MAN
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Kim Y., 2014, P EMP METH NAT LANG, P1746, DOI [DOI 10.3115/V1/D14-1181, 10.3115/v1/D14-1181]
   Nair V., 2010, ICML, P807
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang SH, 2017, DES AUT TEST EUROPE, P1032, DOI 10.23919/DATE.2017.7927142
   Xilinx Inc, 2018, PYNQ PYTH LIB V2 4
NR 12
TC 3
Z9 3
U1 0
U2 4
PY 2020
BP 1758
EP 1762
DI 10.1109/icassp40776.2020.9053228
WC Acoustics; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Nakanoya, M
   Narasimhan, SS
   Bhat, S
   Anemogiannis, A
   Datta, A
   Katti, S
   Chinchali, S
   Pavone, M
AF Nakanoya, Manabu
   Narasimhan, Sai Shankar
   Bhat, Sharachchandra
   Anemogiannis, Alexandros
   Datta, Akul
   Katti, Sachin
   Chinchali, Sandeep
   Pavone, Marco
TI Co-design of communication and machine inference for cloud robotics
SO AUTONOMOUS ROBOTS
DT Article
AB Today, even the most compute-and-power constrained robots can measure complex, high data-rate video and LIDAR sensory streams. Often, such robots, ranging from low-power drones to space and subterranean rovers, need to transmit high-bitrate sensory data to a remote compute server if they are uncertain or cannot scalably run complex perception or mapping tasks locally. However, today's representations for sensory data are mostly designed for human, not robotic, perception and thus often waste precious compute or wireless network resources to transmit unimportant parts of a scene that are unnecessary for a high-level robotic task. This paper presents an algorithm to learn task-relevant representations of sensory data that are co-designed with a pre-trained robotic perception model's ultimate objective. Our algorithm aggressively compresses robotic sensory data by up to 11x more than competing methods. Further, it achieves high accuracy and robust generalization on diverse tasks including Mars terrain classification with low-power deep learning accelerators, neural motion planning, and environmental timeseries classification.
C1 [Nakanoya, Manabu] NEC Corp Ltd, Tokyo, Japan.
   [Narasimhan, Sai Shankar; Bhat, Sharachchandra; Chinchali, Sandeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Anemogiannis, Alexandros] VMware, Palo Alto, CA USA.
   [Datta, Akul] Univ Illinois, Dept Comp Sci, Champaign, IL USA.
   [Katti, Sachin; Pavone, Marco] Stanford Univ, Dept Comp Sci, Stanford, CA USA.
RP Narasimhan, SS (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM nakanoya@nec.com; nsaishankar@utexas.edu; sharachchandra@utexas.edu;
   skatti@stanford.edu; sandeepc@utexas.edu; pavone@stanford.edu
CR Akcin O., 2022, 6 ANN C ROB LEARN
   [Anonymous], 2022, SEMANTIC DISTORTION
   [Anonymous], 2019, EDGE TPU
   [Anonymous], 2010, IEEE RAS INT C HUM R
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cheng Y., 2017, ARXIV171009282
   Chinchali S., 2019, ARXIV
   Chinchali SP, 2018, HOTNETS-XVII: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P50, DOI 10.1145/3286062.3286070
   Crawshaw M., 2020, ARXIV
   Devlin J., 2018, PREPRINT
   Emmons J, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HOT TOPICS IN VIDEO ANALYTICS AND INTELLIGENT EDGES (HOTEDGEVIDEO '19), P27, DOI 10.1145/3349614.3356023
   Engstrom L., 2019, ARXIV
   Engstrom Logan, 2019, ROBUSTNESS PYTHON LI
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   Kang YP, 2017, ACM SIGPLAN NOTICES, V52, P615, DOI 10.1145/3093336.3037698
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Kassir A, 2015, INT J ROBOT RES, V34, P173, DOI 10.1177/0278364914556911
   KeckInstitute for spacestudies, 2020, VIRT WORKSH NEB DE 2
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Kehoe B, 2013, IEEE INT CONF ROBOT, P4263, DOI 10.1109/ICRA.2013.6631180
   Kingma D., 2013, ARXIV
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Li PS, 2018, IEEE INT CON AUTO SC, P1420, DOI 10.1109/COASE.2018.8560447
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Manchester Z., 2013, KICKSAT CROWD FUNDED
   Mars reconnaissance orbiter, 2020, COMM EARTH
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456
   Nakanoya M, 2021, ROBOT SCI SYS
   Nenci F, 2014, IEEE INT C INT ROBOT, P3794, DOI 10.1109/IROS.2014.6943095
   Pacelli V., 2020, ARXIV
   Pacelli V, 2019, IEEE INT CONF ROBOT, P2061, DOI [10.1109/icra.2019.8794213, 10.1109/ICRA.2019.8794213]
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   ROUSSEEUW PJ, 1987, J COMPUT APPL MATH, V20, P53, DOI 10.1016/0377-0427(87)90125-7
   Sonar A., 2020, ARXIV
   Tan M., 2019, ARXIV
   Tanwani AK, 2020, IEEE ROBOT AUTOM LET, V5, P4423, DOI 10.1109/LRA.2020.2998414
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Tsipras D., 2018, ARXIV
   Tu CX, 2019, IEEE INT CONF ROBOT, P3274, DOI [10.1109/icra.2019.8794264, 10.1109/ICRA.2019.8794264]
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   van der Merwe JR, 2020, 2020 EUROPEAN NAVIGATION CONFERENCE (ENC), DOI 10.23919/enc48637.2020.9317518
   Weber M., 2019, ARXIV
NR 43
TC 0
Z9 0
U1 2
U2 5
PD JUN
PY 2023
VL 47
IS 5
SI SI
BP 579
EP 594
DI 10.1007/s10514-023-10093-w
EA MAR 2023
WC Computer Science, Artificial Intelligence; Robotics
DA 2023-11-11
ER

PT J
AU Kim, S
   Kim, J
   Jang, Y
   Kung, J
   Lee, S
AF Kim, Sejin
   Kim, Jungwoo
   Jang, Yongjoo
   Kung, Jaeha
   Lee, Sungjin
TI SEMS: Scalable Embedding Memory System for Accelerating Embedding-Based
   DNNs
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE DNN accelerators; embeddings; recommender systems; system for machine
   learning
AB Embedding layers, which are widely used in various deep learning (DL) applications, are very large in size and are increasing. We propose scalable embedding memory system (SEMS) to deal with the inference of DL applications with a large embedding layer. SEMS is built using scalable embedding memory (SEM) modules, which include FPGA for acceleration. In SEMS, PCIe bus, which is scalable and versatile, is used to expand the system memory and processing in SEMs reduces the amount of data transferred from SEMs to host, improving the effective bandwidth of PCIe. In order to achieve better performance, we apply various optimization techniques at different levels. We develop SEMlib, a Python library to provide convenience in using SEMS. We implement a proof-of-concept prototype of SEMS and using SEMS yields DLRM execution time that is 32.85x faster than that of a CPU-based system when there is a lack of DRAM to hold the entire embedding layer.
C1 [Kim, Sejin; Kim, Jungwoo; Jang, Yongjoo; Kung, Jaeha; Lee, Sungjin] DGIST, Dept Elect Engn & Comp Sci, Daegu 42988, South Korea.
RP Lee, S (corresponding author), DGIST, Dept Elect Engn & Comp Sci, Daegu 42988, South Korea.
EM sejink06@dgist.ac.kr; jungwoo@dgist.ac.kr; dracol@dgist.ac.kr;
   jhkung@dgist.ac.kr; sungjin.lee@dgist.ac.kr
CR Ardestani EK, 2021, Arxiv, DOI arXiv:2110.11489
   BittWare, 2022, 250 M2D M 2 ACC MOD
   Carballo-Hernandez Walther, 2021, ARXIV
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Kaggle, 2014, CRIT DISPL ADV CHALL
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Naumov Maxim, 2019, ARXIV
   Park J, 2018, Arxiv, DOI arXiv:1811.09886
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Xilinx Inc, 2021, ALV U200 U250 DAT CT
NR 10
TC 0
Z9 0
U1 0
U2 0
PD JUL-DEC
PY 2022
VL 21
IS 2
BP 157
EP 160
DI 10.1109/LCA.2022.3227560
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Carmichael, Z
   Langroudi, HF
   Khazanov, C
   Lillie, J
   Gustafson, JL
   Kudithipudi, D
AF Carmichael, Zachariah
   Langroudi, Hamed F.
   Khazanov, Char
   Lillie, Jeffrey
   Gustafson, John L.
   Kudithipudi, Dhireesha
GP IEEE
TI Deep Positron: A Deep Neural Network Using the Posit Number System
SO 2019 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 22nd Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 25-29, 2019
CL Florence, ITALY
DE deep neural networks; machine learning; DNN accelerators; posits;
   floating point; tapered precision; low-precision
AB The recent surge of interest in Deep Neural Networks (DNNs) has led to increasingly complex networks that tax computational and memory resources. Many DNNs presently use 16-bit or 32-bit floating point operations. Significant performance and power gains can be obtained when DNN accelerators support low-precision numerical formats. Despite considerable research, there is still a knowledge gap on how low-precision operations can be realized for both DNN training and inference. In this work, we propose a DNN architecture, Deep Positron, with posit numerical format operating successfully at <= 8 bits for inference. We propose a precision-adaptable FPGA soft core for exact multiply-and-accumulate for uniform comparison across three numerical formats, fixed, floating-point and posit. Preliminary results demonstrate that 8-bit posit has better accuracy than 8-bit fixed or floating-point for three different low-dimensional datasets. Moreover, the accuracy is comparable to 32-bit floating-point on a Xilinx Virtex-7 FPGA device. The trade-offs between DNN performance and hardware resources, i.e. latency, power, and resource utilization, show that posit outperforms in accuracy and latency at 8-bit and below.
C1 [Carmichael, Zachariah; Langroudi, Hamed F.; Khazanov, Char; Lillie, Jeffrey; Kudithipudi, Dhireesha] Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
   [Gustafson, John L.] Natl Univ Singapore, Singapore, Singapore.
RP Carmichael, Z (corresponding author), Rochester Inst Technol, Neuromorph AI Lab, Rochester, NY 14623 USA.
CR [Anonymous], 2014, CORR
   Bengio Yoshua, 2013, Statistical Language and Speech Processing. First International Conference, SLSP 2013. Proceedings: LNCS 7978, P1, DOI 10.1007/978-3-642-39593-2_1
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cococcioni M, 2018, 2018 INTERNATIONAL CONFERENCE OF ELECTRICAL AND ELECTRONIC TECHNOLOGIES FOR AUTOMOTIVE
   Fisher RA, 1936, ANN EUGENIC, V7, P179, DOI 10.1111/j.1469-1809.1936.tb02137.x
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han S., 2016, INT C LEARN REPR ICL
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Iwata A., 1989, IJCNN, V2, P171
   Johnson J., 2018, ARXIV181101721
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kulisch U., 2013, COMPUTER ARITHMETIC, V33
   Langroudi SHF, 2018, 2018 1ST WORKSHOP ON ENERGY EFFICIENT MACHINE LEARNING AND COGNITIVE COMPUTING FOR EMBEDDED APPLICATIONS (EMC2), P19, DOI 10.1109/EMC2.2018.00012
   Mishra A., 2018, ARXIV180300227
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Schlimmer JC, 1987, CONCEPT ACQUISITION
   Shannon C. E., 1948, BELL SYST TECH J, VVol. 27, P623, DOI [DOI 10.1002/J.1538-7305.1948.TB00917.X, DOI 10.1002/J.1538-7305.1948.TB01338.X]
   Shazeer, 2017, P 5 INT C LEARN REPR
   STREET WN, 1993, P SOC PHOTO-OPT INS, V1905, P861, DOI 10.1117/12.148698
   Tichy W., 2016, UBIQUITY, V2016, P1
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
NR 23
TC 52
Z9 52
U1 0
U2 3
PY 2019
BP 1421
EP 1426
DI 10.23919/date.2019.8715262
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jinguji, A
   Sato, S
   Nakahara, H
AF Jinguji, Akira
   Sato, Shimpei
   Nakahara, Hiroki
TI An FPGA Realization of a Random Forest with <i>k</i>-Means Clustering
   Using a High-Level Synthesis Design
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
DT Article
DE machine learning; random forest; k-means clustering; FPGA
AB A random forest (RF) is a kind of ensemble machine learning algorithm used for a classification and a regression. It consists of multiple decision trees that are built from randomly sampled data. The RF has a simple, fast learning, and identification capability compared with other machine learning algorithms. It is widely used for application to various recognition systems. Since it is necessary to un-balanced trace for each tree and requires communication for all the ones, the random forest is not suitable in SIMD architectures such as GPUs. Although the accelerators using the FPGA have been proposed, such implementations were based on HDL design. Thus, they required longer design time than the soft-ware based realizations. In the previous work, we showed the high-level synthesis design of the RF including the fully pipelined architecture and the all-toall communication. In this paper, to further reduce the amount of hardware, we use k-means clustering to share comparators of the branch nodes on the decision tree. Also, we develop the krange tool flow, which generates the bitstream with a few number of hyper parameters. Since the proposed tool flow is based on the high-level synthesis design, we can obtain the high performance RF with short design time compared with the conventional HDL design. We implemented the RF on the Xilinx Inc. ZC702 evaluation board. Compared with the CPU (Intel Xeon (R) E5607 Processor) and the GPU (NVidia Geforce Titan) implementations, as for the performance, the FPGA realization was 8.4 times faster than the CPU one, and it was 62.8 times faster than the GPU one. As for the power consumption efficiency, the FPGA realization was 7.8 times better than the CPU one, and it was 385.9 times better than the GPU one.
C1 [Jinguji, Akira; Sato, Shimpei; Nakahara, Hiroki] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
RP Jinguji, A (corresponding author), Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
EM jinguji@eda.ict.e.titech.ac.jp; satos@eda.ict.e.titech.ac.jp;
   nakahara@ict.e.titech.ac.jp
CR Amit Y, 1997, NEURAL COMPUT, V9, P1545, DOI 10.1162/neco.1997.9.7.1545
   [Anonymous], 2010, CVPR
   [Anonymous], 2007, P 18 ANN ACM SIAM S
   [Anonymous], INT SDK OPENCL
   [Anonymous], INT WORKSH OPENCL 20
   [Anonymous], BMVC
   [Anonymous], IEEE ANN INT S FIELD
   [Anonymous], 2000, ICML
   [Anonymous], COMP VIS LOW POW REC
   [Anonymous], INT C FIELD PROGR TE
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Dantone M, 2012, PROC CVPR IEEE, P2578, DOI 10.1109/CVPR.2012.6247976
   Le HA, 2008, ANN IEEE SYM FIELD P, P33, DOI 10.1109/FCCM.2008.9
   Lo WT, 2014, SCI WORLD J, DOI 10.1155/2014/745640
   MacQueen J., 1967, P 5 BERK S MATH STAT, P1
   Narayanan R, 2007, DES AUT TEST EUROPE, P189
   Oberg J., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P330, DOI 10.1109/FPL.2012.6339226
   Özuysal M, 2010, IEEE T PATTERN ANAL, V32, P448, DOI 10.1109/TPAMI.2009.23
   Shotton J, 2011, PROC CVPR IEEE, P1297, DOI 10.1109/CVPR.2011.5995316
NR 19
TC 8
Z9 8
U1 0
U2 7
PD FEB
PY 2018
VL E101D
IS 2
BP 354
EP 362
DI 10.1587/transinf.2017RCP0006
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Shoaib, M
   Jha, NK
   Verma, N
AF Shoaib, Mohammed
   Jha, Niraj K.
   Verma, Naveen
TI Algorithm-Driven Architectural Design Space Exploration of
   Domain-Specific Medical-Sensor Processors
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Biomedical sensor processors; classification accelerators; embedded
   machine learning; low-energy design by voltage and precision scaling;
   structured hardware specialization; support-vector machines
ID SYNTHESIS METHODOLOGY; CUSTOM-INSTRUCTION; MACHINE; CLASSIFICATION;
   COPROCESSOR; PERFORMANCE; BIOMARKERS; DIAGNOSIS; CIRCUIT; ECG
AB Data-driven machine-learning techniques enable the modeling and interpretation of complex physiological signals. The energy consumption of these techniques, however, can be excessive, due to the complexity of the models required. In this paper, we study the tradeoffs and limitations imposed by the energy consumption of high-order detection models implemented in devices designed for intelligent biomedical sensing. Based on the flexibility and efficiency needs at various processing stages in data-driven biomedical algorithms, we explore options for hardware specialization through architectures based on custom instruction and coprocessor computations. We identify the limitations in the former, and propose a coprocessor-based platform that exploits parallelism in computation as well as voltage scaling to operate at a subthreshold minimum-energy point. We present results from post-layout simulation of cardiac arrhythmia detection with patient data from the MIT-BIH database. After wavelet-based feature extraction, which consumes 12.28 mu J, we demonstrate classification computations in the 12.00-120.05 mu J range using 10 000-100 000 support vectors. This represents 1170x lower energy than that of a low-power processor with custom instructions alone. After morphological feature extraction, which consumes 8.65 mu J of energy, the corresponding energy numbers are 10.24-24.51 mu J, which is 1548x smaller than one based on a custom-instruction design. Results correspond to V-dd = 0.4 V and a data precision of 8 b.
C1 [Shoaib, Mohammed; Jha, Niraj K.; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Shoaib, M (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM mshoaib@princeton.edu; jha@princeton.edu; nverma@princeton.edu
CR AbuKhater IS, 1996, IEEE J SOLID-ST CIRC, V31, P1535, DOI 10.1109/4.540066
   [Anonymous], P ACM IEEE INT S LOW
   [Anonymous], P 12 ANN INT C IEEE
   Avestruz AT, 2008, IEEE J SOLID-ST CIRC, V43, P3006, DOI 10.1109/JSSC.2008.2006460
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Chandrakasan AP, 2008, ANNU REV BIOMED ENG, V10, P247, DOI 10.1146/annurev.bioeng.10.061807.160547
   Chapelle O, 2000, ADV NEUR IN, V12, P230
   Chen TW, 2010, IEEE J SOLID-ST CIRC, V45, P2321, DOI 10.1109/JSSC.2010.2067910
   Csavoy A, 2009, SYMP VLSI CIRCUITS, P4
   de Chazal P, 2000, COMPUT CARDIOL, V27, P327, DOI 10.1109/CIC.2000.898523
   de Chazal P, 2004, IEEE T BIO-MED ENG, V51, P1196, DOI 10.1109/TBME.2004.827359
   Dishman E, 2004, COMPUTER, V37, P34, DOI 10.1109/MC.2004.1297237
   Gyselinckx B, 2006, IFIP VLSI-SOC 2006: IFIP WG 10.5 INTERNATIONAL CONFERENCE ON VERY LARGE SCALE INTEGRATION & SYSTEM-ON-CHIP, P175
   Hau D., 1994, P AAAI S ART INT MED, VSS-94-01, P67
   Jaffe AS, 2006, J AM COLL CARDIOL, V48, P1, DOI 10.1016/j.jacc.2006.02.056
   Joachims T., 2010, SVM LIGHT SUPPORT VE
   Kim H, 2009, IEEE ENG MED BIO, P5409, DOI 10.1109/IEMBS.2009.5332815
   Krupa N, 2011, BIOMED ENG ONLINE, V10, DOI 10.1186/1475-925X-10-6
   Kwong J, 2011, IEEE J SOLID-ST CIRC, V46, P1742, DOI 10.1109/JSSC.2011.2144450
   LAGUNA P, 1990, MED BIOL ENG COMPUT, V28, P67, DOI 10.1007/BF02441680
   Lee KH, 2011, INT CONF ACOUST SPEE, P1597
   Manne U, 2005, DRUG DISCOV TODAY, V10, P965, DOI 10.1016/S1359-6446(05)03487-2
   MENDELSON WB, 1987, PSYCHIAT RES, V21, P89, DOI 10.1016/0165-1781(87)90067-9
   Meyfroidt G, 2009, BEST PRAC RES-CL ANA, V23, P127, DOI 10.1016/j.bpa.2008.09.003
   Nie ZD, 2009, IEEE ENG MED BIO, P2559, DOI 10.1109/IEMBS.2009.5335295
   Osowski S, 2001, IEEE T BIO-MED ENG, V48, P1265, DOI 10.1109/10.959322
   PAN J, 1985, IEEE T BIO-MED ENG, V32, P230, DOI 10.1109/TBME.1985.325532
   Physionet, 2012, MIT BIH PHYS DAT
   Sajda P, 2006, ANNU REV BIOMED ENG, V8, P537, DOI 10.1146/annurev.bioeng.8.061505.095802
   Schleif F.-M., 2007, COMPUT VIS SCI, V4, P189
   Seiler L, 2009, IEEE MICRO, V29, P10, DOI 10.1109/MM.2009.9
   SENHADJI L, 1995, IEEE ENG MED BIOL, V14, P167, DOI 10.1109/51.376755
   Shoaib M, 2011, DES AUT CON, P591
   Shoeb A. H., 2009, THESIS MIT BOSTON
   Shoeb A, 2005, P ANN INT IEEE EMBS, P3546, DOI 10.1109/IEMBS.2005.1617245
   Shoeb A, 2009, IEEE ENG MED BIO, P4202, DOI 10.1109/IEMBS.2009.5333790
   Somorjai RL, 2004, COMPU BIOL, V5, P67
   Sridhara SR, 2010, SYMP VLSI CIRCUITS, P15, DOI 10.1109/VLSIC.2010.5560251
   Sun F, 2004, IEEE T COMPUT AID D, V23, P216, DOI 10.1109/TCAD.2003.822133
   Sun F, 2007, IEEE T COMPUT AID D, V26, P2035, DOI 10.1109/TCAD.2007.906457
   Sun F, 2006, IEEE T VLSI SYST, V14, P1175, DOI 10.1109/TVLSI.2006.886410
   Sun F, 2006, IEEE T COMPUT AID D, V25, P1589, DOI 10.1109/TCAD.2005.858269
   Sunderland T, 2005, BIOL PSYCHIAT, V58, P272, DOI 10.1016/j.biopsych.2005.05.016
   Tang CHH, 2010, PHYSIOL MEAS, V31, P775, DOI 10.1088/0967-3334/31/6/004
   Tensilica Inc, 2012, XTENS PROC
   Übeyli ED, 2007, DIGIT SIGNAL PROCESS, V17, P675, DOI 10.1016/j.dsp.2006.11.009
   Verma N, 2009, SYMP VLSI CIRCUITS, P62
   Vitale SA, 2010, P IEEE, V98, P333, DOI 10.1109/JPROC.2009.2034476
   Wang A, 2005, IEEE J SOLID-ST CIRC, V40, P310, DOI 10.1109/JSSC.2004.837945
NR 49
TC 6
Z9 6
U1 0
U2 14
PD OCT
PY 2013
VL 21
IS 10
BP 1849
EP 1862
DI 10.1109/TVLSI.2012.2220161
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Hanuka, A
   Huang, X
   Shtalenkova, J
   Kennedy, D
   Edelen, A
   Zhang, Z
   Lalchand, VR
   Ratner, D
   Duris, J
AF Hanuka, Adi
   Huang, X.
   Shtalenkova, J.
   Kennedy, D.
   Edelen, A.
   Zhang, Z.
   Lalchand, V. R.
   Ratner, D.
   Duris, J.
TI Physics model-informed Gaussian process for online optimization of
   particle accelerators
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
ID BAYESIAN OPTIMIZATION
AB High-dimensional optimization is a critical challenge for operating large-scale scientific facilities. We apply a physics-informed Gaussian process (GP) optimizer to tune a complex system. Typical GP models learn from past observations to make predictions, but this reduces their applicability to systems where there is limited relevant archive data. Instead, here we use a fast approximate model from physics simulations to design the GP model. The GP is then employed to make inferences from sequential online observations in order to optimize the system. Simulation and experimental studies were carried out to demonstrate the method for online control of a storage ring. Our method is a simple prescription to construct a custom GP model, including correlations between the high-dimensional input space, while encoding the physical response of a system. The ability to inform the machine-learning model with physics, without relying on the availability and range of prior data, may have wide applications in science.
C1 [Hanuka, Adi; Huang, X.; Shtalenkova, J.; Kennedy, D.; Edelen, A.; Zhang, Z.; Ratner, D.; Duris, J.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Lalchand, V. R.] Univ Cambridge, Old Sch, Cambridge CB2 1TN, England.
RP Hanuka, A (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM adiha@slac.stanford.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Aiolli F, 2012, J MACH LEARN RES PRO, V27, P81
   Brodtkorb P. A., 2015, NUMDIFFTOOLS
   Calandra R, 2016, IEEE IJCNN, P3338, DOI 10.1109/IJCNN.2016.7727626
   Camps-Valls G, 2018, APPL SOFT COMPUT, V68, P69, DOI 10.1016/j.asoc.2018.03.021
   Chang WC, 2017, AAAI CONF ARTIF INTE, P1763
   Chollet F., 2015, KERAS
   Constantinescu EM, 2013, INT J UNCERTAIN QUAN, V3, P47, DOI 10.1615/Int.J.UncertaintyQuantification.2012003722
   Damianou A. C., 2013, PMLR, V31, P207
   de Freitas N., 2010, TR2009023 UBC
   Degrave J, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00006
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Duvenaud D., 2013, 30 INT C MACH LEARN, V28, P2203
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Ekström A, 2019, J PHYS G NUCL PARTIC, V46, DOI 10.1088/1361-6471/ab2b14
   Frazier PI, 2016, SPRINGER SER MATER S, V225, P45, DOI 10.1007/978-3-319-23871-5_3
   Gutmann MU, 2016, J MACH LEARN RES, V17
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Hettel R., 2004, 9 EUR PART ACC C EPA
   Huang X., 2019, BEAM BASED CORRECTIO
   Huang XB, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.104601
   Jalas S, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.104801
   Kirschner J, 2019, PR MACH LEARN RES, V97
   MacKay D. J., 1998, NATO ASI SERIES F CO, V168, P133
   McIntire M, 2016, UAI
   Meeds E, 2014, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P593
   Mockus J., 1975, OPTIMIZATION TECHNIQ, P400, DOI [10.1007/3-540-07165-2_55, DOI 10.1007/3-540-07165-2_55]
   Neal R. M., 2012, BAYESIAN LEARNING NE
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Noack MM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48114-3
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Ross Ashby W., 1970, INT J SYST SCI, V1, P89, DOI [DOI 10.1080/00207727008920220, 10.1080/00207727008920220]
   Roussel R., ARXIV201009824
   Safranek J, 1997, NUCL INSTRUM METH A, V388, P27, DOI 10.1016/S0168-9002(97)00309-4
   Sano S, 2020, J PHARM INNOV, V15, P333, DOI 10.1007/s12247-019-09382-8
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Sun SY, 2018, PR MACH LEARN RES, V80
   Taasti VT, 2020, MED PHYS, V47, P3286, DOI 10.1002/mp.14215
   Tartakovsky A. M., 2019, 52 HAW INT C SYST SC, P1
   Terebilo A., 2001, PACS2001. Proceedings of the 2001 Particle Accelerator Conference (Cat. No.01CH37268), P3203, DOI 10.1109/PAC.2001.988056
   Tomin S., 2016, P 7 INT PART ACC C B
   Wiener N, 1930, ACTA MATH-DJURSHOLM, V55, P117, DOI 10.1007/BF02546511
   Wilson AG, 2016, ADV NEUR IN, V29
   Wu JL, 2019, COMPUT FLUIDS, V193, DOI 10.1016/j.compfluid.2019.104292
   Yang X, 2019, J COMPUT PHYS, V395, P410, DOI 10.1016/j.jcp.2019.06.041
NR 47
TC 11
Z9 11
U1 3
U2 12
PD JUL 8
PY 2021
VL 24
IS 7
AR 072802
DI 10.1103/PhysRevAccelBeams.24.072802
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Sarma, A
   Jiang, HP
   Pattnaik, A
   Kotra, J
   Kandemir, MT
   Das, CR
AF Sarma, Anup
   Jiang, Huaipan
   Pattnaik, Ashutosh
   Kotra, Jagadish
   Kandemir, Mahmut Taylan
   Das, Chita R.
GP Assoc Comp Machinery
TI CASH: Compiler Assisted Hardware Design for Improving DRAM Energy
   Efficiency in CNN Inference
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
ID MEMORY
AB The advent of machine learning (ML) and deep learning applications has led to the development of a multitude of hardware accelerators and architectural optimization techniques for parallel architectures. This is due in part to the regularity and parallelism exhibited by the ML workloads, especially convolutional neural networks (CNNs). However, CPUs continue to be one of the dominant compute fabric in data-centers today, thereby also being widely deployed for inference tasks. As CNNs grow larger, the inherent limitations of a CPU-based system become apparent, specifically in terms of main memory data movement. In this paper, we present CASH, a compiler-assisted hardware solution that eliminates redundant data-movement to and from the main memory and, therefore, reduces main memory bandwidth and energy consumption. Our experimental evaluations on a set of four different state-of-the-art CNN workloads indicate that CASH provides, on average, similar to 40% and similar to 18% reductions in main memory bandwidth and energy consumption, respectively.
C1 [Sarma, Anup; Jiang, Huaipan; Pattnaik, Ashutosh; Kotra, Jagadish; Kandemir, Mahmut Taylan; Das, Chita R.] Penn State Univ, University Pk, PA 16802 USA.
RP Sarma, A (corresponding author), Penn State Univ, University Pk, PA 16802 USA.
EM avs6194@psu.edu; hzj5143@psu.edu; ashutosh@psu.edu; jbk5155@cse.psu.edu;
   mtk2@psu.edu; das@cse.psu.edu
CR Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2016, ARXIV160206709
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2016, COMMUN ACM, V59, P105, DOI 10.1145/2996864
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Ferreira AP, 2010, DES AUT TEST EUROPE, P914
   Gao Huang ZL, 2017, PROC CVPR IEEE, P4700, DOI DOI 10.1109/CVPR.2017.243
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Guyer SZ, 2006, ACM SIGPLAN NOTICES, V41, P364, DOI 10.1145/1133981.1134024
   Han S., 2015, ARXIV151000149
   Haria S, 2018, ACM SIGPLAN NOTICES, V53, P637, DOI [10.1145/3296957.3173194, 10.1145/3173162.3173194]
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hennessy J. L., 2011, COMPUTER ARCHITECTUR
   Huh S, 2017, INT SOC DESIGN CONF, P46, DOI 10.1109/ISOCC.2017.8368820
   Iandola FN, 2016, PROC CVPR IEEE, P2592, DOI 10.1109/CVPR.2016.284
   Inc. CISCO, CISC GLOB CLOUD IND
   Jiang HP, 2018, INT SOC DESIGN CONF, P227
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Lee BC, 2010, IEEE MICRO, V30, P131, DOI 10.1109/MM.2010.24
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Lou DD, 2018, J NANOSCI NANOTECHNO, V18, P951, DOI 10.1166/jnn.2018.13977
   Mandal A, 2018, LECT NOTES COMPUT SC, V11014, P265, DOI 10.1007/978-3-319-96983-1_19
   Mishra Asit, 2017, WRPN WIDE REDUCED PR
   Muchnick Steven S., 1997, ADV COMPILER DESIGN
   Park Ji Ho, 2018, BAM BOTTLENECK ATTEN
   Pleiss G, 2017, ARXIV170706990, P1
   Rhu M, 2016, INT SYMP MICROARCH
   Sarma A., 2011, 2011 International Conference on Recent Trends in Information Systems (ReTIS), P175, DOI 10.1109/ReTIS.2011.6146863
   Sartor Jennifer B., 2014, ACM INT C PAR ARCH C
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Zlateski A, 2016, INT PARALL DISTRIB P, P801, DOI 10.1109/IPDPS.2016.119
NR 45
TC 3
Z9 3
U1 0
U2 0
PY 2019
BP 396
EP 407
DI 10.1145/3357526.3357536
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Zhao, JY
   Huang, SY
   Yousuf, O
   Gao, YT
   Hoskins, BD
   Adam, GC
AF Zhao, Junyun
   Huang, Siyuan
   Yousuf, Osama
   Gao, Yutong
   Hoskins, Brian D.
   Adam, Gina C.
TI Gradient Decomposition Methods for Training Neural Networks With
   Non-ideal Synaptic Devices
SO FRONTIERS IN NEUROSCIENCE
DT Article
DE non-negative matrix factorization; gradient data decomposition;
   principal component analysis; memristor; non-idealities; ReRAM
ID NONNEGATIVE MATRIX; OXIDE; ALGORITHMS; RESISTANCE; MODEL
AB While promising for high-capacity machine learning accelerators, memristor devices have non-idealities that prevent software-equivalent accuracies when used for online training. This work uses a combination of Mini-Batch Gradient Descent (MBGD) to average gradients, stochastic rounding to avoid vanishing weight updates, and decomposition methods to keep the memory overhead low during mini-batch training. Since the weight update has to be transferred to the memristor matrices efficiently, we also investigate the impact of reconstructing the gradient matrixes both internally (rank-seq) and externally (rank-sum) to the memristor array. Our results show that streaming batch principal component analysis (streaming batch PCA) and non-negative matrix factorization (NMF) decomposition algorithms can achieve near MBGD accuracy in a memristor-based multi-layer perceptron trained on the MNIST (Modified National Institute of Standards and Technology) database with only 3 to 10 ranks at significant memory savings. Moreover, NMF rank-seq outperforms streaming batch PCA rank-seq at low-ranks making it more suitable for hardware implementation in future memristor-based accelerators.
C1 [Zhao, Junyun; Huang, Siyuan; Gao, Yutong] George Washington Univ, Dept Comp Sci, Washington, DC USA.
   [Yousuf, Osama; Adam, Gina C.] George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
   [Hoskins, Brian D.] NIST, Phys Measurement Lab, Gaithersburg, MD 20899 USA.
RP Adam, GC (corresponding author), George Washington Univ, Dept Elect & Comp Engn, Washington, DC 20052 USA.
EM ginaadam@gwu.edu
CR Adam GC, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07565-4
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2008, PRINCIPAL MANIFOLDS, DOI [10.1007/978-3-540-73750-6_2, DOI 10.1007/978-3-540-73750-6_2]
   ARGALL F, 1968, SOLID STATE ELECTRON, V11, P535, DOI 10.1016/0038-1101(68)90092-0
   Baek IG, 2004, IEEE INTERNATIONAL ELECTRON DEVICES MEETING 2004, TECHNICAL DIGEST, P587, DOI 10.1109/IEDM.2004.1419228
   Barnes R., 1951, ELECTRON ENG, V23, P286
   Berdan R, 2020, NAT ELECTRON, V3, P259, DOI 10.1038/s41928-020-0405-0
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Burrello A, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P235, DOI 10.1145/3310273.3322822
   Ceze L, 2016, 2016 74TH ANNUAL DEVICE RESEARCH CONFERENCE (DRC), DOI 10.1109/DRC.2016.7548506
   Chen P.-Y., 2017, IEEE INT EL DEV M IE
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI DOI 10.1002/9780470747278
   Cichocki A, 2009, IEICE T FUND ELECTR, VE92A, P708, DOI 10.1587/transfun.E92.A.708
   DEARNALEY G, 1970, REP PROG PHYS, V33, P1129, DOI 10.1088/0034-4885/33/3/306
   FORSYTHE GE, 1950, B AM MATH SOC, V56, P61
   Gao YM, 2023, IEEE T PATTERN ANAL, V45, P7019, DOI 10.1109/TPAMI.2020.3025062
   Garipov Timur, 2016, ABS161103214 CORR
   Gokmen T, 2020, FRONT NEUROSCI-SWITZ, V14, DOI 10.3389/fnins.2020.00103
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Golmant N., 2018, ARXIV181112941
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   He K., 2017, P IEEE INT C COMPUTE, DOI 10.1109/ICCV.2017.322
   HICKMOTT TW, 1962, J APPL PHYS, V33, P2669, DOI 10.1063/1.1702530
   Hirtzlin T., 2019, 2019 IEEEACM INT S N, DOI [10.1109/NANOARCH47378.2019.181300, DOI 10.1109/NANOARCH47378]
   Hoskins B.D., 2021, P INT C NEUR SYST IC, DOI [10.1145/3477145.3477260, DOI 10.1145/3477145.3477260]
   Hoskins BD, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00793
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang S., 2020, 2001040771 ARXIV
   Huang SY, 2020, AAAI CONF ARTIF INTE, V34, P13813
   HULL TE, 1966, COMMUN ACM, V9, P108, DOI 10.1145/365170.365212
   Jeong DS, 2005, APPL PHYS LETT, V86, DOI 10.1063/1.1865326
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kim W, 2019, S VLSI TECH, pT66, DOI [10.23919/VLSIT.2019.8776551, 10.23919/vlsit.2019.8776551]
   Langston J, 2020, MICROSOFT ANNOUNCES
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Lee DD, 2001, ADV NEUR IN, V13, P556
   Li C, 2019, NAT MACH INTELL, V1, P49, DOI 10.1038/s42256-018-0001-4
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   Lin YH, 2019, IEEE T ELECTRON DEV, V66, P1289, DOI 10.1109/TED.2019.2894273
   Meng-Fan Chang, 2011, Proceedings of the 2011 IEEE 9th International Conference on ASIC (ASICON 2011), P299, DOI 10.1109/ASICON.2011.6157181
   Neftci EO, 2019, IEEE SIGNAL PROC MAG, V36, P51, DOI 10.1109/MSP.2019.2931595
   Neftci EO, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00324
   Nugent MA, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0085175
   OJA E, 1992, NEURAL NETWORKS, V5, P927, DOI 10.1016/S0893-6080(05)80089-9
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Oxley D. P., 1977, Electrocomponent Science and Technology, V3, P217, DOI 10.1155/APEC.3.217
   PAATERO P, 1994, ENVIRONMETRICS, V5, P111, DOI 10.1002/env.3170050203
   PAGNIA H, 1988, PHYS STATUS SOLIDI A, V108, P11, DOI 10.1002/pssa.2211080102
   Payvand M, 2020, IEEE J EM SEL TOP C, V10, P522, DOI 10.1109/JETCAS.2020.3040248
   Payvand M, 2019, FARADAY DISCUSS, V213, P487, DOI 10.1039/c8fd00114f
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Schein A, 2016, PR MACH LEARN RES, V48
   Seo S, 2004, APPL PHYS LETT, V85, P5655, DOI 10.1063/1.1831560
   Serb A, 2016, IEEE T CIRCUITS-I, V63, P827, DOI 10.1109/TCSI.2015.2476296
   She XY, 2019, IEEE IJCNN
   Stewart K, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P223, DOI [10.1109/aicas48895.2020.9073948, 10.1109/AICAS48895.2020.9073948]
   Strubell E, 2020, AAAI CONF ARTIF INTE, V34, P13693
   Vogels T., 2019, ADV NEURAL INFORM PR, P14236
   Wang D, 2016, IEEE T CYBERNETICS, V46, P233, DOI 10.1109/TCYB.2015.2399533
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
NR 65
TC 2
Z9 2
U1 1
U2 9
PD NOV 22
PY 2021
VL 15
AR 749811
DI 10.3389/fnins.2021.749811
WC Neurosciences
DA 2023-11-11
ER

PT J
AU Garland, J
   Gregg, D
AF Garland, James
   Gregg, David
TI Low Complexity Multiply Accumulate Unit for Weight-Sharing Convolutional
   Neural Networks
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Convolutional neural network; power efficiency; multiply accumulate;
   arithmetic hardware circuits
AB Convolutional Neural Networks (CNNs) are one of the most successful deep machine learning technologies for processing image, voice and video data. CNNs require large amounts of processing capacity and memory, which can exceed the resources of low power mobile and embedded systems. Several designs for hardware accelerators have been proposed for CNNs which typically contain large numbers of Multiply Accumulate (MAC) units. One approach to reducing data sizes and memory traffic in CNN accelerators is "weight sharing", where the full range of values in a trained CNN are put in bins and the bin index is stored instead of the original weight value. In this paper we propose a novel MAC circuit that exploits binning in weight-sharing CNNs. Rather than computing the MAC directly we instead count the frequency of each weight and place it in a bin. We then compute the accumulated value in a subsequent multiply phase. This allows hardware multipliers in the MAC circuit to be replaced with adders and selection logic. Experiments show that for the same clock speed our approach results in fewer gates, smaller logic, and reduced power.
C1 [Garland, James; Gregg, David] Trinity Coll Dublin, Dublin 2, Ireland.
RP Garland, J (corresponding author), Trinity Coll Dublin, Dublin 2, Ireland.
EM jgarland@tcd.ie; david.gregg@cs.tcd.ie
CR [Anonymous], 2015, CORR
   [Anonymous], 2015, 32 ICML
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Fürer M, 2007, ACM S THEORY COMPUT, P57, DOI 10.1145/1250790.1250800
   Gangadharan Sridhar, 2015, CONSTRAINING DESIGNS
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Szegedy C., 2015, P COMP VIS FDN JUN
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 9
TC 20
Z9 23
U1 1
U2 8
PD JUL-DEC
PY 2017
VL 16
IS 2
BP 132
EP 135
DI 10.1109/LCA.2017.2656880
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Rattihalli, G
   Hogade, N
   Dhakal, A
   Frachtenberg, E
   Enriquez, RPH
   Bruel, P
   Mishra, A
   Milojicic, D
AF Rattihalli, Gourav
   Hogade, Ninad
   Dhakal, Aditya
   Frachtenberg, Eitan
   Enriquez, Rolando Pablo Hong
   Bruel, Pedro
   Mishra, Alok
   Milojicic, Dejan
BE Ardagna, C
   Atukorala, N
   Beckman, P
   Chang, C
   Chang, R
   Evangelinos, C
   Fan, J
   Fox, G
   Fox, J
   Hagleitner, C
   Jin, Z
   Kosar, T
   Parashar, M
TI Fine-Grained Heterogeneous Execution Framework with Energy Aware
   Scheduling
SO 2023 IEEE 16TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, CLOUD
SE IEEE International Conference on Cloud Computing
DT Proceedings Paper
CT IEEE 16th International Conference on Cloud Computing (IEEE CLOUD)
CY JUL 02-08, 2023
CL Chicago, IL
DE Energy-awareness; Heterogeneity; Serverless; Framework; Scheduler;
   Fine-granularity
AB The growing convergence of high-performance, data analytics, and machine-learning applications is increasingly pushing computing systems toward heterogeneous processors and specialized hardware accelerators. Hardware heterogeneity, in turn, leads to finer-grained workflows. State-of-the-art serverless computing resource managers do not currently provide efficient scheduling of such fine-grained tasks on systems with heterogeneous CPUs and specialized hardware accelerators (e.g., GPUs and FPGAs). Working with fine-grained tasks presents an opportunity for more efficient energy use via new scheduling models.
   Our proposed scheduler enables technologies like Nvidia's Multi-Process Service (MPS) to pack multiple fine-grained tasks on GPUs efficiently. Its advantages include better co-location of jobs and better sharing of hardware resources such as GPUs that were not previously possible on container orchestration systems. We propose a Kubernetes-native energy-aware scheduler that integrates with our heterogeneous framework. Combining finegrained resource scheduling on heterogeneous hardware and energy-aware scheduling results in up to 17.6% improvement in makespan, up to 20.16% reduction in energy consumption for CPU workloads, and up to 58.15% improvement in makespan, and up to 28.92% reduction in energy consumption for GPU workloads.
C1 [Rattihalli, Gourav; Hogade, Ninad; Dhakal, Aditya; Bruel, Pedro; Milojicic, Dejan] Hewlett Packard Labs, Milpitas, CA 95035 USA.
   [Frachtenberg, Eitan] Hewlett Packard Labs, Portland, OR USA.
   [Enriquez, Rolando Pablo Hong] Hewlett Packard Labs, Oxford, England.
   [Mishra, Alok] Hewlett Packard Labs, Rockaway, NJ USA.
RP Rattihalli, G (corresponding author), Hewlett Packard Labs, Milpitas, CA 95035 USA.
EM gourav.rattihalli@hpe.com; ninad.hogade@hpe.com; aditya.dhakal@hpe.com;
   eitan.frachtenberg@hpe.com; rhong@hpe.com; bruel@hpe.com;
   alok.mishra@hpe.com; dejan.milojicic@hpe.com
CR Andrae A. S. G., 2015, OPEN ACCESS CHALLANG, V6, P117
   [Anonymous], 2011, P 2011 ACM WORKSH GA, DOI DOI 10.1145/2110486.2110490
   Arnaboldi M, 2018, PR INT CONF AUTONOM, P71, DOI 10.1109/ICAC.2018.00017
   Aslanpour MS, 2022, 2022 22ND IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND INTERNET COMPUTING (CCGRID 2022), P190, DOI 10.1109/CCGrid54584.2022.00028
   aws.amazon, AWS LAMBD EN FUNCT C
   aws.amazon, AWS LAMBD
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Brondolin R, 2020, 2020 IEEE INTERNATIONAL CONFERENCE ON AUTONOMIC COMPUTING AND SELF-ORGANIZING SYSTEMS (ACSOS 2020), P11, DOI 10.1109/ACSOS49614.2020.00021
   Chard Ryan, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P65, DOI 10.1145/3369583.3392683
   Cheng HW, 2021, J SUPERCOMPUT, V77, P13385, DOI 10.1007/s11227-021-03805-5
   climateneutralgroup.com, CARB EM DAT CTR
   Copik M., 2022, RFAAS ENABLING HIGH
   Dhakal Aditya, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P492, DOI 10.1145/3419111.3421284
   docs.nvidia, MULT SERV GPU DEPL M
   Douhara Ryuki, 2020, 2020 International Conference on Computational Science and Computational Intelligence (CSCI), P1269, DOI 10.1109/CSCI51800.2020.00238
   fission, FISS SERV FUNCT KUB
   Frampton M., 2018, COMPLETE GUIDE OPEN, P97
   Ghafouri S, 2022, INT CONF UTIL CLOUD, P82, DOI 10.1109/UCC56403.2022.00019
   Gunasekaran JR, 2020, PROCEEDINGS OF THE 2020 21ST INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE '20), P280, DOI 10.1145/3423211.3425683
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang ST, 2021, IEEE T COMPUT, V70, P2015, DOI 10.1109/TC.2021.3123465
   IEA, 2022, DAT CTR DAT TRANSM N
   intel, RUNN AV POW LIM EN R
   James A., 2019, ICT SUSTAINABILITY
   Jia Xuechao, 2021, 2021 IEEE 27th International Conference on Parallel and Distributed Systems (ICPADS)., P434, DOI 10.1109/ICPADS53394.2021.00060
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaur K, 2020, IEEE INTERNET THINGS, V7, P4228, DOI 10.1109/JIOT.2019.2939534
   Khullar R., 2022, 2022 10 IEEE ACS 19, P1
   Knative, US
   Kubernetes, US
   Li ZS, 2021, IEEE ACCESS, V9, P84596, DOI 10.1109/ACCESS.2021.3081559
   manpages.ubuntu, UB MANP STRESS NG TO
   Menouer T, 2021, J SUPERCOMPUT, V77, P4267, DOI 10.1007/s11227-020-03427-3
   Milojicic D, 2020, COMPUTER, V53, P14, DOI 10.1109/MC.2019.2954056
   Nassereldine Amir, 2023, IEEE ACM INT S CLUST
   Numba, 2023, MAND SET COMP US NUM
   nvidia, MULT GPU MIG NVIDIA
   openwhisk.apache, AP OPENWHISK OP SOUR
   pcp, PERF COP
   Rattihalli G, 2019, IEEE INT CONF CLOUD, P33, DOI 10.1109/CLOUD.2019.00018
   Rattihalli G, 2019, IEEE ACM INT SYMP, P188, DOI 10.1109/CCGRID.2019.00033
   Rocha I, 2019, EUROMICRO WORKSHOP P, P400, DOI 10.1109/EMPDP.2019.8671554
   Townend P, 2019, 2019 13TH IEEE INTERNATIONAL CONFERENCE ON SERVICE-ORIENTED SYSTEM ENGINEERING (SOSE) / 10TH INTERNATIONAL WORKSHOP ON JOINT CLOUD COMPUTING (JCC) / IEEE INTERNATIONAL WORKSHOP ON CLOUD COMPUTING IN ROBOTIC SYSTEMS (CCRS), P156, DOI 10.1109/SOSE.2019.00030
   VAUGHAN JR, 1989, U COMPUT, V11, P193
   Zhang W, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P58, DOI 10.1145/3330345.3330351
NR 45
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 35
EP 44
DI 10.1109/CLOUD60044.2023.00014
DA 2023-11-11
ER

PT C
AU Lim, B
   Allard, M
   Grillotti, L
   Cully, A
AF Lim, Bryan
   Allard, Maxime
   Grillotti, Luca
   Cully, Antoine
GP ACM
TI QDax: On the Benefits of Massive Parallelization for Quality-Diversity
SO PROCEEDINGS OF THE 2022 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE
   COMPANION, GECCO 2022
DT Proceedings Paper
CT Genetic and Evolutionary Computation Conference (GECCO)
CY JUL 09-13, 2022
CL Boston, MA
DE Quality Diversity; MAP-Elites; Robotics; Hardware Acceleration
AB Quality-Diversity (QD) algorithms are a well-known approach to generate large collections of diverse and high-quality policies. However, QD algorithms are also known to be data-inefficient, requiring large amounts of computational resources and are slow when used in practice for robotics tasks. Policy evaluations are already commonly performed in parallel to speed up QD algorithms but have limited capabilities on a single machine as most physics simulators run on CPUs. With recent advances in simulators that run on accelerators, thousands of evaluations can be performed in parallel on single GPU/TPU. In this paper, we present QDax, an implementation of MAP-Elites which leverages massive parallelism on accelerators to make QD algorithms more accessible. We show that QD algorithms are ideal candidates and can scale with massive parallelism to be run at interactive timescales. The increase in parallelism does not significantly affect the performance of QD algorithms, while reducing experiment runtimes by two factors of magnitudes, turning days of computation into minutes. These results show that QD can now benefit from hardware acceleration, which contributed significantly to the bloom of deep learning.
C1 [Lim, Bryan; Allard, Maxime; Grillotti, Luca; Cully, Antoine] Imperial Coll London, Adapt & Intelligent Robot Lab, London, England.
RP Lim, B (corresponding author), Imperial Coll London, Adapt & Intelligent Robot Lab, London, England.
EM bryan.lim16@imperial.ac.uk; m.allard20@imperial.ac.uk;
   luca.grillotti16@imperial.ac.uk; a.cully@imperial.ac.uk
CR Barbu A, 2019, ADV NEUR IN, V32
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Chatzilygeroudis K, 2018, ROBOT AUTON SYST, V100, P236, DOI 10.1016/j.robot.2017.11.010
   Coumans E., 2016, PYBULLET PYTHON MODU
   Cully A, 2019, PROCEEDINGS OF THE 2019 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE (GECCO'19), P81, DOI 10.1145/3321707.3321804
   Cully A, 2018, IEEE T EVOLUT COMPUT, V22, P245, DOI 10.1109/TEVC.2017.2704781
   Cully A, 2015, NATURE, V521, P503, DOI 10.1038/nature14422
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Diaz Manfred, 2021, ARXIV
   Ecoffet A, 2021, NATURE, V590, DOI 10.1038/s41586-020-03157-9
   Fontaine MC, 2020, GECCO'20: PROCEEDINGS OF THE 2020 GENETIC AND EVOLUTIONARY COMPUTATION CONFERENCE, P94, DOI 10.1145/3377930.3390232
   Freeman C. D., 2021, BRAX A DIFFERENTIABL
   Kaushik R, 2020, FRONT ROBOT AI, V6, DOI 10.3389/frobt.2019.00151
   Lee J, 2018, J OPEN SOURCE SOFTW, V3, P500, DOI DOI 10.21105/JOSS.00500
   Mouret JB, 2015, Arxiv, DOI arXiv:1504.04909
   Mouret JB, 2010, IEEE C EVOL COMPUTAT
   Pugh JK, 2016, FRONT ROBOT AI, V3, DOI 10.3389/frobt.2016.00040
   Tjanaka Bryon, 2021, PYRIBS BARE BONES PY
   Todorov E, 2012, IEEE INT C INT ROBOT, P5026, DOI 10.1109/IROS.2012.6386109
   Vassiliades V, 2018, IEEE T EVOLUT COMPUT, V22, P623, DOI 10.1109/TEVC.2017.2735550
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 128
EP 131
DI 10.1145/3520304.3528927
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Nakanoya, M
   Chinchali, S
   Anemogiannis, A
   Datta, A
   Katti, S
   Pavone, M
AF Nakanoya, Manabu
   Chinchali, Sandeep
   Anemogiannis, Alexandros
   Datta, Akul
   Katti, Sachin
   Pavone, Marco
BE Shell, DA
   Toussaint, M
   Hsieh, MA
TI Co-Design of Communication and Machine Inference for Cloud Robotics
SO ROBOTICS: SCIENCE AND SYSTEM XVII
SE Robotics - Science and Systems
DT Proceedings Paper
CT Conference on Robotics - Science and Systems
CY JUL 12-16, 2021
CL ELECTR NETWORK
AB Today, even the most compute-and-power constrained robots can measure complex, high data-rate video and LIDAR sensory streams. Often, such robots, ranging from low-power drones to space and subterranean rovers, need to transmit high-bitrate sensory data to a remote compute server if they are uncertain or cannot scalably run complex perception or mapping tasks locally. However, today's representations for sensory data are mostly designed for human, not robotic, perception and thus often waste precious compute or wireless network resources to transmit unimportant parts of a scene that are unnecessary for a high-level robotic task. This paper presents an algorithm to learn task-relevant representations of sensory data that are co-designed with a pre-trained robotic perception model's ultimate objective. Our algorithm aggressively compresses robotic sensory data by up to 11 x more than competing methods. Further, it achieves high accuracy and robust generalization on diverse tasks including Mars terrain classification with low-power deep learning accelerators, neural motion planning, and environmental timeseries classification.
C1 [Nakanoya, Manabu] NEC Corp Ltd, Kawasaki, Kanagawa, Japan.
   [Chinchali, Sandeep; Katti, Sachin] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
   [Pavone, Marco] Stanford Univ, Dept Aeronaut & Astronaut, Stanford, CA 94305 USA.
   [Chinchali, Sandeep] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Nakanoya, M (corresponding author), NEC Corp Ltd, Kawasaki, Kanagawa, Japan.
EM nakanoya@nec.com; csandeep@stanford.edu; skatti@stanford.edu;
   pavone@stanford.edu
CR [Anonymous], 2019, EDGE TPU
   [Anonymous], 2010, IEEE RAS INT C HUM R
   [Anonymous], 2020, MARS RECONNAISSANCE
   Cheng Y., 2017, ARXIV171009282
   Chinchali S, 2019, ARXIV PREPRINT ARXIV
   Chinchali SP, 2018, HOTNETS-XVII: PROCEEDINGS OF THE 2018 ACM WORKSHOP ON HOT TOPICS IN NETWORKS, P50, DOI 10.1145/3286062.3286070
   Crawshaw M., 2020, MULTITASK LEARNING D
   Devlin J., 2018, PREPRINT
   Doran G., 2019, MARS ORBITAL IMAGE H
   Emmons J, 2019, PROCEEDINGS OF THE 2019 WORKSHOP ON HOT TOPICS IN VIDEO ANALYTICS AND INTELLIGENT EDGES (HOTEDGEVIDEO '19), P27, DOI 10.1145/3349614.3356023
   Engstrom Logan, 2019, ROBUSTNESS PYTHON LI
   Ghifary M, 2015, IEEE I CONF COMP VIS, P2551, DOI 10.1109/ICCV.2015.293
   HASSIBI B, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P293, DOI 10.1109/ICNN.1993.298572
   K. I. for Space Studies, 2020, VIRTUAL WORKSHOP NEB
   Kang YP, 2017, ACM SIGPLAN NOTICES, V52, P615, DOI 10.1145/3093336.3037698
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Kehoe B, 2015, IEEE T AUTOM SCI ENG, V12, P398, DOI 10.1109/TASE.2014.2376492
   Kehoe B, 2013, IEEE INT CONF ROBOT, P4263, DOI 10.1109/ICRA.2013.6631180
   Kingma D. P., 2013, ARXIV13126114
   LeCun Y., MNIST DATABASE HANDW
   Li PS, 2018, IEEE INT CON AUTO SC, P1420, DOI 10.1109/COASE.2018.8560447
   Liu Z, 2018, DES AUT CON, DOI 10.1145/3195970.3196022
   Manchester Z., 2013, KICKSAT CROWD FUNDED
   Mohanarajah G, 2015, IEEE T AUTOM SCI ENG, V12, P423, DOI 10.1109/TASE.2015.2408456
   Nenci F, 2014, IEEE INT C INT ROBOT, P3794, DOI 10.1109/IROS.2014.6943095
   Pacelli V., 2020, ARXIV PREPRINT ARXIV
   Pacelli V, 2019, IEEE INT CONF ROBOT, P2061, DOI [10.1109/icra.2019.8794213, 10.1109/ICRA.2019.8794213]
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tanwani A. K., 2020, IEEE ROBOT AUTOM LET
   Tishby N, 2015, 2015 IEEE INFORMATION THEORY WORKSHOP (ITW)
   Tu CX, 2019, IEEE INT CONF ROBOT, P3274, DOI [10.1109/icra.2019.8794264, 10.1109/ICRA.2019.8794264]
   Vander Hook J., 2020, 2020 IEEE AER C, P1
   Weber M, 2019, ARXIV PREPRINT ARXIV
NR 34
TC 4
Z9 4
U1 0
U2 0
PY 2021
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Engineering, Electrical & Electronic; Robotics
DA 2023-11-11
ER

PT C
AU Ivanov, A
   Rothenberger, B
   Dethise, A
   Canini, M
   Hoefler, T
   Perrig, A
AF Ivanov, Andrei
   Rothenberger, Benjamin
   Dethise, Arnaud
   Canini, Marco
   Hoefler, Torsten
   Perrig, Adrian
GP USENIX Association
TI SAGE: Software-based Attestation for GPU Execution
SO PROCEEDINGS OF THE 2023 USENIX ANNUAL TECHNICAL CONFERENCE
DT Proceedings Paper
CT USENIX Annual Technical Conference (USENIX ATC)
CY JUL 10-12, 2023
CL Boston, MA
AB With the application of machine learning to security-critical and sensitive domains, there is a growing need for integrity and privacy in computation using accelerators, such as GPUs. Unfortunately, the support for trusted execution on GPUs is currently very limited - trusted execution on accelerators is particularly challenging since the attestation mechanism should not reduce performance.
   Although hardware support for trusted execution on GPUs is emerging, we study purely software-based approaches for trusted GPU execution. A software-only approach offers distinct advantages: (1) complement hardware-based approaches, enhancing security especially when vulnerabilities in the hardware implementation degrade security, (2) operate on GPUs without hardware support for trusted execution, and (3) achieve security without reliance on secrets embedded in the hardware, which can be extracted as history has shown.
   In this work, we present SAGE, a software-based attestation mechanism for GPU execution. SAGE enables secure code execution on NVIDIA GPUs of the Ampere architecture (A100), providing properties of code integrity and secrecy, computation integrity, as well as data integrity and secrecy - all in the presence of malicious code running on the GPU and CPU. Our evaluation demonstrates that SAGE is already practical today for executing code in a trustworthy way on GPUs without specific hardware support.
C1 [Ivanov, Andrei; Rothenberger, Benjamin; Hoefler, Torsten; Perrig, Adrian] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Dethise, Arnaud; Canini, Marco] KAUST, Thuwal, Saudi Arabia.
RP Ivanov, A (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Anderson R., 1998, Operating Systems Review, V32, P9, DOI 10.1145/302350.302353
   ARM, 2021, ARM TRUSTZONE TECHN
   Butterworth John, 2013, P ACM SIGSAC C COMP
   Costan V., 2016, INTEL SGX EXPLAINED, DOI DOI 10.1145/3061639.3062276
   Ermolov M., 2017, HACK TURNED OFF COMP
   Forlin B, 2020, PROC EUR TEST SYMP, DOI 10.1109/ets48528.2020.9131562
   Gligor Virgil D, 2019, NDSS
   Hunt T, 2020, PROCEEDINGS OF THE 17TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P817
   Intel, 2021, INT GEN CRYP LIB API
   Intel, 2021, XEON GOLD 6348 PROC
   Intel, 2021, SOFTW GUARD EXT LIN
   Jang I, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P455, DOI 10.1145/3297858.3304021
   Jia Z, 2019, Arxiv, DOI arXiv:1903.07486
   Jia Z, 2018, Arxiv, DOI [arXiv:1804.06826, 10.48550/ARXIV.1804.06826]
   JohnWalker, 2008, ENT PSEUDORANDOM NUM
   Kovah X, 2012, P IEEE S SECUR PRIV, P239, DOI 10.1109/SP.2012.45
   Marsaglia G., 1996, DIEHARD BATTERY TEST
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Nunes I, 2021, CCS '21: PROCEEDINGS OF THE 2021 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2921, DOI 10.1145/3460120.3484532
   NVIDIA, 2022, BAS LIN ALG NVIDIA G
   NVIDIA, 2021, MULT INST GPU US GUI
   NVIDIA, 2022, NVIDIA H100 TENS COR
   NVIDIA, 2020, AMP ARCH IN DEPTH
   NVIDIA, 2021, CUDA OCC CALC
   NVIDIA, 2021, CUDA BIN UT
   NVIDIA, 2020, NVIDIA EGX IS FORM C
   NVIDIA, 2021, INT 32 FP64 CAN BE U
   Olson LE, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P470, DOI 10.1145/2830772.2830819
   Ragab Hany, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P1852, DOI 10.1109/SP40001.2021.00020
   Research and Markets, 2021, DAT CTR ACC MARK GLO
   Schaller A, 2019, IEEE T DEPEND SECURE, V16, P462, DOI 10.1109/TDSC.2018.2822298
   Seshadri A, 2004, P IEEE S SECUR PRIV, P272
   Seshadri A., 2005, P 20 ACM S OP SYST P, P1
   Seshadri A, 2008, LECT NOTES COMPUT SC, V5067, P372, DOI 10.1007/978-3-540-69170-9_25
   Shaneck M, 2005, LECT NOTES COMPUT SC, V3813, P27
   Shen TX, 2022, PROCEEDINGS OF THE 2022 USENIX ANNUAL TECHNICAL CONFERENCE, P723
   Smid Elaine Barker, 2010, SPECIAL PUBLICATION
   Tamarin Team, 2021, TAM PROV
   Tamarin Team, 2021, TAM MAN PROP SPEC
   TechSpot, 2022, INT SGX DEPR IMP DRM
   Teh JS, 2015, NONLINEAR DYNAM, V82, P1913, DOI 10.1007/s11071-015-2287-7
   tensorflow, 2021, END TO END OP SOURC
   TramŠr F, 2019, Arxiv, DOI arXiv:1806.03287
   Van Aubel P, 2015, LECT NOTES COMPUT SC, V9354, P228, DOI 10.1007/978-3-319-24126-5_14
   Van Bulck J, 2020, P IEEE S SECUR PRIV, P54, DOI 10.1109/SP40000.2020.00089
   Vigna S, 2017, J COMPUT APPL MATH, V315, P175, DOI 10.1016/j.cam.2016.11.006
   Volos S, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P681
   Zhao Jun, 2013, CAMBR INT WORKSH SEC, P94
   Zhu JP, 2019, Arxiv, DOI arXiv:1904.04782
NR 49
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 485
EP 499
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT J
AU Zabihi, M
   Resch, S
   Cilasun, H
   Chowdhury, ZI
   Zhao, ZY
   Karpuzcu, UR
   Wang, JP
   Sapatnekar, SS
AF Zabihi, Masoud
   Resch, Salonik
   Cilasun, Husrev
   Chowdhury, Zamshed, I
   Zhao, Zhengyang
   Karpuzcu, Ulya R.
   Wang, Jian-Ping
   Sapatnekar, Sachin S.
TI Exploring the Feasibility of Using 3-D XPoint as an In-Memory Computing
   Accelerator
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Three-dimensional displays; Phase change materials; Arrays; Wires;
   Integrated circuit modeling; Heating systems; Computational modeling;
   3-D XPoint; in-memory computing; matrix-vector multiplication; neural
   network; phase-change memory (PCM)
ID DESIGN
AB This article describes how 3-D XPoint memory arrays can be used as in-memory computing accelerators. We first show that thresholded matrix-vector multiplication (TMVM), the fundamental computational kernel in many applications including machine learning (ML), can be implemented within a 3-D XPoint array without requiring data to leave the array for processing. Using the implementation of TMVM, we then discuss the implementation of a binary neural inference engine. We discuss the application of the core concept to address issues such as system scalability, where we connect multiple 3-D XPoint arrays, and power integrity, where we analyze the parasitic effects of metal lines on noise margins. To assure power integrity within the 3-D XPoint array during this implementation, we carefully analyze the parasitic effects of metal lines on the accuracy of the implementations. We quantify the impact of parasitics on limiting the size and configuration of a 3-D XPoint array, and estimate the maximum acceptable size of a 3-D XPoint subarray.
C1 [Zabihi, Masoud; Resch, Salonik; Cilasun, Husrev; Chowdhury, Zamshed, I; Zhao, Zhengyang; Karpuzcu, Ulya R.; Wang, Jian-Ping; Sapatnekar, Sachin S.] Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.
RP Zabihi, M (corresponding author), Univ Minnesota, Dept Elect & Comp Engn, Minneapolis, MN 55455 USA.
EM zabih003@umn.edu
CR Agrawal N., 2008, PROC USENIX ANN TECH, P57, DOI DOI 10.1109/ISSCC.2012.6177101
   Beyer S, 2020, IEEE INT MEM WORKSH, P55, DOI 10.1109/imw48823.2020.9108150
   Burr GW, 2016, IEEE J EM SEL TOP C, V6, P146, DOI 10.1109/JETCAS.2016.2547718
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chien WC, 2018, IEEE T ELECTRON DEV, V65, P5172, DOI 10.1109/TED.2018.2871197
   Clark LT, 2017, P IEEE INT C MICRO, P1, DOI 10.1109/MSE.2017.7945071
   Clark LT, 2016, MICROELECTRON J, V53, P105, DOI 10.1016/j.mejo.2016.04.006
   Fernando BR, 2020, IEEE IJCNN, DOI 10.1109/ijcnn48605.2020.9206929
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Kau D, 2009, INT EL DEVICES MEET, P571
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim Y, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900116
   Le Gallo M, 2020, J PHYS D APPL PHYS, V53, DOI 10.1088/1361-6463/ab7794
   LeCun Y., MNIST DATABASE HANDW
   Lee K, 2012, IEEE C ELEC DEVICES
   Liu MQ, 2017, I SYMPOS LOW POWER E
   Lou Q, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240767
   McAfee A, 2012, HARVARD BUS REV, V90, P60
   Murali GN, 2019, I CONF VLSI DESIGN, P500, DOI 10.1109/VLSID.2019.00106
   Murali GN, 2018, PROCEEDINGS OF THE 2018 8TH INTERNATIONAL SYMPOSIUM ON EMBEDDED COMPUTING AND SYSTEM DESIGN (ISED 2018), P124, DOI 10.1109/ISED.2018.8704015
   Shi LY, 2020, NANOSCALE ADV, V2, P1811, DOI 10.1039/d0na00100g
   Son K, 2020, IEEE T COMP PACK MAN, V10, P858, DOI 10.1109/TCPMT.2020.2984268
   Son K, 2019, ASIA PACIF MICROWAVE, P694, DOI [10.1109/apmc46564.2019.9038362, 10.1109/APMC46564.2019.9038362]
   Son K, 2018, 2018 IEEE SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY, SIGNAL INTEGRITY AND POWER INTEGRITY (EMC, SI & PI), P223
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Wu J Y, 2011, IEEE International Electron Devices Meeting (IEDM), p3.2.1
   Wuttig M, 2007, NAT MATER, V6, P824, DOI 10.1038/nmat2009
   Xu N, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900082
   Yang JF, 2020, ACM TRANS MODELING P, V5, DOI 10.1145/3372783
   Zabihi M, 2020, IEEE J EXPLOR SOLID-, V6, P71, DOI 10.1109/JXCDC.2020.2985314
   Zheng QH, 2017, J PHYS D APPL PHYS, V50, DOI 10.1088/1361-6463/aa70b0
NR 34
TC 2
Z9 2
U1 0
U2 1
PD DEC
PY 2021
VL 7
IS 2
BP 88
EP 96
DI 10.1109/JXCDC.2021.3112238
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Geng, T
   Wu, CS
   Tan, C
   Fang, B
   Li, A
   Herbordt, M
AF Geng, Tong
   Wu, Chunshu
   Tan, Cheng
   Fang, Bo
   Li, Ang
   Herbordt, Martin
GP IEEE
TI CQNN: a CGRA-based QNN Framework
SO 2020 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 21-25, 2020
CL ELECTR NETWORK
DE QNN; CGRA; Accelerator; Machine Learning
AB Quantized Neural Networks (QNNs) have drawn tremendous attention since - when compared with Convolution Neural Networks (CNNs) - they often dramatically reduce computation, communication, and storage demands with negligible loss in accuracy. To find an optimal balance between performance and accuracy, developers use different data-widths for different layers and channels. Given this large parameter space, it is challenging to design a QNN accelerator which is generally efficient for various and flexible model configurations.
   In this paper we propose CQNN, a novel Coarse-Grained Reconfigurable Architecture-based (CGRA) QNN acceleration framework. CQNN has a large number of basic components for binary functions. By programming CQNN at runtime according to the target QNN model, these basic components are integrated to support QNN functions with any data-width and hyperparameter requirements. The result is an optimal QNN for the target model. The framework includes compiler, hardware design, simulator, and RTL generator. Experimental results show CQNNs can complete the inference of AlexNet and VGG-16 within 0.13ms and 2.63ms, respectively. We demonstrate the design on an FPGA platform; however, this is only for showcasing the method: the approach does not rely on any FPGA-specific features and can thus be implemented as ASIC as well.
C1 [Geng, Tong; Wu, Chunshu; Herbordt, Martin] Boston Univ, Boston, MA 02215 USA.
   [Tan, Cheng; Fang, Bo; Li, Ang] PNNL, Richland, WA USA.
RP Geng, T (corresponding author), Boston Univ, Boston, MA 02215 USA.
EM tgeng@bu.edu; happycwu@bu.edu; cheng.tan@pnnl.gov; bo.fang@pnnl.gov;
   ang.li@pnnl.gov; herbordt@bu.edu
CR Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Courbariaux M, 2015, ADV NEUR IN, V28
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Geng T, 2021, IEEE T PARALL DISTR, V32, P199, DOI 10.1109/TPDS.2020.3013637
   Geng T, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P461, DOI 10.1145/3330345.3330386
   Geng T, 2019, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2019.00-43
   Geng T, 2018, I C FIELD PROG LOGIC, P394, DOI 10.1109/FPL.2018.00074
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   Ghasemzadeh M, 2018, ANN IEEE SYM FIELD P, P57, DOI 10.1109/FCCM.2018.00018
   Hubara I, 2018, J MACH LEARN RES, V18
   Ji SW, 2013, IEEE T PATTERN ANAL, V35, P221, DOI 10.1109/TPAMI.2012.59
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lam M., 2020, ARXIV PREPRINT ARXIV
   Li A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356169
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Micikevicius Paulius, 2017, P INT C LEARN REPR I
   Miyashita D., 2016, ARXIV PREPRINT ARXIV
   Park E, 2018, LECT NOTES COMPUT SC, V11208, P608, DOI 10.1007/978-3-030-01225-0_36
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang W, 2017, AAAI CONF ARTIF INTE, P2625
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Zhou S., 2016, DOREFANET TRAINING L
NR 27
TC 11
Z9 11
U1 1
U2 1
PY 2020
DI 10.1109/hpec43674.2020.9286194
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Papadimitriou, M
   Markou, E
   Fumero, J
   Stratikopoulos, A
   Blanaru, F
   Kotselidis, C
AF Papadimitriou, Michail
   Markou, Eleni
   Fumero, Juan
   Stratikopoulos, Athanasios
   Blanaru, Florin
   Kotselidis, Christos
BE Titzer, B
   Xu, H
   Zhang, I
TI Multiple-Tasks on Multiple-Devices (MTMD): Exploiting Concurrency in
   Heterogeneous Managed Runtimes
SO PROCEEDINGS OF THE 17TH ACM SIGPLAN/SIGOPS INTERNATIONAL CONFERENCE ON
   VIRTUAL EXECUTION ENVIRONMENTS (VEE '21)
DT Proceedings Paper
CT 17th ACM SIGPLAN/SIGOPS International Conference on Virtual Execution
   Environments (VEE)
CY APR 16, 2021
CL ELECTR NETWORK
DE JVM; Heterogeneous Hardware; Bytecodes; Multi-threading
AB Modern commodity devices are nowadays equipped with a plethora of heterogeneous devices serving different purposes. Being able to exploit such heterogeneous hardware accelerators to their full potential is of paramount importance in the pursuit of higher performance and energy efficiency. Towards these objectives, the reduction of idle time of each device as well as the concurrent program execution across different accelerators can lead to better scalability within the computing platform.
   In this work, we propose a novel approach for enabling a Java-based heterogeneous managed runtime to automatically and efficiently deploy multiple tasks on multiple devices. We extend TornadoVM with parallel execution of bytecode interpreters to dynamically and concurrently manage and execute arbitrary tasks across multiple OpenCL-compatible devices. In addition, in order to achieve an efficient device-task allocation, we employ a machine learning approach with a multiple-classification architecture of Extra-Trees-Classifiers. Our proposed solution has been evaluated over a suite of 12 applications split into three different groups. Our experimental results showcase performance improvements up 83% compared to all tasks running on the single best device, while reaching up to 91% of the oracle performance.
C1 [Papadimitriou, Michail; Fumero, Juan; Stratikopoulos, Athanasios; Blanaru, Florin; Kotselidis, Christos] Univ Manchester, Manchester, Lancs, England.
   [Markou, Eleni] BEAT, Thessaloniki, Greece.
RP Papadimitriou, M (corresponding author), Univ Manchester, Manchester, Lancs, England.
EM michail.papadimitriou@manchester.ac.uk; e.markou@thebeat.co;
   juan.fumero@manchester.ac.uk;
   athanasios.stratikopoulos@manchester.ac.uk;
   florin.blanaru@manchester.ac.uk; christos.kotselidis@manchester.ac.uk
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   Aji AM, 2016, PARALLEL COMPUT, V58, P37, DOI 10.1016/j.parco.2016.05.006
   Al Umairy Shams A. H., 2012, COMPUTER ARCHITECTUR, DOI [10.1007/978-3-642-24322-6_6, DOI 10.1007/978-3-642-24322-6_6]
   AMD, AP PROJ
   [Anonymous], 2013, P 27 INT ACM C INT C
   Baldini Ioana, 2014, 2014 IEEE 26th International Symposium on Computer Architecture and High-Performance Computing (SBAC-PAD), P254, DOI 10.1109/SBAC-PAD.2014.30
   Boyd Kendrick, 2013, Machine Learning and Knowledge Discovery in Databases. European Conference, ECML PKDD 2013. Proceedings: LNCS 8190, P451, DOI 10.1007/978-3-642-40994-3_29
   Bradley AP, 1997, PATTERN RECOGN, V30, P1145, DOI 10.1016/S0031-3203(96)00142-2
   Braun L, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3431731
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Clarkson James, 2018, P 15 INT C MANAGED L, DOI [10.1145/3237009.3237016, DOI 10.1145/3237009.3237016]
   Clarkson James, 2018, C COMPANION 2 INT C, DOI [10.1145/3191697.3191730, DOI 10.1145/3191697.3191730]
   CLICK C, 1995, SIGPLAN NOTICES, V30, P35, DOI 10.1145/202530.202534
   Cook S, 2012, CUDA PROGRAMMING DEV
   Duboscq Gilles, 2013, P 7 ACM WORKSHO VIRT, P1, DOI DOI 10.1145/2542142.2542143
   Farris FA, 2010, AM MATH MON, V117, P851, DOI 10.4169/000298910X523344
   Fumero Juan, 2019, P 15 ACM SIGPLANSIGO, P165, DOI [10, DOI 10.1145/3313808.3313819]
   Garcia VM, 2011, COMPUT CARDIOL CONF, V38, P233
   Georges A, 2007, ACM SIGPLAN NOTICES, V42, P57, DOI 10.1145/1297105.1297033
   Geurts P, 2006, MACH LEARN, V63, P3, DOI 10.1007/s10994-006-6226-1
   Ghose A, 2020, Arxiv, DOI arXiv:2009.07482
   Govindaraju Naga K, 2008, SC 08 P OF THE 2008, P1, DOI [DOI 10.1109/SC.2008.5213922, 10.1109/SC.2008.5213922]
   Grauer-Gray S., 2013, P 6 WORKSHOP GEN PUR, P127, DOI DOI 10.1145/2458523.2458536
   Grewe D, 2013, INT SYM CODE GENER, P161
   Grewe Dominik, 2011, LECT NOTES COMPUT SC
   Henry Sylvain, 2013, RR8346 INRIA
   Huseinovic A., 2015, 23 TELECOMMUNICATION, DOI [10.1109/TELFOR.2015.7377632, DOI 10.1109/TELFOR.2015.7377632]
   Huynh HP, 2012, ACM SIGPLAN NOTICES, V47, P1, DOI 10.1145/2370036.2145818
   IBM, US
   Intel, ONEAPI SPEC
   Ionescu V. M, 2017, 9 INT C ELECT COMPUT, DOI [10.1109/ECAI.2017.8166501, DOI 10.1109/ECAI.2017.8166501]
   Jordan H, 2013, INT CONFER PARA, P7, DOI 10.1109/PACT.2013.6618799
   Khalid YN, 2019, J PARALLEL DISTR COM, V132, P79, DOI 10.1016/j.jpdc.2019.05.015
   Kim Jungwon, 2012, P 26 ACM INT C SUP I, P341, DOI DOI 10.1145/2304576.2304623
   Kotselidis C, 2017, ACM SIGPLAN NOTICES, V52, P74, DOI [10.1145/3050748.3050764, 10.1145/3140607.3050764]
   Nardi L, 2015, IEEE INT CONF ROBOT, P5783, DOI 10.1109/ICRA.2015.7140009
   Nozal Raul, 2019, 2019 International Conference on High Performance Computing & Simulation (HPCS), P628, DOI 10.1109/HPCS48598.2019.9188188
   Ogilvie William F., 2015, COMPUTING JAMES LANG
   Ohshima Satoshi, 2018, LECT NOTES COMPUT SC
   Pandit Prasanna, 2014, P IEEE ACM INT S COD, DOI [10.1145/2581122.2544163, DOI 10.1145/2581122.2544163]
   Papadimitriou M, 2019, ANN IEEE SYM FIELD P, P310, DOI 10.1109/FCCM.2019.00051
   Papadimitriou Michail, 2020, ART SCI ENG PROGRAM, V5, P2, DOI [10.22152/programming-journal.org/2021/5/8, DOI 10.22152/PROGRAMMING-JOURNAL.ORG/2021/5/8]
   Parravicini A, 2021, Arxiv, DOI arXiv:2012.09646
   Playne D. P., 2009, Proceedings of the 2009 International Conference on Computer Design. CDES 2009, P150
   Rubinstein R., 2017, SIMULATION MONTE CAR
   Singh AK, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126548
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Udupa A, 2009, INT SYM CODE GENER, P200, DOI 10.1109/CGO.2009.20
   Volkov Vasily, 2008, 2008 SC - International Conference for High Performance Computing, Networking, Storage and Analysis, DOI 10.1109/SC.2008.5214359
   Wen Y, 2014, INT C HIGH PERFORM
   You YP, 2015, ACM SIGPLAN NOTICES, V50, P161, DOI [10.1145/2858788.2688505, 10.1145/2688500.2688505]
NR 53
TC 2
Z9 2
U1 0
U2 3
PY 2021
BP 125
EP 138
DI 10.1145/3453933.3454019
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Taher, FN
   Balachandran, A
   Schafer, BC
AF Taher, Farah Naz
   Balachandran, Anjana
   Schafer, Benjamin Carrion
GP IEEE
TI Learning-based Diversity Estimation: Leveraging the Power of High-level
   Synthesis to mitigate Common-mode Failure
SO 2019 IEEE 37TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD 2019)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 37th IEEE International Conference on Computer Design (ICCD)
CY NOV 17-20, 2019
CL New York Univ Abu Dhabi, Abu Dhabi, U ARAB EMIRATES
HO New York Univ Abu Dhabi
DE Common Mode Failure; Diversity; High-Level Synthesis; Design Space
   Exploration; Predictive Modeling; Machine Learning
AB Hardware redundancy techniques are extensively used for enhancing system reliability, availability and fault tolerance. However, traditional identical module N-modular redundancy (NMR) cannot protect against Common Mode Failures (CMFs). One method that has been proposed to protect against CMFs is the use of dissimilar (diverse) module redundancy. One of the problems with previous work is that it generates these diverse modules by perturbing the gate-netlist and thus, achieve very limited diversity. In addition, previous work is very time consuming as it requires to insert fault-pairs in the gate-netlists in order to measure the effect of these on the outputs. To address these issues, this work proposes to first increase diversity by raising the level of abstraction from the gate level to the behavioral level. Secondly, we propose a fast machine learning based method that facilitates the design space exploration (DSE) of single behavioral descriptions in order to generate optimized redundant hardware accelerator system with maximum diversity to protect against CMFs. For this purpose, this work exploits one of the main advantages of C-based VLSI design: The ability to generate micro-architectures with unique characteristics from the same behavioral description by setting different synthesis directives in the form of pragmas. Experimental results show that our proposed method is a fast and efficient way to generate diverse designs to protect the system against CMFs.
C1 [Taher, Farah Naz; Schafer, Benjamin Carrion] Univ Texas Dallas, Richardson, TX 75080 USA.
   [Balachandran, Anjana] Hong Kong Polytech Univ, Hong Kong, Peoples R China.
RP Taher, FN (corresponding author), Univ Texas Dallas, Richardson, TX 75080 USA.
EM farah.taher@utdallas.edu; anjana.balachandran@polyu.hk;
   schaferb@utdallas.edu
CR Aitken A., 1978, TECH REP
   Alcaide S, 2017, DES AUT CON, DOI 10.1145/3061639.3062231
   Avizienis A., 1977, P COMPSAC
   Cohen F. B., 1993, COMPUTERS SECURITY
   Ferrandi Fabrizio, 2008, IEEE COMP SOC ANN S
   Hall M., 2009, ACM SIGKDD EXPLORATI
   Höller A, 2015, DES AUT TEST EUROPE, P531
   McCluskey E., 1986, LOGIC DESIGN PRINCIP
   Mitra S., 2000, INT TEST C ITC
   Mitra S., 2004, IEEE T COMPUTERS
   Mitra S., 2008, DESIGN AUTOMATION TE
   Mitra S., 1999, INT TEST C ITC
   Mitra S., 2002, IEEE T COMPUTERS
   Mitra S., 2000, IEEE T RELIABILITY
   Schafer Benjamin Carrion, 2014, IEEE EMBEDDED SYSTEM
   Shivakumar P, 2002, INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS, PROCEEDINGS, P389, DOI 10.1109/DSN.2002.1028924
   Taher FN, 2019, DES AUT TEST EUROPE, P1563, DOI [10.23919/date.2019.8714816, 10.23919/DATE.2019.8714816]
   Ubar R, 2011, ADV COMPUT ELECTR EN, P1, DOI 10.4018/978-1-60960-212-3
NR 18
TC 0
Z9 0
U1 0
U2 2
PY 2019
BP 460
EP 467
DI 10.1109/ICCD46524.2019.00071
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Kwon, SI
   Regan, A
   Wang, YM
AF Kwon, SI
   Regan, A
   Wang, YM
TI SNS superconducting RF cavity modeling-iterative learning control
SO NUCLEAR INSTRUMENTS & METHODS IN PHYSICS RESEARCH SECTION A-ACCELERATORS
   SPECTROMETERS DETECTORS AND ASSOCIATED EQUIPMENT
DT Article
DE spallation neutron source; pulsed machine; superconducting RF cavity;
   feedback control; feedforward control; iterative
AB The Spallation Neutron Source (SNS) Superconducting RF (SRF) linear accelerator is operated A it It it pulsed beam. For the SRF control system to track the repetitive electromagnetic held reference trajectory. both feedback and feedforward controllers have been proposed, The feedback controller is utilized to guarantee the closed loop system stability and the feedforward controller is used to improve the tracking performance for the repetitive reference trajectory and to suppress repetitive disturbances. As the iteration number increases, the feedforward controller decreases the tracking error. Numerical simulations demonstrate that inclusion of the feedforward controller significantly improves the control system performance over its performance with just the feedback controller. (C) 2002 Published by Elsevier Science B.V.
C1 Los Alamos Natl Lab, SNS Div, RF Technol Grp, Los Alamos, NM 87544 USA.
RP Kwon, SI (corresponding author), Los Alamos Natl Lab, SNS Div, RF Technol Grp, SNS-2,POB 1663, Los Alamos, NM 87544 USA.
CR Amann N, 1996, INT J ADAPT CONTROL, V10, P767, DOI 10.1002/(SICI)1099-1115(199611)10:6<767::AID-ACS420>3.0.CO;2-L
   [Anonymous], 1994, LINEAR MATRIX INEQUA
   [Anonymous], ITERATIVE LEARNING C
   ARIMOTO S, 1984, J ROBOTIC SYST, V1, P123, DOI 10.1002/rob.4620010203
   CHEO BR, 1991, IEEE T ELECTRON DEV, V38, P2264, DOI 10.1109/16.88508
   FORTGANG CM, 1990, REV SCI INSTRUM, V61, P3405, DOI 10.1063/1.1141592
   HARA S, 1988, IEEE T AUTOMAT CONTR, V33, P659, DOI 10.1109/9.1274
   HOROWITZ R, 1991, IEEE T AUTOMAT CONTR, V36, P890, DOI 10.1109/9.85074
   PADAMSEE H, 1998, SUPERCONDUCTIVITY AC
   Zhou K., 1996, ROBUST OPTIMAL CONTR
NR 10
TC 6
Z9 7
U1 0
U2 1
PD APR 11
PY 2002
VL 482
IS 1-2
BP 12
EP 31
AR PII S0168-9002(01)01514-5
DI 10.1016/S0168-9002(01)01514-5
WC Instruments & Instrumentation; Nuclear Science & Technology; Physics,
   Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT J
AU Judd, P
   Albericio, J
   Hetherington, T
   Aamodt, T
   Jerger, NE
   Urtasun, R
   Moshovos, A
AF Judd, Patrick
   Albericio, Jorge
   Hetherington, Tayler
   Aamodt, Tor
   Jerger, Natalie Enright
   Urtasun, Raquel
   Moshovos, Andreas
TI Proteus: Exploiting precision variability in deep neural networks
SO PARALLEL COMPUTING
DT Article
DE Machine learning; Neural networks; Deep learning; Accelerators;
   Approximate computing; Reduced precision
AB This work investigates how using reduced precision data in Deep Neural Networks (DNNs) affects network accuracy during classification. We observe that the tolerance of DNNs to reduced precision data not only varies across networks, but also within networks. We study how error tolerance across layers varies and propose a method for finding a low precision configuration for a network while maintaining high accuracy.
   To exploit these low precision configurations, this work proposes PROTEUS, which reduces the data traffic and storage footprint needed by DNNs, resulting in reduced energy for DNN implementations. Nal-m.1s uses a different representation per layer for both the data (neuron activations) and the weights (synapses) processed by DNNs. PROTEUS is a layered extension over existing DNN implementations that maintains the native precision of the compute engine by converting to and from a fixed-point reduced precision format used in memory. PROTEUS uses a novel memory layout, enabling a simple, low-cost and low-energy conversion unit.
   We evaluate PROTEUS as an extension to a state-of-the-art accelerator [1] which uses a uniform 16-bit fixed-point representation. On five popular Convolutional Neural Networks (CNNs) and during inference PROTEUS reduces data traffic by 43% on average while maintaining accuracy within 1% compared to the full precision baseline. As a result, PROTEUS improves energy by 15% with no performance loss. (C) 2017 Elsevier B.V. All rights reserved.
C1 [Judd, Patrick; Albericio, Jorge; Jerger, Natalie Enright; Moshovos, Andreas] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Hetherington, Tayler; Aamodt, Tor] Univ British Columbia, Dept Elect & Comp Engn, Vancouver, BC, Canada.
   [Urtasun, Raquel] Univ Toronto, Dept Comp Sci, Toronto, ON, Canada.
   [Albericio, Jorge] Univ Toronto, Toronto, ON, Canada.
RP Judd, P (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM juddpatr@ece.utoronto.ca; jalbericiola@nvidia.com; taylerh@ece.ubc.ca;
   aamodt@ece.ubc.ca; enright@ece.utoronto.ca; urtasun@cs.utoronto.edu;
   moshovos@ece.utoronto.ca
CR [Anonymous], 2014, ARXIV14090575CS
   [Anonymous], 2016, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2014, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2015, NIPS
   [Anonymous], 2015, CAFFE MODEL ZOO
   [Anonymous], 2013, ARXIV PREPRINT ARXIV
   [Anonymous], J DAIRY SCI, DOI DOI 10.1109/MICR0.2014.58
   [Anonymous], 2015, CORR
   Anwar S, 2015, INT CONF ACOUST SPEE, P1131, DOI 10.1109/ICASSP.2015.7178146
   ASANOVIC K, 1993, J VLSI SIGNAL PROC, V6, P33, DOI 10.1007/BF01581957
   Buck I., 2015, NVIDIAS NEXT GEN PAS
   Chen L.-C., 2014, ARXIV 14127062
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chippa V. K., 2013, P 50 ANN DESIGN AUTO, P1, DOI DOI 10.1145/2463209.2488873
   Girshick R., 2014, P P IEEE C COMP VIS
   Holt J. L., 1991, IJCNN-91-Seattle: International Joint Conference on Neural Networks (Cat. No.91CH3049-4), P121, DOI 10.1109/IJCNN.1991.155324
   HOLT JL, 1993, IEEE T COMPUT, V42, P281, DOI 10.1109/12.210171
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jain A., 2016, P 2016 49 ANN IEEE A
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Krizhevsky A., 2011, CUDA CONVNET HIGH PE
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Larkin D, 2006, LECT NOTES COMPUT SC, V4234, P1178
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin M., 2013, CORR
   Muralimanohar N., CACTI 6 0 TOOL UNDER
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   PRESLEY RK, 1994, SOUTHEASTCON '94 - CREATIVE TECHNOLOGY TRANSFER - A GLOBAL AFFAIR, P136, DOI 10.1109/SECON.1994.324283
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Seide F, 2014, INTERSPEECH, P1058
   Strey A., 1996, Euro-Par '96 Parallel Processing. Second International Euro-Par Conference. Proceedings, P470, DOI 10.1007/BFb0024738
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Xie Y., 1991, TRAINING ALGORITHMS
NR 36
TC 9
Z9 9
U1 0
U2 27
PD APR
PY 2018
VL 73
SI SI
BP 40
EP 51
DI 10.1016/j.parco.2017.05.003
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Pombo, N
   Araújo, P
   Viana, J
AF Pombo, Nuno
   Araujo, Pedro
   Viana, Joaquim
TI Applied computer technologies in clinical decision support systems for
   pain management: A systematic review
SO JOURNAL OF INTELLIGENT & FUZZY SYSTEMS
DT Review
DE Clinical decision support system; pain measurement; medical informatics;
   machine learning
ID MACHINE LEARNING TECHNIQUES; ACUTE MYOCARDIAL-INFARCTION; ACUTE
   ABDOMINAL-PAIN; CHEST-PAIN; MEDICAL DIAGNOSIS; RULE INDUCTION;
   EXPERT-SYSTEM; ACI-TIPI; TRIAGE; CLASSIFICATION
AB Millions of people around the world suffer from pain, acute or chronic and this raises the importance of its screening, assessment and treatment. Pain, is highly subjective and the use of clinical decision support systems (CDSSs) can play an important part in improving the accuracy of pain assessment, and lead to better clinical practices. This review examines CDSSs, in relation to computer technologies and was conducted with the following electronic databases: CiteSeer(x), IEEE Xplore, ISI Web of Knowledge, Mendeley, Microsoft Academic Search, PubMed, Science Accelerator, Science. gov, ScienceDirect, SpringerLink, and The Cochrane Library. The studies referenced were compiled with several criteria in mind. Firstly, that they constituted a decision support system. Secondly, that study data included pain values or results based on the detection of pain. Thirdly, that they were published in English, between 1992 and 2011, and finally that they focused on patients with acute or chronic pain. In total, thirty-nine studies highlighted the following topics: rule based algorithms, artificial neural networks, rough and fuzzy sets, statistical learning algorithms, terminologies, questionnaires and scores. The median accuracy ranged from 53% to 87.5%. The lack of integration with mobile devices, the limited use of web-based interfaces and the scarcity of systems that allow for data to be inserted by patients were all limitations that were detected.
C1 [Pombo, Nuno; Araujo, Pedro] Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
   [Pombo, Nuno; Araujo, Pedro] Univ Beira Interior, Dept Informat, Covilha, Portugal.
   [Viana, Joaquim] Univ Beira Interior, Fac Hlth Sci, Covilha, Portugal.
RP Pombo, N (corresponding author), Univ Beira Interior, Inst Telecomunicacoes, Covilha, Portugal.
EM ngpombo@ubi.pt
CR Aase O, 1999, CARDIOLOGY, V92, P128, DOI 10.1159/000006960
   Abad-Grau MM, 2008, J BIOMED INFORM, V41, P432, DOI 10.1016/j.jbi.2008.01.007
   Abas H. I., 2011, 2011 International Conference on Semantic Technology and Information Retrieval (STAIR 2011), P106, DOI 10.1109/STAIR.2011.5995773
   AHA DW, 1991, MACH LEARN, V6, P37, DOI 10.1023/A:1022689900470
   [Anonymous], P P 37 ANN HAW INT C
   [Anonymous], IEE C KNOWL DISC DAT
   [Anonymous], 2007, CLIN DECIS SUPPORT S, DOI [DOI 10.1007/978-0-387-38319-4_4, 10.1007/978-0-387-38319-4_4]
   [Anonymous], AMIA ANN S P
   [Anonymous], 2005, SERVICE ORIENTED ARC
   [Anonymous], P 6 EUR KNOWL ACQ WO
   [Anonymous], PARAMETER ADJUSTMENT
   [Anonymous], 2007, CLIN DECISION SUPPOR
   [Anonymous], 1994, IASP PAIN TERMINOLOG
   [Anonymous], 1990, P READ UNC
   [Anonymous], P 11 ANN INT WORKSH
   [Anonymous], ONTOLOGY DRIVEN CARD
   [Anonymous], 35 ANN M DEC SCI I B
   [Anonymous], 1998, J TELECOMMUN INF TEC
   [Anonymous], METHODS INFORM MED
   [Anonymous], P 18 C UNC ART INT S
   [Anonymous], 2011, REL PAIN AM BLUEPR T
   [Anonymous], 1986, 5 NAT C ART INT
   [Anonymous], 2013, ITEM RESPONSE THEORY, DOI DOI 10.1007/978-94-017-1988-9_3
   [Anonymous], TI TI MANUAL NEWID V
   Apkarian AV, 2009, PROG NEUROBIOL, V87, P81, DOI 10.1016/j.pneurobio.2008.09.018
   Ashburn MA, 1999, LANCET, V353, P1865, DOI 10.1016/S0140-6736(99)04088-X
   Ball MJ, 2003, INT J MED INFORM, V69, P83, DOI 10.1016/S1386-5056(02)00098-9
   Baxt WG, 2002, ANN EMERG MED, V39, P366, DOI 10.1067/mem.2002.122705
   Binaghi E, 2008, INT J MED INFORM, V77, P256, DOI 10.1016/j.ijmedinf.2007.06.004
   Blaszczynski J, 2005, LECT NOTES ARTIF INT, V3581, P429
   Blazadonakis M, 1996, ARTIF INTELL MED, V8, P527, DOI 10.1016/S0933-3657(96)00354-5
   Bodenreider O, 2004, NUCLEIC ACIDS RES, V32, pD267, DOI 10.1093/nar/gkh061
   BOURLARD H, 1990, IEEE T PATTERN ANAL, V12, P1167, DOI 10.1109/34.62605
   Bramer M, 2002, KNOWL-BASED SYST, V15, P301, DOI 10.1016/S0950-7051(01)00163-0
   Breiman L., 1984, BIOMETRICS, P357
   Burges CJC, 1998, DATA MIN KNOWL DISC, V2, P121, DOI 10.1023/A:1009715923555
   Camargo LS, 2001, NEURAL COMPUT, V13, P2673, DOI 10.1162/089976601317098484
   CENDROWSKA J, 1987, INT J MAN MACH STUD, V27, P349, DOI 10.1016/S0020-7373(87)80003-2
   Chang CH, 2007, J PAIN SYMPTOM MANAG, V33, P745, DOI 10.1016/j.jpainsymman.2006.09.018
   Ciino, 2006, BIOMEDICAL INFORM CO
   Cimino JJ, 2006, METHOD INFORM MED, V45, P124
   Clark P., 1989, Machine Learning, V3, P261, DOI 10.1007/BF00116835
   Clarke EJ, 1996, COMPUT BIOMED RES, V29, P271, DOI 10.1006/cbmr.1996.0020
   Cole TJ, 1991, STAT MED, V10, P1162, DOI 10.1002/sim.4780100718
   de Lima L. R. S., 1998, Proceedings of the 1998 ACM CIKM International Conference on Information and Knowledge Management, P132, DOI 10.1145/288627.288649
   DOMBI J, 1990, FUZZY SET SYST, V35, P1, DOI 10.1016/0165-0114(90)90014-W
   Dreiseitl S, 2002, J BIOMED INFORM, V35, P352, DOI 10.1016/S1532-0464(03)00034-0
   Eich HP, 1997, COMP MED SY, P2, DOI 10.1109/CBMS.1997.596400
   Ellenius J, 1997, CLIN CHEM, V43, P1919
   Ellenius J, 2000, INT J MED INFORM, V60, P1, DOI 10.1016/S1386-5056(00)00064-2
   Elomaa T, 1999, LECT NOTES COMPUT SC, V1642, P63
   Elvidge K, 2008, ST HEAL T, V136, P169
   Farion K, 2004, LECT NOTES ARTIF INT, V3066, P805
   Farion K, 2009, METHOD INFORM MED, V48, P381, DOI 10.3414/ME0574
   Farion KJ, 2008, INT J MED INFORM, V77, P208, DOI 10.1016/j.ijmedinf.2007.01.004
   FATHITORBAGHAN M, 1994, METHOD INFORM MED, V33, P522
   Forrey AW, 1996, CLIN CHEM, V42, P81
   Gamberger D, 1995, LECT NOTES ARTIF INT, V912, P151
   Giordano J, 2010, PAIN PHYSICIAN, V13, P305
   Guo GD, 2003, LECT NOTES COMPUT SC, V2888, P986
   HANSEL D, 1990, EUROPHYS LETT, V11, P687, DOI 10.1209/0295-5075/11/7/018
   Hastie TJ., 2009, ELEMENTS STAT LEARNI, V2nd ed., DOI DOI 10.1007/B94608
   Hayes B, 2008, COMMUN ACM, V51, P9, DOI [10.1145/1364782.1364786, 10.1145/1364782.1364789]
   Heckerman D., 1995, TUTORIAL LEARNING BA
   Lu HM, 2006, IEEE SYS MAN CYBERN, P1137, DOI 10.1109/ICSMC.2006.384553
   Hu XHT, 2003, LECT NOTES ARTIF INT, V2639, P114
   Hu XH, 2006, 2006 IEEE International Conference on Granular Computing, P67
   Huang HY, 2003, CIN-COMPUT INFORM NU, V21, P206, DOI 10.1097/00024665-200307000-00011
   Hunt DL, 1998, JAMA-J AM MED ASSOC, V280, P1339, DOI 10.1001/jama.280.15.1339
   Indyk P., 1998, Proceedings of the Thirtieth Annual ACM Symposium on Theory of Computing, P604, DOI 10.1145/276698.276876
   John G. H., 1995, Uncertainty in Artificial Intelligence. Proceedings of the Eleventh Conference (1995), P338
   Jurgelenaite R, 2006, LECT NOTES COMPUT SC, V4212, P234
   Kennedy RL, 1997, COMPUT METH PROG BIO, V52, P93, DOI 10.1016/S0169-2607(96)01782-8
   Khemphila A., 2010, 2010 International Conference on Computer Information Systems and Industrial Management Applications (CISIM 2010), P193, DOI 10.1109/CISIM.2010.5643666
   Kon MA, 2000, NEURAL NETWORKS, V13, P365, DOI 10.1016/S0893-6080(00)00015-0
   Kong GL, 2012, EUR J OPER RES, V219, P564, DOI 10.1016/j.ejor.2011.10.044
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Kotsiantis SB, 2006, ARTIF INTELL REV, V26, P159, DOI [10.1007/s10462-007-9052-3, 10.1007/S10462-007-9052-3]
   Lai DTH, 2007, P ANN INT IEEE EMBS, P3144, DOI 10.1109/IEMBS.2007.4352996
   Lee YY, 2006, COMPUT BIOL MED, V36, P893, DOI 10.1016/j.compbiomed.2005.04.013
   Li HX, 2012, INT J APPROX REASON, V53, P24, DOI 10.1016/j.ijar.2011.09.002
   Lin L, 2006, DECIS SUPPORT SYST, V42, P1152, DOI 10.1016/j.dss.2005.10.007
   Loeser JD, 2008, PAIN, V137, P473, DOI 10.1016/j.pain.2008.04.025
   Lorena AC, 2011, EXPERT SYST APPL, V38, P5268, DOI 10.1016/j.eswa.2010.10.031
   LOWE HJ, 1994, JAMA-J AM MED ASSOC, V271, P1103, DOI 10.1001/jama.271.14.1103
   Lu HM, 2008, J BIOMED INFORM, V41, P340, DOI 10.1016/j.jbi.2007.08.009
   Macdonald G, 2012, COCHRANE DB SYST REV, DOI 10.1002/14651858.CD001930.pub3
   MELZACK R, 1975, PAIN, V1, P277, DOI 10.1016/0304-3959(75)90044-5
   Merboth MK, 2000, NURS CLIN N AM, V35, P375
   Meyfroidt G, 2009, BEST PRAC RES-CL ANA, V23, P127, DOI 10.1016/j.bpa.2008.09.003
   Michalowski W, 2005, INFOR, V43, P287
   Michalowski W, 2005, METHOD INFORM MED, V44, P14
   Midboe AM, 2011, TRANSL BEHAV MED, V1, P35, DOI 10.1007/s13142-011-0022-6
   Ohmann C, 1996, ARTIF INTELL MED, V8, P23, DOI 10.1016/0933-3657(95)00018-6
   Pasero CL, 1997, AM J NURS, V97, P15, DOI 10.2307/3465480
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pesonen E, 1998, ARTIF INTELL MED, V13, P139, DOI 10.1016/S0933-3657(98)00027-X
   Pombo N, 2012, LECT NOTES ENG COMP, P589
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Quinlan J.R., 2014, C4 5 PROGRAMS MACHIN
   Ramey D R, 1992, Arthritis Care Res, V5, P119, DOI 10.1002/art.1790050303
   Roshanov PS, 2011, IMPLEMENT SCI, V6, DOI [10.1186/1748-5908-6-88, 10.1186/1748-5908-6-92]
   Rosser BA, 2011, J TELEMED TELECARE, V17, P308, DOI 10.1258/jtt.2011.101102
   Sadeghi S, 2006, INT J MED INFORM, V75, P403, DOI 10.1016/j.ijmedinf.2005.07.028
   Selker HP, 1998, ANN INTERN MED, V129, P845, DOI 10.7326/0003-4819-129-11_Part_1-199812010-00002
   Simonic K. M., 2011, 2011 5th International Conference on Pervasive Computing Technologies for Healthcare (PervasiveHealth 2011), P550, DOI 10.4108/icst.pervasivehealth.2011.246087
   Smith MY, 2007, PAIN MED, V8, pS155, DOI 10.1111/j.1526-4637.2007.00278.x
   SMYTH P, 1992, IEEE T KNOWL DATA EN, V4, P301, DOI 10.1109/69.149926
   Stone Arthur S., 1994, Annals of Behavioral Medicine, V16, P199
   Tan KC, 2009, EXPERT SYST APPL, V36, P8616, DOI 10.1016/j.eswa.2008.10.013
   van Gerven MAJ, 2008, J BIOMED INFORM, V41, P515, DOI 10.1016/j.jbi.2008.01.006
   van Gerven MAJ, 2007, ARTIF INTELL MED, V40, P45, DOI 10.1016/j.artmed.2006.09.003
   VANDERHEIJDE DMFM, 1990, ANN RHEUM DIS, V49, P916, DOI 10.1136/ard.49.11.916
   Vapnik V., 1995, NATURE STAT LEARNING
   Wainer, 2000, COMPUTERIZED ADAPTIV
   Wan Yina, 2010, Proceedings of the 2010 Second International Conference on Multimedia and Information Technology (MMIT 2010), P60, DOI 10.1109/MMIT.2010.32
   Wang AY, 2001, J AM MED INFORM ASSN, P741
   Wang MS, 2004, IEEE T INF TECHNOL B, V8, P287, DOI 10.1109/TITB.2004.834397
   Wang SJ, 2001, COMPUT BIOL MED, V31, P1, DOI 10.1016/S0010-4825(00)00022-6
   Westfall JM, 2006, ANN FAM MED, V4, P153, DOI 10.1370/afm.403
   Wilkie DJ, 2003, J PAIN SYMPTOM MANAG, V25, P213, DOI 10.1016/S0885-3924(02)00638-3
   Yaguinuma CA, 2010, IEEE INT ENTERP, P263, DOI 10.1109/EDOCW.2010.41
   Yang JL, 2011, EXPERT SYST APPL, V38, P9346, DOI 10.1016/j.eswa.2011.01.106
   ZADEH LA, 1965, INFORM CONTROL, V8, P338, DOI 10.1016/S0019-9958(65)90241-X
   ZWICK R, 1989, INT J MAN MACH STUD, V30, P69, DOI 10.1016/S0020-7373(89)80021-5
NR 125
TC 2
Z9 2
U1 0
U2 36
PY 2014
VL 26
IS 5
BP 2411
EP 2425
DI 10.3233/IFS-130912
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Henry, G
   Palangpour, P
   Thomson, M
   Gardner, JS
   Arden, B
   Donahue, J
   Houck, K
   Johnson, J
   O'Brien, K
   Petersen, S
   Seroussi, B
   Walker, T
AF Henry, Glenn
   Palangpour, Parviz
   Thomson, Michael
   Gardner, J. Scott
   Arden, Bryce
   Donahue, Jim
   Houck, Kimble
   Johnson, Jonathan
   O'Brien, Kyle
   Petersen, Scott
   Seroussi, Benjamin
   Walker, Tyler
GP IEEE
TI High-Performance Deep-Learning Coprocessor Integrated into x86 SoC with
   Server-Class CPUs
SO 2020 ACM/IEEE 47TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2020)
SE ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE
DT Proceedings Paper
CT 47th ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY MAY 30-JUN 03, 2020
CL ELECTR NETWORK
AB Demand for high performance deep learning (DL) inference in software applications is growing rapidly. DL workloads run on myriad platforms, including general purpose processors (CPU), system-on-chip (SoC) with accelerators, graphics processing units (GPU), and neural processing unit (NPU) add-in cards. DL software engineers typically must choose between relatively slow general hardware (e.g., CPUs, SoCs) or relatively expensive, large, power-hungry hardware (e.g., GPUs, NPUs).
   This paper describes Centaur Technology's Ncore, the industry's first high-performance DL coprocessor technology integrated into an x86 SoC with server-class CPUs. Ncore's 4096 byte-wide SIMD architecture supports INT8, UINT8, INT16, and BF16 datatypes, with 20 tera-operations-per-second compute capability. Ncore shares the SoC ring bus for low-latency communication and work sharing with eight 64-bit x86 cores, offering flexible support for new and evolving models. The x86 SoC platform can further scale out performance via multiple sockets, systems, or third-party PCIe accelerators. Ncore's software stack automatically converts quantized models for Ncore consumption and leverages existing DL frameworks.
   In MLPerf's Inference v0.5 closed division benchmarks, Ncore achieves 1218 IPS throughput and 1.05ms latency on ResNet-50v1.5 and achieves lowest latency of all Mobilenet-V1 submissions (329 mu s). Ncore yields 23x speedup over other x86 vendor percore throughput, while freeing its own x86 cores for other work. Ncore is the only integrated solution among the memory intensive neural machine translation (NMT) submissions.
C1 [Henry, Glenn; Palangpour, Parviz; Thomson, Michael; Arden, Bryce; Donahue, Jim; Houck, Kimble; Johnson, Jonathan; O'Brien, Kyle; Petersen, Scott; Seroussi, Benjamin; Walker, Tyler] Centaur Technol, Austin, TX 78731 USA.
   [Gardner, J. Scott] Advantage Engn LLC, Columbia, MD USA.
RP Henry, G (corresponding author), Centaur Technol, Austin, TX 78731 USA.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   [Anonymous], 2018, DEEP LEARNING INFERE
   [Anonymous], 2019, STUDY BFLOAT16 DEEP
   [Anonymous], 2019, HERALD OPTIMIZING HE
   [Anonymous], 2019, 2019 IEEE HOT CHIPS
   [Anonymous], 2017, 2017 IEEE HOT CHIPS
   [Anonymous], 2019, INT XEON PLAT 9282 P
   [Anonymous], 2016, ICLR
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Intel Corporation, 2019, INT 64 IA 32 ARCH OP
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lattner Chris, 2019, MLIR PRIMER COMPILER
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Wang Y. E., 2019, BENCHMARKING TPU GPU
   Zhang C, 2015, 2015 8TH INTERNATIONAL CONFERENCE ON BIOMEDICAL ENGINEERING AND INFORMATICS (BMEI), P158, DOI 10.1109/BMEI.2015.7401492
NR 26
TC 3
Z9 3
U1 0
U2 0
PY 2020
BP 15
EP 26
DI 10.1109/ISCA45697.2020.00013
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Xu, HJ
   Shiomi, J
   Onodera, H
AF Xu, Hongjie
   Shiomi, Jun
   Onodera, Hidetoshi
TI Evaluation Metrics for the Cost of Data Movement in Deep Neural Network
   Acceleration
SO IEICE TRANSACTIONS ON FUNDAMENTALS OF ELECTRONICS COMMUNICATIONS AND
   COMPUTER SCIENCES
DT Article
DE convolutional neural networks; machine learning; low power circuit
   design; VLSI; parallel processing
AB Hardware accelerators are designed to support a specialized processing dataflow for everchanging deep neural networks (DNNs) under various processing environments. This paper introduces two hardware properties to describe the cost of data movement in each memory hierarchy. Based on the hardware properties, this paper proposes a set of evaluation metrics that are able to evaluate the number of memory accesses and the required memory capacity according to the specialized processing dataflow. Proposed metrics are able to analytically predict energy, throughput, and area of a hardware design without detailed implementation. Once a processing dataflow and constraints of hardware resources are determined, the proposed evaluation metrics quickly quantify the expected hardware benefits, thereby reducing design time.
C1 [Xu, Hongjie] Kyoto Univ, Commun & Comp Engn, Kyoto 6068501, Japan.
   [Shiomi, Jun; Onodera, Hidetoshi] Kyoto Univ, Dept Commun & Comp Engn, Grad Sch Informat, Kyoto 6068501, Japan.
   [Onodera, Hidetoshi] Kyoto Univ, Dept Elect, Kyoto 6068501, Japan.
RP Xu, HJ (corresponding author), Kyoto Univ, Commun & Comp Engn, Kyoto 6068501, Japan.
EM xuhongjie@vlsi.kuee.kyoto-u.ac.jp; shiomi-jun@i.kyoto-u.ac.jp;
   onodera@i.kyoto-u.ac.jp
CR Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Google, 2019, EDG TPU
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Intel, 2019, INTEL NEURAL COMPUTE
   Jo J, 2018, IEEE T CIRCUITS-I, V65, P4196, DOI 10.1109/TCSI.2018.2840092
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Vissers K, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P83, DOI 10.1145/3289602.3294007
   Wilton SJE, 1996, IEEE J SOLID-ST CIRC, V31, P677, DOI 10.1109/4.509850
   Wu Y, 2020, PSYCHOL MED, V50, P1368, DOI [10.1017/S0033291719001314, 10.1145/3290605.3300666]
   Xu H., 2020, GLSVLSI 20
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/ICASSP40776.2020.9053977, 10.1109/icassp40776.2020.9053977]
   Zisserman A., 2014, 14091556 ARXIV
NR 26
TC 0
Z9 0
U1 0
U2 1
PD NOV
PY 2021
VL E104A
IS 11
BP 1488
EP 1498
DI 10.1587/transfun.2020KEP0003
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shi, X
AF Shi, Xuan
BE Griffith, DA
   Chun, Y
   Dean, DJ
TI Parallelizing Affinity Propagation Using Graphics Processing Units for
   Spatial Cluster Analysis over Big Geospatial Data
SO ADVANCES IN GEOCOMPUTATION
SE Advances in Geographic Information Science
DT Proceedings Paper
CT 13th International Conference on Geocomputation (Geocomputation)
CY MAY 20-23, 2015
CL Univ Texas Dallas, Dallas, TX
HO Univ Texas Dallas
DE Spatial clustering; Affinity propagation; Parallel computing; GPU
ID ALGORITHM
AB Introduced in 2007, affinity propagation (AP) is a relatively new machine learning algorithm for unsupervised classification that has seldom been applied in geospatial applications. One bottleneck is that AP could hardly handle large data, and a serial computer program would take a long time to complete an AP calculation. New multicore and manycore computer architectures, combined with application accelerators, show promise for achieving scalable geocomputation by exploiting task and data levels of parallelism. This chapter introduces our recent progress in parallelizing the AP algorithm on a graphics processing unit (GPU) for spatial cluster analysis, the potential of the proposed solution to process big geospatial data, and its broader impact for the GIScience community.
C1 [Shi, Xuan] Univ Arkansas, Dept Geosci, 216 Gearhart Hall, Fayetteville, AR 72701 USA.
RP Shi, X (corresponding author), Univ Arkansas, Dept Geosci, 216 Gearhart Hall, Fayetteville, AR 72701 USA.
EM xuanshi@uark.edu
CR [Anonymous], 1979, PHILOS GEOGRAPHY
   [Anonymous], 2006, PRIOR GEOINT RES NAT
   [Anonymous], 2009, AFFINITY PROPAGATION
   ANSELIN L, 1995, GEOGR ANAL, V27, P93, DOI 10.1111/j.1538-4632.1995.tb00338.x
   Bodenhofer U, 2015, APCLUSTER R PACKAGE
   Chehdi K, 2014, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083567
   Frey BJ, 2005, NAT GENET, V37, P991, DOI 10.1038/ng1630
   Frey BJ, 2007, SCIENCE, V315, P972, DOI 10.1126/science.1136800
   Frey BJ, 2008, SCIENCE, V319, DOI 10.1126/science.1151268
   Han J, 2001, GEOGRAPHIC DATA MINI, P201
   Jacquez GM, 2008, BLACKW COMPANION GEO, P395
   Kwan MP, 2014, GEOGR ANAL, V46, P297, DOI 10.1111/gean.12040
   Lu Y., 2000, SPATIAL CLUSTER ANAL
   Mennis J, 2009, COMPUT ENVIRON URBAN, V33, P403, DOI 10.1016/j.compenvurbsys.2009.11.001
   Napoleon D, 2012, INT J ADV RES COMPUT, V2, P326
   *NAT RES COUNC, 2006, MAPP M NAT NEEDS ENH
   Xia HY, 2009, IEEE SYS MAN CYBERN, P3116, DOI 10.1109/ICSMC.2009.5346147
   Yang C, 2010, IEEE T GEOSCI REMOTE, V48, P2647, DOI 10.1109/TGRS.2010.2040035
NR 18
TC 2
Z9 2
U1 0
U2 7
PY 2017
BP 355
EP 369
DI 10.1007/978-3-319-22786-3_32
WC Computer Science, Information Systems; Computer Science,
   Interdisciplinary Applications; Geography, Physical
DA 2023-11-11
ER

PT J
AU Khalifa, A
   Winter, J
   Navarro, I
   McIntosh, C
   Purdie, TG
AF Khalifa, Aly
   Winter, Jeff
   Navarro, Inmaculada
   McIntosh, Chris
   Purdie, Thomas G.
TI Domain adaptation of automated treatment planning from computed
   tomography to magnetic resonance
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE machine learning; automated treatment planning; quality assurance;
   magnetic resonance linear accelerator; domain adaptation; prostate
   cancer
ID DOSE PREDICTION; MODEL; RADIOTHERAPY; FEASIBILITY
AB Objective. Machine learning (ML) based radiation treatment planning addresses the iterative and time-consuming nature of conventional inverse planning. Given the rising importance of magnetic resonance (MR) only treatment planning workflows, we sought to determine if an ML based treatment planning model, trained on computed tomography (CT) imaging, could be applied to MR through domain adaptation. Methods. In this study, MR and CT imaging was collected from 55 prostate cancer patients treated on an MR linear accelerator. ML based plans were generated for each patient on both CT and MR imaging using a commercially available model in RayStation 8B. The dose distributions and acceptance rates of MR and CT based plans were compared using institutional dose-volume evaluation criteria. The dosimetric differences between MR and CT plans were further decomposed into setup, cohort, and imaging domain components. Results. MR plans were highly acceptable, meeting 93.1% of all evaluation criteria compared to 96.3% of CT plans, with dose equivalence for all evaluation criteria except for the bladder wall, penile bulb, small and large bowel, and one rectum wall criteria (p < 0.05). Changing the input imaging modality (domain component) only accounted for about half of the dosimetric differences observed between MR and CT plans. Anatomical differences between the ML training set and the MR linac cohort (cohort component) were also a significant contributor. Significance. We were able to create highly acceptable MR based treatment plans using a CT-trained ML model for treatment planning, although clinically significant dose deviations from the CT based plans were observed. Future work should focus on combining this framework with atlas selection metrics to create an interpretable quality assurance QA framework for ML based treatment planning.
C1 [Khalifa, Aly; McIntosh, Chris; Purdie, Thomas G.] Univ Toronto, Dept Med Biophys, Toronto, ON, Canada.
   [Khalifa, Aly; Winter, Jeff; McIntosh, Chris; Purdie, Thomas G.] Univ Hlth Network, Techna Inst, Toronto, ON, Canada.
   [Winter, Jeff; Navarro, Inmaculada; McIntosh, Chris; Purdie, Thomas G.] Princess Margaret Canc Ctr, Radiat Med Program, Toronto, ON, Canada.
   [Winter, Jeff; Navarro, Inmaculada; Purdie, Thomas G.] Univ Toronto, Dept Radiat Oncol, Toronto, ON, Canada.
   [McIntosh, Chris] Univ Hlth Network, Peter Munk Cardiac Ctr, Toronto, ON, Canada.
   [McIntosh, Chris] Univ Hlth Network, Joint Dept Med Imaging, Toronto, ON, Canada.
   [McIntosh, Chris] Vector Inst, Toronto, ON, Canada.
RP Khalifa, A (corresponding author), Univ Toronto, Dept Med Biophys, Toronto, ON, Canada.; Khalifa, A (corresponding author), Univ Hlth Network, Techna Inst, Toronto, ON, Canada.
EM aly.khalifa@mail.utoronto.ca
CR [Anonymous], MACH LEARN
   Babier A, 2021, MED PHYS, V48, P5549, DOI 10.1002/mp.14845
   Cagni E, 2017, PHYS MEDICA, V36, P38, DOI 10.1016/j.ejmp.2017.03.002
   Campbell WG, 2017, MED PHYS, V44, P6148, DOI 10.1002/mp.12621
   Chao ML, 2021, MED DOSIM, V46, P269, DOI 10.1016/j.meddos.2021.02.005
   Conroy L, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abfff0
   Costa E, 2021, PHYS MEDICA, V86, P32, DOI 10.1016/j.ejmp.2021.05.022
   Ge YR, 2019, MED PHYS, V46, P2760, DOI 10.1002/mp.13526
   Johnstone E, 2018, INT J RADIAT ONCOL, V100, P199, DOI 10.1016/j.ijrobp.2017.08.043
   Kandalan RN, 2020, RADIOTHER ONCOL, V153, P228, DOI 10.1016/j.radonc.2020.10.027
   Kazhdan M, 2009, LECT NOTES COMPUT SC, V5762, P100, DOI 10.1007/978-3-642-04271-3_13
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Martin JM, 2007, INT J RADIAT ONCOL, V69, P1084, DOI 10.1016/j.ijrobp.2007.04.049
   Mattes MD, 2014, RADIAT ONCOL J, V32, P23, DOI 10.3857/roj.2014.32.1.23
   McIntosh C, 2021, NAT MED, V27, P999, DOI 10.1038/s41591-021-01359-w
   McIntosh C, 2017, PHYS MED BIOL, V62, P5926, DOI 10.1088/1361-6560/aa71f8
   McIntosh C, 2016, IEEE T MED IMAGING, V35, P1000, DOI 10.1109/TMI.2015.2505188
   Mclntosh C, 2017, PHYS MED BIOL, V62, P415, DOI 10.1088/1361-6560/62/2/415
   Moore KL, 2011, INT J RADIAT ONCOL, V81, P545, DOI 10.1016/j.ijrobp.2010.11.030
   Shortall J, 2020, MED PHYS, V47, P2506, DOI 10.1002/mp.14123
   Wang CH, 2019, TECHNOL CANCER RES T, V18, DOI 10.1177/1533033819873922
   Wang WT, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac3c14
   Wu H, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0684-9
NR 23
TC 0
Z9 0
U1 0
U2 0
PD JUN 21
PY 2022
VL 67
IS 12
AR 125010
DI 10.1088/1361-6560/ac72ec
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Duris, J
   Kennedy, D
   Hanuka, A
   Shtalenkova, J
   Edelen, A
   Baxevanis, P
   Egger, A
   Cope, T
   McIntire, M
   Ermon, S
   Ratner, D
AF Duris, J.
   Kennedy, D.
   Hanuka, A.
   Shtalenkova, J.
   Edelen, A.
   Baxevanis, P.
   Egger, A.
   Cope, T.
   McIntire, M.
   Ermon, S.
   Ratner, D.
TI Bayesian Optimization of a Free-Electron Laser
SO PHYSICAL REVIEW LETTERS
DT Article
AB The Linac coherent light source x-ray free-electron laser is a complex scientific apparatus which changes configurations multiple times per day, necessitating fast tuning strategies to reduce setup time for successive experiments. To this end, we employ a Bayesian approach to maximizing x-ray laser pulse energy by controlling groups of quadrupole magnets. A Gaussian process model provides probabilistic predictions for the machine response with respect to control parameters, enabling a balance of exploration and exploitation in the search for the global optimum. We show that the model parameters can be learned from archived scans, and correlations between devices can be extracted from the beam transport. The result is a sample-efficient optimization routine, combining both historical data and knowledge of accelerator physics to significantly outperform existing optimizers.
C1 [Duris, J.; Kennedy, D.; Hanuka, A.; Shtalenkova, J.; Edelen, A.; Baxevanis, P.; Egger, A.; Cope, T.; Ratner, D.] SLAG Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Kennedy, D.] Univ Calif Santa Cruz, Dept Phys, Santa Cruz, CA 95064 USA.
   [McIntire, M.; Ermon, S.] Stanford Univ, Dept Comp Sci, Stanford, CA 94305 USA.
RP Duris, J (corresponding author), SLAG Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
CR Akre R, 2008, PHYS REV SPEC TOP-AC, V11, DOI 10.1103/PhysRevSTAB.11.030703
   Borland M., ADV PHOTON SOURCE LS, DOI [10.2172/761286, DOI 10.2172/761286]
   Brochu E., ARXIV10122599
   Calandra R, 2016, IEEE IJCNN, P3338, DOI 10.1109/IJCNN.2016.7727626
   CRESSIE N, 1990, MATH GEOL, V22, P239, DOI 10.1007/BF00889887
   Damianou A., 2013, P 16 INT C ARTIFICIA, P207, DOI DOI 10.1002/NME.1296
   Degrave J, 2019, FRONT NEUROROBOTICS, V13, DOI 10.3389/fnbot.2019.00006
   Delhomme JP, 1978, ADV WATER RESOUR, V1, P251, DOI 10.1016/0309-1708(78)90039-8
   Duvenaud D., 2013, 30 INT C MACH LEARN, V28, P2203
   Edelen A., 2019, P MACH LEARN PHYS SC
   Emma P, 2010, NAT PHOTONICS, V4, P641, DOI [10.1038/nphoton.2010.176, 10.1038/NPHOTON.2010.176]
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Huang XB, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.104601
   Huang XB, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.084001
   Jacot A, 2018, ADV NEURAL INFORM PR, P8580, DOI DOI 10.48550/ARXIV.1806.07572
   Kim K, 2005, PHYS PLASMAS, V12, DOI 10.1063/1.1914536
   Kirschner J, 2019, PR MACH LEARN RES, V97
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Martinez-Cantin R, 2009, AUTON ROBOT, V27, P93, DOI 10.1007/s10514-009-9130-2
   Matthews AGD, 2017, J MACH LEARN RES, V18, P1
   McIntire M, 2016, UAI
   Mockus J., 1975, OPTIMIZATION TECHNIQ, P400, DOI [10.1007/3-540-07165-2_55, DOI 10.1007/3-540-07165-2_55]
   NELDER JA, 1965, COMPUT J, V7, P308, DOI 10.1093/comjnl/7.4.308
   Noack MM, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48114-3
   Rasmussen CE, 2010, J MACH LEARN RES, V11, P3011
   Reiche S, 1999, FREE ELECTRON LASERS 1998, P243
   Ross Ashby W., 1970, INT J SYST SCI, V1, P89, DOI [DOI 10.1080/00207727008920220, 10.1080/00207727008920220]
   Salvatier J, 2016, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.55
   Scheinker A, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082802
   Scheinker A, 2018, IEEE T CONTR SYST T, V26, P336, DOI 10.1109/TCST.2017.2664728
   Scheinker A, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.102803
   Seeger Matthias, 2004, Int J Neural Syst, V14, P69, DOI 10.1142/S0129065704001899
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J., 2012, PROC INT C NEURAL IN, V25, P2951
   Srinivas N, 2012, IEEE T INFORM THEORY, V58, P3250, DOI 10.1109/TIT.2011.2182033
   Sun SY, 2018, PR MACH LEARN RES, V80
   Tomin S., 2016, P 7 INT PART ACC C
   Wiedemann H., 2007, PARTICLE ACCELERATOR
   Wilson AG, 2016, ADV NEUR IN, V29
   Wu J., 2018, 38 INT FREE EL LAS C, P229
NR 40
TC 57
Z9 57
U1 4
U2 13
PD MAR 25
PY 2020
VL 124
IS 12
AR 124801
DI 10.1103/PhysRevLett.124.124801
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Munoz, NL
   Valero, A
   Tejero, RG
   Zoni, D
AF Munoz, Nicolas Landeros
   Valero, Alejandro
   Tejero, Ruben Gran
   Zoni, Davide
TI Gated-CNN: Combating NBTI and HCI aging effects in on-chip activation
   memories of Convolutional Neural Network accelerators
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Access patterns; Bit flip patterns; Deep learning; Duty cycle; Hardware
   design; Hot Carrier Injection; Machine learning; Negative Bias
   Temperature Instability; Threshold voltage degradation
AB Negative Bias Temperature Instability (NBTI) and Hot Carrier Injection (HCI) are two of the main reliability threats in current technology nodes. These aging phenomena degrade the transistor's threshold voltage (V-th) over the lifetime of a digital circuit, resulting in slower transistors that eventually lead to a faulty operation when the critical paths become longer than the processor cycle time. Among all the transistors on a chip, the most vulnerable transistors to such wearout effects are those used to implement SRAM storage, since memory cells are continuously degrading. In particular, NBTI ages PMOS cell transistors when a given logic value is stored for a long period (i.e., a long duty cycle), whereas HCI ages NMOS cell transistors not only when the stored value flips but also when it is accessed. This work focuses on mitigating aging in the on-chip SRAM memories of Convolutional Neural Network (CNN) accelerators storing activations. This paper makes two main contributions. At the software level, we quantify the aging induced by current CNN benchmarks with a characterization study of duty cycle, flip, and access patterns in every activation memory cell. Based on the insights from this study, this work proposes a novel microarchitectural technique, Gated-CNN, that ensures a uniform aging degradation of every memory cell. To do so, Gated-CNN exploits power-gating and address rotation techniques tailored to the memory demands and temporal/spatial localities exhibited by CNN applications, as well as the memory organization and management of CNN accelerators. Experimental results show that, compared to a conventional design, the average V-th degradation savings are at least as much as 49% on the of transistor.
C1 [Munoz, Nicolas Landeros; Zoni, Davide] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Milan, Italy.
   [Valero, Alejandro; Tejero, Ruben Gran] Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza, Spain.
RP Valero, A (corresponding author), Univ Zaragoza, Dept Comp Sci & Syst Engn, Zaragoza, Spain.
EM alvabre@unizar.es
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Abella J, 2007, INT SYMP MICROARCH, P85, DOI 10.1109/MICRO.2007.11
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alnuayri T, 2021, IEEE T VLSI SYST, V29, P2064, DOI 10.1109/TVLSI.2021.3115247
   [Anonymous], 2013, P 43 ANN IEEE IFIP I
   [Anonymous], 2013, P INT C HARDWARESOFT
   Bojarski Mariusz, 2016, arXiv
   Brownlee J., 2016, MASTER MACHINE LEARN
   Calimera A, 2014, IEEE T COMPUT AID D, V33, P251, DOI 10.1109/TCAD.2013.2287187
   Calimera A, 2010, IEEE INT SYMP CIRC S, P785, DOI 10.1109/ISCAS.2010.5537452
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Deng J., 2009, 2009 IEEE C COMP VIS, P248, DOI [DOI 10.1109/CVPR.2009.5206848, 10.1109/CVPR.2009.5206848]
   Dounavi HM, 2021, J ELECTRON TEST, V37, P65, DOI 10.1007/s10836-021-05932-6
   Ganapathy S, 2014, PR IEEE COMP DESIGN, P68, DOI 10.1109/ICCD.2014.6974664
   Gebregiorgis A, 2015, ASIA S PACIF DES AUT, P231, DOI 10.1109/ASPDAC.2015.7059010
   Gong N, 2012, MICROELECTRON RELIAB, V52, P1865, DOI 10.1016/j.microrel.2012.06.045
   Gunadi E., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P103, DOI 10.1109/MICRO.2010.37
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hanif M. A., P DES AUT TEST EUR C, V2021, P729
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Iandola F.N., 2014, CORR ABS14041869 ARX
   Iandola F. N., 2016, ARXIV
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kather JN, 2016, SCI REP-UK, V6, DOI 10.1038/srep27988
   Kaxiras S, 2001, ACM COMP AR, P240, DOI 10.1109/ISCA.2001.937453
   Kothawade S, 2012, PR IEEE COMP DESIGN, P345, DOI 10.1109/ICCD.2012.6378662
   Kothawade S, 2011, INT SYM QUAL ELECT, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee S, 2017, IEEE T COMPUT, V66, P834, DOI 10.1109/TC.2016.2619348
   Li S., 2012, HPL2012187
   Mintarno E, 2013, INT RELIAB PHY SYM
   Moreno AA, 2020, IEEE T VLSI SYST, V28, P1993, DOI 10.1109/TVLSI.2020.3005451
   Mottaghi M.H., 2021, IEEE T COMPUT EARLY, P1
   Nigam T, 2009, 2009 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM, VOLS 1 AND 2, P634, DOI 10.1109/IRPS.2009.5173322
   Oboril F, 2012, I C DEPEND SYS NETWO
   Pilo Harold, 2008, 2008 IEEE International Solid-State Circuits Conference - Digest of Technical Papers, P378, DOI 10.1109/ISSCC.2008.4523215
   Pilo H, 2013, ISSCC DIG TECH PAP I, V56, P322, DOI 10.1109/ISSCC.2013.6487753
   Rahman Md. Tauhidur, 2014, P 51 ANN DES AUT C, P1
   Ricketts A, 2010, DES AUT TEST EUROPE, P592
   Ruospo A, 2021, MICROPROCESS MICROSY, V86, DOI 10.1016/j.micpro.2021.104318
   Samajdar A., 2018, CORR ABS181102883 AR
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shin J, 2008, CONF PROC INT SYMP C, P353, DOI 10.1109/ISCA.2008.30
   Siddiqua T, 2012, IEEE T VLSI SYST, V20, P616, DOI 10.1109/TVLSI.2011.2109973
   Siddiqua T, 2010, IEEE COMP SOC ANN, P393, DOI 10.1109/ISVLSI.2010.15
   Sim J, 2020, IEEE T VLSI SYST, V28, P87, DOI 10.1109/TVLSI.2019.2935251
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tiwari A, 2008, INT SYMP MICROARCH, P129, DOI 10.1109/MICRO.2008.4771785
   Tuzov I., 2021, P IEEEACM INT C COMP, P1
   Valero A, 2019, IEEE T COMPUT, V68, P4, DOI 10.1109/TC.2018.2849376
   Valero A, 2017, IEEE T VLSI SYST, V25, P857, DOI 10.1109/TVLSI.2016.2625809
   Vattikonda R, 2006, DES AUT CON, P1047, DOI 10.1109/DAC.2006.229436
   Yazdanbakhsh A., 2021, ARXIV210210423
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
NR 59
TC 1
Z9 1
U1 1
U2 5
PD JUL
PY 2022
VL 128
DI 10.1016/j.sysarc.2022.102553
EA MAY 2022
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Papadonikolakis, M
   Bouganis, CS
AF Papadonikolakis, Markos
   Bouganis, Christos-Savvas
TI Novel Cascade FPGA Accelerator for Support Vector Machines
   Classification
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Cascade classifier; classification; field programmable gate array
   (FPGA); parallel processing; support vector machines (SVMs)
ID ARCHITECTURE; ALGORITHM
AB Support vector machines (SVMs) are a powerful machine learning tool, providing state-of-the-art accuracy to many classification problems. However, SVM classification is a computationally complex task, suffering from linear dependencies on the number of the support vectors and the problem's dimensionality. This paper presents a fully scalable field programmable gate array (FPGA) architecture for the acceleration of SVM classification, which exploits the device heterogeneity and the dynamic range diversities among the dataset attributes. An adaptive and fully-customized processing unit is proposed, which utilizes the available heterogeneous resources of a modern FPGA device in efficient way with respect to the problem's characteristics. The implementation results demonstrate the efficiency of the heterogeneous architecture, presenting a speed-up factor of 2-3 orders of magnitude, compared to the CPU implementation. The proposed architecture outperforms other proposed FPGA and graphic processor unit approaches by more than seven times. Furthermore, based on the special properties of the heterogeneous architecture, this paper introduces the first FPGA-oriented cascade SVM classifier scheme, which exploits the FPGA reconfigurability and intensifies the custom-arithmetic properties of the heterogeneous architecture. The results show that the proposed cascade scheme is able to increase the heterogeneous classifier throughput even further, without introducing any penalty on the resource utilization.
C1 [Papadonikolakis, Markos; Bouganis, Christos-Savvas] Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
RP Papadonikolakis, M (corresponding author), Univ London Imperial Coll Sci Technol & Med, Dept Elect & Elect Engn, London SW7 2AZ, England.
EM markos.papadonikolakis07@imperial.ac.uk;
   christos-savvas.bouganis@imperial.ac.uk
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2008, P 25 INT C MACHINE L, DOI [10.1145/1390156.1390170, DOI 10.1145/1390156.1390170]
   [Anonymous], 2006, P ACMSIGKDD INT C KN
   [Anonymous], 2008, NVIDIA CUDA COMP UN
   Asuncion A., 2007, UCI MACHINE LEARNING
   Burges C. J. C., 1996, Machine Learning. Proceedings of the Thirteenth International Conference (ICML '96), P71
   Burges CJC, 1997, ADV NEUR IN, V9, P375
   Byun H, 2002, LECT NOTES COMPUT SC, V2388, P213
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Carpenter A., 2009, CUSVM CUDA IMPLEMENT
   Gilbert E G., 1966, SIAM J CONTROL, V4, P61
   Hsu C.-W., 2003, 1 NAT TAIW U DEP COM
   Hsu CF, 2009, IEEE INT SOC CONF, P239, DOI 10.1109/SOCCON.2009.5398049
   Irick KM, 2008, ANN IEEE SYM FIELD P, P304, DOI 10.1109/FCCM.2008.40
   Joachims T, 1999, MACHINE LEARNING, PROCEEDINGS, P200
   Keerthi SS, 2000, IEEE T NEURAL NETWOR, V11, P124, DOI 10.1109/72.822516
   Khan FM, 2005, IEEE INT SYMP CIRC S, P5154, DOI 10.1109/ISCAS.2005.1465795
   Kukenys Ignas, 2008, 2008 23 INT C IM VIS, P1
   Langhammer M, 2008, I C FIELD PROG LOGIC, P354
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mandrake L., 2009, P 30 IEEE AER C MAR, P1
   Martin S, 2005, FIFTH IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P306, DOI 10.1109/ICDM.2005.145
   Mercer J, 1909, PHILOS T R SOC LOND, V209, P415, DOI 10.1098/rsta.1909.0016
   Papadonikolakis M., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P283, DOI 10.1109/FPT.2010.5681485
   Papadonikolakis M, 2008, I C FIELD PROG LOGIC, P384, DOI 10.1109/FPL.2008.4629968
   Papadonikolakis M, 2008, PROCEEDINGS OF THE 2008 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, P337, DOI 10.1109/FPT.2008.4762412
   Platt JC, 1999, ADVANCES IN KERNEL METHODS, P185
   Romdhani S, 2004, P ROY SOC A-MATH PHY, V460, P3283, DOI 10.1098/rspa.2004.1333
   Ruiz-Llata M, 2009, LECT NOTES COMPUT SC, V5768, P467, DOI 10.1007/978-3-642-04274-4_49
   Scholkopf B., 2001, LEARNING KERNELS
   Terrillon JC, 2000, INT C PATT RECOG, P210, DOI 10.1109/ICPR.2000.902897
   Vapnik V., 1995, NATURE STAT LEARNING
NR 32
TC 58
Z9 59
U1 2
U2 18
PD JUL
PY 2012
VL 23
IS 7
BP 1040
EP 1052
DI 10.1109/TNNLS.2012.2196446
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Xu, PF
   Zhang, XF
   Hao, C
   Zhao, Y
   Zhang, YA
   Wang, Y
   Li, CJ
   Guan, ZT
   Chen, DM
   Lin, YY
AF Xu, Pengfei
   Zhang, Xiaofan
   Hao, Cong
   Zhao, Yang
   Zhang, Yongan
   Wang, Yue
   Li, Chaojian
   Guan, Zetong
   Chen, Deming
   Lin, Yingyan
GP ACM
TI <i>AutoDNNchip</i>: An Automated DNN Chip Predictor and Builder for Both
   FPGAs and ASICs
SO 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS
   (FPGA '20)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 23-25, 2020
CL Seaside, CA
AB Recent breakthroughs in Deep Neural Networks (DNNs) have fueled a growing demand for domain-specific hardware accelerators (i.e., DNN chips). However, designing DNN chips is non-trivial because: (1) mainstream DNNs have millions of parameters and operations; (2) the design space is large due to the numerous design choices of dataflows, processing elements, memory hierarchy, etc.; and (3) an algorithm/hardware co-design is needed to allow the same DNN functionality to have a different decomposition that would require different hardware IPs that correspond to dramatically different performance/energy/area tradeoffs. Therefore, DNN chips often take months to years to design and require a large team of cross-disciplinary experts. To enable fast and effective DNN chip design, we propose AutoDNNchip - a DNN chip generator that can automatically generate both FPGA- and ASIC-based DNN chip implementation (i.e., synthesizable RTL code with optimized algorithm-to-hardware mapping (i.e., dataflow)) given DNNs from machine learning frameworks (e.g., PyTorch) for a designated application and dataset without humans in the loop. Specifically, AutoDNNchip consists of two integrated enablers: (1) a Chip Predictor, built on top of a graph-based accelerator representation, which can accurately and efficiently predict a DNN accelerator's energy, throughput, latency, and area based on the DNN model parameters, hardware configuration, technology-based IPs, and platform constraints; and (2) a Chip Builder, which can automatically explore the design space of DNN chips (including IP selection, block configuration, resource balance, etc.), optimize chip design via the Chip Predictor, and then generate synthesizable RTL code with optimized dataflows to achieve the target design metrics. Experimental results show that our Chip Predictor's predicted performance differs from the real-measured one by <10% when validated using 15 DNN models and 4 platforms (edge-FPGA/TPU/GPU and ASIC). Furthermore, both the FPGA- and ASIC-based DNN accelerators generated by our AutoDNNchip can achieve better (up to 3.86x improvement) performance than that of expert-crafted state-of-the-art accelerators, showing the effectiveness of AutoDNNchip. Our open-source code can be found at https://github.com/RICE-EIC/AutoDNNchip.git.
C1 [Xu, Pengfei; Zhao, Yang; Zhang, Yongan; Wang, Yue; Li, Chaojian; Guan, Zetong; Lin, Yingyan] Rice Univ, Houston, TX 77251 USA.
   [Zhang, Xiaofan; Hao, Cong; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Xu, PF (corresponding author), Rice Univ, Houston, TX 77251 USA.
EM px5@rice.edu; xiaofan3@illinois.edu; congh@illinois.edu; zy34@rice.edu;
   yz87@rice.edu; yw68@rice.edu; cl114@rice.edu; zg20@rice.edu;
   dchen@illinois.edu; yingyan.lin@rice.edu
CR [Anonymous], 2019, P ADV NEUR INF PROC
   Chen D., 2005, TECHCON, V5
   Chen DM, 2010, IEEE T VLSI SYST, V18, P564, DOI 10.1109/TVLSI.2009.2013353
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Google Inc, EDG TPU
   Google Inc, PIX PHON 2 40
   Google Inc, TENS LIT
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu J., 2019, ACCURACY MEETS POWER
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon Hyoukjun, 2018, MAESTRO OPEN SOURCE
   Liang Y, 2012, J ELECTR COMPUT ENG, V2012, DOI 10.1155/2012/649057
   Lin YY, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P17, DOI 10.1109/SiPS.2016.11
   Lin YC, 2018, 24TH ACM SYMPOSIUM ON VIRTUAL REALITY SOFTWARE AND TECHNOLOGY (VRST 2018), DOI 10.1145/3281505.3284396
   Lin Y, 2017, IEEE INT CONF COMMUN, P782
   Liu SC, 2018, MOBISYS'18: PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P389, DOI 10.1145/3210240.3210337
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   NVIDIA Inc, NVIDIA JETS TX2
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen J., 34 AAAI C INT
   Su Liu, 2011, Proceedings of the 2011 Symposium on Application Accelerators in High-Performance Computing (SAAHPC 2011), P1, DOI 10.1109/SAAHPC.2011.22
   Venkatesan R, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942127
   Wang JS, 2018, I C FIELD PROG LOGIC, P163, DOI 10.1109/FPL.2018.00035
   Wang Y., 2018, NEURIPS WORKSH
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wang Yue, 2019, ARXIV190704523
   Wu JR, 2018, PR MACH LEARN RES, V80
   Xilinx Inc, AVN ULTRA96
   Xinlinx, VIVADO HIGH LEVEL SY
   Xiong W, 2017, INT CONF ACOUST SPEE, P5255, DOI 10.1109/ICASSP.2017.7953159
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
   Zhang XF, 2017, I C FIELD PROG LOGIC
   Zhang Xiaofan, 2019, ARXIV190909709
   Zhuge CH, 2018, PR GR LAK SYMP VLSI, P123, DOI 10.1145/3194554.3194597
   Zisserman A., 2014, 14091556 ARXIV
NR 45
TC 42
Z9 44
U1 1
U2 7
PY 2020
BP 40
EP 50
DI 10.1145/3373087.3375306
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Fan, SY
   Wang, ZW
   Xu, WZ
   Hou, R
   Meng, D
   Zhang, MZ
AF Fan, Shengyu
   Wang, Zhiwei
   Xu, Weizhi
   Hou, Rui
   Meng, Dan
   Zhang, Mingzhe
GP IEEE
TI TensorFHE: Achieving Practical Computation on Encrypted Data Using GPGPU
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
ID HOMOMORPHIC ENCRYPTION; ALGORITHM
AB In the cloud computing era, privacy protection is becoming pervasive in a broad range of applications (e.g., machine learning, data mining, etc). Fully Homomorphic Encryption (FHE) is considered the perfect solution as it enables privacy-preserved computation on untrusted servers. Unfortunately, the prohibitive performance overhead blocks the wide adoption of FHE (about 10, 000x slower than the normal computation). As heterogeneous architectures have gained remarkable success in several fields, achieving high performance for FHE with specifically designed accelerators seems to be a natural choice. Until now, most FHE accelerators have focused on efficiently implementing one FHE operation at a time based on ASIC and with significantly higher performance than GPU and FPGA. However, recent state-of-the-art FHE accelerators rely on an expensive and large on-chip storage and a high-end manufacturing process (i.e., 7nm), which increase the cost of FHE adoption.
   In this paper, we propose TensorFHE, an FHE acceleration solution based on GPGPU for real applications on encrypted data. TensorFHE utilizes Tensor Core Units (TCUs) to boost the computation of Number Theoretic Transform (NTT), which is the part of FHE with highest time-cost. Moreover, TensorFHE focuses on performing as many FHE operations as possible in a certain time period rather than reducing the latency of one operation. Based on such an idea, TensorFHE introduces operation-level batching to fully utilize the data parallelism in GPGPU. We experimentally prove that it is possible to achieve comparable performance with GPGPU as with state-of-the-art ASIC accelerators. TensorFHE performs 913 KOPS and 88 KOPS for NTT and HMULT (key FHE kernels) within NVIDIA A100 GPGPU, which is 2.61x faster than state-of-the-art FHE implementation on GPGPU; Moreover, TensorFHE provides comparable performance to the ASIC FHE accelerators, which makes it even 2.9x faster than the F1+ with a specific workload. Such a pure software acceleration based on commercial hardware with high performance can open up usage of state-of-the-art FHE algorithms for a broad set of applications in real systems.
C1 [Fan, Shengyu; Wang, Zhiwei; Hou, Rui; Meng, Dan; Zhang, Mingzhe] Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
   [Wang, Zhiwei; Hou, Rui; Meng, Dan] Univ Chinese Acad Sci, Sch Cyber Secur, Beijing, Peoples R China.
   [Fan, Shengyu; Xu, Weizhi] Shandong Normal Univ, Sch Informat Sci & Engn, Jinan, Peoples R China.
RP Fan, SY (corresponding author), Chinese Acad Sci, Inst Informat Engn, State Key Lab Informat Secur, Beijing, Peoples R China.
EM damionfan@163.com; wangzhiwei@iie.ac.cn; xuweizhi@sdnu.edu.cn;
   hourui@iie.ac.cn; mengdan@iie.ac.cn; zhangmingzhe@iie.ac.cn
CR Al Badawi Ahmad, 2018, 2018 IEEE International Conference on Service Operations and Logistics, and Informatics (SOLI), P26, DOI 10.1109/SOLI.2018.8476725
   Al Badawi A., 2018, FUTURE INFORM COMMUN, P666
   Al Badawi A., 2018, IACR T CRYPTOGRAPHIC, V2018, P143
   Al Badawi A, 2020, IEEE ACCESS, V8, P226544, DOI 10.1109/ACCESS.2020.3045465
   Bajard Jean-Claude, 2017, Selected Areas in Cryptography - SAC 2016. 23rd International Conference. Revised Selected Papers: LNCS 10532, P423, DOI 10.1007/978-3-319-69453-5_23
   Brakerski Zvika, 2014, ACM Transactions on Computation Theory, V6, DOI 10.1145/2633600
   Brunelli C, 2009, IEEE WRK SIG PRO SYS, P57, DOI 10.1109/SIPS.2009.5336225
   Cao X., 2013, CRYPTOLOGY EPRINT AR
   Cao XL, 2014, LECT NOTES COMPUT SC, V8438, P169, DOI 10.1007/978-3-662-44774-1_14
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen H, 2018, LECT NOTES COMPUT SC, V10820, P315, DOI 10.1007/978-3-319-78381-9_12
   Chen X., 2022, IACR T CRYPTOGRAPH H, V2022, P94
   Cheon J. H., 2018, IACR CRYPTOLOGY EPRI, V2018, P1073
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   COCHRAN WT, 1967, PR INST ELECTR ELECT, V55, P1664, DOI 10.1109/PROC.1967.5957
   COOLEY JW, 1965, MATH COMPUT, V19, P297, DOI 10.2307/2003354
   Cousins DB, 2017, IEEE T EMERG TOP COM, V5, P193, DOI 10.1109/TETC.2016.2619669
   Couso D., 2014, IEEE HIGH PERF EXTR, P1
   Dai W., 2016, LNCS, V9540, P169, DOI [10.1007/978-3-319-29172-71, DOI 10.1007/978-3-319-29172-711]
   Dong J., 2016, THESIS WORCESTER POL
   Durrani S, 2021, INT CONFER PARA, P345, DOI 10.1109/PACT52795.2021.00032
   Erabelli S., 2020, THESIS MIT
   Fan Junfeng, 2012, CRYPTOLOGY EPRINT AR
   Feng BY, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476157
   Guo C, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00020
   GUPTA A, 1990, IEEE T ACOUST SPEECH, V38, P553, DOI 10.1109/29.106875
   Han K, 2020, LECT NOTES COMPUT SC, V12006, P364, DOI 10.1007/978-3-030-40186-3_16
   Han K, 2019, AAAI CONF ARTIF INTE, P9466
   Jia Z, 2019, Arxiv, DOI arXiv:1903.07486
   Jung Hee Cheon, 2019, Selected Areas in Cryptography - SAC 2018. 25th International Conference. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11349), P347, DOI 10.1007/978-3-030-10970-7_16
   Jung W., 2021, IACR T CRYPTOGRAPH H, V2021, P114, DOI DOI 10.46586/TCHES.V2021.I4.114
   Khairy M, 2020, ANN I S COM, P473, DOI 10.1109/ISCA45697.2020.00047
   Kim J, 2022, Arxiv, DOI arXiv:2205.00922
   Kim M, 2015, BMC MED INFORM DECIS, V15, DOI 10.1186/1472-6947-15-S5-S3
   Kim S, 2022, CONF PROC INT SYMP C, P711, DOI 10.1145/3470496.3527415
   Kim S, 2020, I S WORKL CHAR PROC, P264, DOI 10.1109/IISWC50251.2020.00033
   Knezevic M, 2010, IEEE T COMPUT, V59, P1715, DOI 10.1109/TC.2010.93
   Konečny J, 2015, Arxiv, DOI arXiv:1511.03575
   Lee E., 2022, INT C MACHINE LEARNI
   Lee JW, 2022, IEEE ACCESS, V10, P30039, DOI 10.1109/ACCESS.2022.3159694
   Longa P, 2016, LECT NOTES COMPUT SC, V10052, P124, DOI 10.1007/978-3-319-48965-0_8
   Madrid P. E., 1993, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V1, P164, DOI 10.1109/92.238420
   Mert AC, 2019, 2019 22ND EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P253, DOI 10.1109/DSD.2019.00045
   Mouchet C., 2020, WAHC 2020 8 WORKSHOP
   Mukherjee T., 2016, CYCLOTOMIC POLYNOMIA
   NVIDIA, 2022, NVID NSIGHT SYST
   NVIDIA, 2022, CUTLASS 2 8
   NVIDIA, 2022, CUD 11 0
   NVIDIA, 2022, NVID A100 TENS COR G
   NVIDIA, 2017, TESL NVIDIA
   Paszke A, 2019, ADV NEUR IN, V32
   Podschwadt R, 2020, PRIVATENLP WSDM, P27
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Samardzic N., 2021, MICRO2021, P238
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Shoup V, 1995, J SYMB COMPUT, V20, P363, DOI 10.1006/jsco.1995.1055
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Wang W, 2014, IEEE INT SYMP CIRC S, P2800, DOI [10.1109/POWERCON.2014.6993776, 10.1109/ISCAS.2014.6865755]
   Weisstein E. W., 2004, FERMATS LITTLE THEOR
   Yi X, 2013, IEEE T KNOWL DATA EN, V25, P1125, DOI 10.1109/TKDE.2012.90
NR 61
TC 2
Z9 2
U1 1
U2 1
PY 2023
BP 922
EP 934
DI 10.1109/HPCA56546.2023.10071017
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kabrick, R
   Leidel, J
   Donofrio, D
AF Kabrick, Ryan
   Leidel, John
   Donofrio, David
GP IEEE
TI Toward HDL Extensions for Rapid AI/ML Accelerator Generation
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
DE StoneCutter; Chisel; HDL; AI; machine learning
AB StoneCutter, a language construct and compiler embedded in the OpenSoC System Architect family of tools, is designed to provide software architects the ability to rapidly prototype instruction set extensions and hardware accelerators. The StoneCutter compilation flow ingests high level syntax and outputs optimized and pipelined Chisel HDL for further compilation to platform-specific RTL. However, unlike other HDL approaches, StoneCutter is rooted in the notion that users define syntactic blocks that map directly to individual instruction definitions as opposed to classic finite state machines. When integrated with the adjacent System Architect design flow, StoneCutter provides a familiar, C-like language construct by which to develop the implementation for individual, programmable instructions. The LLVM-based StoneCutter compiler performs individual instruction and whole-ISA optimizations in order to generate a high performance, Chisel HDL representation of the target design. Utilizing the existing Chisel tools, users can also generate C++ cycle accurate simulation models as well as Verilog representations of the target design. As a result, the StoneCutter language and associated tooling provides a very rapid, instruction set-centric design environment for rapid development and experimentation.
   This work describes initial efforts to extend the StoneCutter infrastructure in order to encapsulate linear algebraic constructs for direct compilation into optimized AI/ML instructions. This functionality provides users and architects the ability to utilize the StoneCutter high level language constructs to develop target and domain specific AI/ML instructions using optimized linear algebraic constructs compiled directly to target-specific RTL. This enables users to create highly optimized AI/ML hardware implementations with minimal effort in traditional hardware develop flows.
C1 [Kabrick, Ryan] Tact Comp Labs, Newark, DE 19713 USA.
   [Leidel, John] Tact Comp Labs, Muenster, TX USA.
   [Donofrio, David] Tact Comp Labs, San Francisco, CA USA.
RP Kabrick, R (corresponding author), Tact Comp Labs, Newark, DE 19713 USA.
EM rkabrick@tactcomplabs.com; jleidel@tactcomplabs.com;
   ddonofrio@tactcomplabs.com
CR Bachrach J, 2012, DES AUT CON, P1212
   Ben-Kiki Oren, 2009, YAML AINT MARKUP LAN
   Conlon F., COREGEN INTERMEDIATE
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Leidel J. D., STONECUTTER LANGUAGE
   Leidel JD, 2020, 17TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2020 (CF 2020), P233, DOI 10.1145/3387902.3394029
   Leidel JD, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P308, DOI 10.1145/3310273.3323433
NR 9
TC 0
Z9 0
U1 0
U2 1
PY 2021
DI 10.1109/HPEC49654.2021.9622832
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Arora, A
   Ghosh, M
   Mehta, S
   Betz, V
   John, LK
AF Arora, Aman
   Ghosh, Moinak
   Mehta, Samidh
   Betz, Vaughn
   John, Lizy K.
TI Tensor Slices: FPGA Building Blocks For The Deep Learning Era
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; neural networks; deep learning; machine learning; hardware
   acceleration; computer architecture; tensor slice
AB FPGAs are well-suited for accelerating deep learning (DL) applications owing to the rapidly changing algorithms, network architectures and computation requirements in this field. However, the generic building blocks available on traditional FPGAs limit the acceleration that can be achieved. Many modifications to FPGA architecture have been proposed and deployed including adding specialized artificial intelligence (AI) processing engines, adding support for smaller precision math like 8-bit fixed point and IEEE half-precision (fp16) in DSP slices, adding shadow multipliers in logic blocks, etc. In this paper, we describe replacing a portion of the FPGA's programmable logic area with Tensor Slices. These slices have a systolic array of processing elements at their heart that support multiple tensor operations, multiple dynamically-selectable precisions and can be dynamically fractured into individual multipliers and MACs (multiply-and-accumulate). These slices have a local crossbar at the inputs that helps with easing the routing pressure caused by a large block on the FPGA. Adding these DL-specific coarse-grained hard blocks to FPGAs increases their compute density and makes them even better hardware accelerators for DL applications, while still keeping the vast majority of the real estate on the FPGA programmable at fine-grain.
C1 [Arora, Aman; John, Lizy K.] Univ Texas Austin, Dept Elect & Comp Engn, 2501 Speedway, Austin, TX 78712 USA.
   [Ghosh, Moinak] Indian Inst Technol Kharagpur, Dept Elect Engn, Kharagpur, W Bengal, India.
   [Mehta, Samidh] Bits Pilani KK Birla, Dept Elect & Elect Engn, Goa Campus, Mormugao 403726, Goa, India.
   [Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G8, Canada.
RP Arora, A (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, 2501 Speedway, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; moinakghosh2000@gmail.com; samidh99@gmail.com;
   vaughn@ece.utoronto.ca; ljohn@ece.utexas.edu
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Achronix, 2021, SPEEDSTER7T FPGAS
   Achronix, 2019, ACHR MACH LAERN PROC
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Arora Aman, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P23, DOI 10.1145/3431920.3439282
   Arora A, 2021, I C FIELD PROG LOGIC, P355, DOI 10.1109/FPL53798.2021.00068
   Arora A, 2020, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP49362.2020.00018
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Brosser F, 2013, I C FIELD PROG LOGIC
   Eldafrawy M, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3393668
   Flex-Logix, 2019, FLEX LOG NNMAX INF A
   Flex-Logix, 2019, FLEX LOG EFLX EFPGA
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Intel, 2019, INT AG FPGAS SOCS
   Intel, 2020, INT AG VAR PREC DSP
   Intel, 2018, BFLOAT16 HARDW NUM D
   Intel, 2020, INT STRAT 10 NX FPGA
   Langhammer Martin, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P57, DOI 10.1145/3431920.3439293
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2629579
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Nurvitadhi Eriko, 2018, FPGA 18 P 2018 ACM S, P287, DOI [10.1145/ 3174243.3174966, DOI 10.1145/3174243.3174966]
   NVIDIA, 2017, TECH REP
   Jouppi NP, 2017, Arxiv, DOI arXiv:1704.04760
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Vaswani A, 2017, ADV NEUR IN, V30
   Wikipedia, 2021, ROUND
   Wikipedia, 2021, BLOCK FLOAT POINT
   Xilinx, 2018, ACC DNNS XILL ALV AC
   Xilinx, 2021, XIL ACAP ENG ARCH MA
   Xilinx, 2018, XIL ENG THEIR APPL
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
NR 35
TC 4
Z9 4
U1 4
U2 6
PD DEC
PY 2022
VL 15
IS 4
AR 46
DI 10.1145/3529650
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Rahman, MM
   Vidyaratne, L
   Carpenter, A
   Tennant, C
   Iftekharuddin, K
AF Rahman, Md Monibor
   Vidyaratne, L.
   Carpenter, A.
   Tennant, C.
   Iftekharuddin, K.
GP IEEE
TI Uncertainty Aware Deep Learning for Fault Prediction Using Multivariate
   Time Series Signals
SO 2023 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS, IJCNN
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY JUN 18-23, 2023
CL Broadbeach, AUSTRALIA
DE Prediction; Deep learning; Monte Carlo dropout; Uncertainty
   Quantification
AB The superconducting radio-frequency cavities are a crucial component of the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. When a cavity faults, beam delivery to experimental end users is disrupted. Prediction of cavity faults prior to onset is essential to reduce operation and maintenance costs. In this work, a parallel long short-term memory (LSTM)-convolutional neural network (CNN)-based deep learning (DL) model is proposed to predict impending faults using pre-fault signals. Further, we introduce an uncertainty quantification approach using Monte Carlo dropout with the LSTM-CNN model to ascertain confidence in the prediction. The model was tested using multivariate time series signals from stable cavity operations and before faults. Initial results show that on the test dataset, the model can identify impending faults before their onset with an average 10-fold cross validation accuracy of 97.39% and a standard deviation of 0.12% using a 100-ms time window. It is also observed that the model performs better as the prediction time moves closer to the fault onset. For additional context, we compare the performance of the model with three machine-learning (ML)-based fault prediction models. Our proposed parallel LSTM-CNN-based DL method shows better performance than the ML-based methods.
C1 [Rahman, Md Monibor; Iftekharuddin, K.] Old Dominion Univ, Dept Elect & Comp Engn, Vis Lab, Norfolk, VA 23529 USA.
   [Vidyaratne, L.; Carpenter, A.; Tennant, C.] Jefferson Lab, Newport News, VA USA.
RP Rahman, MM (corresponding author), Old Dominion Univ, Dept Elect & Comp Engn, Vis Lab, Norfolk, VA 23529 USA.
CR Alpaydin E, 2021, INTRO MACHINE LEARNI, V4th
   Carvalho TP, 2019, COMPUT IND ENG, V137, DOI 10.1016/j.cie.2019.106024
   Combalia M, 2020, IEEE COMPUT SOC CONF, P3211, DOI 10.1109/CVPRW50498.2020.00380
   Gal Y., DROPOUT BAYESIAN APP, DOI [10.48550/arXiv.1506.02142, DOI 10.48550/ARXIV.1506.02142]
   Gao B., PROPERTIES SOFTMAX F, DOI [10.48550/arXiv.1704.00805, DOI 10.48550/ARXIV.1704.00805]
   Guo JW, 2021, MEASUREMENT, V173, DOI 10.1016/j.measurement.2020.108566
   Huang Y, 2019, IEEE ACCESS, V7, P139086, DOI 10.1109/ACCESS.2019.2940769
   Khalil K, 2020, IEEE T CIRCUITS-I, V67, P3880, DOI 10.1109/TCSI.2020.3010743
   Kumari L, 2022, REV ETNOGR FOLC, P5
   Lee WJ, 2019, PROC CIRP, V80, P506, DOI 10.1016/j.procir.2018.12.019
   Li HF, 2014, TRANSPORT RES C-EMER, V45, P17, DOI 10.1016/j.trc.2014.04.013
   Li S., REV TIME SERIES FORE, DOI [10.48550/arXiv.2209.10705, DOI 10.48550/ARXIV.2209.10705]
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Ling Zheng, 2019, 2019 IEEE International Conference on Energy Internet (ICEI), P537, DOI 10.1109/ICEI.2019.00101
   Lobach I., 2022, P N AM PART ACC C
   Orrù PF, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12114776
   Pham DT, 2005, P I MECH ENG B-J ENG, V219, P395, DOI 10.1243/095440505X32274
   Rahman MM, 2022, LECT NOTES COMPUT SC, V12962, P463, DOI 10.1007/978-3-031-08999-2_40
   Rescic M, 2020, NUCL INSTRUM METH A, V955, DOI 10.1016/j.nima.2019.163240
   Sak H., LONG SHORT TERM MEMO, DOI [10.48550/arXiv.1402.1128, DOI 10.48550/ARXIV.1402.1128]
   Scheinker A., ADAPTIVE LATENT SPAC, DOI [10.48550/arXiv.2105.03584, DOI 10.48550/ARXIV.2105.03584]
   Solopova A., 2019, 10 INT PART ACC C IP, DOI [10.18429/JACoW-IPAC2019- TUXXPLM2, DOI 10.18429/JAC0W-IPAC2019-TUXXPLM2]
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Vidyaratne L, 2022, FRONT ARTIF INTELL, V4, DOI 10.3389/frai.2021.718950
   Xu HL, 2021, DIGIT SIGNAL PROCESS, V117, DOI 10.1016/j.dsp.2021.103150
   Yang J, 2021, 2021 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE BIG DATA AND INTELLIGENT SYSTEMS (HPBD&IS), P291, DOI 10.1109/HPBDIS53214.2021.9658478
   Zhang SL, 2018, IEEE ACCESS, V6, P7675, DOI 10.1109/ACCESS.2017.2785763
NR 27
TC 0
Z9 0
U1 1
U2 1
PY 2023
DI 10.1109/IJCNN54540.2023.10191827
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Oehlmann, P
   Osswald, P
   Blanco, JC
   Friedrich, M
   Rietzel, D
   Witt, G
AF Oehlmann, Paul
   Osswald, Paul
   Blanco, Juan Camilo
   Friedrich, Martin
   Rietzel, Dominik
   Witt, Gerd
TI Modeling Fused Filament Fabrication using Artificial Neural Networks
SO PRODUCTION ENGINEERING-RESEARCH AND DEVELOPMENT
DT Article
DE Additive manufacturing; Fused Filament Fabrication; 3D printing;
   Artificial intelligence; Neural networks; Machine learning; Deep
   learning; Big data; Process control; Process monitoring; Signal
   processing; Industry 4; 0
AB With industries pushing towards digitalized production, adaption to expectations and increasing requirements for modern applications, has brought additive manufacturing (AM) to the forefront of Industry 4.0. In fact, AM is a main accelerator for digital production with its possibilities in structural design, such as topology optimization, production flexibility, customization, product development, to name a few. Fused Filament Fabrication (FFF) is a widespread and practical tool for rapid prototyping that also demonstrates the importance of AM technologies through its accessibility to the general public by creating cost effective desktop solutions. An increasing integration of systems in an intelligent production environment also enables the generation of large-scale data to be used for process monitoring and process control. Deep learning as a form of artificial intelligence (AI) and more specifically, a method of machine learning (ML) is ideal for handling big data. This study uses a trained artificial neural network (ANN) model as a digital shadow to predict the force within the nozzle of an FFF printer using filament speed and nozzle temperatures as input data. After the ANN model was tested using data from a theoretical model it was implemented to predict the behavior using real-time printer data. For this purpose, an FFF printer was equipped with sensors that collect real time printer data during the printing process. The ANN model reflected the kinematics of melting and flow predicted by models currently available for various speeds of printing. The model allows for a deeper understanding of the influencing process parameters which ultimately results in the determination of the optimum combination of process speed and print quality.
C1 [Oehlmann, Paul] Tech Univ Munich, Dept Mech Engn, Munich, Germany.
   [Osswald, Paul; Friedrich, Martin; Rietzel, Dominik] BMW Grp, Munich, Germany.
   [Blanco, Juan Camilo] Fused Form Corp, Bogota, Colombia.
   [Witt, Gerd] Univ Duisburg Essen, Duisburg, Germany.
RP Oehlmann, P (corresponding author), Tech Univ Munich, Dept Mech Engn, Munich, Germany.
EM paul.oehlmann@tum.de
CR Bayraktar Ö, 2017, POLYM ADVAN TECHNOL, V28, P1044, DOI 10.1002/pat.3960
   Bellini A, 2004, J MANUF SCI E-T ASME, V126, P237, DOI 10.1115/1.1688377
   Bishop C.M., 1995, NEURAL NETWORKS PATT
   Frochte J., 2019, MASCHINELLES LERNEN, DOI DOI 10.3139/9783446459977
   Go J, 2017, ADDIT MANUF, V16, P1, DOI 10.1016/j.addma.2017.03.007
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Heaton J., 2008, INTRO NEURAL NETWORK, P157
   Heller BP, 2016, ADDIT MANUF, V12, P252, DOI 10.1016/j.addma.2016.06.005
   Hull C.W., 1986, U.S. Patent, Patent No. [4575330A, 4575330]
   I. Wohlers Associates, 2019, WOHLERS REPORT 2019
   Lee, 2018, AI SUPERPOWERS CHINA
   MAZZEI C, 2019, ADDIT MANUF
   Mohri Mehryar, 2012, FDN MACHINE LEARNING
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Obst P, 2020, ADDIT MANUF, V32, DOI 10.1016/j.addma.2019.101002
   OSSWALD T, 2018, ADDIT MANUF
   Popova E, 2017, INTEGR MATER MANUF I, V6, P54, DOI 10.1007/s40192-017-0088-1
   Qi XB, 2019, ENGINEERING-PRC, V5, P721, DOI 10.1016/j.eng.2019.04.012
   Ramanath HS, 2008, J MATER SCI-MATER M, V19, P2541, DOI 10.1007/s10856-007-3203-6
   Refaeilzadeh P., 2009, ENCY DATABASE SYSTEM, P532, DOI [10.1007/978-0-387-39940-9_565, DOI 10.1007/978-0-387-39940-9_565]
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STAMMERS E, 1969, POLYM ENG SCI, V9, P49, DOI 10.1002/pen.760090108
   Turner BN, 2014, RAPID PROTOTYPING J, V20, P192, DOI 10.1108/RPJ-01-2013-0012
   Wu HX, 2017, INT J ADV MANUF TECH, V90, P2027, DOI 10.1007/s00170-016-9548-6
   Yardimci MA, 1997, SOL FREEFORM FABRIC, P689
NR 25
TC 11
Z9 11
U1 3
U2 21
PD JUN
PY 2021
VL 15
IS 3-4
BP 467
EP 478
DI 10.1007/s11740-021-01020-y
EA FEB 2021
WC Engineering, Manufacturing
DA 2023-11-11
ER

PT J
AU Whatmough, PN
   Lee, SK
   Brooks, D
   Wei, GY
AF Whatmough, Paul N.
   Lee, Sae Kyu
   Brooks, David
   Wei, Gu-Yeon
TI DNN Engine: A 28-nm Timing-Error Tolerant Sparse Deep Neural Network
   Processor for IoT Applications
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Deep neural networks (DNNs); hardware accelerators; Internet of things
   (IoT); machine learning (ML); razor; system-on-chip (SoC); timing error
   detection and correction; timing error tolerance
ID CIRCUIT
AB This paper presents a 28-nm system-on-chip (SoC) for Internet of things (IoT) applications with a programmable accelerator design that implements a powerful fully connected deep neural network (DNN) classifier. To reach the required low energy consumption, we exploit the key properties of neural network algorithms: parallelism, data reuse, small/sparse data, and noise tolerance. We map the algorithm to a very large scale integration (VLSI) architecture based around an single-instruction, multiple-data data path with hardware support to exploit data sparsity by completely eliding unnecessary computation and data movement. This approach exploits sparsity, without compromising the parallel computation. We also exploit the inherent algorithmic noise-tolerance of neural networks, by introducing circuit-level timing violation detection to allow worst case voltage guard-bands to be minimized. The resulting intermittent timing violations may result in logic errors, which conventionally need to be corrected. However, in lieu of explicit error correction, we cope with this by accentuating the noise tolerance of neural networks. The measured test chip achieves high classification accuracy (98.36% for the MNIST test set), while tolerating aggregate timing violation rates >10(-1). The accelerator achieves a minimum energy of 0.36 mu J/inference at 667 MHz; maximum throughput at 1.2 GHz and 0.57 mu J/inference; or a 10% margined operating point at 1 GHz and 0.58 mu J/inference.
C1 [Whatmough, Paul N.] Arm Res, Boston, MA 02451 USA.
   [Whatmough, Paul N.; Lee, Sae Kyu; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Sch Engn & Appl Sci, Cambridge, MA 02138 USA.
   [Lee, Sae Kyu] IBM Res, Yorktown Hts, NY 10598 USA.
RP Whatmough, PN (corresponding author), Arm Res, Boston, MA 02451 USA.
EM paul.whatmough@arm.com; saekyu.lee@ibm.com; dbrooks@eecs.harvard.edu;
   guyeon@eecs.harvard.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2010, SOLID STATE CIRCUITS
   [Anonymous], 2011 IEEE CUST INT C
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Bull David, 2010, 2010 IEEE International Solid-State Circuits Conference (ISSCC), P284, DOI 10.1109/ISSCC.2010.5433919
   Chandrakasan A.P., 1996, P 9 INT C VLSI DES, P352
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Das S, 2014, IEEE T CIRCUITS-I, V61, P2290, DOI 10.1109/TCSI.2014.2333332
   Dasika G, 2008, DES AUT CON, P894
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Esser S.K., 2015, ADV NEURAL INFORM PR, P1117
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hegde R, 2004, IEEE J SOLID-ST CIRC, V39, P388, DOI 10.1109/JSSC.2003.821775
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Kodali S, 2017, PR IEEE COMP DESIGN, P589, DOI 10.1109/ICCD.2017.102
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moons B, 2017, CONF REC ASILOMAR C, P1921, DOI 10.1109/ACSSC.2017.8335699
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Reagen B., P DES AUT C DAC
   Reagen B., 2017, SYNTHESIS LECT COMPU
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Whatmough P.N., 2015, SYMP VLSI CIRCUITS, pC98
   Whatmough PN, 2017, IEEE J SOLID-ST CIRC, V52, P1643, DOI 10.1109/JSSC.2017.2669025
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Whatmough PN, 2013, IEEE T VLSI SYST, V21, P989, DOI 10.1109/TVLSI.2012.2202930
   Whatmough PN, 2013, ISSCC DIG TECH PAP I, V56, P428, DOI 10.1109/ISSCC.2013.6487800
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang YQ, 2018, IEEE J SOLID-ST CIRC, V53, P619, DOI 10.1109/JSSC.2017.2749423
NR 39
TC 63
Z9 64
U1 1
U2 18
PD SEP
PY 2018
VL 53
IS 9
SI SI
BP 2722
EP 2731
DI 10.1109/JSSC.2018.2841824
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sharma, RK
   Gabrani, G
AF Sharma, Ravish Kumar
   Gabrani, Goldie
BE Misra, S
   Gervasi, O
   Murgante, B
   Stankova, E
   Korkhov, V
   Torre, C
   Rocha, AMAC
   Taniar, D
   Apduhan, BO
   Tarantino, E
TI Exploring Deep Learning Methods for Particle Track Reconstruction
SO 2019 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL SCIENCE AND ITS
   APPLICATIONS (ICCSA 2019)
DT Proceedings Paper
CT 19th International Conference on Computational Science and Its
   Applications (ICCSA)
CY JUN 30-JUL 04, 2019
CL St Petersburg State Univ, Saint Petersburg, RUSSIA
HO St Petersburg State Univ
DE Deep Learning; Particle Track Reconstruction; LHC; Long Short Term
   Memory
AB The fundamentals of particle are studied at CERN by smashing beams of protons inside a particle accelerator. The particle coming out of the collision fly all around the space leaving charge on the detector. The trajectory of particles coming out of collision needs to be reconstructed(from data gathered from detectors) in order to identify the particle type, and to study the properties of the particle, this process is called Particle Track Reconstruction (PTR). PTR is a challenging task in high energy physics as the rate of data generated at CERN has already reached tens of petabyte per annum. Further, with the advancement of Large Hadron Collider (LHC) to High-Luminosity Large Hadron Collider (HL-LHC) by the next decade, the data generated is expected to increase around 10 times due to increase in the rate of collision. So, there is a need for a fast, accurate and scalable algorithm for PTR. Deep Learning is a popular machine learning technique that has already shown promising results in the area of computer vision, natural language processing and modelling non-linear dependencies. In this paper, the authors present four different deep learning methods for reconstructing particle track and discuss the strength and weakness of each method by evaluating them on a simulated dataset of collision between protons in the LHC.
C1 [Sharma, Ravish Kumar; Gabrani, Goldie] BML Munjal Univ, Sch Engn & Technol, Gurugram, Haryana, India.
RP Sharma, RK (corresponding author), BML Munjal Univ, Sch Engn & Technol, Gurugram, Haryana, India.
EM ravish.sharma.15cse@bml.edu.in; goldie.gabrani@bmu.edu.in
CR Baranov D., 2017, P 26 INT S NUCL EL C
   Baranov D., 2018, ARXIV181203859CSLG
   CERN, LHCB DET
   CERN, 2018, TRACKML PART TRACK C
   Chung J., 2014, NIPS 2014 WORKSHOP D, P1
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Evans L, 2008, J INSTRUM, V3, DOI 10.1088/1748-0221/3/08/S08001
   Farrell S., 2017, 31 ANN C NEUR INF PR
   Farrell S., 2018, ARXIV181006111HEPEX
   FRUHWIRTH R, 1987, NUCL INSTRUM METH A, V262, P444, DOI 10.1016/0168-9002(87)90887-4
   Glover C., 1992, C COMP HIGH EN PHYS
   Greff K., 2015, ARXIV150304069CSNE
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Lipton Z.C., 2015, COMPUT SCI, V1506, P19
   Ng A., 2018, MACHINE LEARNING YEA, P12
   Outrunner, 2018, 2 PLACE SOLUTION
   The ATLAS Collaboration, 2008, J INSTRUM, V3, P1
   The LHCb Collaboration, 2008, J INSTRUM, V3, P2
   Tsaris A., 2017, 18 INT WORKSH ADV CO
NR 19
TC 0
Z9 0
U1 3
U2 5
PY 2019
BP 120
EP 125
DI 10.1109/ICCSA.2019.00009
WC Computer Science, Interdisciplinary Applications; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Chmielewski, L
   Weissbart, L
AF Chmielewski, Lukasz
   Weissbart, Leo
BE Zhou, J
   Ahmed, CM
   Batina, L
   Chattopadhyay, S
   Gadyatskaya, O
   Jin, C
   Lin, J
   Losiouk, E
   Luo, B
   Majumdar, S
   Maniatakos, M
   Mashima, D
   Meng, W
   Picek, S
   Shimaoka, M
   Su, C
   Wang, C
TI On Reverse Engineering Neural Network Implementation on GPU
SO APPLIED CRYPTOGRAPHY AND NETWORK SECURITY WORKSHOPS, ACNS 2021
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 19th International Conference on Applied Cryptography and Network
   Security (ACNS)
CY JUN 21-24, 2021
CL ELECTR NETWORK
DE Deep neural network; Side-channel analysis; Simple power analysis;
   Reverse engineering
AB In recent years machine learning has become increasingly mainstream across industries. Additionally, Graphical Processing Unit (GPU) accelerators are widely deployed in various neural network (NN) applications, including image recognition for autonomous vehicles and natural language processing, among others. Since training a powerful network requires expensive data collection and computing power, its design and parameters are often considered a secret intellectual property of their manufacturers. However, hardware accelerators can leak crucial information about the secret neural network designs through side-channels, like Electro-Magnetic (EM) emanations, power consumption, or timing.
   We propose and evaluate non-invasive and passive reverse engineering methods to recover NN designs deployed on GPUs through EM side-channel analysis. We employ a well-known technique of simple EM analysis and timing analysis of NN layers execution. We consider commonly used NN architectures, namely Multilayer Perceptron and Convolutional Neural Networks. We show how to recover the number of layers and neurons as well as the types of activation functions. Our experimental results are obtained on a setup that is as close as possible to a real-world device in order to properly assess the applicability and extendability of our methods.
   We analyze the NN execution of a PyTorch python framework implementation running on Nvidia Jetson Nano, a module computer embedding a Tegra X1 SoC that combines an ARM Cortex-A57 CPU and a 128-core GPU within a Maxwell architecture. Our results show the importance of side-channel protections for NN accelerators in real-world applications.
C1 [Chmielewski, Lukasz; Weissbart, Leo] Radboud Univ Nijmegen, Nijmegen, Netherlands.
   [Weissbart, Leo] Delft Univ Technol, Delft, Netherlands.
   [Chmielewski, Lukasz] Riscure BV, Delft, Netherlands.
RP Chmielewski, L (corresponding author), Radboud Univ Nijmegen, Nijmegen, Netherlands.; Chmielewski, L (corresponding author), Riscure BV, Delft, Netherlands.
EM lukaszc@cs.ru.nl; l.weissbart@cs.ru.nl
CR [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2021, NVIDIA JETSON NANOMO
   [Anonymous], 2021, NVIDIA TEGRA X1 WHIT
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Chabanne H, 2021, CAAI T INTELL TECHNO, V6, P3, DOI 10.1049/cit2.12026
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Fujiyoshi H, 2019, IATSS RES, V43, P244, DOI 10.1016/j.iatssr.2019.11.008
   Gao Y., 2018, IACR CRYPTOLOGY EPRI
   Haykin S., 2004, NEURAL NETWORKS, V2, P41, DOI DOI 10.5555/541500
   Hinton G, 2009, LEARNING MULTIPLE LA
   Jiang ZH, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P167, DOI 10.1145/3060403.3060462
   Jiang ZH, 2016, INT S HIGH PERF COMP, P394, DOI 10.1109/HPCA.2016.7446081
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kocher P. C., 1996, Advances in Cryptology - CRYPTO'96. 16th Annual International Cryptology Conference. Proceedings, P104
   Kucera M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P391, DOI 10.1145/3133956.3134079
   Lundervold AS, 2019, Z MED PHYS, V29, P102, DOI 10.1016/j.zemedi.2018.11.002
   Luo C, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P281, DOI 10.1109/ICCD.2015.7357115
   Maji S, 2021, IEEE INTERNET THINGS, V8, P12079, DOI 10.1109/JIOT.2021.3061314
   Mitchell T.M., 1997, MACH LEARN, V1
   Naghibijouybari H., 2019, IEEE T DEPEND SECURE
   Nair V., 2010, ICML, P807
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Papernot N, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P399, DOI 10.1109/EuroSP.2018.00035
   Paszke A, 2019, ADV NEUR IN, V32
   Riscure, 2018, RISC AUT NEUR NETW C
   Takatoi G, 2020, LECT NOTES COMPUT SC, V12418, P181, DOI 10.1007/978-3-030-61638-0_11
   Tariq Z, 2019, IEEE INT CONF BIG DA, P4191, DOI 10.1109/BigData47090.2019.9005638
   Teufl P, 2010, LECT NOTES COMPUT SC, V6258, P256, DOI 10.1007/978-3-642-14706-7_20
   Wei JY, 2020, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN48063.2020.00031
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xiang Y, 2020, IEEE T CIRCUITS-II, V67, P2717, DOI 10.1109/TCSII.2020.2973007
   Xu Q, 2021, ASIA S PACIF DES AUT, P449, DOI 10.1145/3394885.3431639
   Yoshida K, 2020, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS45731.2020.9180580
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
NR 35
TC 10
Z9 10
U1 0
U2 2
PY 2021
VL 12809
BP 96
EP 113
DI 10.1007/978-3-030-81645-2_7
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Mittal, S
AF Mittal, Sparsh
TI A Survey on optimized implementation of deep learning models on the
   NVIDIA Jetson platform
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Review; Embedded system; NVIDIA Jetson; Neural network; Deep learning;
   Autonomous driving; Drone; Low-power computing
ID PROCESSING-IN-MEMORY; FRAMEWORK
AB Design of hardware accelerators for neural network (NN) applications involves walking a tight rope amidst the constraints of low-power, high accuracy and throughput. NVIDIA's Jetson is a promising platform for embedded machine learning which seeks to achieve a balance between the above objectives. In this paper, we provide a survey of works that evaluate and optimize neural network applications on Jetson platform. We review both hardware and algorithmic optimizations performed for running NN algorithms on Jetson and show the real-life applications where these algorithms have been applied. We also review the works that compare Jetson with similar platforms. While the survey focuses on Jetson as an exemplar embedded system, many of the ideas and optimizations will apply just as well to existing and future embedded systems. It is widely believed that the ability to run AI algorithms on low-cost, low-power platforms will be crucial for achieving the "AI for all" vision. This survey seeks to provide a glimpse of the recent progress towards that goal.
C1 [Mittal, Sparsh] IIT Hyderabad, Hyderabad, Telangana, India.
RP Mittal, S (corresponding author), IIT Hyderabad, Hyderabad, Telangana, India.
EM sparsh@iith.ac.in
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   [Anonymous], 2018, NVIDIA JETSON AGX XA
   [Anonymous], 2018, J SYST ARCHIT
   [Anonymous], 2015, IEEE T PARALLEL DIST
   [Anonymous], 2015, ARXIV150503015
   [Anonymous], 2018, JETSON TK1 MOBILE EM
   [Anonymous], P IEEE C SMARTWORLD
   [Anonymous], 2017, IEEE INTERNET THINGS
   [Anonymous], ARXIV180507029
   [Anonymous], ARXIV180306077
   [Anonymous], P IEEE SMARTWORLD UB
   Ardi M., 2018, ARXIV181001732
   Ardiyanto I, 2017, IEEE ENG MED BIO, P1760, DOI 10.1109/EMBC.2017.8037184
   Attaran N., 2018, IEEE T CIRCUITS SY 2
   Azimi S. M., 2018, ARXIV181106318
   Badrinarayanan V, 2017, IEEE T PATTERN ANAL, V39, P2481, DOI 10.1109/TPAMI.2016.2644615
   Bechtel M. G., 2017, ARXIV171208644
   Biddulph A., 2018, ARXIV180903668
   Borghi G., 2017, P 28 IEEE INT VEH S
   Bura H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (ICCC), P17, DOI 10.1109/ICCC.2018.00010
   Cai L., 2018, ARXIV181112065
   Cao S., 2018, ARXIV181106641
   Carrio A., 2018, ARXIV180800259
   Cavigelli L, 2017, 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017), P1, DOI 10.1145/3131885.3131906
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen QW, 2018, IEEE T NEUR NET LEAR, V29, P1622, DOI 10.1109/TNNLS.2017.2676110
   Deepika N, 2017, 2017 INTERNATIONAL CONFERENCE ON ADVANCES IN COMPUTING, COMMUNICATIONS AND INFORMATICS (ICACCI), P2092, DOI 10.1109/ICACCI.2017.8126154
   Duan LY, 2018, IEEE T IMAGE PROCESS, V27, P2201, DOI 10.1109/TIP.2018.2794203
   Fridman L., 2017, ARXIV171106976
   Gamal M, 2018, SHUFFLESEG REAL TIME
   Ghazi P., 2018, ARXIV180710570
   Goyal M, 2019, IEEE J BIOMED HEALTH, V23, P1730, DOI 10.1109/JBHI.2018.2868656
   Gu SS, 2018, IEEE ASME INT C ADV, P170, DOI 10.1109/AIM.2018.8452263
   Hadidi R., 2018, ARXIV180202138
   Hartwell A., 2018, ARXIV180608641
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde G., 2018, TECS, V17, P15
   Hinton G., 2015, NIPS WORKSH, P1
   Howard A. G., 2017, ARXIV
   Ilg E, 2017, PROC CVPR IEEE, P1647, DOI 10.1109/CVPR.2017.179
   Intesa L, 2017, 2017 EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P94, DOI 10.1109/DSD.2017.89
   Jafari A, 2018, IEEE ASME INT C ADV, P1, DOI 10.1109/AIM.2018.8452311
   Jang Y, 2017, IEEE INT CONF COMP V, P1581, DOI 10.1109/ICCVW.2017.186
   Jung S, 2018, IEEE ROBOT AUTOM LET, V3, P2539, DOI 10.1109/LRA.2018.2808368
   Kang D, 2018, INT C COMP AID DES, P105
   Kang D, 2018, DES AUT TEST EUROPE, P715, DOI 10.23919/DATE.2018.8342102
   Kaster J, 2017, PROC NAECON IEEE NAT, P149, DOI 10.1109/NAECON.2017.8268760
   Kim C. E., 2018, 181203451 ARXIV
   Lai CK, 2017, J SYST ARCHITECT, V81, P83, DOI 10.1016/j.sysarc.2017.10.010
   Lee D, 2018, 2018 3RD IEEE INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION ENGINEERING (ICITE), P236, DOI 10.1109/ICITE.2018.8492605
   Lee H., 2017, ARXIV171111200
   Leroux S, 2017, KNOWL INF SYST, V52, P791, DOI 10.1007/s10115-017-1029-1
   Li J, 2018, IEEE ACCESS, V6, P68730, DOI 10.1109/ACCESS.2018.2879270
   Li Q, 2017, IEEE IND ELEC, P8405, DOI 10.1109/IECON.2017.8217476
   Lian S., 2017, DES AUT C DAC, P1
   Lin S., 2018, ARXIV181103921
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   LIU Y, 2017, ADV NEURAL INFORM PR, DOI DOI 10.1155/2017/1461520
   Luo S, 2017, CHIN AUTOM CONGR, P7091, DOI 10.1109/CAC.2017.8244056
   Madaan R, 2017, IEEE INT C INT ROBOT, P3487, DOI 10.1109/IROS.2017.8206190
   Manderson T., 2018, INT C INT ROB SYST I
   Mittal Sparsh, 2014, International Journal of Computer Aided Engineering and Technology, V6, P440, DOI 10.1504/IJCAET.2014.065419
   Mittal S., 2018, NEURAL COMPUTING APP
   Mittal S., 2018, J SYST ARCHIT
   Mittal S, 2014, TECHNICAL REPORT
   Mittal S, 2015, INT J INDIAN CULT BU, V11, P1, DOI 10.1504/IJICBM.2015.070246
   Mittal S, 2019, MACH LEARN KNOW EXTR, V1, P75, DOI 10.3390/make1010005
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1537, DOI 10.1109/TPDS.2015.2442980
   Mittal S, 2015, ACM COMPUT SURV, V48, DOI 10.1145/2856125
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Mittal S, 2014, SUSTAIN COMPUT-INFOR, V4, P33, DOI 10.1016/j.suscom.2013.11.001
   Molchanov P., 2016, 5 INT C LEARNING REP
   Montanari A, 2018, SPRBRIEF MOLEC SCI, P29, DOI 10.1007/978-3-319-74132-1_3
   Otterness N, 2017, IEEE REAL TIME, P353, DOI 10.1109/RTAS.2017.3
   Page A, 2016, IEEE INT SYMP CIRC S, P1086, DOI 10.1109/ISCAS.2016.7527433
   Pedoeem J., 2018, ARXIV181105588
   Pierre JM, 2018, CONFERENCE PROCEEDINGS OF 2018 4TH INTERNATIONAL CONFERENCE ON CONTROL, AUTOMATION AND ROBOTICS (ICCAR), P94, DOI 10.1109/ICCAR.2018.8384651
   Qi X, 2018, 2018 18TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND GRID COMPUTING (CCGRID), P641, DOI 10.1109/CCGRID.2018.00087
   Rallapalli S, 2016, IEEE T CIRC SYST VID
   Ran L., 2016, INT C ADV MOB COMP M, P342
   Reddy B, 2017, IEEE COMPUT SOC CONF, P438, DOI 10.1109/CVPRW.2017.59
   Redmon J., 2016, YOU ONLY LOOK ONCE U, DOI DOI 10.1109/CVPR.2016.91
   Regier P., 2018, INT C HUM ROB
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rouhani BD, 2016, I SYMPOS LOW POWER E, P112, DOI 10.1145/2934583.2934599
   Sa I, 2018, IEEE ROBOT AUTOM LET, V3, P588, DOI 10.1109/LRA.2017.2774979
   Sadiq S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P436, DOI 10.1109/IRI.2018.00070
   Sanket N. J., 2018, IEEE ROB AUTOM LETT
   Sarlin P.-E., 2018, P C ROB LEARN, P456
   Scrbak M, 2017, J SYST ARCHITECT, V75, P59, DOI 10.1016/j.sysarc.2016.08.001
   Shakeel A., 2017, THESIS
   Smolyanskiy N, 2017, IEEE INT C INT ROBOT, P4241, DOI 10.1109/IROS.2017.8206285
   Stanoev A., 2017, IM SYST TECHN IST 20, P1, DOI DOI 10.1109/IST.2017.8261524
   Sun Y, 2018, BIOSYST ENG, V176, P140, DOI 10.1016/j.biosystemseng.2018.10.012
   Susanto, 2017, 2017 INTERNATIONAL ELECTRONICS SYMPOSIUM ON ENGINEERING TECHNOLOGY AND APPLICATIONS (IES-ETA), P146, DOI 10.1109/ELECSYM.2017.8240393
   Tao SQ, 2018, J ROBOT, V2018, DOI 10.1155/2018/5868915
   Taylor J, 2018, TLS-TIMES LIT SUPPL, P31
   Tijtgat N, 2017, IEEE INT CONF COMP V, P2110, DOI 10.1109/ICCVW.2017.247
   Tomè D, 2016, SIGNAL PROCESS-IMAGE, V47, P482, DOI 10.1016/j.image.2016.05.007
   Duong TT, 2018, 2018 19TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P123, DOI 10.1109/SNPD.2018.8441073
   Tsai YC, 2018, INT SYMPOS VLSI DES, DOI 10.1109/ICOPS35962.2018.9575835
   Vinyals O., 2015, ADV NEURAL INFORM PR, P2692, DOI DOI 10.48550/ARXIV.1506.03134
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   Wang B. H., 2018, ARXIV181011408
   Wang C, 2017, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2017.7858304
   Wang JJ, 2018, 2018 THIRD IEEE/ACM SYMPOSIUM ON EDGE COMPUTING (SEC), P159, DOI 10.1109/SEC.2018.00019
   Wang Z., 2018, ARXIV180701726
   Xie XF, 2018, ACM T EMBED COMPUT S, V17, DOI 10.1145/3122788
   Xu X., 2018, ARXIV180900110
   Yang T, 2018, REMOTE SENS-BASEL, V10, DOI 10.3390/rs10111829
   Yazdani Reza, 2017, IEEE Micro, V37, P22, DOI 10.1109/MM.2017.15
   YOSINSKI J, 2014, ADV NEURAL INFORM PR, V27, P3320, DOI DOI 10.5555/2969033.2969197
   Zeng X, 2017, MOBISYS'17: PROCEEDINGS OF THE 15TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE SYSTEMS, APPLICATIONS, AND SERVICES, P56, DOI 10.1145/3081333.3081336
   Zhang X., 2018, HOTEDGE
   Zhang Y, 2016, IEEE T IMAGE PROCESS, V25, DOI 10.1109/TIP.2016.2549360
NR 116
TC 72
Z9 72
U1 11
U2 49
PD AUG
PY 2019
VL 97
BP 428
EP 442
DI 10.1016/j.sysarc.2019.01.011
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Mirhoseini, A
   Goldie, A
   Yazgan, M
   Jiang, JW
   Songhori, E
   Wang, S
   Lee, YJ
   Johnson, E
   Pathak, O
   Nazi, A
   Pak, J
   Tong, A
   Srinivasa, K
   Hang, WL
   Tuncer, E
   Le, QV
   Laudon, J
   Ho, RC
   Carpenter, R
   Dean, J
AF Mirhoseini, Azalia
   Goldie, Anna
   Yazgan, Mustafa
   Jiang, Joe Wenjie
   Songhori, Ebrahim
   Wang, Shen
   Lee, Young-Joon
   Johnson, Eric
   Pathak, Omkar
   Nazi, Azade
   Pak, Jiwoo
   Tong, Andy
   Srinivasa, Kavya
   Hang, William
   Tuncer, Emre
   Le, Quoc V.
   Laudon, James
   Ho, Richard
   Carpenter, Roger
   Dean, Jeff
TI A graph placement methodology for fast chip design
SO NATURE
DT Article
ID OPTIMIZATION; QUALITY
AB Machine learning tools are used to greatly accelerate chip layout design, by posing chip floorplanning as a reinforcement learning problem and using neural networks to generate high-performance chip layouts.
   Chip floorplanning is the engineering task of designing the physical layout of a computer chip. Despite five decades of research(1), chip floorplanning has defied automation, requiring months of intense effort by physical design engineers to produce manufacturable layouts. Here we present a deep reinforcement learning approach to chip floorplanning. In under six hours, our method automatically generates chip floorplans that are superior or comparable to those produced by humans in all key metrics, including power consumption, performance and chip area. To achieve this, we pose chip floorplanning as a reinforcement learning problem, and develop an edge-based graph convolutional neural network architecture capable of learning rich and transferable representations of the chip. As a result, our method utilizes past experience to become better and faster at solving new instances of the problem, allowing chip design to be performed by artificial agents with more experience than any human designer. Our method was used to design the next generation of Google's artificial intelligence (AI) accelerators, and has the potential to save thousands of hours of human effort for each new generation. Finally, we believe that more powerful AI-designed hardware will fuel advances in AI, creating a symbiotic relationship between the two fields.
C1 [Mirhoseini, Azalia; Goldie, Anna; Jiang, Joe Wenjie; Songhori, Ebrahim; Wang, Shen; Johnson, Eric; Nazi, Azade; Le, Quoc V.; Laudon, James; Dean, Jeff] Google, Brain Team, Google Res, Mountain View, CA 94043 USA.
   [Yazgan, Mustafa; Lee, Young-Joon; Pathak, Omkar; Pak, Jiwoo; Tong, Andy; Srinivasa, Kavya; Tuncer, Emre; Ho, Richard; Carpenter, Roger] Google, Google Chip Implementat & Infrastruct CI2 Team, Sunnyvale, CA USA.
   [Goldie, Anna; Hang, William] Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA.
RP Mirhoseini, A; Goldie, A (corresponding author), Google, Brain Team, Google Res, Mountain View, CA 94043 USA.; Goldie, A (corresponding author), Stanford Univ, Comp Sci Dept, Stanford, CA 94305 USA.
EM azalia@google.com; agoldie@google.com
CR Addanki Ravichandra, 2019, ADV NEURAL INFORM PR, V32, P3981
   Agnihotri A. R., 2005, P 2005 INT S PHYS DE, P230
   Ajayi T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3326334
   Alpert C., 2005, P ISPD, P200
   Alpert CJ, 1999, VLSI DES, V10, P99, DOI 10.1155/1999/93607
   Alpert CJ, 1996, APCCAS '96 - IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS '96, P298, DOI 10.1109/APCAS.1996.569275
   [Anonymous], 1998, HMETIS HYPERGRAPH PA
   [Anonymous], 2016, NEURAL COMBINATORIAL
   [Anonymous], 2015, INT C MACH LEARN ICM
   [Anonymous], 2017, ADV NEURAL INFORM PR
   [Anonymous], 2020, REPLACE SOFTWARE OPE
   [Anonymous], 2006, P 2006 IEEE ACM INT
   Aslam B, 2012, 2012 IEEE SYMPOSIUM ON COMPUTERS AND COMMUNICATIONS (ISCC), P423, DOI 10.1109/ISCC.2012.6249333
   Barrett T, P AAAI C ART INT 202, V34, P3243
   Brenner U, 2008, IEEE T COMPUT AID D, V27, P1607, DOI 10.1109/TCAD.2008.927674
   Breuer Melvin A., 1977, PROC 14 DESIGN AUTOM, P284
   Caldwell A. E., 2000, Proceedings ASP-DAC 2000. Asia and South Pacific Design Automation Conference 2000 with EDA TechnoFair 2000. (Cat. No.00EX389), P661, DOI 10.1109/ASPDAC.2000.835182
   Caldwell AE, 1999, IEEE T COMPUT AID D, V18, P1265, DOI 10.1109/43.784119
   Chen HY, 2003, DES AUT CON, P794
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P1228, DOI 10.1109/TCAD.2008.923063
   Cheng CK, 2019, IEEE T COMPUT AID D, V38, P1717, DOI 10.1109/TCAD.2018.2859220
   CHENG CK, 1984, IEEE T COMPUT AID D, V3, P218, DOI 10.1109/TCAD.1984.1270078
   Cherniak C, 2004, P NATL ACAD SCI USA, V101, P1081, DOI 10.1073/pnas.0305212101
   DUNLOP AE, 1985, IEEE T COMPUT AID D, V4, P92, DOI 10.1109/TCAD.1985.1270101
   Fiduccia C., 1982, P 19 DES AUT C JUN, P175, DOI DOI 10.1109/DAC.1982.1585498
   Fogaça M, 2020, INTEGRATION, V74, P32, DOI 10.1016/j.vlsi.2020.03.007
   Fogaça M, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P569, DOI 10.1145/3287624.3287676
   Hu B, 2005, IEEE T COMPUT AID D, V24, P1188, DOI 10.1109/TCAD.2005.850802
   Huang YH, 2019, DES AUT TEST EUROPE, P180, DOI [10.23919/DATE.2019.8715126, 10.23919/date.2019.8715126]
   Kahng A. B., 1998, P 1998 INT S PHYS DE, P190, DOI [10.1145/274535.274563, DOI 10.1145/274535.274563]
   Kahng A. B., 2003, P 2003 INT WORKSH SY, DOI [10.1145/639929.639942, DOI 10.1145/639929.639942]
   Kahng A. B., 2006, P 2006 INT WORKSH SY, DOI [10.1145/1117278.1117282, DOI 10.1145/1117278.1117282]
   Kahng AB, 2005, IEEE IC CAD, P891, DOI 10.1109/ICCAD.2005.1560188
   Kahng AB, 2004, ICCAD-2004: INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, IEEE/ACM DIGEST OF TECHNICAL PAPERS, P565, DOI 10.1109/ICCAD.2004.1382641
   Kahng AB, 2005, IEEE T COMPUT AID D, V24, P734, DOI 10.1109/TCAD.2005.846366
   Kahng AB, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P68, DOI 10.1145/3177540.3177554
   Kahng AB, 2018, DES AUT CON, DOI 10.1145/3195970.3199854
   Kim MC, 2012, DES AUT CON, P747
   Kim MC, 2012, ISPD 12: PROCEEDINGS OF THE 2012 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P193
   Kim MC, 2012, IEEE T COMPUT AID D, V31, P50, DOI 10.1109/TCAD.2011.2170567
   Kipf T., 2017, P ICLR, P1, DOI DOI 10.48550/ARXIV.1609.02907
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Langford J., 2008, ADV NEURAL INFORM PR, P817
   Lin T, 2013, ICCAD-IEEE ACM INT, P357, DOI 10.1109/ICCAD.2013.6691143
   Lin Y, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013302
   Lu JW, 2016, PROCEEDINGS OF THE 2016 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'16), P11, DOI 10.1145/2872334.2872361
   Lu JW, 2015, IEEE T COMPUT AID D, V34, P685, DOI 10.1109/TCAD.2015.2391263
   Lu JW, 2015, ACM T DES AUTOMAT EL, V20, DOI 10.1145/2699873
   Luo T., P AS S PAC DES AUT C, P346
   Markov IL, 2015, P IEEE, V103, P1985, DOI 10.1109/JPROC.2015.2478963
   Medlock J, 2009, SCIENCE, V325, P1705, DOI 10.1126/science.1175570
   Mirhoseini A., 2018, ICLR
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   Naylor W. C., 2001, US Patent, Patent No. [6,301,693, 6301693]
   Nazi A., 2019, INT C LEARN REPR WOR
   Obermeier B., 2005, P ACM IEEE INT S PHY, P242, DOI DOI 10.1145/1055137.1055190
   Paliwal A., 2020, P INT C LEARN REPR
   Roy JA, 2007, INTEGR CIRCUIT SYST, P97, DOI 10.1007/978-0-387-68739-1_5
   Sarrafzadeh Majid, 2003, MODERN PLACEMENT TEC, P57
   Schulman J., 2017, PROXIMAL POLICY OPTI
   Sechen C., 1986, 23rd ACM/IEEE Design Automation Conference. Proceedings 1986 (Cat. No.86CH2288-9), P432, DOI 10.1145/318013.318083
   SHAHOOKAR K, 1991, COMPUT SURV, V23, P143, DOI 10.1145/103724.103725
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Spindler P, 2008, IEEE T COMPUT AID D, V27, P1398, DOI 10.1109/TCAD.2008.925783
   Tang ML, 2007, IEEE T SYST MAN CY B, V37, P62, DOI 10.1109/TSMCB.2006.883268
   Tsay R.-S., 1988, P 25 ACM IEEE DES AU, P318
   Usunier Nicolas, 2017, P INT C LEARN REPR I
   Viswanathan N, 2007, DES AUT CON, P453, DOI 10.1109/DAC.2007.375208
   Viswanathan N, 2007, INTEGR CIRCUIT SYST, P193, DOI 10.1007/978-0-387-68739-1_8
   [谢志鹏 Xie Zhipeng], 2018, [高分子通报, Polymer Bulletin], P1
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
   Zhang M., 2018, NEURIPS, P5171
   Zhou Y., 2021, TRANSFERABLE GRAPH O
   Zhou Y., 2019, GDP GEN DEVICE PLACE
   Zoph B., 2017, P INT C LEARN REPR
NR 76
TC 140
Z9 141
U1 34
U2 136
PD JUN 10
PY 2021
VL 594
IS 7862
BP 207
EP +
DI 10.1038/s41586-021-03544-w
WC Multidisciplinary Sciences
HC Y
HP N
DA 2023-11-11
ER

PT J
AU Zemouri, R
   Devalland, C
   Valmary-Degano, S
   Zerhouni, N
AF Zemouri, Ryad
   Devalland, Christine
   Valmary-Degano, Severine
   Zerhouni, Noureddine
TI Neural network: A future in pathology?
SO ANNALES DE PATHOLOGIE
DT Review
DE Artificial network; Artificial neural networks; Digital pathology;
   Computer-assisted diagnosis
ID DIGITAL PATHOLOGY; IMAGE-ANALYSIS; DEEP; DIAGNOSIS
AB Artificial Intelligence, in particular deep neural networks are the most used machine learning technics in the biomedical field. Artificial neural networks are inspired by the biological neurons; they are interconnected and follow mathematical models. Two phases are required: a learning and a using phase. The two main applications are classification and regression Computer tools such as GPU computational accelerators or some development tools such as MATLAB libraries are used. Their application field is vast and allows the management of big data in genomics and molecular biology as well as the automated analysis of histological slides. The Whole Slide Image scanner can acquire and store slides in the form of digital images. This scanning associated with deep learning algorithms allows automatic recognition of lesions through the automatic recognition of regions of interest previously validated by the pathologist. These computer aided diagnosis techniques are tested in particular in mammary pathology and dermatopathology. They will allow an efficient and a more comprehensive vision, and will provide diagnosis assistance in pathology by correlating several biomedical data such as clinical, radiological and molecular biology data. (C) 2019 Elsevier Masson SAS. All rights reserved.
C1 [Zemouri, Ryad] HESAM Univ, CEDRIC, Lab Conservatoire Natl Arts & Metiers CNAM, 292 Rue St Martin, F-750141 Paris 03, France.
   [Devalland, Christine] Hop Nord Franche Comte, Serv Anat & Cytol Pathol, 100 Route Moval, F-90400 Trevenans, France.
   [Valmary-Degano, Severine] CHU Grenoble Alpes, Serv Anat & Cytol Pathol, TSA10217, F-38043 Grenoble, France.
   [Zerhouni, Noureddine] Univ Bourgogne Franche Comte, CNR, ENSMM, FEMTO ST Inst, F-25000 Besancon, France.
RP Zemouri, R (corresponding author), HESAM Univ, CEDRIC, Lab Conservatoire Natl Arts & Metiers CNAM, 292 Rue St Martin, F-750141 Paris 03, France.
EM ryad.zemouri@cnam.fraa; Christine.devalland@hnfc.fr;
   svalmarydegano@chu-grenoble.fr; zerhouni@ens2m.fr
CR Angermueller C, 2016, MOL SYST BIOL, V12, DOI 10.15252/msb.20156651
   Cao CS, 2018, GENOM PROTEOM BIOINF, V16, P17, DOI 10.1016/j.gpb.2017.07.003
   Cruz-Roa A, 2017, SCI REP-UK, V7, DOI 10.1038/srep46450
   Devalland C, 2017, VIRCHOWS ARCH EUR J, V471, P1, DOI [10.1007/s00428-017-2205-0, DOI 10.1007/S00428-017-2205-0]
   Feng YQ, 2018, INT J COMPUT ASS RAD, V13, P179, DOI 10.1007/s11548-017-1663-9
   Grabe N, 2018, PATHOLOGE, V39, P539, DOI 10.1007/s00292-018-0540-9
   Granter SR, 2017, ARCH PATHOL LAB MED, V141, P624, DOI 10.5858/arpa.2017-0023-ED
   Hamilton PW, 2014, METHODS, V70, P59, DOI 10.1016/j.ymeth.2014.06.015
   Henriet J, 2016, ANN DERMATOL VENER, V143, pS240, DOI [10.1016/j.annder.2016.09.325, DOI 10.1016/J.ANNDER.2016.09.325]
   Janowczyk Andrew, 2016, J Pathol Inform, V7, P29, DOI 10.4103/2153-3539.186902
   Jones W, 2017, EMERG TOP LIFE SCI, V1, P257, DOI 10.1042/ETLS20160025
   Komura D, 2018, COMPUT STRUCT BIOTEC, V16, P34, DOI 10.1016/j.csbj.2018.01.001
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Madabhushi A, 2016, MED IMAGE ANAL, V33, P170, DOI 10.1016/j.media.2016.06.037
   Mahmud M, 2018, IEEE T NEUR NET LEAR, V29, P2063, DOI 10.1109/TNNLS.2018.2790388
   Min S, 2017, BRIEF BIOINFORM, V18, P851, DOI 10.1093/bib/bbw068
   Olsen Thomas George, 2018, J Pathol Inform, V9, P32, DOI 10.4103/jpi.jpi_31_18
   Ravì D, 2017, IEEE J BIOMED HEALTH, V21, P4, DOI 10.1109/JBHI.2016.2636665
   Saha M, 2018, COMPUT MED IMAG GRAP, V64, P29, DOI 10.1016/j.compmedimag.2017.12.001
   Saha M, 2016, TISSUE CELL, V48, P461, DOI 10.1016/j.tice.2016.07.006
   Sheikhzadeh F, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0190783
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Steiner DF, 2018, AM J SURG PATHOL, V42, P1636, DOI 10.1097/PAS.0000000000001151
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Turkki Riku, 2016, J Pathol Inform, V7, P38, DOI 10.4103/2153-3539.189703
   Vandenberghe ME, 2017, SCI REP-UK, V7, DOI 10.1038/srep45938
   Veta M, 2016, PLOS ONE, V11, DOI 10.1371/journal.pone.0161286
   Xu J, 2016, NEUROCOMPUTING, V191, P214, DOI 10.1016/j.neucom.2016.01.034
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zemouri R., 2018, IFAC PAPERSONLINE, V51, P98, DOI [DOI 10.1016/j.ifacol.2018.11.660, 10.1016/j.ifacol.2018.11.660]
NR 30
TC 16
Z9 16
U1 1
U2 11
PD APR
PY 2019
VL 39
IS 2
BP 119
EP 129
DI 10.1016/j.annpat.2019.01.004
WC Pathology
DA 2023-11-11
ER

PT J
AU Jain, S
   Ankit, A
   Chakraborty, I
   Gokmen, T
   Rasch, M
   Haensch, W
   Roy, K
   Raghunathan, A
AF Jain, S.
   Ankit, A.
   Chakraborty, I
   Gokmen, T.
   Rasch, M.
   Haensch, W.
   Roy, K.
   Raghunathan, A.
TI Neural network accelerator design with resistive crossbars:
   Opportunities and challenges
SO IBM JOURNAL OF RESEARCH AND DEVELOPMENT
DT Article
ID PHASE-CHANGE MEMORY; ARRAY; SCALE
AB Deep neural networks (DNNs) achieve best-known accuracies in many machine learning tasks involved in image, voice, and natural language processing and are being used in an ever-increasing range of applications. However, their algorithmic benefits are accompanied by extremely high computation and storage costs, sparking intense efforts in optimizing the design of computing platforms for DNNs. Today, graphics processing units (GPUs) and specialized digital CMOS accelerators represent the state-of-the-art in DNN hardware, with near-term efforts focusing on approximate computing through reduced precision. However, the ever-increasing complexities of DNNs and the data they process have fueled an active interest in alternative hardware fabrics that can deliver the next leap in efficiency. Resistive crossbars designed using emerging nonvolatile memory technologies have emerged as a promising candidate building block for future DNN hardware fabrics since they can natively execute massively parallel vector-matrix multiplications (the dominant compute kernel in DNNs) in the analog domain within the memory arrays. Leveraging in-memory computing and dense storage, resistive-crossbar-based systems cater to both the high computation and storage demands of complex DNNs and promise energy efficiency beyond current DNN accelerators by mitigating data transfer and memory bottlenecks. However, several design challenges need to be addressed to enable their adoption. For example, the overheads of peripheral circuits (analog-to-digital converters and digital-to-analog converters) and other components (scratchpad memories and on-chip interconnect) may significantly diminish the efficiency benefits at the system level. Additionally, the analog crossbar computations are intrinsically subject to noise due to a range of device- and circuit-level nonidealities, potentially leading to lower accuracy at the application level. In this article, we highlight the prospects for designing hardware accelerators for neural networks using resistive crossbars. We also underscore the key open challenges and some possible approaches to address them.
C1 [Jain, S.; Ankit, A.; Chakraborty, I; Roy, K.; Raghunathan, A.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Gokmen, T.; Rasch, M.; Haensch, W.] IBM Thomas TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Jain, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM jain130@purdue.edu; aankit@purdue.edu; ichakra@purdue.edu;
   tgokmen@us.ibm.com; malte.rasch@ibm.com; whaensch@us.ibm.com;
   kaushik@purdue.edu; raghunathan@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit A, 2017, DES AUT CON, DOI 10.1145/3061639.3062311
   Ankit A, 2017, ICCAD-IEEE ACM INT, P533, DOI 10.1109/ICCAD.2017.8203823
   [Anonymous], 2019, P ADV NEURAL INFORM
   [Anonymous], 2015, P 2015 52 ACM EDAC I
   [Anonymous], ANALOG COMPUTATION F
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], P 2015 IEEE INT EL D
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], 2019, ARXIV190602698
   [Anonymous], EFFICIENT CONVNETS A
   [Anonymous], P 53 ANN DES AUT C
   [Anonymous], P 54 ACM EDAC IEEE D
   [Anonymous], AI REVOLUTION WHY DE
   [Anonymous], 2015, 32 ICML
   [Anonymous], IEEE ACCESS
   [Anonymous], P IEDM
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen P, 2015, 2D MATER, V2, DOI 10.1088/2053-1583/2/3/034009
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gokmen T, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00745
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gu P, 2015, ASIA S PACIF DES AUT, P106, DOI 10.1109/ASPDAC.2015.7058989
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   Han Song, 2015, C NEUR INF PROC SYST
   Harlap A., 2018, PIPEDREAM FAST EFFIC
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu M, 2012, DES AUT CON, P498
   Ielmini D, 2007, INT EL DEVICES MEET, P939, DOI 10.1109/IEDM.2007.4419107
   Jain S., 2018, ARXIV180900072
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Jerry Matthew, 2017, 2017 IEEE International Electron Devices Meeting (IEDM), P621, DOI 10.1109/IEDM.2017.8268338
   Jerry M, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aad6f8
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kataeva I., 2015, 2015 INT JOINT C NEU, P1, DOI [10.1109/IJCNN.2015.7280785, DOI 10.1109/IJCNN.2015.7280785]
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Kull L, 2013, ISSCC DIG TECH PAP I, V56, P468, DOI 10.1109/ISSCC.2013.6487818
   Lee D, 2013, IEEE T VLSI SYST, V21, P1583, DOI 10.1109/TVLSI.2012.2217514
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Merced-Grafals EJ, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/36/365202
   Micikevicius P., 2017, ARXIV171003740
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Ranjan A, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317935
   Sengupta A, 2017, APPL PHYS REV, V4, DOI 10.1063/1.5012763
   Sengupta A, 2016, IEEE T BIOMED CIRC S, V10, P1152, DOI 10.1109/TBCAS.2016.2525823
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
   Wang YX, 2017, P INT COMP SOFTW APP, P85, DOI 10.1109/COMPSAC.2017.12
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Xia LX, 2016, DES AUT TEST EUROPE, P469
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
   Yan BN, 2017, ICCAD-IEEE ACM INT, P541, DOI 10.1109/ICCAD.2017.8203824
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 69
TC 12
Z9 12
U1 0
U2 11
PD NOV-DEC
PY 2019
VL 63
IS 6
AR 10
DI 10.1147/JRD.2019.2947011
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT J
AU Morijiri, K
   Mihana, T
   Kanno, K
   Naruse, M
   Uchida, A
AF Morijiri, Kensei
   Mihana, Takatomo
   Kanno, Kazutaka
   Naruse, Makoto
   Uchida, Atsushi
TI Decision making for large-scale multi-armed bandit problems using bias
   control of chaotic temporal waveforms in semiconductor lasers
SO SCIENTIFIC REPORTS
DT Article
ID SINGLE-PHOTON; OPTIMIZATION; GENERATION
AB Decision making using photonic technologies has been intensively researched for solving the multi-armed bandit problem, which is fundamental to reinforcement learning. However, these technologies are yet to be extended to large-scale multi-armed bandit problems. In this study, we conduct a numerical investigation of decision making to solve large-scale multi-armed bandit problems by controlling the biases of chaotic temporal waveforms generated in semiconductor lasers with optical feedback. We generate chaotic temporal waveforms using the semiconductor lasers, and each waveform is assigned to a slot machine (or choice) in the multi-armed bandit problem. The biases in the amplitudes of the chaotic waveforms are adjusted based on rewards using the tug-of-war method. Subsequently, the slot machine that yields the maximum-amplitude chaotic temporal waveform with bias is selected. The scaling properties of the correct decision-making process are examined by increasing the number of slot machines to 1024, and the scaling exponent of the power-law distribution is 0.97. We demonstrate that the proposed method outperforms existing software algorithms in terms of the scaling exponent. This result paves the way for photonic decision making in large-scale multi-armed bandit problems using photonic accelerators.
C1 [Morijiri, Kensei; Mihana, Takatomo; Kanno, Kazutaka; Uchida, Atsushi] Saitama Univ, Dept Informat & Comp Sci, Sakura Ku, 255 Shimo Okubo, Saitama, Saitama 3388570, Japan.
   [Naruse, Makoto] Univ Tokyo, Dept Informat Phys & Comp, Grad Sch Informat Sci & Technol, Bunkyo Ku, 7-3-1 Hongo, Tokyo 1138656, Japan.
RP Morijiri, K; Uchida, A (corresponding author), Saitama Univ, Dept Informat & Comp Sci, Sakura Ku, 255 Shimo Okubo, Saitama, Saitama 3388570, Japan.
EM kensei.1221.0926.snow@gmail.com; auchida@mail.saitama-u.ac.jp
CR Auer P, 2002, MACH LEARN, V47, P235, DOI 10.1023/A:1013689704352
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Bueno J, 2018, OPTICA, V5, P756, DOI 10.1364/OPTICA.5.000756
   Chauvet N, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-77340-3
   Chauvet N, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-48647-7
   Chen XL, 2019, J LIGHTWAVE TECHNOL, V37, P4155, DOI 10.1109/JLT.2019.2923615
   Duan ZC, 2022, IEICE NONLINEAR THEO, V13, P72, DOI 10.1587/nolta.13.72
   Han YN, 2020, PHOTONICS RES, V8, P1792, DOI 10.1364/PRJ.403319
   Homma R, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-45754-3
   Inagaki T, 2016, SCIENCE, V354, P603, DOI 10.1126/science.aah4243
   Ishihara T, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3178452
   Kanno K, 2012, PHYS REV E, V86, DOI 10.1103/PhysRevE.86.066202
   Kim SJ, 2016, PHILOSOPHIES, V1, P245, DOI 10.3390/philosophies1030245
   Kim SJ, 2015, NEW J PHYS, V17, DOI 10.1088/1367-2630/17/8/083023
   Kim SJ, 2010, BIOSYSTEMS, V101, P29, DOI 10.1016/j.biosystems.2010.04.002
   Kima SJ, 2014, IEICE NONLINEAR THEO, V5, P198, DOI 10.1587/nolta.5.198
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kuleshov V., 2016, PREPRINT
   LANG R, 1980, IEEE J QUANTUM ELECT, V16, P347, DOI 10.1109/JQE.1980.1070479
   Larger L, 2012, OPT EXPRESS, V20, P3241, DOI 10.1364/OE.20.003241
   Maeda S, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-84199-5
   Mihana T, 2020, OPT EXPRESS, V28, P40112, DOI 10.1364/OE.411140
   Mihana T, 2019, OPT EXPRESS, V27, P26989, DOI 10.1364/OE.27.026989
   Mihana T, 2018, COMPLEXITY, DOI 10.1155/2018/4318127
   Naruse M, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-29117-y
   Naruse M, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-08585-8
   Naruse M, 2016, ACS PHOTONICS, V3, P2505, DOI 10.1021/acsphotonics.6b00742
   Naruse M, 2015, SCI REP-UK, V5, DOI 10.1038/srep13253
   Oda A, 2022, IEICE NONLINEAR THEO, V13, P112, DOI 10.1587/nolta.13.112
   Ohtsubo J, 2017, SPRINGER SER OPT SCI, V111, P1, DOI 10.1007/978-3-319-56138-7
   Okada N, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/8877660
   ROBBINS H, 1952, B AM MATH SOC, V58, P527, DOI 10.1090/S0002-9904-1952-09620-8
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sutton RS., 1998
   Takano K, 2018, OPT EXPRESS, V26, P29424, DOI 10.1364/OE.26.029424
   Takeuchi S, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-58541-2
   Thompson WR, 1933, BIOMETRIKA, V25, P285, DOI 10.1093/biomet/25.3-4.285
   Uchida A., 2012, OPTICAL COMMUNICATIO, P165, DOI [10.1002/9783527640331, DOI 10.1002/9783527640331]
   Uchida A, 2008, NAT PHOTONICS, V2, P728, DOI 10.1038/nphoton.2008.227
NR 39
TC 3
Z9 3
U1 1
U2 7
PD MAY 16
PY 2022
VL 12
IS 1
AR 8073
DI 10.1038/s41598-022-12155-y
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Hall, M
   Betz, V
AF Hall, Mathew
   Betz, Vaughn
GP IEEE Comp Soc
TI From TensorFlow Graphs to LUTs and Wires: Automated Sparse and
   Physically Aware CNN Hardware Generation
SO 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2020)
DT Proceedings Paper
CT 19th International Conference on Field-Programmable Technology (ICFPT)
CY DEC 07-11, 2020
CL ELECTR NETWORK
AB We present algorithms and an architectural methodology to enable zero skipping while increasing frequency in per-layer customized data flow Convolutional Neural Network (CNN) inference accelerators for FPGAs. Data flow architectures leverage the static configurability of FPGAs to increase processing efficiency, reduce dynamic muxing, and save routing wires. While this holds out the promise of high efficiency, these architectures require a different circuit to implement every CNN, making automated exploration and implementation of the accelerator essential. Each accelerator has layer-specific subcircuits with CNN-specific parallelization parameters and CNN graph topology-based interconnection that impact fanout and routing congestion, which lower the hardware operating frequency with naive implementation strategies. To address this, we designed latency insensitive hardware templates that build a model of signal fanout and span and instantiate different structures within each compute unit to ensure a high operating frequency regardless of CNN topology and parallelism settings. We also leverage the hardware efficiency of data flow architectures to add support for zero-weight-skipping at a normalized area cost less than one half of prior work. The overall optimization tool chooses parallelism settings for each layer-specific hardware unit to balance throughput across all layers of the CNN, while respecting the FPGA device limits on available buffering space and DSP blocks. Together these optimizations enable throughput on a sparse Resnet-50 model at a batch size of 1 of 4550 images/s, which is nearly 4x the throughput of NVIDIA's fastest machine learning targeted GPU, the V100, and outperforms all prior work on FPGAs.
C1 [Hall, Mathew; Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
   [Betz, Vaughn] Vector Inst, Toronto, ON, Canada.
RP Hall, M (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
EM mathew.hall@mail.utoronto.ca; vaughn@ece.utoronto.ca
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Boutros A, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242898
   Cao SJ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P63, DOI 10.1145/3289602.3293898
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Molchanov P., 2016, 5 INT C LEARNING REP
   NVIDIA Corporation, 2019, NVIDIA TESL DEEP LEA
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Tan MX, 2019, PR MACH LEARN RES, V97
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Vincent Kevin, 2017, ICLR
   Wu D, 2019, I C FIELD PROG LOGIC, P136, DOI 10.1109/FPL.2019.00030
   Zeng W., 2019, MLPRUNE MULTILAYER P
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang M, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030295
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 23
TC 9
Z9 9
U1 1
U2 2
PY 2020
BP 56
EP 65
DI 10.1109/ICFPT51103.2020.00017
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Roy, S
   Ali, M
   Raghunathan, A
AF Roy, Sourjya
   Ali, Mustafa
   Raghunathan, Anand
TI PIM-DRAM: Accelerating Machine Learning Workloads Using Processing in
   Commodity DRAM
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Random access memory; Computer architecture; Bandwidth; Microprocessors;
   Organizations; Decoding; Voltage; Deep Neural Network (DNN) inference;
   in-memory computing; Dynamic Random Access Memory (DRAM); neural
   networks
AB Deep Neural Networks (DNNs) have transformed the field of machine learning (ML) and are widely deployed in many applications involving image, video, speech and natural language processing. The increasing compute demands of DNNs have been widely addressed through Graphics Processing Units (GPUs) and specialized accelerators. However, as model sizes grow, these von Neumann architectures require very high off-chip memory bandwidth to keep the processing elements utilized, as a majority of the data resides in the main memory. Processing in memory is actively being explored as a promising solution to the memory wall bottleneck for ML workloads. In this work, we propose a new DRAM-based processing-in-memory (PIM) multiplication primitive coupled with intra-bank accumulation to accelerate matrix vector multiply operations in ML workloads. The proposed multiplication primitive adds <1% area overhead and does not require any change to the DRAM peripherals. Subsequently, we design a DRAM-based PIM architecture (PIM-DRAM) and a data mapping scheme for executing DNNs on the proposed architecture. System evaluations performed on the AlexNet, VGG16 and ResNet18 DNNs show that the proposed architecture, mapping, and data flow can provide up to 19.5x speedup over an NVIDIA Titan Xp GPU, highlighting the potential of processing in memory for future generations of DNN hardware.
C1 [Roy, Sourjya; Ali, Mustafa; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Roy, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM roy48@purdue.edu; ali102@purdue.edu; raghunathan@purdue.edu
CR Ali ME, 2020, IEEE T CIRCUITS-I, V67, P155, DOI 10.1109/TCSI.2019.2945617
   [Anonymous], AI REVOLUTION WHY DE
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Hajinazar N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P329, DOI 10.1145/3445814.3446749
   Hannun A., 2014, DEEP SPEECH SCALING
   He MX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P372, DOI 10.1109/MICRO50266.2020.00040
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kim YB, 1999, INTEGRATION, V27, P179, DOI 10.1016/S0167-9260(99)00006-1
   Seshadri Vivek, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P185, DOI 10.1145/2540708.2540725
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Vogelsang T., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P363, DOI 10.1109/MICRO.2010.42
   Xin X, 2020, INT S HIGH PERF COMP, P303, DOI 10.1109/HPCA47549.2020.00033
NR 17
TC 3
Z9 3
U1 0
U2 5
PD DEC
PY 2021
VL 11
IS 4
BP 701
EP 710
DI 10.1109/JETCAS.2021.3127517
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Roy, K
   Chakraborty, I
   Ali, M
   Ankit, A
   Agrawal, A
AF Roy, Kaushik
   Chakraborty, Indranil
   Ali, Mustafa
   Ankit, Aayush
   Agrawal, Amogh
GP IEEE
TI In-Memory Computing in Emerging Memory Technologies for Machine
   Learning: An Overview
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
AB The saturating scaling trends of CMOS technology have fuelled the exploration of emerging non-volatile memory (NVM) technologies as a promising alternative for accelerating data intensive Machine Learning (ML) workloads. To that effect, researchers have explored special-purpose accelerators based on NVM crossbar primitives. NVM crossbars have high storage density and can efficiently perform massively parallel in-situ Matrix Vector Multiplication (MVM) operations, the key computation in ML workloads, helping overcome the memory bottleneck faced by von Neumann architectures. Despite the promises, analog computing nature of NVM crossbars can lead to functional errors due to device and circuit non-idealities such as parasitic resistances and device non-linearities. Moreover, NVM crossbars need high cost peripheral circuitry to be integrated in large scale systems. Hence, there is a need to study different levels of the design stack to realize the potential of this technology.
   In this paper, we present an overview of in-memory computing in NVM crossbars for ML workloads. We discuss the basic anatomy of NVM crossbars and highlight the challenges faced at the primitive level. Next, we present how the high storage density of NVM crossbars can enable spatially distributed architectures. Further, we present various modeling and evaluation tools which can effectively help us study the functionality as well as performance of NVM crossbar systems. Finally, we provide an outlook on the future research directions in this field.
C1 [Roy, Kaushik; Chakraborty, Indranil; Ali, Mustafa; Ankit, Aayush; Agrawal, Amogh] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Roy, K (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM kaushik@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Agrawal A., 2019, ARXIV190700285
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Ankit Aayush, 2019, ARXIV191211516
   [Anonymous], 2019, ARXIV190602698
   Bavandpour M, 2018, INT EL DEVICES MEET
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chakraborty Indranil, 2020, ARXIV200306902
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Fong XY, 2016, IEEE T COMPUT AID D, V35, P1, DOI 10.1109/TCAD.2015.2481793
   Guan XM, 2012, IEEE ELECTR DEVICE L, V33, P1405, DOI 10.1109/LED.2012.2210856
   Hamann HF, 2006, NAT MATER, V5, P383, DOI 10.1038/nmat1627
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jaiswal Akhilesh, 2019, IEEE TVLSI
   Jeong Y, 2018, IEEE T NANOTECHNOL, V17, P184, DOI 10.1109/TNANO.2017.2784364
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Liu BY, 2015, DES AUT CON, DOI 10.1145/2744769.2744930
   Liu BY, 2014, ICCAD-IEEE ACM INT, P63, DOI 10.1109/ICCAD.2014.7001330
   Liu CF, 2017, DES AUT CON, DOI [10.1145/3061639.3062334, 10.1109/ICCSN.2017.8230067]
   Nag A, 2018, IEEE MICRO, V38, P41, DOI 10.1109/MM.2018.053631140
   Razavi Behzad, 2017, IEEE Solid-State Circuits Magazine, V9, P9, DOI 10.1109/MSSC.2017.2712998
   Razavi Behzad, 2015, IEEE Solid-State Circuits Magazine, V7, P38, DOI 10.1109/MSSC.2015.2442372
   Roy Sourjya, 2020, ARXIV200211151
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Slonczewski JC, 1996, J MAGN MAGN MATER, V159, pL1, DOI 10.1016/0304-8853(96)00062-5
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Wang SY, 2010, J APPL PHYS, V108, DOI 10.1063/1.3518514
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yu SM, 2010, NANOTECHNOLOGY, V21, DOI 10.1088/0957-4484/21/46/465202
NR 38
TC 24
Z9 24
U1 0
U2 3
PY 2020
AR 83.1
DI 10.1109/dac18072.2020.9218505
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Vavaroutsos, P
   Oroutzoglou, I
   Masouros, D
   Soudris, D
AF Vavaroutsos, Petros
   Oroutzoglou, Ioannis
   Masouros, Dimosthenis
   Soudris, Dimitrios
GP IEEE
TI Towards making the most of NLP-based device mapping optimization for
   OpenCL kernels
SO 2022 IEEE INTERNATIONAL CONFERENCE ON OMNI-LAYER INTELLIGENT SYSTEMS
   (IEEE COINS 2022)
DT Proceedings Paper
CT IEEE International Conference on Omni-Layer Intelligent Systems (IEEE
   COINS)
CY AUG 01-03, 2022
CL Barcelona, SPAIN
DE Machine Learning; Natural Language Processing; OpenCL; Heterogeneous
   Systems
AB Nowadays, we are living in an era of extreme device heterogeneity. Despite the high variety of conventional CPU architectures, accelerator devices, such as GPUs and FPGAs, also appear in the foreground exploding the pool of available solutions to execute applications. However, choosing the appropriate device per application needs is an extremely challenging task due to the abstract relationship between hardware and software. Automatic optimization algorithms that are accurate are required to cope with the complexity and variety of current hardware and software. Optimal execution has always relied on time-consuming trial and error approaches. Machine learning (ML) and Natural Language Processing (NLP) has flourished over the last decade with research focusing on deep architectures. In this context, the use of natural language processing techniques to source code in order to conduct autotuning tasks is an emerging field of study.
   In this paper, we extend the work of Cummins et al., namely Deeptune, that tackles the problem of optimal device selection (CPU or GPU) for accelerated OpenCL kernels. We identify three major limitations of Deeptune and, based on these, we propose four different DNN models that provide enhanced contextual information of source codes. Experimental results show that our proposed methodology surpasses that of Cummins et al. work, providing up to 4% improvement in prediction accuracy.
C1 [Vavaroutsos, Petros; Oroutzoglou, Ioannis; Masouros, Dimosthenis; Soudris, Dimitrios] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
RP Vavaroutsos, P (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens, Greece.
EM petrosvav@microlab.ntua.gr; ioroutzoglou@microlab.ntua.gr;
   demo.masouros@microlab.ntua.gr; dsoudirs@microlab.ntua.gr
CR Agakov F, 2006, INT SYM CODE GENER, P295
   Agarwal R, 2014, INFORM SYST RES, V25, P443, DOI 10.1287/isre.2014.0546
   Allamanis M, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3212695
   Ashouri AH, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3197978
   Ben -Nun T., 2018, ADV NEURAL INFORM PR, P3589
   Cavazos J, 2006, ACM SIGPLAN NOTICES, V41, P229, DOI 10.1145/1167515.1167492
   Cummins C, 2016, Arxiv, DOI arXiv:1511.02490
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Grewe D, 2013, INT SYM CODE GENER, P161
   Hawkins DM, 2004, J CHEM INF COMP SCI, V44, P1, DOI 10.1021/ci0342472
   Liu YX, 2009, INT PARALL DISTRIB P, P74
   Magni A, 2014, INT CONFER PARA, P455, DOI 10.1145/2628071.2628087
   Poznanski A, 2016, PROC CVPR IEEE, P2305, DOI 10.1109/CVPR.2016.253
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Siami-Namini S, 2019, IEEE INT CONF BIG DA, P3285, DOI 10.1109/BigData47090.2019.9005997
   Vaswani A., 2017, P 31 INT C NEURAL IN
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 337
EP 342
DI 10.1109/COINS54846.2022.9855002
WC Computer Science, Artificial Intelligence; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ueyoshi, K
   Ando, K
   Orimo, K
   Ikebe, M
   Asai, T
   Motomura, M
AF Ueyoshi, Kodai
   Ando, Kota
   Orimo, Kentaro
   Ikebe, Masayuki
   Asai, Tetsuya
   Motomura, Masato
GP IEEE
TI Exploring Optimized Accelerator Design for Binarized Convolutional
   Neural Networks
SO 2017 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT International Joint Conference on Neural Networks (IJCNN)
CY MAY 14-19, 2017
CL Anchorage, AK
AB The convolutional neural network (CNN) is a state-of-the-art model that can achieve significantly high accuracy in many machine-learning tasks. Recently, for further developing the practical applications of CNNs, efficient hardware platforms for accelerating CNN have been throughly studied. A binarized neural network has been reported to minimize the multipliers, which consume a large amount of resources, with a minimal decrease in accuracy. In this study, we analyzed the optimal performance of CNN implemented on an field programmable gate array (FPGA) considering its logic resources and a memory bandwidth, using multiple types of parallelisms such as kernels, pixels, and channels both in conventional and binarized CNNs. As a result, it became clear that all the parallelisms are required for the binarized neural network to obtain the best performance of 8.38 TOPS.
C1 [Ueyoshi, Kodai; Ando, Kota; Orimo, Kentaro; Ikebe, Masayuki; Asai, Tetsuya; Motomura, Masato] Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
RP Ueyoshi, K (corresponding author), Hokkaido Univ, Grad Sch Informat Sci & Technol, Sapporo, Hokkaido 0600814, Japan.
EM ueyoshi@lalsie.ist.hokudai.ac.jp; ando@lalsie.ist.hokudai.ac.jp;
   orimo@lalsie.ist.hokudai.ac.jp; ikebe@ist.hokudai.ac.jp;
   asai@ist.hokudai.ac.jp; motomura@ist.hokudai.ac.jp
CR [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   [Anonymous], 2016, ARXIV160305279
   [Anonymous], MINIMIZING COMPUTATI
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Hiroki Nakahara H. I., 2017, 25 ACM SIGDA INT S F
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Motamedi M, 2016, ASIA S PACIF DES AUT, P575, DOI 10.1109/ASPDAC.2016.7428073
   Rahman A, 2016, DES AUT TEST EUROPE, P1393
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C., 2015, COMPUTER VISION PATT, P1
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 14
TC 0
Z9 0
U1 0
U2 3
PY 2017
BP 2510
EP 2516
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, CL
   Yu, MC
   Wang, W
   Yan, F
AF Zhang, Chengliang
   Yu, Minchen
   Wang, Wei
   Yan, Feng
GP USENIX Assoc
TI MArk: Exploiting Cloud Services for Cost-Effective, SLO-Aware Machine
   Learning Inference Serving
SO PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE
DT Proceedings Paper
CT USENIX Annual Technical Conference (ATC)
CY JUL 10-12, 2019
CL Renton, WA
AB The advances of Machine Learning (ML) have sparked a growing demand of ML-as-a-Service: developers train ML models and publish them in the cloud as online services to provide low-latency inference at scale. The key challenge of ML model serving is to meet the response-time Service-Level Objectives (SLOs) of inference workloads while minimizing the serving cost. In this paper, we tackle the dual challenge of SLO compliance and cost effectiveness with MArk (Model Ark), a general-purpose inference serving system built in Amazon Web Services (AWS). MArk employs three design choices tailor-made for inference workload. First, MArk dynamically batches requests and opportunistically serves them using expensive hardware accelerators (e.g., GPU) for improved performance-cost ratio. Second, instead of relying on feedback control scaling or over-provisioning to serve dynamic workload, which can be too slow or too expensive for inference serving, MArk employs predictive autoscaling to hide the provisioning latency at low cost. Third, given the stateless nature of inference serving, MArk exploits the flexible, yet costly serverless instances to cover the occasional load spikes that are hard to predict. We evaluated the performance of MArk using several state-of-the-art ML models trained in popular frameworks including TensorFlow, MXNet, and Keras. Compared with the premier industrial ML serving platform SageMaker, MArk reduces the serving cost up to 7:8x while achieving even better latency performance.
C1 [Zhang, Chengliang; Yu, Minchen; Wang, Wei] HKUST, Hong Kong, Peoples R China.
   [Yan, Feng] Univ Nevada, Reno, NV 89557 USA.
RP Zhang, CL (corresponding author), HKUST, Hong Kong, Peoples R China.
EM czhangbn@cse.ust.hk; myuaj@cse.ust.hk; weiwa@cse.ust.hk; fyan@unr.edu
CR Ali-Eldin A., 2012, P 3 WORKSH SCI CLOUD, P31, DOI DOI 10.1145/2287036.2287044
   Ali-Eldin A, 2012, IEEE IFIP NETW OPER, P204, DOI 10.1109/NOMS.2012.6211900
   Amazon, 2018, BUILD TRAIN DEPL MAC
   Amazon, 2018, DYN SCAL AM EC2 AUT
   Amazon, 2018, AWS AUT
   Amazon, 2018, LOAD TEST VAR AUT SC
   Amazon, 2018, CONF LAMBD FUNCT
   Amazon, 2018, TARG TRACK SCAL POL
   Aniello Leonardo, 2014, Networked Systems. Second International Conference, NETYS 2014. Revised Selected Papers. LNCS: 8593, P122, DOI 10.1007/978-3-319-09581-3_9
   [Anonymous], 2018, NEW AM EC2 SPOT PRIC
   [Anonymous], 2018, AMAZON ECS
   [Anonymous], 2018, GOOGLE KUBERNETES EN
   [Anonymous], 2017, ARXIV170707012
   [Anonymous], 2018, AMAZON EC2
   [Anonymous], 2011, CUDA EXAMPLE INTRO G
   [Anonymous], 2018, REDISML
   [Anonymous], 2018, GOOGLE CLOUD FUNCTIO
   [Anonymous], NIPS BIGLEARNING WOR
   [Anonymous], 2018, AWS LAMBDA
   ARCHIVETEAM, 2017, TWITT STREAM TRAC
   AWS, 2018, BURST PERF INST
   AWS, 2018, AM EC2 RES INST
   AWS, 2018, RIGHT SIZ PROV INST
   Awslabs, 2018, MXNET MOD SERV
   Barrett E, 2013, CONCURR COMP-PRACT E, V25, P1656, DOI 10.1002/cpe.2864
   Casale G, 2010, PERFORM EVALUATION, V67, P61, DOI 10.1016/j.peva.2009.09.003
   Chollet F., 2015, KERAS DEEP LEARNING
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Cui Y., 2018, LONG DOES AWS LAMBDA
   Cui Y., 2018, IM AFRAID YOURE THIN
   Doyle R. P., 2003, P 4 C USENIX S INTER, V5
   Fang W., 2012, 2012 IEEE 9 INT C SE, P609, DOI DOI 10.1109/SCC.2012.47
   FISCHER W, 1993, PERFORM EVALUATION, V18, P149, DOI 10.1016/0166-5316(93)90035-S
   Fox A., 2009, HOTCLOUD, V9, P12
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Google, 2018, KUB HOR SCAL
   Google, 2019, CLOUD TPU PERF GUID
   Google, 2018, GOOGL CLOUD AUT
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Han R, 2014, FUTURE GENER COMP SY, V32, P82, DOI 10.1016/j.future.2012.05.018
   Harlap A, 2017, PROCEEDINGS OF THE TWELFTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS 2017), P589, DOI 10.1145/3064176.3064182
   He K., 2015, ARXIV
   He X., 2015, P 24 INT S HIGH PERF, P207
   Hunt Patrick, 2010, P USENIX ATC
   Klein G, 2017, PROCEEDINGS OF THE 55TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2017): SYSTEM DEMONSTRATIONS, P67, DOI 10.18653/v1/P17-4012
   Lee H, 2018, PROC 12 EUR C ANTENN
   Lee Y, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P611
   LEITNER P, 2015, P IEEE ACM UT CLOUD
   Merity S, 2017, ICLR
   Microsoft, 2018, MICR AZ CLOUD COMP P
   NIKRAVESH A. Y, 2015, P IEEE INT S SOFTW E
   NVIDIA, 2018, TENSORRT
   Olston C., 2017, ARXIV171206139
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Prodan R, 2009, FUTURE GENER COMP SY, V25, P785, DOI 10.1016/j.future.2008.11.002
   Qu CH, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3148149
   Qu CH, 2016, J NETW COMPUT APPL, V65, P167, DOI 10.1016/j.jnca.2016.03.001
   RAJABI A, 2012, P IEEE MASCOTS
   Roy Nilabja, 2011, 2011 IEEE 4 INT C CL, P500, DOI DOI 10.1109/CLOUD.2011.42
   Sharma Prateek, 2015, P 10 EUR C COMP SYST, DOI 10.1109/IC4.2015.7375638
   Song BB, 2018, J SUPERCOMPUT, V74, P6554, DOI 10.1007/s11227-017-2044-4
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   TensorFlow, 2018, TENSORFLOW SERV BATC
   TU Z, 2018, P NAACL DEM
   Urgaonkar B, 2008, ACM T AUTON ADAP SYS, V3, DOI 10.1145/1342171.1342172
   WANG C, 2017, P ACM EUROSYS
   Wang W., 2018, RAFIKI MACHINE LEARN
   Xingjian S., 2015, P802
   YAN F, 2016, P IEEE ACM SC16
   YAN F, 2017, P IEEE CLOUD
   ZHANG H, 2017, P ACM SOCC
NR 72
TC 88
Z9 91
U1 0
U2 0
PY 2019
BP 1049
EP 1062
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Kurkure, U
   Vu, L
   Sivaraman, H
AF Kurkure, Uday
   Vu, Lan
   Sivaraman, Hari
BE Smari, WW
   Zinedine, K
TI Virtualized GPUs in High Performance Datacenters
SO PROCEEDINGS 2018 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING
   & SIMULATION (HPCS)
DT Proceedings Paper
CT International Conference on High Performance Computing and Simulation
   (HPCS)
CY JUL 16-20, 2018
CL orelans, FRANCE
DE GPU; High Performance Computing; vGPU; machine learning; deep learning;
   cloud computing; performance optimization; Virtualization; Virtual
   Machine; Graphics
AB Virtualization has become the foundation of high performance datacenters. The scale of high performance datacenters is similar to the scale of supercomputers used in High Performance Computing (HPC). Both involve millions of CPU cores, tens of thousands of accelerators like GPUs, FPGAs connected by high speed interconnects and different connection topologies. GPUs are essential in high performance computing because of their high throughput and energy efficiency. Many high performance computing workloads have avoided virtualization because of performance concerns. As the scale of high performance datacenter increases, the need for ease of management becomes critical. The virtualized GPUs offer new opportunities in efficient resource allocation in managing datacenters. In this paper, we present different GPU virtualization solutions and discuss its related aspects that helps GPU based applications running efficiently at scale. We also present a comprehensive performance study of virtualized GPU that addresses main considerations of running high performance applications in virtualized datacenters. We evaluate the performance of virtual GPUs from many different angles: the overhead of virtual GPUs compared to physical GPU, the impact of using container, the use of virtualized GPUs for many different types of HPC applications, the solution of mixing workloads to increase resource utilization and system consolidation, the scalability, as well as how to make the right choice of vGPU profile.
C1 [Kurkure, Uday; Vu, Lan; Sivaraman, Hari] VMware, Palo Alto, CA 94304 USA.
RP Kurkure, U (corresponding author), VMware, Palo Alto, CA 94304 USA.
EM ukurkure@vmware.com; lanv@vmware.com; hsivaraman@vmware.com
CR Agrawal B., 2009, VMWARE TECHNICAL J
   Arakelian C., 2016, BLAST EXTREME DISPLA
   Arakelian C., 2016, VMWARE TECHNICAL WHI
   Duato J., 2009, 4 WORKSH VIRT HIGH P
   Duato J., 2010, 1 WORKSH LANG COMP A
   Gupta V, 2011, P USENIX ATC
   Gupta Vishakha, 2009, P 3 ACM WORKSHOP SYS, P17, DOI DOI 10.1145/1519138.1519141
   Jaffe Dave, 2016, BIG DATA PERFORMANCE
   Krizhevsky Alex, 2009, NON TRADITIONAL REF
   Kurkure U., 12 WORKSH VIRT HIGH
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Markthub P, 2014, 2014 15TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2014), P105, DOI 10.1109/PDCAT.2014.26
   Merritt A, 2011, P VTDC 2011
   Pandey A., 2017, P 2017 INT C HIGH PE
   Pena A. J, 2014, PARALLEL COMPUTER, V40
   Shi L, 2009, INT PARALL DISTRIB P, P418
   Taylor Ann, 2003, PENN TREEBANK OVERVI
   Vu Lan, 2014, P 22 HIGH PERF COMP
   Walters John Paul, 2014, P 2014 IEEE 7 INT C
   Wang S.Y., 2015, P 14 INT C NETW, P37
   Zaremba Wojciech, 2014, ARXIV14092329
NR 21
TC 6
Z9 6
U1 0
U2 2
PY 2018
BP 887
EP 894
DI 10.1109/HPCS.2018.00142
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Martínez, J
   Vega, J
AF Martinez, Javier
   Vega, Julio
TI ROS System Facial Emotion Detection Using Machine Learning for a
   Low-Cost Robot Based on Raspberry Pi
SO ELECTRONICS
DT Article
DE ROS; low-cost; raspberry Pi; visual attention; facial emotion detection;
   human-robot interaction
ID EXPRESSION RECOGNITION
AB Facial emotion recognition (FER) is a field of research with multiple solutions in the state-of-the-art, focused on fields such as security, marketing or robotics. In the literature, several articles can be found in which algorithms are presented from different perspectives for detecting emotions. More specifically, in those emotion detection systems in the literature whose computational cores are low-cost, the results presented are usually in simulation or with quite limited real tests. This article presents a facial emotion detection system-detecting emotions such as anger, happiness, sadness or surprise-that was implemented under the Robot Operating System (ROS), Noetic version, and is based on the latest machine learning (ML) techniques proposed in the state-of-the-art. To make these techniques more efficient, and that they can be executed in real time on a low-cost board, extensive experiments were conducted in a real-world environment using a low-cost general purpose board, the Raspberry Pi 4 Model B. The final achieved FER system proposed in this article is capable of plausibly running in real time, operating at more than 13 fps, without using any external accelerator hardware, as other works (widely introduced in this article) do need in order to achieve the same purpose.
C1 [Martinez, Javier] Univ Alcala, Dept Welf Anim Res, Pza San Diego S-N, Alcala De Henares 28801, Spain.
   [Vega, Julio] Rey Juan Carlos Univ, Dept Telemat Syst & Comp, Camino Molino 5, Fuenlabrada 28942, Spain.
RP Vega, J (corresponding author), Rey Juan Carlos Univ, Dept Telemat Syst & Comp, Camino Molino 5, Fuenlabrada 28942, Spain.
EM julio.vega@urjc.es
CR Ab Wahab MN, 2021, IEEE ACCESS, V9, P134065, DOI 10.1109/ACCESS.2021.3113337
   Ambadar Z., 2010, 2010 IEEE COMPUTER S, P94, DOI DOI 10.1109/CVPRW.2010.5543262
   Babu RG, 2020, LECT NOTE DATA ENG, V44, P797, DOI 10.1007/978-3-030-37051-0_89
   Bartneck C., 2020, HUMAN ROBOT INTERACT, DOI DOI 10.1017/9781108676649
   Daher AW, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21196526
   Devaram RR, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22093366
   Ekman P., 1978, MANUAL FACIAL ACTION
   Ekman P, 1978, FACIAL ACTION CODING
   Gao Q, 2020, NEUROCOMPUTING, V390, P198, DOI 10.1016/j.neucom.2019.02.066
   Alonso IG, 2011, INTEL SYST CONTR AUT, V53, P89, DOI 10.1007/978-94-007-1491-5_3
   Happy SL, 2015, IEEE T AFFECT COMPUT, V6, P1, DOI 10.1109/TAFFC.2014.2386334
   Jeong M, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18124270
   Jiang P, 2020, IEEE SIGNAL PROC LET, V27, P1954, DOI 10.1109/LSP.2020.3031504
   Kanade T., 2000, Proceedings Fourth IEEE International Conference on Automatic Face and Gesture Recognition (Cat. No. PR00580), P46, DOI 10.1109/AFGR.2000.840611
   Kartynnik Y, 2019, Arxiv, DOI [arXiv:1907.06724, 10.48550/ARXIV.1907.06724]
   Liang A, 2017, J AM MED DIR ASSOC, V18, P871, DOI 10.1016/j.jamda.2017.05.019
   Liu LY, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21062250
   Lu LC, 2021, INNOV AGING, V5, DOI 10.1093/geroni/igab013
   Mehrabian A., 1968, COMMUN THEOR
   Miseikis J, 2020, IEEE ROBOT AUTOM LET, V5, P5339, DOI 10.1109/LRA.2020.3007462
   Mohebbi A., 2020, CURR ROBOT REP, V1, P131, DOI [10.1007/s43154-020-00015-4, DOI 10.1007/S43154-020-00015-4]
   Quiroz M, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22103749
   Rathour N, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app112210540
   Rathour N, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10111289
   Rawal N, 2022, INT J SOC ROBOT, V14, P1583, DOI 10.1007/s12369-022-00867-0
   Saeed U., 2020, P 2020 INT C ELECT I, P1, DOI 10.1109/ICEIC49074.2020.9102342
   Sajjad M, 2019, INFORM SCIENCES, V479, P416, DOI 10.1016/j.ins.2018.07.027
   Shao J, 2019, NEUROCOMPUTING, V355, P82, DOI 10.1016/j.neucom.2019.05.005
   Siam AI, 2022, COMPUT INTEL NEUROSC, V2022, DOI 10.1155/2022/8032673
   Tang Y, 2021, IEEE T IMAGE PROCESS, V30, P444, DOI 10.1109/TIP.2020.3037467
   Tekler ZD, 2022, BUILD ENVIRON, V223, DOI 10.1016/j.buildenv.2022.109472
   Tekler ZD, 2020, BUILD ENVIRON, V171, DOI 10.1016/j.buildenv.2020.106681
   Viola P., 2001, P 2001 IEEE COMP SOC, DOI 10.1109/CVPR.2001.990517
NR 33
TC 1
Z9 1
U1 3
U2 3
PD JAN
PY 2023
VL 12
IS 1
AR 90
DI 10.3390/electronics12010090
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Mondal, PK
   Sanchez, LPA
   Benedetto, E
   Shen, Y
   Guo, MY
AF Mondal, Pritom Kumar
   Aguirre Sanchez, Lizeth P.
   Benedetto, Emmanuele
   Shen, Yao
   Guo, Minyi
TI A dynamic network traffic classifier using supervised ML for a
   Docker-based SDN network
SO CONNECTION SCIENCE
DT Article
DE Quality of service; software-defined network; traffic classification;
   machine learning
AB With the rapid technological growth in the last decades, the number of devices and users has drastically increased. Software-defined networking (SDN) with machine learning (ML) has become an emerging solution for network scheduling, quality of service (QoS), resource allocations, and security. This paper focuses on the implementation of a network traffic classifier using a novel Docker-based SDN network. ML offers good performance to real-time traffic solutions without depending on well-known TCP or UDP port numbers, IP addresses, or encrypted payloads. In this paper, using three ML techniques, we first classify network flows with 3, 5, and 7 parameters giving up to 97.14% accuracy. Additionally, we present a new performance accelerator algorithm (PAA), which incorporates these three ML classifiers and accelerates the overall performance significantly. We then propose a dynamic network classifier (DNC) generated from PAA over a novel Docker-based SDN network. Finally, we propose a new controller algorithm for Ryu platforms, which integrates the DNC and classifies both TCP and UDP flows in real-time. Based on the evaluations, an improvement in latency performance has been demonstrated, where analysing a packet, controller processing time takes on an average of 10 mu s. This study will certainly serve to further research on optimising SDN and QoS.
C1 [Mondal, Pritom Kumar; Aguirre Sanchez, Lizeth P.; Benedetto, Emmanuele; Shen, Yao; Guo, Minyi] Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
   [Benedetto, Emmanuele] Politecn Milan, Milan, Italy.
RP Shen, Y (corresponding author), Shanghai Jiao Tong Univ, Dept Comp Sci & Engn, 800 Dongchuan Rd, Shanghai 200240, Peoples R China.
EM yshen@cs.sjtu.edu.cn
CR Abar T., 2020, INT J WIRELESS MOBIL, V18, DOI https://doi.org/10.1504/IJWMC.2020.104769
   Ahmed Arif, 2020, International Journal of Cloud Computing, V9, P6
   Alsaeedi M, 2019, IEEE ACCESS, V7, P107346, DOI 10.1109/ACCESS.2019.2932422
   ALTMAN NS, 1992, AM STAT, V46, P175, DOI 10.2307/2685209
   Amaral P., 2016, 2016 IEEE 24 INT C N, P1, DOI DOI 10.1109/ICNP.2016.7785327
   Bachiega, 2020, 2020 IEEE INT C SOFT
   Breiman L., 2001, RANDOM FORESTS, V45, P5, DOI 10.1023/A:1010933404324
   Bujlow T, 2015, COMPUT NETW, V76, P75, DOI 10.1016/j.comnet.2014.11.001
   BURROWS WR, 1995, J APPL METEOROL, V34, P1848, DOI 10.1175/1520-0450(1995)034<1848:CDTSAA>2.0.CO;2
   Chawla NV, 2002, J ARTIF INTELL RES, V16, P321, DOI 10.1613/jair.953
   Cisco Visual Networking Index, 2018, 11 CISCO
   CUI L, 2016, IEEE NETWORK, V30
   David B., 2020, SOFTWARE DEFINED NET
   Deri L, 2014, INT WIREL COMMUN, P617, DOI 10.1109/IWCMC.2014.6906427
   Jun Zhang, 2012, International Journal of Security and Networks, V7, P252
   Karatsiolis S, 2012, IEEE INT C BIOINF BI, P139, DOI 10.1109/BIBE.2012.6399663
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Koteeswaran, 2018, INT J INTELL SYST, V17, P467, DOI [10.1504/IJISTA.2018.095114, DOI 10.1504/IJISTA.2018.095114]
   LATAH M, 2018, IET NETW, V8
   Liu CC, 2018, I C COMM SOFTW NET, P45, DOI 10.1109/ICCSN.2018.8488219
   Liu H, 1995, PROC INT C TOOLS ART, P388, DOI 10.1109/TAI.1995.479783
   Liu Z, 2020, CONNECT SCI, V32, P333, DOI 10.1080/09540091.2019.1700911
   LOPEZ M, 2017, IEEE ACCESS, V5
   Mejuia D., 2013, REV POLIT CNICA, V32, P43
   Merkel D., 2014, LINUX J, V2014, DOI 10.5555/2600239.2600241
   Mininet, MIN INST NETW YOUR L
   Moore A, 2013, TECHNICAL REPORT
   Oliveira T.P., 2016, INT J BIG DATA INTEL, V3, DOI https://doi.org/10.1504/IJBDI.2016.073903
   Quinlan J. R., 1986, Machine Learning, V1, P81, DOI 10.1007/BF00116251
   Rezaeijo SM, 2020, 2020 6TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS), DOI 10.1109/ICSPIS51611.2020.9349605
   Wang C, 2015, 2015 11TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND SECURITY (CIS), P78, DOI 10.1109/CIS.2015.27
   Wang P, 2016, P IEEE I C SERV COMP, P760, DOI 10.1109/SCC.2016.133
   Wengang Zhou, 2011, 2011 International Conference on Computational Problem-Solving, P641, DOI 10.1109/ICCPS.2011.6092257
   Wu, 2019, INT J HIGH PERFORM C, V14, P237, DOI [10.1504/IJHPCN.2019.10022739, DOI 10.1504/IJHPCN.2019.10022739]
   Xu J., 2018, 2018 IEEE INT C SIGN, P1
   Yuan ZW, 2016, 2016 IEEE INTERNATIONAL CONFERENCE OF ONLINE ANALYSIS AND COMPUTING SCIENCE (ICOACS), P53, DOI 10.1109/ICOACS.2016.7563047
   ZHANG C, 2018, T EMERG TELECOMMUN T, V29
NR 37
TC 4
Z9 4
U1 0
U2 18
PD JUL 3
PY 2021
VL 33
IS 3
BP 693
EP 718
DI 10.1080/09540091.2020.1870437
EA JAN 2021
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Oliveira, WC
   Canesche, M
   Reis, L
   Nacif, JAM
   Ferreira, RS
AF Oliveira, Westerley C.
   Canesche, Michael
   Reis, Lucas
   Nacif, Jose Augusto M.
   Ferreira, Ricardo S.
TI Heterogeneous reconfigurable architectures for machine learning
   dataflows
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article
DE dataflow computing; FPGA accelerators; heterogeneous architectures; high
   performance computing
AB This work explores the placement and routing of machine learning applications' dataflow graphs on different heterogeneous coarse-grained reconfigurable architectures (CGRA). We analyze three different types of processing element (PE) heterogeneity, the first concerning the interconnection pattern, the second being on the kind of operations a single PE can execute, and the last concerning the PE buffer resources. This analysis aim to propose a fair reduction to the overall cost in comparison to the homogeneous CGRA architecture. We compare our results with the homogeneous case and one of the state-of-the-art tools for placement and routing (P&R). Our algorithm executed, on average, 52% faster than VPR 8.1 (Versatile Place and Route), which is an open-source academic tool designed for the FPGA placement and routing phases, reaching better mapping in 66% of cases and achieving the same results in 26% of cases. Furthermore, a heterogeneous architecture reduces the cost without losing performance in 76% of the cases considering multiplier heterogeneity. We propose a novel heterogeneous buffer architecture that minimizes the buffer resources by 56.3% for K-means dataflow patterns. We also show that a heterogeneous border chess architecture outperforms a homogeneous one. In addition, our mapping reaches optimal instances of single tree dataflows compared to classical Lee/Choi and H-trees.
C1 [Oliveira, Westerley C.; Canesche, Michael; Reis, Lucas; Ferreira, Ricardo S.] Univ Fed Vicosa, Dept Comp Sci, Vicosa, MG, Brazil.
   [Nacif, Jose Augusto M.] Univ Fed Vicosa, Inst Sci & Technol, UFV Florestal Campus, Florestal, MG, Brazil.
RP Ferreira, RS (corresponding author), Univ Fed Vicosa, Dept Informat, Campus Univ, BR-36570900 Vicosa, MG, Brazil.
EM ricardo@ufv.br
CR Abdelrahman TS, 2016, IEEE INT CONF ASAP, P176, DOI 10.1109/ASAP.2016.7760789
   Akbari O, 2020, IEEE T COMPUT AID D, V39, P2558, DOI 10.1109/TCAD.2019.2937738
   Browning, 1980, TREE MACHINE HIGHLY
   Carvalho W, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P233, DOI 10.1109/ICFPT51103.2020.00040
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Donovick C., 2019, P INT C RECONFIGURAB
   Fang Z., 2019, P INT C APPL SPEC SY
   Gobieski G., 2021, P INT S COMP ARCH IS
   Hamzeh M, 2012, DES AUT CON, P1280
   He ZH, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P233, DOI 10.1145/3373087.3375316
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Huang Y., 2013, FPGA, P171
   Jo J, 2018, IEEE J SOLID-ST CIRC, V53, P605, DOI 10.1109/JSSC.2017.2764045
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lee SK, 1996, IEEE T PARALL DISTR, V7, P493, DOI 10.1109/71.503774
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Luo Z., 2000, P INT S CIRC SYST IS
   Mei BF, 2003, LECT NOTES COMPUT SC, V2778, P61
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Nowatzki T, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243212
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Oliveira W., 2020, P 18 S SIST COMP ALT
   Park H, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P166, DOI 10.1145/1454115.1454140
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Ravet F, 2018, PR INT PIPELINE CONF
   Silva M., 2006, P INT C REC COMP FPG
   Thompson NC, 2021, IEEE SPECTRUM, V58, P50, DOI 10.1109/MSPEC.2021.9563954
   Vasilyev A, 2016, INT SYMP MICROARCH
   Walker MJP, 2019, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2019.00019
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Weng J, 2020, ANN I S COM, P268, DOI 10.1109/ISCA45697.2020.00032
   Weng J, 2019, IEEE COMPUT ARCHIT L, V18, P161, DOI 10.1109/LCA.2019.2955456
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Zhang Y., 2021, P INT S COMP ARCH IS
NR 34
TC 0
Z9 0
U1 0
U2 2
PD AUG 1
PY 2023
VL 35
IS 17
SI SI
AR e6939
DI 10.1002/cpe.6939
EA MAR 2022
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Yildirim, M
   Oguz, I
   Kaufmann, F
   Escalé, MR
   Grange, R
   Psaltis, D
   Moser, C
AF Yildirim, Mustafa
   Oguz, Ilker
   Kaufmann, Fabian
   Escale, Marc Reig
   Grange, Rachel
   Psaltis, Demetri
   Moser, Christophe
TI Nonlinear optical feature generator for machine learning
SO APL PHOTONICS
DT Article
ID SUPERCONTINUUM GENERATION; NEURAL-NETWORKS; HIGH-SPEED; PARALLEL
AB Modern machine learning models use an ever-increasing number of parameters to train (175 x 10(9) parameters for GPT-3) with large datasets to achieve better performance. Optical computing has been rediscovered as a potential solution for large-scale data processing, taking advantage of linear optical accelerators that perform operations at lower power consumption. However, to achieve efficient computing with light, it remains a challenge to create and control nonlinearity optically rather than electronically. In this study, a reservoir computing approach (RC) is investigated using a 14-mm waveguide in LiNbO3 on an insulator as an optical processor to validate the benefit of optical nonlinearity. Data are encoded on the spectrum of a femtosecond pulse, which is launched into the waveguide. The output of the waveguide is a nonlinear transform of the input, enabled by optical nonlinearities. We show experimentally that a simple digital linear classifier using the output spectrum of the waveguide increases the classification accuracy of several databases by similar to 10% compared to untransformed data. In comparison, a digital neural network (NN) with tens of thousands of parameters was required to achieve similar accuracy. With the ability to reduce the number of parameters by a factor of at least 20, an integrated optical RC approach can attain a performance on a par with a digital NN.
C1 [Yildirim, Mustafa; Oguz, Ilker; Moser, Christophe] Ecole Polytech Fed Lausanne EPFL, Lab Appl Photon Devices, Lausanne, Switzerland.
   [Kaufmann, Fabian; Grange, Rachel] Swiss Fed Inst Technol, Inst Quantum Elect, Dept Phys, Opt Nanomat Grp, Zurich, Switzerland.
   [Escale, Marc Reig] Versics AG, Auguste Piccard Hof 1,HPT Bldg, CH-8093 Zurich, Switzerland.
   [Psaltis, Demetri] Ecole Polytech Fed Lausanne EPFL, Opt Lab, Lausanne, Switzerland.
RP Yildirim, M (corresponding author), Ecole Polytech Fed Lausanne EPFL, Lab Appl Photon Devices, Lausanne, Switzerland.
EM mustafa.yidirim@epfl.ch
CR Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Dudley JM, 2006, REV MOD PHYS, V78, P1135, DOI 10.1103/RevModPhys.78.1135
   Escalé MR, 2020, APL PHOTONICS, V5, DOI 10.1063/5.0028776
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Frumker E, 2007, J OPT SOC AM B, V24, P2940, DOI 10.1364/JOSAB.24.002940
   GOODMAN JW, 1978, OPT LETT, V2, P1, DOI 10.1364/OL.2.000001
   hamamatsu, US
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Koklu M, 2021, MATH PROBL ENG, V2021, DOI 10.1155/2021/4793293
   Lichtinghagen R., 2020, HCV DATA, DOI [10.24432/C5D612, DOI 10.24432/C5D612]
   Marcucci G, 2020, PHYS REV LETT, V125, DOI 10.1103/PhysRevLett.125.093901
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Mounaix M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13059-8
   O' Neill J, 2020, Arxiv, DOI arXiv:2006.03669
   Paudel U, 2020, OPT EXPRESS, V28, P1225, DOI 10.1364/OE.379264
   Pohl D, 2021, IEEE PHOTONIC TECH L, V33, P85, DOI 10.1109/LPT.2020.3044648
   Rafayelyan M, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.041037
   Romera M, 2018, NATURE, V563, P230, DOI 10.1038/s41586-018-0632-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silva NA, 2021, NEW J PHYS, V23, DOI 10.1088/1367-2630/abda84
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Sorokina M, 2020, J PHYS-PHOTONICS, V2, DOI 10.1088/2515-7647/abb584
   Spall J, 2020, OPT LETT, V45, P5752, DOI 10.1364/OL.401675
   Sunada S, 2020, OPT EXPRESS, V28, P30349, DOI 10.1364/OE.399495
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Tegin U, 2021, NAT COMPUT SCI, V1, P542, DOI 10.1038/s43588-021-00112-0
   Van der Sande G, 2017, NANOPHOTONICS-BERLIN, V6, P561, DOI 10.1515/nanoph-2016-0132
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Wang C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08969-6
   Wang C, 2018, OPT EXPRESS, V26, P1547, DOI 10.1364/OE.26.001547
   Wright LG, 2022, NATURE, V601, P549, DOI 10.1038/s41586-021-04223-6
   Yu MJ, 2019, OPT LETT, V44, P1222, DOI 10.1364/OL.44.001222
   Zhou TY, 2022, J LIGHTWAVE TECHNOL, V40, P1308, DOI 10.1109/JLT.2022.3146131
   Zhu D, 2021, ADV OPT PHOTONICS, V13, P242, DOI 10.1364/AOP.411024
NR 36
TC 0
Z9 0
U1 0
U2 0
PD OCT 1
PY 2023
VL 8
IS 10
AR 106104
DI 10.1063/5.0158611
WC Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Neshatpour, K
   Malik, M
   Ghodrat, MA
   Sasan, A
   Homayoun, H
AF Neshatpour, Katayoun
   Malik, Maria
   Ghodrat, Mohammad Ali
   Sasan, Avesta
   Homayoun, Houman
BE Ho, H
   Ooi, BC
   Zaki, MJ
   Hu, XH
   Haas, L
   Kumar, V
   Rachuri, S
   Yu, SP
   Hsiao, MHI
   Li, J
   Luo, F
   Pyne, S
   Ogan, K
TI Energy-Efficient Acceleration of Big Data Analytics Applications Using
   FPGAs
SO PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA
DT Proceedings Paper
CT IEEE International Conference on Big Data
CY OCT 29-NOV 01, 2015
CL Santa Clara, CA
DE machine learning; hardware plus software co-design; Zynq boards;
   MapReduce; Hadoop; FPGA
AB A recent trend for big data analytics is to provide heterogeneous architectures to allow support for hardware specialization. Considering the time dedicated to create such hardware implementations, an analysis that estimates how much benefit we gain in terms of speed and energy efficiency, through offloading various functions to hardware would be necessary. This work analyzes data mining and machine learning algorithms, which are utilized extensively in big data applications in a heterogeneous CPU+FPGA platform. We select and offload the computational intensive kernels to the hardware accelerator to achieve the highest speed-up and best energy-efficiency. We use the latest Xilinx Zynq boards for implementation and result analysis. We also perform a first order comprehensive analysis of communication and computation overheads to understand how the speedup of each application contributes to its overall execution in an end-to-end Hadoop MapReduce environment. Moreover, we study how other system parameters such as the choice of CPU (big vs little) and the number of mapper slots affect the performance and power-efficiency benefits of hardware acceleration. The results show that a kernel speedup of upto x321.5 with hardware+software co-design can be achieved. This results in x2.72 speedup, 2.13x power reduction, and 15.21x energy efficiency improvement (EDP) in an end-to-end Hadoop MapReduce environment.
C1 [Neshatpour, Katayoun; Malik, Maria; Sasan, Avesta; Homayoun, Houman] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
   [Ghodrat, Mohammad Ali] Univ Calif Los Angeles, Dept Comp Sci, Los Angeles, CA 90024 USA.
RP Neshatpour, K (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
EM kneshatp@gmu.edu; mmalik9@gmu.edu; ghodrat@gmail.com; hhomayou@gmu.edu
CR [Anonymous], 2004, OSDI 2004
   [Anonymous], 2013, PRODUCT GUIDE VIVADO
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H, 2012, P INT S HIGH PERFORM, P1
   Honjo Toshimori, 2013, 2013 IEEE International Conference on Big Data, P118, DOI 10.1109/BigData.2013.6691562
   Joachims T, 1999, ADVANCES IN KERNEL METHODS, P169
   Kachris C., 2014, P ACM SIGDA INT S FP, P241
   Kontorinis V., 2014, 51 ANN DES AUT C 201
   Kontorinis V, 2012, CONF PROC INT SYMP C, P488, DOI 10.1109/ISCA.2012.6237042
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Malik M., 2015, 33 IEEE INT C COMP D
   Malik M., 2015, IEEE INT C BIG DAT I
   Narayanan R, 2006, I S WORKL CHAR PROC, P182
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   Neshatpour K, 2015, IEEE ACM INT SYMP, P1151, DOI 10.1109/CCGrid.2015.165
   Séméria L, 2001, IEEE T VLSI SYST, V9, P743, DOI 10.1109/92.974889
   Shan Y, 2010, FPGA 10, P93
   Van Craeynest K, 2012, CONF PROC INT SYMP C, P213, DOI 10.1109/ISCA.2012.6237019
   White T., 2009, HADOOP DEFINITIVE GU
   Winterstein F, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P362, DOI 10.1109/FPT.2013.6718388
NR 21
TC 30
Z9 31
U1 0
U2 7
PY 2015
BP 115
EP 123
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Konstantinou, D
   Nicopoulos, C
   Lee, J
   Sirakoulis, GC
   Dimitrakopoulos, G
AF Konstantinou, Dimitrios
   Nicopoulos, Chrysostomos
   Lee, Junghee
   Sirakoulis, Georgios Ch
   Dimitrakopoulos, Giorgos
GP IEEE
TI SmartFork: Partitioned Multicast Allocation and Switching in
   Network-on-Chip Routers
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
AB Multicast on-chip communication is encountered in various cache-coherence protocols targeting multi-core processors, and its pervasiveness is increasing due to the proliferation of machine learning accelerators. In-network handling of multicast traffic imposes additional switching-level restrictions to guarantee deadlock freedom, while it stresses the allocation efficiency of Network-on-Chip (NoC) routers. In this work, we propose a novel NoC router microarchitecture, called SmartFork, which employs a versatile and cost-efficient multicast packet replication scheme that allows the design of high-throughput and low-cost NoCs. The design is adapted to the average branch splitting observed in real-world multicast routing algorithms. Compared to state-of-the-art NoC multicast approaches, SmartFork is demonstrated to yield higher performance in terms of latency and throughput, while still offering a cost-effective implementation.
C1 [Konstantinou, Dimitrios; Sirakoulis, Georgios Ch; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, Nicosia, Cyprus.
   [Lee, Junghee] Korea Univ, Sch Cyber Secur, Seoul, South Korea.
RP Konstantinou, D (corresponding author), Democritus Univ Thrace, Elect & Comp Engn, Xanthi, Greece.
CR Abadal S, 2016, COMPUT ELECTR ENG, V51, P168, DOI 10.1016/j.compeleceng.2015.12.018
   Agarwal A, 2007, DES AUT CON, P750, DOI 10.1109/DAC.2007.375264
   [Anonymous], 2015, MICROARCHITECTURE NE
   Arteris, 2018, ART IP FLEXNOC AI PA
   Bhardwaj K., 2017, INT S NETW ON CHIP N
   Boppana R. V., 1994, Proceedings. Sixth IEEE Symposium on Parallel and Distributed Processing (Cat. No.94TH0675-9), P722, DOI 10.1109/SPDP.1994.346103
   Conway P, 2007, IEEE MICRO, V27, P10, DOI 10.1109/MM.2007.43
   Dimitrakopoulos G, 2013, IEEE T COMPUT, V62, P2001, DOI 10.1109/TC.2012.116
   Dimitrakopoulos G, 2008, PR IEEE COMP DESIGN, P664, DOI 10.1109/ICCD.2008.4751932
   Ebrahimi M, 2009, DES AUT TEST EUROPE, P1064
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Krishna T, 2011, INT SYMP MICROARCH, P71
   LIN XL, 1991, ACM COMP AR, V19, P116, DOI 10.1145/115953.115965
   Lu ZH, 2006, IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI, PROCEEDINGS, P205
   Ma S., 2012, IEEE INT S HIGH PERF, P1
   Ma S, 2012, INT S HIGH PERF COMP, P467
   Malumbres MP, 1996, EIGHTH IEEE SYMPOSIUM ON PARALLEL AND DISTRIBUTED PROCESSING, PROCEEDINGS, P186, DOI 10.1109/SPDP.1996.570332
   Martin MMK, 2003, CONF PROC INT SYMP C, P182, DOI 10.1109/ISCA.2003.1206999
   Psarras A, 2016, IEEE T COMPUT, V65, P3136, DOI 10.1109/TC.2016.2519916
   Rodrigo S, 2008, INT SYMP MICROARCH, P364, DOI 10.1109/MICRO.2008.4771805
   Samman FA, 2010, IEEE T VLSI SYST, V18, P1067, DOI 10.1109/TVLSI.2009.2019758
   Seitanidis I, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P135, DOI 10.1109/NOCS.2014.7008772
   Sivaram R., 1997, PARALLEL COMPUTER RO, P39
   Stefan RA, 2014, IEEE T COMPUT, V63, P583, DOI 10.1109/TC.2012.117
   Wang L, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P64, DOI 10.1109/NOCS.2009.5071446
   Wenmin Hu, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P363, DOI 10.1109/ASPDAC.2011.5722214
NR 26
TC 0
Z9 0
U1 0
U2 1
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chen, ZY
   Zhou, H
   Gu, J
AF Chen, Zhengyu
   Zhou, Hai
   Gu, Jie
GP ACM
TI Digital Compatible Synthesis, Placement and Implementation of
   Mixed-Signal Time-Domain Computing
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB Mixed-signal time-domain computing (TC) has recently drawn significant attention due to its high efficiency in applications such as machine learning accelerators. However, due to the nature of analog and mixed-signal design, there is a lack of a systematic flow of synthesis and place & route for time-domain circuits. This paper proposed a comprehensive design flow for TC. In the front-end, a variation-aware digital compatible synthesis flow is proposed. In the back-end, a placement technique using graph-based optimization engine is proposed to deal with the especially stringent matching requirement in TC. Simulation results show significant improvement over the prior analog placement methods. A 55nm test chip is used to demonstrate that the proposed design flow can meet the stringent timing matching target for TC with significant performance boost over conventional digital design.
C1 [Chen, Zhengyu; Zhou, Hai; Gu, Jie] Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
RP Chen, ZY (corresponding author), Northwestern Univ, Dept Elect & Comp Engn, Evanston, IL 60208 USA.
EM zhengyuchen2015@u.northwestern.edu; haizhou@northwestern.edu;
   jgu@northwestern.edu
CR Amravati A., 2018, ISSCC
   Buhler F. N., 2017, VLSI S
   Chen Z., 2019, IEEE JSSC
   Chou Pang-Yen, 2011, IEEE ICCAD
   Guo P.-N., 1999, IEEE ACM DAC
   Lin Chang-Tzu, 2002, IEEE ISCAS
   Lin J.-M., 2004, IEEE T CAD
   Lin P. H., 2008, IEEE ACM DAC
   LIU M, 2017, IEEE ICC, pNI306
   Ma Qiang, 2011, IEEE T COMPUTER AIDE
   Marin Jorge, 2018, IEEE ESSCIRC
   Miyashita Daisuke, 2014, IEEE JSSC
   Miyashita Daisuke, 2016, IEEE ASSCC
   Shim Yong, 2016, IEEE ACM DAC
   Xu Biying, 2017, IEEE ACM DAC
   Yunju Choi Yoontaek, 2016, IEEE S VLSI CIRC
   Zhou Hai, 2004, IEEE ICCD
NR 17
TC 16
Z9 19
U1 0
U2 0
PY 2019
DI 10.1145/3316781.3317800
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Elfadel, IM
AF Elfadel, Ibrahim M.
TI On the Stability of Analog ReLU Networks
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Trajectory; Asymptotic stability; Circuit stability; Neural networks;
   Symmetric matrices; Stability criteria; Design automation; Analog
   networks; Lyapunov theory; rectified linear unit (ReLU) activation;
   stability analysis
AB Rectified linear unit (ReLU) networks have become widely used in machine learning and automated inference using neural networks. Various forms of hardware accelerators based on ReLU networks have also been under development. In this brief, the stability problem in analog ReLU networks is addressed. Using the Lyapunov stability theory, it is shown that the origin of an unforced, analog ReLU dynamical system is globally asymptotically stable if the induced Euclidean norm of its connectivity matrix is less than one. An example is given to demonstrate that this upper bound is the best that can be achieved. In particular, the stability result holds for the case of a nonsymmetric connectivity matrix as may occur in some mathematical models of neurobiology.
C1 [Elfadel, Ibrahim M.] Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.
   [Elfadel, Ibrahim M.] Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi, U Arab Emirates.
RP Elfadel, IM (corresponding author), Khalifa Univ, Ctr Cyber Phys Syst, Abu Dhabi, U Arab Emirates.
EM ibrahim.elfadel@ku.ac.ae
CR [Anonymous], 1985, MATRIX ANAL
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Fleischer B, 2018, SYMP VLSI CIRCUITS, P35, DOI 10.1109/VLSIC.2018.8502276
   FREEMAN WJ, 1987, BIOL CYBERN, V56, P139, DOI 10.1007/BF00317988
   GRAY CM, 1989, P NATL ACAD SCI USA, V86, P1698, DOI 10.1073/pnas.86.5.1698
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   HASLER M, 1985, CIRCUITS NONLINEAIRE
   Haykin S. S., 2009, NEURAL NETWORKS LEAR, V3rd
   HOPFIELD JJ, 1984, P NATL ACAD SCI-BIOL, V81, P3088, DOI 10.1073/pnas.81.10.3088
   Klusowski JM, 2018, IEEE T INFORM THEORY, V64, P7649, DOI 10.1109/TIT.2018.2874447
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Nair V., 2010, ICML, P807
   Vidyasagar M., 1978, NONLINEAR SYSTEMS AN
   Ying Y, 2019, IEEE ACCESS, V7, P101633, DOI 10.1109/ACCESS.2019.2928442
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhu JH, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P265, DOI [10.1109/apccas47518.2019.8953177, 10.1109/APCCAS47518.2019.8953177]
NR 16
TC 4
Z9 4
U1 5
U2 11
PD NOV
PY 2021
VL 40
IS 11
BP 2426
EP 2430
DI 10.1109/TCAD.2020.3042155
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Oyamada, M
   Liu, JQ
   Narita, K
   Araki, T
AF Oyamada, Masafumi
   Liu, Jianquan
   Narita, Kazuyo
   Araki, Takuya
BE Chen, L
   Jia, Y
   Sellis, T
   Liu, G
TI MOARLE: Matrix Operation Accelerator Based on Run-Length Encoding
SO WEB TECHNOLOGIES AND APPLICATIONS, APWEB 2014
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 16th Asia-Pacific Web Conference (APWeb)
CY SEP 05-07, 2014
CL Natl Univ Def Technol, Changsha, PEOPLES R CHINA
HO Natl Univ Def Technol
DE Matrix; Compression; Run-length encoding; Similarity search; Euclidean
   distance
AB Matrix computation is a key technology in various data processing tasks including data mining, machine learning, and information retrieval. Size of matrices has been increasing with the development of computational resources and dissemination of big data. Huge matrices are memory- and computational-time-consuming. Therefore, reducing the size and computational time of huge matrices is a key challenge in the data processing area. We develop MOARLE, a novel matrix computation framework that saves memory space and computational time. In contrast to conventional matrix computational methods that target to sparse matrices, MOARLE can efficiently handle both sparse matrices and dense matrices. Our experimental results show that MOARLE can reduce the memory usage to 2% of the original usage and improve the computational performance by a factor of 124x.
C1 [Oyamada, Masafumi; Liu, Jianquan; Narita, Kazuyo; Araki, Takuya] NEC Corp Ltd, Green Platform Res Labs, Nakahara Ku, Kawasaki, Kanagawa 2118666, Japan.
RP Oyamada, M (corresponding author), NEC Corp Ltd, Green Platform Res Labs, Nakahara Ku, 1753 Shimonumabe, Kawasaki, Kanagawa 2118666, Japan.
EM m-oyamada@cq.jp.nec.com; j-liu@ct.jp.nec.com; k-narita@ct.jp.nec.com;
   t-araki@dc.jp.nec.com
CR [Anonymous], 1999, P ACM IEEE C SUP SC9
   Apple Inc, 1996, TN1023 APPL INC
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   CORMEN T, 2001, INTRO ALGORITHMS
   Deshpande M, 2004, ACM T INFORM SYST, V22, P143, DOI 10.1145/963770.963776
   Feng X., 2012, P 2012 ACM SIGMOD IN, P325, DOI 10.1145/2213836.2213874
   Fu WJJ, 1998, J COMPUT GRAPH STAT, V7, P397, DOI 10.2307/1390712
   Golub G.H., 2013, MATRIX COMPUTATIONS, V4th ed., DOI DOI 10.56021/9781421407944
   Guennebaud G., 2010, EIGEN V3
   Guyon I., 2004, NIPS
   LICHMAN M., 2013, UCI MACHINE LEARNING
   Rendle S, 2013, PROC VLDB ENDOW, V6, P337, DOI 10.14778/2535573.2488340
   Willcock J., 2006, ICS 06, P307, DOI DOI 10.1145/1183401.1183444
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2014
VL 8709
BP 425
EP 436
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Sun, RD
   Liu, PL
   Accetti, C
   Naqvi, AA
   Ahmed, H
   Qian, JC
AF Sun, Rongdi
   Liu, Peilin
   Accetti, Cecil
   Naqvi, Abid A.
   Ahmed, Haroon
   Qian, Jiuchao
GP IEEE
TI A 974GOPS/W Multi-level Parallel Architecture for Binary Weight Network
   Acceleration
SO 2018 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 27-30, 2018
CL Florence, ITALY
AB Deep neural networks dominate in the machine learning field. However, deploying deep neural networks on mobile devices requires aggressive compression of models due to huge amounts of parameters. An extreme case is to restrict weights to binary values {+1/-1} without much loss of accuracy. This promising method not only reduces hardware overhead of memory and computation, but also improves the performance of network inference. In this work, a flexible architecture for binary weight network acceleration is proposed. The architecture fully exploits the inherent multi-level parallelism of neural networks, resulting in utilization of processing elements over 80% for different layers. In addition, we present efficient data placement and transmission methods in coordination with multilevel parallel processing. The accelerator is implemented using SMIC 40nm technology. It operates at 1.2V and achieves up to 974GOPS/W power efficiency.
C1 [Sun, Rongdi; Liu, Peilin; Accetti, Cecil; Naqvi, Abid A.; Ahmed, Haroon; Qian, Jiuchao] Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
RP Sun, RD (corresponding author), Shanghai Jiao Tong Univ, Sch Elect Informat & Elect Engn, Shanghai, Peoples R China.
EM the.sun@sjtu.edu.cn
CR Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2016, BINARYNET TRAINING D
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Glorot X., 2011, P 14 INT C ARTIFICIA, P315
   Han S., 2015, P 28 INT C NEUR INF, V1, P1135
   Kim H, 2017, DES AUT CON, DOI 10.1145/3061639.3062189
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
NR 8
TC 2
Z9 2
U1 0
U2 2
PY 2018
DI 10.1109/ISCAS.2018.8351247
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT S
AU Farrokhbakht, H
   Hessabi, S
   Jerger, NE
AF Farrokhbakht, Hossein
   Hessabi, Shaahin
   Jerger, N. Enright
BE Hurson, AR
   Sarbazi-Azad, H
TI Power-gating in NoCs
SO POWER-EFFICIENT NETWORK-ON-CHIPS: DESIGN AND EVALUATION, VOL. 124
SE Advances in Computers
DT Article; Book Chapter
AB Driven by trends such as machine learning, the internet of things and 5G, it is increasingly common to see computer chips with tens to hundreds of processing cores, ranging from general purpose CPUs to application specific accelerators. All processing cores must share data and coordinate their operation, leading to contention and performance penalties. Communication between cores is handled by a network-on-chip (NoC). However, NoCs for modern chips contribute considerably to the chips overall power budget. Thus, the NoC power consumption is critical for ensuring that chips can continue to keep pace with increasing demand. Although NoCs are over-provisioned to handle worst-case scenarios, the NoCs routers are quite often underutilized, making them a promising candidate for power-gating. However, applying power-gating to the on-chip routers has several challenges. In this chapter, we present different power-gating solutions to alleviate the challenges.
C1 [Farrokhbakht, Hossein] Univ Toronto, Toronto, ON, Canada.
   [Hessabi, Shaahin] Sharif Univ Technol, Dept Comp Engn, Tehran, Iran.
   [Jerger, N. Enright] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON, Canada.
RP Farrokhbakht, H (corresponding author), Univ Toronto, Toronto, ON, Canada.
CR [Anonymous], 2015, INT S NETW ON CHIP
   [Anonymous], 2013, ACM SIGARCH COMPUT A, DOI DOI 10.1145/2508148.2485950
   Badr M, 2014, CONF PROC INT SYMP C, P109, DOI 10.1109/ISCA.2014.6853236
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen LZ, 2015, INT S HIGH PERF COMP, P378, DOI 10.1109/HPCA.2015.7056048
   Chen LZ, 2014, INT S HIGH PERF COMP, P296, DOI 10.1109/HPCA.2014.6835940
   Chen LZ, 2012, INT SYMP MICROARCH, P270, DOI 10.1109/MICRO.2012.33
   Daya BK, 2014, CONF PROC INT SYMP C, P25, DOI 10.1109/ISCA.2014.6853232
   DUATO J, 1993, IEEE T PARALL DISTR, V4, P1320, DOI 10.1109/71.250114
   Farrokhbakht H., 2018, INT S LOW POWER ELEC, P17
   Farrokhbakht H., 2017, INT S NETW ON CHIP N, p15: 1
   Farrokhbakht H, 2019, I SYMPOS LOW POWER E
   Hessabi, 2016, PROC 10 IEEEACM INT, P1
   Jiang N., 2013, INT S PERFORMANCE AN, P86, DOI 10.1109/ISPASS.2013.6557149
   Keating M., 2007, LOW POWER METHODOLOG
   Kim G, 2011, DES AUT CON, P936
   Kim JS, 2003, ISLPED'03: PROCEEDINGS OF THE 2003 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P424
   Kim NS, 2003, COMPUTER, V36, P68, DOI 10.1109/MC.2003.1250885
   Matsutani Hiroki, 2010, 2010 ACM/IEEE International Symposium on Networks-on-Chip (NOCS), P61, DOI 10.1109/NOCS.2010.16
   Matsutani H, 2008, ASIA S PACIF DES AUT, P519
   Mirhosseini A, 2015, DES AUT TEST EUROPE, P1527
   Parikh R, 2014, DES AUT CON
   Samih A, 2013, INT S HIGH PERF COMP, P508, DOI 10.1109/HPCA.2013.6522345
   Sun Chen, 2012, P NOCS
   WOO SC, 1995, ACM COMP AR, P24, DOI 10.1109/ISCA.1995.524546
NR 25
TC 0
Z9 0
U1 1
U2 1
PY 2022
VL 124
BP 319
EP 356
DI 10.1016/bs.adcom.2021.11.013
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Wheeldon, A
   Serb, A
AF Wheeldon, Adrian
   Serb, Alexander
TI A study on the clusterability of latent representations in image
   pipelines
SO FRONTIERS IN NEUROINFORMATICS
DT Article
DE machine learning; symbolics; clustering; convolutional neural networks;
   autoencoders; artificial intelligence; cognitive computing
AB Latent representations are a necessary component of cognitive artificial intelligence (AI) systems. Here, we investigate the performance of various sequential clustering algorithms on latent representations generated by autoencoder and convolutional neural network (CNN) models. We also introduce a new algorithm, called Collage, which brings views and concepts into sequential clustering to bridge the gap with cognitive AI. The algorithm is designed to reduce memory requirements, numbers of operations (which translate into hardware clock cycles) and thus improve energy, speed and area performance of an accelerator for running said algorithm. Results show that plain autoencoders produce latent representations which have large inter-cluster overlaps. CNNs are shown to solve this problem, however introduce their own problems in the context of generalized cognitive pipelines.
C1 [Wheeldon, Adrian; Serb, Alexander] Univ Edinburgh, Ctr Elect Frontiers, Sch Engn, Edinburgh, Scotland.
RP Wheeldon, A (corresponding author), Univ Edinburgh, Ctr Elect Frontiers, Sch Engn, Edinburgh, Scotland.
EM adrian.wheeldon@ed.ac.uk
CR [Anonymous], 2006, PATTERN RECOGN
   Blot M., 2020, PHD THESIS
   Cohen T. S., 2017, P INT C LEARNING REP
   Frady EP, 2020, NEURAL COMPUT, V32, P2311, DOI 10.1162/neco_a_01331
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Hartigan J. A., 1975, CLUSTERING ALGORITHM
   Imani M, 2019, DES AUT TEST EUROPE, P1591, DOI [10.23919/date.2019.8715147, 10.23919/DATE.2019.8715147]
   Kanerva P., 1988, SPARSE DISTRIBUTED M
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Neubert P, 2021, ROBOT SCI SYS
   Newson A, 2020, J MATH IMAGING VIS, V62, P293, DOI 10.1007/s10851-019-00924-w
NR 11
TC 0
Z9 0
U1 0
U2 0
PD FEB 16
PY 2023
VL 17
AR 1074653
DI 10.3389/fninf.2023.1074653
WC Mathematical & Computational Biology; Neurosciences
DA 2023-11-11
ER

PT J
AU Brand, M
   Hannig, F
   Keszocze, O
   Teich, J
AF Brand, Marcel
   Hannig, Frank
   Keszocze, Oliver
   Teich, Juergen
TI Precision- and Accuracy-Reconfigurable Processor Architectures-An
   Overview
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Computer architecture; Arithmetic; Circuits and systems; Neural
   networks; Adders; Machine learning algorithms; Linear algebra; Accuracy;
   arithmetic; reconfigurable architectures; convolutional neural networks
ID FUSED-MULTIPLY-ADD
AB High performance and, at the same time, energy efficiency are important yet often conflicting requirements in many fields of emerging applications. Those applications range from multi-dimensional and multi-sensor digital signal processing to machine learning, such as neural network processing. Whereas conventional fixed-point and floating-point processor architectures cannot adapt to quite diverging demands related to required precision and accuracy of computations, even within a single application, e.g., in different layers of a neural network, domain-specific accelerators may be much too specific and thus rigid to cover a wide enough spectrum of applications. In this tutorial brief, we give an overview of existing processor solutions that are reconfigurable or tunable in precision or accuracy of computations. The spectrum of reviewed architectures ranges from processors with vectorizable processors over multi- and trans-precision solutions, including GPUs to any-time instruction-set processors. The latter works with a fixed precision, but the accuracy of the result of floating-point operations is encoded in the instruction word. It can thus vary from instruction to instruction. This allows realizing accuracy vs. execution time or energy tradeoffs. Subsequently, we investigate several application domains, including neural network processing, linear algebra, and approximate computing, where such emerging processor architectures can be beneficially used.
C1 [Brand, Marcel; Hannig, Frank; Keszocze, Oliver; Teich, Juergen] Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
RP Brand, M (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg, Dept Comp Sci, D-91054 Erlangen, Germany.
EM marcel.brand@fau.de; frank.hannig@fau.de; oliver.keszoecze@fau.de;
   juergen.teich@fau.de
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   [Anonymous], 2021, GAP APPL PROC
   [Anonymous], 2021, XIL AI ENG TECHN
   [Anonymous], 2018, 338302001US INT
   Arunachalam V, 2018, MICROPROCESS MICROSY, V57, P23, DOI 10.1016/j.micpro.2017.12.009
   Brand M, 2020, IEEE INT CONF ASAP, P157, DOI 10.1109/ASAP49362.2020.00034
   Brand M, 2019, CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P215, DOI 10.1145/3310273.3322833
   Darulova E., 2018, TOOLS ALGORITHMS CON
   Darulova E, 2018, ACM IEEE INT CONF CY, P208, DOI 10.1109/ICCPS.2018.00028
   de Dinechin F, 2011, IEEE DES TEST COMPUT, V28, P18, DOI 10.1109/MDT.2011.44
   Ebrahimi Zahra, 2020, PROC ACM GREAT LAKES, P151, DOI 10.1145/3386263.3406907
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   GRANLUND T, GNU MULTIPLE PRECISI
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Hannig F, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2584660
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jaiswal MK, 2019, IEEE ACCESS, V7, P74586, DOI 10.1109/ACCESS.2019.2920936
   Johnson J., 2018, ARXIV 181101721
   Keszocze O., 2021, PROC S APPL COMPUT
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Mach S., 2021, THESIS ETH ZURICH ZU
   Mach S., 2021, FLOATING POINT ARCHI
   Mach S, 2021, IEEE T VLSI SYST, V29, P774, DOI 10.1109/TVLSI.2020.3044752
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Maddock J., BOOST MULTIPRECISION
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Manolopoulos K., 2010, Proceedings of the 2010 17th IEEE International Conference on Electronics, Circuits and Systems (ICECS 2010), P5, DOI 10.1109/ICECS.2010.5724440
   Ortiz M., 2018, ARXIV180405267
   Plagwitz P, 2021, ANN IEEE SYM FIELD P, P10, DOI 10.1109/FCCM51124.2021.00010
   Prasad R, 2020, DES AUT TEST EUROPE, P1067, DOI [10.23919/DATE48585.2020.9116408, 10.23919/date48585.2020.9116408]
   Said NA, 2021, MICROELECTRON RELIAB, V120, DOI 10.1016/j.microrel.2021.114099
   Schuiki F, 2019, DES AUT TEST EUROPE, P662, DOI [10.23919/DATE.2019.8715007, 10.23919/date.2019.8715007]
   Schuster A., 2021, PROC INT WORKSHOP IO
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tagliavini G, 2019, DES AUT TEST EUROPE, P654, DOI [10.23919/DATE.2019.8714897, 10.23919/date.2019.8714897]
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Thompto BW, 2021, CONF PROC INT SYMP C, P29, DOI 10.1109/ISCA52012.2021.00012
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Wang N., 2018, TRAINING DEEP NEURAL
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Yamaguchi H., PROC C AUTOM TEST EU, V2021
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Zamirai P., 2021, PREPRINTS
   Zhang H, 2019, IEEE T COMPUT, V68, P1035, DOI 10.1109/TC.2019.2895031
   Zhang T., 2019, PREPRINTS
NR 46
TC 1
Z9 1
U1 1
U2 4
PD JUN
PY 2022
VL 69
IS 6
BP 2661
EP 2666
DI 10.1109/TCSII.2022.3173753
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU El-Helw, I
   Hofman, R
   Bal, HE
AF El-Helw, Ismail
   Hofman, Rutger
   Bal, Henri E.
BE Malawski, M
   Rzadca, K
TI Accelerating Overlapping Community Detection: Performance Tuning a
   Stochastic Gradient Markov Chain Monte Carlo Algorithm
SO EURO-PAR 2020: PARALLEL PROCESSING
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 26th International Conference on Parallel and Distributed Computing
   (Euro-Par)
CY AUG 24-28, 2020
CL ELECTR NETWORK
DE Algorithms for accelerators and heterogeneous systems; Performance
   analysis; Combinatorial and data intensive application
AB Building efficient algorithms for data-intensive problems requires deep analysis of data access patterns. Random data access patterns exacerbate this process. In this paper, we discuss accelerating a randomized data-intensive machine learning algorithm using multi-core CPUs and several types of GPUs. A thorough analysis of the algorithm's data dependencies enabled a 75% reduction in its memory footprint. We created custom compute kernels via code generation to identify the optimal set of data placement and computational optimizations per compute device. An empirical evaluation shows up to 245x speedup compared to an optimized sequential version. Another result from this evaluation is that achieving peak performance does not always match intuition: e.g., depending on the GPU architecture, vectorization may increase or hamper performance.
C1 [El-Helw, Ismail; Hofman, Rutger; Bal, Henri E.] Vrije Univ Amsterdam, Amsterdam, Netherlands.
RP El-Helw, I (corresponding author), Vrije Univ Amsterdam, Amsterdam, Netherlands.
EM ielhelw@gmail.com; rutger@cs.vu.nl; bal@cs.vu.nl
CR [Anonymous], 2008, 2008 IEEE Hot Chips 20 Symposium (HCS), DOI 10.1109/HOTCHIPS.2008.7476516
   Bal H, 2016, COMPUTER, V49, P54, DOI 10.1109/MC.2016.127
   El-Helw I, 2016, IEEE SYM PARA DISTR, P1463, DOI 10.1109/IPDPSW.2016.165
   Gaihre A, 2019, HPDC'19: PROCEEDINGS OF THE 28TH INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE PARALLEL AND DISTRIBUTED COMPUTING, P121, DOI 10.1145/3307681.3326606
   Girolami M, 2011, J ROY STAT SOC B, V73, P123, DOI 10.1111/j.1467-9868.2010.00765.x
   Gupta S, 2015, Arxiv, DOI arXiv:1502.02551
   Huang FR, 2015, Arxiv, DOI arXiv:1309.0787
   khronos, OPENCL THE OPEN STAN
   Beam AL, 2014, Arxiv, DOI [arXiv:1402.4089, 10.1080/10618600.2015.1035724, DOI 10.1080/10618600.2015.1035724]
   Leskovec J., 2014, SNAP DATASETS STANFO
   Li WZ, 2015, Arxiv, DOI arXiv:1510.04815
   Lim RV, 2017, PROC INT CONF PARAL, P523, DOI 10.1109/ICPP.2017.61
   Medlar A, 2013, BIOINFORMATICS, V29, P413, DOI 10.1093/bioinformatics/bts704
   Mei XX, 2017, IEEE T PARALL DISTR, V28, P72, DOI 10.1109/TPDS.2016.2549523
   Nugteren C., CLCUDAAPI PORTABLE H
   numpy, NUMPY HOME PAGE
   nvidia, CUBLAS HOME PAGE
   Pagh R, 2004, J ALGORITHMS, V51, P122, DOI 10.1016/j.jalgor.2003.12.002
   van Werkhoven B, 2019, FUTURE GENER COMP SY, V90, P347, DOI 10.1016/j.future.2018.08.004
   White G, 2014, COMPUT STAT DATA AN, V71, P643, DOI 10.1016/j.csda.2013.03.027
   Yan F., 2009, ADV NEURAL INFORM PR, P2134
   Zhu HZ, 2020, FUTURE GENER COMP SY, V111, P552, DOI 10.1016/j.future.2019.09.052
NR 22
TC 1
Z9 1
U1 0
U2 0
PY 2020
VL 12247
BP 510
EP 526
DI 10.1007/978-3-030-57675-2_32
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Imani, M
   Gupta, S
   Rosing, T
AF Imani, Mohsen
   Gupta, Saransh
   Rosing, Tajana
GP Assoc Comp Machinery
TI Digital-based Processing In-Memory: A Highly-Parallel Accelerator for
   Data Intensive Applications
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
DE Processing in-memory; Non-volatile memory; Machine learning acceleration
AB Recently, Processing In-Memory (PIM) has been shown as a promising solution to address data movement issue in the current processors. However, today's PIM technologies are mostly analog-based, which involve both scalability and efficiency issues. In this paper, we propose a novel digital-based PIM which accelerates fundamental operations and diverse data analytic procedures using processing in-memory technology. Instead of sending a large amount of data to the processing cores for computation, our design performs a large part of computation tasks inside the memory; thus the application performance can be accelerated significantly by avoiding the memory access bottleneck. Digital-based PIM supports bit-wise operations between two selected bit-line of the memory block and then extends it to support row-parallel arithmetic operations.
C1 [Imani, Mohsen; Gupta, Saransh; Rosing, Tajana] Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
RP Imani, M (corresponding author), Univ Calif San Diego, Dept Comp Sci & Engn, La Jolla, CA 92093 USA.
EM moimani@ucsd.edu; sgupta@ucsd.edu; tajana@ucsd.edu
CR [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ADV FUNCTIONAL MAT
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gupta S, 2019, PR GR LAK SYMP VLSI, P201, DOI 10.1145/3299874.3317977
   Gupta S, 2018, 2018 IEEE 15TH INTERNATIONAL CONFERENCE ON SOFTWARE ARCHITECTURE (ICSA), P1, DOI 10.1109/ICSA.2018.00009
   Haj-Ali A., 2018, IEEE ISCAS
   Imani M., 2019, IEEE ACM INT S COMP
   Imani M, 2017, PROCEEDINGS OF THE 2017 7TH INTERNATIONAL CONFERENCE ON COMPUTER AND KNOWLEDGE ENGINEERING (ICCKE), P8, DOI 10.1109/ICCKE.2017.8167879
   Imani M, 2019, PR GR LAK SYMP VLSI, P429, DOI 10.1145/3299874.3319483
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Kvatinsky S, 2015, IEEE T CIRCUITS-II, V62, P786, DOI 10.1109/TCSII.2015.2433536
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Li C, 2019, 34TH IEEE/ACM INTERNATIONAL CONFERENCE ON AUTOMATED SOFTWARE ENGINEERING (ASE 2019), P1174, DOI 10.1109/ASE.2019.00130
   Salamat S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P166
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Song L, 2017, IOP C SER EARTH ENV, V73, DOI 10.1088/1755-1315/73/1/012017
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Zhou MX, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P591, DOI 10.1145/3287624.3287711
NR 19
TC 2
Z9 2
U1 0
U2 1
PY 2019
BP 38
EP 40
DI 10.1145/3357526.3357551
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Colangelo, P
   Sengupta, S
   Margala, M
AF Colangelo, Philip
   Sengupta, Shayan
   Margala, Martin
GP IEEE
TI Sparse Persistent GEMM Accelerator using OpenCL for Intel FPGAs
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE sparsity; OpenCL; BLAS; FPGA
AB Optimizations of primitive routines such as General Matrix Multiplication (GEMM) continue to advance the state of the art performance for their applications. Various libraries such as Basic Linear Algebra Subprograms (BLAS) exist that provide API interfaces to highly tuned, hardware-specific implementations. Applications such as deep learning push the limits of what is possible from these subroutines by necessitating unique optimizations like lowering numeric precision and data type bit-width, exploiting resiliency, and removing redundancy. Hardware plays a considerable role in the performance of a subroutine because of the inherent layout of memory and arithmetic structures such as the SIMD processors found in general CPU and GPU architectures. FPGAs play a unique role in this space because the reconfigurable circuits and routing provide a pipelined architecture capable of both SIMD and MIMD-like architectures. Within a pipeline, the capability of accelerating operations on FPGA through low-bit and fine-grained designs is typically only seen in ASICs. In this paper, we provide an overview of an OpenCL based GEMM accelerator design that exploits sparsity and compression to persist data in FPGA on-chip, fine-grained SRAM. The design includes support for successive GEMMs with added activation functions, making it suitable for some machine learning applications. Results are measured running on Intel's Arria 10 GX 1150 FPGA. Compared to non-sparse and nonpersistent designs, we achieve a speedup towards the theoretical limit of 6.5x for our fine-grained implementation and 8x for our structured implementation. We measure over 1 TOP/s utilizing only 17% of Arria 10 DSP blocks for a 90% sparse design.
C1 [Colangelo, Philip] Intel Umass Lowell, San Jose, CA 95134 USA.
   [Sengupta, Shayan] Intel, San Jose, CA USA.
   [Margala, Martin] Univ Massachusetts Lowell, Lowell, MA USA.
RP Colangelo, P (corresponding author), Intel Umass Lowell, San Jose, CA 95134 USA.
EM philip.colangelo@intel.com; shayan.sengupta@intel.com;
   Martin_Margala@uml.edu
CR [Anonymous], IMPLEMENTING FPGA DE
   [Anonymous], INTEL FPGA SDK OPENC
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Chiu GR, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P34, DOI 10.1145/3177540.3177561
   Colangelo P, 2019, IEEE HIGH PERF EXTR
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Gupta Suyog., 2018, PRUNE NOT PRUNE EXPL
   Han S., 2015, ARXIV151000149
   Intel<(R), INTEL FPGA PRODUCTS
   Lavin A., 2015, FAST ALGORITHMS CONV, Vabs/1509.09308
   Lawson C. L., 1977, BASIC LINEAR ALGEBRA
   Ling A.C., 2017, P 5 INT WORKSH OPENC
   Lu LQ, 2019, ANN IEEE SYM FIELD P, P17, DOI 10.1109/FCCM.2019.00013
   Mao Huizi, 2017, ABS170508922 ARXIV
   Michael Mathieu, 2013, ARXIV13125851CSCV
   Moss DJM, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P107, DOI 10.1145/3174243.3174258
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2015, INT CONF COMPIL ARCH, P109, DOI 10.1109/CASES.2015.7324551
   Pete Warden, 2015, P WARDENS BLOG
   Sato, 2019, P ACM SIGDA INT S FI, P186, DOI DOI 10.1145/3289602.3293967
   Sheng K, 2009, PROC INT SYMP POWER, P255, DOI 10.1109/ISPSD.2009.5158050
   Sinha Udayan., 2017, ENABLING IMPACTFUL D
   Umuroglu Y., 2016, ABS161207119 CORR
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Khoshavi, N
   Maghsoudloo, M
   Roohi, A
   Sargolzaei, S
   Bi, Y
AF Khoshavi, Navid
   Maghsoudloo, Mohammad
   Roohi, Arman
   Sargolzaei, Saman
   Bi, Yu
TI HARDeNN: Hardware-assisted attack-resilient deep neural network
   architectures
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Black -box adversarial attacks; Binarized neural network accelerator;
   Machine learning; Soft error
AB We propose HARDeNN, a low-overhead end-to-end inference accelerator methodology to armor the underlying pre-trained neural network architecture against black-box non-input adversarial attacks. In order to find the most vulnerable neural network architectures parameters, a hardware-assisted fault injection tool and a statistical stress model have been proposed to synergy uniform fault assessment across layers and targeted in-layer fault assessment to realize a holistic, rigorous fault evaluation in NN topologies susceptible to non-input adversarial black-box attacks. The key observation from the assessment shows that the weights and activation functions are the most vulnerable neural network parameters that are susceptible to both single-bit and multiple-bit flip at-tacks. Concerning the aforementioned parameters, a multi-objective design space exploration is conducted to find a superior design under different resource constraints. The error-resiliency magnitude offered by HARDeNN can be adjusted based on the given boundaries. The experimental results show that HARDeNN methodology enhances the error-resiliency magnitude of cnvW1A1 by 17.19% and 96.15% for 100 multi-bit upsets that target weight and activation layers, respectively, during CIFAR-10 classification.(c) 2017 Elsevier Inc. All rights reserved.
C1 [Khoshavi, Navid] Adv Micro Devices AMD, Santa Clara, CA 95054 USA.
   [Maghsoudloo, Mohammad] Golestan Univ, Fac Engn, Dept Comp Engn, Gorgan, Iran.
   [Roohi, Arman] Univ Nebraska Lincoln, Dept Comp Sci & Engn, Lincoln, NE USA.
   [Sargolzaei, Saman] Univ Tennessee Martin, Dept Engn, Martin, TN USA.
   [Bi, Yu] Univ Rhode Isl, Dept Elect & Comp Engn, Kingston, RI USA.
RP Khoshavi, N (corresponding author), Adv Micro Devices AMD, Santa Clara, CA 95054 USA.
EM navid.khoshavi@amd.com
CR Abdel-Hamid O, 2014, IEEE-ACM T AUDIO SPE, V22, P1533, DOI 10.1109/TASLP.2014.2339736
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Azarkhish E, 2018, IEEE T PARALL DISTR, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Azizimazreah A, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Barenghi A, 2012, P IEEE, V100, P3056, DOI 10.1109/JPROC.2012.2188769
   Breier J, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2204, DOI 10.1145/3243734.3278519
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi Y., 2018, ARXIV
   Courbariaux M., 2016, ARXIV
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Dixit A, 2011, 2011 IEEE INTERNATIONAL RELIABILITY PHYSICS SYMPOSIUM (IRPS)
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Goodfellow J., 2014, ARXIV
   Goyal P, 2017, IEEE I CONF COMP VIS
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Hitaj B, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P603, DOI 10.1145/3133956.3134012
   Hubara I, 2016, ADV NEUR IN, V29
   Jung S., 2018, ARXIV
   Khoshavi N., 2020, ICMLA, P1
   Khoshavi N, 2017, INTEGRATION, V59, P10, DOI 10.1016/j.vlsi.2017.03.013
   Khoshavi N, 2014, MIDWEST SYMP CIRCUIT, P929, DOI 10.1109/MWSCAS.2014.6908568
   Kim M, 2016, ARXIV
   Kim Y., 2014, ARXIV, DOI 10.3115/v1/D14-1181
   Kim Y, 2014, CONF PROC INT SYMP C, P361, DOI 10.1109/ISCA.2014.6853210
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lacey G, 2016, ARXIV
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Lin CY, 2018, ASIA S PACIF DES AUT, P105, DOI 10.1109/ASPDAC.2018.8297290
   Liu W, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120755
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Ma YF, 2018, INTEGRATION, V62, P14, DOI 10.1016/j.vlsi.2017.12.009
   Madry A., 2018, INT C LEARNING REPRE
   Maghsoudloo M, 2015, MICROELECTRON RELIAB, V55, P2439, DOI 10.1016/j.microrel.2015.07.049
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2017, PROC CVPR IEEE, P7197, DOI 10.1109/CVPR.2017.761
   Paudel B. R., 2022, INT S QUALITY ELECT
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roohi A, 2020, IEEE T COMPUT, V69, P349, DOI 10.1109/TC.2019.2949042
   Salem A., 2018, ARXIV
   Seifert N, 2012, IEEE T NUCL SCI, V59, P2666, DOI 10.1109/TNS.2012.2218128
   Sharma H., 2018, P ACMIEEE 45 ANN INT
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan M., 2014, ARXIV
   Tajik Shahin, 2022, Security and Artificial Intelligence: A Crossdisciplinary Approach. Lecture Notes in Computer Science (13049), P72, DOI 10.1007/978-3-030-98795-4_4
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang N., 2018, ADV NEURAL INFORM PR, P7675, DOI DOI 10.1109/THERMINIC.2018.8593303
   Wu SH, 2018, 2018 52ND ANNUAL CONFERENCE ON INFORMATION SCIENCES AND SYSTEMS (CISS), DOI 10.1109/CISS.2018.8362280
   Yih W., 2015, CISC VIS NETW IND GL
   Zhang, 2016, ARXIV
   Zhu C., 2017, P INT C LEARN REPR I
NR 52
TC 1
Z9 1
U1 0
U2 0
PD NOV
PY 2022
VL 95
AR 104710
DI 10.1016/j.micpro.2022.104710
EA OCT 2022
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Oh, YH
   Kim, S
   Jin, Y
   Son, S
   Bae, J
   Lee, J
   Park, Y
   Kim, DU
   Ham, TJ
   Lee, JW
AF Oh, Young H.
   Kim, Seonghak
   Jin, Yunho
   Son, Sam
   Bae, Jonghyun
   Lee, Jongsung
   Park, Yeonhong
   Kim, Dong Uk
   Ham, Tae Jun
   Lee, Jae W.
GP IEEE Comp Soc
TI Layerweaver: Maximizing Resource Utilization of Neural Processing Units
   via Layer-Wise Scheduling
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE Layer-wise Scheduling; Systems for Machine Learning; Inference Serving
   System; Neural Networks; Accelerator Systems; Multi-tasking
ID IOT
AB To meet surging demands for deep learning inference services, many cloud computing vendors employ high-performance specialized accelerators, called neural processing units (NPUs). One important challenge for effective use of NPUs is to achieve high resource utilization over a wide spectrum of deep neural network (DNN) models with diverse arithmetic intensities. There is often an intrinsic mismatch between the compute-to-memory bandwidth ratio of an NPU and the arithmetic intensity of the model it executes, leading to under-utilization of either compute resources or memory bandwidth. Ideally, we want to saturate both compute TOP/s and DRAM bandwidth to achieve high system throughput. Thus, we propose Layerweaver, an inference serving system with a novel multi-model time-multiplexing scheduler for NPUs. Layerweaver reduces the temporal waste of computation resources by interweaving layer execution of multiple different models with opposing characteristics: compute-intensive and memory-intensive. Layerweaver hides the memory time of a memory-intensive model by overlapping it with the relatively long computation time of a compute-intensive model, thereby minimizing the idle time of the computation units waiting for off-chip data transfers. For a two-model serving scenario of batch 1 with 16 different pairs of compute- and memory-intensive models, Layerweaver improves the temporal utilization of computation units and memory channels by 44.0% and 28.7%, respectively, to increase the system throughput by 60.1% on average, over the baseline executing one model at a time.
C1 [Oh, Young H.] Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon, South Korea.
   [Kim, Seonghak; Jin, Yunho; Son, Sam; Bae, Jonghyun; Lee, Jongsung; Park, Yeonhong; Kim, Dong Uk; Ham, Tae Jun; Lee, Jae W.] Seoul Natl Univ, Neural Proc Res Ctr NPRC, Dept Comp Sci & Engn, Seoul, South Korea.
RP Oh, YH (corresponding author), Sungkyunkwan Univ, Dept Elect & Comp Engn, Suwon, South Korea.
EM younghwan@skku.edu; ksh1102@snu.ac.kr; yhjin0509@snu.ac.kr;
   sosson97@snu.ac.kr; jonghbae@snu.ac.kr; leitia@snu.ac.kr;
   ilil96@snu.ac.kr; dongukim12@snu.ac.kr; taejunham@snu.ac.kr;
   jaewlee@snu.ac.kr
CR Alwani M, 2016, INT SYMP MICROARCH
   Amazon, AM SAGEMAKER
   [Anonymous], 2020, TENSORFLOW CORE V2 3
   [Anonymous], 2020, PYTORCH 1 6 0 DOCUME
   [Anonymous], 2013, DATACENTER COMPUTER
   Baek E, 2020, ANN I S COM, P940, DOI 10.1109/ISCA45697.2020.00081
   cambricon, CAMBR MLU100
   Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700
   Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368
   Chen YL, 2016, DESTECH TRANS COMP
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Choi Y, 2020, INT S HIGH PERF COMP, P220, DOI 10.1109/HPCA47549.2020.00027
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Daga B., 2019, S HIGH PERF CHIPS HO, P1
   Devlin J., 2018, PREPRINT
   Elliott GA, 2013, REAL TIM SYST SYMP P, P33, DOI 10.1109/RTSS.2013.12
   Eyerman S, 2008, IEEE MICRO, V28, P42, DOI 10.1109/MM.2008.44
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Google, GOOGL AI PLATF
   Google, GOOGL NOW
   Google Cloud, EDG TPU RUN INF EDG
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Habana, HAB GOYA
   Ham TJ, 2020, INT S HIGH PERF COMP, P328, DOI 10.1109/HPCA47549.2020.00035
   Hauswald J, 2015, ACM SIGPLAN NOTICES, V50, P223, DOI [10.1145/2694344.2694347, 10.1145/2775054.2694347]
   Hauswald J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P27, DOI 10.1145/2749469.2749472
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He K., 2016, P IEEE C COMPUTER VI
   He XN, 2017, PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW'17), P173, DOI 10.1145/3038912.3052569
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kang YP, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P615, DOI 10.1145/3037697.3037698
   Kato Shinpei, 2011, P USENIX ANN TECHNIC, P17
   Kwon H, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P754, DOI 10.1145/3352460.3358252
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Lee Y, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P611
   Li H, 2018, IEEE NETWORK, V32, P96, DOI 10.1109/MNET.2018.1700202
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Matos LO, 2019, 2019 IEEE 4TH COLOMBIAN CONFERENCE ON AUTOMATIC CONTROL (CCAC): AUTOMATIC CONTROL AS KEY SUPPORT OF INDUSTRIAL PRODUCTIVITY, DOI 10.1109/ccac.2019.8921191
   Microsoft, MICR AZ MACH LEARN
   Pellauer Michael, 2019, ASPLOS '19: Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, P137, DOI 10.1145/3297858.3304025
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tanasic I, 2014, CONF PROC INT SYMP C, P193, DOI 10.1109/ISCA.2014.6853208
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang XF, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P1088, DOI 10.1109/HPCC/SmartCity/DSS.2018.00181
   Wang Y.E., 2020, 3 C MACH LEARN SYST
   Xiang YC, 2019, REAL TIM SYST SYMP P, P392, DOI 10.1109/RTSS46320.2019.00042
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yan MY, 2019, IEEE INT CONF ROBOT, P4804, DOI [10.1109/ICRA.2019.8794024, 10.1109/icra.2019.8794024]
   Yang ZW, 2021, ANIM BIOTECHNOL, V32, P67, DOI 10.1080/10495398.2019.1653901
   Yu Peifeng, 2020, P MACHINE LEARNING S, P98
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao ZR, 2018, IEEE T COMPUT AID D, V37, P2348, DOI 10.1109/TCAD.2018.2858384
   Zhou GF, 2018, PROC INT CONF ANTI, P192, DOI 10.1109/ICASID.2018.8693202
NR 60
TC 13
Z9 15
U1 2
U2 4
PY 2021
BP 584
EP 597
DI 10.1109/HPCA51647.2021.00056
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU He, ZH
   Wang, ZK
   Alonso, G
AF He, Zhenhao
   Wang, Zeke
   Alonso, Gustavo
GP ACM
TI BiS-KM: Enabling Any-Precision K-Means on FPGAs
SO 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS
   (FPGA '20)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 23-25, 2020
CL Seaside, CA
DE FPGA; K-Means; Bit-Serial Arithmetic; Low-Precision Clustering; Memory
   Layout
AB K-Means is a popular clustering algorithm widely used and extensively studied in the literature. In this paper we explore the challenges and opportunities in using low precision input in conjunction with a standard K-Means algorithm as a way to improve the memory bandwidth utilization on hardware accelerators. Low precision input through quantization has become a standard technique in machine learning to reduce computational costs and memory traffic. When applied in FPGAs, several issues need to be addressed. First and foremost is the overhead of storing the data at different precision levels since, depending on the training objective, different levels of precision might be needed. Second, the FPGA design needs to accommodate varying precision without requiring reconfiguration. To address these concerns, we propose Bit-Serial K-Means (BiS-KM), a combination of a hybrid memory layout supporting data retrieval at any level of precision, a novel FPGA design based on bit-serial arithmetic, and a modified K-Means algorithm tailored to FPGAs. We have tested BiS-KM with various data sets and compared our design with a state-of-the-art FPGA accelerator. BiS-KM achieves an almost linear speedup as precision decreases, providing a more effective way to perform K-Means on FPGAs.
C1 [He, Zhenhao; Wang, Zeke; Alonso, Gustavo] Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
RP He, ZH (corresponding author), Swiss Fed Inst Technol, Dept Comp Sci, Syst Grp, Zurich, Switzerland.
EM zhenhao.he@inf.ethz.ch; zeke.wang@inf.ethz.ch;
   gustavo.alonso@inf.ethz.ch
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Andrzejak RG, 2001, PHYS REV E, V64, DOI 10.1103/PhysRevE.64.061907
   [Anonymous], 2018, ASPLOS
   Blackard JA, 1999, COMPUT ELECTRON AGR, V24, P131, DOI 10.1016/S0168-1699(99)00046-0
   Bohm Christian, 2017, SIAM
   Choi YM, 2014, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2014.6868624
   Delmas Alberto, 2017, CORR
   Estlick M., 2001, FPGA
   Feng Z., 2015, ICDE
   Feng ZQ, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P31, DOI 10.1145/2723372.2747642
   Gokhale Maya, 2003, J SUPERCOMPUT
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He ZH, 2018, I C FIELD PROG LOGIC, P368, DOI 10.1109/FPL.2018.00069
   Hubara I, 2018, J MACH LEARN RES, V18
   Hussain HM, 2012, INT J RECONFIGURABLE, V2012, DOI 10.1155/2012/135926
   HUSSAIN HM, 2011, NASA ESA C AD HARDW
   Johnson BA, 2016, APPL GEOGR, V67, P140, DOI 10.1016/j.apgeog.2015.12.006
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Kara Kaan, 2019, VLDB
   Kara Kaan, 2018, VLDB
   Lesser Bernd, 2011, ICCS
   Li Y., 2013, SIGMOD C, P289, DOI DOI 10.1145/2463676.2465322
   Lin Z., 2012, FPL
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Oliver N., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P80, DOI 10.1109/ReConFig.2011.4
   Owaida M, 2018, I C FIELD PROG LOGIC, P295, DOI 10.1109/FPL.2018.00057
   Owaida M, 2017, ANN IEEE SYM FIELD P, P211, DOI 10.1109/FCCM.2017.37
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Saegusa T, 2006, I C FIELD PROG LOGIC, P567
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Sinha A., 1999, IEEE INT ASIC SOC C
   Tang Qing Y., 2016, ACM Transactions on Reconfigurable Technology and Systems, V10, DOI 10.1145/2964910
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vergara A, 2012, SENSOR ACTUAT B-CHEM, V166, P320, DOI 10.1016/j.snb.2012.01.074
   Wang X, 2007, ANN IEEE SYM FIELD P, P151, DOI [10.1109/FCCM.2007.38, 10.1109/FCCM.2007.40]
   Wang Z., 2018, ICDE
   Wang ZK, 2019, PROC VLDB ENDOW, V12, P807, DOI 10.14778/3317315.3317322
   Wang ZK, 2016, IEEE T PARALL DISTR, V27, P3547, DOI 10.1109/TPDS.2016.2537805
   Wang ZK, 2016, INT S HIGH PERF COMP, P114, DOI 10.1109/HPCA.2016.7446058
   Williamson T., 2013, VITREORETINAL SURG, V2nd ed., P1
   White S. A., 1989, IEEE ASSP Magazine, V6, P4, DOI 10.1109/44.41514
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
   Zhang HT, 2017, PR MACH LEARN RES, V70
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 49
TC 5
Z9 5
U1 0
U2 2
PY 2020
BP 233
EP 243
DI 10.1145/3373087.3375316
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Oppermann, J
   Sommer, L
   Weber, L
   Reuter-Oppermann, M
   Koch, A
   Sinnen, O
AF Oppermann, Julian
   Sommer, Lukas
   Weber, Lukas
   Reuter-Oppermann, Melanie
   Koch, Andreas
   Sinnen, Oliver
GP IEEE
TI SkyCastle: A Resource-Aware Multi-Loop Scheduler for High-Level
   Synthesis
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
AB A common optimisation problem in the high-level synthesis (HLS) of FPGA-based accelerators is to find a microarchitecture that maximises the performance while keeping the utilisation of the device's low-level resources below certain limits.
   We propose to tackle it directly as part of the HLS scheduler. To that end, we formalise a general, integrated scheduling and allocation problem for HLS kernels, and present SkyCastle, a novel resource-aware multi-loop scheduler using integer linear programming to solve it for a subclass of kernels composed of multiple, nested loops. In order to demonstrate the practical applicability of the approach, we model the scheduler in such a way as to be plug-in compatible with the Xilinx Vivado HLS engine, allowing the computed solutions to be fed back into its synthesis flow.
   We evaluate SkyCastle for three non-trivial kernels from the machine learning, signal processing, and physical simulation domains, on two FPGA devices. Additionally, we investigate the replication of slightly slower, but smaller accelerators as a means to further boost the overall performance. In contrast to Vivado HLS' default settings, which aim at maximum performance but may fail in later synthesis steps, the solutions computed by our scheduler always result in synthesisable designs.
C1 [Oppermann, Julian; Sommer, Lukas; Weber, Lukas; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
   [Reuter-Oppermann, Melanie] Karlsruhe Inst Technol, Discrete Optimizat & Logist Grp, Karlsruhe, Germany.
   [Sinnen, Oliver] Univ Auckland, Parallel & Reconfigurable Comp Lab, Auckland, New Zealand.
RP Oppermann, J (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM oppermann@esa.tu-darmstadt.de; sommer@esa.tu-darmstadt.de;
   weber@esa.tu-darmstadt.de; melanie.reuter@kit.edu;
   koch@esa.tu-darmstadt.de; o.sinnen@auckland.ac.nz
CR [Anonymous], 2013, LLNLTR641973
   Cong J., 2014, P 2014 ACMSIGDA INT, P213, DOI [10.1145/2554688.2554771, DOI 10.1145/2554688.2554771]
   Cong J, 2012, DES AUT TEST EUROPE, P1018
   Dua D, 2020, UCI MACHINE LEARNING
   Eichenberger A. E., 1997, P ACM SIGPLAN 97 C P
   Fan K, 2005, INT SYMP MICROARCH, P219
   Ferrandi Fabrizio, 2008, 2008 IEEE Computer Society Annual Symposium on VLSI, P417, DOI 10.1109/ISVLSI.2008.73
   Gurobi Optimization LLC., 2019, GUR DOC CONSTR
   Korinth Jens, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P214, DOI 10.1007/978-3-030-17227-5_16
   Kudlur M., 2006, P 4 INT C HARDW SOFT, P270, DOI 10.1145/1176254.1176321
   Li Peng, 2015, P 2015 ACM SIGDA INT, P200
   Molina A., 2018, MIXED SUM PRODUCT NE
   Nelson Brent E., 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P353, DOI 10.1007/978-3-030-17227-5_25
   Oppermann J, 2019, LECT NOTES COMPUT SC, V11725, P170, DOI 10.1007/978-3-030-29400-7_13
   Oppermann J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3317670
   Poon H., 2011, P UAI
   Prost-Boucle A, 2014, J SYST ARCHITECT, V60, P79, DOI 10.1016/j.sysarc.2013.10.002
   Reagen B, 2014, I S WORKL CHAR PROC, P110, DOI 10.1109/IISWC.2014.6983050
   Schafer BC, 2016, IEEE T COMPUT AID D, V35, P394, DOI 10.1109/TCAD.2015.2472007
   Solis-Vasquez L., 2018, 5 INT WORKSH FPGAS S
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Wang H., 2019, J ASTRONOMICAL INSTR
   Zhao JR, 2017, ICCAD-IEEE ACM INT, P430, DOI 10.1109/ICCAD.2017.8203809
   Zheming Jin, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P199, DOI 10.1007/978-3-030-17227-5_15
   Zhong GW, 2016, DES AUT CON, DOI 10.1145/2897937.2898040
NR 25
TC 1
Z9 1
U1 0
U2 1
PY 2019
BP 36
EP 44
DI 10.1109/ICFPT47387.2019.00013
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chow, M
   Ranganath, K
   Lerias, R
   Carodan, MS
   Wong, D
AF Chow, Marcus
   Ranganath, Kiran
   Lerias, Robert, Jr.
   Carodan, Mika Shanela
   Wong, Daniel
GP IEEE COMP SOC
TI Energy Efficient Task Graph Execution Using Compute Unit Masking in GPUs
SO PROCEEDINGS OF RSDHA 2021: REDEFINING SCALABILITY FOR DIVERSELY
   HETEROGENEOUS ARCHITECTURES
DT Proceedings Paper
CT Conference on Redefining Scalability for Diversely Heterogeneous
   Architectures (RSDHA)
CY NOV 19, 2021
CL St Louis, MO
DE DAGEE; Windograd-Strassen; Task Graph Execution; Compute Unit Masking;
   Resource Partitioning; Energy Efficient
AB The frontiers of Supercomputers are pushed by novel discrete accelerators. Accelerators such as GPUs are employed to enable faster execution of Machine Learning, Scientific and High-Performance Computing applications. However, it has been harder to gain increased parallelism in traditional workloads. This is why more focus has been into Task Graphs. AMD's Directed Acyclic Graph Execution Engine (DAGEE) allows the programmer to define a workload in fine-grained tasks, and the system handles the dependencies at the lower-level. We evaluate DAGEE with the Winograd-Strassen Matrix Multiplication algorithm and show that DAGEE achieves on average 15.3% speed up over the traditional matrix multiplication algorithm.
   While using DAGEE this may increase the contention among kernels due to the increased amount of parallelism. However, AMD allows the programmer to set the number of active Compute Unit (CU) by masking. This fine-grain scaling allows the system software to enable only the required number of Computation Units within a GPU. Using this mechanism we develop a Runtime that masks CU's for each task during a task graph execution and partitions each task into their separate CU's, reducing overall contention and energy consumption. We show that our CU Masking runtime on average reduces energy by 18%.
C1 [Chow, Marcus; Lerias, Robert, Jr.; Carodan, Mika Shanela] Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.
   [Ranganath, Kiran; Wong, Daniel] Univ Calif Riverside, Dept Elect & Comp Engn, Riverside, CA 92521 USA.
RP Chow, M (corresponding author), Univ Calif Riverside, Dept Comp Sci, Riverside, CA 92521 USA.
EM mchow009@ucr.edu; krang006@ucr.edu; rleri001@ucr.edu; mcaro008@ucr.edu;
   danwong@ucr.edu
CR A. M. D. (AMD), 2021, DIR AC GRAPH EX ENG
   A. M. D. (AMD, 2021, RAD OP COMP SOFTW PL
   Abdolrashidi A, 2021, CONF PROC INT SYMP C, P333, DOI 10.1109/ISCA52012.2021.00034
   Abdolrashidi A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P600, DOI 10.1145/3123939.3123976
   Dennis J. B., 1975, A preliminary architecture for a basic data-flow processor
   Dutu A, 2020, ANN I S COM, P1022, DOI 10.1109/ISCA45697.2020.00087
   Hines J, 2018, COMPUT SCI ENG, V20, P78, DOI 10.1109/MCSE.2018.021651341
   Huang J., 2018, 32 AAAI C ART INT
   Jahanshahi A., 2021, 2021 12 INT GREEN SU
   Jahanshahi A, 2020, IEEE COMPUT ARCHIT L, V19, P139, DOI 10.1109/LCA.2020.3023723
   L. L. N. Labs, 2021, EL CAP SUP
   Lai PW, 2013, INT C HIGH PERFORM, P139, DOI 10.1109/HiPC.2013.6799109
   N. Inc, 2019, NVID DGX 1 ESS INSTR
   Nvidia, 2019, CUD GRAPHS
   O. N. Labs, 2021, FRONT EX SUP
   Otterness N., 2020, 32 EUR C REAL TIM SY
   Otterness N, 2021, 29TH INTERNATIONAL CONFERENCE ON REAL TIME NETWORKS AND SYSTEMS (RTNS 2021), P24, DOI 10.1145/3453417.3453432
   PNNL, 2021, ABSTR RUNT SYST
   Ranganath K., 2021, SC21 INT C HIGH PERF
   Ranganath K., 2021, INT WORKSH LANG COMP
   Ranganath K, 2019, IEEE COMPUT ARCHIT L, V18, P128, DOI 10.1109/LCA.2019.2933842
   Tripathy D., 2021, P 15 IEEE ACM INT C
   Tripathy D, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3451164
   Tripathy Devashree, 2020, P ACMIEEE INT S LOW, P109
NR 24
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 45
EP 51
DI 10.1109/RSDHA54838.2021.00011
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Gonzalez, HA
   George, R
   Muzaffar, S
   Acevedo, J
   Höppner, S
   Mayr, C
   Yoo, J
   Fitzek, FHP
   Elfadel, IM
AF Gonzalez, Hector A.
   George, Richard
   Muzaffar, Shahzad
   Acevedo, Javier
   Hoeppner, Sebastian
   Mayr, Christian
   Yoo, Jerald
   Fitzek, Frank H. P.
   Elfadel, Ibrahim M.
TI Hardware Acceleration of EEG-Based Emotion Classification Systems: A
   Comprehensive Survey
SO IEEE TRANSACTIONS ON BIOMEDICAL CIRCUITS AND SYSTEMS
DT Article
DE Emotion detection and classification; EEG; hardware acceleration;
   machine learning; monitoring of neurological disorders
ID INDEPENDENT COMPONENT ANALYSIS; NEURAL-NETWORKS; IMPAIRED RECOGNITION;
   FACIAL EXPRESSIONS; FEATURE-SELECTION; BRAIN RESPONSES; SCALP EEG;
   MUSIC; IMPLEMENTATION; DESIGN
AB Recent years have witnessed a growing interest in EEG-based wearable classifiers of emotions, which could enable the real-time monitoring of patients suffering from neurological disorders such as Amyotrophic Lateral Sclerosis (ALS), Autism Spectrum Disorder (ASD), or Alzheimer's. The hope is that such wearable emotion classifiers would facilitate the patients' social integration and lead to improved healthcare outcomes for them and their loved ones. Yet in spite of their direct relevance to neuro-medicine, the hardware platforms for emotion classification have yet to fill up some important gaps in their various approaches to emotion classification in a healthcare context. In this paper, we present the first hardware-focused critical review of EEG-based wearable classifiers of emotions and survey their implementation perspectives, their algorithmic foundations, and their feature extraction methodologies. We further provide a neuroscience-based analysis of current hardware accelerators of emotion classifiers and use it to map out several research opportunities, including multi-modal hardware platforms, accelerators with tightly-coupled cores operating robustly in the near/supra-threshold region, and pre-processing libraries for universal EEG-based datasets.
C1 [Gonzalez, Hector A.; George, Richard; Hoeppner, Sebastian; Mayr, Christian] Tech Univ Dresden, Chair Highly Parallel VLSI Syst & Neuromorph Circ, D-01062 Dresden, Germany.
   [Acevedo, Javier; Fitzek, Frank H. P.] Tech Univ Dresden, Deutsch Telekom Chair Commun Networks, D-01187 Dresden, Germany.
   [Mayr, Christian; Fitzek, Frank H. P.] Tech Univ Dresden, Ctr Tactile Internet CeTi Human In The Loop, Cluster Excellence, Dresden, Germany.
   [Yoo, Jerald] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
   [Yoo, Jerald] 1 Inst Hlth, Singapore 117456, Singapore.
   [Muzaffar, Shahzad; Elfadel, Ibrahim M.] Khalifa Univ, Dept Elect Engn & Comp Sci, Abu Dhabi 127788, U Arab Emirates.
   [Muzaffar, Shahzad; Elfadel, Ibrahim M.] Khalifa Univ, Ctr Cyber Phys Syst C2PS, Abu Dhabi 127788, U Arab Emirates.
RP Gonzalez, HA (corresponding author), Tech Univ Dresden, Chair Highly Parallel VLSI Syst & Neuromorph Circ, D-01062 Dresden, Germany.
EM hector.gonzalez@tu-dresden.de; richard_miru.george@tu-dresden.de;
   shahzad.muzaffar@ku.ac.ae; javier.acevedo@tu-dresden.de;
   sebastian.hoeppner@tu-dresden.de; christian.mayr@tu-dresden.de;
   jyoo@nus.edu.sg; frank.fitzek@tu-dresden.de; ibrahim.elfadel@ku.ac.ae
CR Abtahi F, 2018, IEEE WINT CONF APPL, P10, DOI 10.1109/WACV.2018.00008
   Ackermann P, 2016, 2016 IEEE 18TH INTERNATIONAL CONFERENCE ON E-HEALTH NETWORKING, APPLICATIONS AND SERVICES (HEALTHCOM), P159
   Acunzo DJ, 2012, J NEUROSCI METH, V209, P212, DOI 10.1016/j.jneumeth.2012.06.011
   Al-Fahad R., 2019, P INT JOINT C NEUR N, P1
   Alakus TB, 2020, BIOMED SIGNAL PROCES, V60, DOI 10.1016/j.bspc.2020.101951
   Alarcao SM, 2019, IEEE T AFFECT COMPUT, V10, P374, DOI 10.1109/TAFFC.2017.2714671
   Alex M, 2020, IEEE ACCESS, V8, P191080, DOI 10.1109/ACCESS.2020.3032380
   Alhagry S, 2017, INT J ADV COMPUT SC, V8, P355, DOI 10.14569/IJACSA.2017.081046
   Ali M, 2016, INT CONF UBIQ FUTUR, P946, DOI 10.1109/ICUFN.2016.7536936
   Alsolamy M, 2016, INT CONF COMP SCI, DOI 10.1109/CSIT.2016.7549457
   [Anonymous], 2010, PROC IEEE WORLD C CO
   [Anonymous], 2020, IEEE INT SYMP CIRC S, P1, DOI [DOI 10.1109/ISCAS45731.2020.9180909, 10.1109/ISCAS45731.2020.9180909, DOI 10.1109/iscas45731.2020.9180909]
   [Anonymous], 2016, P STUD RES C INF INF
   [Anonymous], 2017, CC0 1 0
   Urigüen JA, 2015, J NEURAL ENG, V12, DOI 10.1088/1741-2560/12/3/031001
   Arikan K, 2006, CLIN EEG NEUROSCI, V37, P230, DOI 10.1177/155005940603700313
   Arnau-González P, 2019, IEEE IMAGE PROC, P2591, DOI [10.1109/ICIP.2019.8803315, 10.1109/icip.2019.8803315]
   Aslam A. R., 2019, P IEEE INT S CIRC SY, P1
   Aslam AR, 2020, IEEE CUST INTEGR CIR
   Aslam AR, 2020, IEEE T BIOMED CIRC S, V14, P838, DOI 10.1109/TBCAS.2020.3008766
   Atkinson J, 2016, EXPERT SYST APPL, V47, P35, DOI 10.1016/j.eswa.2015.10.049
   Baas BM, 1999, IEEE J SOLID-ST CIRC, V34, P380, DOI 10.1109/4.748190
   Bastos T., 2012, P 4 INT C INT HUM CO, P1, DOI [DOI 10.1109/IHCI.2012.6481860, 10.1109/IHCI.2012.6481860]
   Bhatti AM, 2016, COMPUT HUM BEHAV, V65, P267, DOI 10.1016/j.chb.2016.08.029
   Bigirimana AD, 2020, IEEE T NEUR SYS REH, V28, P850, DOI 10.1109/TNSRE.2020.2978951
   Blagojevic M., 2016, IEEE S VLSI CIRCUITS, P1
   Bol D, 2019, ISSCC DIG TECH PAP I, V62, P322, DOI 10.1109/ISSCC.2019.8662293
   BRADLEY MM, 1994, J BEHAV THER EXP PSY, V25, P49, DOI 10.1016/0005-7916(94)90063-9
   Brouwer AM, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00136
   Brown L, 2011, IEEE ENG MED BIO, P2188, DOI 10.1109/IEMBS.2011.6090412
   Bucks RS, 2004, AGING MENT HEALTH, V8, P222, DOI 10.1080/13607860410001669750
   Busek P, 2005, PHYSIOL RES, V54, P327, DOI 10.33549/physiolres.930551
   Candra H, 2017, IEEE ENG MED BIO, P463, DOI 10.1109/EMBC.2017.8036862
   Carter R, 2016, INT EL DEVICES MEET
   Cecbur, 2019, CC BY SA 4 0
   Chai T.-Y., 2010, INT J INTEGR ENG, V1, P71
   Chanel G, 2011, IEEE T SYST MAN CY A, V41, P1052, DOI 10.1109/TSMCA.2011.2116000
   Chanel G, 2009, INT J HUM-COMPUT ST, V67, P607, DOI 10.1016/j.ijhcs.2009.03.005
   Chao H, 2021, IEEE SENS J, V21, P2024, DOI 10.1109/JSEN.2020.3020828
   Chen JX, 2019, IEEE ACCESS, V7, P118530, DOI 10.1109/ACCESS.2019.2936817
   Chen JX, 2019, IEEE ACCESS, V7, P44317, DOI 10.1109/ACCESS.2019.2908285
   Chen J, 2015, APPL SOFT COMPUT, V30, P663, DOI 10.1016/j.asoc.2015.01.007
   Chen YH, 2020, IEEE T CIRCUITS-II, V67, P3437, DOI 10.1109/TCSII.2020.2999573
   Chen YH, 2020, IEEE T BIOMED CIRC S, V14, P373, DOI 10.1109/TBCAS.2020.2974049
   Cheng J, 2021, IEEE J BIOMED HEALTH, V25, P453, DOI 10.1109/JBHI.2020.2995767
   Cho K., 2014, P C EMP METH NAT LAN, P1724
   Clark Jr J. W., 1998, MED INSTRUMENTATION, V3, P121
   Clerc S, 2015, P IEEE INT SOL STAT, P1
   Coan JA, 2003, PSYCHOPHYSIOLOGY, V40, P106, DOI 10.1111/1469-8986.00011
   Craik A, 2019, J NEURAL ENG, V16, DOI 10.1088/1741-2552/ab0ab5
   Darwin C., 1872, P374
   Davidson RJ, 2003, PSYCHOPHYSIOLOGY, V40, P655, DOI 10.1111/1469-8986.00067
   Davis P, 2014, INT SYMP INTEGR CIRC, P248, DOI 10.1109/ISICIR.2014.7029468
   de Cheveigné A, 2018, NEUROIMAGE, V172, P903, DOI 10.1016/j.neuroimage.2018.01.035
   De Pascalis V, 2013, BIOL PSYCHOL, V94, P198, DOI 10.1016/j.biopsycho.2013.05.016
   DEJONG PJ, 1990, INT J NEUROSCI, V51, P89, DOI 10.3109/00207459009000513
   Dong HW, 2015, IEEE INT SYM MULTIM, P13, DOI 10.1109/ISM.2015.71
   Downs M., 2008, EXCELLENCE DEMENTIA
   Du XB, 2022, IEEE T AFFECT COMPUT, V13, P1528, DOI 10.1109/TAFFC.2020.3013711
   Duan RN, 2012, LECT NOTES COMPUT SC, V7666, P468, DOI 10.1007/978-3-642-34478-7_57
   Duan RN, 2013, I IEEE EMBS C NEUR E, P81, DOI 10.1109/NER.2013.6695876
   el Kaliouby R, 2006, ANN NY ACAD SCI, V1093, P228, DOI 10.1196/annals.1382.016
   EYSENCK SBG, 1985, PERS INDIV DIFFER, V6, P21, DOI 10.1016/0191-8869(85)90026-1
   Fang WC, 2019, IEEE J EM SEL TOP C, V9, P645, DOI 10.1109/JETCAS.2019.2951232
   Fdeloche, 2017, CC BY SA 4 0
   Fernandez-Duque D, 2005, NEUROPSYCHOLOGIA, V43, P1673, DOI 10.1016/j.neuropsychologia.2005.01.005
   Fletcher RR, 2010, IEEE T INF TECHNOL B, V14, P215, DOI 10.1109/TITB.2009.2038692
   Fries P, 2005, TRENDS COGN SCI, V9, P474, DOI 10.1016/j.tics.2005.08.011
   Gao ZK, 2021, IEEE T COGN DEV SYST, V13, P945, DOI 10.1109/TCDS.2020.2976112
   Gao ZK, 2020, IEEE T IND INFORM, V16, P7159, DOI 10.1109/TII.2019.2955447
   Gideon J, 2017, INTERSPEECH, P1098, DOI 10.21437/Interspeech.2017-1637
   Gläscher J, 2003, J NEUROSCI, V23, P10274
   Gonzalez HA, 2020, IEEE INT SYMP CIRC S
   Gonzalez HA, 2021, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS51556.2021.9401547
   Gonzalez HA, 2020, IEEE ACCESS, V8, P140896, DOI 10.1109/ACCESS.2020.3012900
   Gonzalez HA, 2019, IEEE ENG MED BIO, P694, DOI [10.1109/EMBC.2019.8857248, 10.1109/embc.2019.8857248]
   Gooding DC, 2002, SCHIZOPHR RES, V57, P109, DOI 10.1016/S0920-9964(01)00295-X
   Govindarajan V, 2018, IEEE INT C INTELL TR, P1017, DOI 10.1109/ITSC.2018.8569585
   Grundlehner B, 2019, ENCYCLOPEDIA OF BIOMEDICAL ENGINEERING, VOL 3, P223, DOI 10.1016/B978-0-12-801238-3.10885-2
   Guo KR, 2019, IEEE ENG MED BIO, P7088, DOI [10.1109/embc.2019.8857698, 10.1109/EMBC.2019.8857698]
   Guo KR, 2017, IEEE ENG MED BIO, P489, DOI 10.1109/EMBC.2017.8036868
   Gupta V, 2019, IEEE SENS J, V19, P2266, DOI 10.1109/JSEN.2018.2883497
   Hadjidimitriou SK, 2012, IEEE T BIO-MED ENG, V59, P3498, DOI 10.1109/TBME.2012.2217495
   Hargrave R, 2002, J NEUROPSYCH CLIN N, V14, P64, DOI 10.1176/appi.neuropsych.14.1.64
   Hasan M, 2002, ELECTRON LETT, V38, P163, DOI 10.1049/el:20020117
   Hatamikia Sepideh, 2014, J Med Signals Sens, V4, P194
   He ZP, 2020, BRAIN SCI, V10, DOI 10.3390/brainsci10100687
   HJORTH B, 1970, ELECTROEN CLIN NEURO, V29, P306, DOI 10.1016/0013-4694(70)90143-4
   Höppner S, 2019, PROC EUR S-STATE DEV, P66, DOI 10.1109/essderc.2019.8901768
   Hong YY, 2012, IEEE T INSTRUM MEAS, V61, P3175, DOI 10.1109/TIM.2012.2211460
   Höppner S, 2020, IEEE T CIRCUITS-II, V67, P2159, DOI 10.1109/TCSII.2019.2959544
   HOSSEINI SA, 2011, INT J IMAGE GRAPH SI, V3, DOI DOI 10.5815/IJIGSP.2011.05.05
   Hu B, 2018, IEEE ACM T COMPUT BI, V15, P38, DOI 10.1109/TCBB.2016.2616395
   Hu HY, 2018, IEEE INT VEH SYM, P156, DOI 10.1109/IVS.2018.8500444
   Huang D., 2012, 2012 INT JOINT C NEU, P1, DOI DOI 10.1109/IJCNN.2012.6252390
   Huang H., 2019, IEEE ACCESS, V8, P3265
   Huang JM, 2017, IEEE INT C BIOINFORM, P958, DOI 10.1109/BIBM.2017.8217786
   Huang WK, 2020, IEEE ACCESS, V8, P131636, DOI 10.1109/ACCESS.2020.3009665
   Huang YD, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919038
   Islam MK, 2016, NEUROPHYSIOL CLIN, V46, P287, DOI 10.1016/j.neucli.2016.07.002
   Issa S, 2021, IEEE T SYST MAN CY-S, V51, P7382, DOI 10.1109/TSMC.2020.2969686
   Jalilifard A, 2016, IEEE ENG MED BIO, P845, DOI 10.1109/EMBC.2016.7590833
   Jatupaiboon N, 2015, J MED IMAG HEALTH IN, V5, P1020, DOI 10.1166/jmihi.2015.1490
   Jatupaiboon N, 2013, INT JOINT CONF COMP, P21
   Jia X, 2020, IEEE SYS MAN CYBERN, P2452, DOI [10.1109/SMC42975.2020.9283159, 10.1109/smc42975.2020.9283159]
   Jiang JF, 2016, 2016 17TH IEEE/ACIS INTERNATIONAL CONFERENCE ON SOFTWARE ENGINEERING, ARTIFICIAL INTELLIGENCE, NETWORKING AND PARALLEL/DISTRIBUTED COMPUTING (SNPD), P105, DOI 10.1109/SNPD.2016.7515886
   Jie X, 2014, BIO-MED MATER ENG, V24, P1185, DOI 10.3233/BME-130919
   Jirayucharoensak S, 2014, SCI WORLD J, DOI 10.1155/2014/627892
   Jobst M., 2020, PROC 6 INT C EVENT B, P1, DOI [10.1109/EBCCSP51266.2020.9291357, DOI 10.1109/EBCCSP51266.2020.9291357]
   Kamae N, 2014, IEEE ASIAN SOLID STA, P53, DOI 10.1109/ASSCC.2014.7008858
   KAMINSKI MJ, 1991, BIOL CYBERN, V65, P203, DOI 10.1007/BF00198091
   Kang HJ, 2013, ELECTRON LETT, V49, DOI 10.1049/el.2013.2461
   Kang HJ, 2013, ELECTRON LETT, V49, P589, DOI 10.1049/el.2013.0689
   Karn RR, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON COGNITIVE COMPUTING (IEEE ICCC 2019), P90, DOI 10.1109/ICCC.2019.00027
   Katsigiannis S, 2018, IEEE J BIOMED HEALTH, V22, P98, DOI 10.1109/JBHI.2017.2688239
   Kelber F, 2020, NICE 20, DOI [10.1145/3381755.3381778, DOI 10.1145/3381755.3381778]
   Kemker R, 2018, AAAI CONF ARTIF INTE, P3390
   Khalili Z., 2009, Proceedings 2009 International Joint Conference on Neural Networks (IJCNN 2009 - Atlanta), P1571, DOI 10.1109/IJCNN.2009.5178854
   Khare SK, 2020, IEEE T INSTRUM MEAS, V69, P9609, DOI 10.1109/TIM.2020.3006611
   Khare SK, 2021, IEEE T NEUR NET LEAR, V32, P2901, DOI 10.1109/TNNLS.2020.3008938
   Khosrowabadi Reza, 2010, Proceedings of the 2010 20th International Conference on Pattern Recognition (ICPR 2010), P4242, DOI 10.1109/ICPR.2010.1031
   Kim BH, 2020, IEEE T AFFECT COMPUT, V11, P230, DOI 10.1109/TAFFC.2018.2790939
   Kirkpatricka J, 2017, P NATL ACAD SCI USA, V114, P3521, DOI 10.1073/pnas.1611835114
   Kiymik MK, 2005, COMPUT BIOL MED, V35, P603, DOI 10.1016/j.compbiomed.2004.05.001
   Knyazev GG, 2019, FRONT HUM NEUROSCI, V13, DOI 10.3389/fnhum.2019.00158
   Koelstra S, 2013, IMAGE VISION COMPUT, V31, P164, DOI 10.1016/j.imavis.2012.10.002
   Koelstra S, 2012, IEEE T AFFECT COMPUT, V3, P18, DOI 10.1109/T-AFFC.2011.15
   Koelstra S, 2010, LECT NOTES ARTIF INT, V6334, P89, DOI 10.1007/978-3-642-15314-3_9
   Krisnandhika B, 2017, 2017 INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS AND DEVICES (ICCED 2017), P50, DOI 10.1109/ICCED.2017.8019990
   Kroupi E, 2016, IEEE T AFFECT COMPUT, V7, P422, DOI 10.1109/TAFFC.2015.2496310
   Kumagai Y, 2017, IEEE ENG MED BIO, P2879, DOI 10.1109/EMBC.2017.8037458
   Kumar N, 2016, PROCEDIA COMPUT SCI, V84, P31, DOI 10.1016/j.procs.2016.04.062
   Lan ZR, 2016, VISUAL COMPUT, V32, P347, DOI 10.1007/s00371-015-1183-y
   LANG PJ, 1993, PSYCHOPHYSIOLOGY, V30, P261, DOI 10.1111/j.1469-8986.1993.tb03352.x
   Lee HY, 2007, IEEE T CIRCUITS-I, V54, P889, DOI 10.1109/TCSI.2006.888764
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P314, DOI 10.1109/ISSCC.2019.8662454
   Lee YY, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0095415
   Li G., 2017, IEEE, V1, P1, DOI [10.1109/BIOCAS.2017.8325198, DOI 10.1109/BIOCAS.2017.8325198]
   Li M, 2009, IEEE ENG MED BIO, P1323
   Li PY, 2019, IEEE T BIO-MED ENG, V66, P2869, DOI 10.1109/TBME.2019.2897651
   Li X, 2016, IEEE INT C BIOINFORM, P352, DOI 10.1109/BIBM.2016.7822545
   Li XY, 2019, IEEE DATA MINING, P389, DOI 10.1109/ICDM.2019.00049
   Li YJ, 2017, APPL SCI-BASEL, V7, DOI 10.3390/app7101060
   Liberati G, 2013, INT CONF AFFECT, P838, DOI 10.1109/ACII.2013.157
   Lin YP, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00094
   Lin YP, 2010, IEEE T BIO-MED ENG, V57, P1798, DOI 10.1109/TBME.2010.2048568
   Lin YP, 2009, INT CONF ACOUST SPEE, P489, DOI 10.1109/ICASSP.2009.4959627
   Liu C, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00840
   Liu NJ, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P896, DOI 10.1109/ICASSP.2018.8462518
   Liu SQ, 2021, IEEE ACM T COMPUT BI, V18, P1710, DOI 10.1109/TCBB.2020.3018137
   Liu S, 2017, IEEE ENG MED BIO, P2231, DOI 10.1109/EMBC.2017.8037298
   Liu S, 2016, IEEE ENG MED BIO, P841, DOI 10.1109/EMBC.2016.7590832
   Liu YH, 2013, IEEE ENG MED BIO, P4306, DOI 10.1109/EMBC.2013.6610498
   Liu YS, 2012, PROCEEDINGS OF THE 2012 INTERNATIONAL CONFERENCE ON CYBERWORLDS, P53, DOI 10.1109/CW.2012.15
   Long Short-Term Memory, 2017, CC BT SA 4 0
   Lotte F, 2018, J NEURAL ENG, V15, DOI [10.1088/1741-2552/aab2f2, 10.1088/1741-2560/4/2/R01]
   Lulé D, 2007, J NEUROL, V254, P519, DOI 10.1007/s00415-006-0409-3
   Luo YL, 2020, IEEE ACCESS, V8, P46007, DOI 10.1109/ACCESS.2020.2978163
   Luo Y, 2018, IEEE ENG MED BIO, P2535, DOI 10.1109/EMBC.2018.8512865
   Makeig S, 2011, LECT NOTES COMPUT SC, V6975, P487, DOI 10.1007/978-3-642-24571-8_61
   Marimpis AD, 2020, IEEE ACCESS, V8, P170928, DOI 10.1109/ACCESS.2020.3025370
   Marque C, 2005, J ELECTROMYOGR KINES, V15, P310, DOI 10.1016/j.jelekin.2004.10.001
   Mauss I, 2009, COGNITION EMOTION, V23, P209, DOI 10.1080/02699930802204677
   Mayr C., 2019, ARXIV191102385
   Mehmood RM, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3011817
   Mehmood RM, 2017, IEEE ACCESS, V5, P14797, DOI 10.1109/ACCESS.2017.2724555
   Mehmood RM, 2016, COMPUT ELECTR ENG, V53, P444, DOI 10.1016/j.compeleceng.2016.04.009
   Mikhail Mina, 2013, International Journal of Autonomous and Adaptive Communications Systems, V6, P80, DOI 10.1504/IJAACS.2013.050696
   Miranda-Correa JA, 2021, IEEE T AFFECT COMPUT, V12, P479, DOI 10.1109/TAFFC.2018.2884461
   Mohammadi Z, 2017, NEURAL COMPUT APPL, V28, P1985, DOI 10.1007/s00521-015-2149-8
   Mohammadpour M, 2017, 2017 ARTIFICIAL INTELLIGENCE AND ROBOTICS (IRANOPEN), P127, DOI 10.1109/RIOS.2017.7956455
   Moon SE, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P2556, DOI 10.1109/ICASSP.2018.8461315
   Mostafa H, 2011, IEEE T VLSI SYST, V19, P1848, DOI 10.1109/TVLSI.2010.2060503
   Murugappan M, 2013, 2013 IEEE 9TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING AND ITS APPLICATIONS (CSPA), P289, DOI 10.1109/CSPA.2013.6530058
   Murugappan M., 2009, International Journal of Medical Engineering and Informatics, V1, P342, DOI 10.1504/IJMEI.2009.022645
   Nasehi S., 2012, WSEAS T SIGNAL PROCE, V3, P87
   Nie D, 2011, I IEEE EMBS C NEUR E, P667, DOI 10.1109/NER.2011.5910636
   Nunez PL, 2006, ELECT FIELDS BRAIN N
   Onton J., 2020, IMAGINED EMOTION STU
   Pan JH, 2016, IEEE IJCNN, P2063, DOI 10.1109/IJCNN.2016.7727453
   Pan SJ, 2010, IEEE T KNOWL DATA EN, V22, P1345, DOI 10.1109/TKDE.2009.191
   Panayiotou G, 2017, PSYCHOPHYSIOLOGY, V54, P1323, DOI 10.1111/psyp.12887
   PAPEZ JW, 1995, J NEUROPSYCH CLIN N, V7, P103
   Parisi GI, 2019, NEURAL NETWORKS, V113, P54, DOI 10.1016/j.neunet.2019.01.012
   Park C. Y, 2020, **DATA OBJECT**, DOI [10.5281/zenodo.3814370, DOI 10.5281/ZENODO.3814370]
   Parra LC, 2005, NEUROIMAGE, V28, P326, DOI 10.1016/j.neuroimage.2005.05.032
   Petrantonakis PC, 2010, IEEE T AFFECT COMPUT, V1, P81, DOI 10.1109/T-AFFC.2010.7
   Petrantonakis PC, 2010, IEEE T INF TECHNOL B, V14, P186, DOI 10.1109/TITB.2009.2034649
   Phan KL, 2002, NEUROIMAGE, V16, P331, DOI 10.1006/nimg.2002.1087
   Picard RW, 2009, PHILOS T R SOC B, V364, P3575, DOI 10.1098/rstb.2009.0143
   Poh MZ, 2010, IEEE T BIO-MED ENG, V57, P1243, DOI 10.1109/TBME.2009.2038487
   Pons M., 2019, PROC IEEE CICC, P1
   Posner J, 2005, DEV PSYCHOPATHOL, V17, P715, DOI 10.1017/S0954579405050340
   Pu Y, 2010, IEEE J SOLID-ST CIRC, V45, P668, DOI 10.1109/JSSC.2009.2039684
   Quelen A, 2018, ISSCC DIG TECH PAP I, P304, DOI 10.1109/ISSCC.2018.8310305
   Rahman FU, 2019, ISSCC DIG TECH PAP I, V62, P312, DOI 10.1109/ISSCC.2019.8662486
   Richman JS, 2000, AM J PHYSIOL-HEART C, V278, pH2039
   Rudovic O, 2018, SCI ROBOT, V3, DOI 10.1126/scirobotics.aao6760
   Salama ES, 2018, INT J ADV COMPUT SC, V9, P329
   Saligane M., 2018, P IEEE S VLSI CIRC, P63
   Sazgar M., 2019, ABSOLUTE EPILEPSY EE, P149, DOI DOI 10.1007/978-3-030-03511-2_8
   Schneider T.R., 2010, SIMULTANEOUS EEG FMR, P121, DOI DOI 10.1093/ACPROF:OSO/9780195372731.003.0008
   Setianingrum AH, 2018, 2018 6TH INTERNATIONAL CONFERENCE ON CYBER AND IT SERVICE MANAGEMENT (CITSM), P407
   Shahabi H, 2016, COMPUT HUM BEHAV, V58, P231, DOI 10.1016/j.chb.2016.01.005
   Shen LL, 2020, IEEE ACCESS, V8, P222966, DOI 10.1109/ACCESS.2020.3039542
   Sheykhivand S, 2020, IEEE ACCESS, V8, P139332, DOI 10.1109/ACCESS.2020.3011882
   Singh K, 2021, IEEE T CIRCUITS-II, V68, P5, DOI 10.1109/TCSII.2020.3040970
   Small DM, 2003, NEURON, V39, P701, DOI 10.1016/S0896-6273(03)00467-7
   Sohaib Ahmad Tauseef, 2013, Foundations of Augmented Cognition. 7th International Conference, AC 2013. Held as Part of HCI International 2013. Proceedings, P492, DOI 10.1007/978-3-642-39454-6_53
   Soleymani M, 2016, IEEE T AFFECT COMPUT, V7, P17, DOI 10.1109/TAFFC.2015.2436926
   Soleymani M, 2015, INT CONF AFFECT, P491, DOI 10.1109/ACII.2015.7344615
   Soleymani M, 2012, IEEE T AFFECT COMPUT, V3, P42, DOI 10.1109/T-AFFC.2011.25
   Song TF, 2020, IEEE T AFFECT COMPUT, V11, P532, DOI 10.1109/TAFFC.2018.2817622
   Sornmo L, 2005, BIOELECTRICAL SIGNAL, V8
   Stikic M, 2014, BRAIN-COMPUT INTERFA, V1, P99, DOI 10.1080/2326263X.2014.912883
   Stone DB, 2018, FRONT HUM NEUROSCI, V12, DOI 10.3389/fnhum.2018.00096
   Sweeney KT, 2012, IEEE T INF TECHNOL B, V16, P488, DOI 10.1109/TITB.2012.2188536
   Tamburro G, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00441
   Tang T, 2020, IEEE T BIOMED CIRC S, V14, P1253, DOI 10.1109/TBCAS.2020.3039353
   Tanner D, 2015, PSYCHOPHYSIOLOGY, V52, P997, DOI 10.1111/psyp.12437
   Tao L, 2020, IEEE INT SYM BROADB, DOI 10.1109/BMSB49480.2020.9379645
   Tao XM, 2019, IEEE J SEL AREA COMM, V37, P1549, DOI 10.1109/JSAC.2019.2916453
   Teo J, 2017, AIP CONF PROC, V1891, DOI 10.1063/1.5005474
   Thammasan N, 2016, IEEE IJCNN, P881, DOI 10.1109/IJCNN.2016.7727292
   Nguyen T, 2019, IEEE T MED IMAGING, V38, P2423, DOI 10.1109/TMI.2019.2900978
   Pham TD, 2012, LECT NOTES COMPUT SC, V7667, P394, DOI 10.1007/978-3-642-34500-5_47
   Tsai WL, 2018, 2018 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2018), P183, DOI 10.1109/APCCAS.2018.8605656
   Ullah H, 2019, IEEE ACCESS, V7, P40144, DOI 10.1109/ACCESS.2019.2904400
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vanhatalo S, 2004, P NATL ACAD SCI USA, V101, P5053, DOI 10.1073/pnas.0305375101
   Vijayan AE, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTATIONAL INTELLIGENCE AND COMMUNICATION TECHNOLOGY CICT 2015, P587, DOI 10.1109/CICT.2015.24
   Wallstrom GL, 2004, INT J PSYCHOPHYSIOL, V53, P105, DOI 10.1016/j.ijpsycho.2004.03.007
   Walter D, 2020, PROC IEEE COOL CHIPS, DOI 10.1109/coolchips49199.2020.9097639
   Wang KY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P142, DOI [10.1109/AICAS.2019.8771581, 10.1109/aicas.2019.8771581]
   Wang KY, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P102, DOI [10.1109/AICAS.2019.8771616, 10.1109/aicas.2019.8771616]
   Wang KJ, 2019, IEEE ROMAN, DOI 10.1109/ro-man46459.2019.8956382
   Wang XW, 2014, NEUROCOMPUTING, V129, P94, DOI 10.1016/j.neucom.2013.06.046
   Wang XW, 2011, LECT NOTES COMPUT SC, V7062, P734, DOI 10.1007/978-3-642-24955-6_87
   Wang XX, 2012, IEEE T VLSI SYST, V20, P1405, DOI 10.1109/TVLSI.2011.2158124
   Wang XH, 2018, IEEE INT C BIOINFORM, P1240, DOI 10.1109/BIBM.2018.8621147
   Wang Y., 2016, BMVC, P1, DOI [10.1109/IJCNN.2018.8489715, DOI 10.1109/IJCNN.2018.8489715, 10.1145/2851141.2851145]
   Wang YX, 2017, PROC CVPR IEEE, P3029, DOI 10.1109/CVPR.2017.323
   Wang ZM, 2019, IEEE ACCESS, V7, P93711, DOI 10.1109/ACCESS.2019.2927768
   Wei CS, 2019, I IEEE EMBS C NEUR E, P328, DOI [10.1109/ner.2019.8716937, 10.1109/icsess47205.2019.9040810, 10.1109/NER.2019.8716937]
   Wei Y, 2020, IEEE T BIOMED CIRC S, V14, P145, DOI 10.1109/TBCAS.2020.2974154
   Widmann A, 2015, J NEUROSCI METH, V250, P34, DOI 10.1016/j.jneumeth.2014.08.002
   Wood KH, 2014, EMOTION, V14, P693, DOI 10.1037/a0036636
   Wu DP, 2021, IEEE J SEL AREA COMM, V39, P479, DOI 10.1109/JSAC.2020.3020677
   Wu H, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01275
   Xu HY, 2016, IEEE INT WORKSH MULT
   Xu HY, 2012, IEEE INT WORKSH MULT, P299, DOI 10.1109/MMSP.2012.6343458
   Yan Y., 2020, ARXIV200908921
   Yan YX, 2019, IEEE T BIOMED CIRC S, V13, P579, DOI 10.1109/TBCAS.2019.2906401
   Yanagimoto M, 2016, 2016 IEEE 9TH INTERNATIONAL WORKSHOP ON COMPUTATIONAL INTELLIGENCE AND APPLICATIONS (IWCIA), P27, DOI 10.1109/IWCIA.2016.7805744
   Yang HC, 2019, INT CONF ACOUST SPEE, P1184, DOI 10.1109/ICASSP.2019.8683290
   Yang YM, 2018, IEEE T COGN DEV SYST, V10, P408, DOI 10.1109/TCDS.2017.2685338
   Yang Y, 2019, IEEE T MULTIMEDIA, V21, P809, DOI 10.1109/TMM.2018.2867742
   Yao DZ, 2001, PHYSIOL MEAS, V22, P693, DOI 10.1088/0967-3334/22/4/305
   Yazdani A., 2009, PROC SIGMM WORKSHOP, P81
   Yeung N, 2004, PSYCHOPHYSIOLOGY, V41, P822, DOI 10.1111/j.1469-8986.2004.00239.x
   Yisi Liu, 2014, Transactions on Computational Science XXIII. Special Issue on Cyberworlds: LNCS 8490, P199, DOI 10.1007/978-3-662-43790-2_11
   Yoo J., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P292, DOI 10.1109/ISSCC.2012.6177019
   Yoon HJ, 2013, COMPUT BIOL MED, V43, P2230, DOI 10.1016/j.compbiomed.2013.10.017
   Yu C, 2015, IEEE T VLSI SYST, V23, P1793, DOI 10.1109/TVLSI.2014.2350017
   Yushu Zhao, 2019, 2019 IEEE 4th Advanced Information Technology, Electronic and Automation Control Conference (IAEAC), P1959, DOI 10.1109/IAEAC47372.2019.8997704
   Yuval-Greenberg S, 2008, NEURON, V58, P429, DOI 10.1016/j.neuron.2008.03.027
   Zaitchik D, 2006, NEUROPSYCHOLOGY, V20, P11, DOI 10.1037/0894-4105.20.1.11
   Zeng GX, 2019, NAT MACH INTELL, V1, P364, DOI 10.1038/s42256-019-0080-x
   Zenke F, 2017, PR MACH LEARN RES, V70
   Zhang K., 2020, SENSORS-BASEL, V6321, P1
   Zhang T, 2022, IEEE T AFFECT COMPUT, V13, P379, DOI 10.1109/TAFFC.2019.2937768
   Zhang T, 2019, IEEE T CYBERNETICS, V49, P839, DOI 10.1109/TCYB.2017.2788081
   Zhao GZ, 2018, IEEE T AFFECT COMPUT, V9, P362, DOI 10.1109/TAFFC.2017.2786207
   Zhao K., 2019, PROC IEEE INT S CIRC, P1
   Zhao W., 2018, 2018 MULTIDISCIP ANA, P1, DOI DOI 10.2514/6.2018-3424
   Zhao Y., 2020, P INT JOINT C NEUR N, P1
   Zheng WL, 2015, IEEE T AUTON MENT DE, V7, P162, DOI 10.1109/TAMD.2015.2431497
   Zheng WM, 2017, IEEE T COGN DEV SYST, V9, P281, DOI 10.1109/TCDS.2016.2587290
NR 278
TC 9
Z9 9
U1 14
U2 42
PD JUN
PY 2021
VL 15
IS 3
BP 412
EP 442
DI 10.1109/TBCAS.2021.3089132
WC Engineering, Biomedical; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhao, SR
   Shah, N
   Meert, W
   Verhelst, M
AF Zhao, Shirui
   Shah, Nimish
   Meert, Wannes
   Verhelst, Marian
BE Bolchini, C
   Verbauwhede, I
   Vatajelu, I
TI Discrete Samplers for Approximate Inference in Probabilistic Machine
   Learning
SO PROCEEDINGS OF THE 2022 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2022)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 25th Design, Automation and Test in Europe Conference and Exhibition
   (DATE)
CY MAR 14-23, 2022
CL ELECTR NETWORK
DE Probabilistic models; approximate inference; discrete sampling; CDT
   algorithm; Knuth-Yao algorithm
AB Probabilistic reasoning models (PMs) and probabilistic inference bring advantages when dealing with small datasets or uncertainty on the observed data, and allow to integrate expert knowledge and create interpretable models. The main challenge of using these PMs in practice is that their inference is very compute-intensive. Therefore, custom hardware architectures for the exact and approximate inference of PMs have been proposed in the SotA. The throughput, energy and area efficiency of approximate PM inference accelerators are strongly dominated by the sampler blocks required to sample arbitrary discrete distributions.
   This paper proposes and studies novel discrete sampler architectures towards efficient and flexible hardware implementations for PM accelerators. Both cumulative distribution table (CDT) and Knuth-Yao (KY) based sampling algorithms are assessed, based on which different sampler hardware architectures were implemented. Innovation is brought in terms of a reconfigurable CDT sampling architecture with a flexible range and a reconfigurable Knuth-Yao sampling architecture that supports both flexible range and dynamic precision. All architectures are benchmarked on real-world Bayesian Networks, demonstrating up to 13x energy efficiency benefits and 11x area efficiency improvement of the optimized reconfigurable Knuth-Yao sampler over the traditional linear CDT-based samplers used in the PM SotA.
C1 [Zhao, Shirui; Shah, Nimish; Verhelst, Marian] Katholieke Univ Leuven, MICAS ESAT, Leuven, Belgium.
   [Meert, Wannes] Katholieke Univ Leuven, DTAI, Leuven, Belgium.
RP Zhao, SR (corresponding author), Katholieke Univ Leuven, MICAS ESAT, Leuven, Belgium.
EM shirui.zhao@kuleuven.be; nimish.shah@kuleuven.be;
   wannes.meert@kuleuven.be; marian.verhelst@kuleuven.be
CR [Anonymous], BAYESIAN NETWORK REP
   Banerjee U, 2019, ISSCC DIG TECH PAP I, V62, P46, DOI 10.1109/ISSCC.2019.8662528
   Guo H., 2002, JOINT WORKSH REAL TI
   Howe J, 2018, IEEE T COMPUT, V67, P322, DOI 10.1109/TC.2016.2642962
   Knuth DE, 1976, ALGORITHMS COMPLEXIT, P357
   Ko G. G., 2020, 2020 IEEE S VLSI CIR, P1
   Kong L, 2021, IEEE T COMPUT, V70, P1019, DOI 10.1109/TC.2020.3001170
   Laurel J, DESIGN AUTOMATION C, P2021
   Li DD, 2021, IEEE WCNC, DOI 10.1109/WCNC49053.2021.9417554
   Ni Y, IEEE ACCESS, V9, P2021
   Roy SS, 2014, LECT NOTES COMPUT SC, V8282, P383
   Saad FA, 2020, PR MACH LEARN RES, V108, P1036
   Song SM, 2018, IEEE CUST INTEGR CIR
   Wu Y., 2016, ARXIV PREPRINT ARXIV
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1221
EP 1226
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Industrial;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jamieson, M
   Brown, N
AF Jamieson, Maurice
   Brown, Nick
TI High level programming abstractions for leveraging hierarchical memories
   with micro-core architectures
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article; Proceedings Paper
CT Exascale Applications and Software Conference (EASC)
CY APR 17-19, 2018
CL Edinburgh, SCOTLAND
DE Parallel programming languages; Interpreters; Runtime environments;
   Hardware accelerators; Neural networks
AB Micro-core architectures combine many low memory, low power computing cores together in a single package. These are attractive for use as accelerators but due to limited on-chip memory and multiple levels of memory hierarchy, the way in which programmers offload kernels needs to be carefully considered. In this paper we use Python as a vehicle for exploring the semantics and abstractions of higher level programming languages to support the offloading of computational kernels to these devices. By moving to a pass by reference model, along with leveraging memory kinds, we demonstrate the ability to easily and efficiently take advantage of multiple levels in the memory hierarchy, even ones that are not directly accessible to the micro-cores. Using a machine learning benchmark, we perform experiments on both Epiphany-Ill and MicroBlaze based micro-cores, demonstrating the ability to compute with data sets of arbitrarily large size. To provide context of our results, we explore the performance and power efficiency of these technologies, demonstrating that whilst these two micro-core technologies are competitive within their own embedded class of hardware, there is still a way to go to reach HPC class GPUs. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Jamieson, Maurice; Brown, Nick] Univ Edinburgh, EPCC, Bayes Ctr, 47 Potterrow, Edinburgh, Midlothian, Scotland.
RP Jamieson, M (corresponding author), Univ Edinburgh, EPCC, Bayes Ctr, 47 Potterrow, Edinburgh, Midlothian, Scotland.
EM maurice.jamieson@ed.ac.uk
CR Agarwal N, 2016, INT S HIGH PERF COMP, P494, DOI 10.1109/HPCA.2016.7446089
   Al Kadi M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3173548
   [Anonymous], 2016, ARXIV160107133
   [Anonymous], 2013, EP ARCH REF
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2017, 1 WORKSH COMP ARCH R
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2013, OPENMP APPL PROGRAM
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], 2017, INTEGRATION, DOI DOI 10.1109/ACCESS.2017.2671881
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Brown N, 2016, PROCEEDINGS OF PYHPC2016: 6TH WORKSHOP ON PYTHON FOR HIGH-PERFORMANCE AND SCIENTIFIC COMPUTING, P59, DOI [10.1109/PyHPC.2016.012, 10.1109/PyHPC.2016.8]
   Cantalupo C., 2015, TECHNICAL REPORT
   Castro FM, 2019, CONCURR COMP-PRACT E, V31, DOI 10.1002/cpe.4786
   deDinechin B.D., 2015, 2015 IEEE HOT CHIPS, P1
   Dongarra JJ, 2003, CONCURR COMP-PRACT E, V15, P803, DOI 10.1002/cpe.728
   Lam Siu Kwan, 2015, P 2 WORKSH LLVM COMP, DOI DOI 10.1145/2833157.2833162
   Landaverde Raphael, 2014, IEEE Conf High Perform Extreme Comput, V2014, DOI 10.1109/HPEC.2014.7040988
   Lysecky R, 2005, DES AUT TEST EUROPE, P18, DOI 10.1109/DATE.2005.38
   Lysecky R, 2006, ACM T DES AUTOMAT EL, V11, P659, DOI 10.1145/1142980.1142986
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Sakharnykh Nikolay., 2017, MAXIMIZING UNIFIED M
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Wolf C., 2019, PICORV32 SIZE OPTIMI
NR 39
TC 0
Z9 0
U1 0
U2 6
PD APR
PY 2020
VL 138
BP 128
EP 138
DI 10.1016/j.jpdc.2019.11.011
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Abdelgawad, MAA
   Cheung, RCC
   Yan, H
AF Abdelgawad, M. A. A.
   Cheung, Ray C. C.
   Yan, Hong
GP IEEE
TI A High-Performance FPGA Accelerator for CUR Decomposition
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
DE CUR decomposition; low-rank decomposition; high level synthesis; SVD and
   QR decomposition
AB A matrix factorization is to decompose a matrix into a product of smaller matrices. It is widely used in machine learning algorithms. There are many matrix decomposition algorithms, and each has various applications. CUR matrix decomposition is a widely-used factorization tool that has been employed for dimension reduction and pattern recognition in many scientific and engineering applications, such as image processing, text mining, and wireless communications. In this paper we propose an efficient FPGA-based floating-point accelerator using high-level synthesis (HLS) for the CUR decomposition algorithm. Our experiment results demonstrate the better efficiency of our hardware design compared to the optimized CPU-based software solutions. The speedup of our FPGA-based architecture over the optimized software implementation ranges from 2.37 to 16.82 times for different dimensions of the data input matrix. We evaluated our design using large dimension matrices 1024x1024 and 2048 x 2048 and the experiment results demonstrated the efficiency of our design in terms of the utilized resources and latency. Finally, we have compared our design with other matrix decomposition algorithms such as SVD and QR decomposition, the experiment results demonstrated that CUR is more efficient than SVD and QR decomposition in terms of latency and required resources.
C1 [Abdelgawad, M. A. A.; Cheung, Ray C. C.; Yan, Hong] City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
RP Abdelgawad, MAA (corresponding author), City Univ Hong Kong, Dept Elect Engn, Hong Kong, Peoples R China.
EM mabdelgaw2-c@my.cityu.edu.hk; r.cheung@cityu.edu.hk; h.yan@cityu.edu.hk
CR Bien J., 2010, ADV NEURAL INFORM PR, V23
   Drineas P., 2007, LINEAR ALGEBRA ITS A, V420, P553
   Drineas P, 2008, SIAM J MATRIX ANAL A, V30, P844, DOI 10.1137/07070471X
   Drineas P, 2006, SIAM J COMPUT, V36, P184, DOI 10.1137/S0097539704442702
   Gittens A., 2013, P 30 INT C MACHINE L, P567
   Hamm K., 2020, STABILITY SAMPLING C
   Hoyer Patrik O, 2004, J MACHINE LEARNING R, V5, P9
   Jolliffe IT., 2002, CHEMOMETR INTELL LAB, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1016/0169-7439(87)80084-9]
   Khichadia I., 2021, 2021 INT C COMM INF, P1
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Lee DD, 1999, NATURE, V401, P788, DOI 10.1038/44565
   Mahoney MW, 2009, P NATL ACAD SCI USA, V106, P697, DOI [10.1073/pnas.0803205105, 10.1073/pnas.0803205106]
   OLoughlin D., 2014, XILINX VIVADO HIGH L
   Skalicky S, 2013, LECT NOTES COMPUT SC, V7806, P146, DOI 10.1007/978-3-642-36812-7_14
   Sorensen DC, 2016, SIAM J SCI COMPUT, V38, pA1454, DOI 10.1137/140978430
   Sun JM, 2007, PROCEEDINGS OF THE SEVENTH SIAM INTERNATIONAL CONFERENCE ON DATA MINING, P366
   Thurau C., 2012, P 2012 SIAM INT C DA, P684, DOI 10.1137/1.9781611972825.59
   Younes H, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10020205
   Zhao XW, 2018, IEEE ACCESS, V6, P3031, DOI 10.1109/ACCESS.2017.2786681
   Zhuo L, 2008, IEEE T COMPUT, V57, P1057, DOI 10.1109/TC.2008.55
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 294
EP 299
DI 10.1109/FPL57034.2022.00052
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Zhu, ZH
   Sun, HB
   Lin, YJ
   Dai, GH
   Xia, LX
   Han, S
   Wang, Y
   Yang, HZ
AF Zhu, Zhenhua
   Sun, Hanbo
   Lin, Yujun
   Dai, Guohao
   Xia, Lixue
   Han, Song
   Wang, Yu
   Yang, Huazhong
GP ACM
TI A Configurable Multi-Precision CNN Computing Framework Based on Single
   Bit RRAM
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB Convolutional Neural Networks (CNNs) play a vital role in machine learning. Emerging resistive random-access memories (RRAMs) and RRAM-based Processing-In-Memory architectures have demonstrated great potentials in boosting both the performance and energy efficiency of CNNs. However, restricted by the immature process technology, it is hard to implement and fabricate a CNN accelerator chip based on multi-bit RRAM devices. In addition, existing single bit RRAM based CNN accelerators only focus on binary or ternary CNNs which have more than 10% accuracy loss compared with full precision CNNs. This paper proposes a con. gurable multi-precision CNN computing framework based on single bit RRAM, which consists of an RRAM computing overhead aware network quantization algorithm and a con. gurable multi-precision CNN computing architecture based on single bit RRAM. The proposed method can achieve equivalent accuracy as full precision CNN but also with lower storage consumption and latency via multiple precision quantization. The designed architecture supports for accelerating the multi-precision CNNs even with various precision among different layers. Experiment results show that the proposed framework can reduce 70% computing area and 75% computing energy on average, with nearly no accuracy loss. And the equivalent energy efficiency is 1.6 similar to 8.6x compared with existing RRAM based architectures with only 1.07% area overhead.
C1 [Zhu, Zhenhua; Sun, Hanbo; Dai, Guohao; Wang, Yu; Yang, Huazhong] Tsinghua Univ, BNRist, Dept EE, Beijing, Peoples R China.
   [Lin, Yujun; Han, Song] MIT, Dept EECS, Cambridge, MA 02139 USA.
   [Xia, Lixue] Alibaba Grp, Hangzhou, Zhejiang, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, BNRist, Dept EE, Beijing, Peoples R China.
EM yu-wang@tsinghua.edu.cn
CR [Anonymous], ISCA 2016
   [Anonymous], 2014, CIFAR 10 OBJECT RECO
   [Anonymous], HPCA 2017
   [Anonymous], ISCA 2016
   [Anonymous], DAC 2015
   [Anonymous], DAC 2016
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], CVPR 2016
   Chang MF, 2014, ISSCC DIG TECH PAP I, V57, P332, DOI 10.1109/ISSCC.2014.6757457
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Choo KD, 2016, ISSCC DIG TECH PAP I, V59, P460, DOI 10.1109/ISSCC.2016.7418106
   Kull L, 2017, ISSCC DIG TECH PAP I, P474, DOI 10.1109/ISSCC.2017.7870467
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin JL, 2018, DES AUT TEST EUROPE, P407, DOI 10.23919/DATE.2018.8342044
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Saberi M, 2011, IEEE T CIRCUITS-I, V58, P1736, DOI 10.1109/TCSI.2011.2107214
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xia L., 2016, P 53 ACMEDACIEEE ANN, P1
   Zhou S., 2016, DOREFANET TRAINING L
   Zhu Z., 2018, ICCAD, P1
NR 24
TC 53
Z9 54
U1 2
U2 7
PY 2019
DI 10.1145/3316781.3317739
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Xu, SY
   Schafer, BC
AF Xu, Siyuan
   Schafer, Benjamin Carrion
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI On the Design of High Performance HW Accelerator through High-level
   Synthesis Scheduling Approximations
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
DE Approximate Computing; High-level Synthesis; Machine Learning;
   Behavioral Hardware Accelerators
AB High-level synthesis (HLS) takes as input a behavioral description (e.g. C/C++) and generates efficient hardware through three main steps: allocation, scheduling, and binding. The scheduling step, times the operations in the behavioral description by scheduling different portions of the code at unique clock steps (control steps). The code portions assigned to each clock step mainly depend on the target synthesis frequency and target technology. This work makes use of this to generate smaller and faster circuits by approximating the program portions scheduled in each clock step and by exploiting the slack between different scheduling step to further increase the performance/reduce the latency of the resultant circuit. In particular, each individual scheduling step is approximated given a maximum error boundary and a library of different approximation techniques. In order to further optimize the resultant circuit, different scheduling steps are merged based on the timing slack of different control step without violating the given timing constraint (target frequency). Experimental results from different domain-specific applications show that our method works well and is able to increase the throughput on average by 82% while at the same time reducing the area by 21% for a given maximum allowable error.
C1 [Xu, Siyuan; Schafer, Benjamin Carrion] Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
RP Xu, SY (corresponding author), Univ Texas Dallas, Dept Elect & Comp Engn, Richardson, TX 75083 USA.
EM siyuan.xu@utdallas.edu; schaferb@utdallas.edu
CR [Anonymous], 2019, NEC CYBERWORKBENCH
   [Anonymous], APPL CONVERSION RES
   [Anonymous], 2014, PROC DESIGN AUTOM TE
   Baek W, 2010, ACM SIGPLAN NOTICES, V45, P198, DOI 10.1145/1809028.1806620
   Cadence, 2019, STRAT
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Dosselmann R., 2005, CAN C EL COMP ENG SA, P1906
   Grigorian B, 2014, PR IEEE COMP DESIGN, P317, DOI 10.1109/ICCD.2014.6974700
   Gupta P, 2011, NANOELECTRONIC CIRCUIT DESIGN, P409, DOI 10.1007/978-1-4419-7609-3_12
   Khudia DS, 2016, IEEE DES TEST, V33, P43, DOI 10.1109/MDAT.2015.2501306
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Li CF, 2015, DES AUT CON, DOI 10.1145/2744769.2744863
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Liu C., 2014, 2014 IEEE Nuclear Science Symposium and Medical Imaging Conference (NSS/MIC), P1, DOI 10.1109/NSSMIC.2014.7431111
   Meng JY, 2009, INT PARALL DISTRIB P, P107
   Mentor Graphics, 2019, CATAP
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mohammadhassani A., 2018, 2018 8 INT C COMP KN
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   Schafer BC, 2014, IEEE EMBED SYST LETT, V6, P53, DOI 10.1109/LES.2014.2320556
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Wu Y, 2017, ASIA S PACIF DES AUT, P163, DOI 10.1109/ASPDAC.2017.7858314
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Xu S., 2019, 38 IEEE ACM INT C CO
   Xu SY, 2017, IEEE T VLSI SYST, V25, P3077, DOI 10.1109/TVLSI.2017.2735299
   Yazdanbakhsh A., 2016, IEEE DESIGN TEST
NR 26
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 1378
EP 1383
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kamath, AK
   Abi-Karam, S
   Bhat, A
   Hao, C
AF Kamath, Akshay Karkal
   Abi-Karam, Stefan
   Bhat, Ashwin
   Hao, Cong
BE IEEE
TI M5: Multi-modal Multi-task Model Mapping on Multi-FPGA with Accelerator
   Configuration Search
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE Multi-FPGA; DNN Model Mapping Framework
AB Recent machine learning (ML) models have advanced from single-modality single-task to multi-modality multi-task (MMMT). MMMT models typically have multiple backbones of different sizes along with complicated connections, exposing great challenges for hardware deployment. For scalable and energy-efficient implementations, multi-FPGA systems are emerging as the ideal design choices. However, finding the optimal solutions for mapping MMMT models onto multiple FPGAs is non-trivial. Existing mapping algorithms focus on either streamlined linear deep neural network architectures or only the critical path of simple heterogeneous models. Direct extensions of these algorithms for MMMT models lead to sub-optimal solutions. To address these shortcomings, we propose M5, a novel MMMT Model Mapping framework for Multi-FPGA platforms. In addition to handling multiple modalities present in the models, M5 can flexibly explore accelerator configurations and possible resource sharing opportunities to significantly improve the system performance. For various computation-heavy MMMT models, experiment results demonstrate that M5 can remarkably outperform existing mapping methods and lead to an average reduction of 35%, 62%, and 70% in the number of low-end, mid-end, and high-end FPGAs required to achieve the same throughput, respectively. Code is publicly available(1).
C1 [Kamath, Akshay Karkal; Abi-Karam, Stefan; Bhat, Ashwin; Hao, Cong] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Abi-Karam, Stefan] Georgia Tech Res Inst, Atlanta, GA USA.
RP Kamath, AK (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM akshay.k2@gatech.edu; stefanabikaram@gatech.edu; ashwinbhat@gatech.edu;
   callie.hao@gatech.edu
CR Biookaghazadeh S, 2021, ACM J EMERG TECH COM, V17, DOI 10.1145/3432816
   Brightwell G., 1991, P 23 ANN ACM S THEOR, P175, DOI DOI 10.1145/103418.103441
   GRAHAM RL, 1969, SIAM J APPL MATH, V17, P416, DOI 10.1137/0117039
   Hao C, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458577
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hu RH, 2021, 2021 IEEE/CVF INTERNATIONAL CONFERENCE ON COMPUTER VISION (ICCV 2021), P1419, DOI 10.1109/ICCV48922.2021.00147
   Iqbal M, 2018, Arxiv, DOI arXiv:1806.11226
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   KAHN AB, 1962, COMMUN ACM, V5, P558, DOI 10.1145/368996.369025
   Mehler A, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P150, DOI 10.1145/3209542.3209572
   Pang JM, 2021, PROC CVPR IEEE, P164, DOI 10.1109/CVPR46437.2021.00023
   Ramezani R, 2021, J SUPERCOMPUT, V77, P597, DOI 10.1007/s11227-020-03281-3
   Ruder S, 2017, Arxiv, DOI [arXiv:1706.05098, 10.48550/arXiv.1706.05098]
   Shan J., 2021, IEEE TCAD
   Shan J., 2020, IEEE TCAD
   Shen T, 2019, IEEE COMPUT SOC CONF, P1611, DOI 10.1109/CVPRW.2019.00203
   Sun YX, 2020, IEICE T INF SYST, VE103D, P2457, DOI 10.1587/transinf.2020PAP0003
   Thuseethan Selvarajah, 2020, 2020 WI IAT
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979
   VALIANT LG, 1979, SIAM J COMPUT, V8, P410, DOI 10.1137/0208032
   Yamauchi Yugo, 2020, 2020 Eighth International Symposium on Computing and Networking Workshops (CANDARW), P277, DOI 10.1109/CANDARW51189.2020.00060
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang WT, 2019, DES AUT TEST EUROPE, P1241, DOI [10.23919/date.2019.8715174, 10.23919/DATE.2019.8715174]
   Zhang X., 2022, DAC
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Ioannou, L
   Fahmy, SA
AF Ioannou, Lenos
   Fahmy, Suhaib A.
TI Streaming Overlay Architecture for Lightweight LSTM Computation on FPGA
   SoCs
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE LSTM; neural networks; overlay; machine learning
AB Long-Short Term Memory (LSTM) networks, and Recurrent Neural Networks (RNNs) in general, have demonstrated their suitability in many time series data applications, especially in Natural Language Processing (NLP). Computationally, LSTMs introduce dependencies on previous outputs in each layer that complicate their computation and the design of custom computing architectures, compared to traditional feed-forward networks. Most neural network acceleration work has focused on optimising the core matrix-vector operations on highly capable FPGAs in server environments. Research that considers the embedded domain has often been unsuitable for streaming inference, relying heavily on batch processing to achieve high throughput. Moreover, many existing accelerator architectures have not focused on fully exploiting the underlying FPGA architecture, resulting in designs that achieve lower operating frequencies than the theoretical maximum. This paper presents a flexible overlay architecture for LSTMs on FPGA SoCs that is built around a streaming dataflow arrangement, uses DSP block capabilities directly, and is tailored to keep parameters within the architecture while moving input data serially to mitigate external memory access overheads. The architecture is designed as an overlay that can be configured to implement alternative models or update model parameters at runtime. It achieves higher operating frequency and demonstrates higher performance than other lightweight LSTM accelerators, as demonstrated in an FPGA SoC implementation.
C1 [Ioannou, Lenos] Univ Warwick, Coventry, W Midlands, England.
   [Fahmy, Suhaib A.] King Abdullah Univ Sci & Technol KAUST, Comp Elect & Math Sci & Engn, Thuwal 23955, Saudi Arabia.
   [Ioannou, Lenos] Sch Engn, Lib Rd, Coventry CV4 7AL, W Midlands, England.
RP Ioannou, L (corresponding author), Univ Warwick, Coventry, W Midlands, England.; Ioannou, L (corresponding author), Sch Engn, Lib Rd, Coventry CV4 7AL, W Midlands, England.
EM l.ioannou@warwick.ac.uk; suhaib.fahmy@kaust.edu.sa
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2020, ZYNQ 7000 SOC Z 7007
   [Anonymous], 2018, 7 SERIES DSP48E1 SLI
   [Anonymous], 2021, VIRTEX 7 T XT FPGAS
   [Anonymous], 2018, ZYNQ 7000 SOC Z 7030
   [Anonymous], HEY SIRI ON DEVICE D
   [Anonymous], 2021, ZYNQ ULTRASCALE MPSO
   Azari E, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3366634
   Azari E, 2019, IEEE INT CONF BIG DA, P4450, DOI 10.1109/BigData47090.2019.9006030
   Chanana Ashish, 2017, 2017 42nd International Conference on Infrared, Millimeter and Terahertz Waves (IRMMW-THz), DOI 10.1109/IRMMW-THz.2017.8067214
   Chang A. X. M., 2015, RECURRENT NEURAL NET, DOI DOI 10.48550/ARXIV.1511.05552
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Chollet F., 2018, DEEP LEARNING PYTHON, DOI DOI 10.1007/978-1-4842-2766-4
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Ghasemzadeh SA, 2021, Arxiv, DOI arXiv:2101.02667
   Hubara I, 2016, ADV NEUR IN, V29
   Ioannou L, 2020, IEEE T VLSI SYST, V28, P1392, DOI 10.1109/TVLSI.2020.2987202
   Ioannou L, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P355, DOI 10.1109/ICFPT47387.2019.00066
   Ioannou L, 2019, I C FIELD PROG LOGIC, P232, DOI 10.1109/FPL.2019.00043
   Jain AK, 2016, DES AUT TEST EUROPE, P1628
   Jihyun Kim, 2016, 2016 International Conference on Platform Technology and Service (PlatCon). Proceedings, P1, DOI 10.1109/PlatCon.2016.7456805
   Langhammer M, 2018, I C FIELD PROG LOGIC, P43, DOI 10.1109/FPL.2018.00015
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Maor G, 2019, PR IEEE COMP DESIGN, P38, DOI 10.1109/ICCD46524.2019.00014
   Milenkoski M, 2018, 2018 41ST INTERNATIONAL CONVENTION ON INFORMATION AND COMMUNICATION TECHNOLOGY, ELECTRONICS AND MICROELECTRONICS (MIPRO), P1126, DOI 10.23919/MIPRO.2018.8400205
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Qing XY, 2018, ENERGY, V148, P461, DOI 10.1016/j.energy.2018.01.177
   Que ZQ, 2020, J SIGNAL PROCESS SYS, V92, P965, DOI 10.1007/s11265-020-01549-8
   Reuther A, 2019, IEEE HIGH PERF EXTR
   Ronak B, 2016, IEEE T COMPUT AID D, V35, P573, DOI 10.1109/TCAD.2015.2474363
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Samajdar A, 2019, I C FIELD PROG LOGIC, P342, DOI 10.1109/FPL.2019.00061
   Skillman Allan, 2020, 2020 IEEE Hot Chips 32 Symposium (HCS), DOI 10.1109/HCS49909.2020.9220415
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Vinyals O, 2017, IEEE T PATTERN ANAL, V39, P652, DOI 10.1109/TPAMI.2016.2587640
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Wu E., 2017, I C FIELD PROG LOGIC, P1, DOI 10.23919/FPL.2017.8056794
   Xie ZZ, 2011, ADV INTEL SOFT COMPU, V111, P125
   Xilinx, 2020, UG579 ULTRASCALE ARC
   Zhang XY, 2020, PR IEEE COMP DESIGN, P469, DOI 10.1109/ICCD50377.2020.00086
   Zhu C., 2017, P INT C LEARN REPR I
NR 43
TC 2
Z9 2
U1 3
U2 7
PD MAR
PY 2023
VL 16
IS 1
AR 8
DI 10.1145/3543069
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Chen, CY
   Chakrabarty, K
AF Chen, Ching-Yuan
   Chakrabarty, Krishnendu
GP IEEE
TI Pruning of Deep Neural Networks for Fault-Tolerant Memristor-based
   Accelerators
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
AB Hardware-level reliability is a major concern when deep neural network (DNN) models are mapped to neuromorphic accelerators such as memristor-based crossbars. Manufacturing defects and variations lead to hardware faults in the crossbar. Although memristor-based DNNs are inherently tolerant to these faults and many faults are benign for a given inferencing application, there is still a non-negligible number of critical faults (CFs) in the memristor crossbars that can lead to misclassification. It is therefore important to efficiently identify these CFs so that fault-tolerance solutions can focus on them. In this paper, we present an efficient technique based on machine learning to identify these CFs; CFs can be identified with over 98% accuracy and at a rate that is 20 times faster than a baseline using random fault injection. We next present a fault-tolerance technique that iteratively prunes a DNN by targeting weights that are mapped to CFs in the memristor crossbars. Our results for the CIFAR-10 data set and several benchmark DNNs show that the proposed pruning technique eliminates up to 95% of the CFs with less than 1% DNN inferencing accuracy loss. This reduction in the total number of CFs leads to a 99% savings in the hardware redundancy required for fault tolerance.
C1 [Chen, Ching-Yuan; Chakrabarty, Krishnendu] Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
RP Chen, CY (corresponding author), Duke Univ, Dept Elect & Comp Engn, Durham, NC 27708 USA.
CR [Anonymous], 2013, HDB MATH FUNCTIONS F
   Chaudhuri A., 2018, ITC
   Chen CY, 2015, IEEE T COMPUT, V64, P180, DOI 10.1109/TC.2014.12
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Fieback M., 2019, ITC
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hamdioui S., 2019, ITC
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   He ZH, 2020, PSYCHOL MED, V50, P2768, DOI 10.1017/S0033291719002915
   Kim SG, 2017, INT EL DEVICES MEET
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, CIFAR 10 CIFAR 100 D
   Li W., 2020, ASPDAC
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Liu CC, 2017, DES AUT CON, DOI 10.1145/3061639.3062310
   Madry A., 2018, INT C LEARN REPR, P1
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Mao MQ, 2018, IEEE T VLSI SYST, V26, P1290, DOI 10.1109/TVLSI.2018.2814544
   Rolewicz S., 1987, FUNCTIONAL ANAL CONT
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Xia LX, 2018, IEEE J EM SEL TOP C, V8, P102, DOI 10.1109/JETCAS.2017.2776980
   Xia LX, 2017, DES AUT CON, DOI 10.1145/3061639.3062248
   Xu Z, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000149
   Zhang S., 2020, IEEE INT C AI CIRC S
   Zisserman, 2014, CORR
NR 28
TC 4
Z9 4
U1 0
U2 6
PY 2021
BP 889
EP 894
DI 10.1109/DAC18074.2021.9586269
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Moraitis, T
   Toichkin, D
   Journé, A
   Chua, Y
   Guo, QH
AF Moraitis, Timoleon
   Toichkin, Dmitry
   Journe, Adrien
   Chua, Yansong
   Guo, Qinghai
TI SoftHebb: Bayesian inference in unsupervised Hebbian soft
   winner-take-all networks
SO NEUROMORPHIC COMPUTING AND ENGINEERING
DT Article
DE adversarial robustness; local plasticity; alternative to
   backpropagation; neuromorphic efficiency; Bayesian generative model;
   online unsupervised Hebbian learning; cortical learning theory
ID INFORMATION
AB Hebbian plasticity in winner-take-all (WTA) networks is highly attractive for neuromorphic on-chip learning, owing to its efficient, local, unsupervised, and on-line nature. Moreover, its biological plausibility may help overcome important limitations of artificial algorithms, such as their susceptibility to adversarial attacks, and their high demands for training-example quantity and repetition. However, Hebbian WTA learning has found little use in machine learning, likely because it has been missing an optimization theory compatible with deep learning (DL). Here we show rigorously that WTA networks constructed by standard DL elements, combined with a Hebbian-like plasticity that we derive, maintain a Bayesian generative model of the data. Importantly, without any supervision, our algorithm, SoftHebb, minimizes cross-entropy, i.e. a common loss function in supervised DL. We show this theoretically and in practice. The key is a 'soft' WTA where there is no absolute 'hard' winner neuron. Strikingly, in shallow-network comparisons with backpropagation, SoftHebb shows advantages beyond its Hebbian efficiency. Namely, it converges in fewer iterations, and is significantly more robust to noise and adversarial attacks. Notably, attacks that maximally confuse SoftHebb are also confusing to the human eye, potentially linking human perceptual robustness, with Hebbian WTA circuits of cortex. Finally, SoftHebb can generate synthetic objects as interpolations of real object classes. All in all, Hebbian efficiency, theoretical underpinning, cross-entropy-minimization, and surprising empirical advantages, suggest that SoftHebb may inspire highly neuromorphic and radically different, but practical and advantageous learning algorithms and hardware accelerators.
C1 [Moraitis, Timoleon; Journe, Adrien] Zurich Res Ctr, Huawei Technol, Zurich, Switzerland.
   [Chua, Yansong; Guo, Qinghai] Adv Comp & Storage Lab, Huawei Technol, Shenzhen, Peoples R China.
RP Moraitis, T (corresponding author), Zurich Res Ctr, Huawei Technol, Zurich, Switzerland.; Guo, QH (corresponding author), Adv Comp & Storage Lab, Huawei Technol, Shenzhen, Peoples R China.
EM timoleon.moraitis@huawei.com; guoqinghai@huawei.com
CR Amato G, 2019, LECT NOTES COMPUT SC, V11751, P324, DOI 10.1007/978-3-030-30642-7_29
   Bardes A, 2022, Arxiv, DOI arXiv:2105.04906
   BELL AJ, 1995, NEURAL COMPUT, V7, P1129, DOI 10.1162/neco.1995.7.6.1129
   Bengio Y, 2016, Arxiv, DOI arXiv:1502.04156
   Berthelot D, 2018, Arxiv, DOI arXiv:1807.07543
   Binas J, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00068
   Binzegger T, 2004, J NEUROSCI, V24, P8441, DOI 10.1523/JNEUROSCI.1400-04.2004
   Bittar A, 2022, FRONT NEUROSCI-SWITZ, V16, DOI 10.3389/fnins.2022.865897
   Bojanowski P, 2019, Arxiv, DOI arXiv:1707.05776
   Cannon J, 2014, EUR J NEUROSCI, V39, P705, DOI 10.1111/ejn.12453
   Chen T, 2020, PR MACH LEARN RES, V119
   Cowen-Rivers AI, 2022, J ARTIF INTELL RES, V74, P1269
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   CRICK F, 1989, NATURE, V337, P129, DOI 10.1038/337129a0
   Czarnecki WM, 2017, PR MACH LEARN RES, V70
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Diehl PU, 2015, FRONT COMPUT NEUROSC, V9, DOI 10.3389/fncom.2015.00099
   Douglas RJ, 2004, ANNU REV NEUROSCI, V27, P419, DOI 10.1146/annurev.neuro.27.070203.144152
   Ernoult M, 2020, Arxiv, DOI arXiv:2005.04168
   Foldiak P., 1989, IJCNN: International Joint Conference on Neural Networks (Cat. No.89CH2765-6), P401, DOI 10.1109/IJCNN.1989.118615
   FOLDIAK P, 1990, BIOL CYBERN, V64, P165, DOI 10.1007/BF02331346
   Frenkel C, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.629892
   Garcia Rodriguez H., 2022, INT C MACHINE LEARNI, P18704
   Goodfellow I. J., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1406.2661
   Grinberg L, 2019, Arxiv, DOI arXiv:1908.08993
   GROSSBERG S, 1987, COGNITIVE SCI, V11, P23, DOI 10.1111/j.1551-6708.1987.tb00862.x
   Guerguiev J, 2017, ELIFE, V6, DOI 10.7554/eLife.22901
   Hahnloser R, 1999, NAT NEUROSCI, V2, P746, DOI 10.1038/11219
   Hinton G, 2015, Arxiv, DOI [arXiv:1503.02531, DOI 10.48550/ARXIV.1503.02531]
   Hu T, 2014, CONF REC ASILOMAR C, P613, DOI 10.1109/ACSSC.2014.7094519
   HUBEL DH, 1962, J PHYSIOL-LONDON, V160, P106, DOI 10.1113/jphysiol.1962.sp006837
   Illing B, 2019, NEURAL NETWORKS, V118, P90, DOI 10.1016/j.neunet.2019.06.001
   Isomura T, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-20082-0
   Jeffares A., 2022, INT C LEARNING REPRE
   Journe A, 2022, Arxiv, DOI arXiv:2209.11883
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Krotov D, 2019, P NATL ACAD SCI USA, V116, P7723, DOI 10.1073/pnas.1820458116
   Lagani G, 2021, NEURAL NETWORKS, V143, P719, DOI 10.1016/j.neunet.2021.08.003
   Lee TW, 1999, NEURAL COMPUT, V11, P417, DOI 10.1162/089976699300016719
   Lillicrap TP, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms13276
   LINSKER R, 1992, NEURAL COMPUT, V4, P691, DOI 10.1162/neco.1992.4.5.691
   Maass W, 2000, NEURAL COMPUT, V12, P2519, DOI 10.1162/089976600300014827
   Madry A, 2019, Arxiv, DOI [arXiv:1706.06083, DOI 10.48550/ARXIV.1706.06083]
   MALSBURG CV, 1973, KYBERNETIK, V14, P85, DOI 10.1007/BF00288907
   Millidge B, 2020, Arxiv, DOI [arXiv:2006.04182, DOI 10.48550/ARXIV.2006.04182]
   Moraitis T, 2021, Arxiv, DOI arXiv:2009.06808
   Nessler B., 2009, ADV NEURAL INFORM PR, P1357
   Nessler B, 2013, PLOS COMPUT BIOL, V9, DOI 10.1371/journal.pcbi.1003037
   Nokland A, 2016, ADV NEUR IN, V29
   OJA E, 1982, J MATH BIOL, V15, P267, DOI 10.1007/BF00275687
   Olshausen BA, 1997, VISION RES, V37, P3311, DOI 10.1016/S0042-6989(97)00169-7
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Payeur A, 2021, NAT NEUROSCI, V24, P1010, DOI 10.1038/s41593-021-00857-x
   Pehlevan C, 2015, ADV NEUR IN, V28
   Pehlevan C, 2017, CONF REC ASILOMAR C, P593, DOI 10.1109/ACSSC.2017.8335410
   Pehlevan C, 2014, CONF REC ASILOMAR C, P769, DOI 10.1109/ACSSC.2014.7094553
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Pogodin R, 2022, Arxiv, DOI arXiv:2106.13031
   Pogodin R, 2020, Arxiv, DOI arXiv:2006.07123
   Poirazi P, 2020, NAT REV NEUROSCI, V21, P303, DOI 10.1038/s41583-020-0301-7
   Qin Y, 2020, Arxiv, DOI arXiv:2002.07405
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Rauber J, 2018, Arxiv, DOI [arXiv:1707.04131, DOI 10.48550/ARXIV.1707.04131]
   Rutishauser U, 2011, NEURAL COMPUT, V23, P735, DOI 10.1162/NECO_a_00091
   SANGER TD, 1989, NEURAL NETWORKS, V2, P459, DOI 10.1016/0893-6080(89)90044-0
   Sarwat SG, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29870-9
   Scellier B, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00024
   Scherr F, 2023, Arxiv, DOI arXiv:2210.09224
   Sejnowski TJ, 2020, P NATL ACAD SCI USA, V117, P30033, DOI 10.1073/pnas.1907373117
   Diehl PU, 2016, Arxiv, DOI arXiv:1608.08267
   Xiao H, 2017, Arxiv, DOI [arXiv:1708.07747, DOI 10.48550/ARXIV.1708.07747]
   Zador A, 2022, Arxiv, DOI [arXiv:2210.08340, 10.48550/arXiv.2210.08340, DOI 10.48550/ARXIV.2210.08340]
NR 72
TC 3
Z9 3
U1 0
U2 0
PD DEC 1
PY 2022
VL 2
IS 4
AR 044017
DI 10.1088/2634-4386/aca710
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Tann, H
   Hashemi, S
   Bahar, RI
   Reda, S
AF Tann, Hokchhay
   Hashemi, Soheil
   Bahar, R. Iris
   Reda, Sherief
GP IEEE
TI Hardware-Software Codesign of Accurate, Multiplier-free Deep Neural
   Networks
SO PROCEEDINGS OF THE 2017 54TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 54th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 18-22, 2017
CL Austin, TX
AB While Deep Neural Networks (DNNs) push the state-of-the-art in many machine learning applications, they often require millions of expensive floating-point operations for each input classification. This computation overhead limits the applicability of DNNs to low-power, embedded platforms and incurs high cost in data centers. This motivates recent interests in designing low-power, low-latency DNNs based on fixed-point, ternary, or even binary data precision. While recent works in this area offer promising results, they often lead to large accuracy drops when compared to the floating-point networks. We propose a novel approach to map floating-point based DNNs to 8-bit dynamic fixed-point networks with integer power-of-two weights with no change in network architecture. Our dynamic fixed-point DNNs allow different radix points between layers. During inference, power-of-two weights allow multiplications to be replaced with arithmetic shifts, while the 8-bit fixed-point representation simplifies both the buffer and adder design. In addition, we propose a hardware accelerator design to achieve low-power, low-latency inference with insignificant degradation in accuracy. Using our custom accelerator design with the CIFAR-10 and ImageNet datasets, we show that our method achieves significant power and energy savings while increasing the classification accuracy.
C1 [Tann, Hokchhay; Hashemi, Soheil; Bahar, R. Iris; Reda, Sherief] Brown Univ, Sch Engn, Providence, RI 02912 USA.
RP Tann, H (corresponding author), Brown Univ, Sch Engn, Providence, RI 02912 USA.
EM hokchhay_tann@brown.edu; soheil_hashemi@brown.edu; iris_bahar@brown.edu;
   sherief_reda@brown.edu
CR Ba LJ, 2014, ADV NEURAL INFORM PR, V3, P2654, DOI DOI 10.5555/2969033.2969123
   Bucilua C., 2006, P ACM SIGKDD
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Courbariaux Matthieu, 2014, ARXIV14127024
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Hwang K., 2014 IEEE SIPS
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Romero Adriana, 2014, CORR
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sankaradas M., 2009, P IEEE ASAP IEEE COM
   Sarwar S. S., 2016, CORR
   Soudry D., 2014, ADV NEURAL INFORM PR, P963, DOI DOI 10.5555/2968826.2968934
   TANG CZ, 1993, IEEE T SIGNAL PROCES, V41, P2724, DOI 10.1109/78.229903
   Tann H., 2016, CORR
   Zhang C., 2015, P ACM SIGDA FPGA
NR 21
TC 40
Z9 42
U1 1
U2 1
PY 2017
DI 10.1145/3061639.3062259
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chien, SWD
   Markidis, S
   Olshevsky, V
   Bulatov, Y
   Laure, E
   Vetter, JS
AF Chien, Steven W. D.
   Markidis, Stefano
   Olshevsky, Vyacheslav
   Bulatov, Yaroslav
   Laure, Erwin
   Vetter, Jeffrey S.
GP IEEE
TI TensorFlow Doing HPC An Evaluation of TensorFlow Performance in HPC
   Applications
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE TensorFlow; Emerging Programming Environments; Parallel Computing;
   Heterogeneous Supercomputers; HPC Applications
AB TensorFlow is a popular emerging open-source programming framework supporting the execution of distributed applications on heterogeneous hardware. While TensorFlow has been initially designed for developing Machine Learning (ML) applications, in fact TensorFlow aims at supporting the development of a much broader range of application kinds that are outside the ML domain and can possibly include HPC applications. However, very few experiments have been conducted to evaluate TensorFlow performance when running HPC workloads on supercomputers. This work addresses this lack by designing four traditional HPC benchmark applications: STREAM, matrix-matrix multiply, Conjugate Gradient (CG) solver and Fast Fourier Transform (FFT). We analyze their performance on two supercomputers with accelerators and evaluate the potential of TensorFlow for developing HPC applications. Our tests show that TensorFlow can fully take advantage of high performance networks and accelerators on supercomputers. Running our Tensor-Flow STREAM benchmark, we obtain over 50% of theoretical communication bandwidth on our testing platform. We find an approximately 2x, 1.7x and 1.8x performance improvement when increasing the number of GPUs from two to four in the matrix-matrix multiply, CG and FFT applications respectively. All our performance results demonstrate that TensorFlow has high potential of emerging also as HPC programming framework for heterogeneous supercomputers.
C1 [Chien, Steven W. D.; Markidis, Stefano; Olshevsky, Vyacheslav; Laure, Erwin] KTH Royal Inst Technol, Stockholm, Sweden.
   [Bulatov, Yaroslav] South Pk Commons, San Francisco, CA USA.
   [Vetter, Jeffrey S.] Oak Ridge Natl Lab, Oak Ridge, TN USA.
RP Chien, SWD (corresponding author), KTH Royal Inst Technol, Stockholm, Sweden.
CR Abadi M, 2017, MAPL'17: PROCEEDINGS OF THE 1ST ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P1, DOI 10.1145/3088525.3088527
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Agullo E, 2017, LECT NOTES COMPUT SC, V10104, P69, DOI 10.1007/978-3-319-58943-5_6
   [Anonymous], 2018, ARXIV180508430
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2018, ARXIV180401138
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Awan AA, 2017, ACM SIGPLAN NOTICES, V52, P193, DOI [10.1145/3155284.3018769, 10.1145/3018743.3018769]
   Bosilca G, 2013, COMPUT SCI ENG, V15, P36, DOI 10.1109/MCSE.2013.98
   Chien S. W. D., 2018, 2018 IEEE ACM 3 INT
   Geron A., HANDS ON MACHINE LEA
   Jia C., 2017, INT J PARALLEL PROGR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kleppmann M., 2017, DESIGNING DATA INTEN
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Markidis S, 2015, INT J HIGH PERFORM C, V29, P311, DOI 10.1177/1094342015576846
   Mathuriya A., 2018, ARXIV180804728
   McCalpin John D., 1995, IEEE COMPUTER SOC TE, P19
   Nowak F, 2013, LECT NOTES COMPUT SC, V7767, P171, DOI 10.1007/978-3-642-36424-2_15
   Paszke Adam, 2017, AUTOMATIC DIFFERENTI
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Vishnu A., 2016, ARXIV160302339
   Yi B., 2017, P SIGCOMM POST DEM, P28, DOI DOI 10.1145/3123878.3131975
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
NR 25
TC 1
Z9 1
U1 1
U2 7
PY 2019
BP 509
EP 518
DI 10.1109/IPDPSW.2019.00092
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Salamat, S
   Imani, M
   Khaleghi, B
   Rosing, T
AF Salamat, Sahand
   Imani, Mohsen
   Khaleghi, Behnam
   Rosing, Tajana
GP ACM
TI F5-HD: Fast Flexible FPGA-based Framework for Refreshing
   Hyperdimensional Computing
SO PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 24-26, 2019
CL Seaside, CA
DE Brain-inspired Hyperdimensional Computing; Machine Learning; FPGA-based
   Acceleration; Automated Template-based Hardware Generation
AB Hyperdimensional (HD) computing is a novel computational paradigm that emulates the brain functionality in performing cognitive tasks. The underlying computation of HD involves a substantial number of element-wise operations (e.g., addition and multiplications) on ultra-wise hypervectors, in the granularities of as small as a single bit, which can be effectively parallelized and pipelined. In addition, though different HD applications might vary in terms of number of input features and output classes (labels), they generally follow the same computation flow. Such characteristics of HD computing inimitably matches with the intrinsic capabilities of FPGAs, making these devices a unique solution for accelerating these applications.
   In this paper, we propose F5-HD, a fast and flexible FPGA-based framework for refreshing the performance of HD computing. F5-HD eliminates the arduous task of handcrafted designing of hardware accelerators by automatically generating an FPGA implementation of HD accelerator leveraging a template of optimized processing elements, according to the applications specification and user's constraint. Our evaluations using different classification benchmarks revealed that F5-HD provides 86.9x and 7.8x (11.9x and 1.7x) higher energy efficiency improvement and faster training (inference) as compared to an optimized implementation of HD on AMD R9 390 GPU, respectively.
C1 [Salamat, Sahand; Imani, Mohsen; Khaleghi, Behnam; Rosing, Tajana] Univ Calif San Diego, Comp Sci & Engn Dept, La Jolla, CA 92093 USA.
RP Salamat, S (corresponding author), Univ Calif San Diego, Comp Sci & Engn Dept, La Jolla, CA 92093 USA.
EM sasalama@ucsd.edu; moimani@ucsd.edu; bkhaleghi@ucsd.edu; tajana@ucsd.edu
CR [Anonymous], 2012, CISC VIS NETW IND GL
   [Anonymous], 2017, XILINX POWER ESTIMAT
   [Anonymous], 2019, ASP DAC
   [Anonymous], 2007, CALTECH 256 OBJECT C
   [Anonymous], 2018, 2018 IEEE INT C REB
   [Anonymous], DAC
   [Anonymous], 2018, ICCAD
   [Anonymous], 2015, IEEE T NEUR NET LEAR
   [Anonymous], 2018, ARXIV180708583
   [Anonymous], 2018, IOT
   DeHon A, 2000, COMPUTER, V33, P41, DOI 10.1109/2.839320
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Falsafi B, 2017, IEEE MICRO, V37, P60, DOI 10.1109/MM.2017.19
   Imani Mohsen, 2018, 2018 IEEE EMBS International Conference on Biomedical & Health Informatics (BHI), P271, DOI 10.1109/BHI.2018.8333421
   Imani M., 2019, DATE IEEE ACM
   Imani M, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P97
   Imani M, 2017, IEEE DES TEST, V34, P94, DOI 10.1109/MDAT.2017.2740839
   Imani M, 2017, INT S HIGH PERF COMP, P445, DOI 10.1109/HPCA.2017.28
   Joshi A., QUANTUM INTERACTION
   Kanerva P, 2014, ANN ALLERTON CONF, P304, DOI 10.1109/ALLERTON.2014.7028470
   Kanerva P, 2009, COGN COMPUT, V1, P139, DOI 10.1007/s12559-009-9009-8
   Li HT, 2016, INT EL DEVICES MEET
   Montagna  F., 2018, P ACM 55 ANN DES AUT, P111
   Najafabadi F. R., 2016, DESIGN AUTOMATION TE, P1
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Räsänen OJ, 2016, IEEE T NEUR NET LEAR, V27, P1878, DOI 10.1109/TNNLS.2015.2462721
   Reiss A., 2012, P 5 INT C PERV TECHN
   Salvatore A, 2018, WILEY BLACK HIST REL, P1
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wu TF, 2018, ISSCC DIG TECH PAP I, P492, DOI 10.1109/ISSCC.2018.8310399
NR 30
TC 51
Z9 51
U1 0
U2 3
PY 2019
BP 53
EP 62
DI 10.1145/3289602.3293913
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Awais, M
   Zahir, A
   Shah, SAA
   Reviriego, P
   Ullah, A
   Ullah, N
   Khan, A
   Ali, H
AF Awais, Muhammad
   Zahir, Ali
   Shah, Syed Ayaz Ali
   Reviriego, Pedro
   Ullah, Anees
   Ullah, Nasim
   Khan, Adam
   Ali, Hazrat
TI Toward Optimal Softcore Carry-aware Approximate Multipliers on Xilinx
   FPGAs
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Neural Network
ID RADIX-8 BOOTH MULTIPLIERS; LOW-POWER; DESIGN
AB Domain-specific accelerators for signal processing, image processing, and machine learning are increasingly being implemented on SRAM-based field-programmable gate arrays (FPGAs). Owing to the inherent error tolerance of such applications, approximate arithmetic operations, in particular, the design of approximate multipliers, have become an important research problem. Truncation of lower bits is a widely used approximation approach; however, analyzing and limiting the effects of carry-propagation due to this approximation has not been explored in detail yet. In this article, an optimized carry-aware approximate radix-4 Booth multiplier design is presented that leverages the built-in slice look-up tables (LUTs) and carry-chain resources in a novel configuration. The proposed multiplier simplifies the computation of the upper and lower bits and provides significant benefits in terms of FPGA resource usage (LUTs saving 38.5%-42.9%), Power Delay Product (PDP saving 49.4%-53%), performance metric (LUTs x critical path delay (CPD) x PDP saving 68.9%-73.1%) and errors (70% improvement in mean relative error distance) compared to the latest state-of-the-art designs. Therefore, the proposed designs are an attractive choice to implement multiplication on FPGA-based accelerators.
C1 [Awais, Muhammad; Zahir, Ali; Shah, Syed Ayaz Ali] COM SATS Univ Islamabad, Dept Elect & Comp Engn, Islamabad, Pakistan.
   [Reviriego, Pedro] Univ Politecn Madrid, Dept Telemat Syst Engn, Madrid, Spain.
   [Ullah, Anees; Khan, Adam] Univ Engn & Technol, Dept Elect Engn, Peshawar, Pakistan.
   [Ullah, Nasim] Taif Univ KSA, Dept Elect Engn, Coll Engn, Taif, Saudi Arabia.
   [Ali, Hazrat] Hamad Bin Khalifa Univ, Coll Sci & Engn, Doha, Qatar.
RP Awais, M (corresponding author), COM SATS Univ Islamabad, Dept Elect & Comp Engn, Islamabad, Pakistan.
EM awais9362@gmail.com; alizahir@cuiatd.edu.pk; ayaz@cuiatd.edu.pk;
   pedro.reviriego@upm.es; aneesullah@uetpeshawar.edu.pk;
   nasimullah@tu.edu.sa; adamkhan@uetpeshawar.edu.pk; haali2@hbku.edu.qa
CR Ahmadinejad M, 2019, AEU-INT J ELECTRON C, V110, DOI 10.1016/j.aeue.2019.152859
   Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Chen K, 2019, IEEE T COMPUT, V68, P784, DOI 10.1109/TC.2018.2885044
   Dadda L., 1965, ALTA FREQ, V34, P349
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P189, DOI 10.1109/TCSI.2018.2856245
   Jiang HL, 2016, IEEE T COMPUT, V65, P2638, DOI 10.1109/TC.2015.2493547
   Koren I., 2002, COMPUTER ARITHMETIC
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Lin CH, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P33, DOI 10.1109/ICCD.2013.6657022
   Liu C, 2014, DES AUT TEST EUROPE
   Liu WQ, 2020, P IEEE, V108, P394, DOI 10.1109/JPROC.2020.2975695
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Lotric U, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10101175
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Parhami B., 2010, COMPUTER ARITHMETIC
   Pilipovic R, 2021, IEEE T CIRCUITS-I, V68, P2535, DOI 10.1109/TCSI.2021.3069168
   Qiqieh I, 2017, DES AUT TEST EUROPE, P7, DOI 10.23919/DATE.2017.7926950
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Sabetzadeh F, 2019, IEEE T CIRCUITS-I, V66, P4200, DOI 10.1109/TCSI.2019.2918241
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Ullah S, 2022, IEEE T COMPUT AID D, V41, P211, DOI 10.1109/TCAD.2021.3056337
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Venkatachalam S, 2019, IEEE T COMPUT, V68, P1697, DOI 10.1109/TC.2019.2926275
   Walters EG, 2016, COMPUTERS, V5, DOI 10.3390/computers5040020
   Waris H, 2021, IEEE T CIRCUITS-II, V68, P1566, DOI 10.1109/TCSII.2021.3065333
   Waris H, 2020, IEEE T CIRCUITS-II, V67, P3367, DOI 10.1109/TCSII.2020.2975094
   Xilinx, 2018, 7 SER FPGAS CONF US
   Xilinx, 2019, VIVADO DESIGN SUITE
   Yang TX, 2017, PR IEEE COMP DESIGN, P89, DOI 10.1109/ICCD.2017.22
NR 32
TC 1
Z9 1
U1 0
U2 0
PD JUL
PY 2023
VL 22
IS 4
AR 76
DI 10.1145/3564243
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Sebastian, A
   Le Gallo, M
   Khaddam-Aljameh, R
   Eleftheriou, E
AF Sebastian, Abu
   Le Gallo, Manuel
   Khaddam-Aljameh, Riduan
   Eleftheriou, Evangelos
TI Memory devices and applications for in-memory computing
SO NATURE NANOTECHNOLOGY
DT Review
ID PHASE-CHANGE MATERIALS; DEEP NEURAL-NETWORKS; LOGIC; DESIGN; SPIN;
   ACCELERATOR; GENERATION; SWITCHES; SYNAPSE; SIGNAL
AB Traditional von Neumann computing systems involve separate processing and memory units. However, data movement is costly in terms of time and energy and this problem is aggravated by the recent explosive growth in highly data-centric applications related to artificial intelligence. This calls for a radical departure from the traditional systems and one such non-von Neumann computational approach is in-memory computing. Hereby certain computational tasks are performed in place in the memory itself by exploiting the physical attributes of the memory devices. Both charge-based and resistance-based memory devices are being explored for in-memory computing. In this Review, we provide a broad overview of the key computational primitives enabled by these memory devices as well as their applications spanning scientific computing, signal processing, optimization, machine learning, deep learning and stochastic computing.
   This Review provides an overview of memory devices and the key computational primitives for in-memory computing, and examines the possibilities of applying this computing approach to a wide range of applications.
C1 [Sebastian, Abu; Le Gallo, Manuel; Khaddam-Aljameh, Riduan; Eleftheriou, Evangelos] IBM Res Zurich, Ruschlikon, Switzerland.
RP Sebastian, A (corresponding author), IBM Res Zurich, Ruschlikon, Switzerland.
EM ase@zurich.ibm.com
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agarwal S, 2017, S VLSI TECH, pT174, DOI 10.23919/VLSIT.2017.7998164
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2014, IEEE HOT CHIP SYMP
   Aziz A, 2018, DES AUT TEST EUROPE, P1289, DOI 10.23919/DATE.2018.8342213
   Balatti S, 2016, IEEE T ELECTRON DEV, V63, P2029, DOI 10.1109/TED.2016.2537792
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Beck A, 2000, APPL PHYS LETT, V77, P139, DOI 10.1063/1.126902
   Bekas C., 2009, P 2 WORKSH HIGH PERF, P1
   Benjamin B, 2014, P IEEE, V102, P699, DOI 10.1109/JPROC.2014.2313565
   Bichler O, 2012, IEEE T ELECTRON DEV, V59, P2206, DOI 10.1109/TED.2012.2197951
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Brivio S, 2017, NANOTECHNOLOGY, V28, DOI 10.1088/1361-6528/aa8013
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2016, IEEE J EM SEL TOP C, V6, P146, DOI 10.1109/JETCAS.2016.2547718
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai F., 2019, HARNESSING INTRINSIC
   Carboni R, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900198
   Carboni R, 2018, IEEE ELECTR DEVICE L, V39, P951, DOI 10.1109/LED.2018.2833543
   Chanthbouala A, 2012, NAT MATER, V11, P860, DOI [10.1038/nmat3415, 10.1038/NMAT3415]
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheng L, 2019, ADV FUNCT MAT
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   Chua L, 2011, APPL PHYS A-MATER, V102, P765, DOI 10.1007/s00339-011-6264-9
   Covi E, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00482
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   Dazzi M, 2019, P NEURIPS MLSYS WORK
   Di Ventra M, 2013, NAT PHYS, V9, P200, DOI 10.1038/nphys2566
   Diehl Peter U, 2015, 2015 INT JOINT C NEU, P1, DOI [DOI 10.1109/IJCNN.2015.7280696, 10.1109/IJCNN.2015.7280696]
   Diorio C, 1996, IEEE T ELECTRON DEV, V43, P1972, DOI 10.1109/16.543035
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Eleftheriou E, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947008
   Eryilmaz SB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00205
   Esser S.K., 2015, ADV NEURAL INFORM PR, P1117
   Farooq M., 2011, P INT EL DEV M, P7
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Fuller EJ, 2019, SCIENCE, V364, P570, DOI 10.1126/science.aaw5581
   Gaba S, 2013, NANOSCALE, V5, P5872, DOI 10.1039/c3nr01176c
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Giannopoulos I., 2018, 2018 IEEE INT EL DEV, P27
   Godse A. P., 2008, COMPUTER ORG ARCHITE
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Graves A, 2016, NATURE, V538, P471, DOI 10.1038/nature20101
   Gupta S, 2018, ADV ASIAN HUM-ENV RE, P173, DOI 10.1007/978-3-319-72257-3_8
   Haj-Ali A, 2018, IEEE T CIRCUITS-I, V65, P4258, DOI 10.1109/TCSI.2018.2846699
   Hamdioui S, 2019, DES AUT TEST EUROPE, P486, DOI [10.23919/DATE.2019.8715020, 10.23919/date.2019.8715020]
   He K., 2016, P IEEE C COMPUTER VI
   HICKMOTT TW, 1962, J APPL PHYS, V33, P2669, DOI 10.1063/1.1702530
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu SG, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8522
   Hubara I, 2018, J MACH LEARN RES, V18
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jeong DS, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600090
   Jia Z, 2019, DISSECTING NVIDIA TU
   Jiang H, 2018, NAT ELECTRON, V1, P548, DOI 10.1038/s41928-018-0146-5
   Jiang WG, 2017, NAT COMMUN, V8, P1, DOI 10.1038/ncomms15066
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jo SH, 2009, NANO LETT, V9, P496, DOI 10.1021/nl803669s
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karam R, 2015, P IEEE, V103, P1311, DOI 10.1109/JPROC.2015.2434888
   Kavehei O, 2013, NANOSCALE, V5, P5119, DOI 10.1039/c3nr00535f
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kent AD, 2015, NAT NANOTECHNOL, V10, P187, DOI 10.1038/nnano.2015.24
   Kheradpisheh SR, 2018, NEURAL NETWORKS, V99, P56, DOI 10.1016/j.neunet.2017.12.005
   Khvalkovskiy AV, 2013, J PHYS D APPL PHYS, V46, DOI 10.1088/0022-3727/46/7/074001
   Kim KM, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201800629
   Kim T, 2015, 2015 28TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P170, DOI 10.1109/SOCC.2015.7406934
   Kimura H, 2004, IEEE J SOLID-ST CIRC, V39, P919, DOI 10.1109/JSSC.2004.827802
   Koelmans WW, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9181
   Kumar S, 2017, NATURE, V548, P318, DOI 10.1038/nature23307
   Kuzum D, 2012, NANO LETT, V12, P2179, DOI 10.1021/nl201040y
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Le Gallo M, 2017, INT EL DEVICES MEET
   Le Gallo M, 2018, IEEE T ELECTRON DEV, V65, P4304, DOI 10.1109/TED.2018.2865352
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Le Gallo M, 2016, PROC EUR S-STATE DEV, P373, DOI 10.1109/ESSDERC.2016.7599664
   Le Gallo M, 2016, J APPL PHYS, V119, DOI 10.1063/1.4938532
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lecun Y, 2019, ISSCC DIG TECH PAP I, V62, P12, DOI 10.1109/ISSCC.2019.8662396
   Lee JM, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00191
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li KS, 2014, S VLSI TECH
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Liu BY, 2015, DES AUT CON, DOI 10.1145/2744769.2744930
   Liu SJ, 2018, IEEE CIRC SYST MAG, V18, P29, DOI 10.1109/MCAS.2017.2785421
   Maan AK, 2017, IEEE T NEUR NET LEAR, V28, P1734, DOI 10.1109/TNNLS.2016.2547842
   Mahmoudi H, 2013, SOLID STATE ELECTRON, V84, P191, DOI 10.1016/j.sse.2013.02.017
   Mancini C, 2016, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON ANIMAL-COMPUTER INTERACTION, ACI 2016, DOI 10.1145/2995257.2995395
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Moraitis T, 2018, IEEE NANOTECHNOL MAG, V12, P45, DOI 10.1109/MNANO.2018.2845479
   Mostafa H, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9941
   MURRAY AF, 1994, IEEE T NEURAL NETWOR, V5, P792, DOI 10.1109/72.317730
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Nandakumar SR, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351656
   Hao N, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P224, DOI 10.1109/CISP.2015.7407880
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Nicholas JH., 2002, ACCURACY STABILITY N
   Nili H, 2018, NAT ELECTRON, V1, P197, DOI 10.1038/s41928-018-0039-7
   OVSHINSKY SR, 1968, PHYS REV LETT, V21, P1450, DOI 10.1103/PhysRevLett.21.1450
   Pantazi A, 2016, NANOTECHNOLOGY, V27, DOI 10.1088/0957-4484/27/35/355205
   Parihar A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-00825-1
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Pawlowski J. T., 2011, P IEEE HOT CHIPS 23, DOI DOI 10.1109/HOTCHIPS.2011.7477494
   Pfeiffer M, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00774
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Qiao N, 2015, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00141
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Salinga M, 2018, NAT MATER, V17, P681, DOI 10.1038/s41563-018-0110-9
   Sebastian A., 2019, 2019 Symposium on VLSI Technology, pT168, DOI 10.23919/VLSIT.2019.8776518
   Sebastian A, 2018, J APPL PHYS, V124, DOI 10.1063/1.5042413
   Sebastian A, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-01481-9
   Sengupta A, 2019, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.00095
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serb A, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12611
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharmin S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11732-w
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Sheridan PM, 2016, IEEE T NEUR NET LEAR, V27, P2327, DOI 10.1109/TNNLS.2015.2482220
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   STURGES RH, 1988, IEEE T ROBOTIC AUTOM, V4, P157, DOI 10.1109/56.2079
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Suri M, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Talati N, 2016, IEEE T NANOTECHNOL, V15, P635, DOI 10.1109/TNANO.2016.2570248
   Tang J., 2018, 2018 IEEE INT EL DEV, DOI [10.1109/IEDM.2018.8614551, DOI 10.1109/IEDM.2018.8614551]
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   Tuma T, 2016, IEEE ELECTR DEVICE L, V37, P1238, DOI 10.1109/LED.2016.2591181
   Tuma T, 2016, NAT NANOTECHNOL, V11, P693, DOI [10.1038/nnano.2016.70, 10.1038/NNANO.2016.70]
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/nmat4856, 10.1038/NMAT4856]
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Vourkas I, 2016, IEEE CIRC SYST MAG, V16, P15, DOI 10.1109/MCAS.2016.2583673
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
   Wang ZR, 2020, NAT REV MATER, V5, P173, DOI 10.1038/s41578-019-0159-3
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Woniak S., 2018, DEEP NETWORKS INCORP
   Wright CD, 2013, ADV FUNCT MATER, V23, P2248, DOI 10.1002/adfm.201202383
   Wu TF, 2018, IEEE J SOLID-ST CIRC, V53, P3183, DOI 10.1109/JSSC.2018.2870560
   Wuttig M, 2017, NAT PHOTONICS, V11, P465, DOI [10.1038/nphoton.2017.126, 10.1038/NPHOTON.2017.126]
   Xiong F, 2011, SCIENCE, V332, P568, DOI 10.1126/science.1201938
   Xu N, 2019, PHYS STATUS SOLIDI-R, V13, DOI 10.1002/pssr.201900033
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang KY, 2014, ISSCC DIG TECH PAP I, V57, P280, DOI 10.1109/ISSCC.2014.6757434
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yoon KJ, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600326
   Yoon SM, 2014, INT C CONTR AUTOMAT, P127, DOI 10.1109/ICCAS.2014.6987971
   Yu J, 2017, ASIAPAC SIGN INFO PR, P171
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhirnov V. V., 2015, EMERGING NANOELECTRO
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 180
TC 747
Z9 757
U1 100
U2 666
PD JUL
PY 2020
VL 15
IS 7
BP 529
EP 544
DI 10.1038/s41565-020-0655-z
EA MAR 2020
WC Nanoscience & Nanotechnology; Materials Science, Multidisciplinary
HC Y
HP N
DA 2023-11-11
ER

PT J
AU Ahammed, A
   Ezekiel, AM
   Obermaisser, R
AF Ahammed, Abu Shad
   Ezekiel, Aniebiet Micheal
   Obermaisser, Roman
TI Time-Efficient Identification Procedure for Neurological Complications
   of Rescue Patients in an Emergency Scenario Using Hardware-Accelerated
   Artificial Intelligence Models
SO ALGORITHMS
DT Article
DE neurology; machine learning; TVM; VTA; artificial intelligence; support
   vector machine; random forest; logistic regression; naive bayes;
   artificial neural network; K-nearest neighbour; prediction; rescue
   patient
ID DISEASES; BRAIN
AB During an emergency rescue operation, rescuers have to deal with many different health complications like cardiovascular, respiratory, neurological, psychiatric, etc. The identification process of the common health complications in rescue events is not very difficult or time-consuming because the health vital symptoms or primary observations are enough to identify, but it is quite difficult with some complications related to neurology e.g., schizophrenia, epilepsy with non-motor seizures, or retrograde amnesia because they cannot be identified with the trend of health vital data. The symptoms have a wide spectrum and are often non-distinguishable from other types of complications. Further, waiting for results from medical tests like MRI and ECG is time-consuming and not suitable for emergency cases where a quick treatment path is an obvious necessity after the diagnosis. In this paper, we present a novel solution for overcoming these challenges by employing artificial intelligence (AI) models in the diagnostic procedure of neurological complications in rescue situations. The novelty lies in the procedure of generating input features from raw rescue data used in AI models, as the data are not like traditional clinical data collected from hospital repositories. Rather, the data were gathered directly from more than 200,000 rescue cases and required natural language processing techniques to extract meaningful information. A step-by-step analysis of developing multiple AI models that can facilitate the fast identification of neurological complications, in general, is presented in this paper. Advanced data analytics are used to analyze the complete record of 273,183 rescue events in a duration of almost 10 years, including rescuers' analysis of the complications and their diagnostic methods. To develop the detection model, seven different machine learning algorithms-Support Vector Machine (SVM), Random Forest (RF), K-nearest neighbor (KNN), Extreme Gradient Boosting (XGB), Logistic Regression (LR), Naive Bayes (NB) and Artificial Neural Network (ANN) were used. Observing the model's performance, we conclude that the neural network and extreme gradient boosting show the best performance in terms of selected evaluation criteria. To utilize this result in practical scenarios, the paper also depicts the possibility of embedding such machine learning models in hardware like FPGA. The goal is to achieve fast detection results, which is a primary requirement in any rescue mission. An inference time analysis of the selected ML models and VTA AI accelerator of Apache-TVM machine learning compiler used for the FPGA is also presented in this research.
C1 [Ahammed, Abu Shad; Ezekiel, Aniebiet Micheal; Obermaisser, Roman] Univ Siegen, Chair Embedded Syst, Dept Elect Engn & Comp Sci, D-57076 Siegen, Germany.
RP Ahammed, A; Obermaisser, R (corresponding author), Univ Siegen, Chair Embedded Syst, Dept Elect Engn & Comp Sci, D-57076 Siegen, Germany.
EM abu.ahammed@uni-siegen.de; micheal.ezekiel@uni-siegen.de;
   roman.obermaisser@uni-siegen.de
CR Ahammed A.S., 2022, P IECON 2022 48 ANN
   Anderson M.R., 2013, P CIDR
   Berrar D., 2019, ENCY BIOINFORMATICS, P542, DOI [10.1016/B978-0-12-809633-8.20349-X, DOI 10.1016/B978-0-12-809633-8.20349-X]
   Chen TQ, 2018, Arxiv, DOI arXiv:1802.04799
   Chin JH, 2014, NEUROLOGY, V83, P349, DOI 10.1212/WNL.0000000000000610
   Chowdhary K. R., 2020, FUNDAMENTALS ARTIFIC, P603, DOI DOI 10.1007/978-81-322-3972-7_19
   Farkiya A., 2015, INT J COMPUT SCI INF, V6, P5465
   Feigin VL, 2019, LANCET NEUROL, V18, P459, DOI [10.1016/S1474-4422(18)30499-X, 10.1016/S1474-4422(19)30034-1, 10.1016/S1474-4422(18)30415-0]
   Fiala G, 2022, 2022 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS 2022), DOI 10.1109/SAS54819.2022.9881378
   Friedman J, 2000, ANN STAT, V28, P337, DOI 10.1214/aos/1016218223
   Gautam R, 2020, J MED SYST, V44, DOI 10.1007/s10916-019-1519-7
   Goeders J, 2018, ANN IEEE SYM FIELD P, P149, DOI 10.1109/FCCM.2018.00032
   Goldsmith J, 2020, IEEE ACCESS, V8, P129012, DOI 10.1109/ACCESS.2020.3008954
   Grattarola D, 2021, IEEE COMPUT INTELL M, V16, P99, DOI 10.1109/MCI.2020.3039072
   Guo S, 2004, GENES BRAIN BEHAV, V3, P63, DOI 10.1046/j.1601-183X.2003.00053.x
   HANLEY JA, 1982, RADIOLOGY, V143, P29, DOI 10.1148/radiology.143.1.7063747
   Jain A., 2020, P 26 ACM SIGKDD INT
   Jeyaraj M.N., 2022, ARXIV
   Jung M.G., 2015, P 2015 8 INT C DAT T
   Katarya Rahul, 2020, 2020 International Conference on Electronics and Sustainable Communication Systems (ICESC). Proceedings, P302, DOI 10.1109/ICESC48915.2020.9155586
   Kennedy DP, 2012, TRENDS COGN SCI, V16, P559, DOI 10.1016/j.tics.2012.09.006
   Kumar A, 2019, CHI EA '19 EXTENDED ABSTRACTS: EXTENDED ABSTRACTS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI [10.1145/3290607.3312928, 10.1109/imarc45935.2019.9118731]
   Li MZ, 2021, IEEE T PARALL DISTR, V32, P708, DOI 10.1109/TPDS.2020.3030548
   Lutz C, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1633, DOI 10.1145/3318464.3389705
   Ma BS, 2020, COMPUT BIOL MED, V121, DOI 10.1016/j.compbiomed.2020.103761
   Manaswi N. K, 2018, DEEP LEARNING APPL U, DOI [DOI 10.1007/978-1-4842-3516-4_2, 10.1007/978-1-4842-3516-4_2]
   Moreau T, 2019, IEEE MICRO, V39, P8, DOI 10.1109/MM.2019.2928962
   Nahiduzzaman M., 2020, P BRAIN INF 13 INT C
   Pradhan A., 2012, INT J EMERGING TECHN, V2, P82, DOI 10.1007/978-3-662-47926-1_26
   Ray Susmita, 2019, 2019 International Conference on Machine Learning, Big Data, Cloud and Parallel Computing (COMITCon), P35, DOI 10.1109/COMITCon.2019.8862451
   Realdigital, 2023, HARDW PYNQ Z2
   Saric R, 2020, BIOMED SIGNAL PROCES, V62, DOI 10.1016/j.bspc.2020.102106
   Sharma M, 2017, IRBM, V38, P305, DOI 10.1016/j.irbm.2017.09.002
   Shoeibi A, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18115780
   Silva J, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22062184
   Singh P., 2021, MACHINE LEARNING INT, P89, DOI DOI 10.1016/B978-0-12-821229-5.00003-3
   Siuly S, 2016, DATA SCI ENG, V1, P54, DOI 10.1007/s41019-016-0011-3
   Subramanian M., 1999, IEEE DATA ENG B, V22, P27
   Tanasa D, 2004, IEEE INTELL SYST, V19, P59, DOI 10.1109/MIS.2004.1274912
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Valliani AA, 2019, NEUROL THER, V8, P351, DOI 10.1007/s40120-019-00153-8
   Venkatesh R, 2019, J MED SYST, V43, DOI 10.1007/s10916-019-1398-y
NR 42
TC 0
Z9 0
U1 4
U2 4
PD MAY 18
PY 2023
VL 16
IS 5
AR 258
DI 10.3390/a16050258
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Zhang, KH
AF Zhang, Kaiheng
TI An Efficiency-Based Improvement of a Reconstruction Algorithm
   Reconstructs Signal from Its Scattering Transform
SO INTERNATIONAL JOURNAL OF WIRELESS INFORMATION NETWORKS
DT Article
DE Efficiency; Scattering transform; Gradient descent; Signal
   reconstruction
AB Scattering transform has many advantages and has been widely used in various fields since proposed. An algorithm using machine learning was proposed by some developers of Kymatio to reconstruct the signal based on the Scattering transform of the signal on the internet (Reconstruct a synthetic signal from its scattering transform (DB/OL) and Andreux et al. , 2019). In this paper, I improve this reconstruction algorithm to an efficiency-based algorithm. However, the coefficient in the original formula for the input signal is defined and followed by original gradient descent algorithm with the learning rate multiplied by an accelerator or braker for every iteration. Once the error is spotted out then the system is discarded. By introducing an efficiency parameter, the calculation time and the eliminated error are linked, so that coefficient can be determined to improve the efficiency and eliminated most errors in a short time. Also, the experimenter can adjust the importance parameter in the efficiency parameter to determine the importance of speed and accuracy, which provides the experimenter with more choices.
C1 [Zhang, Kaiheng] Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
RP Zhang, KH (corresponding author), Beijing Univ Posts & Telecommun, Beijing, Peoples R China.
EM 2018212828@bupt.edu.cn
CR Andén J, 2019, IEEE T SIGNAL PROCES, V67, P3704, DOI 10.1109/TSP.2019.2918992
   Andén J, 2014, IEEE T SIGNAL PROCES, V62, P4114, DOI 10.1109/TSP.2014.2326991
   Bruna J, 2013, IEEE T PATTERN ANAL, V35, P1872, DOI 10.1109/TPAMI.2012.230
   Eickenberg M., 2019, KYMATIO SCATTERING T
   Gupta R, 2020, CMES-COMP MODEL ENG, V123, P1175, DOI 10.32604/cmes.2020.010092
   Lostanlen V, SCATTERING M MATLAB
   Mallat S, 2016, PHILOS T R SOC A, V374, DOI 10.1098/rsta.2015.0203
   Mallat S, 2012, COMMUN PUR APPL MATH, V65, P1331, DOI 10.1002/cpa.21413
   Manogaran Gunasekaran, 2018, International Journal of Advanced Intelligence Paradigms, V10, P118
   Tateishi, 2020, MATH MACHINE LEARNIN, P15
   The Kymatio Developers, US GUID
   The Kymatio Developers, REC SYNTH SIGN ITS S
   The Mathwork Inc, WAV SCATT
   Waldspurger I, 2017, 2017 INTERNATIONAL CONFERENCE ON SAMPLING THEORY AND APPLICATIONS (SAMPTA), P143, DOI 10.1109/SAMPTA.2017.8024473
NR 14
TC 0
Z9 0
U1 0
U2 3
PD MAR
PY 2023
VL 30
IS 1
BP 111
EP 118
DI 10.1007/s10776-021-00526-7
EA AUG 2021
WC Telecommunications
DA 2023-11-11
ER

PT J
AU Lee, SH
   Zhu, XJ
   Lu, WD
AF Lee, Seung Hwan
   Zhu, Xiaojian
   Lu, Wei D.
TI Nanoscale resistive switching devices for memory and computing
   applications
SO NANO RESEARCH
DT Review
DE resistive switching; oxygen vacancy; metal cation; memory application;
   in-memory computing; bio-inspired application
ID MEMRISTIVE DEVICES; FILAMENT GROWTH; NEURAL-NETWORK; LOGIC OPERATIONS;
   CROSSBAR ARRAYS; DYNAMICS; CLASSIFICATION; EFFICIENT; STORAGE; SYSTEM
AB With the slowing down of the Moore's law and fundamental limitations due to the von-Neumann bottleneck, continued improvements in computing hardware performance become increasingly more challenging. Resistive switching (RS) devices are being extensively studied as promising candidates for next generation memory and computing applications due to their fast switching speed, excellent endurance and retention, and scaling and three-dimensional (3D) stacking capability. In particular, RS devices offer the potential to natively emulate the functions and structures of synapses and neurons, allowing them to efficiently implement neural networks (NNs) and other in-memory computing systems for data intensive applications such as machine learning tasks. In this review, we will examine the mechanisms of RS effects and discuss recent progresses in the application of RS devices for memory, deep learning accelerator, and more faithful brain-inspired computing tasks. Challenges and possible solutions at the device, algorithm, and system levels will also be discussed.
C1 [Lee, Seung Hwan; Zhu, Xiaojian; Lu, Wei D.] Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
RP Lu, WD (corresponding author), Univ Michigan, Dept Elect Engn & Comp Sci, Ann Arbor, MI 48109 USA.
EM wluee@umich.edu
CR Adam GC, 2016, NANO RES, V9, P3914, DOI 10.1007/s12274-016-1260-1
   Agarwal S, 2016, FRONT NEUROSCI-SWITZ, V9, DOI 10.3389/fnins.2015.00484
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   [Anonymous], 2017, P IEEE INT EL DEV M
   Appeltant L, 2011, NAT COMMUN, V2, DOI 10.1038/ncomms1476
   Baek IG, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Bai Y, 2014, SCI REP-UK, V4, DOI 10.1038/srep05780
   Balatti S, 2013, ADV MATER, V25, P1474, DOI 10.1002/adma.201204097
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P1831, DOI 10.1109/TED.2015.2422999
   Belmonte A, 2018, NANO RES, V11, P4017, DOI 10.1007/s12274-018-1983-2
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Burr GW, 2008, IBM J RES DEV, V52, P449, DOI 10.1147/rd.524.0449
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Chen B, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi BJ, 2016, ADV FUNCT MATER, V26, P5290, DOI 10.1002/adfm.201600680
   Choi BJ, 2016, ADV MATER, V28, P356, DOI 10.1002/adma.201503604
   Choi S, 2018, NAT MATER, V17, P335, DOI 10.1038/s41563-017-0001-5
   CHUA LO, 1976, P IEEE, V64, P209, DOI 10.1109/PROC.1976.10092
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Di Ventra M, 2013, NAT PHYS, V9, P200, DOI 10.1038/nphys2566
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Fackenthal R, 2014, ISSCC DIG TECH PAP I, V57, P338, DOI 10.1109/ISSCC.2014.6757460
   Fang HH, 2010, APPL PHYS LETT, V97, DOI 10.1063/1.3486683
   Feng S, 2019, MATER DESIGN, V162, P300, DOI 10.1016/j.matdes.2018.11.060
   Frank DJ, 2001, P IEEE, V89, P259, DOI 10.1109/5.915374
   Gaba S, 2014, IEEE ELECTR DEVICE L, V35, P1239, DOI 10.1109/LED.2014.2363618
   Gao LG, 2015, IEEE ELECTR DEVICE L, V36, P1157, DOI 10.1109/LED.2015.2481819
   Gao LG, 2013, IEEE T NANOTECHNOL, V12, P115, DOI 10.1109/TNANO.2013.2241075
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gomez R, 2012, ACMIEEE INT CONF HUM, P439
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Govoreanu B, 2014, IEEE ELECTR DEVICE L, V35, P63, DOI 10.1109/LED.2013.2291911
   Handy J, 2015, P 2015 STOR DEV C SA
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hsieh MC, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hsu CW, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Huang JJ, 2011, IEEE ELECTR DEVICE L, V32, P1427, DOI 10.1109/LED.2011.2161601
   Huang P, 2016, ADV MATER, V28, P9758, DOI 10.1002/adma.201602418
   Hubara I, 2018, J MACH LEARN RES, V18
   Hyung Dong Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P151, DOI 10.1109/VLSIT.2012.6242506
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Ielmini D, 2011, IEEE T ELECTRON DEV, V58, P3246, DOI 10.1109/TED.2011.2161088
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jaeger H, 2004, SCIENCE, V304, P78, DOI 10.1126/science.1091277
   Jaegera H, 2007, NEURAL NETWORKS, V20, P335, DOI 10.1016/j.neunet.2007.04.016
   James AP, 2014, IEEE T VLSI SYST, V22, P190, DOI 10.1109/TVLSI.2012.2232946
   Jeong DS, 2016, ADV ELECTRON MATER, V2, DOI 10.1002/aelm.201600090
   Jo S.H., 2015, P IEEE INT EL DEV M
   Jo SH, 2015, IEEE T ELECTRON DEV, V62, P3477, DOI 10.1109/TED.2015.2426717
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jo SH, 2009, NANO LETT, V9, P870, DOI 10.1021/nl8037689
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kau D., 2009, IEEE INT ELECT DEVIC, P1
   Kawahara A, 2013, IEEE J SOLID-ST CIRC, V48, P178, DOI 10.1109/JSSC.2012.2215121
   Khan HN, 2018, NAT ELECTRON, V1, P14, DOI 10.1038/s41928-017-0005-9
   Kim GH, 2013, ADV FUNCT MATER, V23, P1440, DOI 10.1002/adfm.201202170
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kim S, 2015, NANO LETT, V15, P2203, DOI 10.1021/acs.nanolett.5b00697
   Kim S, 2014, ACS NANO, V8, P2369, DOI 10.1021/nn405827t
   Kim S, 2013, SCI REP-UK, V3, DOI 10.1038/srep01680
   Kim WG, 2014, S VLSI TECH
   KRESSE G, 1993, PHYS REV B, V47, P558, DOI 10.1103/PhysRevB.47.558
   Lam Chung H, 2010, 10 IEEE INT C SOLID, P1080
   Larentis S, 2012, IEEE T ELECTRON DEV, V59, P2468, DOI 10.1109/TED.2012.2202320
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Lee J, 2019, ACS APPL MATER INTER, V11, P11579, DOI 10.1021/acsami.8b18386
   Lee J, 2018, ADV MATER, V30, DOI 10.1002/adma.201702770
   Lee J, 2016, ACS NANO, V10, P3571, DOI 10.1021/acsnano.5b07943
   Lee MJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3629
   Lee MJ, 2011, NAT MATER, V10, P625, DOI [10.1038/nmat3070, 10.1038/NMAT3070]
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Liu Q, 2010, ACS NANO, V4, P6162, DOI 10.1021/nn1017582
   Liu TY, 2014, IEEE J SOLID-ST CIRC, V49, P140, DOI [10.1109/JSSC.2013.2280296, 10.1109/ISSCC.2013.6487703]
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Markram H, 1997, SCIENCE, V275, P213, DOI 10.1126/science.275.5297.213
   Markram H, 2012, SCI AM, V306, P50, DOI 10.1038/scientificamerican0612-50
   Menzel S, 2015, NANOSCALE, V7, P12673, DOI 10.1039/c5nr02258d
   Menzel S, 2012, J APPL PHYS, V111, DOI 10.1063/1.3673239
   Moon J, 2019, NAT ELECTRON, V2, P480, DOI 10.1038/s41928-019-0313-3
   Moore G. E., 1975, IEDM, P11, DOI DOI 10.1109/N-SSC.2006.4804410
   MOORE GE, 1965, ELECTRONICS, V38
   Nardi F, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   OVSHINSKY SR, 1968, PHYS REV LETT, V21, P1450, DOI 10.1103/PhysRevLett.21.1450
   Park GS, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3382
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Pickett MD, 2013, NAT MATER, V12, P114, DOI [10.1038/NMAT3510, 10.1038/nmat3510]
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Qin SJ, 2015, PHYS CHEM CHEM PHYS, V17, P8627, DOI 10.1039/c4cp04903a
   Russo U, 2009, IEEE T ELECTRON DEV, V56, P1040, DOI 10.1109/TED.2009.2016019
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shin J, 2011, J APPL PHYS, V109, DOI 10.1063/1.3544205
   Sills S, 2014, S VLSI TECH
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Snider GS, 2007, NANOTECHNOLOGY, V18, DOI 10.1088/0957-4484/18/3/035204
   Son M, 2011, IEEE ELECTR DEVICE L, V32, P1579, DOI 10.1109/LED.2011.2163697
   Stoliar P, 2017, ADV FUNCT MATER, V27, DOI 10.1002/adfm.201604740
   Strukov DB, 2005, NANOTECHNOLOGY, V16, P888, DOI 10.1088/0957-4484/16/6/045
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun XY, 2019, IEEE J EM SEL TOP C, V9, P570, DOI 10.1109/JETCAS.2019.2933148
   Sutter H, 2005, DR DOBBS J, V30, P16
   Taur Y, 1997, P IEEE, V85, P486, DOI 10.1109/5.573737
   Tian XZ, 2014, NANO RES, V7, P1065, DOI 10.1007/s12274-014-0469-0
   Torrejon J, 2017, NATURE, V547, P428, DOI 10.1038/nature23011
   Valov I, 2016, NANOSCALE, V8, P13828, DOI 10.1039/c6nr01383j
   Valov I, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254003
   Verstraeten D, 2006, IEEE IJCNN, P1050
   Wang W, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aat4752
   Wang ZQ, 2012, ADV FUNCT MATER, V22, P2759, DOI 10.1002/adfm.201103148
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Woo J. O., 2014, SCI WORLD J, V2014, P7
   Wootae Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P37, DOI 10.1109/VLSIT.2012.6242449
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xia QF, 2009, NANO LETT, V9, P3640, DOI 10.1021/nl901874j
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Yang JJ, 2008, NAT NANOTECHNOL, V3, P429, DOI 10.1038/nnano.2008.160
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang YC, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5232
   Yang YC, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms1737
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Zahurak J, 2014, INT EL DEVICES MEET
   Zhu XJ, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900184
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, IEEE T MULTI-SCALE C, V4, P698, DOI 10.1109/TMSCS.2017.2721160
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
   Zidan MA, 2017, IEEE T NANOTECHNOL, V16, P721, DOI 10.1109/TNANO.2017.2710158
NR 138
TC 76
Z9 78
U1 5
U2 43
PD MAY
PY 2020
VL 13
IS 5
BP 1228
EP 1243
DI 10.1007/s12274-020-2616-0
EA JAN 2020
WC Chemistry, Physical; Nanoscience & Nanotechnology; Materials Science,
   Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Zhang, P
   Fang, JB
   Yang, CQ
   Huang, C
   Tang, T
   Wang, Z
AF Zhang, Peng
   Fang, Jianbin
   Yang, Canqun
   Huang, Chun
   Tang, Tao
   Wang, Zheng
TI Optimizing Streaming Parallelism on Heterogeneous Many-Core
   Architectures
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Task analysis; Graphics processing units; Hardware; Parallel processing;
   Runtime; Machine learning; Predictive models; Heterogeneous computing;
   parallelism; performance tuning; machine learning
ID INTEL XEON PHI; PERFORMANCE; OPENCL; OPTIMIZATION; COMPILER; PROCESSORS;
   GENERATION; PROGRAMS
AB As many-core accelerators keep integrating more processing units, it becomes increasingly more difficult for a parallel application to make effective use of all available resources. An effective way of improving hardware utilization is to exploit spatial and temporal sharing of the heterogeneous processing units by multiplexing computation and communication tasks - a strategy known as heterogeneous streaming. Achieving effective heterogeneous streaming requires carefully partitioning hardware among tasks, and matching the granularity of task parallelism to the resource partition. However, finding the right resource partitioning and task granularity is extremely challenging, because there is a large number of possible solutions and the optimal solution varies across programs and datasets. This article presents an automatic approach to quickly derive a good solution for hardware resource partition and task granularity for task-based parallel applications on heterogeneous many-core architectures. Our approach employs a performance model to estimate the resulting performance of the target application under a given resource partition and task granularity configuration. The model is used as a utility to quickly search for a good configuration at runtime. Instead of hand-crafting an analytical model that requires expert insights into low-level hardware details, we employ machine learning techniques to automatically learn it. We achieve this by first learning a predictive model offline using training programs. The learned model can then be used to predict the performance of any unseen program at runtime. We apply our approach to 39 representative parallel applications and evaluate it on two representative heterogeneous many-core platforms: a CPU-XeonPhi platform and a CPU-GPU platform. Compared to the single-stream version, our approach achieves, on average, a 1.6x and 1.1x speedup on the XeonPhi and the GPU platform, respectively. These results translate to over 93 percent of the performance delivered by a theoretically perfect predictor.
C1 [Zhang, Peng; Fang, Jianbin; Yang, Canqun; Huang, Chun; Tang, Tao] Natl Univ Def Technol, Comp Sci, Changsha 410073, Hunan, Peoples R China.
   [Wang, Zheng] Univ Leeds, Leeds LS2 9JT, W Yorkshire, England.
RP Fang, JB (corresponding author), Natl Univ Def Technol, Comp Sci, Changsha 410073, Hunan, Peoples R China.
EM zhangpeng13a@nudt.edu.cn; j.fang@nudt.edu.cn; canqun@nudt.edu.cn;
   chunhuang@nudt.edu.cn; taotang84@nudt.edu.cn; z.wang5@leeds.ac.uk
CR [Anonymous], 2017, INT J PARALLEL PROG, DOI DOI 10.1007/S10766-016-0425-6
   [Anonymous], 2013, ACM SIGPLAN NOTICES
   [Anonymous], 2015, POPULATION PYRAMIDS
   [Anonymous], 2017, P S COMP ARITHM, DOI DOI 10.1109/ARITH.2017.19
   [Anonymous], 2008, CH CRC COMP SCI DATA
   [Anonymous], 2018, INT C SUP ICS 2018, DOI DOI 10.1145/3205289.3205321
   [Anonymous], 2014, P 2014 IEEE INT PAR, DOI DOI 10.1109/IPDPSW.2014.115
   [Anonymous], 2018, J PARALLEL DISTR COM, DOI DOI 10.1016/J.JPDC.2017.09.005
   [Anonymous], 2016, IEEE SYM PARA DISTR, DOI DOI 10.1109/IPDPSW.2016.217
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-47099-3_10
   [Anonymous], 2017, SC17 P INT C HIGH, DOI DOI 10.1145/3126908.3126931
   [Anonymous], 2018, CON P 14 INT C EM, DOI DOI 10.1145/3281411.3281422
   [Anonymous], 2017, ACM SIGPLAN NOTICES, DOI DOI 10.1145/3078633.3081040
   [Anonymous], 2014, LECT NOTES COMPUT SC
   [Anonymous], 2016, PARALLEL PROCESS LET, DOI DOI 10.1142/S0129626416400028
   [Anonymous], 2013, INT SYM CODE GENER
   [Anonymous], 2015, CUDA C BEST PRACT GU
   [Anonymous], 2011, ENV LOWC STRAT
   [Anonymous], 2016, IEEE T PARALL DISTR, DOI DOI 10.1109/TPDS.2015.2442983
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Boslaugh S., 2012, STAT NUTSHELL, V2nd
   Chen C, 2017, COMPUTING, V99, P791, DOI 10.1007/s00607-016-0537-2
   Cummins C, 2017, INT CONFER PARA, P219, DOI 10.1109/PACT.2017.24
   Dastgeer U., 2011, P 4 INT WORKSH MULT, P25
   Ertel W., 1994, P INT C PAR ARCH LAN, P289
   Ferrao P., 2018, P EUR C PAR PROC, P796
   Fursin G., 2008, GCC SUMMIT
   Gómez-Luna J, 2012, J PARALLEL DISTR COM, V72, P1117, DOI 10.1016/j.jpdc.2011.07.011
   Gorsuch R. L., 2014, FACTOR ANAL, V2nd
   Grewe D, 2013, INT SYM CODE GENER, P161
   Grosser T., 2016, P INT C SUP, P1
   Hotelling H, 1933, J EDUC PSYCHOL, V24, P417, DOI 10.1037/h0071325
   Jha S, 2015, PROC VLDB ENDOW, V8, P642, DOI 10.14778/2735703.2735704
   Katagiri T, 2017, IEEE SYM PARA DISTR, P1399, DOI 10.1109/IPDPSW.2017.27
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kreyszig E., 2009, ADV ENG MATH, V10th
   Lastovetsky A, 2017, IEEE T PARALL DISTR, V28, P787, DOI 10.1109/TPDS.2016.2599527
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lee S., 2010, P ACM IEEE INT C HIG, P1
   Lee S, 2009, ACM SIGPLAN NOTICES, V44, P101, DOI 10.1145/1594835.1504194
   Li ZK, 2016, IEEE SYM PARA DISTR, P1341, DOI 10.1109/IPDPSW.2016.99
   Liao L., 2018, P 47 INT C PAR PROC
   Liu BZ, 2016, INT J HIGH PERFORM C, V30, P169, DOI 10.1177/1094342015585845
   Lu M, 2015, IEEE T PARALL DISTR, V26, P3066, DOI 10.1109/TPDS.2014.2365784
   Luk C. K., 2009, MICRO, P45
   Manly B. F., 2004, MULTIVARIATE STAT ME
   Marco VS, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P95, DOI 10.1145/3135974.3135984
   Memeti S, 2018, IEEE INT C COMPUT, P138, DOI 10.1109/CSE.2018.00026
   Meswani MR, 2013, INT J HIGH PERFORM C, V27, P89, DOI 10.1177/1094342012468180
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Nukada A., 2009, P C HIGH PERF COMP N, P1
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Rawat PS, 2018, P IEEE, V106, P1902, DOI 10.1109/JPROC.2018.2862896
   Ren J, 2017, IEEE INFOCOM SER
   Shen J, 2016, IEEE T PARALL DISTR, V27, P2766, DOI 10.1109/TPDS.2015.2509972
   Tang WT, 2015, INT SYM CODE GENER, P136, DOI 10.1109/CGO.2015.7054194
   Dao TT, 2018, IEEE T PARALL DISTR, V29, P283, DOI 10.1109/TPDS.2017.2755657
   The Khronos OpenCL Working Group, 2016, OPENCL OP STAND PAR
   Tillet P., 2017, P C HIGH PERF COMP N, P1
   Tournavitis G, 2009, ACM SIGPLAN NOTICES, V44, P177, DOI 10.1145/1543135.1542496
   van Werkhoven B, 2014, IEEE ACM INT SYMP, P11, DOI 10.1109/CCGrid.2014.16
   Wang Z, 2018, P IEEE, V106, P1879, DOI 10.1109/JPROC.2018.2817118
   Wang Z, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P307
   Wang Z, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2677036
   Wang Z, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2579561
   Wang Z, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2512436
   Wen Y, 2014, INT C HIGH PERFORM
   Yuan L., 2019, IEEE ACCESS, V7
   Zhang P, 2018, INT PARALL DISTRIB P, P515, DOI 10.1109/IPDPS.2018.00061
NR 69
TC 8
Z9 11
U1 2
U2 16
PD AUG 1
PY 2020
VL 31
IS 8
BP 1878
EP 1896
DI 10.1109/TPDS.2020.2978045
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zhang, X
   Hao, C
   Zhou, PP
   Jones, A
   Hu, JT
AF Zhang, Xinyi
   Hao, Cong
   Zhou, Peipei
   Jones, Alex
   Hu, Jingtong
GP ACM
TI H2H: Heterogeneous Model to Heterogeneous System Mapping with
   Computation and Communication Awareness
SO PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022
DT Proceedings Paper
CT 59th ACM/IEEE Design Automation Conference (DAC) - From Chips to Systems
   - Learn Today, Create Tomorrow
CY JUL 10-14, 2022
CL San Francisco, CA
AB The complex nature of real-world problems calls for heterogeneity in both machine learning (ML) models and hardware systems. The heterogeneity in ML models comes from multi-sensor perceiving and multi-task learning, i.e., multi-modality multi-task (MMMT), resulting in diverse deep neural network (DNN) layers and computation patterns. The heterogeneity in systems comes from diverse processing components, as it becomes the prevailing method to integrate multiple dedicated accelerators into one system. Therefore, a new problem emerges: heterogeneous model to heterogeneous system mapping (H2H). While previous mapping algorithms mostly focus on efficient computations, in this work, we argue that it is indispensable to consider computation and communication simultaneously for better system efficiency. We propose a novel H2H mapping algorithm with both computation and communication awareness; by slightly trading computation for communication, the system overall latency and energy consumption can be largely reduced. The superior performance of our work is evaluated based on MAESTRO modeling, demonstrating 15%-74% latency reduction and 23%-64% energy reduction compared with existing computation-prioritized mapping algorithms. Code is publicly available at https://github.com/xyzxinyizhang/H2H.
C1 [Zhang, Xinyi; Zhou, Peipei; Jones, Alex; Hu, Jingtong] Univ Pittsburgh, Pittsburgh, PA USA.
   [Hao, Cong] Georgia Inst Technol, Atlanta, GA USA.
RP Zhang, X (corresponding author), Univ Pittsburgh, Pittsburgh, PA USA.
EM xiz173@pitt.edu; callie.hao@ece.gatech.edu; peipei.zhou@pitt.edu;
   akjones@pitt.edu; jthu@pitt.edu
CR [Anonymous], AWS NETW
   Chen DR, 2018, J PARALLEL DISTR COM, V118, P379, DOI 10.1016/j.jpdc.2017.08.006
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Ditty M., 2018, HOT CHIPS S HIGH PER
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gaide B, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P84, DOI 10.1145/3289602.3293906
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3289185
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hao C, 2021, 2021 IEEE 3RD INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS), DOI 10.1109/AICAS51828.2021.9458577
   Iqbal M, 2018, Arxiv, DOI arXiv:1806.11226
   Jiang WW, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358192
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Kwon H, 2020, IEEE MICRO, V40, P20, DOI 10.1109/MM.2020.2985963
   Li B., 2020, P ACMIEEE INT S LOW, P175
   Li XY, 2017, Arxiv, DOI arXiv:1702.01638
   Ma YF, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P45, DOI 10.1145/3020078.3021736
   Mehler A, 2018, HT'18: PROCEEDINGS OF THE 29TH ACM CONFERENCE ON HYPERTEXT AND SOCIAL MEDIA, P150, DOI 10.1145/3209542.3209572
   nvidia, US
   Podili A, 2017, IEEE INT CONF ASAP, P11, DOI 10.1109/ASAP.2017.7995253
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Riley Chris, 2019, BASIC TUTORIAL MAXIM
   Shen T, 2019, IEEE COMPUT SOC CONF, P1611, DOI 10.1109/CVPRW.2019.00203
   Talpes E, 2020, IEEE MICRO, V40, P25, DOI 10.1109/MM.2020.2975764
   Taura K., 2000, Proceedings 9th Heterogeneous Computing Workshop (HCW 2000) (Cat. No.PR00556), P102, DOI 10.1109/HCW.2000.843736
   Thuseethan Selvarajah, 2020, 2020 WI IAT
   Tripathi S, 2019, Arxiv, DOI arXiv:1804.05788
   Valada A, 2018, IEEE INT CONF ROBOT, P6939, DOI 10.1109/ICRA.2018.8462979
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Chang AXM, 2017, Arxiv, DOI arXiv:1708.00117
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang SF, 2019, PROC CVPR IEEE, P919, DOI 10.1109/CVPR.2019.00101
   Zhang XY, 2020, PR IEEE COMP DESIGN, P469, DOI 10.1109/ICCD50377.2020.00086
NR 36
TC 3
Z9 3
U1 0
U2 0
PY 2022
BP 601
EP 606
DI 10.1145/3489517.3530509
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Robson, R
   Kelsey, E
   Goel, A
   Nasir, SM
   Robson, E
   Garn, M
   Lisle, M
   Kitchens, J
   Rugaber, S
   Ray, F
AF Robson, Robby
   Kelsey, Elaine
   Goel, Ashok
   Nasir, Sazzad M.
   Robson, Elliot
   Garn, Myk
   Lisle, Matt
   Kitchens, Jeanne
   Rugaber, Spencer
   Ray, Fritz
TI Intelligent links: AI-supported connections between employers and
   colleges
SO AI MAGAZINE
DT Article
AB When modernization and other changes demand workforce reskilling, employers often turn to local colleges for training programs. Doing so can be a frustrating experience. HR and talent professionals have difficulty identifying and communicating requirements, especially for new jobs and roles, while college continuing education (CE) and professional development offices have difficulty understanding and responding to company needs. This article describes an NSF Convergence Accelerator project called SkillSync((TM)) in which multiple forms of AI are used to address this specific problem and provide national efforts (e.g., the US Chamber of Commerce Talent Pipeline Management initiative) with skills data and skills alignment services. Skillsync uses variations on the Siamese Multi-depth Transformer-based Hierarchical Encoder (SMITH) and other natural language understanding methods to map job descriptions and course information to skills taxonomies, uses machine-learned models to align skills needs with learning outcomes and training, and incorporates an intelligent coach based on Georgia Tech's Jill Watson "virtual teaching assistant" to answer questions about Skillsync's vocabulary, functionality, and process. This article describes these AI methods, how these methods are used in Skillsync, and the challenges involved.
C1 [Robson, Robby; Kelsey, Elaine; Nasir, Sazzad M.; Robson, Elliot; Ray, Fritz] Eduworks Corp, 400 SW 4th St Suite 110, Corvallis, OR 97333 USA.
   [Goel, Ashok; Garn, Myk; Rugaber, Spencer] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Lisle, Matt] Univ Syst Georgia, Atlanta, GA USA.
   [Kitchens, Jeanne] Credential Engine, Washington, DC USA.
RP Robson, R (corresponding author), Eduworks Corp, 400 SW 4th St Suite 110, Corvallis, OR 97333 USA.
EM robby.robson@eduworks.com
CR An S, 2020, LECT NOTES ARTIF INT, V12164, P20, DOI 10.1007/978-3-030-52240-7_4
   [Anonymous], 1999, DESCENT MIND PSYCHOL
   Baxter G, 2011, INTERACT COMPUT, V23, P4, DOI 10.1016/j.intcom.2010.07.003
   Bell B., 2020, P 8 ANN GEN INT FRAM, P101
   Bordia S, 2019, NAACL HLT 2019: THE 2019 CONFERENCE OF THE NORTH AMERICAN CHAPTER OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS: HUMAN LANGUAGE TECHNOLOGIES: PROCEEDINGS OF THE STUDENT RESEARCH WORKSHOP, P7
   Broscheit Samuel, 2019, P 23 C COMP NAT LANG, P677, DOI DOI 10.18653/V1/K19-1063
   Devlin J., BERT PRE TRAINING DE
   Du J., 2019, ARXIV PREPRINT ARXIV
   Ferrucci D, 2010, AI MAG, V31, P59, DOI 10.1609/aimag.v31i3.2303
   Fry R., 2021, PEW RES CTR REPORT
   Goel A., 2020, ABS200601908 CORR
   Goel A., 2018, ED SCALE ENG ONLINE
   Goel A. K., 2016, VIRTUAL TEACHING ASS
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Joshi M, 2019, 2019 CONFERENCE ON EMPIRICAL METHODS IN NATURAL LANGUAGE PROCESSING AND THE 9TH INTERNATIONAL JOINT CONFERENCE ON NATURAL LANGUAGE PROCESSING (EMNLP-IJCNLP 2019), P5803
   Lu K, 2020, LOGIC LANGUAGE SECUR, P189
   Rajapakse, 2020, SIMPLE TRANSFORMERS
   Ruder Sebastian., 2019, P 2019 C N AM CHAPT, P15, DOI [10.18653/v1/N19-5004, 10.18653/v1/n19-5004, DOI 10.18653/V1/N19-5004]
   Stewart F, 2020, ECON DEV Q, V34, P356, DOI 10.1177/0891242420948604
   Wolf T, 2020, P 2020 C EMPIRICAL M, P38
   Yang L, 2020, CIKM '20: PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, P1725, DOI 10.1145/3340531.3411908
NR 21
TC 0
Z9 0
U1 3
U2 9
PD MAR
PY 2022
VL 43
IS 1
BP 75
EP 82
DI 10.1002/aaai.12040
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Srivastava, A
   Lazaris, A
   Brooks, B
   Kannan, R
   Prasanna, VK
AF Srivastava, Ajitesh
   Lazaris, Angelos
   Brooks, Benjamin
   Kannan, Rajgopal
   Prasanna, Viktor K.
GP Assoc Comp Machinery
TI Predicting Memory Accesses: The Road to Compact ML-driven Prefetcher
SO MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY
   SYSTEMS
DT Proceedings Paper
CT International Symposium on Memory Systems (MEMSYS)
CY SEP 30-OCT 03, 2019
CL Washington, DC
DE memory access prediction; prefetching; deep learning; compression
AB With the advent of fast processors, TPUs, accelerators, and heterogeneous architectures, computation is no longer the only bottleneck. In fact for many applications, speed of execution is limited by memory performance. To address memory performance, more accurate prefetching is necessary. While sophisticated machine learning algorithms have shown to predict memory accesses with high accuracy, they suffer with several issues that prevent them from being practical solutions as hardware prefetchers. These issues are centered around size of the model that results in high memory requirement, high latency and difficulty in online retraining. As the first step towards building ML-based prefetchers, we propose a compressed-LSTM approach for accurate memory access prediction. With a novel compression technique based on output encoding, we show that for the problem of predicting one of n memory locations, our technique results in O(n/log n) compression factor over the traditional LSTM approach. We further demonstrate through experiments on several benchmarks that the prediction accuracy drop due to compression is small and the training is fast. The actual compression obtained is of the order of 100x.
C1 [Srivastava, Ajitesh; Lazaris, Angelos; Brooks, Benjamin; Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90007 USA.
   [Kannan, Rajgopal] Army Res Lab West, Adelphi, MD USA.
RP Srivastava, A (corresponding author), Univ Southern Calif, Los Angeles, CA 90007 USA.
EM ajiteshs@usc.edu; alazaris@usc.edu; bjbrooks@usc.edu;
   rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR [Anonymous], 2016, 49 ANN IEEE ACM INT, DOI DOI 10.1109/MICR0.2016.7783763
   [Anonymous], 1999, LEARNING FORGET CONT
   [Anonymous], 2009, PROC ACM C HIGH PERF
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2016, ARXIV160405529
   [Anonymous], 2018, CORR
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Fedchenko V., 2018, CORR
   Hashemi M., 2018, LEARNING MEMORY ACCE
   Hashemi Milad, 2018, CORR
   Hinton G., 2015, ADV NEURAL INFORM PR, P2773
   Kondguli S, 2018, CONF PROC INT SYMP C, P83, DOI 10.1109/ISCA.2018.00018
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Michaud P, 2016, INT S HIGH PERF COMP, P469, DOI 10.1109/HPCA.2016.7446087
   Moreira FB, 2017, ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2017, P45, DOI 10.1145/3075564.3075578
   Narayanan Arvind, 2018, P 2018 WORKSH NETW M, P48
   Peled L, 2018, NEURAL NETWORK MEMOR
   Rahman S, 2015, IEEE I C EMBED SOFTW, P383, DOI 10.1109/HPCC-CSS-ICESS.2015.175
   Sakr M.F., 1997, ICML, V97, P305
   Sakr MF, 1996, IEEE IJCNN, P1564, DOI 10.1109/ICNN.1996.549133
   Shevgoor M, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P141, DOI 10.1145/2830772.2830793
   Xu ZX, 2017, DES AUT TEST EUROPE, P169, DOI 10.23919/DATE.2017.7926977
   Zeng Y, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P305, DOI 10.1145/3132402.3132405
NR 24
TC 14
Z9 14
U1 0
U2 1
PY 2019
BP 461
EP 470
DI 10.1145/3357526.3357549
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Wei, MT
   Lin, YS
   Lee, CR
AF Wei, Ming-ting
   Lin, Yu-Shiang
   Lee, Che-Rung
BE Chen, J
   Yang, LT
TI Performance Optimization for InfiniB and Virtualization on QEMU/KVM
SO 11TH IEEE INTERNATIONAL CONFERENCE ON CLOUD COMPUTING TECHNOLOGY AND
   SCIENCE (CLOUDCOM 2019)
SE International Conference on Cloud Computing Technology and Science
DT Proceedings Paper
CT 11th IEEE Int Conf on Cloud Comp Technol and Sci (CloudCom) / 19th IEEE
   Int Conf Comp and Informat Technol (CIT) / 2019 Int Workshop on Resource
   Brokering with Blockchain (RBchain) / Asia-Pacific Serv Comp Conf
   (APSCC)
CY DEC 11-13, 2019
CL Sydney, AUSTRALIA
DE Memory virtualization; QEMU/KVM; Infini-Band
AB The emergence of machine learning applications has brought the new demands for high performance computing in cloud environment. Besides accelerators, such as GPU or TPU, fast interconnection among and within computers becomes more and more important to achieve efficient training and learning. One of the high-bandwidth, low-latency interconnection architectures is InfiniBand. However, software based virtualization of InfiniBand in QEMU/KVM suffers large performance degradation owing to virtualization overhead and memory allocation problem. In this paper, two techniques, doorbell mapping and memlink, are proposed to optimize the performance the InfiniBand virtualization on QEMU/KVM. Doorbell mapping allows the applications in guest user-space to access the doorbell memory page directly so that the virtualization overhead is minimized. Memlink ensures memory contiguity after virtualization, which is a critical requirement for zero-copy between guest and host. Experiments show that the virtualized InfiniBand with mmap and memlink can achieve near native performance for large data transmissions. Comparing to the previous InfiniBand virtualization on QEMU/KVM, our implementation obtains over 3.5 times performance improvement in various benchmarks.
C1 [Wei, Ming-ting] Rayark Inc, Taipei, Taiwan.
   [Lin, Yu-Shiang] Ind Technol Res Inst, Informat & Commun Res Lab, Hsinchu, Taiwan.
   [Lee, Che-Rung] Natl Tsing Hua Univ, Dept Comp Sci, Hsinchu, Taiwan.
RP Wei, MT (corresponding author), Rayark Inc, Taipei, Taiwan.
EM mwei@rayark.com; YuShiangLin@itri.org.tw; cherung@cs.nthu.edu.tw
CR [Anonymous], ICPP 2018
   [Anonymous], 2014, RDMA AW NETW PROGR U
   [Anonymous], 2010, CISC VIS NETW IND GL
   [Anonymous], 2017, ACCURATE LARGE MINIB
   [Anonymous], 2009, CISC VIS NETW IND GL
   [Anonymous], 2001, HIGH PERFORMANCE MAS
   Bellard F, 2005, USENIX Association Proceedings of the FREENIX/Open Source Track, P41
   Bhoedjang RAF, 1998, COMPUTER, V31, P53, DOI 10.1109/2.730737
   Duato J., 2010, RCUDA REDUCING NUMBE, P224
   Gillespie M., 2009, BEST PRACTICES PARAV, V26, P2013
   Hsu HC, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY (CIT), P545, DOI 10.1109/CIT.2016.30
   Kutch P., 2011, APPL NOTE
   Liu J., HIGH PERFORMANCE VMM
   Liu JX, 2004, IEEE MICRO, V24, P42, DOI 10.1109/MM.2004.1268994
   Luszczek P. R., 2006, SC 06
   Russell R., 2018, ACM SIGOPS OPERATING, V42, P95
   Sayantan Sur, 2006, Proceedings of the 2006 ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming PPoPP'06, P32
   Shi L, 2012, IEEE T COMPUT, V61, P804, DOI 10.1109/TC.2011.112
   Tian Kun, 2014, P 2014 USENIX C USEN, P121
   Yi-Man Ma, 2012, 2012 IEEE 4th International Conference on Cloud Computing Technology and Science (CloudCom). Proceedings, P777, DOI 10.1109/CloudCom.2012.6427589
   Ying C., 2018, CORR
NR 21
TC 2
Z9 2
U1 2
U2 4
PY 2019
BP 19
EP 26
DI 10.1109/CloudCom.2019.00016
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Kinzer, S
   Kim, JK
   Ghodrati, S
   Yatham, B
   Althoff, A
   Mahajan, D
   Lerner, S
   Esmaeilzadeh, H
AF Kinzer, Sean
   Kim, Joon Kyung
   Ghodrati, Soroush
   Yatham, Brahmendra
   Althoff, Alric
   Mahajan, Divya
   Lerner, Sorin
   Esmaeilzadeh, Hadi
GP IEEE Comp Soc
TI A Computational Stack for Cross-Domain Acceleration
SO 2021 27TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2021)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 27th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 27-MAR 03, 2021
CL ELECTR NETWORK
DE Accelerator design; Machine learning systems; Algorithms/System
   Co-design; Domain Specific Language
ID LANGUAGE; DESIGN
AB Domain-specific accelerators obtain performance benefits by restricting their algorithmic domain. These accelerators utilize specialized languages constrained to particular hardware, thus trading off expressiveness for high performance. The pendulum has swung from one hardware for all domains (general-purpose processors) to one hardware per individual domain. The middle-ground on this spectrum-which provides a unified computational stack across multiple, but not all, domains-is an emerging and open research challenge. This paper sets out to explore this region and its associated tradeoff between expressiveness and performance by defining a cross-domain stack, dubbed PolyMath. This stack defines a high-level cross-domain language (CDL), called PMLang, that in a modular and reusable manner encapsulates mathematical properties to be expressive across multiple domains-Robotics, Graph Analytics, Digital Signal Processing, Deep Learning, and Data Analytics. PMLang is backed by a recursively-defined intermediate representation allowing simultaneous access to all levels of operation granularity, called srDFG. Accelerator-specific or domain-specific IRs commonly capture operations in the granularity that best fits a set of Domain-Specific Architectures (DSAs). In contrast, the recursive nature of the srDFG enables simultaneous access to all the granularities of computation for every operation, thus forming an ideal bridge for converting to various DSA-specific IRs across multiple domains. Our stack unlocks multi-acceleration for end-to-end applications that cross the boundary of multiple domains each comprising different data and compute patterns.
   Evaluations show that by using PolyMath it is possible to harness accelerators across the five domains to realize an average speedup of 3.3 x over a Xeon CPU along with 18.1 x reduction in energy. In comparison to Jetson Xavier and Titan XP, cross-domain acceleration offers 1.7 x and 7.2 x improvement in performance-per-watt, respectively. We measure the cross-domain expressiveness and performance tradeoff by comparing each benchmark against its hand-optimized implementation to achieve 83.9% and 76.8% of the optimal performance for single-domain algorithms and end-to-end applications. For the two case studies of end-to-end applications (comprising algorithms from multiple domains), results show that accelerating all kernels offers an additional 2.0 x speedup over CPU, 6.1 x improvement in performance-per-watt over Titan Xp, and 2.8 x speedup over Jetson Xavier compared to only the one most effective single-domain kernel being accelerated. Finally, we examine the utility and expressiveness of PolyMath through a user study, which shows, on average, PolyMath requires 1.9 x less time to implement algorithms from two different domains with 2.5 x fewer lines of code relative to Python.
C1 [Kinzer, Sean; Kim, Joon Kyung; Ghodrati, Soroush; Yatham, Brahmendra; Lerner, Sorin; Esmaeilzadeh, Hadi] Univ Calif San Diego, Alternat Comp Technol ACT Lab, San Diego, CA 92103 USA.
   [Althoff, Alric] Tortuga Log, San Jose, CA USA.
   [Mahajan, Divya] Microsoft, Redmond, WA USA.
RP Kinzer, S (corresponding author), Univ Calif San Diego, Alternat Comp Technol ACT Lab, San Diego, CA 92103 USA.
EM skinzer@eng.ucsd.edu; jkkim@eng.ucsd.edu; soghodra@eng.ucsd.edu;
   byatham@eng.ucsd.edu; alric@tortugalogic.com;
   divya.mahajan@microsoft.com; lerner@eng.ucsd.edu; hadi@eng.ucsd.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   ACTLab, 2017, TABLA SOURC COD
   Ahn Byung Hoon, 2020, ICLR
   Ahn Byung Hoon, 2020, MLSYS
   [Anonymous], 2007, TEXAS INSTRUMENTS C6
   [Anonymous], 2011, ICML
   [Anonymous], 2017, MATLAB VERS 9 3 0 71
   Auerbach J, 2010, ACM SIGPLAN NOTICES, V45, P89, DOI 10.1145/1932682.1869469
   Bezanson J, 2012, ABS12095145 CORR
   Bordignon M, 2011, IEEE INT C INT ROBOT, P3659, DOI 10.1109/IROS.2011.6048419
   Chandramoorthy N, 2015, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2015.7056017
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen Y, 2016, DESTECH TRANS COMP
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Curtin RR, 2013, J MACH LEARN RES, V14, P801
   Davis JD, 2008, DES AUT CON, P780
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Del Sozzo E., 2018, 2018 IEEE 29 INT C A, P1
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Felipe Kuhne, 2005, LAT AM ROB S
   Fix Jordan, 2018, ABS180500907 CORR
   Frigerio Marco, 2015, INT WORKSH DOM SPEC
   Frigo M, 2005, P IEEE, V93, P216, DOI 10.1109/JPROC.2004.840301
   Ghodrati Soroush, 2020, 2020 53 ANN IEEE ACM
   Ghodrati Soroush, 2020, PACT
   Grouplens, MOVIELENS DATASET
   Ham TJ, 2016, INT SYMP MICROARCH
   Hameed R, 2010, CONF PROC INT SYMP C, P37, DOI 10.1145/1816038.1815968
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Houska B, 2011, OPTIM CONTR APPL MET, V32, P298, DOI 10.1002/oca.939
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Jain AK, 2016, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2016.10
   Kamel M, 2015, IEEE INTL CONF CONTR, P1160, DOI 10.1109/CCA.2015.7320769
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Kotsifakou M, 2018, ACM SIGPLAN NOTICES, V53, P68, DOI 10.1145/3200691.3178493
   Kwak Haewoon, 2010, P 19 INT C WORLD WID, P591, DOI DOI 10.1145/1772690.1772751
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner Chris, 2019, MLIR PRIMER COMPILER
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LICHMAN M., 2013, UCI MACHINE LEARNING
   Lindholm T., 2014, JAVA VIRTUAL MACHINE, V8th
   Liu H, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807594
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Moreau T., 2019, IEEE MICRO
   Moreau Thierry, 2018, ABS180704188 CORR
   Morris GW, 2007, I C FIELD PROG LOGIC, P5, DOI 10.1109/FPL.2007.4380617
   Murray S., 2016, P 49 ANN IEEE ACM IN, P1, DOI DOI 10.1109/MICRO.2016.7783748
   Nicolas Vasilache, 2018, ABS180204730 CORR
   Nvidia, 2008, NVID CUD SDK IM VID
   Nvidia, DENS LIN ALG GPUS
   Nvidia, NV TOOLK
   Nvidia, NVID NVBLAS LIB
   Nvidia, NV CUD FAST FOUR TRA
   Paszke A., 2017, NEURIPS
   Patterson David, 2017, ABS170404760 CORR
   R Core Team, 2021, R LANG ENV STAT COMP
   Ragan-Kelley J, 2018, COMMUN ACM, V61, P106, DOI 10.1145/3150211
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Roesch J, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P58, DOI 10.1145/3211346.3211348
   Sacks J, 2018, CONF PROC INT SYMP C, P479, DOI 10.1109/ISCA.2018.00047
   Samragh M, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3391901
   Sanderson Conrad, 2016, J OPEN SOURCE SOFTW
   Shao YS, 2014, CONF PROC INT SYMP C, P97, DOI 10.1109/ISCA.2014.6853196
   Sharma H, 2016, INT SYMP MICROARCH
   Steele Guy L., 2006, P 11 ACM SIGPLAN S P, P1, DOI [10.1145/1122971.1122972, DOI 10.1145/1122971.1122972]
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Turakhia Y, 2018, ACM SIGPLAN NOTICES, V53, P199, DOI [10.1145/3173162.3173193, 10.1145/3296957.3173193]
   van der Walt S, 2011, COMPUT SCI ENG, V13, P22, DOI 10.1109/MCSE.2011.37
   Venkatesh G, 2010, ASPLOS XV: FIFTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P205
   Zhang XY, 2012, INT C PAR DISTRIB SY, P684, DOI 10.1109/ICPADS.2012.97
NR 72
TC 5
Z9 5
U1 0
U2 2
PY 2021
BP 54
EP 70
DI 10.1109/HPCA51647.2021.00015
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ganesan, V
   Selvam, S
   Sen, S
   Kumar, P
   Raghunathan, A
AF Ganesan, Vinod
   Selvam, Surya
   Sen, Sanchari
   Kumar, Pratyush
   Raghunathan, Anand
GP IEEE
TI A Case for Generalizable DNN Cost Models for Mobile Devices
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON WORKLOAD CHARACTERIZATION (IISWC
   2020)
SE International Symposium on Workload Characterization Proceedings
DT Proceedings Paper
CT 16th IEEE International Symposium on Workload Characterization (IISWC)
CY OCT 27-29, 2020
CL ELECTR NETWORK
DE runtime; deep learning; mobile devices; machine learning
AB Accurate workload characterization of Deep Neural Networks (DNNs) is challenged by both network and hardware diversity. Networks are being designed with newer motifs such as depthwise separable convolutions, bottleneck layers, etc., which have widely varying performance characteristics. Further, the adoption of Neural Architecture Search (NAS) is creating a Cambrian explosion of networks, greatly expanding the space of networks that must be modeled. On the hardware front, myriad accelerators are being built for DNNs, while compiler improvements are enabling more efficient execution of DNNs on a wide range of CPUs and GPUs. Clearly, characterizing each DNN on each hardware system is infeasible. We thus need cost models to estimate performance that generalize across both devices and networks. In this work, we address this challenge by building a cost model of DNNs on mobile devices. The modeling and evaluation are based on latency measurements of 118 networks on 105 mobile System-on-Chips (SoCs). As a key contribution, we propose that a hardware platform can be represented by its measured latencies on a judiciously chosen, small set of networks, which we call the signature set. We also design a machine learning model that takes as inputs (i) the target hardware representation (measured latencies of the signature set on the hardware) and (ii) a representation of the structure of the DNN to be evaluated, and predicts the latency of the DNN on the target hardware. We propose and evaluate different algorithms to select the signature set. Our results show that by carefully choosing the signature set, the network representation, and the machine learning algorithm, we can train accurate cost models that generalize well. We demonstrate the value of such a cost model in a collaborative workload characterization setup, wherein every mobile device contributes a small set of latency measurements to a centralized repository. With even a small number of measurements per new device, we show that the proposed cost model matches the accuracy of device-specific models trained on an order-of-magnitude larger number of measurements. The entire codebase is released at https://github.com/iitm-sysdl/Generalizable-DNNcost-models.
C1 [Ganesan, Vinod; Selvam, Surya; Kumar, Pratyush] IIT Madras, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
   [Sen, Sanchari; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
   [Selvam, Surya] Purdue Univ, W Lafayette, IN 47907 USA.
   [Sen, Sanchari] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
RP Ganesan, V (corresponding author), IIT Madras, Dept Comp Sci & Engn, Chennai, Tamil Nadu, India.
EM vinodg@cse.iitm.ac.in; cs16b029@cse.iitm.ac.in; sen9@purdue.edu;
   pratyush@cse.iitm.ac.in; raghunathan@purdue.edu
CR Adams A, 2019, ACM T GRAPHIC, V38, DOI 10.1145/3306346.3322967
   [Anonymous], 2016, KDD16 P 22 ACM, DOI DOI 10.1145/2939672.2939785
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Cai H., 2019, ONCE FOR ALL TRAIN N
   Chen Tianqi, 2018, ARXIV180508166, V31, P3389
   Dai XL, 2019, PROC CVPR IEEE, P11390, DOI 10.1109/CVPR.2019.01166
   Han S., 2018, ARXIV PREPRINT ARXIV
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kaufman Samuel, 2019, P WORKSH ML SYST NEU, P1
   Krause A, 2008, J MACH LEARN RES, V9, P235
   Leskovec J., 2017, NIPS
   Paszke A, 2019, ADV NEUR IN, V32
   Redmon J., 2016, ARXIV160207360, P779
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Wang D., SINGLE PATH NAS DESI
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
NR 20
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 169
EP 180
DI 10.1109/IISWC50251.2020.00025
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Shea, C
   Mohsenin, T
AF Shea, Colin
   Mohsenin, Tinoosh
TI Heterogeneous Scheduling of Deep Neural Networks for Low-power Real-time
   Designs
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT 3rd Workshop on Hardware Algorithms for Learning On-a-Chip (HALO)
CY NOV 16, 2017
CL Irvine, CA
DE Machine learning; real-time; scheduling; co-design; hardware; software;
   FPGA
AB Deep neural networks have become the readiest answer to a range of application challenges including image recognition, stock analysis, natural language processing, and biomedical applications such as seizure detection. All while outperforming prior leading solutions that relied heavily on hand-engineered techniques. However, deployment of these neural networks often requires high-computational and memory-intensive solutions. These requirements make it challenging to deploy Deep Neural Networks (DNNs) in embedded, real-time low-power applications where classic architectures, GPUs and CPUs, still impose significant power burden. Systems-on-Chip (SoC) with Field-programmable Gate Arrays (FPGAs) can be used to improve performance and allow more fine-grain control of resources than CPUs or GPUs, but it is difficult to find the optimal balance between hardware and software to improve DNN efficiency. In the current research literature there have been few proposed solutions to address optimizing hardware and software deployments of DNNs in embedded low-power systems. To address the computation resource restriction and low-power needs for deploying these networks, we describe and implement a domain-specific metric model for optimizing task deployment on differing platforms, hardware and software. Next, we propose a DNN hardware accelerator called Scalable Low-power Accelerator for real-time deep neural Networks (SCALENet) that includes multithreaded software workers. Finally, we propose a heterogeneous aware scheduler that uses the DNN-specific metric models and the SCALENet accelerator to allocate a task to a resource based on solving a numerical cost for a series of domain objectives. To demonstrate the applicability of our contribution, we deploy nine modern deep network architectures, each containing a different number of parameters within the context of two different neural network applications: image processing and biomedical seizure detection. Utilizing the metric modeling techniques integrated into the heterogeneous aware scheduler and the SCALENet accelerator, we demonstrate the ability to meet computational requirements, adapt to multiple architectures, and lower power by providing an optimized task to resource allocation. Our heterogeneous aware scheduler improves power saving by decreasing power consumption by 10% of the total system power, does not affect the accuracy of the networks, and still meets the real-time deadlines. We demonstrate the ability to achieve parity with or exceed the energy efficiency of NVIDIA GPUs when evaluated against Jetson TK1 with embedded GPU SoC and with a 4x power savings in a power envelope of 2.0W. When compared to existing FPGA-based accelerators, SCALENet's accelerator and heterogeneous aware scheduler achieves a 4.8x improvement in energy efficiency.
C1 [Shea, Colin; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, 1000 Hilltop Circle, Catonsville, MD 21250 USA.
RP Shea, C (corresponding author), Univ Maryland Baltimore Cty, 1000 Hilltop Circle, Catonsville, MD 21250 USA.
EM cshea3@umbc.edu; tinoosh@umbc.edu
CR Abtahi T., 2017, 2017 IEEE INT S CIRC, P1
   Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   Acharya UR, 2018, COMPUT BIOL MED, V100, P270, DOI 10.1016/j.compbiomed.2017.09.017
   [Anonymous], POW METH GUID
   [Anonymous], 2018, P INT C RECONFIGURAB
   [Anonymous], ACM SIGARCH COMPUTER
   [Anonymous], 2015, 2015 IEEE 12 INT C W, DOI DOI 10.1109/BSN.2015.7299406
   Braun TD, 2001, J PARALLEL DISTR COM, V61, P810, DOI 10.1006/jpdc.2000.1714
   Cannell P, 2016, J INTERACT MEDIA EDU, DOI 10.5334/jime.412
   Chafi H, 2011, ACM SIGPLAN NOTICES, V46, P35, DOI 10.1145/2038037.1941561
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   DiCecco R, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P265, DOI 10.1109/FPT.2016.7929549
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Figueira SM, 1996, PROCEEDINGS OF THE FIFTH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, P392, DOI 10.1109/HPDC.1996.546210
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   He K., 2016, INDIAN J CHEM B
   Hosseini M, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317873
   Hosseini M, 2019, INT SYM QUAL ELECT, P259, DOI 10.1109/ISQED.2019.8697574
   Iandola FN, 2016, PROC INT C LEARN
   Inggs G, 2013, PROC INT CONF PARAL, P688, DOI 10.1109/ICPP.2013.82
   Javaheripi Mojan, 2019, P AUTOML WORKSH 36 I
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kang QM, 2011, J SYST SOFTWARE, V84, P985, DOI 10.1016/j.jss.2011.01.051
   Khaturia M., 2018, P 2018 IEEE 19 WORKS, P1
   Khatwani M., 2019, P IEEE EMBS C NEUR E
   Liu X., ABS180206367 CORR
   Ma JZ, 2015, SOLID STATE SCI, V49, P1, DOI 10.1016/j.solidstatesciences.2015.09.007
   Makrani HM, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P727, DOI 10.1145/3287624.3288756
   Neshatpour K, 2019, INT SYM QUAL ELECT, P265, DOI 10.1109/ISQED.2019.8697497
   Neshatpour K, 2018, DES AUT TEST EUROPE, P551, DOI 10.23919/DATE.2018.8342068
   Ortega-Zamorano F, 2014, IEEE T IND INFORM, V10, P1154, DOI 10.1109/TII.2013.2294137
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Park SH, 2015, PLANT BIOTECHNOL REP, V9, P6
   Samragh M., 2019, ABS190105582 CORR
   Samragh M., 2019, P ML FOR SYST WORKSH
   Sayadi H, 2017, PR IEEE COMP DESIGN, P129, DOI 10.1109/ICCD.2017.28
   Shea C., 2018, ACM P GREAT LAK S VE
   Sim Jaehyeong, 2016, P INT SOL STAT CIRC
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035
   Vasilache N, 2014, ABS14127580 CORR
   Zhang Chen, 2015, P INT S FIELD PROGR
   Zhong G., 2018, ABS180400706 CORR
   Zisserman A., 2014, 14091556 ARXIV
NR 49
TC 9
Z9 10
U1 0
U2 6
PD DEC
PY 2019
VL 15
IS 4
SI SI
AR 36
DI 10.1145/3358699
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Vidyaratne, L
   Carpenter, A
   Powers, T
   Tennant, C
   Iftekharuddin, KM
   Rahman, MM
   Shabalina, AS
AF Vidyaratne, Lasitha
   Carpenter, Adam
   Powers, Tom
   Tennant, Chris
   Iftekharuddin, Khan M. M.
   Rahman, Md Monibor
   Shabalina, Anna S. S.
TI Deep Learning Based Superconducting Radio-Frequency Cavity Fault
   Classification at Jefferson Laboratory
SO FRONTIERS IN ARTIFICIAL INTELLIGENCE
DT Article
DE time-series classification; fault identification; superconducting
   radio-frequency cavities; particle accelerator; LINAC; deep recurrent
   learning; convolutional neural networks
ID TIME-SERIES; SYSTEM
AB This work investigates the efficacy of deep learning (DL) for classifying C100 superconducting radio-frequency (SRF) cavity faults in the Continuous Electron Beam Accelerator Facility (CEBAF) at Jefferson Lab. CEBAF is a large, high-power continuous wave recirculating linac that utilizes 418 SRF cavities to accelerate electrons up to 12 GeV. Recent upgrades to CEBAF include installation of 11 new cryomodules (88 cavities) equipped with a low-level RF system that records RF time-series data from each cavity at the onset of an RF failure. Typically, subject matter experts (SME) analyze this data to determine the fault type and identify the cavity of origin. This information is subsequently utilized to identify failure trends and to implement corrective measures on the offending cavity. Manual inspection of large-scale, time-series data, generated by frequent system failures is tedious and time consuming, and thereby motivates the use of machine learning (ML) to automate the task. This study extends work on a previously developed system based on traditional ML methods (Tennant and Carpenter and Powers and Shabalina Solopova and Vidyaratne and Iftekharuddin, Phys. Rev. Accel. Beams, 2020, 23, 114601), and investigates the effectiveness of deep learning approaches. The transition to a DL model is driven by the goal of developing a system with sufficiently fast inference that it could be used to predict a fault event and take actionable information before the onset (on the order of a few hundred milliseconds). Because features are learned, rather than explicitly computed, DL offers a potential advantage over traditional ML. Specifically, two seminal DL architecture types are explored: deep recurrent neural networks (RNN) and deep convolutional neural networks (CNN). We provide a detailed analysis on the performance of individual models using an RF waveform dataset built from past operational runs of CEBAF. In particular, the performance of RNN models incorporating long short-term memory (LSTM) are analyzed along with the CNN performance. Furthermore, comparing these DL models with a state-of-the-art fault ML model shows that DL architectures obtain similar performance for cavity identification, do not perform quite as well for fault classification, but provide an advantage in inference speed.
C1 [Vidyaratne, Lasitha; Carpenter, Adam; Powers, Tom; Tennant, Chris] Jefferson Lab, Newport News, VA 23606 USA.
   [Iftekharuddin, Khan M. M.; Rahman, Md Monibor] Old Dominion Univ, Dept Elect & Comp Engn, ODU Vis Lab, Norfolk, VA USA.
   [Shabalina, Anna S. S.] Jefferson Lab, Warrington, England.
RP Vidyaratne, L (corresponding author), Jefferson Lab, Newport News, VA 23606 USA.
EM lasithav@jlab.org
CR BEVERIDGE S, 1981, J MONETARY ECON, V7, P151, DOI 10.1016/0304-3932(81)90040-4
   Breiman L, 2001, MACH LEARN, V45, P5, DOI 10.1023/A:1010933404324
   Caiado J, 2006, COMPUT STAT DATA AN, V50, P2668, DOI 10.1016/j.csda.2005.04.012
   Cho J, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20123491
   Chua KC, 2010, MED ENG PHYS, V32, P679, DOI 10.1016/j.medengphy.2010.04.009
   De Veaux R. D., 2005, STATS DATA MODELS
   Eren L, 2019, J SIGNAL PROCESS SYS, V91, P179, DOI 10.1007/s11265-018-1378-3
   Geron A., 2019, HANDS ON MACHINE LEA
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Malhotra P., 2015, P ESANN, V89
   Meidinger EE., 1980, APPL TIME SERIES ANA
   Paszke A, 2019, ADV NEUR IN, V32
   Reece CE, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.124801
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Shoeb A., 2010, P 27 INT C MACH LEAR, P975, DOI [10.5555/3104322.3104446, DOI 10.5555/3104322.3104446]
   Shumway R.H., 2000, TIME SERIES ANAL ITS, DOI 10.1007/978-1-4757-3261-0
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
   Ullah I, 2018, EXPERT SYST APPL, V107, P61, DOI 10.1016/j.eswa.2018.04.021
   Vidyaratne&DAG; L., 2021, 18 INT C ACCELERATOR
   Wei XY, 2018, BMC MED INFORM DECIS, V18, DOI 10.1186/s12911-018-0693-8
   Zhao XQ, 2019, IEEE T NEUR SYS REH, V27, P2164, DOI 10.1109/TNSRE.2019.2938295
NR 24
TC 1
Z9 1
U1 1
U2 5
PD JAN 3
PY 2022
VL 4
AR 718950
DI 10.3389/frai.2021.718950
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Kulkarni, A
   Page, A
   Attaran, N
   Jafari, A
   Malik, M
   Homayoun, H
   Mohsenin, T
AF Kulkarni, Adwaya
   Page, Adam
   Attaran, Nasrin
   Jafari, Ali
   Malik, Maria
   Homayoun, Houman
   Mohsenin, Tinoosh
TI An Energy-Efficient Programmable Manycore Accelerator for Personalized
   Biomedical Applications
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Low-power manycore accelerator; personalized biomedical applications;
   seizure detection; stress detection; tongue drive system (TDS)
ID PROCESSOR; PARALLEL; PLATFORM
AB Wearable personalized health monitoring systems can offer a cost-effective solution for human health care. These systems must constantly monitor patients' physiological signals and provide highly accurate, and quick processing and delivery of the vast amount of data within a limited power and area footprint. These personalized biomedical applications require sampling and processing multiple streams of physiological signals with a varying number of channels and sampling rates. The processing typically consists of feature extraction, data fusion, and classification stages that require a large number of digital signal processing (DSP) and machine learning (ML) kernels. In response to these requirements, in this paper, a tiny, energy-efficient, and domain-specific manycore accelerator referred to as power-efficient nanoclusters (PENC) is proposed to map and execute the kernels of these applications. Simulation results show that the PENC is able to reduce energy consumption by up to 80% and 25% for DSP and ML kernels, respectively, when optimally parallelized. In addition, we fully implemented three compute-intensive personalized biomedical applications, namely, multichannel seizure detection, multiphysiological stress detection, and standalone tongue drive system (sTDS), to evaluate the proposed manycore performance relative to commodity embedded CPU, graphical processing unit (GPU), and field-programmable gate array (FPGA)-based implementations. For these three case studies, the energy consumption and the performance of the proposed PENC manycore, when acting as an accelerator along with an Intel Atom processor as a host, are compared with the existing commercial off-the-shelf general-purpose, customizable, and programmable embedded platforms, including Intel Atom, Xilinx Artix-7 FPGA, and NVIDIA TK1 advanced RISC machine -A15 and KI GPU system on a chip. For these applications, the PENC manycore is able to significantly improve throughput and energy efficiency by up to 1872x and 276x, respectively. For the most computational intensive application of seizure detection, the PENC manycore is able to achieve a throughput of 15.22 giga-operations-per-second (GOPs), which is a 14x improvement in throughput over custom FPGA solution. For stress detection, the PENC achieves a throughput of 21.36 GOPs and an energy efficiency of 4.23 GOP/J, which is 14.87x and 2.28x better over FPGA implementation, respectively. For the sTDS application, the PENC improves a throughput by 5.45x and an energy efficiency by 2.37x over FPGA implementation.
C1 [Kulkarni, Adwaya; Page, Adam; Attaran, Nasrin; Jafari, Ali; Mohsenin, Tinoosh] Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
   [Malik, Maria; Homayoun, Houman] George Mason Univ, Elect & Comp Engn Dept, Fairfax, VA 22030 USA.
RP Kulkarni, A (corresponding author), Univ Maryland, Dept Comp Sci & Elect Engn, Baltimore, MD 21250 USA.
EM adwayak1@umbc.edu
CR Al Khatib I, 2006, DES AUT CON, P125, DOI 10.1109/DAC.2006.229190
   Alemzadeh H., 2011, 2011 IEEE/NIH 5th Life Science Systems and Applications Workshop (LiSSA), P112, DOI 10.1109/LISSA.2011.5754169
   [Anonymous], P IEEE BIOM CIRC SYS
   [Anonymous], 2016, IEEE SENSORS DIG TEC
   [Anonymous], 2014, DAC 14
   [Anonymous], THESIS
   [Anonymous], IEEE T BIOM IN PRESS
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2016, 2016 INT C HARDWARES
   [Anonymous], 2006, IMPERIAL COLL REPORT
   [Anonymous], CADENCE DESIGN SYSTE
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 2012, PROC IEEE S VLSI CIR, DOI DOI 10.1109/VLSIC.2012.6243837
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], 2013, THESIS
   [Anonymous], 2010, P INT C MOB COMP APP
   [Anonymous], ACM T EMBED IN PRESS
   [Anonymous], 2013, P WORKSH POW AW COMP
   [Anonymous], P 21 ED GREAT LAK S
   Asano S, 2009, I C FIELD PROG LOGIC, P126, DOI 10.1109/FPL.2009.5272532
   Bisasky J, 2013, INT SYM QUAL ELECT, P368, DOI 10.1109/ISQED.2013.6523637
   Bisasky J, 2012, IEEE INT SYMP CIRC S, P564, DOI 10.1109/ISCAS.2012.6272092
   Bohnenstiehl B, 2017, IEEE J SOLID-ST CIRC, V52, P891, DOI 10.1109/JSSC.2016.2638459
   Choi J, 2012, IEEE T INF TECHNOL B, V16, P279, DOI 10.1109/TITB.2011.2169804
   Conti F, 2016, J SIGNAL PROCESS SYS, V84, P339, DOI 10.1007/s11265-015-1070-9
   Deng Y, 2012, 2012 IEEE 13TH INTERNATIONAL CONFERENCE ON INFORMATION REUSE AND INTEGRATION (IRI), P584, DOI 10.1109/IRI.2012.6303062
   Dogan AY, 2011, LECT NOTES COMPUT SC, V6951, P102, DOI 10.1007/978-3-642-24154-3_11
   Dreslinski Ronald G., 2007, 2007 16th International Conference on Parallel Architectures and Compilation Techniques, P175
   Ghasemzadeh H, 2013, ACM T EMBED COMPUT S, V13, DOI 10.1145/2501626.2501636
   Hanson S, 2009, IEEE J SOLID-ST CIRC, V44, P1145, DOI 10.1109/JSSC.2009.2014205
   Healey JA, 2005, IEEE T INTELL TRANSP, V6, P156, DOI 10.1109/TITS.2005.848368
   Homayoun H, 2012, P INT S HIGH PERFORM, P1
   Jafari Ali, 2015, 2015 IEEE Biomedical Circuits and Systems Conference (BioCAS), P1, DOI 10.1109/BioCAS.2015.7348376
   Kim C, 2012, 2012 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT'12), P329, DOI 10.1109/FPT.2012.6412157
   Krimer E, 2010, IEEE COMPUT ARCHIT L, V9, P21, DOI 10.1109/L-CA.2010.5
   Kulkarni A, 2016, ACM J EMERG TECH COM, V13, DOI 10.1145/2827699
   Kulkarni A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P57, DOI 10.1145/2902961.2902984
   Kulkarni A, 2016, IEEE INT SYMP CIRC S, P1138, DOI 10.1109/ISCAS.2016.7527446
   Kulkarni A, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P120, DOI 10.1109/HST.2016.7495568
   Kulkarni A, 2016, INT SYM QUAL ELECT, P362, DOI 10.1109/ISQED.2016.7479228
   Kulkarni A, 2014, PR GR LAK SYMP VLSI, P299, DOI 10.1145/2591513.2591598
   Kulkarni A, 2015, IEEE INT SYMP CIRC S, P970, DOI 10.1109/ISCAS.2015.7168797
   Kumar R, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P81
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee KH, 2013, IEEE J SOLID-ST CIRC, V48, P1625, DOI 10.1109/JSSC.2013.2253226
   Lukefahr A, 2012, INT SYMP MICROARCH, P317, DOI 10.1109/MICRO.2012.37
   Malik M, 2016, IEEE COMP SOC ANN, P559, DOI 10.1109/ISVLSI.2016.112
   Malik M, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P85, DOI 10.1109/BigData.2015.7363745
   Malik M, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P379, DOI 10.1109/ICCD.2015.7357128
   Neshatpour K, 2016, IEEE INT SYMP CIRC S, P1134, DOI 10.1109/ISCAS.2016.7527445
   Neshatpour K, 2015, PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA, P115, DOI 10.1109/BigData.2015.7363748
   Neshatpour K, 2015, ANN IEEE SYM FIELD P, P164, DOI 10.1109/FCCM.2015.59
   Neshatpour K, 2015, IEEE ACM INT SYMP, P1151, DOI 10.1109/CCGrid.2015.165
   Page A., 2016, PROC IEEE 24 ANN INT, P1
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Page A, 2015, IEEE ENG MED BIO, P7111, DOI 10.1109/EMBC.2015.7320031
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Pu Y, 2010, IEEE J SOLID-ST CIRC, V45, P668, DOI 10.1109/JSSC.2009.2039684
   Rosén J, 2007, RTSS 2007: 28TH IEEE INTERNATIONAL REAL-TIME SYSTEMS SYMPOSIUM, PROCEEDINGS, P49, DOI 10.1109/RTSS.2007.24
   Tavana MK, 2015, DES AUT CON, DOI 10.1145/2744769.2744833
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Truong DN, 2009, IEEE J SOLID-ST CIRC, V44, P1130, DOI 10.1109/JSSC.2009.2013772
   Tsoi KH, 2010, FPGA 10, P115
   Viseh S, 2015, IEEE T CIRCUITS-II, V62, P174, DOI 10.1109/TCSII.2014.2387683
   Yoo J, 2013, IEEE J SOLID-ST CIRC, V48, P214, DOI 10.1109/JSSC.2012.2221220
NR 66
TC 9
Z9 10
U1 0
U2 10
PD JAN
PY 2018
VL 26
IS 1
BP 96
EP 109
DI 10.1109/TVLSI.2017.2754272
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU He, MX
   Thottethodi, M
   Vijaykumar, TN
AF He, Mingxuan
   Thottethodi, Mithuna
   Vijaykumar, T. N.
GP IEEE
TI Booster: An Accelerator for Gradient Boosting Decision Trees Training
   and Inference
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM (IPDPS 2022)
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Gradient boosting; accelerator
AB Recent breakthroughs in machine learning (ML) have sparked hardware innovation for efficient execution of the emerging ML workloads. For instance, due to recent refinements and high-performance implementations, well-established gradient boosting decision tree (GBT) models (e.g., XGBoost) have demonstrated their dominance in commercially-important contexts, such as table-based datasets (e.g., relational databases and spreadsheets). Unfortunately, GBT training and inference are time-consuming (e.g., several hours of training for large datasets). Despite their importance, GBTs have not been targeted for hardware acceleration as much as neural networks.
   We propose Booster, a novel accelerator for GBTs based on their unique characteristics. We observe that the dominant steps of GBT training and inference (accounting for 90-98% of time) involve simple, fine-grained, independent operations on smallf-ootprint data structures (e.g., histograms and shallow trees) - i.e., GBT is on-chip memory bandwidth-bound. Unfortunately, existing multicores and GPUs do not support massively-parallel data structure accesses that are irregular and data-dependent. By employing a scalable sea-of-small-SRAMs approach and an SRAM bandwidth-preserving mapping of data record fields to the SRAMs called group-by-field mapping, Booster achieves significantly more parallelism (e.g., 3200-way parallelism) than multicores and GPUs. In addition, Booster employs a redundant data representation that significantly lowers the memory bandwidth demand. Our simulations reveal that Booster achieves 11.4x and 6.4x speedups for training, and 45x and 22x (21x and 11x) speedups for offline (online) inference, over an ideal 32-core multicore and an ideal GPU, respectively. Based on ASIC synthesis of FPGA-validated RTL using 45 nm technology, we estimate a Booster chip to occupy 60 mm(2) of area and dissipate 23 W when operating at 1-GHz clock speed.
C1 [He, Mingxuan; Thottethodi, Mithuna; Vijaykumar, T. N.] Purdue Univ, Elmore Family Sch ECE, W Lafayette, IN 47907 USA.
RP He, MX (corresponding author), Purdue Univ, Elmore Family Sch ECE, W Lafayette, IN 47907 USA.
EM he238@purdue.edu; mithuna@purdue.edu; vijay@ecn.purdue.edu
CR Alcolea A, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030314
   Ampere, AMP ALTR
   [Anonymous], LIGHTGBM EXPT
   [Anonymous], 2013, ALLSTATE CLAIM DATA
   [Anonymous], 2012, BOOSTING ADAPTIVE CO
   [Anonymous], AWESOME XGBOOST
   [Anonymous], TERABYTE CLICK LOG
   [Anonymous], HG INSIGHTS
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen YR, 2020, ENGINEERING-PRC, V6, P264, DOI 10.1016/j.eng.2020.01.007
   Data Expo, 2009, AIRLINE ON TIME PERF
   Dorogush A. V, 2017, WORKSHOP ML SYSTEMS
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Gantz J., 2011, EXTRACTING VALUE CHA, V1142, P1
   He Xinran, 2014, P 8 INT WORKSH DAT M, V5, P1, DOI DOI 10.1145/2648584.2648589
   Ke GL, 2017, ADV NEUR IN, V30
   Keck T., 2016, ARXIV
   Ling XL, 2017, WWW'17 COMPANION: PROCEEDINGS OF THE 26TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB, P689, DOI 10.1145/3041021.3054192
   Meidan Y, 2018, IEEE PERVAS COMPUT, V17, P12, DOI 10.1109/MPRV.2018.03367731
   NCSU, FREEPDK45
   Neugebauer R, 2018, PROCEEDINGS OF THE 2018 CONFERENCE OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '18), P327, DOI 10.1145/3230543.3230560
   Pafka S, 2016, FLIGHT DELAY DATA
   Qin T, 2013, Arxiv, DOI arXiv:1306.2597
   Rawat W, 2017, NEURAL COMPUT, V29, P2352, DOI [10.1162/NECO_a_00990, 10.1162/neco_a_00990]
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Sadasue T, 2020, ANN IEEE SYM FIELD P, P234, DOI 10.1109/FCCM48280.2020.00067
   Schmidt P, 2018, ICMI'18: PROCEEDINGS OF THE 20TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P400, DOI 10.1145/3242969.3242985
   Tanaka Takuya, 2018, Arxiv, DOI arXiv:1812.08295
   Wen ZY, 2019, IEEE T PARALL DISTR, V30, P2706, DOI 10.1109/TPDS.2019.2920131
   Wikipedia, US
NR 33
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 1051
EP 1062
DI 10.1109/IPDPS53621.2022.00106
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Wang, Y
   Li, P
AF Wang, Yu
   Li, Peng
GP IEEE Comp Soc
TI Algorithm and Hardware Co-Design for FPGA Acceleration of Hamiltonian
   Monte Carlo Based No-U-Turn Sampler
SO 2021 IEEE 32ND INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2021)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 32nd IEEE International Conference on Application-specific Systems,
   Architectures and Processors (ASAP)
CY JUL 07-08, 2021
CL ELECTR NETWORK
DE Hamiltonian Monte Carlo; No-U-Turn Sampler; FPGA; Hardware Acceleration
AB Monte Carlo (MC) methods are widely used in many research areas such as physical simulation, statistical analysis, and machine learning. Application of MC methods requires drawing fast mixing samples from a given probability distribution. Among existing sampling methods, the Hamiltonian Monte Carlo (HMC) utilizes gradient information during Hamiltonian simulation and can produce fast mixing samples at the highest efficiency. However, without carefully chosen simulation parameters for a specific problem, HMC generally suffers from simulation locality and computation waste. As a result, the No-U-Turn Sampler (NUTS) has been proposed to automatically tune these parameters during simulation and is the current state-of-the-art sampling algorithm. However, application of NUTS requires frequent gradient calculation of a given distribution and high-volume vector processing, especially for large-scale problems, leading to drawing an expensively large number of samples and a desire of hardware acceleration. While some hardware acceleration works have been proposed for traditional Markov Chain Monte Carlo (MCMC) and HMC methods, there is no existing work targeting hardware acceleration of the NUTS algorithm. In this paper, we present the first NUTS accelerator on FPGA while addressing the high complexity of this state-of-the-art algorithm. Our hardware and algorithm co-optimizations include an incremental resampling technique which leads to a more memory efficient architecture and pipeline optimization for multi-chain sampling to maximize the throughput. We also explore three levels of parallelism in the NUTS accelerator to further boost performance. Compared with optimized C++ NUTS package: RSTAN, our NUTS accelerator can reach a maximum speedup of 50.6X and an energy improvement of 189.7X.
C1 [Wang, Yu; Li, Peng] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
RP Wang, Y (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM yu95@ucsb.edu; lip@ucsb.edu
CR Bingham E, 2018, J MACH LEARN RES
   Carpenter B, 2017, J STAT SOFTW, V76, P1, DOI 10.18637/jss.v076.i01
   Chen TQ, 2014, PR MACH LEARN RES, V32, P1683
   Gonzalez J., 2011, P 14 INT C ARTIFICIA, P324
   Hoffman MD, 2014, J MACH LEARN RES, V15, P1593
   Koushanfar F., 2018, CAUSALEARN AUTOMATED, P1
   Liu SL, 2017, IEEE T COMPUT, V66, P745, DOI 10.1109/TC.2016.2630682
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Mingas Grigorios, 2012, Reconfigurable Computing: Architectures, Tools and Applications. Proceedings of the 8th International Symposium, ARC 2012, P227, DOI 10.1007/978-3-642-28365-9_19
   Neal R. M., 1996, BAYESIAN LEARNING NE, P29, DOI DOI 10.1007/978-1-4612-0745-0_2
   Neal RM, 2011, CH CRC HANDB MOD STA, P113
   Nesterov Y, 2009, MATH PROGRAM, V120, P221, DOI 10.1007/s10107-007-0149-x
NR 12
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 9
EP 16
DI 10.1109/ASAP52443.2021.00009
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Raha, A
   Raghunathan, V
AF Raha, Arnab
   Raghunathan, Vijay
TI QLUT: Input-Aware Quantized Table Lookup for Energy-Efficient
   Approximate Accelerators
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Approximate computing; Low-power design; Accelerators; Lookup table
AB Approximate computing has emerged as a popular design paradigm for optimizing the performance and energy consumption of error-resilient applications in domains such as machine learning, graphics, data analytics, etc. Numerous techniques for approximate computing have been proposed at different layers of the system stack, from circuits to architecture to software. In this work, we propose a new technique, called quantized table lookup, for approximating the meta-functions used in the core computational kernels of error-resilient applications. In contrast to prior work that directly approximates the functionality of the meta-functions, the proposed technique instead approximates the input data to the meta-functions by reducing/quantizing them to a much smaller set of values that we call quantized inputs. The small number of quantized inputs enables us to completely replace the energy-intensive arithmetic units in the meta-function with small and energy-efficient lookup tables (called quantized lookup tables or QLUT) that contain precomputed output values corresponding to the quantized inputs. The proposed approximation technique is not only highly generic, but also inherently quality-configurable and input-aware. Quality-configurability and input-awareness are achieved bymodulating the size of the qLUT as well as selecting the values of the quantized inputs judiciously based on the statistics of the original input data. To evaluate the proposed technique, we have implemented the dominant meta-functions of nine error-resilient application benchmarks as quantized table lookup based hardware accelerators using 45nm technology. Experimental results demonstrate average energy savings of 46% at the application-level for minimal (< 1%) loss in output quality.
C1 [Raha, Arnab; Raghunathan, Vijay] Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
RP Raha, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, 465 Northwestern Ave, W Lafayette, IN 47907 USA.
EM araha@purdue.edu; vr@purdue.edu
CR Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Amirtharajah R, 2004, IEEE J SOLID-ST CIRC, V39, P337, DOI 10.1109/JSSC.2003.821774
   [Anonymous], 2011, P DATE
   [Anonymous], ICCAD IEEE ACM INT
   [Anonymous], P 50 ANN DES AUT C D
   [Anonymous], P INT C SUP ICS 17
   Ayinala M, 2013, CONF REC ASILOMAR C, P2167, DOI 10.1109/ACSSC.2013.6810693
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Chippa V. K., 2013, P 50 ANN DESIGN AUTO, P1, DOI DOI 10.1145/2463209.2488873
   Chippa V, 2011, DES AUT CON, P603
   de Dinechin F, 2005, IEEE T COMPUT, V54, P319, DOI 10.1109/TC.2005.54
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Krause PK, 2011, DES AUT TEST EUROPE, P944
   Laurenzano MA, 2016, ACM SIGPLAN NOTICES, V51, P161, DOI [10.1145/2980983.2908087, 10.1145/2908080.2908087]
   Martin D, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL II, PROCEEDINGS, P416, DOI 10.1109/ICCV.2001.937655
   Nguyen HT, 2000, IEEE T VLSI SYST, V8, P419, DOI 10.1109/92.863621
   Potkonjak M, 1996, IEEE T COMPUT AID D, V15, P151, DOI 10.1109/43.486662
   Raha A, 2014, I CONF VLSI DESIGN, P324, DOI 10.1109/VLSID.2014.62
   Raha A, 2017, DES AUT CON, DOI 10.1145/3061639.3062333
   Raha A, 2017, IEEE EMBED SYST LETT, V9, P21, DOI 10.1109/LES.2017.2658566
   Raha A, 2017, IEEE T VLSI SYST, V25, P462, DOI 10.1109/TVLSI.2016.2586379
   Raha A, 2016, IEEE T VLSI SYST, V24, P846, DOI 10.1109/TVLSI.2015.2424212
   Raha A, 2015, DES AUT TEST EUROPE, P665
   Ranjan A., 2014, P DATE, P1, DOI DOI 10.7873/DATE.2014.377
   Samadi Mehrzad, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P13, DOI 10.1145/2540708.2540711
   Shafique M, 2016, 2016 53 ACM EDAC IEE, P1, DOI DOI 10.1145/2897937.2905008
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Voronenko Y, 2007, ACM T ALGORITHMS, V3, DOI 10.1145/1240233.1240234
NR 32
TC 12
Z9 12
U1 0
U2 5
PD OCT
PY 2017
VL 16
SU 5
SI SI
AR 130
DI 10.1145/3126531
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Amarnath, C
   Chatterjee, A
AF Amarnath, Chandramouli
   Chatterjee, Abhijit
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI A Novel Approach to Error Resilience in Online Reinforcement Learning
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Neural Networks; Fault Tolerance; Resilience; Soft Errors; Reinforcement
   Learning
ID DNN ACCELERATORS; NETWORK
AB Online reinforcement learning (RL) based systems are being increasingly deployed in a variety of safety-critical applications ranging from drone control to medical robotics. These systems typically use RL onboard rather than relying on remote operation from high-performance datacenters. Due to the dynamic nature of the environments they work in, onboard RL hardware is vulnerable to soft errors from radiation, thermal effects and electrical noise that corrupt the results of computations. Existing approaches to on-line error resilience in machine learning systems have relied on availability of the large training datasets to configure resilience parameters, which is not necessarily feasible for online RL systems. Similarly, other approaches involving specialized hardware or modifications to training algorithms are difficult to implement for onboard RL applications. In contrast, we present a novel error resilience approach for online RL that makes use of running statistics collected across the (real-time) RL training process to configure error detection thresholds without the need to access a reference training dataset. In this methodology, statistical concentration bounds leveraging running statistics are used to diagnose neuron outputs as erroneous. These erroneous neurons are then set to zero (suppressed). Our approach is compared against the state of the art and validated on several RL algorithms involving the use of multiple concentration bounds on CPU as well as GPU hardware.
C1 [Amarnath, Chandramouli; Chatterjee, Abhijit] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Amarnath, C (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM chandamarnath@gatech.edu; abhijit.chatterjee@ece.gatech.edu
CR Amarnath C, 2022, IEEE INT ON LINE, DOI 10.1109/IOLTS56730.2022.9897815
   Banerjee S, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3338123
   Chen Z, 2021, INT J PROD RES, DOI [10.1080/00207543.2021.2006818, 10.1109/DSN48987.2021.00018]
   F. Foundation, 2022, GYMNASIUM-GER
   Ghosh BK, 2002, AM STAT, V56, P186, DOI 10.1198/000313002119
   Hanif MA, 2020, IEEE INT ON LINE, DOI 10.1109/iolts50870.2020.9159734
   Hari SKS, 2022, IEEE T DEPEND SECURE, V19, P2546, DOI 10.1109/TDSC.2021.3063083
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Huang S., 2022, J MACH LEARN RES, V23, P1
   Ibrahim Y, 2020, MICROELECTRON RELIAB, V115, DOI 10.1016/j.microrel.2020.113969
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   Mahmoud A., 2020, HARDNN FEATURE MAP V
   Mahmoud A, 2020, 50TH ANNUAL IEEE/IFIP INTERNATIONAL CONFERENCE ON DEPENDABLE SYSTEMS AND NETWORKS WORKSHOPS (DSN-W 2020), P25, DOI 10.1109/DSN-W50199.2020.00014
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Ozen E, 2022, IEEE T COMPUT AID D, V41, P3934, DOI 10.1109/TCAD.2022.3197540
   Ozen E, 2021, ACM T EMBED COMPUT S, V20, DOI 10.1145/3477007
   Ozen E, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415680
   Ozen E, 2020, IEEE T COMPUT AID D, V39, P3250, DOI 10.1109/TCAD.2020.3012209
   Paszke A, 2019, ADV NEUR IN, V32
   Rech P, 2013, IEEE T NUCL SCI, V60, P2797, DOI 10.1109/TNS.2013.2252625
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   Skolik A, 2023, EPJ QUANTUM TECHNOL, V10, DOI 10.1140/epjqt/s40507-023-00166-1
   Tan KL, 2020, P AMER CONTR CONF, P3959, DOI [10.23919/ACC45564.2020.9147846, 10.23919/acc45564.2020.9147846]
   Terpstra D, 2010, TOOLS FOR HIGH PERFORMANCE COMPUTING 2009, P157, DOI 10.1007/978-3-642-11261-4_11
   Vershynin R., 2019, HIGH DIMENSIONAL PRO
   Wang X., 2022, IEEE T NEUR NET LEAR
   WELFORD BP, 1962, TECHNOMETRICS, V4, P419, DOI 10.2307/1266577
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Yang C. H., 2021, CAUSAL INFERENCE Q N
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang S, 2016, IEEE T SIGNAL PROCES, V64, P3338, DOI 10.1109/TSP.2016.2546224
NR 31
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224892
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Aceto, G
   Ciuonzo, D
   Montieri, A
   Persico, V
   Pescape, A
AF Aceto, Giuseppe
   Ciuonzo, Domenico
   Montieri, Antonio
   Persico, Valerio
   Pescape, Antonio
BE Secci, S
   Chrisment, I
   Fiore, M
   Tabourier, L
   Lim, KW
TI Know your Big Data Trade-offs when Classifying Encrypted Mobile Traffic
   with Deep Learning
SO PROCEEDINGS OF THE 3RD NETWORK TRAFFIC MEASUREMENT AND ANALYSIS
   CONFERENCE (TMA 2019)
DT Proceedings Paper
CT 3rd IFIP/IEEE Network Traffic Measurement and Analysis Conference (TMA)
CY JUN 19-21, 2019
CL Paris, FRANCE
DE traffic classification; mobile apps; big data; deep learning; Android
   apps; iOS apps; encrypted traffic
ID IDENTIFICATION
AB The spread of handheld devices has led to the unprecedented growth of traffic volumes traversing both local networks and the Internet, appointing mobile traffic classification as a key tool for gathering highly-valuable profiling information, other than traffic engineering and service management. However, the nature of mobile traffic severely challenges state-of-art Machine-Learning (ML) approaches, since the quickly evolving and expanding set of apps generating traffic hinders ML-based approaches, that require domain-expert design. Deep Learning (DL) represents a promising solution to this issue, but results in higher completion times, in turn suggesting the application of the Big-Data (BD) paradigm. In this paper, we investigate for the first time BD-enabled classification of encrypted mobile traffic using DL from a general standpoint, (a) defining general design guidelines, (b) leveraging a public-cloud platform, and (c) resorting to a realistic experimental setup. We found that, while BD represents a transparent accelerator for some tasks, this is not the case for the training phase of DL architectures for traffic classification, requiring a specific BD-informed design. The experimental setup is built upon a three-dimensional investigation path in the BD adoption, namely: (i) completion time, (ii) deployment costs, and (iii) classification performance, highlighting relevant non-trivial trade-offs.
C1 [Aceto, Giuseppe; Ciuonzo, Domenico; Montieri, Antonio; Persico, Valerio; Pescape, Antonio] Univ Napoli Federico II, Naples, Italy.
   [Aceto, Giuseppe; Persico, Valerio; Pescape, Antonio] NM2 Srl, Naples, Italy.
RP Aceto, G (corresponding author), Univ Napoli Federico II, Naples, Italy.; Aceto, G (corresponding author), NM2 Srl, Naples, Italy.
EM giuseppe.aceto@unina.it; domenico.ciuonzo@unina.it;
   antonio.montieri@unina.it; valerio.persico@unina.it; pescape@unina.it
CR Abu Alsheikh M, 2016, IEEE NETWORK, V30, P22, DOI 10.1109/MNET.2016.7474340
   Aceto G, 2019, IEEE T NETW SERV MAN, V16, P445, DOI 10.1109/TNSM.2019.2899085
   Aceto G, 2018, J NETW COMPUT APPL, V103, P131, DOI 10.1016/j.jnca.2017.11.007
   Dainotti A, 2012, IEEE NETWORK, V26, P35, DOI 10.1109/MNET.2012.6135854
   Diro AA, 2018, IEEE COMMUN MAG, V56, P169, DOI 10.1109/MCOM.2018.1700332
   Quoc DL, 2015, 2015 IEEE 8TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING, P1008, DOI 10.1109/CLOUD.2015.138
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hajjar A, 2015, J NETW COMPUT APPL, V58, P130, DOI 10.1016/j.jnca.2015.10.003
   Jejdling F, 2019, ERICSSON MOBILITY RE
   Joeri C. I.-D., 2016, DISTRIBUTED KERAS DI
   Le L.-V, 2018, T NETWORKS COMMUNICA, V6
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lotfollahi M, 2018, Arxiv, DOI arXiv:1709.02656
   Majchrzak TA, 2017, PROCEEDINGS OF THE 50TH ANNUAL HAWAII INTERNATIONAL CONFERENCE ON SYSTEM SCIENCES, P6162
   Mulinka P, ACM BIG DAMA 18
   Persico V, 2018, FUTURE GENER COMP SY, V89, P98, DOI 10.1016/j.future.2018.05.068
   Rajashekar D, 2016, INT CONF DAT MIN WOR, P319, DOI [10.1109/ICDMW.2016.89, 10.1109/ICDMW.2016.0052]
   Razaghpanah A, 2017, CONEXT'17: PROCEEDINGS OF THE 2017 THE 13TH INTERNATIONAL CONFERENCE ON EMERGING NETWORKING EXPERIMENTS AND TECHNOLOGIES, P350, DOI 10.1145/3143361.3143400
   Taylor VF, 2018, IEEE T INF FOREN SEC, V13, P63, DOI 10.1109/TIFS.2017.2737970
   Viegas E, 2019, BIGFLOW REAL TIME RE
   Wang W, IEEE ISI 17
   Wang Zhanyi, 2015, BLACKHAT US
   Yao HY, 2015, MOBICOM '15: PROCEEDINGS OF THE 21ST ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, P439, DOI 10.1145/2789168.2790097
   Zhou BJ, 2018, INT WIREL COMMUN, P1507, DOI 10.1109/IWCMC.2018.8450335
NR 24
TC 10
Z9 11
U1 0
U2 0
PY 2019
BP 121
EP 128
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Telecommunications
DA 2023-11-11
ER

PT J
AU Hassan, O
   Paul, T
   Shuvo, MH
   Parvin, D
   Thakker, R
   Chen, MR
   Mosa, AM
   Islam, SK
AF Hassan, Omiya
   Paul, Tanmoy
   Shuvo, Maruf Hossain
   Parvin, Dilruba
   Thakker, Rushil
   Chen, Mengrui
   Mosa, Abu Saleh Mohammad
   Islam, Syed Kamrul
TI Energy Efficient Deep Learning Inference Embedded on FPGA for Sleep
   Apnea Detection
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Deep learning; Feedforward neural network; FPGA; Sleep apnea; ECG;
   Oxygen saturation; System-on-a-chip
ID AUTOMATIC DETECTION
AB Sleep apnea is a type of disorder caused by the absence of breathing for a specific period of time coupled with a significant decrease in the blood oxygen saturation level. The monitoring process of sleep apnea is challenging due to the requirement of overnight expensive sleep study, hand-crafted feature extraction from breathing signals, and manual annotations by the sleep experts. Therefore, a low-cost, energy-efficient, portable, and automated biomedical system is necessary to improve early detection, frequent monitoring, and clinical decision-making. In this paper, a digital hardware design of a trained deep feedforward neural network (FNN) is implemented on a Field Programmable Gate-Array (FPGA) for the detection of sleep apnea. The model was trained and evaluated with hyperparameters obtained from a three-step optimization process which ensures compact design solution in low-power miniaturized CMOS circuits. A three-layer FNN trained with ADAM optimizer and mean square error (MSE) loss minimization shows an accuracy of around 88%. An application-specific deep learning inference module realized in FPGA hardware platform confirms a power consumption below 34 W which is 5 x lower than that of commercially available machine learning accelerators. The outcome of this research can be integrated into a system-on-a-chip (SoC) platform for developing a smart automated sleep apnea detection device.
C1 [Hassan, Omiya; Paul, Tanmoy; Shuvo, Maruf Hossain; Parvin, Dilruba; Thakker, Rushil; Chen, Mengrui; Islam, Syed Kamrul] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
   [Mosa, Abu Saleh Mohammad] Univ Missouri, Dept Hlth Management & Informat, Columbia, MO 65211 USA.
RP Hassan, O (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65201 USA.
EM omiya.hassan@mail.missouri.edu
CR Agarap AF, 2018, ARXIV PREPRINT ARXIV, V1803
   Alvarez D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62223-4
   Azimi H, 2020, IEEE ACCESS, V8, P173428, DOI 10.1109/ACCESS.2020.3025808
   Bhattacharjee R, 2021, J CLIN SLEEP MED, V17, P1379, DOI 10.5664/jcsm.9202
   Dey D, 2018, BIOMED ENG LETT, V8, P95, DOI 10.1007/s13534-017-0055-y
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Gottlieb DJ, 2020, JAMA-J AM MED ASSOC, V323, P1389, DOI 10.1001/jama.2020.3514
   Hassan O., 2020, MACHINE LEARNING MOD, P607
   Hassan O, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137291
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   King DB, 2015, ACS SYM SER, V1214, P1
   Kristiansen Stein, 2021, ACM Transactions on Computing and Healthcare, V2, DOI 10.1145/3433987
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Mahbub Ifana, 2015, 2015 IEEE Topical Conference on Biomedical Wireless Technologies, Networks and Sensing Systems (BioWireleSS). Proceedings, P1, DOI 10.1109/BIOWIRELESS.2015.7152130
   Mahbub I, 2017, IEEE SENS J, V17, P1858, DOI 10.1109/JSEN.2017.2651073
   Mendonça F, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20030888
   Mendonça F, 2018, SLEEP MED REV, V41, P149, DOI 10.1016/j.smrv.2018.02.004
   Nikonov D. E., 2019, ARXIV PREPRINT ARXIV
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   Penzel Thomas, 2018, F1000Res, V7, P413, DOI 10.12688/f1000research.13010.1
   Pullano Salvatore Andrea, 2017, IEEE Rev Biomed Eng, V10, P199, DOI 10.1109/RBME.2017.2757899
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Shamsir S., 2020, 2020 IEEE INT INSTR, P1, DOI [10.1109/I2MTC43012.2020.9129295, DOI 10.1109/I2MTC43012.2020.9129295]
   Shamsir S, 2018, IEEE IMTC P, P529
   Song CY, 2016, IEEE T BIO-MED ENG, V63, P1532, DOI 10.1109/TBME.2015.2498199
   Tisan A., 2009, ACTA TECHNICA NAPOCE, V50, P15, DOI DOI 10.1109/CADSM.2019.8779253
   Tsmots I, 2019, EXP DES APPL CAD SYS, DOI 10.1109/cadsm.2019.8779253
   Vanegas E, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20185446
   Varon C, 2015, IEEE T BIO-MED ENG, V62, P2269, DOI 10.1109/TBME.2015.2422378
   Wang T, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9768072
   Ye GH, 2021, IEEE J BIOMED HEALTH, V25, P2848, DOI 10.1109/JBHI.2021.3050113
   Yüzer AH, 2020, IRBM, V41, P39, DOI 10.1016/j.irbm.2019.10.007
NR 33
TC 3
Z9 3
U1 1
U2 14
PD JUN
PY 2022
VL 94
IS 6
BP 609
EP 619
DI 10.1007/s11265-021-01722-7
EA JAN 2022
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Homayoun, H
AF Homayoun, Houman
GP ACM
TI Heterogeneous Chip Multiprocessor Architectures for Big Data
   Applications
SO PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS
   (CF'16)
DT Proceedings Paper
CT ACM International Conference on Computing Frontiers (CF)
CY MAY 16-18, 2016
CL Como, ITALY
DE Heterogeneous Architectures; Performance; Power; Application
   Characterization; Big Data; Accelerator
AB Emerging big data analytics applications require a significant amount of server computational power. The costs of building and running a computing server to process big data and the capacity to which we can scale it are driven in large part by those computational resources. However, big data applications share many characteristics that are fundamentally different from traditional desktop, parallel, and scale-out applications. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and are running a complex and deep software stack with various components (e.g. Hadoop, Spark, MPI, Hbase, Impala, MySQL, Hive, Shark, Apache, and MangoDB) that are bound together with a runtime software system and interact significantly with I/O and OS, exhibiting high computational intensity, memory intensity, I/O intensity and control intensity. Current server designs, based on commodity homogeneous processors, will not be the most efficient in terms of performance/watt for this emerging class of applications. In other domains, heterogeneous architectures have emerged as a promising solution to enhance energy-efficiency by allowing each application to run on a core that matches resource needs more closely than a one-size-fits-all core. A heterogeneous architecture integrates cores with various micro-architectures and accelerators to provide more opportunity for efficient workload mapping. In this work, through methodical investigation of power and performance measurements, and comprehensive system level characterization, we demonstrate that a heterogeneous architecture combining high performance big and low power little cores is required for efficient big data analytics applications processing, and in particular in the presence of accelerators and near real-time performance constraints.
C1 [Homayoun, Houman] George Mason Univ, Fairfax, VA 22030 USA.
RP Homayoun, H (corresponding author), George Mason Univ, Fairfax, VA 22030 USA.
EM hhomayou@gmu.edu
CR Andersen DG, 2009, SOSP'09: PROCEEDINGS OF THE TWENTY-SECOND ACM SIGOPS SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P1
   [Anonymous], 2007, P 2007 SPEC BENCHM W
   Armstrong, 2013, P ACM SIGMOD
   ARNOLD M., 2001, P 9 CODES
   Arora M, 2012, IEEE MICRO, V32, P4, DOI 10.1109/MM.2012.57
   Arora N, 2010, VLSI DES
   Baru C, LECT NOTES COMPUTER
   Chung E. S., 2013, ACM SIGARCH COMPUTER, V41
   Clark NT, 2005, IEEE T COMPUT, V54, P1258, DOI 10.1109/TC.2005.156
   Ferdman M, 2012, ASPLOS XVII: SEVENTEENTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P37
   Gao W., ASBD 2013 CONJUNCTIO
   Ghazal Ahmad, 2013, P 2013 ACM SIGMOD IN, P1197, DOI 10.1145/2463676.2463712
   Gutierrez A., 2014, INTEGRATED 3DSTACKED
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H, 2006, LECT NOTES COMPUT SC, V4017, P299, DOI 10.1007/11796435_31
   Homayoun Houman, 2008, ICCD IEEE INT C COMP
   Homayoun Houman, HIGH PERFORMANCE COM
   Huang SS, 2010, I C DATA ENGIN WORKS, P41, DOI 10.1109/ICDEW.2010.5452747
   Kontorinis V, 2014, DES AUT CON
   Kukunas James T, 2014, CISC VIS NETW IND GL
   Kumar R, 2005, COMPUTER, V38, P32, DOI 10.1109/MC.2005.379
   Li A., ACM 10
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Luo Xi, BIGDATA 2013
   Neshatpour Katayoun, 2015, CLUST CLOUD GRID COM
   Neshatpour Katayoun, 2015, FIELD PROGR CUST COM
   Neshatpour Katayoun, 2015, BIG DAT BIG DAT 2015
   Nilakantan S., 2013, PLATFORM INDEPENDENT
   Prakash TK, 2008, ISAST T COMPUT SOFTW, V2, P36, DOI DOI 10.1109/TPDS.2010.199
   Reddi VJ, 2010, CONF PROC INT SYMP C, P314, DOI 10.1145/1816038.1816002
   Shan Y, 2010, P ACM SIGDA INT S FI
   Wu Ren, 2009, GPU ACCELERATED LARG
   YU P., P CASES 04
   Yu P, 2007, I C FIELD PROG LOGIC, P273, DOI 10.1109/FPL.2007.4380659
NR 34
TC 1
Z9 1
U1 0
U2 4
PY 2016
BP 400
EP 405
DI 10.1145/2903150.2908078
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Garrett, T
   George, AD
AF Garrett, Tyler
   George, Alan D.
GP IEEE COMP SOC
TI Improving Dependability of Onboard Deep Learning with Resilient
   TensorFlow
SO 2021 IEEE SPACE COMPUTING CONFERENCE (SCC)
DT Proceedings Paper
CT IEEE Space Computing Conference (SCC)
CY AUG 23-26, 2021
CL ELECTR NETWORK
DE TensorFlow; GPU-Based Computing; Deep Learning; Onboard Processing;
   Fault-Tolerant Design; High-Performance Computing
AB As the dawn of a new age in spaceflight approaches, the drive to equip future spacecraft with high-performance computing capabilities is increasing. Many within the industry are looking to leverage solutions enabled by machine learning (ML) and artificial intelligence to enhance mission efficiency. Tasks such as image processing and object tracking are desired for long-duration spaceflight and extravehicular activities. In order to realize these applications in practice, enhancements to onboard processing are needed. ML applications require state-of-the-art processors and hardware accelerators, such as GPUs. However, GPUs are heavily susceptible to radiation-induced single-event effects (SEEs). Additionally, missions require a level of safety-criticality, which is unable to be met by existing commercial-off-the-shelf (COTS) GPUs. In an effort to create an end-to-end solution, this work aims to bridge ML-application development with device-architectural awareness to deliver a fault-aware implementation of the TensorFlow framework called Resilient TensorFlow (RTF). By building customized operations into the TensorFlow framework and employing them within the graph of various models, RTF demonstrates an ability to mask faults that occur during processing while minimizing overhead. Reducing faults during the processing of deep-learning applications brings the space computing industry closer to realizing onboard high-performance computing.
C1 [Garrett, Tyler; George, Alan D.] Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
RP Garrett, T (corresponding author), Univ Pittsburgh, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
EM tmg61@pitt.edu; alan.george@pitt.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Bruhn FC, 2020, CEAS SPACE J, V12, P551, DOI 10.1007/s12567-020-00321-9
   Chen ZT, 2020, PROC INT SYMP SOFTW, P426, DOI 10.1109/ISSRE5003.2020.00047
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li GP, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P240, DOI 10.1109/SC.2016.20
   Mahmoud A., 2020, ARXIV PREPRINT ARXIV
   Oliveira DAG, 2014, IEEE T NUCL SCI, V61, P3115, DOI 10.1109/TNS.2014.2362014
   Oliveira DAG, 2014, INT SYM DEFEC FAU TO, P209, DOI 10.1109/DFT.2014.6962085
   Ozen E, 2019, ASIAN TEST SYMPOSIUM, P7, DOI 10.1109/ATS47505.2019.000-8
   Roffe S, 2020, AEROSP CONF PROC, DOI 10.1109/aero47225.2020.9172799
   Rudolph D., 2014, PROC 28 ANN AIAAUSU
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan JWJ, 2012, INT CONFER PARA, P191
   Villa O, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P372, DOI 10.1145/3352460.3358307
   Wyrwas E. J., 2017, 2017 NEPP EL TECHN W, P26
NR 17
TC 3
Z9 3
U1 0
U2 3
PY 2021
BP 134
EP 142
DI 10.1109/SCC49971.2021.00021
WC Engineering, Aerospace; Computer Science, Hardware & Architecture;
   Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Basaklar, T
   Goksoy, AA
   Krishnakumar, A
   Gumussoy, S
   Ogras, UY
AF Basaklar, Toygun
   Goksoy, A. Alper
   Krishnakumar, Anish
   Gumussoy, Suat
   Ogras, Umit Y.
TI DTRL: Decision Tree-based Multi-Objective Reinforcement Learning for
   Runtime Task Scheduling in Domain-Specific System-on-Chips
SO ACM TRANSACTIONS ON EMBEDDED COMPUTING SYSTEMS
DT Article
DE Domain-specific system-on-chip; task scheduling; reinforcement learning;
   decision trees; resource management; multi-objective optimization
ID GRAPHS; ALGORITHMS
AB Domain-specific systems-on-chip (DSSoCs) combine general-purpose processors and specialized hardware accelerators to improve performance and energy efficiency for a specific domain. The optimal allocation of tasks to processing elements (PEs) withminimal runtime overheads is crucial to achieving this potential. However, this problem remains challenging as prior approaches suffer from non-optimal scheduling decisions or significant runtime overheads. Moreover, existing techniques focus on a single optimization objective, such as maximizing performance. This work proposes DTRL, a decision-tree-based multi-objective reinforcement learning technique for runtime task scheduling in DSSoCs. DTRL trains a single global differentiable decision tree (DDT) policy that covers the entire objective space quantified by a preference vector. Our extensive experimental evaluations using our novel reinforcement learning environment demonstrate that DTRL captures the trade-off between execution time and power consumption, thereby generating a Pareto set of solutions using a single policy. Furthermore, comparison with state-of-the-art heuristic-, optimization-, and machine learning-based schedulers shows that DTRL achieves up to 9x higher performance and up to 3.08x reduction in energy consumption. The trained DDT policy achieves 120 ns inference latency on Xilinx Zynq ZCU102 FPGA at 1.2 GHz, resulting in negligible runtime overheads. Evaluation on the same hardware shows that DTRL achieves up to 16% higher performance than a state-of-the-art heuristic scheduler.
C1 [Basaklar, Toygun; Goksoy, A. Alper; Krishnakumar, Anish; Ogras, Umit Y.] Univ Wisconsin, 1415 Engn Dr, Madison, WI 53706 USA.
   [Gumussoy, Suat] Siemens Corp Technol, 755 Coll Rd E, Princeton, NJ 08540 USA.
RP Basaklar, T (corresponding author), Univ Wisconsin, 1415 Engn Dr, Madison, WI 53706 USA.
EM basaklar@wisc.edu; agoksoy@wisc.edu; anish.n.krishnakumar@wisc.edu;
   suat.gumussoy@siemens.com; uogras@wisc.edu
CR Abazari F, 2019, SIMUL MODEL PRACT TH, V93, P119, DOI 10.1016/j.simpat.2018.10.004
   Abdolmaleki Abbas, 2020, P 37 INT C MACHINE L, P11
   Amarnath A, 2021, IEEE COMPUT ARCHIT L, V20, P82, DOI 10.1109/LCA.2021.3085505
   Andrychowicz Marcin, 2021, INT C LEARN REPR, P1
   Arda SE, 2020, IEEE T COMPUT, V69, P1248, DOI 10.1109/TC.2020.2986963
   Basaklar T, 2022, Arxiv, DOI arXiv:2208.07914
   Behnamian J, 2014, APPL SOFT COMPUT, V21, P139, DOI 10.1016/j.asoc.2014.03.031
   Benini L, 2008, LECT NOTES COMPUT SC, V5366, P470, DOI 10.1007/978-3-540-89982-2_41
   Bittencourt LF, 2010, EUROMICRO WORKSHOP P, P27, DOI 10.1109/PDP.2010.56
   Bose Pradip, 2021, P INT WORKSH DOM SPE, P1
   Brockman G, 2016, Arxiv, DOI [arXiv:1606.01540, DOI 10.48550/ARXIV.1606.01540]
   Chen X, 2019, IEEE INT C INT ROBOT, P977, DOI [10.1109/iros40897.2019.8968092, 10.1109/IROS40897.2019.8968092]
   Chronaki K, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P329, DOI 10.1145/2751205.2751235
   Cplex I. I, 2009, INT BUSINESS MACHINE, V46, P157
   Ding ZH, 2021, Arxiv, DOI arXiv:2011.07553
   Frosst N, 2017, Arxiv, DOI arXiv:1711.09784
   futurenetworks.ieee, RF CONV SIGN COMP DR
   github, CEDR COMP INT EXT DS
   github, DS3 SIM
   Goksoy AA, 2022, IEEE EMBED SYST LETT, V14, P51, DOI 10.1109/LES.2021.3110426
   Green D., 2018, HETEROGENEOUS INTEGR
   HAMIDZADEH B, 1995, CONCURRENCY-PRACT EX, V7, P633, DOI 10.1002/cpe.4330070705
   Hayes CF, 2022, AUTON AGENT MULTI-AG, V36, DOI 10.1007/s10458-022-09552-y
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Hu ZM, 2019, INT CON DISTR COMP S, P2037, DOI 10.1109/ICDCS.2019.00201
   Huang SY, 2022, Arxiv, DOI arXiv:2006.14171
   HWANG JJ, 1989, SIAM J COMPUT, V18, P244, DOI 10.1137/0218016
   Jiang ED, 2021, TSINGHUA SCI TECHNOL, V26, P646, DOI 10.26599/TST.2021.9010007
   Krishnakumar A, 2020, IEEE T COMPUT AID D, V39, P4064, DOI 10.1109/TCAD.2020.3012861
   Kwok YK, 1996, IEEE T PARALL DISTR, V7, P506, DOI 10.1109/71.503776
   Kwok YK, 1999, ACM COMPUT SURV, V31, P406, DOI 10.1145/344588.344618
   Lipton Z. C., 2018, QUEUE, V16, P31, DOI [DOI 10.1145/3236386.3241340, 10.1145/3236386.3241340]
   Liu CM, 2015, IEEE T SYST MAN CY-S, V45, P385, DOI 10.1109/TSMC.2014.2358639
   Mack J, 2023, ACM T EMBED COMPUT S, V22, DOI 10.1145/3529257
   Mao HZ, 2019, SIGCOMM '19 - PROCEEDINGS OF THE ACM SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P270, DOI 10.1145/3341302.3342080
   Mao HZ, 2016, PROCEEDINGS OF THE 15TH ACM WORKSHOP ON HOT TOPICS IN NETWORKS (HOTNETS '16), P50, DOI 10.1145/3005745.3005750
   Moazzemi K, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358203
   Mossalam H, 2016, Arxiv, DOI arXiv:1610.02707
   Navon A., 2020, LEARNING PARETO FRON
   Pan XL, 2017, Arxiv, DOI arXiv:1704.03952
   Roijers DM, 2013, J ARTIF INTELL RES, V48, P67, DOI 10.1613/jair.3987
   Sakellariou R., 2004, Proceedings. 18th International Parallel and Distributed Processing Symposium
   Schulman J, 2017, Arxiv, DOI arXiv:1707.06347
   Silva A, 2020, Arxiv, DOI arXiv:1903.09338
   Silva Andrew, 2020, INT C ARTIFICIAL INT, P1855
   Suárez A, 1999, IEEE T PATTERN ANAL, V21, P1297, DOI 10.1109/34.817409
   Sung TT, 2022, IEEE ACCESS, V10, P98048, DOI 10.1109/ACCESS.2022.3203401
   Tong Z, 2020, NEURAL COMPUT APPL, V32, P5553, DOI 10.1007/s00521-019-04118-8
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Topcuoglu H, 1999, PROC HETER COMP WORK, P3, DOI 10.1109/HCW.1999.765092
   Torrado Ruben Rodriguez, 2018, IEEE C COMP INT GAM, P1
   ULLMAN JD, 1975, J COMPUT SYST SCI, V10, P384, DOI 10.1016/S0022-0000(75)80008-0
   Vega Augusto, 2021, DOSSA 3 WORKSH HPCA
   VELTMAN B, 1990, PARALLEL COMPUT, V16, P173, DOI 10.1016/0167-8191(90)90056-F
   Wang XJ, 2022, IEEE T MOBILE COMPUT, V21, P598, DOI 10.1109/TMC.2020.3012509
   xilinx, ZCU102 EV BOARD
   Xu Jie, 2020, INT C MACHINE LEARNI, P10607
   Yang H, 2008, ISOCC: 2008 INTERNATIONAL SOC DESIGN CONFERENCE, VOLS 1-3, P134, DOI 10.1109/SOCDC.2008.4815591
   Yang Runzhe, 2019, ADV NEURAL INFORM PR, V32, P14636
   Yu C, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3477600
   Zhou JY, 2020, MICROPROCESS MICROSY, V79, DOI 10.1016/j.micpro.2020.103282
   2023, Arxiv, DOI [arXiv:2303.08774, 10.48550/ARXIV.2303.08774, DOI 10.48550/ARXIV.2303.08774]
NR 62
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 22
IS 5
SU S
DI 10.1145/3609108
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Alioto, M
   De, V
   Marongiu, A
AF Alioto, Massimo
   De, Vivek
   Marongiu, Andrea
TI Energy-Quality Scalable Integrated Circuits and Systems: Continuing
   Energy Scaling in the Twilight of Moore's Law
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Energy-efficient integrated circuits; VLSI; machine learning; signal
   processing; architectures; software
ID VERIFYING QUANTITATIVE RELIABILITY; VLSI CIRCUITS; SPECIAL-ISSUE;
   APPROXIMATE; EFFICIENT; PROCESSOR; SRAM; AWARE; ARCHITECTURE; MANAGEMENT
AB This paper aims to take stock of recent advances in the field of energy-quality (EQ) scalable circuits and systems, as promising direction to continue the historical exponential energy downscaling under diminished returns from technology and voltage scaling. EQ-scalable systems explicitly trade off energy and quality at different levels of abstraction and sub-systems, dealing with "quality" as an explicit design requirement, and reducing energy whenever the application, the task, or the dataset allow quality degradation (e.g., vision and machine learning). A general framework for EQ-scalable systems based on the concept of quality slack is presented along with scalable architectures. A taxonomy of techniques to trade off energy and quality, a VLSI perspective, and possible quality control strategies are then discussed. The state of the art is surveyed to put the advances in its different sub-fields into a unitary perspective, emphasizing the on-going and prospective trends. At the component level, the generality of the EQ-scaling concept is shown through several examples, ranging from logic to analog circuits, to memories, data converters, and accelerators. Interesting implications of the joint adoption of EQ scaling and machine learning are also discussed, suggesting that their synergy gives ample room for further energy and performance improvements. From a level of abstraction viewpoint, EQ scaling is discussed from the circuit level to architectures, the hardware-software interface, the programming language, the compiler level, and run-time adaptation. Several case studies are discussed to put EQ scaling in the context of real-world applications.
C1 [Alioto, Massimo] Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
   [De, Vivek] Intel Labs, Circuit Technol Res Grp, Hillsboro, OR 97124 USA.
   [Marongiu, Andrea] Univ Bologna, Dept Comp Sci & Engn, I-40126 Bologna, Italy.
RP Alioto, M (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, Singapore 117583, Singapore.
EM massimo.alioto@nus.edu.sg; vivek.de@intel.com; a.marongiu@unibo.it
CR Aamodt TM, 2008, ACM T EMBED COMPUT S, V7, DOI 10.1145/1347375.1347379
   Addabbo T, 2006, IEEE T CIRCUITS-I, V53, P326, DOI 10.1109/TCSI.2005.856670
   Alaghi A, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465794
   Alioto M, 2017, ENABLING INTERNET TH
   Alioto M, 2018, IEEE J EM SEL TOP C, V8, P361, DOI 10.1109/JETCAS.2018.2865783
   Alioto M, 2017, IEEE T CIRCUITS-I, V64, P2221, DOI 10.1109/TCSI.2017.2730678
   Alioto M, 2017, DES AUT TEST EUROPE, P127, DOI 10.23919/DATE.2017.7926970
   Alioto M, 2012, IEEE T CIRCUITS-II, V59, P849, DOI 10.1109/TCSII.2012.2231011
   Alioto M, 2012, IEEE T CIRCUITS-I, V59, P3, DOI 10.1109/TCSI.2011.2177004
   Almurib HAF, 2016, DES AUT TEST EUROPE, P660
   Alvarez A. B., IEEE J SOLID STATE C
   Alvarez AB, 2017, IEEE ASIAN SOLID STA, P241, DOI 10.1109/ASSCC.2017.8240261
   Alvarez C, 2005, IEEE T COMPUT, V54, P922, DOI 10.1109/TC.2005.119
   Aman M. N., IEEE INTERNET THINGS
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2015, P 25 GREAT LAK S VLS
   [Anonymous], LOW POWER RADIO SURV
   [Anonymous], 2010, P 7 INT C AUTONOMIC
   [Anonymous], 2017, ADV VIDEO CODING GEN
   [Anonymous], 2018, HIGH EFFICIENCY VIDE
   [Anonymous], 2007, PATTERN RECOGN, V16
   [Anonymous], 2011, DESIGN AUTOMATION TE
   [Anonymous], 2013, 2013 INT C HARDWARES
   Ansel J, 2011, INT SYM CODE GENER, P85, DOI 10.1109/CGO.2011.5764677
   Ansel J, 2009, ACM SIGPLAN NOTICES, V44, P38, DOI 10.1145/1543135.1542481
   Ariyarathna V, 2018, IEEE J EM SEL TOP C, V8, P466, DOI 10.1109/JETCAS.2018.2832177
   Babic Z, 2011, MICROPROCESS MICROSY, V35, P23, DOI 10.1016/j.micpro.2010.07.001
   Baek W, 2010, PLDI '10: PROCEEDINGS OF THE 2010 ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P198, DOI 10.1145/1806596.1806620
   Barroso LA, 2007, COMPUTER, V40, P33, DOI 10.1109/MC.2007.443
   Behroozi S, 2018, IEEE J EM SEL TOP C, V8, P379, DOI 10.1109/JETCAS.2018.2856085
   Bergman K., 2008, AIR FORCE RES LAB, V15
   Bolchini C, 2012, DES AUT TEST EUROPE, P1429
   Borkar S., 2011, P 48 DES AUT C DAC S
   Boston B, 2015, ACM SIGPLAN NOTICES, V50, P470, DOI [10.1145/2858965.2814301, 10.1145/2814270.2814301]
   Bowman KA, 2009, IEEE J SOLID-ST CIRC, V44, P49, DOI 10.1109/JSSC.2008.2007148
   Boyapati R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P666, DOI [10.1145/3140659.3080241, 10.1145/3079856.3080241]
   Boyd S., 2004, CONVEX OPTIMIZATION, DOI 10.1017/CBO9780511804441
   Campanoni S, 2015, INT SYM CODE GENER, P235, DOI 10.1109/CGO.2015.7054203
   Carbin M, 2016, COMMUN ACM, V59, P83, DOI 10.1145/2958738
   Carbin M, 2013, ACM SIGPLAN NOTICES, V48, P33, DOI [10.1145/2544173.2509546, 10.1145/2509136.2509546]
   Carbin M, 2012, ACM SIGPLAN NOTICES, V47, P169, DOI 10.1145/2345156.2254086
   Carroll TL, 2005, CHAOS, V15, DOI 10.1063/1.1827451
   Cehovin L, 2016, IEEE T IMAGE PROCESS, V25, P1261, DOI 10.1109/TIP.2016.2520370
   Ceze L., ISAT DARPA WORKSH AC
   Chang G, 2018, IEEE J EM SEL TOP C, V8, P369, DOI 10.1109/JETCAS.2018.2864655
   Chang IJ, 2011, IEEE T CIRC SYST VID, V21, P101, DOI 10.1109/TCSVT.2011.2105550
   Chaudhuri S, 2011, P 19 ACM SIGSOFT S 1, P102
   Cheemalavagu S., 2005, IFIP VLSI-SoC 2005. IFIP WG 10.5 International Conference on Very Large Scale Integration System-on-Chip, P452
   Chen J., 2012, THESIS
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chippa V, 2011, DES AUT CON, P603
   Chippa VK, 2010, DES AUT CON, P555
   Cho M, 2011, IEEE T VLSI SYST, V19, P161, DOI 10.1109/TVLSI.2009.2031468
   Choudhury MR, 2008, DES AUT TEST EUROPE, P782
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Das S, 2009, IEEE J SOLID-ST CIRC, V44, P32, DOI 10.1109/JSSC.2008.2007145
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   de Kruijf M, 2010, CONF PROC INT SYMP C, P497, DOI 10.1145/1816038.1816026
   Desoli G, 2017, ISSCC DIG TECH PAP I, P238, DOI 10.1109/ISSCC.2017.7870349
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Dreslinski RG, 2010, P IEEE, V98, P253, DOI 10.1109/JPROC.2009.2034764
   Du K, 2012, DES AUT TEST EUROPE, P1257
   Egilmez B, 2015, DES AUT TEST EUROPE, P1217
   Eldar Y. C., 2012, COMPRESSED SENSING T
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Fangzhe Chang, 2001, Cluster Computing, V4, P49, DOI 10.1023/A:1011464226688
   Farkhani H, 2018, IEEE J EM SEL TOP C, V8, P627, DOI 10.1109/JETCAS.2018.2813389
   Fick L, 2014, IEEE J SOLID-ST CIRC, V49, P2462, DOI 10.1109/JSSC.2014.2358589
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   Frustaci F, 2016, IEEE T VLSI SYST, V24, P2128, DOI 10.1109/TVLSI.2015.2503733
   Frustaci F, 2015, IEEE J SOLID-ST CIRC, V50, P1310, DOI 10.1109/JSSC.2015.2408332
   Gaines B. R., 1969, ADV INFORM SYSTEMS S, V2, P37
   George J, 2006, CASES 06 P 2006 INT, P158, DOI 10.1145/1176760.1176781
   Giterman R, 2018, IEEE J SOLID-ST CIRC, V53, P2136, DOI 10.1109/JSSC.2018.2820145
   Graillat S., 2016, P 17 INT S SCI COMP, P98
   Guo YX, 2013, IEEE T PARALL DISTR, V24, P1149, DOI 10.1109/TPDS.2012.201
   Halpern M, 2016, INT S HIGH PERF COMP, P64, DOI 10.1109/HPCA.2016.7446054
   Han S., 2016, INT C LEARN REPR ICL
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harpe P., 2015, HIGH PERFORMANCE AD
   Hegde R, 2004, IEEE J SOLID-ST CIRC, V39, P388, DOI 10.1109/JSSC.2003.821775
   Hegde R, 2001, IEEE T VLSI SYST, V9, P813, DOI 10.1109/92.974895
   Hegde R., 1999, Proceedings. 1999 International Symposium on Low Power Electronics and Design (Cat. No.99TH8477), P30, DOI 10.1109/LPE.1999.799405
   HERLIHY M, 1993, CONF PROC INT SYMP C, P289, DOI 10.1145/173682.165164
   Hoffmann H, 2011, ACM SIGPLAN NOTICES, V46, P199, DOI 10.1145/1961296.1950390
   Howard A. G., 2017, ARXIV
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Iandola F. N., 2016, ARXIV
   Jolliffe IT., 2002, CHEMOMETR INTELL LAB, DOI [DOI 10.1016/0169-7439(87)80084-9, 10.1016/0169-7439(87)80084-9]
   Kahng AB, 2012, DES AUT CON, P820
   Karam LJ, 2009, IEEE SIGNAL PROC MAG, V26, P38, DOI 10.1109/MSP.2009.934113
   Kaul H., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P182, DOI 10.1109/ISSCC.2012.6176987
   Kerman M. C., 2009, EVENT DETECTION CHAL
   Khayatzadeh M, 2016, ISSCC DIG TECH PAP I, V59, P310, DOI 10.1109/ISSCC.2016.7418031
   Khudia DS, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P554, DOI 10.1145/2749469.2750371
   Kim SH, 2011, IEEE T COMPUT AID D, V30, P1163, DOI 10.1109/TCAD.2011.2126573
   Kim Y, 2015, IEEE T VLSI SYST, V23, P2733, DOI 10.1109/TVLSI.2014.2365458
   Koomey JG, 2011, IEEE ANN HIST COMPUT, V33, P46, DOI 10.1109/MAHC.2010.28
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kurdahi FJ, 2010, IEEE T VLSI SYST, V18, P852, DOI 10.1109/TVLSI.2009.2016665
   Kwon J, 2012, IEEE T CIRCUITS-I, V59, P2275, DOI 10.1109/TCSI.2012.2185335
   Kyaw K Y, 2010, IEEE INT C ELECT DEV, DOI DOI 10.1109/EDSSC.2010.5713751
   Lam Michael O, 2013, P 27 INT ACM C SUPER, P369
   Le Callet P, 2003, IEEE IMAGE PROC, P437
   Liu C., 2014, P DES AUT TEST EUR C, P1, DOI DOI 10.7873/DATE.2014.108
   Lu SL, 2004, COMPUTER, V37, P67, DOI 10.1109/MC.2004.1274006
   Ludwig JT, 1996, IEEE J SOLID-ST CIRC, V31, P395, DOI 10.1109/4.494201
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Madisetti V., 2009, DIGIT SIGNAL PROCESS
   Maes R., 2013, PHYS UNCLONABLE FUNC
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Maier D, 2018, INT SYM CODE GENER, P290, DOI 10.1145/3168814
   Makhzan MA, 2009, IEEE T VLSI SYST, V17, P827, DOI 10.1109/TVLSI.2009.2016714
   Malladi KT, 2012, CONF PROC INT SYMP C, P37, DOI 10.1109/ISCA.2012.6237004
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Mangharam R., 2011, Proceedings of the 2011 IEEE 32nd Real-Time Systems Symposium (RTSS 2011), P47, DOI 10.1109/RTSS.2011.41
   Medhat R, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126519
   Menezes A. J., 1996, HDB APPL CRYPTOGRAPH
   Meng JY, 2009, INT PARALL DISTRIB P, P107
   Miao J., 2013, P DATE, P1
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Misailovic S., 2010, P 32 ACMIEEE INT C S, V1, P25, DOI DOI 10.1145/1806799.1806808
   Misailovic S, 2014, ACM SIGPLAN NOTICES, V49, P309, DOI [10.1145/10.1145/2660193.2660231, 10.1145/2714064.2660231]
   Misailovic S, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465790
   Misailovic S, 2011, LECT NOTES COMPUT SC, V6887, P316, DOI 10.1007/978-3-642-23702-7_24
   Mohammed A, 2018, IEEE J EM SEL TOP C, V8, P603, DOI 10.1109/JETCAS.2018.2830971
   Mohapatra D, 2009, I SYMPOS LOW POWER E, P195
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Moskvitch K., 2018, QUANTAMAGAZINE
   Murmann B, ADC PERFORMANCE SURV
   Murphy KP, 2012, MACHINE LEARNING: A PROBABILISTIC PERSPECTIVE, P1
   Na Gong, 2012, IEEE Transactions on Circuits and Systems II: Express Briefs, V59, P883, DOI 10.1109/TCSII.2012.2231018
   Narayanamoorthy S, 2015, IEEE T VLSI SYST, V23, P1180, DOI 10.1109/TVLSI.2014.2333366
   Nelson M., 1996, DATA COMPRESSION BOO
   Ho NM, 2017, ASIA S PACIF DES AUT, P63, DOI 10.1109/ASPDAC.2017.7858297
   Nii K, 2008, SYMP VLSI CIRCUITS, P212, DOI 10.1109/VLSIC.2008.4586011
   Ning Zhu, 2011, 2011 International SoC Design Conference (ISOCC 2011), P393, DOI 10.1109/ISOCC.2011.6138614
   Nogues E., IEEE T EMERG TOPICS
   Okada K, 2011, DIGITALLY-ASSISTED ANALOG AND RF CMOS CIRCUIT DESIGN FOR SOFTWARE-DEFINED RADIO, P1, DOI 10.1007/978-1-4419-8514-9
   Papagiannopoulou D, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126556
   Park J, 2010, IEEE T VLSI SYST, V18, P787, DOI 10.1109/TVLSI.2009.2016839
   Parlitz U., 1999, 1999 European Control Conference (ECC). Proceedings, P4637
   Pennebaker W. B., 1993, JPEG STILL IMAGE DAT
   Poppelbaum W., 1967, P NOV 14 16 1967 FAL
   Powers D. M. W., 2020, ARXIV201016061, DOI 10.48550/arXiv.2010.16061
   Preskill J., 2018, QUANTUM COMPUTING IN
   Rabaey J. M., 2011, 2011 Symposium on VLSI Circuits. Digest of Technical Papers, P6
   Rahimi A, 2015, DES AUT CON, DOI 10.1145/2744769.2744915
   Rahimi A, 2013, DES AUT TEST EUROPE, P541
   Rahimi A, 2014, IEEE J EM SEL TOP C, V4, P216, DOI 10.1109/JETCAS.2014.2315883
   Rajwar R, 2001, INT SYMP MICROARCH, P294, DOI 10.1109/MICRO.2001.991127
   Ranjan A., 2012, P DAC
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Renganarayana L., 2012, P 2012 ACM WORKSH RE, P41, DOI DOI 10.1145/2414729.2414737
   Rinard M., 2006, P 20 ANN INT C SUPER, P324
   Ringenburg M, 2015, ACM SIGPLAN NOTICES, V50, P399, DOI [10.1145/2694344.2694365, 10.1145/2775054.2694365]
   Rovere G, 2018, IEEE J EM SEL TOP C, V8, P543, DOI 10.1109/JETCAS.2018.2828505
   Rubio-González C, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503296
   Rusci M, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P314, DOI 10.1145/3203217.3204463
   Samadi M, 2014, ACM SIGPLAN NOTICES, V49, P35, DOI 10.1145/2541940.2541948
   Sampson A., 2016, P WORKSH APPR COMP S, P1
   Sampson A., 2015, TECH REP
   Sampson A, 2011, PLDI 11: PROCEEDINGS OF THE 2011 ACM CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION, P164
   Schulte MJ, 2000, IEEE T COMPUT, V49, P387, DOI 10.1109/12.859535
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Sidiroglou-Douskos S., 2011, P 19 ACM SIGSOFT S 1, P124, DOI [DOI 10.1145/2025113.2025133, 10.1145/2025113.2025133]
   Sinha A., 1999, Twelfth Annual IEEE International ASIC/SOC Conference (Cat. No.99TH8454), P327, DOI 10.1109/ASIC.1999.806528
   Sorber J, 2007, SENSYS'07: PROCEEDINGS OF THE 5TH ACM CONFERENCE ON EMBEDDED NETWORKED SENSOR SYSTEMS, P161
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tagliavini G, 2018, IEEE T COMPUT AID D, V37, P982, DOI 10.1109/TCAD.2016.2633474
   Tagliavini G, 2015, IEEE COMP SOC ANN, P280, DOI 10.1109/ISVLSI.2015.64
   Tahan Oussama, 2012, Architecture of Computing Systems - ARCS 2012. Proceedings 25th International Conference, P25, DOI 10.1007/978-3-642-28293-5_3
   Tarkoma S, 2014, SMARTPHONE ENERGY CONSUMPTION: MODELING AND OPTIMIZATION, P1, DOI 10.1017/CBO9781107326279
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Van De Plassche R., 2003, CMOS INTEGRATED ANAL
   Vassiliadis V., 2015, P 12 ACM INT C COMP
   Venkataramani S, 2013, DES AUT TEST EUROPE, P1367
   Venkataramani S, 2012, DES AUT CON, P796
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weis C., 2018, P IEEE INT S CIRC SY, P1
   Wells JW, 2018, IEEE J EM SEL TOP C, V8, P578, DOI 10.1109/JETCAS.2018.2859218
   Weste N. H. E., 2011, CMOS VLSI DESIGN CIR
   Winkler S, 2008, IEEE T BROADCAST, V54, P660, DOI 10.1109/TBC.2008.2000733
   Xu JW, 2018, IEEE J EM SEL TOP C, V8, P616, DOI 10.1109/JETCAS.2018.2834140
   Xu Q, 2016, IEEE DES TEST, V33, P8, DOI 10.1109/MDAT.2015.2505723
   Yalcin G, 2013, DES AUT TEST EUROPE, P220
   Yip M., 2011, 2011 IEEE International Solid-State Circuits Conference (ISSCC 2011), P190, DOI 10.1109/ISSCC.2011.5746277
   Zhang YQ, 2016, ISSCC DIG TECH PAP I, V59, P160, DOI 10.1109/ISSCC.2016.7417956
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
   Zhu ZA, 2012, POPL 12: PROCEEDINGS OF THE 39TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P441
   Zimmer B, 2016, IEEE J SOLID-ST CIRC, V51, P930, DOI 10.1109/JSSC.2016.2519386
NR 196
TC 25
Z9 25
U1 1
U2 11
PD DEC
PY 2018
VL 8
IS 4
BP 653
EP 678
DI 10.1109/JETCAS.2018.2881461
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wang, WJ
   Caselle, M
   Boltz, T
   Blomley, E
   Brosi, M
   Dritschler, T
   Ebersoldt, A
   Kopmann, A
   Garcia, AS
   Schreiber, P
   Bründermann, E
   Weber, M
   Müller, AS
   Fang, YW
AF Wang, Weija
   Caselle, Michele
   Boltz, Tobias
   Blomley, Edmund
   Brosi, Miriam
   Dritschler, Timo
   Ebersoldt, Andreas
   Kopmann, Andreas
   Garcia, Andrea Santamaria
   Schreiber, Patrick
   Bruendermann, Erik
   Weber, Marc
   Mueller, Anke-Susanne
   Fang, Yangwang
TI Accelerated Deep Reinforcement Learning for Fast Feedback of Beam
   Dynamics at KARA
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article; Proceedings Paper
CT 22nd IEEE-NPSS Real Time Conference (RT) on Computing Applications in
   Nuclear and Plasma Sciences
CY OCT, 2020
CL ELECTR NETWORK
DE Hardware; Radio frequency; Real-time systems; Detectors; Control
   systems; Reinforcement learning; Perturbation methods; Artificial
   intelligence; beam diagnostics; control systems; machine learning;
   particle accelerators; real-time control; reinforcement learning (RL)
AB Coherent synchrotron radiation (CSR) is generated when the electron bunch length is in the order of the magnitude of the wavelength of the emitted radiation. The self-interaction of short electron bunches with their own electromagnetic fields changes the longitudinal beam dynamics significantly. Above a certain current threshold, the micro-bunching instability develops, characterized by the appearance of distinguishable substructures in the longitudinal phase space of the bunch. To stabilize the CSR emission, a real-time feedback control loop based on reinforcement learning (RL) is proposed. Informed by the available THz diagnostics, the feedback is designed to act on the radio frequency (RF) system of the storage ring to mitigate the micro-bunching dynamics. To satisfy low-latency requirements given by the longitudinal beam dynamics, the RL controller has been implemented on hardware (FPGA). In this article, a real-time feedback loop architecture and its performance is presented and compared with a software implementation using Keras-RL on CPU/GPU. The results obtained with the CSR simulation Inovesa demonstrate that the functionality of both platforms is equivalent. The training performance of the hardware implementation is similar to software solution, while it outperforms the Keras-RL implementation by an order of magnitude. The presented RL hardware controller is considered as an essential platform for the development of intelligent CSR control systems.
C1 [Wang, Weija; Caselle, Michele; Dritschler, Timo; Ebersoldt, Andreas; Kopmann, Andreas] Karlsruhe Inst Technol KIT, Inst Data Proc & Elect, D-76344 Eggenstein Leopoldshafen, Germany.
   [Boltz, Tobias; Blomley, Edmund; Brosi, Miriam; Bruendermann, Erik; Mueller, Anke-Susanne] Karlsruhe Inst Technol KIT, Inst Beam Phys & Technol, D-76344 Eggenstein Leopoldshafen, Germany.
   [Garcia, Andrea Santamaria; Schreiber, Patrick] Karlsruhe Inst Technol KIT, Lab Applicat Synchrotron Radiat, D-76131 Karlsruhe, Germany.
   [Weber, Marc] Karlsruhe Inst Technol KIT, Div Phys & Math 5, D-76344 Eggenstein Leopoldshafen, Germany.
   [Fang, Yangwang] Northwestern Polytech Univ, Unmanned Syst Res Inst, Xian 710072, Peoples R China.
RP Caselle, M (corresponding author), Karlsruhe Inst Technol KIT, Inst Data Proc & Elect, D-76344 Eggenstein Leopoldshafen, Germany.
EM michele.caselle@kit.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2016, ZYNQ ULTR MPSOC PROD
   [Anonymous], 2012, TERAHERTZ TECHNIQUES
   Boltz T, 2019, P 10 INT PART ACC C, P104
   Brosi M, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.110701
   Caselle M, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/03/C03015
   Chollet F., 2015, KERAS
   Fu Y., 2017, WP486 XIL
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Müller AS, 2010, REV ACCEL SCI TECH, V3, P165, DOI 10.1142/S1793626810000427
   Muller A.-S, 2017, J INSTRUM, V12
   Schönfeldt P, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.030704
   Schulman J., 2017, ARXIV, DOI DOI 10.1016/J.JDEVECO.2016.04.001
   Schulman J, 2015, PR MACH LEARN RES, V37, P1889
   Shoji Y, 2008, P C P, V806233
   Steinmann J. L, 2019, DIAGNOSTICS SHORT EL
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Teytelman D, 2019, IGP12 720F
NR 20
TC 3
Z9 3
U1 2
U2 10
PD AUG
PY 2021
VL 68
IS 8
BP 1794
EP 1800
DI 10.1109/TNS.2021.3084515
PN 1-3
WC Engineering, Electrical & Electronic; Nuclear Science & Technology
DA 2023-11-11
ER

PT J
AU Senoo, T
   Jinguji, A
   Kuramochi, R
   Nakahara, H
AF Senoo, Takeshi
   Jinguji, Akira
   Kuramochi, Ryosuke
   Nakahara, Hiroki
TI Multilayer Perceptron Training Accelerator Using Systolic Array
SO IEICE TRANSACTIONS ON INFORMATION AND SYSTEMS
DT Article
DE neural network; training accelerator; multilayer perceptron; machine
   learning; intrusion detection system
AB Multilayer perceptron (MLP) is a basic neural network model that is used in practical industrial applications, such as network in-trusion detection (NID) systems. It is also used as a building block in newer models, such as gMLP. Currently, there is a demand for fast training in NID and other areas. However, in training with numerous GPUs, the problems of power consumption and long training times arise. Many of the latest deep neural network (DNN) models and MLPs are trained using a back -propagation algorithm which transmits an error gradient from the output layer to the input layer such that in the sequential computation, the next input cannot be processed until the weights of all layers are updated from the last layer. This is known as backward locking. In this study, a weight parameter update mechanism is proposed with time delays that can accom-modate the weight update delay to allow simultaneous forward and back-ward computation. To this end, a one-dimensional systolic array structure was designed on a Xilinx U50 Alveo FPGA card in which each layer of the MLP is assigned to a processing element (PE). The time-delay backpropa-gation algorithm executes all layers in parallel, and transfers data between layers in a pipeline. Compared to the Intel Core i9 CPU and NVIDIA RTX 3090 GPU, it is 3 times faster than the CPU and 2.5 times faster than the GPU. The processing speed per power consumption is 11.5 times better than that of the CPU and 21.4 times better than that of the GPU. From these results, it is concluded that a training accelerator on an FPGA can achieve high speed and energy efficiency.
C1 [Senoo, Takeshi; Jinguji, Akira; Kuramochi, Ryosuke; Nakahara, Hiroki] Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
RP Senoo, T (corresponding author), Tokyo Inst Technol, Dept Informat & Commun Engn, Tokyo 1528552, Japan.
EM senoo@reconf.ict.e.titech.ac.jp; jinguji@reconf.ict.e.titech.ac.jp;
   kuramochi@reconf.ict.e.titech.ac.jp; nakahara@ict.e.titech.ac.jp
CR [Anonymous], 2006, FPGA IMPLEMENTATIONS
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Carreira-Perpiñán MA, 2014, JMLR WORKSH CONF PRO, V33, P10
   Czarnecki W.M., 2017, ARXIV
   Geng T, 2018, ANN IEEE SYM FIELD P, P81, DOI 10.1109/FCCM.2018.00021
   Gironés RG, 2005, J VLSI SIG PROC SYST, V40, P189, DOI 10.1007/s11265-005-4961-3
   Glorot X., 2010, P JMLR WORKSH C P 13, P249, DOI DOI 10.1177/1753193409103364.
   HUO ZY, 2018, PR MACH LEARN RES, V80
   Isakov M, 2018, I C FIELD PROG LOGIC, P55, DOI 10.1109/FPL.2018.00017
   Jaderberg Max, 2016, ARXIV
   Liu H, 2021, PHYS REV LETT, V126, DOI 10.1103/PhysRevLett.126.250502
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Nakahara H, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P168, DOI 10.1109/FPT.2017.8280135
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Senoo T., 2021, APCCAS, P173
   Taylor G, 2016, PR MACH LEARN RES, V48
   Umuroglu Y, 2020, I C FIELD PROG LOGIC, P291, DOI 10.1109/FPL50879.2020.00055
   Yadan O., 2015, ARXIV
   Zhao W., 2016, IEEE 27 INT C APPL S
NR 20
TC 1
Z9 1
U1 0
U2 2
PD DEC
PY 2022
VL E105D
IS 12
BP 2048
EP 2056
DI 10.1587/transinf.2022PAP0003
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Feng, JH
   Qin, DT
   Liu, YG
   Wang, X
   Lv, H
AF Feng, Jihao
   Qin, Datong
   Liu, Yonggang
   Wang, Xin
   Lv, Hao
TI Pseudo-spectral optimization and model predictive control of vehicle
   shift process with dual clutch transmission
SO PROCEEDINGS OF THE INSTITUTION OF MECHANICAL ENGINEERS PART C-JOURNAL OF
   MECHANICAL ENGINEERING SCIENCE
DT Article
DE Dual-clutch transmission; shifting control; pseudo-spectral
   optimization; trajectory planning; model predictive control
ID MICRO-SLIP CONTROL; CONTROL STRATEGY; GEAR SHIFT; ENGAGEMENT
AB To improve the shift quality of dual clutch transmission (DCT) vehicles and reduce the jerk and sliding friction in the shift process, a real-time planning of clutch optimal engagement trajectory and control method in the shift process is proposed. This method combines pseudo-spectral optimization, machine learning, and model predictive control. First, considering the jerk, sliding friction work, and shift time as the optimization indices, the adaptive pseudo-spectral method is employed to optimize the engagement trajectory of the clutch during the shift process. Based on the optimal trajectory data set, a gradient boosting decision tree-based real-time planning method for the clutch target engagement trajectory is proposed. Second, a model predictive control strategy for the shift process is proposed based on the DCT system model to track the optimal target trajectory in real-time. Simulations and experiments reveal that the proposed target engagement trajectory planning method can plan the clutch target engagement trajectory for various accelerator pedal openings and initial clutch speed states in real-time, and the proposed model predictive control method can accurately track the target trajectory. Compared with the original vehicle strategy, under 35% and 65% accelerator pedal opening, the maximum absolute value of jerk produced by the proposed strategy was reduced by 31.06% and 31.46%, respectively, and the sliding friction work was reduced by 22.87% and 23.24%, respectively. The shift times of the proposed strategy under 35% and 65% accelerator pedal openings were 19.12% and 20.69% lower than that of the original vehicle strategy, respectively.
C1 [Feng, Jihao; Qin, Datong; Liu, Yonggang] Chongqing Univ, State Key Lab Mech Transmiss, Chongqing, Peoples R China.
   [Feng, Jihao; Qin, Datong; Liu, Yonggang] Chongqing Univ, Coll Mech & Vehicle Engn, Chongqing, Peoples R China.
   [Wang, Xin; Lv, Hao] Chongqing Changan Automobile Co Ltd, Chongqing, Peoples R China.
   [Qin, Datong] Chongqing Univ, State Key Lab Mech Transmiss, A Campus, Chongqing 400044, Peoples R China.
RP Qin, DT (corresponding author), Chongqing Univ, State Key Lab Mech Transmiss, A Campus, Chongqing 400044, Peoples R China.
EM dtqin@cqu.edu.cn
CR Coric M, 2017, J DYN SYST-T ASME, V139, DOI 10.1115/1.4035403
   Darby CL, 2011, J SPACECRAFT ROCKETS, V48, P433, DOI 10.2514/1.52136
   Ding Z, 2021, MECHATRONICS, V73, DOI 10.1016/j.mechatronics.2020.102466
   Feng JH, 2021, MEASUREMENT, V181, DOI 10.1016/j.measurement.2021.109609
   Gao AY, 2020, IEEE ACCESS, V8, P60428, DOI 10.1109/ACCESS.2020.2983613
   Garg D, 2010, AUTOMATICA, V46, P1843, DOI 10.1016/j.automatica.2010.06.048
   Kim S, 2020, IEEE-ASME T MECH, V25, P1578, DOI 10.1109/TMECH.2020.2980120
   Kim S, 2018, MECH MACH THEORY, V121, P633, DOI 10.1016/j.mechmachtheory.2017.11.008
   Kim S, 2017, MECH MACH THEORY, V113, P109, DOI 10.1016/j.mechmachtheory.2017.02.013
   Li AT, 2022, MECH MACH THEORY, V173, DOI 10.1016/j.mechmachtheory.2022.104804
   Li GQ, 2018, MECH SYST SIGNAL PR, V103, P23, DOI 10.1016/j.ymssp.2017.09.040
   Liu JK, 2018, P I MECH ENG D-J AUT, V232, P651, DOI 10.1177/0954407017704783
   Liu QF, 2020, IEEE T VEH TECHNOL, V69, P1055, DOI 10.1109/TVT.2019.2949469
   Mishra KD, 2017, CONTROL ENG PRACT, V65, P100, DOI 10.1016/j.conengprac.2017.05.007
   Oh JJ, 2017, IEEE T CONTR SYST T, V25, P1856, DOI 10.1109/TCST.2016.2620421
   Ouyang TC, 2020, APPL MATH MODEL, V85, P157, DOI 10.1016/j.apm.2020.03.019
   Song XY, 2011, J DYN SYST-T ASME, V133, DOI 10.1115/1.4003797
   Tan SQ, 2021, SAE INT J COMMER VEH, V14, P173, DOI 10.4271/02-14-02-0013
   Tongli Lu, 2019, Proceedings of the Institution of Mechanical Engineers, Part K (Journal of Multi-Body Dynamics), V233, P43, DOI 10.1177/1464419318785422
   van Berkel K, 2014, CONTROL ENG PRACT, V22, P57, DOI 10.1016/j.conengprac.2013.09.010
   Wang SH, 2019, MECH SYST SIGNAL PR, V130, P164, DOI 10.1016/j.ymssp.2019.05.008
   Wang WC, 2020, VEHICLE SYST DYN, V58, P604, DOI 10.1080/00423114.2019.1594316
   Wei WP, 2022, IEEE T CONTR SYST T, V30, P368, DOI 10.1109/TCST.2021.3058330
   Wu GQ, 2023, SAE INT J VEH DYN ST, V7, P3, DOI 10.4271/10-07-01-0001
   Wu JL, 2017, APPL MATH MODEL, V51, P1, DOI 10.1016/j.apm.2017.06.030
   Yahagi S, 2020, P I MECH ENG D-J AUT, V234, P2279, DOI 10.1177/0954407020907257
   Zhang CS, 2017, EXPERT SYST APPL, V82, P128, DOI 10.1016/j.eswa.2017.04.003
   ZHAO ZG, 2014, MATH PROBL ENG, V2014
   Zhao ZG, 2016, MECH SYST SIGNAL PR, V75, P413, DOI 10.1016/j.ymssp.2015.12.027
   Zhou B, 2017, P I MECH ENG K-J MUL, V231, P750, DOI 10.1177/1464419317699308
NR 30
TC 0
Z9 0
U1 11
U2 17
PD AUG
PY 2023
VL 237
IS 16
BP 3789
EP 3806
DI 10.1177/09544062221148040
EA JAN 2023
WC Engineering, Mechanical
DA 2023-11-11
ER

PT C
AU Nicholas, GS
   Gui, YT
   Saqib, F
AF Nicholas, Geraldine Shirley
   Gui, Yutian
   Saqib, Fareena
GP IEEE
TI A Survey and Analysis on SoC Platform Security in ARM, Intel and RISC-V
   Architecture
SO 2020 IEEE 63RD INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT 63rd IEEE International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY APR 09-12, 2020
CL ELECTR NETWORK
DE RISC-V; ARM TrustZone; Intel SGX; Trusted Execution Environment (TEE)
ID BOOT
AB Modern heterogeneous computing including IoT devices and Networks deliver optimized and enhanced performance along with high speed but rely on an increased number of components to achieve the desired results. The design productivity for hardware accelerators with machine learning platforms for various application has significant progress on system-on-chip architectures. Most of these technologies provide the desired performance, however, there is always a tradeoff between security and performance. The major role in developing frameworks for hardware security attacks depends on the IP and system architecture. RISC-V provides a platform for custom implementation of security extensions when compared to other traditional architectures. This paper provides a brief survey of different hardware/ software security attacks and summarizes a comparison of security features in RISC-V and other traditional architectures along with security extensions that can be achieved by RISC-V.
C1 [Nicholas, Geraldine Shirley; Gui, Yutian; Saqib, Fareena] Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
RP Nicholas, GS (corresponding author), Univ N Carolina, Dept Elect & Comp Engn, Charlotte, NC 28223 USA.
EM gnichola@uncc.edu; ygui@uncc.edu; fasqib@uncc.edu
CR [Anonymous], 2017, TRUSTZONE TECHN ARMV
   Benhani E, 2017, 2017 30TH IEEE INTERNATIONAL SYSTEM-ON-CHIP CONFERENCE (SOCC), P108, DOI 10.1109/SOCC.2017.8226018
   Costan V., 2016, INTEL SGX EXPLAINED, DOI DOI 10.1145/3061639.3062276
   Costan V, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P857
   Hwang D, 2019, DES AUT TEST EUROPE, P740, DOI [10.23919/DATE.2019.8715277, 10.23919/date.2019.8715277]
   Intel Corporation, 2014, SOFTW GUARD EXT PROG
   Lebedev I, 2018, P IEEE COMPUT SECUR, P46, DOI 10.1109/CSF.2018.00011
   Lee Dayeol, 2019, ABS190710119 ARXIV
   Mukhtar MA, 2019, 2019 2ND INTERNATIONAL CONFERENCE ON COMMUNICATION, COMPUTING AND DIGITAL SYSTEMS (C-CODE), P299, DOI [10.1109/C-CODE.2019.8680982, 10.1109/c-code.2019.8680982]
   Sabet M, 2015, 2015 IEEE TRUSTCOM/BIGDATASE/ISPA, VOL 1, P57, DOI 10.1109/Trustcom.2015.357
   Schwarz Michael, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P3, DOI 10.1007/978-3-319-60876-1_1
   Siddiqui AS, 2019, INT WORKSHOP MICROPR, P56, DOI 10.1109/MTV48867.2019.00019
   Siddiqui AS, 2019, 2019 IEEE 4TH INTERNATIONAL VERIFICATION AND SECURITY WORKSHOP (IVSW 2019), P37, DOI [10.1109/ivsw.2019.8854418, 10.1109/IVSW.2019.8854418]
   Hoang TT, 2020, IEEE ACCESS, V8, P74015, DOI 10.1109/ACCESS.2020.2987617
   Waterman A, 2014, UCBEECS201454, VI
   Yasin M, 2017, IEEE INT CONF VLSI, P237
   Zhang N., 2016, IACR CRYPTOLOGY EPRI, V2016, P980
NR 17
TC 4
Z9 4
U1 2
U2 8
PY 2020
BP 718
EP 721
DI 10.1109/mwscas48704.2020.9184573
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Titov, M
AF Titov, M.
TI Next frontiers in particle physics detectors: INSTR2020 summary and a
   look into the future
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Accelerator Applications; Instrumentation for particle accelerators and
   storage rings high energy (linear accelerators, synchrotrons)
ID TIMING PERFORMANCE; CHAMBER; DAMAGE; TPC
AB The physics goals of high luminosity particle accelerators, from LHC to HL-LHC and to the next generation of lepton colliders, have set quite stringent constraints on the future needs at the Instrumentation Frontier. Many technologies are reaching their sensitivity limit and new approaches need to be developed to overcome the currently irreducible technological challenges. The detrimental effect of the material budget and power consumption represents a very serious concern for a high-precision silicon vertex and tracking detectors. One of the most promising areas is CMOS sensors offering low mass and potentially radiation-hard technology for the future proton-proton and electron-positron colliders, intensity frontier and heavy-ion experiments. MPGDs have become a well-established technique in the fertile field of gaseous detectors; these will remain the primary choice whenever the large-area coverage with low material budget is required. Vacuum tube technology is inherently fast and new developments include advances in microchannel plates for photomultipliers with a potential for a picosecond-time resolution in large systems. Several novel concepts of picosecond-timing detectors will have numerous powerful applications in particle identification, pile-up rejection and event reconstruction, and serve numerous scientific goals. The story of modern calorimetry is a textbook example of physics research driving the development of an experimental method. Silicon photomultipliers have seen a rapid progress in the last decade, becoming the standard solution for scintillator-based devices. The integration of advanced electronics and data transmission functionalities plays an increasingly important role and needs to be addressed. Bringing the modern algorithmic advances from the field of machine learning from offline applications to online operations and trigger systems is another major challenge. The timescales spanned by future projects in particle physics, ranging from few years to many decades, constitute a challenge in itself, in addition to the complexity and diversity of the required accelerator and detector R&D. This paper summarizes advances and recent trends in the instrumentation techniques for particle physics experiments, largely based on the presentations given at the International Conference "Instrumentation for Colliding Beam Physics" (INSTR-20), held at BINP Novosibirsk, Russia, from 24 to 28 February, 2020.
C1 [Titov, M.] Commissariat Energie Atom & Energies Alternative, DRF, IRFU, DPHP, F-91191 Gif Sur Yvette, France.
RP Titov, M (corresponding author), Commissariat Energie Atom & Energies Alternative, DRF, IRFU, DPHP, F-91191 Gif Sur Yvette, France.
EM maxim.titov@cea.fr
CR Abbon P, 2007, NUCL INSTRUM METH A, V577, P455, DOI 10.1016/j.nima.2007.03.026
   Abi B, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/t08008
   Achasov MN, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07005
   Adams B., ARXIV160301843
   Adams BW, 2015, NUCL INSTRUM METH A, V795, P1, DOI 10.1016/j.nima.2015.05.027
   Ahmed Z., 2019, CPAD INSTR FRONT WOR
   Aimard B, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/11/P11003
   Akchurin N, 2017, NUCL INSTRUM METH A, V859, P31, DOI 10.1016/j.nima.2017.03.065
   Akimov D., 2020, COMMUNICATION   0224
   Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   Aleksa M., 2018, CERNOPEN2018006
   Alexopoulos T, 2011, NUCL INSTRUM METH A, V640, P110, DOI 10.1016/j.nima.2011.03.025
   ALICE collaboration, ALICEPUBLIC2018003
   Allport P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/C05005
   Angelico E, 2020, REV SCI INSTRUM, V91, DOI 10.1063/5.0008606
   Angelico E, 2017, NUCL INSTRUM METH A, V846, P75, DOI 10.1016/j.nima.2016.12.008
   Arazi L., 2020, COMMUNICATION   0224
   Arogancia DC, 2009, NUCL INSTRUM METH A, V602, P403, DOI 10.1016/j.nima.2009.01.014
   Attié D, 2017, NUCL INSTRUM METH A, V856, P109, DOI 10.1016/j.nima.2016.11.002
   Bambade P., ARXIV190301629
   Baracchini E, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07036
   Belias A., 2020, COMMUNICATION   0224
   Bencivenni G, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09034
   Blondel A., ARXIV190912245
   Boldyrev A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09030
   Brau JE, 2010, ANNU REV NUCL PART S, V60, P615, DOI 10.1146/annurev.nucl.012809.104449
   Brunbauer F., 2020, COMMUNICATION   0224
   Budnev N., 2020, P INT C INSTR COLL B
   CALICE collaboration, ARXIV12125127 CALICE
   CALICE collaboration, 2014, JINST, V9
   CALICE collaboration, 2010, JINST, V5
   Calzaferri S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09040
   Cartiglia N, 2019, NUCL INSTRUM METH A, V924, P350, DOI 10.1016/j.nima.2018.09.157
   Casse G, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/05/C05057
   Cavallari F, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/03/C03041
   Ceresa D, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/01/C01054
   Chadeeva M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07014
   Chefdeville M, 2016, NUCL INSTRUM METH A, V824, P510, DOI 10.1016/j.nima.2015.11.073
   CMS Collaboration, 2017, PHASE 2 UPGRADE CMS, DOI DOI 10.17181/CERN.IV8M.1JY2
   Credo T, 2004, IEEE NUCL SCI CONF R, P586
   Croci G, 2010, J INSTRUM, V5, DOI 10.1088/1748-0221/5/03/P03001
   Dasgupta S., 2020, COMMUNICATION   0224
   de Oliveira R., 2020, COMMUNICATION   0224
   Deptuch G., 2003, ARXIV13074301
   Di Mauro A, 2020, NUCL INSTRUM METH A, V952, DOI 10.1016/j.nima.2019.04.078
   Dittmeier S, 2016, NUCL INSTRUM METH A, V830, P417, DOI 10.1016/j.nima.2016.06.016
   Dolinski MJ, 2019, ANNU REV NUCL PART S, V69, P219, DOI [10.1146/annurev-nucl-101918023407, 10.1146/annurev-nucl-101918-023407]
   Domenici D., 2020, COMMUNICATION   0224
   Donghia R., 2020, COMMUNICATION   0224
   Dörenkamp S, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/9427231
   Ellis R.K., ARXIV191011775
   Elsen E., 2020, COMMUNICATION   0224
   Fabjan CW, 2003, REV MOD PHYS, V75, P1243, DOI 10.1103/RevModPhys.75.1243
   Fedotov S., 2020, COMMUNICATION   0224
   Fernando W, 2012, PHYSCS PROC, V37, P1805, DOI 10.1016/j.phpro.2012.02.507
   Frisch H.J., 2019, POS MPGD2017
   Garcia L., 2020, COMMUNICATION   0224
   Garcia-Sciveres M, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aab064
   Garutti E, 2019, NUCL INSTRUM METH A, V926, P69, DOI 10.1016/j.nima.2018.10.191
   Gianotti P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06047
   Gnanvo K., 2020, COMMUNICATION   0224
   Gnesi I, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09019
   Gololo MGD, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08020
   Gostkin M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06046
   Grancagnolo F., 2020, COMMUNICATION   0224
   Guz Yu., 2020, COMMUNICATION   0224
   Hartmann F, 2019, NUCL INSTRUM METH A, V924, P250, DOI 10.1016/j.nima.2018.08.101
   Hartmann F, 2011, ANNU REV NUCL PART S, V61, P197, DOI 10.1146/annurev-nucl-102010-130052
   Heuer RD, 2013, PHYS SCRIPTA, VT158, DOI 10.1088/0031-8949/2013/T158/014018
   Hoffman A.C. Abusleme, ARXIV190502520
   Hong D, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09032
   Iddon JP, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08009
   ILD collaboration, ARXIV 1912 0 46 01
   Iodice M., 2020, COMMUNICATION   0224
   Isaacson J.P., 2017, FRAM TDR LHCB UPGR 2
   Jeitler M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09009
   Jesus-Valls C., 2020, P INT C INSTR COLL B
   Joram C, 2015, J INSTRUM, V10, DOI 10.1088/1748-0221/10/08/C08005
   Joram C., 2019, COMMUNICATION   0218
   Kimura M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08012
   Kodys P., 2020, COMMUNICATION   0224
   Korzhik M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08001
   Krammer N, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07038
   Krizan P., 2020, COMMUNICATION   0224
   Krizan P, 2014, J INSTRUM, V9, DOI 10.1088/1748-0221/9/10/C10010
   Krizan P, 2013, NUCL INSTRUM METH A, V706, P48, DOI 10.1016/j.nima.2012.05.013
   Kröger J, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08005
   Kudenko Yu., 2020, P INT C INSTR COLL B
   Kugathasan T., 2018, P 27 INT WORKSH VERT
   Kulish E., 2020, COMMUNICATION   0224
   Kumpan A., 2020, COMMUNICATION   0224
   Lai A., COMMUNICATION   0224
   Lai Y.T., 2020, P INT C INSTR COLL B
   Lee S, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.025002
   Lippmann C, 2012, NUCL INSTRUM METH A, V666, P148, DOI 10.1016/j.nima.2011.03.009
   Liu Z, 2019, NUCL INSTRUM METH A, V927, P396, DOI 10.1016/j.nima.2019.02.068
   Logachev P., 2020, COMMUNICATION   0224
   Longo S., 2020, COMMUNICATION   0224
   Lupberger M, 2017, IEEE T NUCL SCI, V64, P1159, DOI 10.1109/TNS.2017.2689244
   Mahon DJ, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06045
   Mandurrino M., 2019, ARXIV191006045
   Massafferri A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08006
   Maximov D., 2020, COMMUNICATION   0224
   Meschi E, 2015, J PHYS CONF SER, V664, DOI 10.1088/1742-6596/664/8/082032
   Moll M, 2018, IEEE T NUCL SCI, V65, P1561, DOI 10.1109/TNS.2018.2819506
   Monzani S, 2019, NUOVO CIM C-COLLOQ C, V42, DOI 10.1393/ncc/i2019-19184-8
   Movchan S., 2020, COMMUNICATION   0224
   Muchnoi N, 2009, NUCL INSTRUM METH A, V607, P340, DOI 10.1016/j.nima.2009.05.145
   Musienko Y, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09036
   Mussgiller A., 2020, COMMUNICATION   0224
   Nakagiri K., 2020, COMMUNICATION   0224
   Nappi E, 2005, RIV NUOVO CIMENTO, V28, P1, DOI 10.1393/ncr/i2006-10004-6
   Nappi E, 2011, NUCL INSTRUM METH A, V628, P1, DOI 10.1016/j.nima.2010.06.277
   Neri N, 2016, J INSTRUM, V11, DOI 10.1088/1748-0221/11/11/C11040
   Ovtin I., 2020, COMMUNICATION   0224
   Paladino A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07023
   Papanestis A, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09022
   Pernegger H, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/06/P06008
   Poitras ME, 2016, RECH SOINS INFIRM, P24, DOI 10.3917/rsi.126.0024
   Poluektov A., 2020, COMMUNICATION   0224
   Preston M, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08011
   Pudzha D., 2020, COMMUNICATION   0224
   Qi H., 2020, COMMUNICATION   0224
   Ratcliff B, 2020, NUCL INSTRUM METH A, V970, DOI 10.1016/j.nima.2020.163442
   Rodriguez AR, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/08/C08015
   Ruchti RC, 1996, ANNU REV NUCL PART S, V46, P281, DOI 10.1146/annurev.nucl.46.1.281
   Sagawa H, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09012
   Sahin O., 2020, COMMUNICATION   0224
   Sauli F., 2014, GASEOUS RAD DETECTOR
   Schwarz C., 2020, COMMUNICATION   0224
   Schwiening J., 2020, COMMUNICATION   0224
   Sefkow F, 2016, REV MOD PHYS, V88, DOI 10.1103/RevModPhys.88.015003
   Shebalin V., 2020, COMMUNICATION   0224
   Shebalin V., 2020, RUSSIA
   Shekhtman L, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/06/C06005
   Shiltsev V., ARXIV200309084
   Simon F, 2019, NUCL INSTRUM METH A, V926, P85, DOI 10.1016/j.nima.2018.11.042
   Sinev N., 2015, P 24 INT WORKSH VERT
   Snoeys W, 2019, NUCL INSTRUM METH A, V924, P51, DOI 10.1016/j.nima.2018.06.034
   Sprygin A. V., 2012, Sel'skokhozyaistvennaya Biologiya, P24
   Suvorov Y., 2020, COMMUNICATION   0224
   Tassielli G.F., 2020, COMMUNICATION   0224
   Tessarotto F, 2017, NUCL INSTRUM METH A, V876, P225, DOI 10.1016/j.nima.2017.03.011
   Thomson MA, 2009, NUCL INSTRUM METH A, V611, P25, DOI 10.1016/j.nima.2009.09.009
   Titov M., 2004, ICFA INSTRUM B, V26, P002
   Titov M., LC DETECTORS R D LIA
   Titov M, 2013, MOD PHYS LETT A, V28, DOI 10.1142/S0217732313400221
   Torre S. Dalla, 2018, ARXIV180609955
   Tsuboyama T, 2019, NUCL INSTRUM METH A, V924, P422, DOI 10.1016/j.nima.2018.08.089
   Turchetta R, 2011, J INSTRUM, V6, DOI 10.1088/1748-0221/6/01/C01099
   Tyrtyshnaia A, 2020, INT J MOL SCI, V21, DOI 10.3390/ijms21249703
   Tytgat M, 2011, IEEE NUCL SCI CONF R, P1019, DOI 10.1109/NSSMIC.2011.6154312
   Tzanis P, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07002
   Uno S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/07/C07016
   Va'vra J., 2020, Journal of Physics: Conference Series, V1498, DOI 10.1088/1742-6596/1498/1/012013
   Va'vra J., 2020, COMMUNICATION   0224
   Vaidyanathan A., 2020, COMMUNICATION   0224
   Valderanis C., 2020, COMMUNICATION   0224
   Valerio P., 2015, P 23 INT WORKSH VERT
   Vereschagin S, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09044
   Verzi V, 2017, PROG THEOR EXP PHYS, V2017, DOI 10.1093/ptep/ptx082
   Vinogradov S, 2020, NUCL INSTRUM METH A, V952, DOI 10.1016/j.nima.2018.12.067
   Wang F, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/07/C07006
   Wang J, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09008
   Winter M., 2019, P 28 INT WORKSH VERT
   Yarema R, 2013, J INSTRUM, V8, DOI 10.1088/1748-0221/8/01/C01052
   Yashin II, 2015, J PHYS CONF SER, V632, DOI 10.1088/1742-6596/632/1/012030
   Zakareishvili T, 2020, J INSTRUM, V15, DOI 10.1088/1748-0221/15/09/C09003
   Zhang Y, 2019, J INSTRUM, V14, DOI 10.1088/1748-0221/14/08/P08021
   Zhao R., 2019, THESIS
   Zhu RY, 2019, J PHYS CONF SER, V1162, DOI 10.1088/1742-6596/1162/1/012022
NR 171
TC 1
Z9 1
U1 3
U2 11
PD OCT
PY 2020
VL 15
IS 10
AR C10023
DI 10.1088/1748-0221/15/10/C10023
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Zhang, XY
   Xia, HJ
   Zhuang, DL
   Sun, H
   Fu, X
   Taylor, MB
   Song, SWL
AF Zhang, Xingyao
   Xia, Haojun
   Zhuang, Donglin
   Sun, Hao
   Fu, Xin
   Taylor, Michael B.
   Song, Shuaiwen Leon
GP IEEE Comp Soc
TI η-LSTM: Co-Designing Highly-Efficient Large LSTM Training via Exploiting
   Memory-Saving and Architectural Design Opportunities
SO 2021 ACM/IEEE 48TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA 2021)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT ACM/IEEE 48th Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 14-19, 2021
CL ELECTR NETWORK
DE Machine Learning; Neural nets; Recurrent Neural Network; Accelerator
AB Recently, the recurrent neural network, or its most popular type-the Long Short Term Memory (LSTM) network-has achieved great success in a broad spectrum of real-world application domains, such as autonomous driving, natural language processing, sentiment analysis, and epidemiology. Due to the complex features of the real-world tasks, current LSTM models become increasingly bigger and more complicated for enhancing the learning ability and prediction accuracy. However, through our in-depth characterization on the state-of-the-art general-purpose deep-learning accelerators, we observe that the LSTM training execution grows inefficient in terms of storage, performance, and energy consumption, under an increasing model size. With further algorithmic and architectural analysis, we identify the root cause for large LSTM training inefficiency: massive intermediate variables. To enable a highly-efficient LSTM training solution for the ever-growing model size, we exploit some unique memory-saving and performance improvement opportunities from the LSTM training procedure, and leverage them to propose the first cross-stack training solution, eta-LSTM, for large ISTM models. eta-LSTM comprises both software-level and hardware-level innovations that effectively lower the memory footprint upper-bound and excessive data movements during large ISTM training, while also drastically improving training performance and energy efficiency. Experimental results on six real-world large LSTM training benchmarks demonstrate that eta-LSTM reduces the required memory footprint by an average of 57.5% (up to 75.8%) and brings down the data movements for weight matrices, activation data, and intermediate variables by 40.9%, 32.9%, and 80.0%, respectively. Furthermore, it outperforms the state-of-the-art GPU implementation for LSTM training by an average of 3.99x (up to 5.73x) on performance and 2.75x (up to 4.25x) on energy. We hope this work can shed some light on how to design high logic utilization for future NPUs.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, ECOMS Lab, Houston, TX 77004 USA.
   [Zhang, Xingyao; Taylor, Michael B.] Univ Washington, Bespoke Silicon Grp BSG, Seattle, WA 98195 USA.
   [Xia, Haojun; Zhuang, Donglin; Sun, Hao; Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture Lab, Sydney, NSW, Australia.
RP Zhang, XY (corresponding author), Univ Houston, ECOMS Lab, Houston, TX 77004 USA.; Zhang, XY (corresponding author), Univ Washington, Bespoke Silicon Grp BSG, Seattle, WA 98195 USA.
EM xingyaoz@cs.washington.edu; xhjustc@gmail.com; dzhu9887@sydney.edu.au;
   hsun2147@uni.sydney.edu.au; xfu8@central.uh.edu; prof.taylor@gmail.com;
   leonange1991@gmail.com
CR Abiodun OI, 2018, HELIYON, V4, DOI 10.1016/j.heliyon.2018.e00938
   [Anonymous], ACCUMULATOR V12 0 LO
   [Anonymous], AXI HIGH BANDWIDTH M
   [Anonymous], 2016, ARXIV PREPRINT ARXIV
   [Anonymous], NVIDIA TURING GPU AR
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Feist T., 2012, CISC VIS NETW IND GL, V5, P30
   Gao C, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P21, DOI 10.1145/3174243.3174261
   Geng T, 2019, IEEE INT CONF ASAP, P9, DOI 10.1109/ASAP.2019.00-43
   Girma A, 2019, PROC INT C TOOLS ART, P894, DOI 10.1109/ICTAI.2019.00127
   Gu ZC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10062046
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hochreiter S., 2001, FIELD GUIDE DYNAMICA, P237, DOI 10.1109/9780470544037.ch14
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Islam Md Zabirul, 2020, Inform Med Unlocked, V20, P100412, DOI 10.1016/j.imu.2020.100412
   Jia R, 2016, PROCEEDINGS OF THE 54TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, VOL 1, P12
   Jin S., 2021, PPOPP 21 26 ACM SIGP, P2021
   Johnson M., 2017, T ASSOC COMPUT LING, V5, P339, DOI [10.1162/tacl_a_00065, DOI 10.1162/TACL_A_00065]
   Li A, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356169
   Liu WB, 2017, NEUROCOMPUTING, V234, P11, DOI 10.1016/j.neucom.2016.12.038
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Luong Minh-Thang, 2016, ARXIV160400788
   Maas A., 2011, P 49 ANN M ASS COMP, P142, DOI DOI 10.5555/2002472.2002491
   Mahmoud M, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P781, DOI 10.1109/MICRO50266.2020.00069
   Marcus M., 1994, HUMAN LANGUAGE TECHN
   Mattson Peter, 2020, MLSYS, V2, P336
   Palmer D. A., 2014, US Patent, Patent No. [8,655,815, 8655815]
   Park SH, 2018, IEEE INT VEH SYM, P1672, DOI 10.1109/IVS.2018.8500658
   Paszke A, 2019, ADV NEUR IN, V32
   Polyzos S, 2021, TOUR RECREAT RES, V46, P175, DOI 10.1080/02508281.2020.1777053
   Profiler N. V., 2014, US GUID
   Rhu M, 2016, INT SYMP MICROARCH
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Silfa F, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243184
   Tax N, 2017, LECT NOTES COMPUT SC, V10253, P477, DOI 10.1007/978-3-319-59536-8_30
   Ullrich K., 2017, ICLR
   Voorhees E. M., 2000, SIGIR Forum, V34, P200
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Wang S., P 2018 ACM SIGDA INT, P11
   Wang SR, 2019, IEEE ACCESS, V7, P62930, DOI 10.1109/ACCESS.2019.2917312
   Weston J., 2015, ARXIV150205698
   Wissolik M., 2017, XILINX WHITEPAPER
   Yang DQ, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P711, DOI 10.1109/MICRO50266.2020.00064
   Yu Y, 2019, NEURAL COMPUT, V31, P1235, DOI 10.1162/neco_a_01199
   Zhang C., 2021, 35 ACM INT C SUP
   Zhang XY, 2021, IEEE T COMPUT, V70, P495, DOI 10.1109/TC.2021.3056929
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhao Y, 2020, ANN I S COM, P954, DOI 10.1109/ISCA45697.2020.00082
   Zheng BJ, 2020, ANN I S COM, P1089, DOI 10.1109/ISCA45697.2020.00092
NR 51
TC 2
Z9 2
U1 2
U2 10
PY 2021
BP 567
EP 580
DI 10.1109/ISCA52012.2021.00051
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Tanomoto, M
   Takamaeda-Yamazaki, S
   Yao, J
   Nakashima, Y
AF Tanomoto, Masakazu
   Takamaeda-Yamazaki, Shinya
   Yao, Jun
   Nakashima, Yasuhiko
GP IEEE
TI A CGRA-based Approach for Accelerating Convolutional Neural Networks
SO 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE
   SYSTEMS-ON-CHIP (MCSOC)
DT Proceedings Paper
CT 9th IEEE International Symposium on Embedded Multicore/Manycore
   Systems-on-Chip (MCSoC)
CY SEP 23-25, 2015
CL Polytechn Turin, Turin, ITALY
HO Polytechn Turin
AB Convolutional neural network (CNN) is an emerging approach for achieving high recognition accuracy in various machine learning applications. To accelerate CNN computations, various GPU-based or application-specific hardware approaches have been recently proposed. However, since they require large computing hardware and absolute energy amount, they are not suitable for embedded applications. In this paper, we propose a novel approach to accelerate CNN computations using a CGRA (Coarse Grained Reconfigurable Architecture) for low-power embedded systems. We first present a new CGRA with distributed scratchpad memory blocks for efficient temporal blocking to reduce memory bandwidth pressure. We then show the architecture of our CNN accelerator using the CGRA with some dedicated software implementation. We evaluated our approach by comparing some existing platforms, such as high-end and mobile GPUs, and general multicore CPUs. The evaluation result shows that our proposal achieves 1.93x higher performance per memory bandwidth and 2.92x higher area performance, respectively.
C1 [Tanomoto, Masakazu; Takamaeda-Yamazaki, Shinya; Yao, Jun; Nakashima, Yasuhiko] Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
RP Tanomoto, M (corresponding author), Nara Inst Sci & Technol, Grad Sch Informat Sci, Nara, Japan.
EM tanomoto.masakazu.tb8@is.naist.jp; shinya@is.naist.jp;
   yaojun@is.naist.jp; nakashim@is.naist.jp
CR [Anonymous], 2015, MISCELLANEOUS
   [Anonymous], 2015, DEEP RESIDUAL LEARNI
   [Anonymous], 2014, CORR
   [Anonymous], 2011, NIPS 2011 BIGLEARNIN
   [Anonymous], 2014, ACMMM
   Cadambi S, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P273, DOI 10.1145/1854273.1854309
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen Y., 2014, ACM IEEE INT S MICR
   Collobert R., 2008, P 25 INT C MACH LEAR, P160, DOI DOI 10.1145/1390156.1390177
   Collobert R, BIGLEARN NIPS WORKSH
   Farabet C., 2011, WORSH IN CVPR
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Inagaki Y, 2014, 2014 SECOND INTERNATIONAL SYMPOSIUM ON COMPUTING AND NETWORKING (CANDAR), P388, DOI 10.1109/CANDAR.2014.100
   Jafri SMAH, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P506, DOI 10.1109/HPCSim.2014.6903727
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Simard P, 2006, 10 INT WORKSH FRONT
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 23
TC 34
Z9 42
U1 0
U2 6
PY 2015
BP 73
EP 80
DI 10.1109/MCSoC.2015.41
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Denton, M
   Schmit, H
AF Denton, Matthew
   Schmit, Herman
GP IEEE Comp Soc
TI Direct Spatial Implementation of Sparse Matrix Multipliers for Reservoir
   Computing
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
AB Reservoir computing is a nascent sub-field of machine learning which relies on the recurrent multiplication of a very large, sparse, fixed matrix. We argue that direct spatial implementation of these fixed matrices minimizes the work performed in the computation, and allows for significant reduction in latency and power through constant propagation and logic minimization. Bit-serial arithmetic enables massive static matrices to be implemented. We present the structure of our bit-serial matrix multiplier, and evaluate using canonical signed digit representation to further reduce logic utilization. We have implemented these matrices on a large FPGA and provide a cost model that is simple and extensible. These FPGA implementations, on average, reduce latency by 50x up to 86x versus GPU libraries. Comparing against a recent sparse DNN accelerator, we measure a 4.1x to 47x reduction in latency depending on matrix dimension and sparsity.
C1 [Denton, Matthew; Schmit, Herman] Google Res, Mountain View, CA 94043 USA.
RP Denton, M (corresponding author), Google Res, Mountain View, CA 94043 USA.
EM myuzaki@google.com; schmit@google.com
CR Albericio J., 2016, ARXIV
   [Anonymous], 2005, P 16 ANN PROR WORKSH
   Antonik P., 2015, 24 BELG DUTCH C MACH
   Avizienis A, 1961, IRE T ELECT COMPUTER, VEC-10, P389
   Barham P, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P177, DOI 10.1145/3317550.3321441
   Bianchi FM, 2021, IEEE T NEUR NET LEAR, V32, P2169, DOI 10.1109/TNNLS.2020.3001377
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Dong JAT, 2020, Arxiv, DOI arXiv:2006.07310
   Dua D, 2020, UCI MACHINE LEARNING
   Frankle Jonathan, 2019, Arxiv, DOI [arXiv:1803.03635, 10.48550/arXiv.1803.03635]
   Gale T, 2020, Arxiv, DOI arXiv:2006.10901
   Gallicchio C, 2020, Arxiv, DOI arXiv:2006.02957
   Han S, 2016, Arxiv, DOI arXiv:1602.01528
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Dau HA, 2019, IEEE-CAA J AUTOMATIC, V6, P1293, DOI 10.1109/JAS.2019.1911747
   Hooker S, 2021, COMMUN ACM, V64, P58
   Hooker Sara, 2020, HARDWARE LOTTERY
   Reddi VJ, 2020, Arxiv, DOI arXiv:1911.02549
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd P, 2017, IEEE COMPUT ARCHIT L, V16, P80, DOI 10.1109/LCA.2016.2597140
   Karpathy A., CVPR 21 WORKSH AUT D
   Kawai Y, 2019, NEURAL NETWORKS, V112, P15, DOI 10.1016/j.neunet.2019.01.002
   Kleyko D, 2020, Arxiv, DOI arXiv:1706.00280
   Murray A. F., 1988, NEURAL INFORM PROCES, P573
   NVIDIA, 2020, NVIDIA CUSPARSE API
   NVIDIA, 2017, NVIDIA TESLA V100 GP
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Sabour S, 2017, Arxiv, DOI [arXiv:1710.09829, DOI 10.48550/ARXIV.1710.09829]
   Schrauwen B, 2007, LECT NOTES COMPUT SC, V4668, P471
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Sharma H, 2018, Arxiv, DOI arXiv:1712.01507
   Tan MX, 2020, Arxiv, DOI [arXiv:1905.11946, DOI 10.48550/ARXIV.1905.11946]
   Tanaka G, 2019, NEURAL NETWORKS, V115, P100, DOI 10.1016/j.neunet.2019.03.005
   Vaswani A., 2017, PROC INT C NEURAL IN, V30, P5998, DOI DOI 10.48550/ARXIV.1706.03762
   Xilinx, 2020, VIRT ULTRASCALE
NR 35
TC 1
Z9 1
U1 1
U2 2
PY 2022
BP 1
EP 11
DI 10.1109/HPCA53966.2022.00009
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Konstantinou, D
   Nicopoulos, C
   Lee, J
   Dimitrakopoulos, G
AF Konstantinou, Dimitris
   Nicopoulos, Chrysostomos
   Lee, Junghee
   Dimitrakopoulos, Giorgos
TI Multicast-enabled network-on-chip routers leveraging partitioned
   allocation and switching
SO INTEGRATION-THE VLSI JOURNAL
DT Article
DE Network-on-Chip; Multicast; Router; Micro-architecture
AB Multicast on-chip communication is encountered in various cache-coherence protocols targeting multi-core processors, and its pervasiveness is increasing due to the proliferation of machine learning accelerators. Innetwork handling of multicast traffic imposes additional switching-level restrictions to guarantee deadlock freedom, while it stresses the allocation efficiency of Network-on-Chip (NoC) routers. In this work, we propose a novel partitioned NoC router microarchitecture, called SmartFork, which employs a versatile and cost-efficient multicast packet replication scheme that allows the design of high-throughput and low-cost NoCs. The design is adapted to the average branch splitting observed in real-world multicast routing algorithms. Compared to state-of-the-art NoC multicast approaches, SmartFork is demonstrated to yield high performance in terms of latency and throughput, while still offering a cost-effective implementation.
C1 [Konstantinou, Dimitris; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Dept Elect & Comp Engn, Nicosia, Cyprus.
   [Lee, Junghee] Korea Univ, Sch Cyber Secur, Seoul, South Korea.
RP Dimitrakopoulos, G (corresponding author), Democritus Univ Thrace, Dept Elect & Comp Engn, Xanthi, Greece.
EM dimitrak@ee.duth.gr
CR Abadal S, 2016, COMPUT ELECTR ENG, V51, P168, DOI 10.1016/j.compeleceng.2015.12.018
   Agarwal A, 2007, DES AUT CON, P750, DOI 10.1109/DAC.2007.375264
   Agarwal N, 2009, INT SYM PERFORM ANAL, P33, DOI 10.1109/ISPASS.2009.4919636
   [Anonymous], 2003, INT S COMP ARCH ISCA
   [Anonymous], 2012, PROC INT S HIGH PERF
   [Anonymous], 2015, MICROARCHITECTURE NE
   Arteris, 2018, ART IP FLEXNOC AI PA
   Bhardwaj K., 2017, INT S NETW ON CHIP N
   Bhardwaj K, 2019, IEEE T VLSI SYST, V27, P350, DOI 10.1109/TVLSI.2018.2876856
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Boppana R. V., 1994, Proceedings. Sixth IEEE Symposium on Parallel and Distributed Processing (Cat. No.94TH0675-9), P722, DOI 10.1109/SPDP.1994.346103
   Boyd S., 2014, CONVEX OPTIMIZATION
   Conway P, 2007, IEEE MICRO, V27, P10, DOI 10.1109/MM.2007.43
   Daya BK, 2014, CONF PROC INT SYMP C, P25, DOI 10.1109/ISCA.2014.6853232
   Dimitrakopoulos G, 2013, IEEE T COMPUT, V62, P2001, DOI 10.1109/TC.2012.116
   Dimitrakopoulos G, 2008, PR IEEE COMP DESIGN, P664, DOI 10.1109/ICCD.2008.4751932
   Ebrahimi M, 2009, DES AUT TEST EUROPE, P1064
   Gurobi L, 2020, OPTIMIZATION GUROBI
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Krishna T, 2011, INT SYMP MICROARCH, P71
   Krishna T, 2010, PR IEEE COMP DESIGN, P439, DOI 10.1109/ICCD.2010.5647666
   LIN XL, 1991, ACM COMP AR, V19, P116, DOI 10.1145/115953.115965
   Lu Z., 2006, ISVLSI
   Ma S., 2012, IEEE INT S HIGH PERF, P1
   Magnusson PS, 2002, COMPUTER, V35, P50, DOI 10.1109/2.982916
   Malumbres M.P., 1996, IEEE S PAR DIST PROC
   Martin MM., 2005, COMPUTER ARCHITECTUR, V33, P92
   Psarras A, 2016, IEEE T COMPUT, V65, P3136, DOI 10.1109/TC.2016.2519916
   Rodrigo S, 2008, INT SYMP MICROARCH, P364, DOI 10.1109/MICRO.2008.4771805
   Samman FA, 2010, IEEE T VLSI SYST, V18, P1067, DOI 10.1109/TVLSI.2009.2019758
   Seitanidis I, 2014, 2014 EIGHTH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS), P135, DOI 10.1109/NOCS.2014.7008772
   Sivaram R., 1997, PARALLEL COMPUTER RO, P39
   Stefan RA, 2014, IEEE T COMPUT, V63, P583, DOI 10.1109/TC.2012.117
   Wang L, 2009, 2009 3RD ACM/IEEE INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, P64, DOI 10.1109/NOCS.2009.5071446
   Wenmin Hu, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P363, DOI 10.1109/ASPDAC.2011.5722214
   Ye Lu, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P358, DOI 10.1109/SOCC.2012.6398332
NR 36
TC 4
Z9 4
U1 0
U2 5
PD MAR
PY 2021
VL 77
BP 104
EP 112
DI 10.1016/j.vlsi.2020.10.008
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Jo, CW
   Lee, KY
AF Jo, Cheol-Won
   Lee, Kwang-Yeob
GP IEEE
TI Design of multicycle path accelerator for neural network
SO 2019 INTERNATIONAL SOC DESIGN CONFERENCE (ISOCC)
SE International SoC Design Conference
DT Proceedings Paper
CT 16th International System-on-Chip Design Conference (ISOCC)
CY OCT 06-09, 2019
CL SOUTH KOREA
DE Multi Cycle; Neural Network; MAC; machine learning
AB In this paper, MAC computation, which is the most used operation in neural network computing, is accelerated by multicycle_path. When using a pipeline, we can not divide the operation into fixed delays. Thus, exiting pipelines determine the operating frequency with the lowest frequency. We proposed the method confirmed that confirmed that the operation frequency of the whole process is improved by using multicycle_path to divide the operation into a certain delay and to perform the operation. In this paper, the experiment was divided into SingleCycle, Conventional Multicycle, MultiCycle_Ex and MultiCycle_Slice. Conventional Multicycle achieved 2.23 times higher operating frequency than SingleCycle, but resource usage tripled. MultiCycle_Ex achieved a 2.67 times higher operating frequency while maintaining the resource usage of SingleCycle, and MultiCycle_Slice achieved operating frequency about 8.2 times higher than SingleCycle.
C1 [Jo, Cheol-Won; Lee, Kwang-Yeob] Seokyoung Univ, Dept Comp Engn, Seoul, South Korea.
RP Lee, KY (corresponding author), Seokyoung Univ, Dept Comp Engn, Seoul, South Korea.
EM cheolgu94@skuniv.ac.kr; kylee@skuniv.ac.kr
CR Caulfield AM, 2016, INT SYMP MICROARCH
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Higuchi H, 2002, DES AUT CON, P164, DOI 10.1109/DAC.2002.1012613
   Jeong Hyung-Ki, 2008, J IKEEE, V12, P246
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Singh M, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1008, DOI 10.1109/DATE.2004.1269025
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zheng HB, 2014, IEEE T COMPUT AID D, V33, P1832, DOI 10.1109/TCAD.2014.2361661
NR 9
TC 0
Z9 0
U1 0
U2 0
PY 2019
BP 221
EP 224
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chen, YZ
   Lu, L
   Kim, B
   Kim, TTH
AF Chen, Yuzong
   Lu, Lu
   Kim, Bongjin
   Kim, Tony Tae-Hyoung
GP IEEE
TI Reconfigurable 2T2R ReRAM with Split Word-lines for TCAM Operation and
   In-Memory Computing
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE Non-volatile memory; ReRAM; TCAM; in-memory computing
AB The increased latency and power consumption due to data movement between memory and ALU have become the major obstacle in modern big-data and machine learning applications. Beyond von-Neumann architectures, particularly in-memory computing, is under intensive research to overcome this memory access bottleneck. In this work, we propose a 2T2R ReRAM structure that supports ternary content addressable memory (TCAM), logic in-memory operations, and in-memory dot product for Deep Neural Networks (DNNs) besides the normal non-volatile memory (NVM) functionality. This is achieved by employing reconfigurable sense amplifiers and novel word-line drivers. The proposed architecture can serve as a high-density storage system as well as an accelerator for data-intensive applications. Simulation results verify that the proposed 2T2R structure functions correctly for TCAM search, logic in-memory operations and in-memory dot product.
C1 [Chen, Yuzong; Lu, Lu; Kim, Bongjin; Kim, Tony Tae-Hyoung] Nanyang Technol Univ, VIRTUS, Sch Elect & Elect Engn, Singapore, Singapore.
RP Chen, YZ (corresponding author), Nanyang Technol Univ, VIRTUS, Sch Elect & Elect Engn, Singapore, Singapore.
EM E150056@e.ntu.edu.sg
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Bocquet M., 2018, 2018 IEEE INT ELECT, DOI 10.1109/IEDM.2018.8614639
   Chang MF, 2016, IEEE INT SYMP CIRC S, P1142, DOI 10.1109/ISCAS.2016.7527447
   Chen W. H., 2017, IEDM, DOI [10.1109/IEDM.2017.8268468, DOI 10.1109/IEDM.2017.8268468]
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jung Myoungsoo, 2013, P INT ACM C INT C SU, P103
   Ly DRB, 2018, INT EL DEVICES MEET
   Messaris I, 2018, IEEE T COMPUT AID D, V37, P3151, DOI 10.1109/TCAD.2018.2791468
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yang Zhaohui, 2019, IEEE INT SYMP CIRC S, P1, DOI [10.1109/ICC.2019.8761939, DOI 10.1109/iscas.2019.8702555]
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zheng L, 2014, IEEE INT SYMP CIRC S, P2253, DOI 10.1109/ISCAS.2014.6865619
NR 14
TC 0
Z9 0
U1 0
U2 1
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Sadredini, E
   Rahimi, R
   Verma, V
   Stan, M
   Skadron, K
AF Sadredini, Elaheh
   Rahimi, Reza
   Verma, Vaibhav
   Stan, Mircea
   Skadron, Kevin
TI A Scalable and Efficient In-Memory Interconnect Architecture for
   Automata Processing
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Interconnect; processing in memory; automata processing
AB Accelerating finite automata processing benefits regular-expression workloads and a wide range of other applications that do not map obviously to regular expressions, including pattern mining, bioinfomatics, and machine learning. Existing in-memory automata processing accelerators suffer from inefficient routing architectures. They are either incapable of efficiently place-and-route a highly connected automaton or require an excessive amount of hardware resources. In this paper, we propose a compact, low-overhead, and yet flexible in-memory interconnect architecture that efficiently implements routing for next-state activation, and can be applied to the existing in-memory automata processing architectures. We use SRAM 8T subarrays to evaluate our interconnect. Compared to the Cache Automaton routing design, our interconnect reduces the number of switches 7x, therefore, reduces area overhead for the interconnect. It also has faster row cycle time because of shorter wires and consumes less power.
C1 [Sadredini, Elaheh; Skadron, Kevin] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
   [Rahimi, Reza; Verma, Vaibhav; Stan, Mircea] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22903 USA.
RP Sadredini, E (corresponding author), Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
EM elaheh@virginia.edu; rahimi@virginia.edu; vv8dn@virginia.edu;
   mircea@virginia.edu; skadron@virginia.edu
CR [Anonymous], 2016, P INT C HIGH PERF CO
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Gogte, 2016, MICR MICRO 2016 49 A, P1, DOI DOI 10.1109/MICRO.2016.7783747
   ReemKaraki, 2017, P INT C REC COMP FPG, P1
   Sadredini E., 2017, P INT C SUPERCOMPUTI, DOI [10.1145/3079079.3079084, DOI 10.1145/3079079.3079084]
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Wadden J, 2018, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2018.8573482
   Wadden J, 2017, ANN IEEE SYM FIELD P, P180, DOI 10.1109/FCCM.2017.38
   Wadden P, 2016, CAMBR MEDIEV CELT ST, P1
   Zhuo YW, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P29, DOI 10.1109/MICRO.2018.00012
NR 13
TC 2
Z9 2
U1 1
U2 8
PD JUL-DEC
PY 2019
VL 18
IS 2
BP 87
EP 90
DI 10.1109/LCA.2019.2909870
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Jeng, YL
   Huang, SB
   Lai, CF
AF Jeng, Yu -Lin
   Huang, Sheng-Bo
   Lai, Chin-Feng
GP IEEE
TI Inspect Road Quality by Using Anomaly Detection Approach
SO 2018 INTERNATIONAL CONFERENCE ON SYSTEM SCIENCE AND ENGINEERING (ICSSE)
SE International Conference on System Science and Engineering
DT Proceedings Paper
CT International Conference on System Science and Engineering (ICSSE)
CY JUN 28-30, 2018
CL Taipei, TAIWAN
DE Road quality monitoring; Crowdsensing; Mobile Sensors; Smartphones
AB Road quality can be representative of a country's development status, affect transportation speeds and traveler safety. However, there is no standard or set of rules to protect people from the dangers of damaged roads. This study proposes a method for evaluating road quality, which has been made possible by the recent rapid development of information technology and machine learning algorithms, and the popularity and widespread use of smartphones. The proposed inspection method is a road quality inspection APP which collects raw data from smartphone sensors, including GPS and accelerator sensors. Once the data is collected, the server side of the proposed system runs an anomaly detection algorithm to interpret the recorded oscillating amplitude of a specific section of road. The calculated results are then added to the Google Maps app, and abnormal road sections are marked in different colors.
C1 [Jeng, Yu -Lin] Southern Taiwan Univ Sci & Technol, Dept Informat Management, Tainan, Taiwan.
   [Huang, Sheng-Bo; Lai, Chin-Feng] Natl Cheng Kung Univ, Dept Engn Sci, Tainan, Taiwan.
RP Jeng, YL (corresponding author), Southern Taiwan Univ Sci & Technol, Dept Informat Management, Tainan, Taiwan.
EM jackjeng@stust.edu.tw; n98074037@ncku.edu.tw; cinfon@ieee.org
CR Ding MM, 2016, TSINGHUA SCI TECHNOL, V21, P500
   Ganti RK, 2011, IEEE COMMUN MAG, V49, P32, DOI 10.1109/MCOM.2011.6069707
   Hoang Dang Hai, 2018, ADV COMM TECHN ICACT, P281
   Hodge VJ, 2004, ARTIF INTELL REV, V22, P85, DOI 10.1023/B:AIRE.0000045502.10941.a9
   Prarthana TS, 2017, IEEE CONF CLOUD COMP, P3, DOI 10.1109/CCEM.2017.19
   Prasad NR, 2009, CMC-COMPUT MATER CON, V14, P1, DOI 10.1145/1541880.1541882
   Qing Yu, 2017, 2017 International Conference on Computing Intelligence and Information System (CIIS). Proceedings, P62, DOI 10.1109/CIIS.2017.18
   Sun T, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P405, DOI 10.1109/CompComm.2017.8322580
   Yousefi H, 2017, 2017 19TH CSI INTERNATIONAL SYMPOSIUM ON ARTIFICIAL INTELLIGENCE AND SIGNAL PROCESSING (AISP), P205, DOI 10.1109/AISP.2017.8324082
NR 9
TC 0
Z9 0
U1 0
U2 1
PY 2018
WC Computer Science, Interdisciplinary Applications; Engineering,
   Multidisciplinary
DA 2023-11-11
ER

PT C
AU Crovetti, P
   Rubino, R
   Abdullah, A
   Musolino, F
AF Crovetti, Paolo
   Rubino, Roberto
   Abdullah, Ahmed
   Musolino, Francesco
GP IEEE
TI Emerging Relaxation and DDPM D/A Converters: Overview and Perspectives
SO 2022 IEEE 65TH INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS 2022)
DT Proceedings Paper
CT IEEE 65th International Midwest Symposium on Circuits and Systems
   (MWSCAS)
CY AUG 07-10, 2022
CL Fukuoka, JAPAN
DE Relaxation Digital to Analog Converter (ReDAC); Dyadic Digital Pulse
   Modulation (DDPM); Digital to Analog Converter (DAC); Digital-based
   Analog Processing
ID ANALOG
AB In this paper, two emerging, digital-intensive, matching-indifferent, bitstream digital-to-analog (D/A) conversion techniques proposed in the last years, namely: the Relaxation D/A Conversion (ReDAC) and the Dyadic Digital Pulse Modulation (DDPM)-based D/A conversion, are reviewed and compared. After the basic concepts are introduced, the main challenges and research achievements over the last years are summarized and the performance of different integrated circuit (IC), field-programmable gate array (FPGA) and microcontroller-based ReDACs and DDPM-DACs are discussed and compared, highlighting advantages and open research questions. Present applications of the two techniques in voltage and current mode A/D conversion, RF modulation, digitally controlled switching-mode power converters, and machine learning accelerators will be discussed, and future application perspectives will be outlined.
C1 [Crovetti, Paolo; Rubino, Roberto; Abdullah, Ahmed; Musolino, Francesco] Politecn Torino, Dipartimento Elettron & Telecomunicaz DET, Turin, Italy.
RP Crovetti, P (corresponding author), Politecn Torino, Dipartimento Elettron & Telecomunicaz DET, Turin, Italy.
EM paolo.crovetti@polito.it
CR Abdullah A, 2022, IEEE ACCESS, V10, P17515, DOI 10.1109/ACCESS.2022.3150865
   Aiello O, 2020, IEEE ACCESS, V8, P70890, DOI 10.1109/ACCESS.2020.2986949
   Aiello O, 2019, IEEE I C ELECT CIRC, P715, DOI [10.1109/ICECS46596.2019.8964789, 10.1109/icecs46596.2019.8964789]
   Aiello O, 2019, IEEE ACCESS, V7, P126479, DOI 10.1109/ACCESS.2019.2938737
   Aiello O, 2019, IEEE T CIRCUITS-I, V66, P2865, DOI 10.1109/TCSI.2019.2903464
   Alioto M, 2017, ENABLING INTERNET TH
   Carrara S, 2021, IEEE SENS J, V21, P12398, DOI 10.1109/JSEN.2020.3029432
   Crovari Pietro, 2020, IEEE INT SYMP CIRC S, P1, DOI [10.1145/3405755.3406163, DOI 10.1109/iscas45731.2020.9180696]
   Crovetti PS, 2021, ELECTRON LETT, V57, P212, DOI 10.1049/ell2.12050
   Crovetti PS, 2019, ELECTRON LETT, V55, P685, DOI 10.1049/el.2019.0784
   Crovetti PS, 2019, ELECTRON LETT, V55, P672, DOI 10.1049/el.2019.1622
   Crovetti PS, 2012, ELECTRON LETT, V48, P1114, DOI 10.1049/el.2012.1683
   Crovetti PS, 2020, IEEE T POWER ELECTR, V35, P11155, DOI 10.1109/TPEL.2020.2978696
   Crovetti PS, 2017, IEEE T CIRCUITS-I, V64, P573, DOI 10.1109/TCSI.2016.2614231
   Crovetti PS, 2015, IEEE T CIRCUITS-I, V62, P1315, DOI 10.1109/TCSI.2015.2402991
   Crovetti PS, 2013, IEEE T CIRCUITS-I, V60, P3107, DOI 10.1109/TCSI.2013.2255671
   Gupta A., 2022, 2022 IEEE CUSTOM INT
   Hyun D, 2002, IEEE T CIRCUITS-I, V49, P646, DOI 10.1109/TCSI.2002.1001954
   Lu YS, 2020, IEEE T CIRCUITS-I, V67, P2859, DOI 10.1109/TCSI.2020.2979336
   Moffo BL, 2015, IEEE T CIRCUITS-II, V62, P543, DOI 10.1109/TCSII.2015.2407233
   Mohan R, 2017, IEEE J SOLID-ST CIRC, V52, P298, DOI 10.1109/JSSC.2016.2615320
   Rubino R., 2022, 2022 IEEE INT S CIRC, DOI DOI 10.1109/ISCAS48785.2022.9937502
   Rubino R, 2021, IEEE T CIRCUITS-I, V68, P2494, DOI 10.1109/TCSI.2021.3064419
   Rubino R, 2019, 2019 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS 2019), P13, DOI 10.1109/APCCAS47518.2019.8953168
   Song Y, 2022, IEEE T INTELL TRANSP, V23, P22084, DOI 10.1109/TITS.2022.3164596
   Toledo P, 2021, IEEE T CIRCUITS-II, V68, P816, DOI 10.1109/TCSII.2021.3049680
   Toledo P, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9060983
   Usmonov M, 2019, IEEE ENER CONV, P2224, DOI [10.1109/ECCE.2019.8913214, 10.1109/ecce.2019.8913214]
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/MWSCAS54063.2022.9859310
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Filippas, D
   Nicopoulos, C
   Dimitrakopoulos, G
AF Filippas, Dionysios
   Nicopoulos, Chrysostomos
   Dimitrakopoulos, Giorgos
TI Templatized Fused Vector Floating-Point Dot Product for High-Level
   Synthesis
SO JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS
DT Article
DE floating point arithmetic; vector dot product; high level synthesis
AB Machine-learning accelerators rely on floating-point matrix and vector multiplication kernels. To reduce their cost, customized many-term fused architectures are preferred, which improve the latency, power, and area of the designs. In this work, we design a parameterized fused many-term floating-point dot product architecture that is ready for high-level synthesis. In this way, we can exploit the efficiency offered by a well-structured fused dot-product architecture and the freedom offered by high-level synthesis in tuning the design's pipeline to the selected floating-point format and architectural constraints. When compared with optimized dot-product units implemented directly in RTL, the proposed design offers lower-latency implementations under the same clock frequency with marginal area savings. This result holds for a variety of floating-point formats, including standard and reduced-precision representations.
C1 [Filippas, Dionysios; Dimitrakopoulos, Giorgos] Democritus Univ Thrace, Elect & Comp Engn, Xanthi 67100, Greece.
   [Nicopoulos, Chrysostomos] Univ Cyprus, Elect & Comp Engn, CY-1678 Nicosia, Cyprus.
RP Nicopoulos, C (corresponding author), Univ Cyprus, Elect & Comp Engn, CY-1678 Nicosia, Cyprus.
EM nicopoulos@ucy.ac.cy
CR Agrawal A, 2019, P S COMP ARITHM, P92, DOI 10.1109/ARITH.2019.00023
   Andersch M., NVIDIA HOPPER ARCHIT
   Burgess N, 2019, P S COMP ARITHM, P88, DOI 10.1109/ARITH.2019.00022
   cadence, GEN SYNTH SOL
   Cadence, INN IMPL SYST
   de Dinechin F, 2011, IEEE DES TEST COMPUT, V28, P18, DOI 10.1109/MDT.2011.44
   Dimitrakopoulos G, 2008, IEEE T VLSI SYST, V16, P837, DOI 10.1109/TVLSI.2008.2000458
   Fingeroff M., 2010, HIGH LEVEL SYNTHESIS
   Galal S, 2011, P S COMP ARITHM, P129, DOI 10.1109/ARITH.2011.26
   Gholami A., 2021, ARXIV
   github, SIEMENS EDA ALGORITH
   github, IC LAB DUTH REPOSITO
   Hickmann B, 2020, P S COMP ARITHM, P133, DOI 10.1109/ARITH48897.2020.00029
   Hickmann B, 2019, P S COMP ARITHM, P116, DOI 10.1109/ARITH.2019.00031
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Kasgen P., 2018, USING TEMPLATE METAP
   Kaul H, 2019, P S COMP ARITHM, P84, DOI 10.1109/ARITH.2019.00021
   Kim D, 2009, IEEE T COMPUT, V58, P890, DOI 10.1109/TC.2008.210
   Liu Z, 2022, PROC CVPR IEEE, P11966, DOI 10.1109/CVPR52688.2022.01167
   Micikevicius P, 2017, ARXIV
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Saleh HH, 2008, PR IEEE COMP DESIGN, P427, DOI 10.1109/ICCD.2008.4751896
   Seidel PM, 2001, P S COMP ARITHM, P184, DOI 10.1109/ARITH.2001.930118
   Siemens, EDA QUEST ADV SIM
   Sohn J, 2013, P S COMP ARITHM, P41, DOI 10.1109/ARITH.2013.26
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tambe T, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218516
   Thomas DB, 2019, ANN IEEE SYM FIELD P, P227, DOI 10.1109/FCCM.2019.00038
   Uguen Y, 2020, ACM T ARCHIT CODE OP, V17, DOI 10.1145/3377403
   Wang Shibo, 2019, GOOGLE CLOUD BLOG
   Xilinx Vitis, HLS HARDW DES METH A
NR 31
TC 0
Z9 0
U1 1
U2 1
PD DEC
PY 2022
VL 12
IS 4
AR 56
DI 10.3390/jlpea12040056
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kim, D
   Zhao, J
   Bachrach, J
   Asanovi, K
AF Kim, Donggyu
   Zhao, Jerry
   Bachrach, Jonathan
   Asanovi, Krste
GP Assoc Comp Machinery
TI Simmani: Runtime Power Modeling for Arbitrary RTL with Automatic Signal
   Selection
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
ID REGULARIZATION; PERFORMANCE
AB This paper presents a novel runtime power modeling methodology which automatically identifies key signals for power dissipation of any RTL design. The toggle-pattern matrix is constructed with the VCD dumps from a training set, where each signal is represented as a high-dimensional point. By clustering signals showing similar switching activities, a small number of signals are automatically selected, and then the design-specific but workload-independent activity-based power model is constructed using regression against cycle-accurate power traces obtained from industry-standard CAD tools. We can also automatically instrument an FPGA-accelerated RTL simulation with runtime activity counters to obtain power traces of realistic workloads at speed. Our methodology is demonstrated with a heterogeneous processor composed of an in-order core and a custom vector accelerator, running not only microbenchmarks but also real-world machine-learning applications.
C1 [Kim, Donggyu; Zhao, Jerry; Bachrach, Jonathan; Asanovi, Krste] Univ Calif Berkeley, Berkeley, CA 94720 USA.
RP Kim, D (corresponding author), Univ Calif Berkeley, Berkeley, CA 94720 USA.
EM dgkim@berkeley.edu; jerryz123@berkeley.edu; jrb@berkeley.edu;
   krste@berkeley.edu
CR [Anonymous], ICCAD
   [Anonymous], 2016, ISCA
   [Anonymous], DAC
   [Anonymous], 2016, TECHNICAL REPORT
   [Anonymous], 9 ACM SIGOPS EUR WOR
   [Anonymous], PROC ICML
   [Anonymous], PACT
   [Anonymous], HPCA
   [Anonymous], 2009, HP LAB
   [Anonymous], ICCAD
   [Anonymous], DAC
   [Anonymous], HPCA
   [Anonymous], MICRO
   [Anonymous], ISCA
   [Anonymous], ISPASS
   [Anonymous], 2017, 1 WORKSH COMP ARCH R
   [Anonymous], DAC
   [Anonymous], 2009, MICRO
   [Anonymous], 2009, ISPASS
   [Anonymous], ISCA
   [Anonymous], 2015, RICE RES
   [Anonymous], INT S COMP ARCH HIGH
   [Anonymous], 2010, FPL
   [Anonymous], HOMILIA HEXAEMERON
   [Anonymous], ISLPED
   [Anonymous], MICR MOB LPDDR2 SDRA
   [Anonymous], UCBEECS201617
   [Anonymous], 2015 IEEE ACM INT S
   [Anonymous], DATE
   [Anonymous], 2002, ASPLOS
   [Anonymous], 2015, HPCA
   [Anonymous], ISCA
   [Anonymous], ISCA
   [Anonymous], MOB LPDDR2 SYST POW
   [Anonymous], 2012, MICRO
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Bertran R, 2013, IEEE T COMPUT, V62, P1289, DOI 10.1109/TC.2012.97
   Blum A, 2016, FOUND DATA SCI
   BOGLIOLO A, 2000, ACM T DESIGN AUTOMAT, V5
   Cochran R, 2011, INT SYMP MICROARCH, P175
   Dubach C., 2007, MICRO
   Eyerman S, 2010, IEEE T COMPUT, V59, P1576, DOI 10.1109/TC.2010.65
   Friedman J, 2010, J STAT SOFTW, V33, P1, DOI 10.18637/jss.v033.i01
   Gupta S, 2000, IEEE T VLSI SYST, V8, P18, DOI 10.1109/92.820758
   IPEK E, 2006, ASPLOS
   ISCI C, 2003, MICRO
   Isci C, 2006, INT SYMP MICROARCH, P347
   Isci C, 2006, INT S HIGH PERF COMP, P122, DOI 10.1109/HPCA.2006.1598119
   Jacobson H., 2011, HPCA
   JOSEPH PJ, 2006, MICRO
   JOSEPH PJ, 2006, HPCA
   KASS RE, 1995, J AM STAT ASSOC, V90, P773, DOI 10.1080/01621459.1995.10476572
   Kim D., 2017, 1 WORKSH COMP ARCH R
   Kim D, 2019, THESIS
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Laeufer K, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240842
   Lee B., 2008, MICRO
   LEE B, 2007, HPCA
   LEE B, 2006, ASPLOS
   Leng Jingwen, 2013, ISCA
   LI T, 2003, SIGMETRICS
   Najm F. N., 1994, IEEE Transactions on Very Large Scale Integration (VLSI) Systems, V2, P446, DOI 10.1109/92.335013
   Palacharla S., 1997, ISCA
   Patel A., 2011, DAC
   SCHWARZ G, 1978, ANN STAT, V6, P461, DOI 10.1214/aos/1176344136
   Shafi H, 2003, IBM J RES DEV, V47, P641, DOI 10.1147/rd.475.0641
   Shao Yakun Sophia, 2014, ISCA
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wenisch TF, 2006, IEEE MICRO, V26, P18, DOI 10.1109/MM.2006.79
   Zheng B, 2016, IEEE COMP SOC ANN, P53, DOI 10.1109/ISVLSI.2016.126
   Zou H, 2005, J R STAT SOC B, V67, P301, DOI 10.1111/j.1467-9868.2005.00503.x
   Zou H, 2007, ANN STAT, V35, P2173, DOI 10.1214/009053607000000127
NR 72
TC 16
Z9 16
U1 0
U2 0
PY 2019
BP 1050
EP 1062
DI 10.1145/3352460.3358322
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Temple, S
   Neto, WL
   Snelgrove, A
   Tang, XF
   Gaillardon, PE
AF Temple, Scott
   Neto, Walter Lau
   Snelgrove, Ashton
   Tang, Xifan
   Gaillardon, Pierre-Emmanuel
GP IEEE
TI Invited: Getting the Most out of your Circuits with Heterogeneous Logic
   Synthesis
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
AB High Level Synthesis (HLS) speeds hardware development and opens the door to non-expert designers, focusing on functionality rather than implementation. The expense and rigidity of commercial electronic design automation (EDA) tool chains can be an obstacle for these users. LSOracle is an opensource logic synthesis tool which leverages multiple underlying data structures, including and -inverter graphs (AIGs), majority-inverter graphs (MIGs), and xor-and graphs (XAGs) to automatically optimize circuits using the best representation for each region of a design, without manual intervention. The use of MIGs and XAGs gives particularly strong performance in arithmetic logic, cryptography cores, and machine-learning accelerators; applications which may be of particular interest for HLS users. Here we present an overview of the approach and demonstrate an open-source HLS-to-GDS II workflow using LSOracle, Bambu, and OpenROAD. We test the integration on a small benchmark suite and show a reduction in delay of up to 31%.
C1 [Temple, Scott; Neto, Walter Lau; Snelgrove, Ashton; Tang, Xifan; Gaillardon, Pierre-Emmanuel] Univ Utah, Elect & Comp Engn, Salt Lake City, UT 84112 USA.
RP Gaillardon, PE (corresponding author), Univ Utah, Elect & Comp Engn, Salt Lake City, UT 84112 USA.
EM pierre-emmanuel.gaillardon@utah.edu
CR Ajayi T., 2019, DAC
   Amarú L, 2014, DES AUT CON, DOI 10.1145/2593069.2593158
   [Anonymous], ABC SYSTEM SEQUENTIA
   Neto W. L., 2020, DATE
   Pilato C, 2013, I C FIELD PROG LOGIC
   Schlag S., 2016, ALENEX
   Soeken M., 2018, ARXIV180505121
   Sui X., 2010, LCPC
   Temple S., 2021, GOMACTECH
   Testa E., 2020, DATE
   Testa E., 2019, DAC
   Wolf Clifford, 2013, P 21 AUSTRIAN WORKSH
NR 12
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 1331
EP 1334
DI 10.1109/DAC18074.2021.9586215
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Bolsens, I
AF Bolsens, Ivo
GP IEEE
TI Future workloads drive the need for high performant and adaptive
   computing hardware
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM,
   IPDPS
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
AB As big data pushes the need for high-performance and adaptive computing beyond the exascale threshold, the pressure is on to find computing architectures that meet the right mix of price, performance, and power efficiency to support cost-effective data center scalability, acceleration of applications that drive higher end-user productivity and faster time to insights and lower power consumption for sustainability. This will require heterogeneous architectures that combine traditional CPUs and GPUs with innovative accelerators to meet the ever-growing demand of big-data-driven workloads. Endpoints connected to the cloud are being infused with intelligence through sensors, cameras and other devices and are creating massive amounts of mostly unstructured data. Processing this data is driving demand for new workloads such as machine learning. Adaptive computing allows for compute and connectivity hardware that can adapt to the workload and efficiently process data in use, in motion and at rest.
C1 [Bolsens, Ivo] AMD, Adapt & Embedded Comp Grp, Santa Clara, CA 95054 USA.
RP Bolsens, I (corresponding author), AMD, Adapt & Embedded Comp Grp, Santa Clara, CA 95054 USA.
NR 0
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 690
EP 690
DI 10.1109/IPDPS54959.2023.00074
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Kulichenko, M
   Barros, K
   Lubbers, N
   Fedik, N
   Zhou, GQ
   Tretiak, S
   Nebgen, B
   Niklasson, AMN
AF Kulichenko, Maksim
   Barros, Kipton
   Lubbers, Nicholas
   Fedik, Nikita
   Zhou, Guoqing
   Tretiak, Sergei
   Nebgen, Benjamin
   Niklasson, Anders M. N.
TI Semi-Empirical Shadow Molecular Dynamics: A PyTorch Implementation
SO JOURNAL OF CHEMICAL THEORY AND COMPUTATION
DT Article
ID GRAMICIDIN-S; BROYDEN METHOD; CONVERGENCE; PARAMETERS; SPECTRA; MODEL
AB Extended Lagrangian Born-Oppenheimer molecular dynamics (XL-BOMD) in its most recent shadow potential energy version has been implemented in the semiempirical PyTorch-based software PySeQM. The implementation includes finite electronic temperatures, canonical density matrix perturbation theory, and an adaptive Krylov subspace approximation for the integration of the electronic equations of motion within the XL-BOMB approach (KSA-XL-BOMD). The PyTorch implementation leverages the use of GPU and machine learning hardware accelerators for the simulations. The new XL-BOMD formulation allows studying more challenging chemical systems with charge instabilities and low electronic energy gaps. The current public release of PySeQM continues our development of modular architecture for large-scale simulations employing semi-empirical quantum-mechanical treatment. Applied to molecular dynamics, simulation of 840 carbon atoms, one integration time step executes in 4 s on a single Nvidia RTX A6000 GPU.
C1 [Kulichenko, Maksim; Barros, Kipton; Fedik, Nikita; Nebgen, Benjamin; Niklasson, Anders M. N.] Los Alamos Natl Lab, Theoret Div, Los Alamos, NM 87545 USA.
   [Barros, Kipton; Fedik, Nikita] Los Alamos Natl Lab, Ctr Nonlinear Studies, Los Alamos, NM 87545 USA.
   [Lubbers, Nicholas] Los Alamos Natl Lab, Comp Computat & Stat Sci Div, Los Alamos, NM 87545 USA.
   [Zhou, Guoqing] NVIDIA Corp, Santa Clara, CA 95051 USA.
   [Tretiak, Sergei] Los Alamos Natl Lab, Theoret Div, Ctr Nonlinear Studies, Los Alamos, NM 87545 USA.
   [Tretiak, Sergei] Los Alamos Natl Lab, Ctr Integrated Nanotechnol, Los Alamos, NM 87545 USA.
RP Kulichenko, M; Niklasson, AMN (corresponding author), Los Alamos Natl Lab, Theoret Div, Los Alamos, NM 87545 USA.
EM maxim@lanl.gov; amn@lanl.gov
CR Albaugh A, 2018, J CHEM THEORY COMPUT, V14, P499, DOI 10.1021/acs.jctc.7b01041
   Albaugh A, 2017, J PHYS CHEM LETT, V8, P1714, DOI 10.1021/acs.jpclett.7b00450
   Allen M., 1989, COMPUTER SIMULATION, DOI DOI 10.1007/BF00646086
   ANDERSON DG, 1965, J ACM, V12, P547, DOI 10.1145/321296.321305
   Arita M, 2014, J CHEM THEORY COMPUT, V10, P5419, DOI 10.1021/ct500847y
   Atkins P., 2009, ELEMENTS PHYS CHEM, P459
   Bannwarth C, 2021, WIRES COMPUT MOL SCI, V11, DOI 10.1002/wcms.1493
   Bikadi Z, 2009, J CHEMINFORMATICS, V1, DOI 10.1186/1758-2946-1-15
   Bjorgaard JA, 2018, J CHEM THEORY COMPUT, V14, P799, DOI 10.1021/acs.jctc.7b00857
   Bonella S, 2020, PHYS CHEM CHEM PHYS, V22, P10775, DOI 10.1039/d0cp00163e
   BROYDEN CG, 1965, MATH COMPUT, V19, P557
   CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471
   Christensen AS, 2016, CHEM REV, V116, P5301, DOI 10.1021/acs.chemrev.5b00584
   Coretti A, 2018, J CHEM PHYS, V149, DOI 10.1063/1.5055704
   Davidchack RL, 2009, J CHEM PHYS, V130, DOI 10.1063/1.3149788
   DEWAR MJS, 1977, J AM CHEM SOC, V99, P4899, DOI 10.1021/ja00457a004
   DEWAR MJS, 1985, J AM CHEM SOC, V107, P3902, DOI 10.1021/ja00299a024
   Dral PO, 2015, J CHEM THEORY COMPUT, V11, P2120, DOI 10.1021/acs.jctc.5b00141
   Erteeb MA, 2021, AM J CHEM, P1, DOI [./10.5923/j.chemistry.20211101.01, DOI 10.5923/J.CHEMISTRY.20211101.01]
   Gause GF, 1944, NATURE, V154, P703, DOI 10.1038/154703a0
   GLASSER L, 1987, J CHEM EDUC, V64, pA260, DOI 10.1021/ed064pA260
   Hourahine B, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5143190
   JOHNSON DD, 1988, PHYS REV B, V38, P12807, DOI 10.1103/PhysRevB.38.12807
   Joshi K, 2012, J PHYS CHEM B, V116, P483, DOI 10.1021/jp207102v
   KERKER GP, 1981, PHYS REV B, V23, P3082, DOI 10.1103/PhysRevB.23.3082
   KOHN W, 1965, PHYS REV, V140, P1133, DOI 10.1103/PhysRev.140.A1133
   Kupser P, 2010, J AM CHEM SOC, V132, P2085, DOI 10.1021/ja909842j
   Leven I, 2019, PHYS CHEM CHEM PHYS, V21, P18652, DOI 10.1039/c9cp02979f
   Martínez E, 2015, J CHEM PHYS, V142, DOI 10.1063/1.4917546
   Marx D., 2000, NIC SERIES, V3, P329
   MCWEENY R, 1960, REV MOD PHYS, V32, P335, DOI 10.1103/RevModPhys.32.335
   MERMIN ND, 1963, ANN PHYS-NEW YORK, V21, P99, DOI 10.1016/0003-4916(63)90226-4
   Nagornova NS, 2010, J AM CHEM SOC, V132, P4040, DOI 10.1021/ja910118j
   Niklasson AMN, 2006, PHYS REV LETT, V97, DOI 10.1103/PhysRevLett.97.123001
   Niklasson AMN, 2021, EUR PHYS J B, V94, DOI 10.1140/epjb/s10051-021-00151-6
   Niklasson AMN, 2020, J CHEM THEORY COMPUT, V16, P3628, DOI 10.1021/acs.jctc.0c00264
   Niklasson AMN, 2020, J CHEM PHYS, V152, DOI 10.1063/1.5143270
   Niklasson AMN, 2017, J CHEM PHYS, V147, DOI 10.1063/1.4985893
   Niklasson AMN, 2009, J CHEM PHYS, V130, DOI 10.1063/1.3148075
   Niklasson AMN, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.123004
   Niklasson AMN, 2007, J CHEM PHYS, V126, DOI 10.1063/1.2715556
   Paszke Adam, 2017, NIPS 2017 WORKSHOP A
   Peak D., 2005, ENCY SOILS ENV, V4, P80, DOI DOI 10.1016/B0-12-348530-4/00174-0
   PULAY P, 1980, CHEM PHYS LETT, V73, P393, DOI 10.1016/0009-2614(80)80396-4
   Pulay P, 2004, CHEM PHYS LETT, V386, P272, DOI 10.1016/j.cplett.2004.01.069
   PULAY P, 1969, MOL PHYS, V17, P197, DOI 10.1080/00268976900100941
   PURVIS GD, 1982, J CHEM PHYS, V76, P1910, DOI 10.1063/1.443164
   Radhi A.H., 2020, NEUROQUANTOLOGY, V18, P37, DOI https://doi.org/10.14704/nq.2020.18.1.NQ20105
   Remler DK, 1990, MOL PHYS, V70, P921, DOI 10.1080/00268979000101451
   ROOTHAAN CCJ, 1951, REV MOD PHYS, V23, P69, DOI 10.1103/RevModPhys.23.69
   Sabirov DS, 2020, MATHEMATICS-BASEL, V8, DOI 10.3390/math8060968
   Schwerdtfeger P, 2015, WIRES COMPUT MOL SCI, V5, P96, DOI 10.1002/wcms.1207
   SRIVASTAVA GP, 1984, J PHYS A-MATH GEN, V17, pL317, DOI 10.1088/0305-4470/17/6/002
   Steneteg P, 2010, PHYS REV B, V82, DOI 10.1103/PhysRevB.82.075110
   STEWART JJP, 1989, J COMPUT CHEM, V10, P209, DOI 10.1002/jcc.540100208
   Thiel W, 2014, WIRES COMPUT MOL SCI, V4, P145, DOI 10.1002/wcms.1161
   TOXVAERD S, 1994, PHYS REV E, V50, P2271, DOI 10.1103/PhysRevE.50.2271
   VandeVondele J, 2005, COMPUT PHYS COMMUN, V167, P103, DOI 10.1016/j.cpc.2004.12.014
   Vitale V, 2015, J CHEM THEORY COMPUT, V11, P3321, DOI 10.1021/acs.jctc.5b00391
   Wilson Jr E.B., 1980, MOL VIBRATIONS
   Zhang Q, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-79153-w
   Zheng GS, 2011, J CHEM PHYS, V135, DOI 10.1063/1.3605303
   Zheng PK, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-27340-2
   Zhou GQ, 2022, P NATL ACAD SCI USA, V119, DOI 10.1073/pnas.2120333119
   Zhou GQ, 2020, J CHEM THEORY COMPUT, V16, P4951, DOI 10.1021/acs.jctc.0c00243
NR 65
TC 0
Z9 0
U1 6
U2 6
PD MAY 10
PY 2023
VL 19
IS 11
BP 3209
EP 3222
DI 10.1021/acs.jctc.3c00234
EA MAY 2023
WC Chemistry, Physical; Physics, Atomic, Molecular & Chemical
DA 2023-11-11
ER

PT C
AU Vieira, J
   Roma, N
   Falcao, G
   Tomás, P
AF Vieira, Joao
   Roma, Nuno
   Falcao, Gabriel
   Tomas, Pedro
GP IEEE
TI PROCESSING CONVOLUTIONAL NEURAL NETWORKS ON CACHE
SO 2020 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH, AND SIGNAL
   PROCESSING
SE International Conference on Acoustics Speech and Signal Processing
   ICASSP
DT Proceedings Paper
CT IEEE International Conference on Acoustics, Speech, and Signal
   Processing (ICASSP)
CY MAY 04-08, 2020
CL Barcelona, SPAIN
DE CNNs; SIMD; Near-cache processing
ID CNN
AB With the advent of Big Data application domains, several Machine Learning (ML) signal-processing algorithms, such as Convolutional Neural Networks (CNNs), are required to process progressively larger datasets at a great cost in terms of both compute power and memory bandwidth. Although dedicated accelerators have been developed targeting this issue, they usually require moving massive amounts of data across the memory hierarchy to the processing cores and low-level knowledge of how data is stored in the memory devices to enable in-/near-memory processing solutions. In this paper, we propose and assess a novel mechanism that operates at cache level, leveraging both data-proximity and parallel processing capabilities, enabled by dedicated fully-digital vector Functional Units (FUs). We also demonstrate the integration of this mechanism in a conventional Central Processing Unit (CPU). The obtained results show that our engine provides performance improvements on CNNs ranging from 3.92x to 16.6x.
C1 [Vieira, Joao; Roma, Nuno; Tomas, Pedro] Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
   [Falcao, Gabriel] Univ Coimbra, Inst Telecomunicacoes, Coimbra, Portugal.
RP Vieira, J (corresponding author), Univ Lisbon, Inst Super Tecn, INESC ID, Lisbon, Portugal.
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal T, 2019, INT CONF ACOUST SPEE, P1363, DOI 10.1109/ICASSP.2019.8682397
   Barmpoutis P, 2019, INT CONF ACOUST SPEE, P8301, DOI [10.1109/ICASSP.2019.8682647, 10.1109/icassp.2019.8682647]
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Eckert C, 2019, IEEE MICRO, V39, P11, DOI 10.1109/MM.2019.2908101
   Fujiki D, 2018, ACM SIGPLAN NOTICES, V53, P1, DOI [10.1145/3296957.3173171, 10.1145/3173162.3173171]
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Karpathy A, 2014, PROC CVPR IEEE, P1725, DOI 10.1109/CVPR.2014.223
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Liu X., 2019, ISLPED, P1
   Pons J, 2019, INT CONF ACOUST SPEE, P336, DOI 10.1109/ICASSP.2019.8682912
   Pouyan P, 2016, INT WORKS POW TIM, P141, DOI 10.1109/PATMOS.2016.7833679
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2015, IEEE COMPUT ARCHIT L, V14, P127, DOI 10.1109/LCA.2015.2434872
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shaikh S, 2019, BJR CASE REP, V5, DOI 10.1259/bjrcr.20180001
   Sun J, 2019, INT CONF ACOUST SPEE, P7285, DOI 10.1109/ICASSP.2019.8682201
   Vieira J., 2019, VLSI SOC
   Vieira J, 2018, INT SYM COMP ARCHIT, P197, DOI [10.1109/CAHPC.2018.8645905, 10.1109/SBAC-PAD.2018.00041]
   Wang XW, 2019, INT S HIGH PERF COMP, P81, DOI 10.1109/HPCA.2019.00029
   Wang Y, 2018, IEEE T PARALL DISTR, V29, P1428, DOI 10.1109/TPDS.2018.2791440
   Wu X, 2017, NONLINEAR ANAL-HYBRI, V26, P1, DOI 10.1016/j.nahs.2017.04.001
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Yitbarek SF, 2016, DES AUT TEST EUROPE, P1449
NR 27
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 1658
EP 1662
DI 10.1109/icassp40776.2020.9054326
WC Acoustics; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Cancilla, M
   Canalini, L
   Bolelli, F
   Allegretti, S
   Carrión, S
   Paredes, R
   Gómez, JA
   Leo, S
   Piras, ME
   Pireddu, L
   Badouh, A
   Marco-Sola, S
   Alvarez, L
   Moreto, M
   Grana, C
AF Cancilla, Michele
   Canalini, Laura
   Bolelli, Federico
   Allegretti, Stefano
   Carrion, Salvador
   Paredes, Roberto
   Gomez, Jon A.
   Leo, Simone
   Piras, Marco Enrico
   Pireddu, Luca
   Badouh, Asaf
   Marco-Sola, Santiago
   Alvarez, Lluc
   Moreto, Miquel
   Grana, Costantino
GP IEEE COMP SOC
TI The DeepHealth Toolkit: A Unified Framework to Boost Biomedical
   Applications
SO 2020 25TH INTERNATIONAL CONFERENCE ON PATTERN RECOGNITION (ICPR)
SE International Conference on Pattern Recognition
DT Proceedings Paper
CT 25th International Conference on Pattern Recognition (ICPR)
CY JAN 10-15, 2021
CL ELECTR NETWORK
AB Given the overwhelming impact of machine learning on the last decade, several libraries and frameworks have been developed in recent years to simplify the design and training of neural networks, providing array-based programming, automatic differentiation and user-friendly access to hardware accelerators. None of those tools, however, was designed with native and transparent support for Cloud Computing or heterogeneous High-Performance Computing (HPC). The DeepHealth Toolkit is an open source Deep Learning toolkit aimed at boosting productivity of data scientists operating in the medical field by providing a unified framework for the distributed training of neural networks, which is able to leverage hybrid HPC and cloud environments in a transparent way for the user. The toolkit is composed of a Computer Vision library, a Deep Learning library, and a front-end for non-expert users; all of the components are focused on the medical domain, but they are general purpose and can be applied to any other field. In this paper, the principles driving the design of the DeepHealth libraries are described, along with details about the implementation and the interaction between the different elements composing the toolkit. Finally, experiments on common benchmarks prove the efficiency of each separate component and of the DeepHealth Toolkit overall.
C1 [Cancilla, Michele; Canalini, Laura; Bolelli, Federico; Allegretti, Stefano; Grana, Costantino] Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
   [Carrion, Salvador; Paredes, Roberto; Gomez, Jon A.] Univ Politecn Valencia, PRHLT Res Ctr, Valencia, Spain.
   [Leo, Simone; Piras, Marco Enrico; Pireddu, Luca] CRS4, Data Intens Comp Grp, Pula, Italy.
   [Badouh, Asaf; Marco-Sola, Santiago] Barcelona Supercomp Ctr, Barcelona, Spain.
   [Marco-Sola, Santiago; Alvarez, Lluc; Moreto, Miquel] Univ Autonoma Barcelona, Barcelona, Spain.
   [Alvarez, Lluc; Moreto, Miquel] Univ Politecn Cataluna, Barcelona, Spain.
RP Cancilla, M (corresponding author), Univ Modena & Reggio Emilia, Dipartimento Ingn Enzo Ferrari, Modena, Italy.
EM michele.cancilla@unimore.it; laura.canalini@unimore.it;
   federico.bolelli@unimore.it; stefano.allegretti@unimore.it;
   salcarpo@prhlt.upv.es; rparedes@prhlt.upv.es; jon@prhlt.upv.es;
   simone.leo@crs4.it; marco.enrico.piras@crs4.it; luca.pireddu@crs4.it;
   asaf.badouh@bsc.es; santiago.marco-sola@bsc.es; lluc.alvarez@bsc.es;
   miguel.moreto@bsc.es; costantino.grana@unimore.it
CR Allegretti S., 2020, 4 INT C IM VIS PATT
   Allegretti S, 2020, IEEE T PARALL DISTR, V31, P423, DOI 10.1109/TPDS.2019.2934683
   [Anonymous], 2020, SIIM ACR PNEUMOTHORA
   [Anonymous], 2020, KUBEFLOW MACHINE LEA
   [Anonymous], 2020, RABBITMQ MESSAGING J
   [Anonymous], 2020, CELERY DISTRIBUTED T
   [Anonymous], 2020, WXWIDGETS CROSSPLATF
   [Anonymous], 2020, DJANGO WEB FRAMEWORK
   [Anonymous], 2020, OPENAPI SPECIFICATIO
   [Anonymous], 2020, LANGUAGE NEUTRAL PLA
   [Anonymous], 2020, YAML YAML AINT MARKU
   [Anonymous], 2020, OPEN NEURAL NETWORK
   Badia Rosa M., 2015, SoftwareX, V3-4, P32, DOI 10.1016/j.softx.2015.10.004
   Bolelli F, 2019, LECT NOTES COMPUT SC, V11752, P148, DOI 10.1007/978-3-030-30645-8_14
   Bolelli F, 2020, J REAL-TIME IMAGE PR, V17, P229, DOI 10.1007/s11554-018-0756-1
   Bolelli F, 2020, IEEE T IMAGE PROCESS, V29, P1999, DOI 10.1109/TIP.2019.2946979
   Chollet F., 2015, KERAS
   Combalia M., 2019, BCN20000 DERMOSCOPIC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Jakob W., 2020, PYBIND11 SEAMLESS OP
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lyskov S, 2020, BINDER
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
NR 25
TC 7
Z9 7
U1 0
U2 3
PY 2021
BP 9881
EP 9888
DI 10.1109/ICPR48806.2021.9411954
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic; Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT C
AU Schimmelpfennig, RDR
   Vef, MRAR
   Salkhordeh, RZ
   Miranda, AEO
   Nou, RAM
   Brinkmann, AR
AF Schimmelpfennig, Frederic
   Vef, Marc-Andre
   Salkhordeh, Reza
   Miranda, Alberto
   Nou, Ramon
   Brinkmann, Andre
GP IEEE Comp Soc
TI Streamlining distributed Deep Learning I/O with ad hoc file systems
SO 2021 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER 2021)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT IEEE International Conference on Cluster Computing (Cluster)
CY SEP 07-10, 2021
CL ELECTR NETWORK
DE Deep Learning; HPC; file system; data parallel
AB With evolving techniques to parallelize Deep Learning (DL) and the growing amount of training data and model complexity, High-Performance Computing (HPC) has become increasingly important for machine learning engineers. Although many compute clusters already use learning accelerators or GPUs, HPC storage systems are not suitable for the I/O requirements of DL workflows. Therefore, users typically copy the whole training data to the worker nodes or distribute partitions. Because DL depends on randomized input data, prior work stated that partitioning impacts DL accuracy. Their solutions focused mainly on training I/O performance on a high-speed network but did not cover the data stage-in process, for example.
   We show in this paper that, in practice, (unbiased) partitioning is not harmful for distributed DL accuracy. Nevertheless, manual partitioning can be error prone and inefficient. Typically, data must be unpacked and shuffled before it is distributed to nodes. We propose a solution that features both: efficient stage-in and fast access to a global namespace to prevent biases. Our architecture is based around an ad hoc storage system relying on a high-speed interconnect allowing an efficient stage-in of DL data sets into a single global namespace. Our proposed solution does not limit access to parts of the data set or relies on data duplication, also relieving the HPC storage system. We obtain high I/O performance during training and ensure minimal interference with communication of the learning workers. The optimizations are transparent to DL applications and their accuracy is not affected by our architecture.
C1 [Schimmelpfennig, Frederic; Vef, Marc-Andre; Salkhordeh, Reza; Brinkmann, Andre] Johannes Gutenberg Univ Mainz, Mainz, Germany.
   [Miranda, Alberto; Nou, Ramon] Barcelona Supercomp Ctr BSC, Barcelona, Spain.
RP Schimmelpfennig, RDR (corresponding author), Johannes Gutenberg Univ Mainz, Mainz, Germany.
EM frschimm@uni-mainz.de; vef@uni-mainz.de; rsalkhor@uni-mainz.de;
   alberto.miranda@bsc.es; ramon.nou@bsc.es; brinkman@uni-mainz.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2016, BRIT MACHINE VISION
   [Anonymous], 2015, 13 USENIX C FILE STO
   Bahri Y., 2021, ABS210206701 CORR
   Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Braam P., 2005, ABS190301955
   Brinkmann A, 2020, J COMPUT SCI TECH-CH, V35, P4, DOI 10.1007/s11390-020-9801-1
   Chien SWD, 2020, IEEE INT C CL COMP, P359, DOI 10.1109/CLUSTER49012.2020.00046
   Chien SWD, 2018, PROCEEDINGS OF 2018 IEEE/ACM 3RD JOINT INTERNATIONAL WORKSHOP ON PARALLEL DATA STORAGE & DATA INTENSIVE SCALABLE COMPUTING SYSTEMS (PDSW-DISCS), P54, DOI 10.1109/PDSW-DISCS.2018.00011
   Chowdhury F, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337902
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dueben PD, 2018, GEOSCI MODEL DEV, V11, P3999, DOI 10.5194/gmd-11-3999-2018
   He K., 2015, ARXIV
   He K., 2017, P IEEE INT C COMPUTE, DOI 10.1109/ICCV.2017.322
   Herold Frank, 2014, INTRO BEEGFS
   Hinton G, 2009, LEARNING MULTIPLE LA
   Jacob S, 2019, PROCEEDINGS OF THE 2019 RESEARCH ON EQUITY AND SUSTAINED PARTICIPATION IN ENGINEERING, COMPUTING, AND TECHNOLOGY (RESPECT), DOI [10.1109/respect46404.2019.8985944, 10.1109/cluster.2019.8891012]
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurth T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Meng Q, 2019, NEUROCOMPUTING, V337, P46, DOI 10.1016/j.neucom.2019.01.037
   Mikami H., 2018, ARXIV PREPRINT ARXIV
   Oral S., 2013, P CRAY US GROUP C CU
   Oyama Y, 2021, IEEE T PARALL DISTR, V32, P1641, DOI 10.1109/TPDS.2020.3047974
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Patel T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356183
   Pumma S, 2019, ACM TRANS PARALLEL C, V6, DOI 10.1145/3331526
   Rasp S, 2018, P NATL ACAD SCI USA, V115, P9684, DOI 10.1073/pnas.1810286115
   Reichstein M, 2019, NATURE, V566, P195, DOI 10.1038/s41586-019-0912-1
   Schmuck F, 2002, USENIX ASSOCIATION PROCEEDINGS OF THE FAST'02 CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P231
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Soumagne J., 2013, IEEE INT C CL COMP, P1
   Sun P., 2019, ARXIV190206855
   Vef M.-A., 2018, P 2018 IEEE INT C CL
   Vef MA, 2020, J COMPUT SCI TECH-CH, V35, P72, DOI 10.1007/s11390-020-9797-6
   Vef MA, 2018, ACM T STORAGE, V14, DOI 10.1145/3149376
   Wang LP, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404472
   Wang T, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P807, DOI 10.1109/SC.2016.68
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   You Y, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225069
   Zhang Z, 2020, INT PARALL DISTRIB P, P409, DOI 10.1109/IPDPS47924.2020.00050
   Zhu Y, 2019, IEEE INT C CL COMP, P34, DOI 10.1109/cluster.2019.8891023
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
NR 44
TC 0
Z9 0
U1 0
U2 2
PY 2021
BP 169
EP 180
DI 10.1109/Cluster48925.2021.00062
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Valdes, G
   Morin, O
   Valenciaga, Y
   Kirby, N
   Pouliot, J
   Chuang, C
AF Valdes, Gilmer
   Morin, Olivier
   Valenciaga, Yanisley
   Kirby, Niel
   Pouliot, Jean
   Chuang, Cynthia
TI Use of TrueBeam developer mode for imaging QA
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE automated QA; TrueBeam developer mode; XML scripts; image-guidance
   radiation therapy; support vector machine
ID CONE-BEAM CT; QUALITY-ASSURANCE; SYSTEM
AB The purpose of this study was to automate regular Imaging QA procedures to become more efficient and accurate. Daily and monthly imaging QA for SRS and SBRT protocols were fully automated on a Varian linac. A three-step paradigm where the data are automatically acquired, processed, and analyzed was defined. XML scripts were written and used in developer mode in a TrueBeam linac to automatically acquire data. MATLAB R013B was used to develop an interface that could allow the data to be processed and analyzed. Hardware was developed that allowed the localization of several phantoms simultaneously on the couch. 14 KV CBCTs from the Emma phantom were obtained using a TrueBeam onboard imager as example of data acquisition and analysis. The images were acquired during two months. Artifacts were artificially introduced in the images during the reconstruction process using iTool reconstructor. Support vector machine algorithms to automatically identify each artifact were written using the Machine Learning MATLAB R2011 Toolbox. A daily imaging QA test could be performed by an experienced medical physicist in 14.3 +/- 2.4 min. The same test, if automated using our paradigm, could be performed in 4.2 +/- 0.7 min. In the same manner, a monthly imaging QA could be performed by a physicist in 70.7 +/- 8.0 min and, if fully automated, in 21.8 +/- 0.6 min. Additionally, quantitative data analysis could be automatically performed by Machine Learning Algorithms that could remove the subjectivity of data interpretation in the QA process. For instance, support vector machine algorithms could correctly identify beam hardening, rings and scatter artifacts. Traditional metrics, as well as metrics that describe texture, are needed for the classification. Modern linear accelerators are equipped with advanced 2D and 3D imaging capabilities that are used for patient alignment, substantially improving IGRT treatment accuracy. However, this extra complexity exponentially increases the number of QA tests needed. Using the new paradigm described above, not only the bare minimum - but also best practice - QA programs could be implemented with the same manpower.
C1 [Valdes, Gilmer; Morin, Olivier; Kirby, Niel] Univ Calif San Francisco, Dept Radiat Oncol, San Francisco, CA USA.
   [Valdes, Gilmer; Pouliot, Jean; Chuang, Cynthia] Univ Penn, Dept Radiat Oncol, Perelman Ctr Adv Med, Philadelphia, PA 19104 USA.
   [Valenciaga, Yanisley] Univ Calif Los Angeles, David Geffen Sch Med, Biomed Phys Interdept Program, Los Angeles, CA 90095 USA.
RP Valdes, G (corresponding author), Perelman Ctr Adv Med, Dept Radiat Oncol, 3400 Civ Blvd, Philadelphia, PA 19104 USA.
EM gilmer.valdes@uphs.upenn.edu
CR Bissonnette JP, 2012, MED PHYS, V39, P1946, DOI 10.1118/1.3690466
   Clausi DA, 2002, CAN J REMOTE SENS, V28, P45, DOI 10.5589/m02-004
   Das Indra J, 2011, J Appl Clin Med Phys, V12, P3350
   DROEGE RT, 1982, MED PHYS, V9, P758, DOI 10.1118/1.595124
   FONTENOT JD, 2014, J APPL CLIN MED PHY, V15, P4528
   Gao S, 2012, MED PHYS, V39, P3604, DOI 10.1118/1.4734633
   Gayou O, 2007, MED PHYS, V34, P3183, DOI 10.1118/1.2752374
   Gopal A, 2009, MED PHYS, V36, P2006, DOI 10.1118/1.3099559
   Kim C, 2012, MED PHYS, V39, P3656, DOI 10.1118/1.4734854
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   LUTZ W, 1988, INT J RADIAT ONCOL, V14, P373, DOI 10.1016/0360-3016(88)90446-4
   Soh L., 1999, IEEE T GEOSCI REMOTE, V37
   Sumida I, 2014, J RADIAT RES, V55, P191, DOI 10.1093/jrr/rrt100
   Tourassi GD, 1999, RADIOLOGY, V213, P317, DOI 10.1148/radiology.213.2.r99nv49317
NR 14
TC 26
Z9 27
U1 0
U2 11
PY 2015
VL 16
IS 4
BP 322
EP 333
DI 10.1120/jacmp.v16i4.5363
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Rankin, D
   Krupa, J
   Harris, P
   Flechas, MA
   Holzman, B
   Klijnsma, T
   Pedro, K
   Tran, N
   Hauck, S
   Hsu, SC
   Trahms, M
   Lin, K
   Lou, Y
   Ho, TW
   Duarte, J
   Liu, M
AF Rankin, Dylan
   Krupa, Jeffrey
   Harris, Philip
   Flechas, Maria Acosta
   Holzman, Burt
   Klijnsma, Thomas
   Pedro, Kevin
   Tran, Nhan
   Hauck, Scott
   Hsu, Shih-Chieh
   Trahms, Matthew
   Lin, Kelvin
   Lou, Yu
   Ho, Ta-Wei
   Duarte, Javier
   Liu, Mia
GP IEEE
TI FPGAs-as-a-Service Toolkit (FaaST)
SO PROCEEDINGS OF H2RC 2020: 2020 SIXTH IEEE/ACM INTERNATIONAL WORKSHOP ON
   HETEROGENEOUS HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC)
DT Proceedings Paper
CT 6th IEEE/ACM International Workshop on Heterogeneous High-performance
   Reconfigurable Computing (H2RC)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE FPGAs; machine learning; as a service; high energy physics
AB Computing needs for high energy physics are already intensive and are expected to increase drastically in the coming years. In this context, heterogeneous computing, specifically as-a-service computing, has the potential for significant gains over traditional computing models. Although previous studies and packages in the field of heterogeneous computing have focused on GPUs as accelerators, FPGAs are an extremely promising option as well. A series of workflows are developed to establish the performance capabilities of FPGAs as a service. Multiple different devices and a range of algorithms for use in high energy physics are studied. For a small, dense network, the throughput can be improved by an order of magnitude with respect to GPUs as a service. For large convolutional networks, the throughput is found to be comparable to GPUs as a service. This work represents the first open-source FPGAs-as-a-service toolkit.
C1 [Rankin, Dylan; Krupa, Jeffrey; Harris, Philip] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Flechas, Maria Acosta; Holzman, Burt; Klijnsma, Thomas; Pedro, Kevin; Tran, Nhan] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Hauck, Scott; Hsu, Shih-Chieh; Trahms, Matthew; Lin, Kelvin; Lou, Yu] Univ Washington, Seattle, WA 98195 USA.
   [Ho, Ta-Wei] Natl Tsing Hua Univ, Hsinchu 300044, Taiwan.
   [Duarte, Javier] Univ Calif San Diego, La Jolla, CA 92093 USA.
   [Liu, Mia] Purdue Univ, W Lafayette, IN 47907 USA.
RP Rankin, D (corresponding author), MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Agarap AF, 2018, ARXIV PREPRINT ARXIV, V1803
   Armbrust M, 2010, COMMUN ACM, V53, P50, DOI 10.1145/1721654.1721672
   ATLAS Collaboration, 2020, COMPUTING SOFTWARE P
   Aymerich FM, 2008, 2008 FIRST INTERNATIONAL CONFERENCE ON THE APPLICATIONS OF DIGITAL INFORMATION AND WEB TECHNOLOGIES, VOLS 1 AND 2, P120
   Banerjee P, 2011, COMPUTER, V44, P36, DOI 10.1109/MC.2011.67
   Bennett K, 2000, SEVENTH ASIA-PACIFIC SOFTWARE ENGINEERING CONFERENCE, PROCEEDINGS, P214, DOI 10.1109/APSEC.2000.896702
   Bouguettaya A, 2017, COMMUN ACM, V60, P64, DOI 10.1145/2983528
   CMS Collaboration, 2020, CMS OFFLINE COMPUTIN
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Duarte Javier, 2019, Computing and Software for Big Science, V3, DOI 10.1007/s41781-019-0027-2
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fabjan CW, 2003, REV MOD PHYS, V75, P1243, DOI 10.1103/RevModPhys.75.1243
   Ghanathe NP, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/01/C01083
   Google LLC, 2018, GRPC
   Holzman B, 2017, COMPUT SOFTW BIG SCI, V1, P1, DOI DOI 10.1007/S41781-017-0001-9
   Intel, 2018, THREAD BUILDING BLOC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kasieczka G., 2019, **DATA OBJECT**, DOI [10.5281/zenodo.2603256, DOI 10.5281/ZENODO.2603256]
   Kasieczka G, 2019, SCIPOST PHYS, V7, DOI 10.21468/SciPostPhys.7.1.014
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Krupa J., 2020, ARXIV200710359
   Loncar V, 2020, HLS FPGA MACHINE LEA, V6, DOI [DOI 10.5281/ZENODO.3969548V0.3.0, 10.5281/zenodo.3969548V0.3.0]
   Lou Y, 2020, ML SUITE GRPC INTERF
   Massironi A, 2020, J PHYS CONF SER, V1525, DOI 10.1088/1742-6596/1525/1/012040
   Microsoft Corporation, 2020, AZURE STACK EDGE DAT
   Microsoft Corporation, 2017, MICROSOFT PLATFORM W
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2788396
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Nvidia, 2019, TRITON INFERENCE SER
   Rankin D., FAAST FACILE, DOI DOI 10.5281/ZENODO.3992377
   Reese Will, 2008, LINUX J, P2, DOI DOI 10.5555/1412202.1412204
   Rovere M, 2020, FRONT BIG DATA, V3, DOI 10.3389/fdata.2020.591315
   Tarafdar N, 2020, ANN IEEE SYM FIELD P, P239, DOI 10.1109/FCCM48280.2020.00072
   Tarreau W., 2020, HAPROXY
   Xilinx Inc., 2020, XILINX ML SUITE
NR 38
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 38
EP 47
DI 10.1109/H2RC51942.2020.00010
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Looe, HK
   Blum, I
   Schönfeld, AB
   Tekin, T
   Delfs, B
   Poppe, B
AF Looe, Hui Khee
   Blum, Isabel
   Schoenfeld, Ann-Britt
   Tekin, Tuba
   Delfs, Bjoern
   Poppe, Bjoern
TI Model-based machine learning for the recovery of lateral dose profiles
   of small photon fields in magnetic field
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE magnetic resonance guided radiation therapy; Lorentz force; small field
   dosimetry; lateral response function; artificial neural network;
   deconvolution; machine learning
ID BODY RADIATION-THERAPY; MONTE-CARLO; IONIZATION CHAMBERS; DOSIMETER
   RESPONSE; DETECTOR DENSITY; DIODE; DECONVOLUTION; ACCELERATOR; SYSTEM;
   IMPACT
AB Objective. To investigate the feasibility to train artificial neural networks (NN) to recover lateral dose profiles from detector measurements in a magnetic field. Approach. A novel framework based on a mathematical convolution model has been proposed to generate measurement-less training dataset. 2D dose deposition kernels and detector lateral fluence response functions of two air-filled ionization chambers and two diode-type detectors have been simulated without magnetic field and for magnetic field B = 0.35 and 1.5 T. Using these convolution kernels, training dataset consisting pairs of dose profiles D (x, y) and signal profiles M (x, y) were computed for a total of 108 2D photon fluence profiles psi(x, y) (80% training/20% validation). The NN were tested using three independent datasets, where the second test dataset has been obtained from simulations using realistic phase space files of clinical linear accelerator and the third test dataset was measured at a conventional linac equipped with electromagnets. Main results. The convolution kernels show magnetic field dependence due to the influence of the Lorentz force on the electron transport in the water phantom and detectors. The NN show good performance during training and validation with mean square error reaching a value of 1e-6 or smaller. The corresponding correlation coefficients R reached the value of 1 for all models indicating an excellent agreement between expected D (x, y) and predicted D-pred(x, y). The comparisons between D (x, y) and D-pred (x, y) using the three test datasets resulted in gamma indices (1 mm/1% global) <1 for all evaluated data points. Significance. Two verification approaches have been proposed to warrant the mathematical consistencies of the NN outputs. Besides offering a correction strategy not existed so far for relative dosimetry in a magnetic field, this work could help to raise awareness and to improve understanding on the distortion of detector's signal profiles by a magnetic field.
C1 [Looe, Hui Khee; Blum, Isabel; Tekin, Tuba; Delfs, Bjoern; Poppe, Bjoern] Carl von Ossietzky Univ Oldenburg, Pius Hosp, Univ Clin Med Radiat Phys, Med Campus, Oldenburg, Germany.
   [Schoenfeld, Ann-Britt] PTB, Braunschweig, Germany.
RP Looe, HK (corresponding author), Carl von Ossietzky Univ Oldenburg, Pius Hosp, Univ Clin Med Radiat Phys, Med Campus, Oldenburg, Germany.
EM hui.k.looe@uni-oldenburg.de
CR Bednarz G, 2002, PHYS MED BIOL, V47, P3643, DOI 10.1088/0031-9155/47/20/306
   Blum I, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac0f2e
   Chofor N, 2014, Z MED PHYS, V24, P27, DOI 10.1016/j.zemedi.2013.04.001
   Chofor N, 2012, Z MED PHYS, V22, P181, DOI 10.1016/j.zemedi.2012.05.001
   Corradini S, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1308-y
   Cranmer-Sargison G, 2011, MED PHYS, V38, P6592, DOI 10.1118/1.3658572
   de Pooter J, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ab9efe
   Delfs B, 2021, MED PHYS, DOI 10.1002/mp.14994
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aadd3d
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aa9bd5
   FEIST H, 1968, NUCL INSTRUM METHODS, V58, P236, DOI 10.1016/0029-554X(68)90470-9
   Fenwick JD, 2013, PHYS MED BIOL, V58, P2901, DOI 10.1088/0031-9155/58/9/2901
   Folkert MR, 2017, ADV DRUG DELIVER REV, V109, P3, DOI 10.1016/j.addr.2016.11.005
   Francescon P, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/ab6154
   Francescon P, 2017, PHYS MED BIOL, V62, P1076, DOI 10.1088/1361-6560/aa5610
   Harder D., 2014, COMPREHENSIVE BIOMED, P249
   Herrup D, 2005, MED PHYS, V32, P3636, DOI 10.1118/1.2128086
   Kim HE, 2020, LANCET DIGIT HEALTH, V2, pE138, DOI 10.1016/S2589-7500(20)30003-0
   Kontaxis C, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/abd66d
   Laub WU, 2003, MED PHYS, V30, P341, DOI 10.1118/1.1544678
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Looe HK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aab50c
   Looe HK, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aa9b46
   Looe HK, 2017, PHYS MED BIOL, V62, P5131, DOI 10.1088/1361-6560/aa6ca0
   Looe HK, 2015, PHYS MED BIOL, V60, P6585, DOI 10.1088/0031-9155/60/16/6585
   Looe HK, 2013, Z MED PHYS, V23, P129, DOI 10.1016/j.zemedi.2012.12.010
   Malkov VN, 2016, MED PHYS, V43, P4447, DOI 10.1118/1.4954318
   Meijsing I, 2009, PHYS MED BIOL, V54, P2993, DOI 10.1088/0031-9155/54/10/002
   Morales JE, 2014, MED PHYS, V41, DOI 10.1118/1.4895827
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Mutic S, 2014, SEMIN RADIAT ONCOL, V24, P196, DOI 10.1016/j.semradonc.2014.02.008
   O'Brien DJ, 2018, MED PHYS, V45, P884, DOI 10.1002/mp.12699
   Palacios MA, 2018, INT J RADIAT ONCOL, V102, P426, DOI 10.1016/j.ijrobp.2018.06.002
   Pappas E, 2006, MED PHYS, V33, P3700, DOI 10.1118/1.2349691
   Pojtinger S, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aac4f2
   Poppinga D, 2018, Z MED PHYS, V28, P224, DOI 10.1016/j.zemedi.2017.07.006
   Raaymakers BW, 2009, PHYS MED BIOL, V54, pN229, DOI 10.1088/0031-9155/54/12/N01
   Reynolds M, 2014, MED PHYS, V41, DOI 10.1118/1.4893276
   Reynolds M, 2013, MED PHYS, V40, DOI 10.1118/1.4794496
   Rister B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-00715-8
   Schönfeld AB, 2021, J APPL CLIN MED PHYS, V22, P64, DOI 10.1002/acm2.13447
   Schönfeld AB, 2019, MED PHYS, V46, P4257, DOI 10.1002/mp.13710
   Scott AJD, 2012, PHYS MED BIOL, V57, P4461, DOI 10.1088/0031-9155/57/14/4461
   Shorten C, 2019, J BIG DATA-GER, V6, DOI 10.1186/s40537-019-0197-0
   Simiele E, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aab56c
   SKARSGARD L, 1961, RADIAT RES, V14, P261, DOI 10.2307/3570921
   Spindeldreier CK, 2017, PHYS MED BIOL, V62, P6708, DOI 10.1088/1361-6560/aa7ae4
   Tekin T, 2020, MED PHYS, V47, P6509, DOI 10.1002/mp.14535
   Thariat J, 2013, NAT REV CLIN ONCOL, V10, P52, DOI 10.1038/nrclinonc.2012.203
   Timmerman RD, 2014, J CLIN ONCOL, V32, P2847, DOI 10.1200/JCO.2014.55.4675
   Underwood TSA, 2013, MED PHYS, V40, DOI 10.1118/1.4812687
   Weber C, 2020, MED PHYS, V47, P3165, DOI 10.1002/mp.14149
NR 52
TC 0
Z9 0
U1 0
U2 1
PD APR 21
PY 2022
VL 67
IS 8
AR 085006
DI 10.1088/1361-6560/ac5bfa
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Tsung, PK
   Tsai, SF
   Pai, A
   Lai, SJ
   Lu, C
AF Tsung, Pei-Kuei
   Tsai, Sung-Fang
   Pai, Alex
   Lai, Shu-Jen
   Lu, Chienping
GP IEEE
TI High Performance Deep Neural Network on Low Cost Mobile GPU
SO 2016 IEEE INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS (ICCE)
SE International Conference on Consumer Electronics
DT Proceedings Paper
CT IEEE International Conference on Consumer Electronics (ICCE)
CY JAN 07-11, 2016
CL Las Vegas, NV
AB In recent years, machine learning based on deep neural networks (DNN) is playing an increasingly important role. Artificial intelligence applications using DNN are achieving higher and higher accuracy levels. However, the multi-layer characteristic of a DNN makes for huge computational complexity consumption requirements. In order to feasibly run DNN applications on mobile devices, an efficient DNN flow optimized for a mobile GPU is desired. In this paper, a mobile-GPU-accelerated DNN flow is proposed. By the proposed input buffer address remapping scheme, shader assembly code optimization and kernel merging between computing nodes, 10.6 FPS is achieved in a 35.2 GFLOPS mobile GPU with 94.9mJ per frame, which is a 58x speed up and a 104x more energy efficient compared to a pure mobile CPU solution. Compared with state-of-the-art GPU accelerator devices and libraries, the proposed scheme provides a 226%similar to 1000% higher computing efficiency.
C1 [Tsung, Pei-Kuei; Tsai, Sung-Fang; Pai, Alex; Lai, Shu-Jen; Lu, Chienping] MediaTek, Hsinchu, Taiwan.
RP Tsung, PK (corresponding author), MediaTek, Hsinchu, Taiwan.
EM pei-kuei.tsung@mediatek.com; sung-fang.tsai@mediatek.com;
   alex.pai@mediatek.com; sz.lai@mediatek.com; chienping.lu@mediatek.com
CR [Anonymous], 2014, IEEE CVPR
   [Anonymous], 2013, ICASSP
   [Anonymous], 2009, PROC IEEE C COMPUT V
   [Anonymous], 2014, DEEP VISUAL SEMANTIC
   Brown L., 2015, GTC
   Krizhevsky A, 2012, NIPS, P1097
   Simonyan K., 2015, ICLR
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1, DOI 10.1109/CVPR.2015.7298594
NR 8
TC 0
Z9 0
U1 0
U2 2
PY 2016
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chirila, M
   D'Alberto, P
   Ting, HY
   Veidenbaum, A
   Nicolau, A
AF Chirila, Mihnea
   D'Alberto, Paolo
   Ting, Hsin-Yu
   Veidenbaum, Alexander
   Nicolau, Alexandru
GP IEEE
TI A Heterogeneous Solution to the All-pairs Shortest Path Problem using
   FPGAs
SO PROCEEDINGS OF THE TWENTY THIRD INTERNATIONAL SYMPOSIUM ON QUALITY
   ELECTRONIC DESIGN (ISQED 2022)
SE International Symposium on Quality Electronic Design
DT Proceedings Paper
CT 23rd International Symposium on Quality Electronic Design (ISQED)
CY APR 06-07, 2022
CL Santa Jose, CA
DE FPGA; heterogeneous computing; graph algorithms
AB Heterogeneous systems present exciting new opportunities for graph and Machine Learning applications. This paper presents a novel approach for the All-pairs Shortest Path (APSP) computation using a heterogeneous CPU-FPGA Accelerator system. It is based on a recursive variant of Kleene's APSP algorithm. Carefully re-engineering the algorithm to exploit parallelism in both the Floyd-Warshall algorithm and the general Kleene algorithm to perform Floyd-Warshall and Matrix-Multiply on the FPGA while the CPU efficiently balances the communication and computation between the kernels, improves state-of-the-art performance on FPGAs for APSP, while achieving near-GPU levels of performance, with less power and hardware resources, and outperforms the CPU-only solution by over 137x for a 8192x8192 problem size. When adjusted for power draw differences in process nodes, it also surpasses the GPU implementation in terms of performance per Watt by over 13%.
C1 [Chirila, Mihnea; D'Alberto, Paolo; Ting, Hsin-Yu; Veidenbaum, Alexander; Nicolau, Alexandru] Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
RP Chirila, M (corresponding author), Univ Calif Irvine, Dept Comp Sci, Irvine, CA 92697 USA.
EM mchirila@uci.edu; paolod@Xilinx.com; hting1@uci.edu; alexv@ics.uci.edu;
   nicolau@ics.uci.edu
CR [Anonymous], 2009, INTRO ALGORITHMS
   Besta M., 2019, GRAPH PROCESSING FPG
   Betkaoui B., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P99, DOI 10.1109/FPL.2012.6339247
   Betkaoui B, 2012, IEEE INT CONF ASAP, P8, DOI 10.1109/ASAP.2012.30
   Bondhugula U., 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Bondhugula U, 2006, ANN IEEE SYM FIELD P, P152
   Buluc A, 2010, PARALLEL COMPUT, V36, P241, DOI 10.1016/j.parco.2009.12.002
   D'Alberto P, 2007, ALGORITHMICA, V47, P203, DOI 10.1007/s00453-006-1224-z
   FLOYD RW, 1962, COMMUN ACM, V5, P345, DOI 10.1145/367766.368168
   Huiling Shang, 2012, 2012 IEEE Symposium on VLSI Technology, P129, DOI 10.1109/VLSIT.2012.6242495
   Litvinov G. L, 2012, IDEMPOTENT TROPICAL
   Rezaei S., 2016, 2016 INT C RECONFIGU, P1
   Sao P, 2020, PROCEEDINGS OF THE 25TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING (PPOPP '20), P250, DOI 10.1145/3332466.3374533
   Tommiska M., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P653
   TSMC, 16 12NM TECHN
   ULLMAN JD, 1990, SIGMOD REC, V19, P44, DOI 10.1145/93605.93620
   WARSHALL S, 1962, J ACM, V9, P11, DOI 10.1145/321105.321107
   Wu SY, 2013, 2013 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Xilinx.Inc, XIL GEMX LIB
   Zhou SJ, 2017, INT SYM COMP ARCHIT, P137, DOI 10.1109/SBAC-PAD.2017.25
   Zhou SJ, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P129, DOI 10.1109/IPDPSW.2015.130
   Zhou SJ, 2016, ANN IEEE SYM FIELD P, P103, DOI 10.1109/FCCM.2016.35
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 108
EP 113
DI 10.1109/ISQED54688.2022.9806279
WC Engineering, Biomedical; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Deng, L
   Li, GQ
   Han, S
   Shi, LP
   Xie, Y
AF Deng, Lei
   Li, Guoqi
   Han, Song
   Shi, Luping
   Xie, Yuan
TI Model Compression and Hardware Acceleration for Neural Networks: A
   Comprehensive Survey
SO PROCEEDINGS OF THE IEEE
DT Article
DE Neural networks; Tensor decomposition; Data quantization; Acceleration;
   Program processors; Machine learning; Task analysis; Compact neural
   network; data quantization; neural network acceleration; neural network
   compression; sparse neural network; tensor decomposition
ID SINGULAR-VALUE DECOMPOSITION; TENSOR DECOMPOSITIONS; MEMORY; TRAIN;
   COMPUTATION; ENERGY; ARCHITECTURES; PREDICTION; ACCURACY; CNN
AB Domain-specific hardware is becoming a promising topic in the backdrop of improvement slow down for general-purpose processors due to the foreseeable end of Moore's Law. Machine learning, especially deep neural networks (DNNs), has become the most dazzling domain witnessing successful applications in a wide spectrum of artificial intelligence (AI) tasks. The incomparable accuracy of DNNs is achieved by paying the cost of hungry memory consumption and high computational complexity, which greatly impedes their deployment in embedded systems. Therefore, the DNN compression concept was naturally proposed and widely used for memory saving and compute acceleration. In the past few years, a tremendous number of compression techniques have sprung up to pursue a satisfactory tradeoff between processing efficiency and application accuracy. Recently, this wave has spread to the design of neural network accelerators for gaining extremely high performance. However, the amount of related works is incredibly huge and the reported approaches are quite divergent. This research chaos motivates us to provide a comprehensive survey on the recent advances toward the goal of efficient compression and execution of DNNs without significantly compromising accuracy, involving both the high-level algorithms and their applications in hardware design. In this article, we review the mainstream compression approaches such as compact model, tensor decomposition, data quantization, and network sparsification. We explain their compression principles, evaluation metrics, sensitivity analysis, and joint-way use. Then, we answer the question of how to leverage these methods in the design of neural network accelerators and present the state-of-the-art hardware architectures. In the end, we discuss several existing issues such as fair comparison, testing workloads, automatic compression, influence on security, and framework/hardware-level support, and give promising topics in this field and the possible challenges as well. This article attempts to enable readers to quickly build up a big picture of neural network compression and acceleration, clearly evaluate various methods, and confidently get started in the right way.
C1 [Deng, Lei; Li, Guoqi; Shi, Luping] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
   [Deng, Lei; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Li, Guoqi; Shi, Luping] Tsinghua Univ, Beijing Innovat Ctr Future Chip, Beijing 100084, Peoples R China.
   [Han, Song] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
RP Li, GQ (corresponding author), Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
EM leideng@ucsb.edu; liguoqi@mail.tsinghua.edu.cn; songhan@mit.edu;
   lpshi@mail.tsinghua.edu.cn; yuanxie@ucsb.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Aizenberg I, 2012, SOFT COMPUT, V16, P563, DOI 10.1007/s00500-011-0755-7
   Al Bahou A, 2018, PROC IEEE COOL CHIPS
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2018, ADV NEURAL INFORM PR
   [Anonymous], ARXIV190305662
   [Anonymous], 2018, ARXIV181007378
   [Anonymous], 1990, WAVELETS, DOI [10.1007/978-3-642-75988-8_28, DOI 10.1007/978-3-642-75988-8_28]
   [Anonymous], 2016, ADV NEURAL INFORM PR
   [Anonymous], 2017, P IEEE C COMPUTER VI
   [Anonymous], ARXIV161101427
   [Anonymous], ARXIV180902220
   [Anonymous], 2011, COMPUT METH APPL MAT, DOI DOI 10.2478/CMAM-2011-0016
   [Anonymous], 2018, P ICLR
   [Anonymous], P IEEE C COMP VIS PA
   [Anonymous], 2017, P ICLR
   [Anonymous], 2018, ARXIV181000859
   [Anonymous], 2018, ADV NEURAL INFORM PR
   [Anonymous], 2018, ARXIV180900095
   [Anonymous], 2018, P INT C LEARNING REP
   [Anonymous], ARXIV180510352
   [Anonymous], P AAAI FEB
   [Anonymous], 2018, ADV IN NEURAL INFORM
   [Anonymous], 2020, P ICLR
   [Anonymous], 2017, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, P ICLR
   [Anonymous], 2017, ARXIV170805552
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], IEEE T COMPUT AIDED
   [Anonymous], 2018, ARXIV180511797
   [Anonymous], 2016, INT C LEARNING REPRE
   [Anonymous], 2018, CORR
   [Anonymous], 2018, ARXIV181100482
   [Anonymous], 2016, P ICLR
   [Anonymous], 2017, FPL
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2018, P ICLR
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2014, P INT C LEARN REPR
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2017, PROC INT C LEARN REP
   [Anonymous], 2016, BRIT MACHINE VISION
   [Anonymous], 2018, P ICLR
   [Anonymous], 2013, NIPS
   [Anonymous], 2018, ARXIV180600512
   [Anonymous], 2018, P INT C LEARN REPR
   [Anonymous], MATRIX
   [Anonymous], P SIAM INT C DAT MIN
   [Anonymous], 2015, NEURAL NETWORKS FEW
   [Anonymous], 2014, ARXIV NEURAL EVOLUTI
   [Anonymous], 2017, ARXIV170405119
   [Anonymous], 2018, UNQ UNIFORM NOISE IN
   [Anonymous], 2018, P INT C LEARN REPR I
   [Anonymous], 2014, LEARNING PHRASE REPR, DOI [10, DOI 10.3115/V1/D14-1179]
   [Anonymous], 2016, COMPUTER SCI
   [Anonymous], 2018, ARXIV180506523
   [Anonymous], ARXIV180602639
   [Anonymous], 2016, P IEEE INT S CIRC SY, DOI DOI 10.48550/ARXIV.1605.07678
   [Anonymous], P ACM IEEE 45 ANN IN
   [Anonymous], 2016, GOOGLES NEURAL MACHI
   [Anonymous], 2019, ARXIV190907514
   [Anonymous], IEEE J SOLID STATE C
   [Anonymous], ARXIV170805344
   [Anonymous], 2017, TENSOR REGRESSION NE
   [Anonymous], ARXIV181200332
   [Anonymous], 2018, 6 INT C LEARNING REP
   [Anonymous], P IEEE CVF C COMP VI
   [Anonymous], ARXIV150701526
   [Anonymous], P ICLR
   [Anonymous], 2018, P INT C COMPUTER AID
   [Anonymous], ARXIV180101928
   [Anonymous], 2017, NIPS
   [Anonymous], P ACM IEEE 45 ANN IN
   [Anonymous], ARXIV170206763
   [Anonymous], 2018, ARXIV180200150
   [Anonymous], 2018, 2018 17 INT S INFOTE, DOI DOI 10.1109/INFOTEH.2018.8345545
   [Anonymous], 2015, P ICLR
   [Anonymous], ARXIV190301061
   [Anonymous], 2018, INT C LEARN REPR
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], ARXIV171100436
   [Anonymous], 2018, ADAM ADMM UNIFIED SY
   [Anonymous], P EMNLP OCT
   [Anonymous], 2016, P ICLR
   [Anonymous], ARXIV190111117
   [Anonymous], 2018, PROC IEEE UNDERGRADU
   [Anonymous], 2017, LONG TERM FORECASTIN
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2015, ADV NEUR IN
   [Anonymous], 2016, P ICLR
   [Anonymous], 2017, ARXIV170310722
   [Anonymous], 2018, ARXIV180609228
   [Anonymous], 2016, ARXIV160301025
   [Anonymous], 2018, ARXIV180806866
   [Anonymous], P ADV NEUR INF PROC
   [Anonymous], 2018, 35 INT C MACH LEARN
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   Astrid M, 2017, INT CONF BIG DATA, P115, DOI 10.1109/BIGCOMP.2017.7881725
   Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Banner R., 2018, P ADV NEURAL INFORM, P5145
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Cai Y, 2018, DES AUT CON, DOI 10.1145/3195970.3196071
   Cai ZW, 2017, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR.2017.574
   Chen Y.-H., 2018, ARXIV180707928
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen YP, 2018, PROCEEDINGS OF THE TWENTY-SEVENTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P635
   Cheng J, 2018, IEEE T NEUR NET LEAR, V29, P4730, DOI 10.1109/TNNLS.2017.2774288
   Cheng M, 2019, IEEE T COMPUT AID D, V38, P834, DOI 10.1109/TCAD.2018.2824304
   Cheng Y, 2018, IEEE SIGNAL PROC MAG, V35, P126, DOI 10.1109/MSP.2017.2765695
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chien JT, 2018, IEEE T NEUR NET LEAR, V29, P1998, DOI 10.1109/TNNLS.2017.2690379
   Chin T.-W., 2018, ARXIV181000518
   Choi Y., 2018, ARXIV180508303
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Cichocki A, 2018, STUD COMPUT INTELL, V738, P3, DOI 10.1007/978-3-319-67946-4_1
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Cohen N, 2016, PR MACH LEARN RES, V48
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dai JF, 2017, IEEE I CONF COMP VIS, P764, DOI 10.1109/ICCV.2017.89
   Dai XL, 2019, IEEE T COMPUT, V68, P1487, DOI 10.1109/TC.2019.2914438
   Dally, 2016, ARXIV161201064
   Tran DT, 2018, NEURAL NETWORKS, V105, P328, DOI 10.1016/j.neunet.2018.05.017
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1253, DOI 10.1137/S0895479896305696
   Deb T, 2018, MATER TODAY-PROC, V5, P2222
   Deng CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P264, DOI 10.1145/3307650.3322258
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Deng L, 2018, NEURAL NETWORKS, V100, P49, DOI 10.1016/j.neunet.2018.01.010
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Elsken T., 2018, ARXIV180409081
   Espig M, 2012, COMPUT VIS SCI, V15, P331, DOI 10.1007/s00791-014-0218-7
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Farabet Clement, 2011, COMP VIS PATT REC WO
   Garipov Timur, 2016, ABS161103214 CORR
   Ge LH, 2017, PROC CVPR IEEE, P5679, DOI 10.1109/CVPR.2017.602
   Gers FA, 2000, NEURAL COMPUT, V12, P2451, DOI 10.1162/089976600300015015
   Gittens A, 2016, J MACH LEARN RES, V17
   Grasedyck L, 2010, SIAM J MATRIX ANAL A, V31, P2029, DOI 10.1137/090764189
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guo X., 2017, IEDM, P6
   Guo Y., 2018, ARXIV PREPRINT ARXIV
   Hammerstrom D., 1990, IJCNN International Joint Conference on Neural Networks (Cat. No.90CH2879-5), P537, DOI 10.1109/IJCNN.1990.137621
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hassibi B., 1992, P ADV NEUR INF PROC, V5, DOI DOI 10.5555/645753.668069
   He Q., 2016, EFFECTIVE QUANTIZATI
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   He ZZ, 2017, ARCH BIOCHEM BIOPHYS, V623, P1, DOI 10.1016/j.abb.2017.01.013
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hieu TH, 2009, ICCIT: 2009 FOURTH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCES AND CONVERGENCE INFORMATION TECHNOLOGY, VOLS 1 AND 2, P1300, DOI 10.1109/ICCIT.2009.170
   Hou M, 2015, IEEE IMAGE PROC, P1344, DOI 10.1109/ICIP.2015.7351019
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2018, PROC CVPR IEEE, P2752, DOI 10.1109/CVPR.2018.00291
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Hubara I, 2018, J MACH LEARN RES, V18
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jafari A, 2018, PR GR LAK SYMP VLSI, P443, DOI 10.1145/3194554.3194634
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Jain S., 2018, ARXIV180900072
   Janzamin M., 2015, ARXIV150608473
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Jia Xianyan, 2018, ARXIV180711205
   Jian Xue, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P6359, DOI 10.1109/ICASSP.2014.6854828
   Jiang P, 2018, ADV CIV ENG, V2018, DOI 10.1155/2018/4748526
   Jiang Su, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P29, DOI 10.1007/978-3-319-78890-6_3
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jozefowicz R, 2015, PR MACH LEARN RES, V37, P2342
   Judd P, 2016, INT SYMP MICROARCH
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim C, 2018, IEEE J EM SEL TOP C, V8, P770, DOI 10.1109/JETCAS.2018.2865006
   Kim E, 2018, PROC CVPR IEEE, P8669, DOI 10.1109/CVPR.2018.00904
   KLEMA VC, 1980, IEEE T AUTOMAT CONTR, V25, P164, DOI 10.1109/TAC.1980.1102314
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Krishnamoorthi R., 2018, ARXIV180608342, V8, P667
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumamoto T, 2017, J PHYS SOC JPN, V86, DOI 10.7566/JPSJ.86.024005
   Kumar NK, 2017, LINEAR MULTILINEAR A, V65, P2212, DOI 10.1080/03081087.2016.1267104
   Kung HT, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P821, DOI 10.1145/3297858.3304028
   Kurakin A., 2017, 5 INT C LEARN REPR, P1
   Lasenby, 2018, ARXIV180404849
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Lee J, 2017, IEEE ASIAN SOLID STA, P237, DOI 10.1109/ASSCC.2017.8240260
   Lee N, 2018, MULTIDIM SYST SIGN P, V29, P921, DOI 10.1007/s11045-017-0481-0
   Lee N, 2016, SIAM J MATRIX ANAL A, V37, P598, DOI 10.1137/15M1028479
   Li CH, 2007, 2007 CIT: 7TH IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND INFORMATION TECHNOLOGY, PROCEEDINGS, P47, DOI 10.1109/CIT.2007.52
   Li GQ, 2018, NEUROCOMPUTING, V272, P154, DOI 10.1016/j.neucom.2017.06.058
   Li H, 2017, ADV NEUR IN, V30
   Li L, 2013, INT CONF ACOUST SPEE, P3707, DOI 10.1109/ICASSP.2013.6638350
   Li S, 2018, PROC CVPR IEEE, P5457, DOI 10.1109/CVPR.2018.00572
   Li SC, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P696, DOI [10.1109/MICRO.2018.00062, 10.1109/MICR0.2018.00062]
   Liang L, 2018, IEEE ACCESS, V6, P58324, DOI 10.1109/ACCESS.2018.2874823
   Lin C, 2018, P ADV NEUR INF PROC, P10169
   Lin JL, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P639, DOI 10.1145/3287624.3287715
   Lin M, 2014, PUBLIC HEALTH NUTR, V17, P2029, DOI [10.1017/S1368980013002176, 10.1109/PLASMA.2013.6634954]
   Lin YC, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P3756
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu Hanxiao, 2018, INT C LEARNING REPRE
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Liu YG, 2016, IEEE T NEUR NET LEAR, V27, P273, DOI 10.1109/TNNLS.2015.2496964
   Liu Z., 2018, ARXIV181005270
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Luo WJ, 2016, ADV NEUR IN, V29
   Makhzani A., 2015, ADV NEURAL INFORM PR, P2791
   Marzi Z, 2018, IEEE INT SYMP INFO, P31, DOI 10.1109/ISIT.2018.8437638
   Masana Marc, 2017, P IEEE INT C COMPUTE
   McKinstry Jeffrey L, 2018, ARXIV PREPRINT ARXIV
   Micikevicius P., 2017, ARXIV171003740
   Mishra Asit, 2017, WRPN WIDE REDUCED PR
   Molchanov P., 2016, 5 INT C LEARNING REP
   Morcos A. S., 2018, P INT C LEARN REPR
   Neil Daniel, 2016, P 30 INT C NEUR INF, P3882, DOI DOI 10.48550/ARXIV.1610.09513
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Oseledets IV, 2010, SIAM J MATRIX ANAL A, V31, P2130, DOI 10.1137/090757861
   Ott J., 2016, CORR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Perros I, 2015, IEEE DATA MINING, P943, DOI 10.1109/ICDM.2015.29
   Ramachandran P., 2017, ARXIV
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Rauhut H, 2015, APPL NUMER HARMON AN, P419, DOI 10.1007/978-3-319-16042-9_14
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Ren A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P925, DOI 10.1145/3297858.3304076
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Rovid A., 2011, Proceedings of the 2011 15th IEEE International Conference on Intelligent Engineering Systems (INES), P69, DOI 10.1109/INES.2011.5954721
   Sainath TN, 2013, INT CONF ACOUST SPEE, P6655, DOI 10.1109/ICASSP.2013.6638949
   Sak H, 2014, INTERSPEECH, P338
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schütt KT, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms13890
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Shim K, 2017, ADV NEUR IN, V30
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Song MC, 2018, CONF PROC INT SYMP C, P752, DOI 10.1109/ISCA.2018.00068
   Spring R, 2017, KDD'17: PROCEEDINGS OF THE 23RD ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P445, DOI 10.1145/3097983.3098035
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Srivastava R. K., 2015, ARXIV150500387, P1
   Sun X, 2017, PR MACH LEARN RES, V70
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tang TQ, 2017, ASIA S PACIF DES AUT, P782, DOI 10.1109/ASPDAC.2017.7858419
   Tang W, 2017, AAAI CONF ARTIF INTE, P2625
   Tjandra A, 2018, IEEE IJCNN
   Tjandra A, 2017, IEEE IJCNN, P4451, DOI 10.1109/IJCNN.2017.7966420
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang Naigang, 2018, ARXIV181208011, P7686
   Wang PQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196116
   Weinberger K.Q., 2013, ADV NEURAL INFORM PR, P3084
   Wen W., 2017, ARXIV170905027
   Wen W, 2016, ADV NEUR IN, V29
   Wen W, 2017, ADV NEUR IN, V30
   Wen W, 2017, IEEE I CONF COMP VIS, P658, DOI 10.1109/ICCV.2017.78
   WEST J, 1995, DISCRETE MATH, V146, P247, DOI 10.1016/0012-365X(94)00067-1
   Wu BC, 2018, PROC CVPR IEEE, P9127, DOI 10.1109/CVPR.2018.00951
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Wu ZZ, 2016, INT CONF ACOUST SPEE, P5140, DOI 10.1109/ICASSP.2016.7472657
   Xiao LC, 2018, PR MACH LEARN RES, V80
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xue SF, 2015, INT CONF ACOUST SPEE, P4555, DOI 10.1109/ICASSP.2015.7178833
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yang YC, 2017, PR MACH LEARN RES, V70
   Ye JM, 2018, PROC CVPR IEEE, P9378, DOI 10.1109/CVPR.2018.00977
   Yin PH, 2018, SIAM J IMAGING SCI, V11, P2205, DOI 10.1137/18M1166134
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Yu RC, 2018, PROC CVPR IEEE, P9194, DOI 10.1109/CVPR.2018.00958
   Zhang, 2016, ARXIV
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang SZ, 2016, ADV NEUR IN, V29
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang TY, 2018, LECT NOTES COMPUT SC, V11212, P191, DOI 10.1007/978-3-030-01237-3_12
   Zhang T, 2017, IEEE I CONF COMP VIS, P4383, DOI 10.1109/ICCV.2017.469
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang XY, 2016, IEEE T PATTERN ANAL, V38, P1943, DOI 10.1109/TPAMI.2015.2502579
   Zhang XY, 2015, PROC CVPR IEEE, P1984, DOI 10.1109/CVPR.2015.7298809
   Zhao HJ, 2017, IEEE T INTELL TRANSP, V18, P192, DOI 10.1109/TITS.2016.2571726
   Zhao Q., 2016, ARXIV
   Zhao QB, 2019, INT CONF ACOUST SPEE, P8608, DOI 10.1109/ICASSP.2019.8682231
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
   Zhou GB, 2016, INT J AUTOM COMPUT, V13, P226, DOI 10.1007/s11633-016-1006-2
   Zhou MY, 2019, SIGNAL PROCESS-IMAGE, V73, P12, DOI 10.1016/j.image.2018.03.017
   Zhou S., 2016, DOREFANET TRAINING L
   Zhou SC, 2017, J COMPUT SCI TECH-CH, V32, P667, DOI 10.1007/s11390-017-1750-y
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhu Michael, 2017, ARXIV171001878
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zou ZX, 2016, IEEE T GEOSCI REMOTE, V54, P5832, DOI 10.1109/TGRS.2016.2572736
NR 307
TC 316
Z9 332
U1 50
U2 202
PD APR
PY 2020
VL 108
IS 4
BP 485
EP 532
DI 10.1109/JPROC.2020.2976475
WC Engineering, Electrical & Electronic
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Dann, J
   Ritter, D
   Fröning, H
AF Dann, Jonas
   Ritter, Daniel
   Froening, Holger
GP IEEE
TI GraphScale: Scalable Bandwidth-Efficient Graph Processing on FPGAs
SO 2022 32ND INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS, FPL
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 32nd International Conference on Field-Programmable Logic and
   Applications (FPL)
CY AUG 29-SEP 02, 2022
CL Belfast, NORTH IRELAND
AB Recent advances in graph processing on FPGAs promise to alleviate performance bottlenecks with irregular memory access patterns. Such bottlenecks challenge performance for a growing number of important application areas like machine learning and data analytics. While FPGAs denote a promising solution through flexible memory hierarchies and massive parallelism, we argue that current graph processing accelerators either use the off-chip memory bandwidth inefficiently or do not scale well across memory channels.
   In this work, we propose GraphScale, a scalable graph processing framework for FPGAs. For the first time, GraphScale combines multi-channel memory with asynchronous graph processing (i.e., for fast convergence on results) and a compressed graph representation (i.e., for efficient usage of memory bandwidth and reduced memory footprint). GraphScale solves common graph problems like breadth-first search, PageRank, and weakly-connected components through modular user-defined functions, a novel two-dimensional partitioning scheme, and a high-performance two-level crossbar design.
C1 [Dann, Jonas; Ritter, Daniel] SAP SE, Walldorf, Germany.
   [Dann, Jonas; Froening, Holger] Heidelberg Univ, Heidelberg, Germany.
RP Dann, J (corresponding author), SAP SE, Walldorf, Germany.; Dann, J (corresponding author), Heidelberg Univ, Heidelberg, Germany.
EM jonas.dann@sap.com; daniel.ritter@sap.com;
   holger.froening@ziti.uni-heidelberg.de
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   Attia OG, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P228, DOI 10.1109/IPDPSW.2014.30
   Balaji V, 2018, I S WORKL CHAR PROC, P203, DOI 10.1109/IISWC.2018.8573478
   Besta Maciej, 2019, DEMYSTIFYING GRAPH D
   Betkaoui B, 2012, IEEE INT CONF ASAP, P8, DOI 10.1109/ASAP.2012.30
   Chen X., 2022, TRETS
   Chenhao Liu, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, DOI 10.1145/3431920.3439463
   Dai GH, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P217, DOI 10.1145/3020078.3021739
   Dann J., 2020, NONRELATIONAL DATABA
   Dann J., 2021, BTW, P101
   Dann J., 2021, GRADES NDA
   Lei G., 2015, IRACST ESTIJ, V5
   Leskovec J., 2014, SNAP DATASETS STANFO
   Lumsdaine A, 2007, PARALLEL PROCESS LET, V17, P5, DOI 10.1142/S0129626407002843
   Rossi R. A., AAAI
   Shao Z., 2019, FPGA
   Shijie Zhou, 2015, 2015 International Conference on Reconfigurable Computing and FPGAs (ReConFig), P1, DOI 10.1109/ReConFig.2015.7393332
   Xinyu Chen, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P69, DOI 10.1145/3431920.3439290
   Yao PC, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243201
   Zhang JL, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P229, DOI 10.1145/3174243.3174245
   Zhou SJ, 2019, IEEE T PARALL DISTR, V30, P2249, DOI 10.1109/TPDS.2019.2910068
   Zhu Xiaowei, 2015, USENIX ANN TECHN C, P375
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 24
EP 32
DI 10.1109/FPL57034.2022.00016
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Prasad, R
   Das, S
   Martin, KJM
   Tagliavini, G
   Coussy, P
   Benini, L
   Rossi, D
AF Prasad, Rohit
   Das, Satyajit
   Martin, Kevin J. M.
   Tagliavini, Giuseppe
   Coussy, Philippe
   Benini, Luca
   Rossi, Davide
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI TRANSPIRE: An energy-efficient TRANSprecision floating-point
   Programmable archItectuRE
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB In recent years, Coarse Grain Reconfigurable Architecture (CGRA) accelerators have been increasingly deployed in Internet-of-Things (IoT) end nodes. A modern CGRA has to support and efficiently accelerate both integer and floating-point (FP) operations. In this paper, we propose an ultra-low-power tunable-precision CGRA architectural template, called TRANSprecision floating-point Programmable archItectuRE (TRANSPIRE), and its associated compilation flow supporting both integer and FP operations. TRANSPIRE employs transprecision computing and multiple Single Instruction Multiple Data (SIMD) to accelerate FP operations while boosting energy efficiency as well. Experimental results show that TRANSPIRE achieves a maximum of 10.06x performance gain and consumes 12.91x less energy w.r.t. a RISC-V based CPU with an enhanced ISA supporting SIMD-style vectorization and FP data-types, while executing applications for near-sensor computing and embedded machine learning, with an area overhead of 1.25x only.
C1 [Prasad, Rohit; Martin, Kevin J. M.; Coussy, Philippe] Univ Bretagne Sud, UMR 6285, Lab STICC, F-56100 Lorient, France.
   [Prasad, Rohit; Tagliavini, Giuseppe; Benini, Luca; Rossi, Davide] Univ Bologna, Elect Elect & Informat Engn, Bologna, Italy.
   [Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab, Zurich, Switzerland.
   [Das, Satyajit] IIT Palakkad, Dept Comp Sci & Engn, Pudussery East, Kerala, India.
RP Prasad, R (corresponding author), Univ Bretagne Sud, UMR 6285, Lab STICC, F-56100 Lorient, France.
EM Rohit.Prasad@univ-ubs.fr; satyajitdas@iitkpd.ac.in;
   Giuseppe.Tagliavini@unibo.it; Luca.Benini@iis.ee.ethz.ch
CR Akbari O., 2018, DATE 2018
   [Anonymous], 2019, STM32H7 SER
   [Anonymous], 2018, STM32 ULTRALOW POWER
   Brunelli C., 2010, J SYST ARCHIT, V56
   Carroll A., 2007, DESIGNING COARSE GRA
   Das S., 2019, TCAD, V38
   Das S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351749
   Das S, 2016, IEEE COMP SOC ANN, P655, DOI 10.1109/ISVLSI.2016.54
   De Sutter B., 2010, HDB SIGNAL PROCESSIN
   Duch L, 2017, IEEE T CIRCUITS-I, V64, P2448, DOI 10.1109/TCSI.2017.2701499
   FAN X, 2018, IEEE T VLSI SYST, V29, DOI DOI 10.1007/S41365-018-0389-X
   Frantz G., 2004, SPRY061 TEX INSTR
   Gautschi M., 2017, IEEE T VLSI SYST, V25
   He WJ, 2017, DES AUT CON, DOI 10.1145/3061639.3062291
   Jo M., 2013, INTEGRATION VLSI J, V47
   Levi G., 1973, CALCOLO, V9, P341, DOI DOI 10.1007/BF02575586
   Mach S., 2019, VLSI SOC
   Mach S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351816
   Montagna Fabio, 2017, Journal of Low Power Electronics and Applications, V7, DOI 10.3390/jlpea7020016
   Nicol C., 2017, WAVE COMPUTING
   Nicol C., 2016, WAVE COMPUTING
   Rossi D, 2014, IEEE CONV EL ELECT I
   Sukjin Kim, 2015, 2015 IEEE Hot Chips 27 Symposium (HCS), DOI 10.1109/HOTCHIPS.2015.7477475
   Tagliavini G., 2018, DATE 2018
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
NR 25
TC 12
Z9 12
U1 0
U2 2
PY 2020
BP 1067
EP 1072
DI 10.23919/date48585.2020.9116408
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Gessinger-Befurt, P
   Salzburger, A
   Niermann, J
AF Gessinger-Befurt, Paul
   Salzburger, Andreas
   Niermann, Joana
GP IOP
TI The Open Data Detector Tracking System
SO 20TH INTERNATIONAL WORKSHOP ON ADVANCED COMPUTING AND ANALYSIS
   TECHNIQUES IN PHYSICS RESEARCH
SE Journal of Physics Conference Series
DT Proceedings Paper
CT 20th International Workshop on Advanced Computing and Analysis
   Techniques in Physics Research (ACAT)
CY NOV 29-DEC 03, 2021
CL ELECTR NETWORK
AB Charged particle reconstruction in High Energy Physics experiments is a significant part of overall event reconstruction. Depending on the physics environment, for instance in collider experiments with high multiplicities or luminosities, the tracking problem increases in complexity and often poses not only an algorithmic, but also a computational challenge. With the high-luminosity phase of the LHC at CERN approaching, research for new approaches and algorithms for track reconstruction has seen an increased interest. Both new technological approaches like hardware accelerators, as well as machine learning are being developed. However, testing and developing these new approaches against the existing experiments' software stacks can prove to be challenging, as they typically focus on stable data taking, discouraging disruptive changes. This document presents a virtual tracking detector that is designed to be a simplified, but realistic model of a real-world detector, that can serve as a robust testbed for new developments.
C1 [Gessinger-Befurt, Paul; Salzburger, Andreas; Niermann, Joana] CERN, CH-1211 Geneva, Switzerland.
   [Niermann, Joana] Georg August Univ Gottingen, Phys Inst 2, D-37073 Gottingen, Germany.
RP Gessinger-Befurt, P (corresponding author), CERN, CH-1211 Geneva, Switzerland.
EM paul.gessinger@cern.ch; andreas.salzburger@cern.ch;
   joana.niermann@phys.uni-goettingen.de
CR Agostinelli S, 2003, NUCL INSTRUM METH A, V506, P250, DOI 10.1016/S0168-9002(03)01368-8
   Ai X., 2021, PREPRINT
   Allaire Corentin, 2022, Zenodo, DOI 10.5281/ZENODO.6445359
   Amrouche S, 2021, PREPRINT
   Amrouche S, 2020, SPRING SER CHALLENGE, P231, DOI 10.1007/978-3-030-29135-8_9
   [Anonymous], 2017, HIGH LUMINOSITY LARG
   [Anonymous], 2017, CERNLHCC2017005
   ATLAS Collaboration, 2008, J INSTRUM, V3, DOI DOI 10.1088/1748-0221/3/08/S08003
   Kiehn M, 2019, EPJ WEB CONF, V214, DOI 10.1051/epjconf/201921406037
   Petri c M, 2017, J PHYS C SERIES, V898
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2023
VL 2438
AR 012110
DI 10.1088/1742-6596/2438/1/012110
WC Computer Science, Interdisciplinary Applications; Physics, Applied;
   Physics, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Siauciulis, M
   Northcote, D
   Goldsmith, J
   Crockett, LH
   Kalade, S
AF Siauciulis, Marius
   Northcote, David
   Goldsmith, Josh
   Crockett, Louise H.
   Kalade, Sarunas
GP IEEE
TI 100GBit/s RF sample offload for RFSoC using GNU Radio and PYNQ
SO 2023 21ST IEEE INTERREGIONAL NEWCAS CONFERENCE, NEWCAS
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 21st IEEE Interregional NEWCAS Conference (NEWCAS)
CY JUN 26-28, 2023
CL Edinburgh, SCOTLAND
DE high speed offload; GNU Radio; PYNQ; Software Defined Radio; Zynq
   UltraScale plus RFSoC; hardware software co-design
AB Modern software defined radio systems are capable of multi-gigabit-per-second sampling rates producing unprecedented amounts of digitized RF data. In applications such as wideband spectrum sensing and machine learning algorithms for cognitive radio, prototyping, and instrumentation, it is often impractical to process the acquired data locally in real-time. This motivates the need for a high speed connection to offload data to an accelerator application running on a secondary processing resource. In this paper, we present a novel hardware and software co-design using the AMD RFSoC 4x2 platform, PYNQ and GNU Radio projects. The demonstrated system is capable of continuous 80GBit/s offload in a 100GBit/s channel, utilising a GPU acceleration to rapidly process the Fast Fourier Transforms of a full 2GHz bandwidth RF signal at 60 frames per second.
C1 [Siauciulis, Marius; Northcote, David; Goldsmith, Josh; Crockett, Louise H.] Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Scotland.
   [Kalade, Sarunas] Adv Micro Devices Inc, Santa Clara, CA USA.
RP Siauciulis, M (corresponding author), Univ Strathclyde, Dept Elect & Elect Engn, Glasgow, Scotland.
EM marius.siauciulis@strath.ac.uk
CR AMD Inc, ULTRASCALE DEVICES I
   AMD Inc, VIT MOD COMP
   AMD Inc, VIV ML OV
   AMD Inc, XUP VITIS NETWORK EX
   AMD Inc, 2019, UND KEY PAR RF SAMPL
   AMD Inc, 2019, AD DIR RF SAMPL SOL
   [Anonymous], RFSOC 4X2 OV
   [Anonymous], PYNQ PYTHON PRODUCTI
   casper- toolflow.readthedocs, TUTORIAL 4 100GBE CA
   Chao Liu, 2021, Monthly Notices of the Royal Astronomical Society, V501, P5096, DOI 10.1093/mnras/staa3895
   MathWorks Inc, SIMULINK SIMULATION
   osmocom, GR FOSPHOR GNU RADIO
   Roland R., NLOAD REAL TIME NETW
   Smith Jenny, 100GBE PYNQ
   Stefanazzi L, 2022, REV SCI INSTRUM, V93, DOI 10.1063/5.0076249
   StrathSDR, U STRATHCLYDE SOFTWA
   xmlrpc, WHAT IS XML RPC
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/NEWCAS57931.2023.10198070
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Abdelfattah, A
   Costa, T
   Dongarra, J
   Gates, M
   Haidar, A
   Hammarling, S
   Higham, NJ
   Kurzak, J
   Luszczek, P
   Tomov, S
   Zounon, M
AF Abdelfattah, Ahmad
   Costa, Timothy
   Dongarra, Jack
   Gates, Mark
   Haidar, Azzam
   Hammarling, Sven
   Higham, Nicholas J.
   Kurzak, Jakub
   Luszczek, Piotr
   Tomov, Stanimire
   Zounon, Mawussi
TI A Set of Batched Basic Linear Algebra Subprograms and LAPACK Routines
SO ACM TRANSACTIONS ON MATHEMATICAL SOFTWARE
DT Article
DE BLAS; batched BLAS
ID EXTENDED SET; PERFORMANCE; FERMI; MODEL
AB This article describes a standard API for a set of Batched Basic Linear Algebra Subprograms (Batched BLAS or BBLAS). The focus is on many independent BLAS operations on small matrices that are grouped together and processed by a single routine. called a Batched BLAS routine. The matrices are grouped together in uniformly sized groups, with just one group if all the matrices are of equal size. The aim is to provide more efficient, but portable, implementations of algorithms on high-performance many-core platforms. These include multicore and many-core CPU processors, GPUs and coprocessors, and other hardware accelerators with floating-point compute facility. As well as the standard types of single and double precision, we also include half and quadruple precision in the standard. In particular, half precision is used in many very large scale applications, such as those associated with machine learning.
C1 [Abdelfattah, Ahmad; Dongarra, Jack; Gates, Mark; Luszczek, Piotr; Tomov, Stanimire] Univ Tennessee, 1122 Volunteer Blvd,Suite 203, Knoxville, TN 37996 USA.
   [Costa, Timothy; Haidar, Azzam] NVIDIA, Santa Clara, CA USA.
   [Dongarra, Jack] Oak Ridge Natl Lab, Oak Ridge, TN USA.
   [Dongarra, Jack; Hammarling, Sven; Higham, Nicholas J.] Univ Manchester, Manchester, Lancs, England.
   [Kurzak, Jakub] AMD, Knoxville, TN USA.
   [Zounon, Mawussi] NAG Ltd, Manchester, Lancs, England.
RP Abdelfattah, A (corresponding author), Univ Tennessee, 1122 Volunteer Blvd,Suite 203, Knoxville, TN 37996 USA.
EM ahmad@icl.utk.edu; dongarra@icl.utk.edu; mgates3@icl.utk.edu;
   azzamhaidar@nvidia.com; sven.hammarling@btinternet.com;
   nick.higham@manchester.ac.uk; luszczek@icl.utk.edu; tomov@icl.utk.edu;
   mawussi.zounon@nag.co.uk
CR Abdelfattah A, 2016, LECT NOTES COMPUT SC, V9697, P21, DOI 10.1007/978-3-319-41321-1_2
   Agullo E., 2010, GPU COMPUTING GEMS, V2
   Agullo E, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012037
   Anderson E., 1999, LAPACK USERS GUIDE, DOI 10.1137/1.9780898719604
   Anderson MJ, 2012, INT PARALL DISTRIB P, P2, DOI 10.1109/IPDPS.2012.11
   [Anonymous], 2016, 201625 MIMS U MANCH
   [Anonymous], 2015, FULL WALK SGEMM IMPL
   [Anonymous], 2011, PROC INT C HIGH PERF
   [Anonymous], 2012, P STATE OF THE ART S
   [Anonymous], 2015, P 8 WORKSH GEN PURP, DOI DOI 10.1145/2716282.2716288
   Auer AA, 2006, MOL PHYS, V104, P211, DOI 10.1080/00268970500275780
   Baboulin Marc, 2015, P SMOK MOUNT COMP SC
   Baboulin Marc, 2016, UTEECS16738
   Brock B, 2015, J COMPUT PHYS, V302, P591, DOI 10.1016/j.jcp.2015.09.013
   Demmel J., 2017, PROPOSAL NEXT GENERA
   Dong TX, 2014, 2014 IEEE INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS, 2014 IEEE 6TH INTL SYMP ON CYBERSPACE SAFETY AND SECURITY, 2014 IEEE 11TH INTL CONF ON EMBEDDED SOFTWARE AND SYST (HPCC,CSS,ICESS), P157, DOI 10.1109/HPCC.2014.30
   Dong TX, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.103
   DONGARA JJ, 1979, LINPACK USERS GUIDE
   Dongarra J, 2019, ACM T MATH SOFTWARE, V45, DOI 10.1145/3264491
   Dongarra J, 2017, PROCEDIA COMPUT SCI, V108, P495, DOI 10.1016/j.procs.2017.05.138
   DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P1, DOI 10.1145/42288.42291
   DONGARRA JJ, 1988, ACM T MATH SOFTWARE, V14, P18, DOI 10.1145/42288.42292
   DONGARRA JJ, 1990, ACM T MATH SOFTWARE, V16, P1, DOI 10.1145/77626.79170
   Gates Mark, 2019, P INT C HIGH PERF CO, P13
   Guney Murat, 2015, BATCHED MATRIX MATRI
   Hackbusch W, 1999, COMPUTING, V62, P89, DOI 10.1007/s006070050015
   Haidar A, 2015, ACM SIGPLAN NOTICES, V50, P261, DOI [10.1145/2858788.2688534, 10.1145/2688500.2688534]
   Haidar A, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.58
   Hammarling Sven, 2017, 2 WORKSH BATCH REPR
   Hammarling Sven, 2016, WORKSH BATCH REPR RE
   Higham Nicholas J, 2018, 201833 MIMS U MANCH
   HSL, 2013, COLL FORTR COD LARG
   Im EJ, 2004, INT J HIGH PERFORM C, V18, P135, DOI 10.1177/1094342004041296
   Jack Dongarra, 2016, CEUR WORKSHOP P, V1686
   Kabir K, 2015, LECT NOTES COMPUT SC, V9137, P58, DOI 10.1007/978-3-319-20119-1_5
   Keyes David, 2011, NSF ACCI TASK FORCE
   Khodayari A, 2014, METAB ENG, V25, P50, DOI 10.1016/j.ymben.2014.05.014
   Lai JJ, 2013, INT SYM CODE GENER, P89
   Lawson C. L., 1979, ACM Transactions on Mathematical Software, V5, P324, DOI [10.1145/355841.355847, 10.1145/355841.355848]
   Masliah Ian, 2016, UTEECS16740
   Molero J. M., 2013, PUMPS-POMPES-PUMPEN, DOI [10.1145/2716282.2716288, DOI 10.1145/2716282.2716288]
   Nath R, 2010, INT J HIGH PERFORM C, V24, P511, DOI 10.1177/1094342010385729
   NVIDIA, 2016, CUBLAS 7 5
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Villa O., 2013, 2013 IEEE INT C CLUS, P1, DOI DOI 10.1109/CLUSTER.2013.6702656
   Villa O, 2013, LECT NOTES COMPUT SC, V8097, P813, DOI 10.1007/978-3-642-40047-6_81
   Yeralan SN, 2017, ACM T MATH SOFTWARE, V44, DOI 10.1145/3065870
NR 47
TC 11
Z9 13
U1 1
U2 7
PD JUN
PY 2021
VL 47
IS 3
AR 21
DI 10.1145/3431921
WC Computer Science, Software Engineering; Mathematics, Applied
DA 2023-11-11
ER

PT C
AU Kotselidis, C
   Diamantopoulos, S
   Akrivopoulos, O
   Rosenfeld, V
   Doka, K
   Mohammed, H
   Mylonas, G
   Spitadakis, V
   Morgan, W
AF Kotselidis, Christos
   Diamantopoulos, Sothis
   Akrivopoulos, Orestis
   Rosenfeld, Viktor
   Doka, Katerina
   Mohammed, Hazeef
   Mylonas, Georgios
   Spitadakis, Vassilis
   Morgan, Will
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI Efficient Compilation and Execution of JVM-Based Data Processing
   Frameworks on Heterogeneous Co-Processors
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB This paper addresses the fundamental question of how modern Big Data frameworks can dynamically and transparently exploit heterogeneous hardware accelerators. After presenting the major challenges that have to be addressed towards this goal, we describe our proposed architecture for automatic and transparent hardware acceleration of Big Data frameworks and applications, Our vision is to retain the uniform programming model of Big Data frameworks and enable automatic, dynamic Just-In-Time compilation of the candidate code segments that benefit from hardware acceleration to the corresponding format. In conjunction with machine learning-based device selection, that respect user-defined constraints (e.g., cost, time, etc.), we enable dynamic code execution on GPUs and FPGAs transparently to the user. In addition, we dynamically re-steer execution at runtime based on the availability of resources. Our preliminary results demonstrate that our approach can accelerate an existing Apache Flink application by up to 16.5x.
C1 [Kotselidis, Christos] Univ Manchester, Manchester, Lancs, England.
   [Diamantopoulos, Sothis] Exus Ltd, London, England.
   [Akrivopoulos, Orestis] SparkWorks ITC Ltd, Swadlincote, England.
   [Rosenfeld, Viktor] German Res Ctr Artificial Intelligence, Kaiserslautern, Germany.
   [Doka, Katerina] Natl Tech Univ Athens, Athens, Greece.
   [Mohammed, Hazeef] Kaleao Ltd, Cambridge, England.
   [Mylonas, Georgios] Comp Technol Inst & Press Diophantus, Patras, Greece.
   [Spitadakis, Vassilis] Neurocom Luxembourg, Luxembourg, Luxembourg.
   [Morgan, Will] IProov Ltd, London, England.
RP Kotselidis, C (corresponding author), Univ Manchester, Manchester, Lancs, England.
EM christos.kotselidis@manchester.ac.uk; s.diamantopoulos@exus.co.uk;
   akribopo@sparkworks.net; viktor.rosenfeld@dfki.de;
   katerina@cslab.ece.ntua.gr; hazeef.mohammed@kaleao.com; mylonasg@cti.gr;
   v.spitadakis@neurocom.lu; will.morgan@iproov.com
CR [Anonymous], 2010, P 1 ACM S CLOUD COMP, DOI [10.1145/1807128.1807148, DOI 10.1145/1807128.1807148]
   Bress S., 2018, VLDB J
   Carbone P., 2015, ABS150608603 CORR
   Carbone Paris, 2015, B IEEE COMPUTER SOC, V36, P4, DOI DOI 10.1109/IC2EW.2016.56
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Clark JE, 2018, PSYCHOL MED, V48, P2277, DOI 10.1017/S0033291718000430
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   El-Helw I., 2014, P 23 INT S HIGH PERF
   Fowers J, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P47
   Fumero J., 2019, P 15 ACM SIGPLAN SIG
   Grossman M., 2013, 27 INT PAR DISTR PRO
   Ishizaki K, 2015, INT CONFER PARA, P419, DOI 10.1109/PACT.2015.46
   Koliousis A, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P555, DOI 10.1145/2882903.2882906
   Kotselidis C, 2017, ACM SIGPLAN NOTICES, V52, P74, DOI [10.1145/3050748.3050764, 10.1145/3140607.3050764]
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Li P., 2015, 2015 IEEE INT C NETW
   Lindholm T., 2014, JAVA VIRTUAL MACHINE, V8th
   Miao HY, 2017, 2017 USENIX ANNUAL TECHNICAL CONFERENCE (USENIX ATC '17), P617
   Rosenfeld V., 2015, ADMS VLDG
   Sabne Amit, 2015, P 24 INT S HIGH PERF
   Tan W., 2018, 1 CLASS GPUS SUPP AP
   Vavilapalli Vinod Kumar, 2013, SOCC, P1
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
NR 24
TC 2
Z9 3
U1 0
U2 5
PY 2020
BP 175
EP 179
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Plaza, M
   Deniziak, S
   Plaza, M
   Belka, R
   Pieta, P
AF Plaza, Malgorzata
   Deniziak, Stanislaw
   Plaza, Miroslaw
   Belka, Radoslaw
   Pieta, Pawel
BE Romaniuk, RS
   Linczuk, M
TI Analysis of parallel computational models for clustering
SO PHOTONICS APPLICATIONS IN ASTRONOMY, COMMUNICATIONS, INDUSTRY, AND
   HIGH-ENERGY PHYSICS EXPERIMENTS 2018
SE Proceedings of SPIE
DT Proceedings Paper
CT SPIE-IEEE-PSP WILGA on Photonics Applications in Astronomy,
   Communications, Industry, and High-Energy Physics Experiments
CY JUN 03-10, 2018
CL Wilga, POLAND
DE big data; clustering; cluster analysis; data mining; machine learning;
   parallel algorithms
ID ALGORITHM
AB Clustering is one of the main task of data mining, where groups of similar objects are discovered and grouping of similar data as well as outliers detection are performed. Processing of huge datasets requires scalable models of computations and distributed computing environments, therefore efficient parallel clustering methods are required for this purpose. Usually for parallel data analytics the MapReduce processing model is used. But growing computer power of heterogeneous platforms based on graphic processors and FPGA accelerators causes that CUDA and OpenCL models may be interesting alternative to MapReduce. This paper presents comparative analysis of effectiveness of applying MapReduce and CUDA/OpenCL processing models for clustering. We compare different methods of clustering in terms of their possibilities of parallelization using both models of computation. The conclusions indicate directions for further work in this area.
C1 [Plaza, Malgorzata; Deniziak, Stanislaw; Plaza, Miroslaw; Belka, Radoslaw; Pieta, Pawel] Kielce Univ Technol, Fac Elect Engn Automat Control & Comp Sci, Al Tysiaclecia PP 7, PL-25314 Kielce, Poland.
RP Plaza, M (corresponding author), Kielce Univ Technol, Fac Elect Engn Automat Control & Comp Sci, Al Tysiaclecia PP 7, PL-25314 Kielce, Poland.
EM malgorzata.plaza@tu.kielce.pl
CR Aggarwal CC, 2000, SIGMOD REC, V29, P70, DOI 10.1145/335191.335383
   AMD, 2009, AMD US GUID
   Anchalia P., 2014, 16 INT CON COMP MOD
   Anderberg M.R., 1973, CLUSTER ANAL APPL
   Andrade G, 2013, PROCEDIA COMPUT SCI, V18, P369, DOI 10.1016/j.procs.2013.05.200
   Andreopoulos B, 2009, BRIEF BIOINFORM, V10, P297, DOI 10.1093/bib/bbn058
   Ankerst M., 1999, SIGMOD Record, V28, P49, DOI 10.1145/304181.304187
   [Anonymous], EVALUATING MAPREDUCE
   [Anonymous], 1994, P INT C VERY LARGE D
   [Anonymous], 2009, OPENCL SPEC VERS 1 0
   [Anonymous], 2013, 2013 INT C INFORM SC
   Berkhin P., 2006, GROUPING MULTIDIMENS, P25, DOI DOI 10.1007/3-540-28349-8_2
   BEZDEK JC, 1984, COMPUT GEOSCI, V10, P191, DOI 10.1016/0098-3004(84)90020-7
   Bi-Ru Dai, 2012, 2012 IEEE 5th International Conference on Cloud Computing (CLOUD), P59, DOI 10.1109/CLOUD.2012.42
   Buyya R., 2016, BIG DATA PRINCIPLES
   Chang D., 2009, 22 INT C PAR DISTR C
   Cheeseman P, 1996, ADV KNOWLEDGE DISCOV, P153, DOI DOI 10.5555/257938.257954
   Cheng C.-H., 1999, PROC ACM SIGMOD INT, P84, DOI [10.1145/312129.312199, DOI 10.1145/312129.312199]
   Dean J., 2004, P 6 S OP SYST DES IM, P139
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dobre C, 2014, INT J PARALLEL PROG, V42, P710, DOI 10.1007/s10766-013-0272-7
   Ene A., 2011, SIGKDD, P681, DOI DOI 10.1145/2020408.2020515
   Ester M., 1996, P 2 INT C KNOWL DISC, P226, DOI DOI 10.5555/3001460.3001507
   Fahad A., 2014, IEEE T EMERGING TOPI, V2
   Fisher D. H., 1987, Machine Learning, V2, P139, DOI 10.1023/A:1022852608280
   Gao H., 2010, INT J DIGITAL CONTEN, V4, P95, DOI DOI 10.4156/JDCTA
   GENNARI JH, 1989, ARTIF INTELL, V40, P11, DOI 10.1016/0004-3702(89)90046-5
   Grossman M., 2013, 27 INT IEEE PAR DIST
   Guha S, 2000, INFORM SYST, V25, P345, DOI 10.1016/S0306-4379(00)00022-3
   Guha S, 2001, INFORM SYST, V26, P35, DOI 10.1016/S0306-4379(01)00008-4
   Han J., 2006, DATA MINING CONCEPTS
   He B., 2008, PARALLEL ARCHITECTUR
   He BS, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P260, DOI 10.1145/1454115.1454152
   Hinneburg A., 1998, Proceedings Fourth International Conference on Knowledge Discovery and Data Mining, P58
   Hinneburg A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P506
   Hong CT, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P217, DOI 10.1145/1854273.1854303
   Hong-tao B., 2009, IEEE, V7
   Huang Z., 1997, RES ISSUES DATA MINI, V3, P34
   HUBERT L, 1985, J CLASSIF, V2, P193, DOI 10.1007/BF01908075
   Hussain H. M., 2011, RECONFIGURABLE COMPU
   Hussain H. M., 2011, ADAPTIVE HARDWARE SY
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain AK., 1988, ALGORITHMS CLUSTERIN
   Jiadong Wu, 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P1740, DOI 10.1109/IPDPS.2011.331
   Jin C., 2013, P 4 INT SC WORKSH DA
   Junker B. H., 2008, ANAL BIOL NETWORKS, P314
   Kailing K, 2004, SIAM PROC S, P246
   Kambatla K, 2014, J PARALLEL DISTR COM, V74, P2561, DOI 10.1016/j.jpdc.2014.01.003
   Karypis G, 1999, COMPUTER, V32, P68, DOI 10.1109/2.781637
   Kaufman L., 1987, Statistical Data Analysis Based on the L1-Norm and Related Methods. First International Conference, P405
   Kaufman L., 2009, FINDING GROUPS DATA, V344
   Kaufman L., 1990, FINDING GROUPS DATA
   Kohonen T., 1998, Neurocomputing, V21, P1, DOI 10.1016/S0925-2312(98)00030-7
   Krechowicz A, 2016, LECT NOTES COMPUT SC, V9573, P302, DOI 10.1007/978-3-319-32149-3_29
   Lee KH, 2011, SIGMOD REC, V40, P11, DOI 10.1145/2094114.2094118
   Li L, 2011, MODELLING SIMULATION, P325
   Lin C, 2011, ADV INTEL SOFT COMPU, V123, P93
   MacQueen J., 1967, P 5 BERK S MATH STAT, V14, P281
   Mahmood AN, 2008, IEEE T KNOWL DATA EN, V20, P752, DOI 10.1109/TKDE.2007.190725
   Ng RT, 2002, IEEE T KNOWL DATA EN, V14, P1003, DOI 10.1109/TKDE.2002.1033770
   NVIDIA, 2008, TESL C1060 COMP PROC
   NVIDIA, 2012, CUDA PROGR GUID
   Okur S., 2012, HADOOP APARAPI MAKIN
   Papadimitriou S, 2008, IEEE DATA MINING, P512, DOI 10.1109/ICDM.2008.142
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Sadalage P. J., 2012, NOSQL DISTILLED BRIE
   Sheikholeslami G., 1998, Proceedings of the Twenty-Fourth International Conference on Very-Large Databases, P428
   Srirama SN, 2012, FUTURE GENER COMP SY, V28, P184, DOI 10.1016/j.future.2011.05.025
   Sun TY, 2009, 2009 INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED COMPUTING, APPLICATIONS AND TECHNOLOGIES (PDCAT 2009), P494, DOI 10.1109/PDCAT.2009.46
   Tan H., 2011, IEEE 17 INT C PAR DI
   Wang W, 1997, PROCEEDINGS OF THE TWENTY-THIRD INTERNATIONAL CONFERENCE ON VERY LARGE DATABASES, P186
   Wang ZK, 2016, IEEE T PARALL DISTR, V27, P3547, DOI 10.1109/TPDS.2016.2537805
   Xu XW, 1998, PROC INT CONF DATA, P324, DOI 10.1109/ICDE.1998.655795
   Zaharia Matei, 2008, 8 USENIX C OP SYST D, P29
   Zechner M, 2009, INTENSIVE: 2009 FIRST INTERNATIONAL CONFERENCE ON INTENSIVE APPLICATIONS AND SERVICES, P7, DOI 10.1109/INTENSIVE.2009.19
   Zhang T, 1997, DATA MIN KNOWL DISC, V1, P141, DOI 10.1023/A:1009783824328
   Zhang T., 1996, ACM SIGMOD RECORD, V25, P103, DOI [DOI 10.1145/235968.233324, 10.1145/233269.233324]
   Zhang YQ, 2016, P IEEE, V104, P2114, DOI 10.1109/JPROC.2016.2591592
   Zhao WZ, 2013, INT CON ADV INFO NET, P862, DOI 10.1109/AINA.2013.47
NR 79
TC 2
Z9 2
U1 0
U2 1
PY 2018
VL 10808
AR 108081O
DI 10.1117/12.2500795
WC Optics
DA 2023-11-11
ER

PT J
AU Wuraola, A
   Patel, N
   Nguang, SK
AF Wuraola, Adedamola
   Patel, Nitish
   Nguang, Sing Kiong
TI Efficient activation functions for embedded inference engines
SO NEUROCOMPUTING
DT Article
DE Activation function; Square non-linearity; Embedded neural networks;
   Hardware accelerator
ID MULTILAYER FEEDFORWARD NETWORKS; DEEP NEURAL-NETWORKS; LINEAR UNITS;
   APPROXIMATION
AB The importance of the choice of the activation function for training and inferencing in machine learning cannot be overemphasized. Activation functions can influence network training convergence, performance accuracy, and can make training and inference stages computationally expensive. We introduce a family of square-based activation functions for embedded devices that consume only one instruction cycle with the potential of being resource efficient when constructed in silicon. We show that the proposed family are computationally efficient when compared with exponential-based non-linearities. The family includes functions for deep neural network architectures, support vector machines, recurrent neural networks, and others. We demonstrate the universal ability of the square-based family of activation functions on a variety of neural network architectures. We analyze the hidden representations of our trained multilayer perceptron network in an attempt to explain the performance gains, and speed-up observed when using square non-linearities. Speed-up was recorded with the quadratic-based kernel transformation on support vector machines. We record higher performance accuracy for recurrent neural network architectures and logistic regression using this family. Speed up was also recorded for implementation on Intel CPU and ARM processors. This family will find particular importance in low-end hardware devices with limited hardware capabilities.
   (c) 2021 Elsevier B.V. All rights reserved.
C1 [Wuraola, Adedamola; Patel, Nitish; Nguang, Sing Kiong] Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
RP Wuraola, A (corresponding author), Univ Auckland, Dept Elect & Comp Engn, Auckland, New Zealand.
EM awur978@aucklanduni.ac.nz; nd.patel@auckland.ac.nz;
   sk.nguang@auckland.ac.nz
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Abai Z., 2019, ARXIV PREPRINT ARXIV
   Adedamola W, 2020, SQNL FAMILY
   Aimonen P, 2009, LIBFIXMATH
   Amari S, 1998, NEURAL COMPUT, V10, P251, DOI 10.1162/089976698300017746
   Apicella A, 2019, NEUROCOMPUTING, V370, P1, DOI 10.1016/j.neucom.2019.08.065
   Aymeric, 2017, TENSORFLOW EXAMPLES
   Brownlee J, 2019, SEQUENCE CLASSIFICAT
   Carlile B., 2017, ARXIV171009967
   Ciuparu A, 2020, NEUROCOMPUTING, V384, P376, DOI 10.1016/j.neucom.2019.12.014
   Clevert D.A., 2016, P 6 INT C LEARN REPR
   Dheeru D., 2017, UCI MACHINE LEARNING
   Dimitrios R, 2020, SVHN CLASSIFICATION
   Drewnik M, 2017, LECT NOTES COMPUT SC, V10244, P87, DOI 10.1007/978-3-319-59105-6_8
   Giri S., 2019, RESNET MODEL TINY IM
   Gulcehre C, 2016, PR MACH LEARN RES, V48
   Hao L., 2017, P 31 C NEUR INF PROC
   Harrison, 2016, RNN W LSTM CELL EXAM
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hendrycks D., 2016, PREPRINT
   HORNIK K, 1991, NEURAL NETWORKS, V4, P251, DOI 10.1016/0893-6080(91)90009-T
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intel, 2018, VECT MATH VM PERF AC
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Jaderberg M, 2015, ADV NEUR IN, V28
   Jiang XH, 2018, NEUROCOMPUTING, V275, P1132, DOI 10.1016/j.neucom.2017.09.056
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keras, 2019, KER EX
   Kim D, 2020, NEUROCOMPUTING, V406, P253, DOI 10.1016/j.neucom.2020.03.051
   Komodakis N, 2016, BMVC, P1, DOI DOI 10.5244/C.30.87
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Krizhevsky A., CIFAR 10
   LESHNO M, 1993, NEURAL NETWORKS, V6, P861, DOI 10.1016/S0893-6080(05)80131-5
   Li Y., TRAINING NEURAL NETW
   Li Y, 2018, NEUROCOMPUTING, V301, P11, DOI 10.1016/j.neucom.2018.01.084
   Lin M, 2013, NETWORK IN NETWORK
   Martens J., 2010, PROC 27 INT C MACH L, P735
   Moreno PJ, 2004, ADV NEUR IN, V16, P1385
   Nvidia, 2014, NVIDIA CUDNN
   Qian S, 2018, NEUROCOMPUTING, V272, P204, DOI 10.1016/j.neucom.2017.06.070
   Ramachandran P., 2017, P INT C LEARN REPR W
   Roopal, 2017, LSTM TENSORFLOW
   Schraudolph NN, 1999, NEURAL COMPUT, V11, P853, DOI 10.1162/089976699300016467
   Sen S, 2018, IEEE T COMPUT AID D, V37, P2266, DOI 10.1109/TCAD.2018.2858362
   Simonyan K., 2015, ICLR
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang X, 2019, NEUROCOMPUTING, V363, P88, DOI 10.1016/j.neucom.2019.07.017
   Wei, 2018, CONVOLUTIONAL NEURAL
   Wuraola A, 2018, IEEE IJCNN
   Wuraola A, 2018, LECT NOTES COMPUT SC, V11302, P103, DOI 10.1007/978-3-030-04179-3_9
   Xi S, 2017, RESTRICTED BOLTZMANN
   Ying Y, 2019, IEEE ACCESS, V7, P101633, DOI 10.1109/ACCESS.2019.2928442
NR 54
TC 5
Z9 5
U1 1
U2 5
PD JUN 28
PY 2021
VL 442
BP 73
EP 88
DI 10.1016/j.neucom.2021.02.030
EA MAR 2021
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Gong, HH
   Xing, K
   Du, WW
AF Gong, Haihua
   Xing, Kai
   Du, Wenwen
GP IEEE
TI Distinguishing between a Driver and Passenger via a Silent Smartphone
SO 2017 1ST IEEE SYMPOSIUM ON PRIVACY-AWARE COMPUTING (PAC)
DT Proceedings Paper
CT 1st IEEE Symposium on Privacy-Aware Computing (PAC)
CY AUG 01-04, 2017
CL George Washington Univ, Washington, DC
HO George Washington Univ
AB This poster investigates the discrimination problem between car driver and car passengers using smartphones, which is critical to active safety enhancement and usage based insurance. The proposed system leverages a smartphone without the assistance of extra devices or resources, e.g., car speakers, bluetooth network, Internet or cloud. Specifically, our system builds a unsupervised machine learning platform on Android based smartphones, in which the data of the Inertial Measurement Unit (IMU), i.e., gyro, accelerator, magnetometer, is taken as the input. With the attitude and trajectory data generated from the IMU measurement, the neural network extract the fundamental features of the spacial characteristics of driver and passengers during accelerating, deceleration, turning, starting, stopping, driving, based on which we may further distinguish driver and passengers. The experiments show that the proposed system is able to provide a classification accuracy over 95%, at a low false positive rate.
C1 [Gong, Haihua; Xing, Kai; Du, Wenwen] Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
RP Gong, HH (corresponding author), Univ Sci & Technol China, Sch Comp Sci & Technol, Hefei 230027, Anhui, Peoples R China.
EM ghh8513@mail.ustc.edu.cn; kxing@ustc.edu.cn; dwwo@mail.ustc.edu.cn
CR [Anonymous], 2013, P 11 ANN INT C MOBIL
   Bo C., 2013, P 19 ANN INT C MOB C, P199, DOI DOI 10.1145/2500423.2504575
   Yang J, 2011, MOBICOM, P97, DOI 10.1145/2030613.2030625
NR 3
TC 0
Z9 0
U1 0
U2 1
PY 2017
BP 190
EP 191
DI 10.1109/PAC.2017.37
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Song, YS
   Li, FY
   Liu, JY
   Zhang, JA
AF Song, Yunsheng
   Li, Fangyi
   Liu, Jianyu
   Zhang, Juao
BE TallonBallesteros, AJ
TI The Mechanism Analysis of the Accelerator for Support Vector Regression
   Based on Data Partition
SO FUZZY SYSTEMS AND DATA MINING VI
SE Frontiers in Artificial Intelligence and Applications
DT Proceedings Paper
CT 6th International Conference on Fuzzy Systems and Data Mining (FSDM)
CY NOV 13-16, 2020
CL ELECTR NETWORK
DE Machine learning; Large-scale data; Data partition; Support vector
   regression; Generation ability
AB Support vector regression is an important algorithm in machine learning, and it is widely used in real life for its good performance, such as house price forecast, disease prediction, weather forecast, and so on. However, it cannot efficiently process large-scale data, because it has a high time complexity in the training process. Data partition as an important solution to solve the large-scale learning problem mainly focuses on the classification task, it trains the classifiers over the divided subsets produced by data partition and obtain the final classifier by combining those classifiers. Meanwhile, the most existing method rarely study the influence of data partition on the regressor performance, so that it is difficult to keep its generation ability. To solve this problem, we obtain the estimation of the difference in objective function before and after the data partition. Mini-Batch K-Means clustering is adopted to largely reduce this difference, and an improved algorithm is proposed. This proposed algorithm includes training stage and prediction stage. In training stag, it uses Mini-Batch K-Means clustering to divide the input space into some disjoint sub-regions of equal sample size, then it trains the regressor on each divided sub-region using support vector regression algorithm. In the prediction stage, the regressor merely offers the predicted label for the unlabeled instances that are in the same sub-region. Experiment results on real datasets illustrate that the proposed algorithm obtains the similar generation ability as the original algorithm, but it has less execution time than other acceleration algorithms.
C1 [Song, Yunsheng; Li, Fangyi; Liu, Jianyu; Zhang, Juao] Shandong Agr Univ, Sch Informat Sci & Engn, Tai An 271018, Shandong, Peoples R China.
RP Song, YS (corresponding author), Shandong Agr Univ, Tai An 271018, Shandong, Peoples R China.
EM sys_sd@126.com
CR Adnan RM, 2020, J HYDROL, V586, DOI 10.1016/j.jhydrol.2019.124371
   [Anonymous], 2011, ACM T INTEL SYST TEC, DOI DOI 10.1145/1961189.1961199
   CACHIN C, 1994, NEURAL NETWORKS, V7, P175, DOI 10.1016/0893-6080(94)90066-3
   Foody GM, 1999, INT J REMOTE SENS, V20, P3549, DOI 10.1080/014311699211192
   Guo G, 2007, PATTERN RECOGN LETT, V28, P2173, DOI 10.1016/j.patrec.2007.04.017
   Han J, 2012, MOR KAUF D, P1
   Han XX, 2014, QUAL RELIAB ENG INT, V30, P891, DOI 10.1002/qre.1654
   Ho CH, 2012, J MACH LEARN RES, V13, P3323
   Jimenez S., 2019, ADV INTELL SYST COMP, V1099, P182, DOI [10.1007/978-3-030-35740-5_13, DOI 10.1007/978-3-030-35740-5_13]
   Kleiner A, 2014, J R STAT SOC B, V76, P795, DOI 10.1111/rssb.12050
   Pan XL, 2018, NEUROCOMPUTING, V287, P163, DOI 10.1016/j.neucom.2018.01.083
   Pan XL, 2018, IEEE T NEUR NET LEAR, V29, P1876, DOI 10.1109/TNNLS.2017.2688182
   Song YS, 2019, INT J MACH LEARN CYB, V10, P2389, DOI 10.1007/s13042-018-0877-7
   Wang KN, 2019, SCI PROGRAMMING-NETH, V2019, DOI 10.1155/2019/7102946
   Yang LM, 2019, APPL SOFT COMPUT, V81, DOI 10.1016/j.asoc.2019.105483
   Zhang C, 2020, INFORM SCIENCES, V507, P665, DOI 10.1016/j.ins.2019.01.033
NR 16
TC 1
Z9 1
U1 1
U2 4
PY 2020
VL 331
BP 528
EP 535
DI 10.3233/FAIA200730
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Interdisciplinary Applications; Mathematics,
   Applied
DA 2023-11-11
ER

PT J
AU Akarvardar, K
   Wong, HSP
AF Akarvardar, Kerem
   Wong, H-S Philip
TI Technology Prospects for Data-Intensive Computing
SO PROCEEDINGS OF THE IEEE
DT Article
DE Artificial intelligence (AI); AI accelerators; big data applications;
   CMOS technology; deep learning; DRAM chips; energy efficiency; high
   performance computing; machine learning; Moore's Law; multichip modules
   (MCMs); nonvolatile memory; roadmaps (technology planning); SRAM chips;
   system integration; system-in-package (SiP); system-on-chip;
   three-dimensional integrated circuits; wafer bonding
ID MOORES LAW; POWER; GPU; OPTIMIZATION; INTERCONNECT; EFFICIENCY;
   ROOFLINE; TUTORIAL; DESIGN; SYSTEM
AB For many decades, progress in computing hardware has been closely associated with CMOS logic density, performance, and cost. As such, slowdown in 2-D scaling, frequency saturation in CPUs, and increased cost of design and chip fabrication for advanced technology nodes since the early 2000s have led to concerns about how semiconductor technology may evolve in the future. However, the last two decades have also witnessed a parallel development in the application landscape: the advent of big data and consequent rise of data-intensive computing, using techniques such as machine learning. In this article, we advance the idea that data-intensive computing would further cement semiconductor technology as a foundational technology with multidimensional pathways for growth. Continued progress of semiconductor technology in this new context would require the adoption of a system-centric perspective to holistically harness logic, memory, and packaging resources. After examining the performance metrics for data-intensive computing, we present the historical trends for general-purpose graphics processing unit (GPGPU) as a representative data-intensive computing hardware. Thereon, we estimate the values of the key data-intensive computing parameters for the next decade, and our projections may serve as a precursor for a dedicated technology roadmap. By analyzing the compiled data, we identify and discuss specific opportunities and challenges for data-intensive computing hardware technology.
C1 [Akarvardar, Kerem; Wong, H-S Philip] Corp Res, Taiwan Semicond Mfg Co TSMC, San Jose, CA 95134 USA.
   [Wong, H-S Philip] Stanford Univ, Dept Elect Engn, Stanford, CA 94305 USA.
RP Akarvardar, K (corresponding author), Corp Res, Taiwan Semicond Mfg Co TSMC, San Jose, CA 95134 USA.
EM kerema@tsmc.com; hspwong@stanford.edu
CR Aamodt Tor M., 2018, GEN PURPOSE GRAPHICS, DOI DOI 10.1007/978-3-031-01759-9
   Alfano M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2624284
   Altman A., 2019, PROC IEEE HOT CHIPS, P1
   Aly MMS, 2019, P IEEE, V107, P19, DOI 10.1109/JPROC.2018.2882603
   AMD, ADDR CHALL EN EFF CO
   [Anonymous], TSMCS CHIP SCALING E
   [Anonymous], NEW STANDARD COULD L
   [Anonymous], IMAGE OPENCLIPART VE
   [Anonymous], AMD AIMS INCREASE CH
   [Anonymous], JEDEC PUBLISHES HBM3
   [Anonymous], TSMC LAUNCHES NEW N1
   [Anonymous], 2009, NVIDIAS FERMI 1 COMP
   [Anonymous], CHIP MARKET WILL HIT
   [Anonymous], SAMBANOVAS NEW SILIC
   [Anonymous], NVIDIA TESLA V100 GP
   [Anonymous], NVIDIA A100 TENSOR C
   [Anonymous], NVIDIA ARM INTEL PUB
   [Anonymous], MUCH DATA IS CREATED
   [Anonymous], 2003, 2003 IEEE INT ELECT
   [Anonymous], AMD ADDRESSING CHALL
   [Anonymous], JEDEC UPDATES HBM2 M
   [Anonymous], NVIDIA H100 TENSOR C
   [Anonymous], 2012, P 2012 ACMIEEE INT S
   [Anonymous], TSMC BEGINS PILOT PR
   [Anonymous], GEFORCE GPU POWER PR
   [Anonymous], NVIDIA HOPPER GPU AR
   [Anonymous], CUDA C BEST PRACT GU
   [Anonymous], HETEROGENEOUS INTEGR, V2021
   [Anonymous], TSMC UNVEILS N4X NOD
   [Anonymous], AMD CDNA 2 ARCHITECT
   [Anonymous], GPU SPECS DATABASE
   [Anonymous], GRAPHICS CARDS TDP T
   Arunkumar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P320, DOI 10.1145/3079856.3080231
   Auth C., 2017, 2017 IEEE International Electron Devices Meeting (IEDM), p29.1.1, DOI 10.1109/IEDM.2017.8268472
   Auth C., 2012, 2012 IEEE Symposium on VLSI Technology, P131, DOI 10.1109/VLSIT.2012.6242496
   Batra G., 2019, ARTIF INTELL
   Beyne E., 2021, INT EL DEVICES MEET, P3
   Bohr Mark, 2009, 2009 IEEE International Solid-State Circuits Conference (ISSCC 2009), P23, DOI 10.1109/ISSCC.2009.4977293
   Bohr Mark, 2007, IEEE SOLID STATE CIR, V12, P11, DOI [DOI 10.1109/N-SSC.2007.4785534, 10.1109/N-SSC.2007.4785534]
   Bourjot E, 2021, ELEC COMP C, P470, DOI 10.1109/ECTC32696.2021.00085
   Brochard L., 2019, ENERGY EFFICIENT COM
   Burkacky O., 2021, VALUE CREATION CAN S
   Cao K, 2019, J SYST ARCHITECT, V97, P397, DOI 10.1016/j.sysarc.2019.01.003
   Chang K, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3273956
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chehab B., 2020, PROC SPIE, V11328
   Chen A, 2016, SOLID STATE ELECTRON, V125, P25, DOI 10.1016/j.sse.2016.07.006
   Chen FC, 2019, ELEC COMP C, P594, DOI 10.1109/ECTC.2019.00095
   Chen JY, 2009, INT EL DEVICES MEET, P1, DOI 10.1109/CLEOE-EQEC.2009.5196326
   Chen MF, 2020, IEEE T ELECTRON DEV, V67, P5343, DOI 10.1109/TED.2020.3021358
   Chen R., 2020, INT EL DEVICES MEET, P15
   Chen YH, 2020, ELEC COMP C, P576, DOI 10.1109/ECTC32862.2020.00096
   Cheng Y. -K., 2020, INT EL DEVICES MEET, P41
   Choi JW, 2013, INT PARALL DISTRIB P, P661, DOI 10.1109/IPDPS.2013.77
   Close GF, 2013, IEEE T CIRCUITS-I, V60, P1521, DOI 10.1109/TCSI.2012.2220459
   Dally W. J., 2017, DEEP LEARNING HPC
   Dally W. J., 2016, EFFICIENCY PROGRAMMA
   Dally WJ, 2020, COMMUN ACM, V63, P48, DOI 10.1145/3361682
   DeBenedictis EP, 2017, COMPUTER, V50, P69, DOI 10.1109/MC.2017.3001236
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Dolbeau R, 2018, J SUPERCOMPUT, V74, P1341, DOI 10.1007/s11227-017-2177-5
   Douglas C, 2021, 2021 IEEE IEDM IEEE, P3
   Elsherbini A, 2021, ELEC COMP C, P1014, DOI 10.1109/ECTC32696.2021.00166
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Farmahini-Farahani A, 2018, PROCEEDINGS OF WORKSHOP ON MEMORY CENTRIC HIGH PERFORMANCE COMPUTING (MCHPC'18), P4, DOI 10.1145/3286475.3286484
   Fazio A, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371976
   Fu Y., 2022, BMC PLANT BIOL, V19, P1
   Games W, 2020, ISSCC DIG TECH PAP I, P144
   Garland M, 2010, COMMUN ACM, V53, P58, DOI 10.1145/1839676.1839694
   Ghane M, 2018, Arxiv, DOI arXiv:1809.09206
   Gokhale M, 2008, COMPUTER, V41, P60, DOI 10.1109/MC.2008.125
   Gomes Wilfred, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P42, DOI 10.1109/ISSCC42614.2022.9731673
   Guerreiro J, 2018, INT S HIGH PERF COMP, P789, DOI 10.1109/HPCA.2018.00072
   Gupta MK, 2021, IEEE T ELECTRON DEV, V68, P6106, DOI 10.1109/TED.2021.3121349
   Gupta MK, 2021, IEEE T ELECTRON DEV, V68, P3819, DOI 10.1109/TED.2021.3088392
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Hanhirova J, 2018, PROCEEDINGS OF THE 9TH ACM MULTIMEDIA SYSTEMS CONFERENCE (MMSYS'18), P204, DOI 10.1145/3204949.3204975
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hou SY, 2017, IEEE T ELECTRON DEV, V64, P4071, DOI 10.1109/TED.2017.2737644
   Hsia H, 2021, ELEC COMP C, P263, DOI 10.1109/ECTC32696.2021.00052
   Huang H. Howie, 2014, 2014 IEEE International Conference on Big Data (Big Data), P16, DOI 10.1109/BigData.2014.7004471
   Huang PK, 2021, ELEC COMP C, P101, DOI 10.1109/ECTC32696.2021.00028
   Hung JN, 2021, ELEC COMP C, P105, DOI 10.1109/ECTC32696.2021.00029
   Hwang T, 2018, Arxiv, DOI [arXiv:1803.08971, DOI 10.2139/SSRN.3147971, 10.48550/arXiv.1803.08971]
   Hwu WM, 2018, IEEE MICRO, V38, P56, DOI 10.1109/MM.2018.2877839
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Esser SK, 2020, Arxiv, DOI arXiv:1902.08153
   Kaisler S, 2013, P ANN HICSS, P995, DOI 10.1109/HICSS.2013.645
   Kammler Th, 2018, ECS Transactions, V85, P39, DOI 10.1149/08508.0039ecst
   Kandiah V., 2021, PROC ANN IEEEACM INT, P738
   Keckler S., ENERGY EFFICIENT ARC
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Knowles S., 2021, IEEE HOT CHIPS 33 S, P1
   Le BQ, 2019, IEEE T ELECTRON DEV, V66, P641, DOI 10.1109/TED.2018.2879788
   Lee D, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2832911
   Leiserson CE, 2020, SCIENCE, V368, P1079, DOI 10.1126/science.aam9744
   Lie S, 2022, IEEE HOT CHIPS 34 S
   Lin X. -W., 2021, INT CONF SOFTW ENG, P3
   Liu M, 2021, ISSCC DIG TECH PAP I, V64, P9, DOI 10.1109/ISSCC42613.2021.9366060
   Liu YZ, 2019, NAT ELECTRON, V2, P555, DOI 10.1038/s41928-019-0340-0
   Loubet N, 2017, S VLSI TECH, pT230, DOI 10.23919/VLSIT.2017.7998183
   Madan N, 2007, INT SYMP MICROARCH, P223, DOI 10.1109/MICRO.2007.31
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Mathur R., 2021, PROC IEEE CUSTOM INT, P1
   Mathur R, 2020, ELEC COMP C, P541, DOI 10.1109/ECTC32862.2020.00091
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Milojevic D, 2021, PROC SPIE, V11614, DOI 10.1117/12.2584532
   Min M, 2020, 2020 INTERNATIONAL WAFER LEVEL PACKAGING CONFERENCE (IWLPC), DOI 10.23919/IWLPC52010.2020.9375855
   Mistry K, 2007, INT EL DEVICES MEET, P247, DOI 10.1109/IEDM.2007.4418914
   Mittal S, 2017, IEEE T PARALL DISTR, V28, P16, DOI 10.1109/TPDS.2016.2546249
   Moore SK, 2020, IEEE SPECTRUM, V57, P25, DOI [10.1109/mspec.2020.9150552, 10.1109/MSPEC.2020.9150552]
   Mutlu Onur, 2014, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V1, P19
   Naffziger S, 2021, ISSCC
   Naffziger S, 2021, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA52012.2021.00014
   Nakamura H., 2006, S VLSI TECHNOL DIG T, P158, DOI [10.1109/VLSIT.2006.1705265, DOI 10.1109/VLSIT.2006.1705265]
   Nickolls J, 2010, IEEE MICRO, V30, P56, DOI 10.1109/MM.2010.41
   Niu D., 2022, 2022 IEEE INT SOLIDS, P1
   Nogami T., 2022, IEEE S VLSI TECHN CI, P423
   Nurvitadhi E, 2018, I C FIELD PROG LOGIC, P106, DOI 10.1109/FPL.2018.00027
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   OConnor M., HIGH BANDWIDTH ENERG
   Oh CS, 2020, ISSCC DIG TECH PAP I, P330, DOI 10.1109/isscc19947.2020.9063110
   Oh Y, 2022, IEEE EMBED SYST LETT, V14, P187, DOI 10.1109/LES.2022.3163749
   Oldiges P, 2020, IEEE ACCESS, V8, P154329, DOI 10.1109/ACCESS.2020.3017756
   Paik Y., 2017, FLASH MEM SUMM
   Papermaster M., 2019, PROC IEEE 26 INT C H, P1
   Papermaster M., 2021, PROC S VLSI CIRCUITS, P1
   Park MJ, 2022, IEEE J SOLID-ST CIRC, DOI [10.1109/JSSC.2022.3193354, 10.1109/ISSCC42614.2022.9731562]
   Patterson D. A., 2012, COMPUTER ARCHITECTUR
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Perumkunnil M., 2020, IEDM, P15
   Pomianowski A., 2021, IEEE HOT CHIPS 33 S, P1
   Puttaswamy K, 2009, IEEE T COMPUT, V58, P1369, DOI 10.1109/TC.2009.92
   Qadeer W, 2015, COMMUN ACM, V58, P85, DOI 10.1145/2735841
   Qureshi Z, 2023, Arxiv, DOI arXiv:2203.04910
   Rydning DRJGJ., 2018, DIGITIZATION WORLD E
   Samajdar A, 2020, INT SYM PERFORM ANAL, P58, DOI 10.1109/ISPASS48437.2020.00016
   Samavedam SB, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372023
   Scherer M, 2022, IEEE T COMPUT AID D, V41, P1020, DOI 10.1109/TCAD.2021.3075420
   Shahidi GG, 2019, IEEE ACCESS, V7, P851, DOI 10.1109/ACCESS.2018.2885895
   Sharma D.D., UNIVERSAL CHIPLET IN
   Sheikh Farhana, 2021, IEEE Solid-State Circuits Magazine, V13, P77, DOI 10.1109/MSSC.2021.3111386
   Shen YW, 2019, J LIGHTWAVE TECHNOL, V37, P245, DOI 10.1109/JLT.2019.2897365
   Shiba K, 2021, IEEE T CIRCUITS-I, V68, P692, DOI 10.1109/TCSI.2020.3037892
   Sinha S, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9372120
   Sinha S, 2020, Arxiv, DOI arXiv:2005.10866
   Smith Shaden, 2022, ARXIV, DOI DOI 10.48550/ARXIV.2201.11990
   Song LH, 2018, INT S HIGH PERF COMP, P531, DOI 10.1109/HPCA.2018.00052
   Stosic D, TRAINING NEURAL NETW
   Stow D, 2019, IEEE COMPUT ARCHIT L, V18, P132, DOI 10.1109/LCA.2019.2941715
   Su L. T., 2017, INT EL DEVICES MEET, P1
   Swaminathan R., 2021, HOT CHIPS 33 TUTORIA
   Sze Vivienne, 2020, IEEE Solid-State Circuits Magazine, V12, P28, DOI 10.1109/MSSC.2020.3002140
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tang ZH, 2019, E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P315, DOI 10.1145/3307772.3328315
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Timoneda X, 2020, IEEE T COMMUN, V68, P3247, DOI 10.1109/TCOMM.2020.2973988
   Tsai YF, 2008, IEEE T VLSI SYST, V16, P444, DOI 10.1109/TVLSI.2007.915429
   TSMC, 2023, INT TSMC HINTS 3400M
   WANG NG, 2018, ADV NEUR IN, V31
   Wang PH, 2011, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2019608.2019612
   Wang X, 2019, 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS (ITHINGS) AND IEEE GREEN COMPUTING AND COMMUNICATIONS (GREENCOM) AND IEEE CYBER, PHYSICAL AND SOCIAL COMPUTING (CPSCOM) AND IEEE SMART DATA (SMARTDATA), P711, DOI 10.1109/iThings/GreenCom/CPSCom/SmartData.2019.00134
   Watson HJ, 2014, COMMUN ASSOC INF SYS, V34, P1247
   Wei TW, 2021, IEEE T COMP PACK MAN, V11, P415, DOI 10.1109/TCPMT.2020.3045113
   Wen W, 2017, MICROPROCESS MICROSY, V49, P44, DOI 10.1016/j.micpro.2017.01.005
   Williams S, PERFORMANCE TUNING R
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Wong HSP, 2020, P IEEE, V108, P478, DOI 10.1109/JPROC.2020.2981715
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wu C.H., 2021, 2021 S VLSI CIRCUITS, P1
   Wu H., 2018, IEDM
   Wu SY, 2019, INT EL DEVICES MEET
   Wulf W. A., 1995, Computer Architecture News, V23, P20, DOI 10.1145/216585.216588
   Wuu John, 2022, 2022 IEEE International Solid- State Circuits Conference (ISSCC), P428, DOI 10.1109/ISSCC42614.2022.9731565
   Yeap G, 2019, INT EL DEVICES MEET, DOI 10.1109/IEDM19573.2019.8993577
   Yu D., 2014, P IEEE CUST INT CIRC, P1
   Yu D., 2021, HOTCHIPS 33 TUTORIAL
   Zhang Y, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2020.2975656
   Zhao J., 2013, ACM T ARCHIT CODE OP, V10, P1
   Zhu LJ, 2021, IEEE T VLSI SYST, V29, P1152, DOI 10.1109/TVLSI.2021.3073070
   Zhu MH, 2018, IEEE T VLSI SYST, V26, P831, DOI 10.1109/TVLSI.2018.2791442
NR 183
TC 3
Z9 3
U1 5
U2 8
PD JAN
PY 2023
VL 111
IS 1
BP 92
EP 112
DI 10.1109/JPROC.2022.3218057
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Huang, HJ
   Li, YT
   Sun, J
   Zhu, XY
   Zhang, J
   Luo, L
   Li, JL
   Wang, ZK
AF Huang, Hongjing
   Li, Yingtao
   Sun, Jie
   Zhu, Xueying
   Zhang, Jie
   Luo, Liang
   Li, Jialin
   Wang, Zeke
TI P4SGD: Programmable Switch Enhanced Model-Parallel Training on
   Generalized Linear Models on Distributed FPGAs
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Distributed training system; FPGA; GLMs; P4
ID MACHINE
AB Generalized linear models (GLMs) are a widely utilized family of machine learning models in real-world applications. As data size increases, it is essential to perform efficient distributed training for these models. However, existing systems for distributed training have a high cost for communication and often use large batch sizes to balance computation and communication, which negatively affects convergence. Therefore, we argue for an efficient distributed GLM training system that strives to achieve linear scalability, while keeping batch size reasonably low. As a start, we propose P4SGD, a distributed heterogeneous training system that efficiently trains GLMs through model parallelism between distributed FPGAs and through forward-communication-backward pipeline parallelism within an FPGA. Moreover, we propose a light-weight, latency-centric in-switch aggregation protocol to minimize the latency of the AllReduce operation between distributed FPGAs, powered by a programmable switch. As such, to our knowledge, P4SGD is the first solution that achieves almost linear scalability between distributed accelerators through model parallelism. We implement P4SGD on eight Xilinx U280 FPGAs and a Tofino P4 switch. Our experiments show P4SGD converges up to 6.5X faster than the state-of-the-art GPU counterpart.
C1 [Huang, Hongjing; Li, Yingtao; Zhu, Xueying; Zhang, Jie; Wang, Zeke] Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
   [Sun, Jie] Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
   [Sun, Jie] Alibaba Grp, Hangzhou 311121, Peoples R China.
   [Luo, Liang] Univ Washington, Seattle, WA 98195 USA.
   [Li, Jialin] Natl Univ Singapore, Singapore 119077, Singapore.
RP Wang, ZK (corresponding author), Zhejiang Univ, Collaborat Innovat Ctr Artificial Intelligence, Hangzhou 310027, Zhejiang, Peoples R China.
EM huang_hj@zju.edu.cn; Li_Yingtao@zju.edu.cn; sunjie.sun@alibaba-inc.com;
   zhuxueying@zju.edu.cn; carlzhang4@zju.edu.cn;
   liangluo@cs.washington.edu; lijl@comp.nus.edu.sg; wangzeke@zju.edu.cn
CR [Anonymous], 2015, P SPE RES SIM S
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Bressana Pietro, 2020, NAI '20: Proceedings of the Workshop on Network Application Integration/CoDesign, P35, DOI 10.1145/3405672.3405807
   Cadambi S, 2009, ANN IEEE SYM FIELD P, P115, DOI 10.1109/FCCM.2009.34
   Caulfield AM, 2016, INT SYMP MICROARCH
   Chang CC, 2011, ACM T INTEL SYST TEC, V2, DOI 10.1145/1961189.1961199
   Chiu GR, 2018, PROCEEDINGS OF THE 2018 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN (ISPD'18), P34, DOI 10.1145/3177540.3177561
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Cui HG, 2016, PROCEEDINGS OF THE ELEVENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS, (EUROSYS 2016), DOI 10.1145/2901318.2901323
   Dass J, 2020, IEEE T COMPUT, V69, P1015, DOI 10.1109/TC.2020.2993552
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Edge-core, 2020, WEDG 100BF 32X R07
   Elgohary A, 2016, PROC VLDB ENDOW, V9, P960
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Free Software Foundation Inc., 2019, LM SENS
   Graham RL, 2016, PROCEEDINGS OF FIRST WORKSHOP ON OPTIMIZATION OF COMMUNICATION IN HPC RUNTIME SYSTEMS (COM-HPC 2016), P1, DOI [10.1109/COM-HPC.2016.6, 10.1109/COMHPC.2016.006]
   Gray Alan, 2019, GETTING STARTED CUDA
   Ho Qirong, 2013, Adv Neural Inf Process Syst, V2013, P1223
   Huang YP, 2019, ADV NEUR IN, V32
   Intel, 2021, INT TOF PROGR ETH SW
   Intel, 2021, INT TOF 2 P4 PROGR E
   Jia ZH, 2018, Arxiv, DOI arXiv:1807.05358
   Kara K, 2017, ANN IEEE SYM FIELD P, P160, DOI 10.1109/FCCM.2017.39
   Krizhevsky A, 2014, Arxiv, DOI [arXiv:1404.5997, DOI 10.48550/ARXIV.1404.5997]
   Lao C, 2021, PROCEEDINGS OF THE 18TH USENIX SYMPOSIUM ON NETWORKED SYSTEM DESIGN AND IMPLEMENTATION, P741
   Lee JH, 2020, IEEE INT SYMP PHYS, DOI 10.1109/ipfa49335.2020.9260706
   Li M., 2014, P S OP SYST DES IMPL, P583
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Li Zhuohan, 2021, TERAPIPE TOKEN LEVEL
   Luo L, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P41, DOI 10.1145/3267809.3267840
   Mahajan D, 2018, Arxiv, DOI arXiv:1801.06027
   Mahajan D, 2016, INT S HIGH PERF COMP, P14, DOI 10.1109/HPCA.2016.7446050
   Microsoft, 2020, ZERO DEEPSP NEW SYST
   Moreau T, 2015, INT S HIGH PERF COMP, P603, DOI 10.1109/HPCA.2015.7056066
   NVIDIA, 2023, CUBLAS REL 12 1
   NVIDIA, 2012, NVIDIA SYST MAN INT
   NVIDIA, 2021, ACC GPU STOR COMM NV
   NVIDIA, 2020, NVIDIA COLL COMM LIB
   Oden L, 2014, IEEE ACM INT SYMP, P483, DOI 10.1109/CCGrid.2014.21
   Park JH, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P307
   Pop P, 2016, IET CYBER PHYS SYST, V1, P86, DOI 10.1049/iet-cps.2016.0021
   Rendle Steffen, 2010, Proceedings 2010 10th IEEE International Conference on Data Mining (ICDM 2010), P995, DOI 10.1109/ICDM.2010.127
   Sapio A, 2020, Arxiv, DOI arXiv:1903.06701
   Sharma H, 2016, INT SYMP MICROARCH
   Shoeybi M, 2020, Arxiv, DOI [arXiv:1909.08053, DOI 10.1073/PNAS.2205690119]
   Thangakrishnan I, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/sc41405.2020.00048
   Umuroglu Y, 2018, I C FIELD PROG LOGIC, P307, DOI 10.1109/FPL.2018.00059
   Wang Q, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P277
   Wang ZK, 2019, PROC VLDB ENDOW, V12, P807, DOI 10.14778/3317315.3317322
   Xilinx, 2020, ALV U280 DAT CTR ACC
   Xillinx, 2023, ALV CARD MAN SOL SUB
   Xu YZ, 2021, Arxiv, DOI arXiv:2105.04663
   Zhang ZP, 2020, PROC INT CONF DATA, P1513, DOI 10.1109/ICDE48307.2020.00134
   Zheng LM, 2022, Arxiv, DOI arXiv:2201.12023
   Zheng TY, 2019, SCI CHINA INFORM SCI, V62, DOI 10.1007/s11432-018-9834-8
NR 56
TC 0
Z9 0
U1 3
U2 3
PD AUG
PY 2023
VL 34
IS 8
BP 2311
EP 2324
DI 10.1109/TPDS.2023.3279255
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Taheri, F
   Bayat-Sarmadi, S
   Hadayeghparast, S
AF Taheri, Farhad
   Bayat-Sarmadi, Siavash
   Hadayeghparast, Shahriar
TI RISC-HD: Lightweight RISC-V Processor for Efficient Hyperdimensional
   Computing Inference
SO IEEE INTERNET OF THINGS JOURNAL
DT Article
DE FPGA design; hyperdimensional (HD) computing; instruction set
   architecture (ISA) extension; pruning; RISC-V
ID INTERNET
AB Hyperdimensional (HD) computing is a lightweight machine learning method widely used in Internet of Things applications for classification tasks. Although many hardware accelerators are proposed to improve the performance of HD, they suffer from low flexibility that makes them not practical in most real-life scenarios. To improve the flexibility, an opensource instruction set architecture (ISA) called RISC-V has been employed and extended for a specific application such as machine learning. This article aims to improve the efficiency and flexibility of HD computing for resource-constrained applications. To this end, we extend a RISC-V core (RI5CY) for HD computing called RISC-HD. First, to reduce the computational overhead at the HD inference phase, we introduce a pruning method to remove the ineffectual dimensions. The proposed pruning method can reduce the dimension from 10k to 1k with negligible accuracy loss. Second, an ISA extension for RI5CY is proposed to compute the HD inference efficiently. Experimental results indicate that RISC-HD adds 1.42x area overhead to the RI5CY core; however, it consumes only 2932 slices on the Artix-7 FPGA, which is suitable for resource-constrained devices. Additionally, RISC-HD improves the total clock cycle by 7.48x compared to the RI5CY core and 6.17x compared to ARM Cortex-M4 in the ISOLET data set. Moreover, RISC-HD achieves 7.22x energy efficiency compared to the RI5CY core.
C1 [Taheri, Farhad; Bayat-Sarmadi, Siavash; Hadayeghparast, Shahriar] Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
RP Bayat-Sarmadi, S (corresponding author), Sharif Univ Technol, Dept Comp Engn, Tehran 1458889694, Iran.
EM farhadtaheri@ce.sharif.edu; sbayat@sharif.edu;
   hadayeghparast@ce.sharif.edu
CR Anguita D., 2013, P 21 INT EUR S ART N, P437
   [Anonymous], IBEX
   [Anonymous], ROCKET
   [Anonymous], OVP SIMULATOR
   [Anonymous], 2010, UCI MACHINE LEARNING
   [Anonymous], RI5CY
   [Anonymous], PULPINO
   [Anonymous], VIVADO DESIGN SUITE
   [Anonymous], FREEDOM
   Bartolini A, 2019, IEEE I C ELECT CIRC, P771, DOI [10.1109/icecs46596.2019.8964699, 10.1109/ICECS46596.2019.8964699]
   Benatti S, 2019, IEEE T BIOMED CIRC S, V13, P516, DOI 10.1109/TBCAS.2019.2914476
   Burrello Alessio, 2019, 2019 Design, Automation & Test in Europe Conference & Exhibition (DATE). Proceedings, P752, DOI 10.23919/DATE.2019.8715186
   Burrello A, 2021, IEEE J BIOMED HEALTH, V25, P935, DOI 10.1109/JBHI.2020.3022211
   Das K, 2017, IJIRCCE, V5, P1301, DOI DOI 10.15680/IJIRCCE.2017.0502001
   Farzam SMH, 2022, IEEE T CIRCUITS-I, V69, P1221, DOI 10.1109/TCSI.2021.3129589
   Fritzmann Tim, 2020, IACR T CRYPTOGRAPH H, V4, P239
   Garofalo A, 2020, DES AUT TEST EUROPE, P186, DOI 10.23919/DATE48585.2020.9116529
   Garofalo A, 2019, IEEE I C ELECT CIRC, P33, DOI [10.1109/icecs46596.2019.8965067, 10.1109/ICECS46596.2019.8965067]
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Gubbi J, 2013, FUTURE GENER COMP SY, V29, P1645, DOI 10.1016/j.future.2013.01.010
   Hadayeghparast S, 2022, IEEE INTERNET THINGS, V9, P15839, DOI 10.1109/JIOT.2022.3152850
   Imani M, 2020, IEEE T COMPUT AID D, V39, P2268, DOI 10.1109/TCAD.2019.2954472
   Imani M, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317785
   Imani M, 2019, ANN IEEE SYM FIELD P, P190, DOI 10.1109/FCCM.2019.00034
   Imani M, 2019, DES AUT TEST EUROPE, P126, DOI [10.23919/date.2019.8714821, 10.23919/DATE.2019.8714821]
   Imani M, 2018, DES AUT CON, DOI 10.1145/3195970.3196060
   Kazemi A, 2021, I SYMPOS LOW POWER E, DOI 10.1109/ISLPED52811.2021.9502498
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kundu S, 2020, IEEE T COMPUT, V69, P1045, DOI 10.1109/TC.2020.2972520
   Lin J, 2017, IEEE INTERNET THINGS, V4, P1125, DOI 10.1109/JIOT.2017.2683200
   Montagna F, 2018, DES AUT CON, DOI 10.1145/3195970.3196096
   Morris J., 2019, I SYMPOS LOW POWER E, P1, DOI [DOI 10.1109/islped.2019.8824908, 10.1109/ISLPED.2019.8824908, DOI 10.1109/ISLPED.2019.8824908]
   Morris J, 2022, IEEE T COMPUT AID D, V41, P897, DOI 10.1109/TCAD.2021.3069139
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paulin G, 2021, IEEE T VLSI SYST, V29, P1624, DOI 10.1109/TVLSI.2021.3093242
   Rahimi A, 2016, I SYMPOS LOW POWER E, P64, DOI 10.1145/2934583.2934624
   Reiss A., 2012, P 5 INT C PERV TECHN
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Taheri F., 2022, IEEE T CIRCUITS SY 1, V69, P1045
   Wang XY, 2020, IEEE INTERNET THINGS, V7, P4403, DOI 10.1109/JIOT.2020.2976702
   Waterman, 2011, UCBEECS201162
NR 42
TC 2
Z9 2
U1 1
U2 5
PD DEC 1
PY 2022
VL 9
IS 23
BP 24030
EP 24037
DI 10.1109/JIOT.2022.3191717
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Li, JY
   Wang, FG
   Araki, T
   Qiu, JD
AF Li, Jiayu
   Wang, Fugang
   Araki, Takuya
   Qiu, Judy
GP IEEE
TI Generalized Sparse Matrix-Matrix Multiplication for Vector Engines and
   Graph Applications
SO PROCEEDINGS OF MCHPC'19: 2019 IEEE/ACM WORKSHOP ON MEMORY CENTRIC HIGH
   PERFORMANCE COMPUTING (MCHPC)
DT Proceedings Paper
CT IEEE/ACM Workshop on Memory Centric High Performance Computing (MCHPC)
CY NOV 18, 2019
CL Denver, CO
DE Sparse Linear Algebra Kernel; NEC Vector Engine; Graph
AB Generalized sparse matrix-matrix multiplication (SpGEMM) is a key primitive kernel for many high-performance graph algorithms as well as for machine learning and data analysis algorithms. Although many SpGEMM algorithms have been proposed, such as ESC and SPA, there is currently no SpGEMM kernel optimized for vector engines (VEs). NEC SX-Aurora is the new vector computing system that can achieve high performance by leveraging high bandwidth memory of 1.2TB/s and long vector of VEs, where the execution of scientific applications is limited by memory bandwidth. In this paper, we demonstrate significant initial work of SpGEMM kernel for a vector engine and implement it to vectorize several essential graph analysis algorithms: Butterfly counting and Triangle counting. We propose a SpGEMM algorithm with a novel hybrid method based on sparse vectors and loop raking to maximize the length of vectorizable code for vector machine architectures. The experimental results show that the vector engine has advantages on more massive data sets. This work contributes to the high performance and portability of the SpGEMM kernel to a new family of heterogeneous computing systems, which is Vector Host (VH) equipped with different accelerators or VEs.
C1 [Li, Jiayu; Wang, Fugang; Qiu, Judy] Indiana Univ, Intelligent Syst Engn, Bloomington, IN 47405 USA.
   [Araki, Takuya] NEC Corp Ltd, Data Sci Res Labs, Yokohama, Kanagawa, Japan.
RP Li, JY (corresponding author), Indiana Univ, Intelligent Syst Engn, Bloomington, IN 47405 USA.
EM jl145@iu.edu; fuwang@indiana.edu; t-araki@dc.jp.nec.com;
   xqiu@indiana.edu
CR Afanasyev Ilya V., 2019, Parallel Computing Technologies. 15th International Conference, PaCT 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11657), P125, DOI 10.1007/978-3-030-25636-4_10
   Alon N, 2008, BIOINFORMATICS, V24, pI241, DOI 10.1093/bioinformatics/btn163
   [Anonymous], ARXIV10062183
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Battiston F, 2017, CHAOS, V27, DOI 10.1063/1.4979282
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   Chen L., 2019, ARXIV190304395
   Dalton S, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2699470
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049670
   Demouth Julien, 2012, GPU TECHN C
   GILBERT JR, 1992, SIAM J MATRIX ANAL A, V13, P333, DOI 10.1137/0613024
   Kepner J, 2011, SOFTW ENVIRON TOOLS, V22, P1, DOI 10.1137/1.9780898719918
   Komatsu Kazuhiko, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P685, DOI 10.1109/SC.2018.00057
   Liu WF, 2015, J PARALLEL DISTR COM, V85, P47, DOI 10.1016/j.jpdc.2015.06.010
   Nagasaka Y., 2017, P 46 INT C PAR PROC
   Sanei-Mehri SV, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2150, DOI 10.1145/3219819.3220097
   Stanley Richard P, 2013, SPRINGER, V20, P22
   Zagha M., 1991, Proceedings Supercomputing '91 (Cat. No.91CH3058-5), P712, DOI 10.1145/125826.126164
NR 18
TC 2
Z9 2
U1 0
U2 1
PY 2019
BP 33
EP 42
DI 10.1109/MCHPC49590.2019.00012
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Kwasniewska, A
   Raghava, S
   Davila, C
   Sevenier, M
   Gamba, D
   Ruminski, J
AF Kwasniewska, Alicja
   Raghava, Sharath
   Davila, Carlos
   Sevenier, Mikael
   Gamba, David
   Ruminski, Jacek
GP IEEE
TI Preferred Benchmarking Criteria for Systematic Taxonomy of Embedded
   Platforms (STEP) in Human System Interaction Systems
SO 2022 15TH INTERNATIONAL CONFERENCE ON HUMAN SYSTEM INTERACTION (HSI)
SE Conference on Human System Interaction
DT Proceedings Paper
CT 15th IEEE International Conference on Human System Interaction (HSI)
CY JUL 28-31, 2022
CL Trobe Univ, Melbourne, AUSTRALIA
HO Trobe Univ
DE embedded systems; benchmarking; system design; neural networks; machine
   learning
AB The rate of progress in the field of Artificial Intelligence (AI) and Machine Learning (ML) has significantly increased over the past ten years and continues to accelerate. Since then, AI has made the leap from research case studies to real production ready applications. The significance of this growth cannot be undermined as it catalyzed the very nature of computing. Conventional platforms struggle to achieve greater performance and efficiency, what causes a surging demand for innovative AI accelerators, specialized platforms and purpose-built computes. At the same time, it is required to provide solutions for assessment of ML platform performance in a reproducible and unbiased manner to be able to provide a fair comparison of different products. This is especially valid for Human System Interaction (HSI) systems that require specific data handling for low latency responses in emergency situations or to improve user experience, as well as for preserving data privacy and security by processing it locally. Taking it into account, this work presents a comprehensive guideline on preferred benchmarking criteria for evaluation of ML platforms that include both lower level analysis of ML models and system-level evaluation of the entire pipeline. In addition, we propose a Systematic Taxonomy of Embedded Platforms (STEP) that can be used by the community and customers for better selection of specific ML hardware consistent with their needs for better design of ML-based HSI solutions.
C1 [Kwasniewska, Alicja; Raghava, Sharath; Davila, Carlos; Sevenier, Mikael; Gamba, David] SiMa Technol, San Jose, CA 95110 USA.
   [Ruminski, Jacek] Gdansk Univ Technol, Gdansk, Poland.
RP Kwasniewska, A (corresponding author), SiMa Technol, San Jose, CA 95110 USA.
EM alicja@sima.ai; sharath.raghava@sima.ai; carlos@sima.ai;
   sevenier@sima.ai; david.gamba@sima.ai; jacek.ruminski@pg.edu.pl
CR Ajani TS, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21134412
   Banbury Colby R., 2020, BENCHMARKING TINYML
   Baruffaldi S., 2020, IDENTIFYING MEASURIN
   Basicmi, 2022, AI CHIP ICS IPS
   Batarseh FA, 2020, J BIG DATA-GER, V7, DOI 10.1186/s40537-020-00315-8
   Batra G., 2019, ARTIF INTELL, V2
   Beyer D, 2019, INT J SOFTW TOOLS TE, V21, P1, DOI 10.1007/s10009-017-0469-y
   Burr GW, 2022, IEEE DES TEST, V39, P18, DOI 10.1109/MDAT.2021.3063366
   Casalino L, 2021, INT J HIGH PERFORM C, V35, P432, DOI 10.1177/10943420211006452
   Deng CY, 2020, ISCIENCE, V23, DOI 10.1016/j.isci.2020.101656
   Duan KW, 2019, IEEE I CONF COMP VIS, P6568, DOI 10.1109/ICCV.2019.00667
   Famili A., 1997, Intelligent Data Analysis, V1
   H. AI, 2019, HIGH LEV EXP GROUP A
   Hamdan S, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226441
   Henderson P, 2017, LECT NOTES COMPUT SC, V10115, P198, DOI 10.1007/978-3-319-54193-8_13
   Jacob B, 2017, Arxiv, DOI [arXiv:1712.05877, 10.48550/ARXIV.1712.05877]
   Kaczmarek M, 2012, J MED IMAG HEALTH IN, V2, P56, DOI 10.1166/jmihi.2012.1061
   Krishnamoorthi R, 2018, Arxiv, DOI arXiv:1806.08342
   Kwasniewska A, 2019, IEEE IND ELEC, P96, DOI 10.1109/IECON.2019.8927153
   Kwasniewska A, 2020, ENG APPL ARTIF INTEL, V87, DOI 10.1016/j.engappai.2019.103263
   Kwasniewska A, 2017, C HUM SYST INTERACT, P41, DOI 10.1109/HSI.2017.8004993
   Lewandowska M., 2011, 2011 Federated Conference on Computer Science and Information Systems (FedCSIS), P405
   Luo H, 2019, IEEE COMPUT SOC CONF, P1487, DOI 10.1109/CVPRW.2019.00190
   Mao YZ, 2021, WIREL COMMUN MOB COM, V2021, DOI 10.1155/2021/6635638
   Paisitkriangkrai S, 2015, PROC CVPR IEEE, P1846, DOI 10.1109/CVPR.2015.7298794
   Perpetuini D, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063286
   Rai R, 2021, INT J PROD RES, V59, P4773, DOI 10.1080/00207543.2021.1956675
   Reddi VJ, 2020, ANN I S COM, P446, DOI 10.1109/ISCA45697.2020.00045
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Sakuma Y, 2021, Arxiv, DOI arXiv:2103.11704
   Shafique M, 2021, Arxiv, DOI arXiv:2109.09829
   Shahriari Kyarash, 2017, 2017 IEEE Canada International Humanitarian Technology Conference (IHTC), P197, DOI 10.1109/IHTC.2017.8058187
   Shalf J, 2020, PHILOS T R SOC A, V378, DOI 10.1098/rsta.2019.0061
   Suo Kun, 2021, SAC '21: Proceedings of the 36th Annual ACM Symposium on Applied Computing, P1182, DOI 10.1145/3412841.3441993
   Szankin M, 2019, C HUM SYST INTERACT, P28, DOI 10.1109/hsi47298.2019.8942636
   Theissler A, 2021, RELIAB ENG SYST SAFE, V215, DOI 10.1016/j.ress.2021.107864
   Wei YC, 2020, COMPUT INTEL NEUROSC, V2020, DOI 10.1155/2020/8875910
   Wojke N, 2017, IEEE IMAGE PROC, P3645, DOI 10.1109/ICIP.2017.8296962
   Wolf S, 2021, REMOTE SENS-BASEL, V13, DOI 10.3390/rs13163088
   Wu N, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3418498
   Zhou Y, 2020, 2020 INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE AND COMPUTER ENGINEERING (ICAICE 2020), P494, DOI 10.1109/ICAICE51518.2020.00102
   Zitouni H, 2022, J KING SAUD UNIV-COM, V34, P1124, DOI 10.1016/j.jksuci.2020.04.012
NR 42
TC 1
Z9 1
U1 0
U2 0
PY 2022
WC Computer Science, Cybernetics
DA 2023-11-11
ER

PT C
AU Golnari, PA
   Malik, S
AF Golnari, Pareesa Ameneh
   Malik, Sharad
GP IEEE
TI Evaluating Matrix Representations for Error-Tolerant Computing
SO PROCEEDINGS OF THE 2017 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 20th Conference and Exhibition on Design, Automation and Test in Europe
   (DATE)
CY MAR 27-31, 2017
CL EPFL Campus, Lausanne, SWITZERLAND
HO EPFL Campus
AB 'We propose a methodology to determine the suitability of different data representations in terms of their errortolerance for a given application with accelerator-based computing. This methodology helps match the characteristics of a representation to the data access patterns in an application. For this, we first identify a benchmark of key kernels from linear algebra that can be used to construct applications of interest using any of several widely used data representations. This is then used in an experimental framework for studying the error tolerance of a specific data format for an application.
   As case studies, we evaluate the error-tolerance of seven dataformats on sparse matrix to vector multiplication, diagonal add, and two machine learning applications i) principal component analysis (PCA), which is a statistical technique widely used in data analysis and ii) movie recommendation system with Restricted Boltzmann Machine (RBM) as the core. We observe that the Dense format behaves well for complicated data accesses such as diagonal accessing but is poor in utilizing local memory. Sparse formats with simpler addressing methods and a careful selection of stored information, e.g., CRS and ELLPACK, demonstrate a better error-tolerance for most of our target applications.
C1 [Golnari, Pareesa Ameneh; Malik, Sharad] Princeton Univ, Princeton, NJ 08544 USA.
RP Golnari, PA (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
EM amene@princeton.edu; sharad@princeton.edu
CR [Anonymous], 1994, TECHNICAL REPORT
   [Anonymous], 2007, ICML
   [Anonymous], 2003, CITESEERX
   Borkar S, 2005, IEEE MICRO, V25, P10, DOI 10.1109/MM.2005.110
   Cota E. G., 2015, DAC
   Golnari A., 2015, ICCAD
   Hugues M. R., 2010, HPCC
   Lee K.-H., 2013, SIPS
   Thomas S., 2014, IISWC
   Yetim Y., 2013, DATE
NR 10
TC 1
Z9 1
U1 0
U2 1
PY 2017
BP 1659
EP 1662
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mitchell, R
   Frank, E
   Holmes, G
AF Mitchell, Rory
   Frank, Eibe
   Holmes, Geoffrey
TI GPUTreeShap: massively parallel exact calculation of SHAP scores for
   tree ensembles
SO PEERJ COMPUTER SCIENCE
DT Article
DE Shapley values; GPU computing; Interpretability
ID ALGORITHMS
AB SHapley Additive exPlanation (SHAP) values (Lundberg & Lee, 2017) provide a game theoretic interpretation of the predictions of machine learning models based on Shapley values (Shapley, 1953). While exact calculation of SHAP values is computationally intractable in general, a recursive polynomial-time algorithm called TreeShap (Lundberg et al., 2020) is available for decision tree models. However, despite its polynomial time complexity, TreeShap can become a significant bottleneck in practical machine learning pipelines when applied to large decision tree ensembles. Unfortunately, the complicated TreeShap algorithm is difficult to map to hardware accelerators such as GPUs. In this work, we present GPUTreeShap, a reformulated TreeShap algorithm suitable for massively parallel computation on graphics processing units. Our approach first preprocesses each decision tree to isolate variable sized sub-problems from the original recursive algorithm, then solves a bin packing problem, and finally maps sub-problems to single-instruction, multiple-thread (SIMT) tasks for parallel execution with specialised hardware instructions. With a single NVIDIA Tesla V100-32 GPU, we achieve speedups of up to 19x for SHAP values, and speedups of up to 340x for SHAP interaction values, over a state-of-the-art multi-core CPU implementation executed on two 20-core Xeon E5-2698 v4 2.2 GHz CPUs. We also experiment with multi-GPU computing using eight V100 GPUs, demonstrating throughput of 1.2 M rows per second-equivalent CPU-based performance is estimated to require 6850 CPU cores.
C1 [Mitchell, Rory] Nvidia, Santa Clara, CA 95051 USA.
   [Frank, Eibe; Holmes, Geoffrey] Univ Waikato, Hamilton, New Zealand.
RP Mitchell, R (corresponding author), Nvidia, Santa Clara, CA 95051 USA.
EM ramitchellnz@gmail.com
CR Anderson R, 1984, 1003 STANF U COMP SC
   ANDERSON RJ, 1989, INFORM COMPUT, V82, P262, DOI 10.1016/0890-5401(89)90003-5
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 2010, P 2010 ACM SIGMOD IN, DOI DOI 10.1145/1807167.1807207
   Blackard JA, 1998, THESIS COLARADO STAT
   Boyer V, 2012, COMPUT OPER RES, V39, P42, DOI 10.1016/j.cor.2011.03.014
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chetlur S, 2014, ARXIV14100759, DOI [10. 48550/arXiv.1410.0759, DOI 10.48550/ARXIV.1410.0759]
   Coffman Jr E. G., 1997, APPROXIMATION ALGORI, P46
   CONNOLLY D, 1991, J OPER RES SOC, V42, P513
   Dorogush A.V., 2018, CATBOOST GRADIENT BO, DOI DOI 10.48550/ARXIV.1810.11363
   Fang B, 2005, IEEE INT SYMP CIRC S, P1126
   Fatahalian Kayvon, 2004, P ACM SIGGRAPH EUROG, P133
   Fujimoto K, 2006, GAME ECON BEHAV, V55, P72, DOI 10.1016/j.geb.2005.03.002
   Garey M. R., 1979, Computers and intractability. A guide to the theory of NP-completeness
   Green Oded, 2012, INT C SUPERCOMPUTING, P331
   Guidotti R, 2019, ACM COMPUT SURV, V51, DOI 10.1145/3236009
   Hall Jesse D., 2003, CACHE BANDWIDTH AWAR
   Harris M, 2005, GPU GEMS, V2, P547
   Jiang CH, 2005, PACT 2005: 14TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P185
   JOHNSON DS, 1974, J COMPUT SYST SCI, V8, P272, DOI 10.1016/S0022-0000(74)80026-7
   Ke GL, 2017, ADV NEUR IN, V30
   Kohavi R., 1996, KDD-96 Proceedings. Second International Conference on Knowledge Discovery and Data Mining, P202
   Liu Y, 2006, LECT NOTES COMPUT SC, V3994, P188
   Lundberg SM, 2017, ADV NEUR IN, V30
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Mitchell R, 2017, PEERJ COMPUT SCI, DOI 10.7717/peerj-cs.127
   Moreland K., 2003, P ACM SIGGRAPHEUROGR, P112
   NVIDIA Corporation, 2020, CUDA C PROGRAMMING G
   Pace RK, 1997, STAT PROBABIL LETT, V33, P291, DOI 10.1016/s0167-7152(96)00140-x
   Perry M, 2014, J PHYS CONF SER, V513, DOI 10.1088/1742-6596/513/2/022027
   Quinlan J.R., 1993, C4 5 PROGRAMS MACHIN
   Ribeiro MT, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1135, DOI 10.1145/2939672.2939778
   Selvaraju RR, 2017, IEEE I CONF COMP VIS, P618, DOI 10.1109/ICCV.2017.74
   Shapley L.S, 2016, CLASSICS GAME THEORY, V17, DOI [10.1515/9781400881970-018, DOI 10.1515/9781400881970-018]
   Sharp T., 2012, US Patent, Patent No. [8,290,882, 8290882]
   Sharp T, 2008, LECT NOTES COMPUT SC, V5305, P595, DOI 10.1007/978-3-540-88693-8_44
   Si S., 2017, GPU ACCELERATION LAR, DOI [10.48550/arXiv.1706.08359, DOI 10.48550/ARXIV.1706.08359]
   Steflen P, 2010, LECT NOTES COMPUT SC, V6068, P290
   Xiao H, 2017, ARXIV, DOI DOI 10.48550/ARXIV.1708.07747
NR 40
TC 10
Z9 10
U1 4
U2 11
PD APR 5
PY 2022
VL 8
AR e880
DI 10.7717/peerj-cs.880
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Gandhi, J
   Shekhawat, D
   Santosh, M
   Pandey, JG
AF Gandhi, Jugal
   Shekhawat, Diksha
   Santosh, M.
   Pandey, Jai Gopal
TI Logic locking for IP security: A comprehensive analysis on challenges,
   techniques, and trends
SO COMPUTERS & SECURITY
DT Article
DE IP piracy and IP security; Logic locking; Logic obfuscation;
   Boolean-SATisfiability (SAT) attack; Machine learning-based attacks;
   Graph neural network (GNN)
ID HARDWARE ACCELERATORS; INTEGRATED-CIRCUITS; SUPPLY-CHAIN; LOW-COST;
   OBFUSCATION; ATTACK; SCAN; FUNCTIONALITY; METHODOLOGY; PARADIGM
AB A substantial part of the Integrated Circuit (IC) supply chain that involves semiconductor fabrication, packaging, and testing has shifted globally to minimize IC costs and satisfy market needs. This globalized supply chain and the presence of non-trusted entities have raised concerns about security issues. The fabless business model has resulted in numerous vulnerabilities. Logic Locking (LL) has emerged as a potential/versatile technique utilized by industries/academia. LL protects IPs integrated with System-onChip (SoC) designs from hardware threats throughout the IC supply chain. The applicability, feasibility, and effectiveness of LL have been investigated for more than a decade. The research interests involve metrics that evaluate the consequences of locking at multiple levels of abstraction, tampering, threat model description, machine learning implementation, and resiliency against physical attacks. However, complex logical and physical vulnerabilities that increase in effectiveness simultaneously as LL prevention/mitigation solutions have challenged the trustworthiness and resilience of modern LL solutions. We have classified known defenses and vulnerabilities by explaining measurements and fundamentals of LL, assumptions, limitations, and emerging technologies that highlight needs and guide future research. This survey paper aims to enable IP owners, SoC engineers, and researchers to explore and determine stateof-the-art logic locking techniques for further evaluation and research.(c) 2023 Elsevier Ltd. All rights reserved.
C1 [Gandhi, Jugal; Shekhawat, Diksha; Santosh, M.; Pandey, Jai Gopal] Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.
   [Gandhi, Jugal; Shekhawat, Diksha; Santosh, M.; Pandey, Jai Gopal] CSIR, Cent Elect Engn Res Inst CEERI, Pilani 333031, Rajasthan, India.
RP Gandhi, J (corresponding author), Acad Sci & Innovat Res AcSIR, Ghaziabad 201002, Uttar Pradesh, India.; Gandhi, J (corresponding author), CSIR, Cent Elect Engn Res Inst CEERI, Pilani 333031, Rajasthan, India.
EM jugalacsir@ceeri.res.in; jai@ceeri.res.in
CR Alam M, 2019, PR GR LAK SYMP VLSI, P105, DOI 10.1145/3299874.3318001
   Alaql A, 2022, IEEE T COMPUT AID D, V41, P854, DOI 10.1109/TCAD.2021.3075939
   Alaql A, 2021, IEEE T VLSI SYST, V29, P1529, DOI 10.1109/TVLSI.2021.3089555
   Alaql A, 2021, IEEE T INF FOREN SEC, V16, P3724, DOI 10.1109/TIFS.2021.3092135
   Alaql A, 2019, PROCEEDINGS OF THE 2019 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM (ASIANHOST)
   Alkabani YM, 2007, USENIX ASSOCIATION PROCEEDINGS OF THE 16TH USENIX SECURITY SYMPOSIUM, P291
   Alrahis L., 2019, ARXIV
   Alrahis L., 2021, ARXIV
   Alrahis L, 2021, Arxiv, DOI arXiv:2111.07062
   Alrahis L, 2022, IEEE T EMERG TOP COM, V10, P1575, DOI 10.1109/TETC.2021.3108487
   Alrahis L, 2022, IEEE T CIRCUITS-II, V69, P1602, DOI 10.1109/TCSII.2021.3113035
   Alrahis L, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P780, DOI 10.23919/DATE51398.2021.9474039
   Alrahis L, 2021, IEEE T INF FOREN SEC, V16, P2508, DOI 10.1109/TIFS.2021.3057576
   Amirov SF, 2020, 2020 INTERNATIONAL CONFERENCE ON INDUSTRIAL ENGINEERING, APPLICATIONS AND MANUFACTURING (ICIEAM), DOI 10.1109/icieam48468.2020.9112045
   [Anonymous], 2013, P 8 ANN CYBER SECURI, DOI DOI 10.1145/2459976.2459985
   [Anonymous], 2015, AUTOMOTIVE NEWS
   [Anonymous], 2019, MAXIM INTEGRATED
   [Anonymous], 2012, INFORM TECHNOLOGY SE
   [Anonymous], 2014, NXP SMARTMXTM HIGH S
   [Anonymous], 1971, 12 ANN S SWITCH AUT, DOI DOI 10.1109/SWAT.1971.10
   Apple Secure Enclave (SEP), US
   Azar K., 2018, P IACR T CRYPT HARDW, V1, P97
   Baumgarten A, 2010, IEEE DES TEST COMPUT, V27, P66, DOI 10.1109/MDT.2010.24
   Bhandari J, 2021, Arxiv, DOI arXiv:2111.04222
   Bhandari J, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643548
   Bhunia S., 2018, HARDWARE SECURITY HA
   Bossuet L., 2017, FDN HARDWARE IP PROT
   Caldwell AE, 2004, IEEE T COMPUT AID D, V23, P208, DOI 10.1109/TCAD.2003.822126
   Chakraborty A, 2020, IEEE T COMPUT AID D, V39, P1952, DOI 10.1109/TCAD.2019.2944586
   Chakraborty A, 2018, DES AUT CON, DOI 10.1145/3195970.3196058
   Chakraborty P, 2018, PROCEEDINGS OF THE 2018 ASIAN HARDWARE ORIENTED SECURITY AND TRUST SYMPOSIUM (ASIANHOST), P56, DOI 10.1109/AsianHOST.2018.8607163
   Chakraborty RS, 2009, IEEE T COMPUT AID D, V28, P1493, DOI 10.1109/TCAD.2009.2028166
   Chakravarty P, 2019, IDEA OF THE UNIVERSITY: HISTORIES AND CONTEXTS, P181, DOI 10.1109/HST.2019.8741028
   Chaudhuri P.P., 1997, ADDITIVE CELLULAR AU, V43
   Chen HL, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942134
   Chiang HY, 2020, IEEE T COMPUT AID D, V39, P2178, DOI 10.1109/TCAD.2019.2960351
   Colombier Brice, 2017, 2017 IEEE Computer Society Annual Symposium on VLSI (ISVLSI). Proceedings, P98, DOI 10.1109/ISVLSI.2017.26
   Colombier B, 2014, IET COMPUT DIGIT TEC, V8, P274, DOI 10.1049/iet-cdt.2014.0028
   Corno F, 2000, IEEE DES TEST COMPUT, V17, P44, DOI 10.1109/54.867894
   Critical Program Information (CPI), ID PROT RES DEV TEST
   Daniel B., 2020, COUNTERFEIT ELECT PA
   Darjani Armin, 2022, GLSVLSI '22: Proceedings of the Great Lakes Symposium on VLSI 2022, P147, DOI 10.1145/3526241.3530371
   Dey S., 2022, SECURE PHYS DESIGN
   Diaz-Rizo A.R., 2022, IEEE T CIRCUITS-I
   Dofe J, 2018, IEEE T COMPUT AID D, V37, P273, DOI 10.1109/TCAD.2017.2697960
   Dupuis S, 2019, J ELECTRON TEST, V35, P273, DOI 10.1007/s10836-019-05800-4
   Dupuis S, 2014, IEEE INT ON LINE, P49, DOI 10.1109/IOLTS.2014.6873671
   Duvalsaint D, 2019, INT TEST CONF P, DOI 10.1109/itc44170.2019.9000130
   Duvalsaint D, 2019, 2019 IEEE INTERNATIONAL TEST CONFERENCE IN ASIA (ITC-ASIA 2019), P97, DOI 10.1109/ITC-Asia.2019.00030
   Editorial, 2016, TOP 10 FABLESS IC DE
   EETimes, 2012, IHS COUNTERFEIT PART
   El Massad M, 2017, Arxiv, DOI arXiv:1703.10187
   El Massad M, 2015, 22ND ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2015), DOI 10.14722/ndss.2015.23218
   El Massad M, 2017, ICCAD-IEEE ACM INT, P33, DOI 10.1109/ICCAD.2017.8203757
   Elshamy M, 2021, IEEE T VLSI SYST, V29, P2130, DOI 10.1109/TVLSI.2021.3117584
   Elsharief S., 2022, 20221752 CRYPT EPRIN
   False, 2019, DS3660 DEEPCOVER SEC
   Felton D., 2021, WHAT IS ARM TRUSTZON
   Fyrbiak Marc, 2018, IACR T CRYPTOGR HARD, V2018, P293
   Gdi T., 2020, DARPA SELECTS TEAMS
   Gilmer J, 2017, Arxiv, DOI [arXiv:1704.01212, DOI 10.48550/ARXIV.1704.01212]
   Guin U, 2018, IEEE T VLSI SYST, V26, P818, DOI 10.1109/TVLSI.2018.2797019
   Guin U, 2014, J ELECTRON TEST, V30, P9, DOI 10.1007/s10836-013-5430-8
   Han ZK, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1055
   hensoldt- cyber, MIG V HENSOLDT CYBER
   Hu B, 2019, PR GR LAK SYMP VLSI, P171, DOI 10.1145/3299874.3317992
   Hu YH, 2021, Arxiv, DOI arXiv:2108.04892
   intel, INTEL TRUSTED EXECUT
   intel, ANTITAMPER CAPABILIT
   iwls, IWLS 20 05 BENCHMARK
   Jain A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL CONFERENCE ON PHYSICAL ASSURANCE AND INSPECTION ON ELECTRONICS (PAINE), DOI 10.1109/PAINE49178.2020.9337734
   Jayasankaran NG, 2022, IEEE T EMERG TOP COM, V10, P386, DOI 10.1109/TETC.2020.3025561
   Kahng AB, 1998, 1998 DESIGN AUTOMATION CONFERENCE, PROCEEDINGS, P776, DOI 10.1109/DAC.1998.724576
   Kahng AB, 1998, 1998 DESIGN AUTOMATION CONFERENCE, PROCEEDINGS, P782, DOI 10.1109/DAC.1998.724577
   Kamali H. M., 2020, P 2020 GREAT LAK S V, DOI DOI 10.1145/3386263.3407655
   Kamali H. M., 2022, ADV LOGIC LOCKING PR
   Kamali HM, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415667
   Kamali HM, 2018, IEEE COMP SOC ANN, P405, DOI 10.1109/ISVLSI.2018.00080
   Karfa C, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P32, DOI 10.23919/DATE51398.2021.9473927
   Karmakar R, 2018, Arxiv, DOI [arXiv:1801.04961, 10.48550/arXiv.1801.04961]
   Karmakar R, 2021, IEEE T EMERG TOP COM, V9, P2109, DOI 10.1109/TETC.2019.2963094
   Karmakar R, 2020, DES AUT TEST EUROPE, P448, DOI 10.23919/DATE48585.2020.9116259
   Karmakar R, 2017, I CONF VLSI DESIGN, P429, DOI 10.1109/VLSID.2017.29
   Karousos N, 2017, IEEE INT ON LINE, P221, DOI 10.1109/IOLTS.2017.8046226
   Karri R, 2010, COMPUTER, V43, P39, DOI 10.1109/MC.2010.299
   Kennedy J, 1995, 1995 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS PROCEEDINGS, VOLS 1-6, P1942, DOI 10.1109/icnn.1995.488968
   Keshavarz S., 2018, J HARDWARE SYSTEMS S, V2, P214
   Kirk J., 2013, 3 INDICTED ALLEGED S
   Kirovski D, 2003, IEEE T COMPUT AID D, V22, P1277, DOI 10.1109/TCAD.2003.816208
   Kocher P, 2019, P IEEE S SECUR PRIV, P1, DOI 10.1109/SP.2019.00002
   Koushanfar F, 2001, DES AUT CON, P490, DOI 10.1109/DAC.2001.935558
   Koushanfar F., 2017, HARDWARE PROTECTION, P161, DOI DOI 10.1007/978-3-319-49019-9_7
   Koushanfar F, 2012, IEEE T INF FOREN SEC, V7, P51, DOI 10.1109/TIFS.2011.2163307
   Hamilton WL, 2018, Arxiv, DOI [arXiv:1706.02216, DOI 10.48550/ARXIV.1706.02216]
   Lee J, 2005, INT SYM DEFEC FAU TO, P51
   Lee J, 2007, IEEE T DEPEND SECURE, V4, P325, DOI 10.1109/TDSC.2007.70215
   Lee J, 2006, IEEE VLSI TEST SYMP, P94, DOI 10.1109/VTS.2006.7
   Leonhard J, 2021, IEEE T COMPUT AID D
   Leonhard J, 2019, DES AUT TEST EUROPE, P84, DOI [10.23919/date.2019.8715043, 10.23919/DATE.2019.8715043]
   Li L, 2022, DES AUT TEST EUROPE, P1323, DOI 10.23919/DATE54114.2022.9774729
   Li L, 2021, 2021 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P292, DOI 10.1109/HOST49136.2021.9702288
   Li L, 2019, DES AUT TEST EUROPE, P540, DOI [10.23919/DATE.2019.8714955, 10.23919/date.2019.8714955]
   Li M, 2019, IEEE T COMPUT AID D, V38, P1399, DOI 10.1109/TCAD.2017.2750088
   Limaye N, 2021, DES AUT CON, P91, DOI 10.1109/DAC18074.2021.9586314
   Limaye N, 2022, IEEE T INF FOREN SEC, V17, P744, DOI 10.1109/TIFS.2022.3149147
   Limaye N, 2021, IEEE T COMPUT AID D, V40, P1740, DOI 10.1109/TCAD.2020.3029133
   Limaye N, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942047
   Limaye N, 2020, DES AUT TEST EUROPE, P270, DOI 10.23919/DATE48585.2020.9116197
   Lipp M, 2018, Arxiv, DOI [arXiv:1801.01207, 10.1145/3357033]
   Liu B, 2016, INTEGRATION, V55, P438, DOI 10.1016/j.vlsi.2016.03.002
   Liu YT, 2020, INT SYM QUAL ELECT, P199, DOI [10.1109/isqed48828.2020.9136983, 10.1109/ISQED48828.2020.9136983]
   Mankali L, 2023, IEEE T INF FOREN SEC, V18, P304, DOI 10.1109/TIFS.2022.3218429
   maximintegrated, DEEPCOVER SECURITY M
   McMillan KL, 2003, LECT NOTES COMPUT SC, V2725, P1
   Meade T, 2017, IEEE INT SYMP CIRC S
   Mellor J, 2021, 2021 IEEE VIRTUAL IEEE INTERNATIONAL SYMPOSIUM ON TECHNOLOGIES FOR HOMELAND SECURITY, DOI 10.1109/HST53381.2021.9619800
   Miller B. L., 1995, Complex Systems, V9, P193
   Mishra P., 2017, HARDWARE IP SECURITY, DOI 10.1007/978-3-319-49025-0
   Mohan P, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1186, DOI 10.23919/DATE51398.2021.9473910
   Mutschler A. S., 2008, SEMI SEMIEQUIPMENT I
   Muttaki MR, 2021, DES AUT CON, P79, DOI 10.1109/DAC18074.2021.9586159
   Nguyen QL, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11233906
   Ojo B., 2013, XILINX SUES FLEXTRON
   Patnaik S, 2022, IEEE T INF FOREN SEC, V17, P3290, DOI 10.1109/TIFS.2022.3207361
   Patnaik S, 2020, IEEE T COMPUT AID D, V39, P4466, DOI 10.1109/TCAD.2020.2981034
   Perez TD, 2020, IEEE ACCESS, V8, P184013, DOI 10.1109/ACCESS.2020.3029339
   Pilato C, 2021, Arxiv, DOI arXiv:2010.05344
   Pilato C, 2018, DES AUT CON, DOI 10.1145/3195970.3196126
   Pilato C, 2018, IEEE EMBED SYST LETT, V10, P77, DOI 10.1109/LES.2017.2774800
   Plaza SM, 2015, IEEE T COMPUT AID D, V34, P961, DOI 10.1109/TCAD.2015.2404876
   pld, INDEX MAKSIMBENCHMAR
   Potluri S., 2020, CORRARXIV, V2005, P13032
   Press R., 2021, HARDWARE ROOT TRUST
   qualcomm, QUALCOMM SECURITY MO
   Rahman MS, 2022, PROCEEDINGS OF THE 59TH ACM/IEEE DESIGN AUTOMATION CONFERENCE, DAC 2022, P775, DOI 10.1145/3489517.3530542
   Rahman MS, 2021, ACM T DES AUTOMAT EL, V26, DOI 10.1145/3444960
   Rajendran J., 2013, P 2013 ACM SIGSAC C, P709, DOI [DOI 10.1145/2508859.2516656, 10.1145/2508859.2516656]
   Rajendran J, 2015, IEEE T COMPUT, V64, P410, DOI 10.1109/TC.2013.193
   Rajendran J, 2014, P IEEE, V102, P1266, DOI 10.1109/JPROC.2014.2332154
   Rajendran J, 2012, DES AUT CON, P83
   Rajendran R, 2013, 2013 13TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS (ITST), P1, DOI 10.1109/ITST.2013.6685512
   Rambus, 2020, CRYPTOMANAGER PROVIS
   Rezaei A, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P358, DOI 10.1145/3287624.3287691
   Rezaei A, 2018, DES AUT TEST EUROPE, P85, DOI 10.23919/DATE.2018.8341984
   Rizo A.R.D., 2022, IEEE T CIRCUITS-II
   Roshanisefat S., 2021, RANE OPEN SOURCE FOR, P221
   Roshanisefat S., 2020, IEEE VLSI TEST SYMP, p2002.07857
   Roshanisefat Shervin, 2018, Arxiv, DOI arXiv:1804.09162
   Roshanisefat S, 2020, IEEE T VLSI SYST, V28, P954, DOI 10.1109/TVLSI.2020.2968552
   Rostami M, 2014, P IEEE, V102, P1283, DOI 10.1109/JPROC.2014.2335155
   Roy JA, 2008, DES AUT TEST EUROPE, P948
   Saha A, 2021, IEEE T COMPUT AID D, V40, P2445, DOI 10.1109/TCAD.2021.3050035
   Salmani H, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P471, DOI 10.1109/ICCD.2013.6657085
   Scarselli F, 2009, IEEE T NEURAL NETWOR, V20, P61, DOI 10.1109/TNN.2008.2005605
   Selsam D, 2019, Arxiv, DOI arXiv:1802.03685
   Sengupta A., 2021, IACR T CRYPTOGRAPHIC, P418, DOI DOI 10.46586/TCHES.V2021.I3.418-440
   Sengupta A, 2020, IEEE T COMPUT AID D, V39, P4439, DOI 10.1109/TCAD.2020.2968898
   Sengupta A, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3243467
   Sengupta A, 2018, IEEE VLSI TEST SYMP
   Shakya B., 2020, IACR T CRYPTOGRAPHIC, P175
   Shakya B., 2017, J HARDWARE SYSTEMS S, DOI DOI 10.1007/S41635-017-0001-6
   Shakya B., 2017, HARDWARE PROTECTION, P3
   Shamsi K, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942049
   Shamsi K, 2018, PR GR LAK SYMP VLSI, P147, DOI 10.1145/3194554.3194580
   Shamsi K, 2019, DES AUT TEST EUROPE, P534, DOI [10.23919/DATE.2019.8715053, 10.23919/date.2019.8715053]
   Shamsi K, 2019, IEEE T INF FOREN SEC, V14, P347, DOI 10.1109/TIFS.2018.2850319
   Shamsi K, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P173, DOI 10.1145/3060403.3060458
   Shamsi K, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P95, DOI 10.1109/HST.2017.7951805
   Shen YQ, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P657, DOI 10.1145/3287624.3287670
   Shen YQ, 2018, DES AUT TEST EUROPE, P629, DOI 10.23919/DATE.2018.8342086
   Shen YQ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P179, DOI 10.1145/3060403.3060469
   Sherstinsky A, 2021, Arxiv, DOI arXiv:1808.03314
   Shihab MM, 2019, DES AUT TEST EUROPE, P528, DOI [10.23919/date.2019.8714856, 10.23919/DATE.2019.8714856]
   Sisejkovic D., 2021, ARXIV
   Sisejkovic D., 2022, DESIGNING TRUSTWORTH
   Sisejkovic D, 2022, Arxiv, DOI arXiv:2203.05399
   Sisejkovic D, 2021, Arxiv, DOI arXiv:2107.08695
   Sisejkovic D, 2020, Arxiv, DOI arXiv:2011.10389
   Sisejkovic D, 2021, IEEE INT CONF VLSI, P180, DOI 10.1109/VLSI-SoC53125.2021.9606998
   Sisejkovic D, 2018, 2018 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION (SAMOS XVIII), P179, DOI 10.1145/3229631.3229636
   Skudlarek JP, 2016, COMPUTER, V49, P28, DOI 10.1109/MC.2016.243
   Sorensson N., 2005, INT C THEOR APPL SAT
   Staff R., 2016, EPIC SYSTEMS WINS 94
   STM32Trust, US
   Subramanyan P, 2015, 2015 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P137, DOI 10.1109/HST.2015.7140252
   Sweeney J., 2020, P 2020 IEEE INT S HA, V2005, P10649
   synopsys, SECURITY IP CRYPTOGR
   Technologies Ag I., OPTIGA TRUST X SLS 3
   Tehranipoor F, 2019, PR GR LAK SYMP VLSI, P335, DOI 10.1145/3299874.3318031
   Tehranipoor M, 2012, INTRODUCTION TO HARDWARE SECURITY AND TRUST, P1, DOI 10.1007/978-1-4419-8080-9
   Torrance R, 2011, DES AUT CON, P333
   Tuyls P, 2006, LECT NOTES COMPUT SC, V4249, P369
   Vaidyanathan K, 2014, 2014 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2014.6855559
   Veli ckovi c P., 2018, GRAPH ATTENTION NETW, V1710, P10903
   Wang XX, 2018, IEEE T COMPUT AID D, V37, P1867, DOI 10.1109/TCAD.2017.2772817
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Xie Y, 2019, IEEE T COMPUT AID D, V38, P199, DOI 10.1109/TCAD.2018.2801220
   Xie Y, 2017, DES AUT CON, DOI 10.1145/3061639.3062226
   Xu XL, 2017, LECT NOTES COMPUT SC, V10529, P189, DOI 10.1007/978-3-319-66787-4_10
   Yang FF, 2019, IEEE T INF FOREN SEC, V14, P2778, DOI 10.1109/TIFS.2019.2904838
   Yang S., 1991, LOGIC SYNTHESIS OPTI
   Yang XM, 2022, IEEE T COMPUT AID D, V41, P29, DOI 10.1109/TCAD.2021.3053912
   Yasin M., 2019, TRUSTWORTHY HARDWARE
   Yasin M, 2015, INT SYM DEFEC FAU TO, P97, DOI 10.1109/DFT.2015.7315143
   Yasin M, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942150
   Yasin M, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967012
   Yasin M, 2020, IEEE T EMERG TOP COM, V8, P517, DOI 10.1109/TETC.2017.2740364
   Yasin M, 2017, IEEE INT CONF VLSI, P237
   Yasin M, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1601, DOI 10.1145/3133956.3133985
   Yasin M, 2017, 2017 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P166, DOI 10.1109/HST.2017.7951830
   Yasin M, 2017, ASIA S PACIF DES AUT, P342, DOI 10.1109/ASPDAC.2017.7858346
   Yasin M, 2016, IEEE T COMPUT AID D, V35, P1411, DOI 10.1109/TCAD.2015.2511144
   Yasin M, 2016, PROCEEDINGS OF THE 2016 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P236, DOI 10.1109/HST.2016.7495588
   Yiqiong Shi, 2012, 2012 International Symposium on Communications and Information Technologies (ISCIT), P538, DOI 10.1109/ISCIT.2012.6380958
   Zaman M, 2018, DES AUT TEST EUROPE, P1592, DOI 10.23919/DATE.2018.8342269
   Zamiri Azar Kimia, 2020, Arxiv, DOI arXiv:2009.02208
   Azar KZ, 2021, IEEE T VLSI SYST, V29, P643, DOI 10.1109/TVLSI.2021.3060345
   Zaruba F, 2019, IEEE T VLSI SYST, V27, P2629, DOI 10.1109/TVLSI.2019.2926114
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zhang DR, 2017, IEEE VLSI TEST SYMP
   Zhang GL, 2018, DES AUT TEST EUROPE, P91, DOI 10.23919/DATE.2018.8341985
   Zhang JN, 2018, Arxiv, DOI arXiv:1803.07294
   Zhang MH, 2018, Arxiv, DOI arXiv:1802.09691
   Zhang MH, 2018, AAAI CONF ARTIF INTE, P4438
   Zhang YQ, 2019, PROCEEDINGS OF THE 3RD ACM WORKSHOP ON ATTACKS AND SOLUTIONS IN HARDWARE SECURITY WORKSHOP (ASHES '19), P75, DOI 10.1145/3338508.3359576
   Zhou H, 2017, ICCAD-IEEE ACM INT, P49, DOI 10.1109/ICCAD.2017.8203759
   Zhou JB, 2021, Arxiv, DOI arXiv:1910.12142
NR 227
TC 0
Z9 0
U1 3
U2 3
PD JUN
PY 2023
VL 129
AR 103196
DI 10.1016/j.cose.2023.103196
EA APR 2023
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Dhakal, A
   Kulkarni, SG
   Ramakrishnan, KK
AF Dhakal, Aditya
   Kulkarni, Sameer G.
   Ramakrishnan, K. K.
GP IEEE Comp Soc
TI Machine Learning at the Edge: Efficient Utilization of Limited CPU/GPU
   Resources by Multiplexing
SO 2020 IEEE 28TH INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS (IEEE ICNP
   2020)
SE IEEE International Conference on Network Protocols Proceedings
DT Proceedings Paper
CT 28th IEEE International Conference on Network Protocols (IEEE ICNP)
CY OCT 13-16, 2020
CL ELECTR NETWORK
DE GPU; Machine Learning; Deep Neural Networks; Inference
AB Edge clouds can provide very responsive services for end-user devices that require more significant compute capabilities than they have. But edge cloud resources such as CPUs and accelerators such as GPUs are limited and must be shared across multiple concurrently running clients. However, multiplexing GPUs across applications is challenging. Further, edge servers are likely to require considerable amounts of streaming data to be processed. Getting that data from the network stream to the GPU can be a bottleneck, limiting the amount of work GPUs do. Finally, the lack of prompt notification of job completion from GPU also results in ineffective GPU utilization. We propose a framework that addresses these challenges in the following manner. We utilize spatial sharing of GPUs to multiplex the GPU more efficiently. While spatial sharing of GPU can increase GPU utilization, the uncontrolled spatial sharing currently available with state-of-the-art systems such as CUDA-MPS can cause interference between applications, resulting in unpredictable latency. Our framework utilizes controlled spatial sharing of GPU, which limits the interference across applications. Our framework uses the GPU DMA engine to offload data transfer to GPU, therefore preventing CPU from being bottleneck while transferring data from the network to GPU. Our framework uses the CUDA event library to have timely, low overhead GPU notifications. Preliminary experiments show that we can achieve low DNN inference latency and improve DNN inference throughput by a factor of similar to 1.4.
C1 [Dhakal, Aditya; Ramakrishnan, K. K.] Univ Calif Riverside, Riverside, CA 92521 USA.
   [Kulkarni, Sameer G.] Indian Inst Technol, Gandhinagar, Gujarat, India.
RP Dhakal, A (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM adhak001@ucr.edu; sameergk@iitgn.ac.in; kk@cs.ucr.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2020, NVIDIA HYPER Q
   [Anonymous], 2020, TORCHSERVE
   [Anonymous], 2017, 2017 IEEE INT S LOCA
   [Anonymous], 2018, USENIX WORKSH HOT TO
   [Anonymous], 2011, NVIDIA UNIVERSAL VIR
   Chang H, 2014, IEEE CONF COMPUT, P346, DOI 10.1109/INFCOMW.2014.6849256
   Chen JS, 2019, P IEEE, V107, P1655, DOI 10.1109/JPROC.2019.2921977
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Collobert R, BIGLEARN NIPS WORKSH
   Dhakal A, 2019, PROCEEDINGS OF THE 2019 IEEE CONFERENCE ON NETWORK SOFTWARIZATION (NETSOFT 2019), P396, DOI [10.1109/NETSOFT.2019.8806698, 10.1109/netsoft.2019.8806698]
   Liu LD, 2019, IEEE INT SYM BROADB, DOI [10.1109/bmsb47279.2019.8971843, 10.1145/3326285.3329055]
   NVIDIA Corporation, 2019, TENS DEV GUID
   NVIDIA Tesla., 2019, NVIDIA, P108
   Ran XK, 2018, IEEE INFOCOM SER, P1421, DOI 10.1109/INFOCOM.2018.8485905
   Redmon J., 2013, DARKNET OPEN SOURCE
   Seide F, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2135, DOI 10.1145/2939672.2945397
   Suo J, 2016, 2016 21ST OPTOELECTRONICS AND COMMUNICATIONS CONFERENCE (OECC) HELD JOINTLY WITH 2016 INTERNATIONAL CONFERENCE ON PHOTONICS IN SWITCHING (PS)
   Wang SQ, 2020, IEEE T COMPUT AID D, V39, P2254, DOI 10.1109/TCAD.2019.2944584
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
NR 20
TC 4
Z9 4
U1 0
U2 0
PY 2020
DI 10.1109/icnp49622.2020.9259361
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Xing, Y
   Liang, S
   Sui, LZ
   Jia, XJ
   Qiu, JT
   Liu, X
   Wang, YS
   Shan, Y
   Wang, Y
AF Xing, Yu
   Liang, Shuang
   Sui, Lingzhi
   Jia, Xijie
   Qiu, Jiantao
   Liu, Xin
   Wang, Yushun
   Shan, Yi
   Wang, Yu
TI DNNVM: End-to-End Compiler Leveraging Heterogeneous Optimizations on
   FPGA-Based CNN Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Hardware; Optimization; Layout; Field programmable gate arrays;
   Throughput; Computer architecture; Deep learning; Compiler;
   convolutional neural network (CNN); field-programmable gate array
   (FPGA); fusion; optimizations
ID SUBGRAPH ISOMORPHISM; ALGORITHM
AB The convolutional neural network (CNN) has become a state-of-the-art method for several artificial intelligence domains in recent years. The increasingly complex CNN models are both computation-bound and I/O-bound. Field-programmable gate array-based accelerators driven by custom instruction set architecture (ISA) achieve a balance between generality and efficiency, but there is much on them left to be optimized. We propose the full-stack compiler deep neural network virtual machine (DNNVM), which is an integration of optimizers for graphs, loops and data layouts, an assembler, a runtime supporter, and a validation environment. The DNNVM works in the context of deep learning frameworks and transforms CNN models into the directed acyclic graph: XGraph. Based on XGraph, we transform the optimization challenges for both data layout and pipeline into graph-level problems. DNNVM enumerates all potentially profitable fusion opportunities by a heuristic subgraph isomorphism algorithm to leverage pipeline and data layout optimizations, and searches for the best choice of execution strategies of the whole computing graph. On the Xilinx ZU2@330 MHz and ZU9@330 MHz, we achieve equivalently state-of-the-art performance on our benchmarks by naive implementations without optimizations, and the throughput is further improved up to 1.26x by leveraging heterogeneous optimizations in DNNVM. Finally, with ZU9@330 MHz, we achieve state-of-the-art performance for VGG and ResNet50. We achieve a throughput of 2.82 TOPs/s and an energy efficiency of 123.7 GOPs/s/W for VGG. Additionally, we achieve 1.38 TOPs/s for ResNet50 and 1.41 TOPs/s for GoogleNet.
C1 [Xing, Yu; Sui, Lingzhi; Jia, Xijie; Liu, Xin; Wang, Yushun; Shan, Yi] Xilinx Inc, Dept Architecture, Beijing 100083, Peoples R China.
   [Xing, Yu; Liang, Shuang; Qiu, Jiantao; Wang, Yu] Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
   [Xing, Yu; Liang, Shuang; Qiu, Jiantao; Wang, Yu] Beijing Natl Res Ctr Informat Sci & Technol, Beijing 100084, Peoples R China.
RP Wang, Y (corresponding author), Tsinghua Univ, Dept Elect Engn, Tsinghua Natl Lab Informat Sci & Technol, Beijing 100084, Peoples R China.
EM yuxing@xilinx.com; yu-wang@tsinghua.edu.cn
CR Abdelfattah MS, 2018, I C FIELD PROG LOGIC, P411, DOI 10.1109/FPL.2018.00077
   Alwani M, 2016, INT SYMP MICROARCH
   [Anonymous], 2018, CORR
   [Anonymous], 2017, INCREMENTAL NETWORK
   [Anonymous], 2017, ABS170404861 CORR
   [Anonymous], 2018, ABS180204730 CORR
   [Anonymous], CORR
   Chang A. X., 2017, CORR
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Cordella LP, 2004, IEEE T PATTERN ANAL, V26, P1367, DOI 10.1109/TPAMI.2004.75
   De Chen, 2019, International Journal of Pavement Engineering, V20, P557, DOI 10.1080/10298436.2017.1316644
   Fu V. Y., 2017, WP490 XIL
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jangda A, 2018, ACM SIGPLAN NOTICES, V53, P261, DOI 10.1145/3200691.3178507
   Jia Y., 2019, CAFFE
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Lee J, 2012, PROC VLDB ENDOW, V6, P133, DOI 10.14778/2535568.2448946
   Liu YZ, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1025
   Moreau T., 2018, CORR
   Mullapudi RT, 2016, ACM T GRAPHIC, V35, DOI 10.1145/2897824.2925952
   Mullapudi RT, 2015, ACM SIGPLAN NOTICES, V50, P429, DOI [10.1145/2694344.2694364, 10.1145/2775054.2694364]
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J., 2018, TECH REPORT, P1
   Redmon J., 2019, DARKNET
   Ren XG, 2015, PROC VLDB ENDOW, V8, P617, DOI 10.14778/2735479.2735493
   Sharma H, 2016, INT SYMP MICROARCH
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tidwell R. P., 2005, XAPP706 XIL
   ULLMANN JR, 1976, J ACM, V23, P31, DOI 10.1145/321921.321925
   Venieris SI, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P291, DOI 10.1145/3020078.3021791
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wang Y, 2016, DES AUT CON, DOI 10.1145/2897937.2898003
   Wei R., 2018, INT C LEARN REPR
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhao RZ, 2018, I C FIELD PROG LOGIC, P147, DOI 10.1109/FPL.2018.00033
NR 41
TC 41
Z9 42
U1 1
U2 29
PD OCT
PY 2020
VL 39
IS 10
BP 2668
EP 2681
DI 10.1109/TCAD.2019.2930577
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Herrmann, V
   Knapheide, J
   Steinert, F
   Stabernack, B
AF Herrmann, Viktor
   Knapheide, Justin
   Steinert, Fritjof
   Stabernack, Benno
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI A YOLO v3-tiny FPGA Architecture using a Reconfigurable Hardware
   Accelerator for Real-time Region of Interest Detection
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE FPGA; Object Detection; Hardware; YOLO
AB With the recent advances in the fields of machine learning, neural networks and deep-learning algorithms have become a prevalent subject of computer vision. Especially for tasks like object classification and detection Convolutional Neuronal Networks (CNNs) have surpassed the previous traditional approaches. In addition to these applications, CNNs can recently also be found in other applications. For example the parametrization of video encoding algorithms as used in our example is quite a new application domain. Especially CNN's high recognition rate makes them particularly suitable for finding Regions of Interest (ROIs) in video sequences, which can be used for adapting the data rate of the compressed video stream accordingly.
   On the downside, these CNN require an immense amount of processing power and memory bandwidth. Object detection networks such as You Only Look Once (YOLO) try to balance processing speed and accuracy but still rely on power-hungry GPUs to meet real-time requirements. Specialized hardware like Field Programmable Gate Array (FPGA) implementations proved to strongly reduce this problem while still providing sufficient computational power. In this paper we propose a flexible architecture for object detection hardware acceleration based on the YOLO v3-tiny model. The reconfigurable accelerator comprises a high throughput convolution engine, custom blocks for all additional CNN operations and a programmable control unit to manage on-chip execution. The model can be deployed without significant changes based on 32-bit floating point values and without further methods that would reduce the model accuracy. Experimental results show a high capability of the design to accelerate the object detection task with a processing time of 27.5 ms per frame. It is thus real-time-capable for 30 FPS applications at frequency of 200 MHz.
C1 [Herrmann, Viktor; Knapheide, Justin; Steinert, Fritjof; Stabernack, Benno] Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
   [Knapheide, Justin; Steinert, Fritjof; Stabernack, Benno] Univ Potsdam, Embedded Syst Architectures Signal Proc, Potsdam, Germany.
RP Herrmann, V (corresponding author), Fraunhofer Inst Telecommun, Heinrich Hertz Inst, Berlin, Germany.
EM viktor.herrmann@hhi.fraunhofer.de; justin.knapheide@hhi.fraunhofer.de;
   fritjof.steinert@hhi-extern.fraunhofer.de;
   benno.stabernack@hhi.fraunhofer.de
CR Adiono T, 2021, IEEE ACCESS, V9, P141890, DOI 10.1109/ACCESS.2021.3120629
   [Anonymous], 2022, XIL VIT
   [Anonymous], 2018, YOLO REAL TIME OBJEC
   Bochkovskiy A., 2020, PREPRINT
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu B, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P241, DOI 10.1109/FPT.2018.00043
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Pestana D, 2021, IEEE ACCESS, V9, P75864, DOI 10.1109/ACCESS.2021.3081818
   Redmon J, 2016, Arxiv, DOI [arXiv:1612.08242, DOI 10.48550/ARXIV.1612.08242]
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shiguang Zhang, 2020, 2020 IEEE 3rd International Conference on Electronics Technology (ICET), P74, DOI 10.1109/ICET49382.2020.9119500
   Steinert F, 2022, J SIGNAL PROCESS SYS, V94, P693, DOI 10.1007/s11265-021-01727-2
   Steinert F, 2020, 2020 23RD EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2020), P149, DOI 10.1109/DSD51259.2020.00033
   Wang ZX, 2020, IEEE ACCESS, V8, P116569, DOI 10.1109/ACCESS.2020.3004198
   Zhewen Yu, 2020, Applied Reconfigurable Computing Architectures, Tools, and Applications. 16th International Symposium, ARC 2020. Proceedings. Lecture Notes in Computer Science (LNCS 120830), P330, DOI 10.1007/978-3-030-44534-8_25
NR 19
TC 0
Z9 0
U1 5
U2 7
PY 2022
BP 84
EP 92
DI 10.1109/DSD57027.2022.00021
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Gao, MX
   Chen, H
   Liu, DK
AF Gao, Muxuan
   Chen, He
   Liu, Dake
TI An ASIP for Neural Network Inference on Embedded Devices with 99% PE
   Utilization and 100% Memory Hidden under Low Silicon Cost
SO SENSORS
DT Article
DE deep neural networks; machine learning; deep learning processor;
   scheduling framework; instruction set architecture (ISA)
ID ACCELERATOR; PROCESSOR
AB The computation efficiency and flexibility of the accelerator hinder deep neural network (DNN) implementation in embedded applications. Although there are many publications on deep neural network (DNN) processors, there is still much room for deep optimization to further improve results. Multiple dimensions must be simultaneously considered when designing a DNN processor to reach the performance limit of the architecture, including architecture decision, flexibility, energy efficiency, and silicon cost minimization. Flexibility is defined as the ability to support as many multiple networks as possible and to easily adjust the scale. For energy efficiency, there are huge opportunities for power efficiency optimization, which involves access minimization and memory latency minimization based on on-chip memory minimization. Therefore, this work focused on low-power and low-latency data access with minimized silicon cost. This research was implemented based on an ASIP (application specific instruction set processor) in which an ISA was based on the caffe2 inference operator and the hardware design was based on a single instruction multiple data (SIMD) architecture. The scalability and system performance of our SoC extension scheme were demonstrated. The VLIW was used to execute multiple instructions in parallel. All costs for data access time were thus eliminated for the convolution layer. Finally, the processor was synthesized based on TSMC 65 nm technology with a 200 MHz clock, and the Soc extension scheme was analyzed in an experimental model. Our design was tested on several typical neural networks, achieving 196 GOPS at 200 MHz and 241 GOPS/W on the VGG16Net and AlexNet.
C1 [Gao, Muxuan; Chen, He; Liu, Dake] Beijing Inst Technol, Sch Informat & Elect, Beijing 100811, Peoples R China.
RP Chen, H (corresponding author), Beijing Inst Technol, Sch Informat & Elect, Beijing 100811, Peoples R China.
EM gao.muxuan@foxmail.com; chenhe@bit.edu.cn; dake@bit.edu.cn
CR Amdahl G. M., 1967, AFIPS CONF P, P483, DOI 10.1145/1465482.1465560
   Azimirad V, 2022, NEUROCOMPUTING, V490, P319, DOI 10.1016/j.neucom.2021.11.097
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chenarlogh VA, 2019, 2019 5TH IRANIAN CONFERENCE ON SIGNAL PROCESSING AND INTELLIGENT SYSTEMS (ICSPIS 2019), DOI 10.1109/icspis48872.2019.9066079
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Fan Y, 2016, ICMI'16: PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON MULTIMODAL INTERACTION, P445, DOI 10.1145/2993148.2997632
   Gao M., 2018, SCALABLE NEAR DATA P
   Ghani A, 2022, ELECTRONICS-SWITZ, V11, DOI 10.3390/electronics11071148
   Gukeh MJ, 2021, ACS APPL MATER INTER, V13, P46171, DOI 10.1021/acsami.1c13262
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P., 2016, ARXIV
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Horowitz M., ENERGY TABLE 45 NM P
   Huang BM, 2021, IEEE T CIRCUITS-I, V68, P4672, DOI 10.1109/TCSI.2021.3108762
   Ju Y., 2022, P 2022 IEEE INT SOLI, V65, P1
   Kadetotad D, 2020, IEEE J SOLID-ST CIRC, V55, P1877, DOI 10.1109/JSSC.2020.2992900
   Liu D, 2008, MORG KAUF SER SYST, P1
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Markham A., 2017, NVIDIA DEV BLOG
   Ouyang P, 2017, DES AUT CON, DOI 10.1145/3061639.3062187
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Roshani M, 2020, FLOW MEAS INSTRUM, V75, DOI 10.1016/j.flowmeasinst.2020.101804
   Shukla S, 2018, IEEE SOLID-ST CIRC L, V1, P217, DOI 10.1109/LSSC.2019.2902738
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tu FB, 2021, IEEE J SOLID-ST CIRC, V56, P658, DOI 10.1109/JSSC.2020.3021661
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
NR 26
TC 0
Z9 0
U1 4
U2 6
PD MAY
PY 2022
VL 22
IS 10
AR 3841
DI 10.3390/s22103841
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT J
AU Hu, X
   Zhao, Y
   Deng, L
   Liang, L
   Zuo, PF
   Ye, J
   Lin, YY
   Xie, Y
AF Hu, Xing
   Zhao, Yang
   Deng, Lei
   Liang, Ling
   Zuo, Pengfei
   Ye, Jing
   Lin, Yingyan
   Xie, Yuan
TI Practical Attacks on Deep Neural Networks by Memory Trojaning
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Trojan horses; Hardware; Integrated circuit modeling; Computational
   modeling; Security; Payloads; Convolutional neural networks (CNNs); deep
   learning accelerator; deep learning attack; hardware Trojan
ID THREAT
AB Deep neural network (DNN) accelerators are widely deployed in computer vision, speech recognition, and machine translation applications, in which attacks on DNNs have become a growing concern. This article focuses on exploring the implications of hardware Trojan attacks on DNNs. Trojans are one of the most challenging threat models in hardware security where adversaries insert malicious modifications to the original integrated circuits (ICs), leading to malfunction once being triggered. Such attacks can be conducted by adversaries because modern ICs commonly include third-party intellectual property (IP) blocks. Previous studies design hardware Trojans to attack DNNs with the assumption that adversaries have full knowledge or manipulation of the DNN systems' victim model and toolchain in addition to the hardware platforms, yet such a threat model is strict, limiting their practical adoption. In this article, we propose a memory Trojan methodology that implants the malicious logics merely into the memory controllers of DNN systems without the necessity of toolchain manipulation or accessing to the victim model and thus is feasible for practical uses. Specifically, we locate the input image data among the massive volume of memory traffics based on memory access patterns and propose a Trojan trigger mechanism based on detecting the geometric feature in input images. Extensive experiments show that the proposed trigger mechanism is effective even in the presence of environmental noises and preprocessing operations. Furthermore, we design and implement the payload and verify that the proposed Trojan technique can effectively conduct both untargeted and targeted attacks on DNNs.
C1 [Hu, Xing; Ye, Jing] Chinese Acad Sci, Inst Comp Technol, State Key Lab Comp Architecture, Beijing 100190, Peoples R China.
   [Zhao, Yang; Lin, Yingyan] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
   [Deng, Lei; Liang, Ling; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Zuo, Pengfei] Huazhong Univ Sci & Technol, Dept Comp Sci & Technol, Wuhan 430074, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM huxing@ict.ac.cn; zhao.yang@rice.edu; leideng@ucsb.edu;
   lingliang@ucsb.edu; pfzuo@hust.edu.cn; yejing@ict.ac.cn;
   yingyan.lin@rice.edu; yuanxie@ucsb.edu
CR Ahmed E, 2015, PROC CVPR IEEE, P3908, DOI 10.1109/CVPR.2015.7299016
   Akhtar N, 2018, IEEE ACCESS, V6, P14410, DOI 10.1109/ACCESS.2018.2807385
   Alfeld S, 2016, AAAI CONF ARTIF INTE, P1452
   Alwani M, 2016, INT SYMP MICROARCH
   Amodei D., 2016, ARXIV160606565
   [Anonymous], 2015, CORR ABS14126572
   [Anonymous], 2015, CHINA UNVEILS WORLDS
   [Anonymous], 2010, IMAGENET 1 CROP ERRO
   [Anonymous], 2018, GARTNER IDENTIFIES T
   [Anonymous], FRACTAL GEOMETRY MAT
   Ateniese G., 2013, ARXIV13064447
   Backes M., 2016, ADVERSARIAL PERTURBA
   Bhunia S, 2014, P IEEE, V102, P1229, DOI 10.1109/JPROC.2014.2334493
   Biggio B., 2013, JOINT EUR C MACH LEA, P387, DOI DOI 10.1007/978-3-642-40994-3_25
   Brown Tom B, 2017, ARXIV171209665
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Carlini N., 2017, PROVABLY MINIMALLY D
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cisse Moustapha M., 2017, ARXIV170705373, P6977
   Clements J., 2018, HARDWARE TROJAN ATTA
   Deng L, 2020, IEEE T COMPUT AID D, V39, P117, DOI 10.1109/TCAD.2018.2883959
   Dong Y., 2017, CVPR
   Fredrikson M, 2014, PROCEEDINGS OF THE 23RD USENIX SECURITY SYMPOSIUM, P17
   Guo K, 2016, 2016 IEEE HOT CHIPS, P1, DOI DOI 10.1109/HOTCHIPS.2016.7936208
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2009, LEARNING MULTIPLE LA
   Howard, 2017, ARXIV170404861
   Ji Y., 2019, PROGRAMMABLE NEURAL
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   King S. T., 2008, LEET 08, P1
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2017, ADVERSARIAL EXAMPLES, P1
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Li WS, 2018, IEEE COMP SOC ANN, P482, DOI 10.1109/ISVLSI.2018.00093
   Liu T, 2018, PROCEEDINGS OF THE 2018 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P227, DOI 10.1109/HST.2018.8383920
   Liu Xin, 2018, ARXIV180602299
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Liu YQ, 2018, 25TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2018), DOI 10.14722/ndss.2018.23291
   Mopuri Konda Reddy, 2017, PROC BRIT MACH VIS C
   Narodytska N., 2016, ARXIV161206299
   Nvidia Deep Learning Accelerator (NVDLA), 2017, NVIDIA
   Oh SJ, 2017, IEEE I CONF COMP VIS, P1491, DOI 10.1109/ICCV.2017.165
   Papernot N., 2016, SCI SECURITY PRIVACY
   Papernot N, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P506, DOI 10.1145/3052973.3053009
   Papernot N, 2016, 1ST IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY, P372, DOI 10.1109/EuroSP.2016.36
   Papernot Nicolas, 2016, ARXIV160507277
   Putic M, 2018, DES AUT CON, DOI 10.1145/3195970.3196033
   Ren S., 2017, IEEE T PATTERN ANAL, V39, P1137, DOI [DOI 10.1109/TPAMI.2016.2577031, https://doi.org/10.1109/TPAMI.2016.2577031]
   Rozsa A, 2016, IEEE COMPUT SOC CONF, P410, DOI 10.1109/CVPRW.2016.58
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sabour S., 2015, ARXIV151105122
   Samajdar A., 2018, COMPUTING RES REPOSI
   Sarkar Sayantan, 2017, ARXIV170701159
   Shafahi A., 2018, NEURIPS
   Sharif M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1528, DOI 10.1145/2976749.2978392
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srndic N, 2014, P IEEE S SECUR PRIV, P197, DOI 10.1109/SP.2014.20
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Szegedy C, 2017, AAAI CONF ARTIF INTE, P4278
   Tehranipoor M, 2010, IEEE DES TEST COMPUT, V27, P10, DOI 10.1109/MDT.2010.7
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Wang BH, 2018, P IEEE S SECUR PRIV, P36, DOI 10.1109/SP.2018.00038
   Werner DH, 1999, IEEE ANTENNAS PROPAG, V41, P37, DOI 10.1109/74.801513
   Xi GH, 2019, TSINGHUA SCI TECHNOL, V24, P226, DOI 10.26599/TST.2018.9010114
   Xu WL, 2016, 23RD ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2016), DOI 10.14722/ndss.2016.23115
   Xue MF, 2019, IEEE ACCESS, V7, P5124, DOI 10.1109/ACCESS.2018.2887268
   Ye J, 2018, ASIAN TEST SYMPOSIUM, P68, DOI 10.1109/ATS.2018.00024
   Yu SC, 2019, IEEE COMP SOC ANN, P303, DOI 10.1109/ISVLSI.2019.00062
   Zhang WC, 2019, TSINGHUA SCI TECHNOL, V24, P360, DOI 10.26599/TST.2018.9010111
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 74
TC 11
Z9 11
U1 4
U2 11
PD JUN
PY 2021
VL 40
IS 6
BP 1230
EP 1243
DI 10.1109/TCAD.2020.2995347
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Basalama, S
   Sohrabizadeh, A
   Wang, J
   Guo, LC
   Cong, J
AF Basalama, Suhail
   Sohrabizadeh, Atefeh
   Wang, Jie
   Guo, Licheng
   Cong, Jason
TI FlexCNN: An End-to-end Framework for Composing CNN Accelerators on FPGA
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; CNN; ONNX; systolic array; transposed convolution; dilated
   convolution; OpenPose; U-Net; E-Net
AB With reduced data reuse and parallelism, recent convolutional neural networks (CNNs) create new challenges for FPGA acceleration. Systolic arrays (SAs) are efficient, scalable architectures for convolutional layers, but without proper optimizations, their efficiency drops dramatically for reasons: (1) the different dimensions within same-type layers, (2) the different convolution layers especially transposed and dilated convolutions, and (3) CNN's complex dataflow graph. Furthermore, significant overheads arise when integrating FPGAs into machine learning frameworks. Therefore, we present a flexible, composable architecture called FlexCNN, which delivers high computation efficiency by employing dynamic tiling, layer fusion, and data layout optimizations. Additionally, we implement a novel versatile SA to process normal, transposed, and dilated convolutions efficiently. FlexCNN also uses a fully pipelined software-hardware integration that alleviates the software overheads. Moreover, with an automated compilation flow, FlexCNN takes a CNN in the ONNX1 representation, performs a design space exploration, and generates an FPGA accelerator. The framework is tested using three complex CNNs: OpenPose, U-Net, and E-Net. The architecture optimizations achieve 2.3x performance improvement. Compared to a standard SA, the versatile SA achieves close-to-ideal speedups, with up to 15.98x and 13.42x for transposed and dilated convolutions, with a 6% average area overhead. The pipelined integration leads to a 5x speedup for OpenPose.
C1 [Basalama, Suhail; Sohrabizadeh, Atefeh; Wang, Jie; Guo, Licheng; Cong, Jason] Univ Calif Los Angeles, 404 Westwood Blvd Engn,6 Room 468, Los Angeles, CA 90095 USA.
RP Basalama, S (corresponding author), Univ Calif Los Angeles, 404 Westwood Blvd Engn,6 Room 468, Los Angeles, CA 90095 USA.
EM basalama@ucla.edu; atefehsz@cs.ucla.edu; jiewang@cs.ucla.edu;
   lcguo@cs.ucla.edu; cong@cs.ucla.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Bai L, 2018, IEEE T CIRCUITS-II, V65, P1415, DOI 10.1109/TCSII.2018.2865896
   Cao Z, 2017, PROC CVPR IEEE, P1302, DOI 10.1109/CVPR.2017.143
   Chang Tian-Sheuan, 2020, IEEE INT S CIRCUITS, P1
   Chen QY, 2020, IEEE T VLSI SYST, V28, P1540, DOI 10.1109/TVLSI.2020.2976454
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Chen YT, 2016, ANN IEEE SYM FIELD P, P29, DOI 10.1109/FCCM.2016.18
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   Chi YZ, 2021, ANN IEEE SYM FIELD P, P204, DOI [10.1109/FCCM51124.2021.00032, 10.1109/fccm51124.2021.00032]
   Chi YZ, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240850
   Cong Jason, 2018, 10 USENIX WORKSHOP H
   Cong Jason, 2018, IEEE ACM INT C COMPU, P1
   Deng HP, 2021, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM51124.2021.00029
   Di XK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020286
   docs.xilinx.com, U280 PERFORMANCE 14E
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   DPUCAHX8H Resource Utilization, US
   DPUCAHX8L Resource Utilization, US
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, DOI 10.48550/ARXIV.1704.04861]
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Guo KY, 2016, IEEE COMP SOC ANN, P24, DOI 10.1109/ISVLSI.2016.129
   Ignatov A, 2019, LECT NOTES COMPUT SC, V11133, P288, DOI 10.1007/978-3-030-11021-5_19
   Im D, 2019, IEEE INT SYMP CIRC S
   Jinguji A, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P313, DOI 10.1109/FPT.2018.00061
   Kim Ildoo, 2018, TF POSE ESTIMATION
   Kim T, 2017, PR MACH LEARN RES, V70
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Li YH, 2018, PROC CVPR IEEE, P1091, DOI 10.1109/CVPR.2018.00120
   Licheng Guo, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P81, DOI 10.1145/3431920.3439289
   Liu SL, 2019, I C FIELD PROG LOGIC, P187, DOI 10.1109/FPL.2019.00037
   Liu SL, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242900
   Liu WJ, 2019, IEEE INT SYMP CIRC S
   Matthews AGD, 2017, J MACH LEARN RES, V18, P1
   Noronha D. H., 2018, FSP WORKSH 2018 5 IN, P1
   Paszke A, 2016, Arxiv, DOI [arXiv:1606.02147, DOI 10.48550/ARXIV.1606.02147]
   Radford A, 2016, Arxiv, DOI [arXiv:1511.06434, DOI 10.48550/ARXIV.1511.06434]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma H, 2016, INT SYMP MICROARCH
   Shen JZ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P97, DOI 10.1145/3174243.3174257
   Shen YM, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P535, DOI 10.1145/3079856.3080221
   Sifre Laurent, 2014, THESIS ECOLE NORMALE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sohrabizadeh A, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P133, DOI 10.1145/3373087.3375321
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Tan WR, 2017, IEEE IMAGE PROC, P3760, DOI 10.1109/ICIP.2017.8296985
   Venieris SI, 2019, IEEE T NEUR NET LEAR, V30, P326, DOI 10.1109/TNNLS.2018.2844093
   Vitis AI, US
   Wei XC, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240856
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Yang X, 2020, Arxiv, DOI arXiv:1809.04070
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Yu FS, 2016, Arxiv, DOI [arXiv:1511.07122, DOI 10.48550/ARXIV.1511.07122]
   Yu YX, 2020, IEEE T VLSI SYST, V28, P1545, DOI 10.1109/TVLSI.2020.2995741
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2019, IEEE T COMPUT AID D, V38, P2072, DOI 10.1109/TCAD.2017.2785257
   Zhang N, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10030282
   Zhang XF, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415609
   Zhang XF, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240801
NR 63
TC 1
Z9 1
U1 3
U2 3
PD JUN
PY 2023
VL 16
IS 2
AR 23
DI 10.1145/3570928
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Malik, M
   Rafatirah, S
   Sasan, A
   Homayoun, H
AF Malik, Maria
   Rafatirah, Setareh
   Sasan, Avesta
   Homayoun, Houman
BE Ho, H
   Ooi, BC
   Zaki, MJ
   Hu, XH
   Haas, L
   Kumar, V
   Rachuri, S
   Yu, SP
   Hsiao, MHI
   Li, J
   Luo, F
   Pyne, S
   Ogan, K
TI System and Architecture Level Characterization of Big Data Applications
   on Big and Little Core Server Architectures
SO PROCEEDINGS 2015 IEEE INTERNATIONAL CONFERENCE ON BIG DATA
DT Proceedings Paper
CT IEEE International Conference on Big Data
CY OCT 29-NOV 01, 2015
CL Santa Clara, CA
DE Performance; Power; Characterization; Big Data; High-Performance server;
   Low-Power server; Accelerator
AB Emerging Big Data applications require a significant amount of server computational power. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and exhibit high computational intensity, memory intensity, I/O intensity and control intensity. Big data applications require computing resources that can efficiently scale to manage massive amounts of diverse data. However, the rapid growth in the data yields challenges to process data efficiently using current server architectures such as big Xeon cores. Furthermore, physical design constraints, such as power and density, have become the dominant limiting factor for scaling out servers. Therefore recent work advocates the use of low-power embedded cores in servers such as little Atom to address these challenges. In this work, through methodical investigation of power and performance measurements, and comprehensive system level and micro-architectural analysis, we characterize emerging big data applications on big Xeon and little Atom-based server architecture. The characterization results across a wide range of real-world big data applications and various software stacks demonstrate how the choice of big vs little core-based server for energy-efficiency is significantly influenced by the size of data, performance constraints, and presence of accelerator. Furthermore, the microarchitecture-level analysis highlights where improvement is needed in big and little cores microarchitecture.
C1 [Malik, Maria; Sasan, Avesta; Homayoun, Houman] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
   [Rafatirah, Setareh] George Mason Univ, Dept Informat Sci & Technol, Fairfax, VA 22030 USA.
RP Malik, M (corresponding author), George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA 22030 USA.
EM mmalik9@gmu.edu; srafatir@gmu.edu; hhomayou@gmu.edu
CR Absalyamov I., 2013, ADMS VLDB
   ANDERSEN DG, 2009, P ACM SIGOPS 22 SOSP, P1
   [Anonymous], ACM SIGARCH COMPUTER
   Armstrong, 2013, P ACM SIGMOD
   ARNOLD M., 2001, P 9 CODES
   Arora M, 2012, IEEE MICRO, V32, P4, DOI 10.1109/MM.2012.57
   Arora N, 2010, VLSI DESIGN
   Baru C, LECT NOTES COMPUTER
   Blem E., HPCA2013 IEEE 19 INT, P1
   Gao W., ASBD 2013 CONJUNCTIO
   Ghazal A., 2013, ACM SIGMOD C
   Gutierrez A., 2014, P 19 ASPLOS
   Hardavellas N, 2011, IEEE MICRO, V31, P6, DOI 10.1109/MM.2011.77
   Homayoun H., HPCA 2012
   Honjo Toshimori, 2013, 2013 IEEE International Conference on Big Data, P118, DOI 10.1109/BigData.2013.6691562
   Huang S, 2010, P 26 ICDEW
   Kontorinis V., 2014, 51 ANN DAC 2014
   Kontorinis V., 39TH ISCA 2012
   Kukunas J.T., 2014, HIGH PERFORMANCE ZLI
   Li A., ACM 10
   Li T., 2009, P CASES
   Lin ZD, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P450, DOI 10.1109/FPT.2013.6718411
   Luo Xi, 2013, BIGDATA 2013
   Neshatpour K, 2015, 15 IEEE ACM CCGRID 2
   Neshatpour K, 2015, BIGDATA 2015
   Neshatpour K., IEEE FCCM 2015
   Nilakantan S., 2013, IISWC IEEE
   PRAKASH TK, 2008, ISAST 2008
   Reddi VJ, 2010, CONF PROC INT SYMP C, P314, DOI 10.1145/1816038.1816002
   Shan Y., 2010, P ANN ACM SIGDA INT
   Tavana Khavari, ISLPED 14
   Willke T.L., 2012, BIG LEARNING WS NIPS
   YU P., P FPL 07, P273
   YU P., P CASES 04
NR 34
TC 12
Z9 12
U1 0
U2 6
PY 2015
BP 85
EP 94
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Crumley, D
   Hossain, M
   Martin, K
   Ivey, F
   Yarnell, R
   DeMara, RF
   Bai, Y
AF Crumley, D.
   Hossain, M.
   Martin, K.
   Ivey, F.
   Yarnell, Richard
   DeMara, R. F.
   Bai, Y.
GP IEEE
TI Rehosting YOLOv2 Framework for Reconfigurable Fabric-based Acceleration
SO SOUTHEASTCON 2022
SE IEEE SoutheastCon-Proceedings
DT Proceedings Paper
CT SoutheastCon Conference
CY MAR 26-APR 03, 2022
CL Mobile, AL
DE Field Programmable Gate Array (FPGA); Machine Learning Accelerator;
   Convolutional Neural Network (CNN); You Only Look Once (YOLO) framework
AB While Convolutional Neural Networks are attaining widespread utility for computer vision tasks such as object detection and classification, the frameworks used to implement these systems are largely designed for use with CPUs and GPUs, with the latter being the hardware-optimized approach. This application-optimized hardware approach can be advanced further by researching Convolutional Neural Networks implemented on low-power and embedded devices using FPGAs. FPGAs consume substantially less energy than GPUs, offering additional potential benefits for embedded hardware acceleration of Convolutional Neural Nets. Because GPUs are still the favored target device for CNNs, there is an abundance of libraries and tools that can be used to create custom architectures in languages such as Python and C++. This, however, is not the case for FPGA development. Herein, a workflow is outlined for the conversion of Convolutional Neural Networks from a high-level language implementation to a bitstream which can be configured on an FPGA device and utilized as a hardware accelerator for image and video processing. Within this workflow, the data is quantized to reduce memory usage, C++ code is synthesized to Verilog using Vivado HLS tools, the resulting hardware module is integrated with the ZYNQ SOC processor, and the final implementation is tested for accuracy.
C1 [Crumley, D.; Hossain, M.; Martin, K.; Ivey, F.; Yarnell, Richard; DeMara, R. F.] Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
   [Bai, Y.] Calif State Univ Fullerton, Comp Engn Program, Fullerton, CA 92831 USA.
RP Crumley, D (corresponding author), Univ Cent Florida, Dept Elect & Comp Engn, Orlando, FL 32816 USA.
EM david_crumley@knights.ucf.edu; mousam.hossain@knights.ucf.edu;
   kaitlyn.martin@knights.ucf.edu; boivey3@knights.ucf.edu;
   richardyarnell@knights.ucf.edu; ronald.demara@ucf.edu;
   ybai@fullerton.edu
CR Alhussain A., 2022, PROCOF IEEE C INFORM, P1
   Cai YX, 2021, AAAI CONF ARTIF INTE, V35, P955
   Chen C, 2019, THESIS JIANGNAN U
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Xilinx PYNQ documentation, PYTH PROD ZYNQ PYNQ
   Zhang KN, 2005, LECT NOTES COMPUT SC, V3637, P12, DOI 10.1007/11549703_2
NR 6
TC 1
Z9 1
U1 2
U2 5
PY 2022
BP 445
EP 446
DI 10.1109/SoutheastCon48659.2022.9763979
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Zha, Y
   Nowak, E
   Li, J
AF Zha, Yue
   Nowak, Etienne
   Li, Jing
TI Liquid Silicon: A Nonvolatile Fully Programmable Processing-in-Memory
   Processor With Monolithically Integrated ReRAM
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE In-memory processing; neural network (NN); nonvolatile; reconfigurable
   architecture; resistive-RAM (RRAM); ternary content-addressable memory
AB The slowdown of the CMOS technology scaling, and the trade-off between efficiency and flexibility have fueled the exploration into novel architectures with emerging post-CMOS technology [e.g., resistive-RAM (RRAM)]. In this article, a nonvolatile fully programmable processing-in-memory (PIM) processor named Liquid Silicon is demonstrated, which combines the superior programmability of general-purpose computing devices [e.g., field-programmable gate array (FPGA)] and the high efficiency of domain-specific accelerators. Besides the general computing applications, Liquid Silicon is particularly well suited for artificial intelligence (AI)/machine learning and big data applications, which not only poses high computational/memory demand but also evolves rapidly. To fabricate the Liquid Silicon chip, the HfO2 RRAM is monolithically integrated on top of the commercial 130 nm CMOS. Our measurement confirms that Liquid Silicon chip can operate reliably at a low voltage of 650 mV. It achieves 60.9 TOPS/W in performing neural network (NN) inferences, and 480 GOPS/W in performing content-based similarity search (a key big data application) at a nominal voltage supply of 1.2 V, showing $3\times $ and $100\times $ improvement over the state-of-the-art domain-specific CMOS-/RRAM-based accelerators. In addition, it outperforms the latest nonvolatile FPGA in energy efficiency by $3\times $ in general computing applications.
C1 [Zha, Yue; Li, Jing] Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA.
   [Nowak, Etienne] CEA Leti, Minatec Campus, F-38054 Grenoble, France.
RP Li, J (corresponding author), Univ Penn, Dept Elect & Syst Engn, Philadelphia, PA 19104 USA.
EM zhayue@seas.upenn.edu; janeli@seas.upenn.edu
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Ambrogio S., 2015, P IEEE INT REL PHYS
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   [Anonymous], 2015, 2015 S VLSI CIRC DIG
   [Anonymous], 2009, INTR INT QUICKPATH I
   [Anonymous], 1991, TECH REP
   [Anonymous], 2016, PROC 35TH INT CONF C
   Chhajed G, 2010, INT CONF COMP SCI, P375, DOI 10.1109/ICCSIT.2010.5564782
   Farmahini-Farahani A, 2015, IEEE COMPUT ARCHIT L, V14, P26, DOI 10.1109/LCA.2014.2333735
   Grossi A, 2016, INT EL DEVICES MEET
   Grossi A, 2019, IEEE T ELECTRON DEV, V66, P1281, DOI 10.1109/TED.2019.2894387
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Liu YP, 2016, ISSCC DIG TECH PAP I, V59, P84, DOI 10.1109/ISSCC.2016.7417918
   Moons B, 2018, IEEE CUST INTEGR CIR
   Stuecheli J, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2014.2380198
   Su F, 2017, SYMP VLSI CIRCUITS, pC260
   Tsurumi K, 2018, IEEE ASIAN SOLID STA, P129
   Yin SY, 2018, SYMP VLSI CIRCUITS, P37, DOI 10.1109/VLSIC.2018.8502388
   Yin SY, 2018, SYMP VLSI CIRCUITS, P139, DOI 10.1109/VLSIC.2018.8502309
   Young Yang Liauw, 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P406, DOI 10.1109/ISSCC.2012.6177067
   Zha Y, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P51, DOI 10.1145/31742433174244
   Zha Y, 2018, ACM SIGPLAN NOTICES, V53, P214, DOI [10.1145/3296957.3173167, 10.1145/3173162.3173167]
NR 23
TC 14
Z9 16
U1 2
U2 22
PD APR
PY 2020
VL 55
IS 4
BP 908
EP 919
DI 10.1109/JSSC.2019.2963005
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Choong, BCM
   Luo, T
   Liu, C
   He, BS
   Zhang, W
   Zhou, JT
AF Choong, Benjamin Chen Ming
   Luo, Tao
   Liu, Cheng
   He, Bingsheng
   Zhang, Wei
   Zhou, Joey Tianyi
TI Hardware-software co-exploration with racetrack memory based in-memory
   computing for CNN inference in embedded systems
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Artificial intelligence; Hardware-software co-design; Deep learning;
   Embedded systems; Emerging memory
ID NEURAL-NETWORKS; ENERGY; ARCHITECTURE; ACCELERATOR; MACHINE; ADDER
AB Deep neural networks generate and process large volumes of data, posing challenges for low-resource embedded systems. In-memory computing has been demonstrated as an efficient computing infrastructure and shows promise for embedded AI applications. Among newly-researched memory technologies, racetrack memory is a non-volatile technology that allows high data density fabrication, making it a good fit for in memory computing. However, integrating in-memory arithmetic circuits with memory cells affects both the memory density and power efficiency. It remains challenging to build efficient in-memory arithmetic circuits on racetrack memory within area and energy constraints. To this end, we present an efficient in-memory convolutional neural network (CNN) accelerator optimized for use with racetrack memory. We design a series of fundamental arithmetic circuits as in-memory computing cells suited for multiply-and-accumulate operations. Moreover, we explore the design space of racetrack memory based systems and CNN model architectures, employing co-design to improve the efficiency and performance of performing CNN inference in racetrack memory while maintaining model accuracy. Our designed circuits and model-system co-optimization strategies achieve a small memory bank area with significant improvements in energy and performance for racetrack memory based embedded systems.
C1 [Choong, Benjamin Chen Ming] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117583, Singapore.
   [Luo, Tao] Agcy Sci Technol & Res, Inst High Performance Comp, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
   [Liu, Cheng] Chinese Acad Sci, Inst Comp Technol, 6 Kexueyuan South Rd, Beijing 100190, Peoples R China.
   [He, Bingsheng] Natl Univ Singapore, Sch Comp, COM1,13 Comp Dr, Singapore 117417, Singapore.
   [Zhang, Wei] Hong Kong Univ Sci & Technol, Kowloon, Clear Water Bay, Hong Kong, Peoples R China.
   [Zhou, Joey Tianyi] ASTAR, Ctr Frontier AI Res, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
RP Luo, T (corresponding author), Agcy Sci Technol & Res, Inst High Performance Comp, 1 Fusionopolis Way,16-16 Connexis, Singapore 138632, Singapore.
EM leto.luo@gmail.com
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], 2014, 51 ACMEDACIEEE DESIG
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Chauwin M, 2019, PHYS REV APPL, V12, DOI 10.1103/PhysRevApplied.12.064053
   Chen C, 2018, IEEE T COMPUT, V67, P1765, DOI 10.1109/TC.2018.2839719
   Chen C, 2018, IEEE T PARALL DISTR, V29, P1275, DOI 10.1109/TPDS.2018.2794343
   Chen C, 2017, IEEE T SYST MAN CY-S, V47, P2740, DOI 10.1109/TSMC.2017.2690673
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen ZG, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358199
   Ding RZ, 2018, ASIA S PACIF DES AUT, P1, DOI 10.1109/ASPDAC.2018.8297274
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Furui S, 2012, IEEE SIGNAL PROC MAG, V29, P16, DOI 10.1109/MSP.2012.2209906
   Han S, 2016, ARXIV 151000149
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Trinh HP, 2013, IEEE T CIRCUITS-I, V60, P1469, DOI 10.1109/TCSI.2012.2220507
   Howard, 2017, ARXIV170404861
   Hsu LC, 2020, J SYST ARCHITECT, V111, DOI 10.1016/j.sysarc.2020.101831
   Hu QD, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P397, DOI 10.1145/2902961.2902967
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Kang HJ, 2020, IEEE T CIRC SYST VID, V30, P2093, DOI 10.1109/TCSVT.2019.2911674
   Kang W, 2018, IEEE NON-VOLATILE ME, P7, DOI 10.1109/NVMSA.2018.00009
   Kang W, 2017, IEEE T ELECTRON DEV, V64, P1060, DOI 10.1109/TED.2017.2656140
   Kim N, 2021, IEEE T NEUR NET LEAR, V32, P2925, DOI 10.1109/TNNLS.2020.3008996
   Kwon H, 2021, INT S HIGH PERF COMP, P71, DOI 10.1109/HPCA51647.2021.00016
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lin CJ, 2009, INT EL DEVICES MEET, P256
   Liu BC, 2017, IEEE INT SYMP PARAL, P383, DOI 10.1109/ISPA/IUCC.2017.00061
   Luo SJ, 2021, APL MATER, V9, DOI 10.1063/5.0042917
   Luo T, 2020, INT CON DISTR COMP S, P1409, DOI 10.1109/ICDCS47774.2020.00186
   Luo T, 2020, IEEE T COMPUT AID D, V39, P438, DOI 10.1109/TCAD.2018.2889670
   Luo T, 2017, ICCAD-IEEE ACM INT, P276, DOI 10.1109/ICCAD.2017.8203789
   Luo T, 2016, ASIA S PACIF DES AUT, P286, DOI 10.1109/ASPDAC.2016.7428025
   Malladi KT, 2012, CONF PROC INT SYMP C, P37, DOI 10.1109/ISCA.2012.6237004
   Mao MJ, 2017, IEEE T COMPUT, V66, P1478, DOI 10.1109/TC.2017.2690855
   Matsunaga S, 2008, APPL PHYS EXPRESS, V1, DOI 10.1143/APEX.1.091301
   Mei LY, 2021, IEEE T COMPUT, V70, P1160, DOI 10.1109/TC.2021.3059962
   Meng H, 2005, IEEE ELECTR DEVICE L, V26, P360, DOI 10.1109/LED.2005.848129
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Parkin SSP, 2008, SCIENCE, V320, P190, DOI 10.1126/science.1145799
   Paszke A, 2019, ADV NEUR IN, V32
   Riente F., 2021, IEEE T EMERG TOP COM, DOI DOI 10.1109/TETC.2021.3078061
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Silicon Integration Initiative Inc., 2016, 45NM FREEPDK LIB
   Simonyan K., 2015, P 3 INT C LEARN REPR, P1
   Song LL, 2017, IEEE T VLSI SYST, V25, P1285, DOI 10.1109/TVLSI.2016.2644279
   Sun ZY, 2013, DES AUT CON
   Venkatesan R, 2013, DES AUT TEST EUROPE, P1825
   Venkatesan R, 2014, CONF PROC INT SYMP C, P253, DOI 10.1109/ISCA.2014.6853233
   Wang GD, 2019, IEEE T CIRCUITS-I, V66, P215, DOI 10.1109/TCSI.2018.2866932
   Wang J., 2020, IEEE T COMPUT, DOI DOI 10.1109/TC.2020.3045433
   Wang YH, 2014, DES AUT TEST EUROPE
   Wang YH, 2016, IEEE T INF FOREN SEC, V11, P2426, DOI 10.1109/TIFS.2016.2576903
   Xu HF, 2015, ASIA S PACIF DES AUT, P417, DOI 10.1109/ASPDAC.2015.7059042
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yu H, 2014, ASIA S PACIF DES AUT, P191, DOI 10.1109/ASPDAC.2014.6742888
   Zand R, 2017, IEEE T NANOTECHNOL, V16, P32, DOI 10.1109/TNANO.2016.2625749
   Zhang C, 2015, ASIA S PACIF DES AUT, P100, DOI 10.1109/ASPDAC.2015.7058988
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhang XC, 2015, SCI REP-UK, V5, DOI 10.1038/srep09400
   Zhang Y, 2012, J APPL PHYS, V111, DOI 10.1063/1.4716460
   Zhao W., 2013, 2013 IEEE FAIBLE TEN, P1, DOI DOI 10.1109/FTFC.2013.6577771
   Zhou  A., 2017, ARXIV170203044
   Zhu CY, 2020, IEEE T VLSI SYST, V28, P1953, DOI 10.1109/TVLSI.2020.3002779
NR 68
TC 1
Z9 1
U1 1
U2 13
PD JUL
PY 2022
VL 128
AR 102507
DI 10.1016/j.sysarc.2022.102507
EA MAY 2022
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Albericio, J
   Delmás, A
   Judd, P
   Sharify, S
   O'Leary, G
   Genov, R
   Moshovos, A
AF Albericio, Jorge
   Delmas, Alberto
   Judd, Patrick
   Sharify, Sayeh
   O'Leary, Gerard
   Genov, Roman
   Moshovos, Andreas
GP ACM
TI Bit-Pragmatic Deep Neural Network Computing
SO 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE
   (MICRO)
DT Proceedings Paper
CT 50th Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 14-18, 2017
CL Cambridge, MA
DE Hardware Accelerators; Machine Learning; Neural Networks
AB Deep Neural Networks expose a high degree of parallelism, making them amenable to highly data parallel architectures. However, data-parallel architectures often accept inefficiency in individual computations for the sake of overall efficiency. We show that on average, activation values of convolutional layers during inference in modern Deep Convolutional Neural Networks (CNNs) contain 92% zero bits. Processing these zero bits entails ineffectual computations that could be skipped. We propose Pragmatic (PRA), a massively data-parallel architecture that eliminates most of the ineffectual computations on-the-fly, improving performance and energy efficiency compared to state-of-the-art high-performance accelerators [5]. The idea behind PRA is deceptively simple: use serial-parallel shift-and-add multiplication while skipping the zero bits of the serial input. However, a straightforward implementation based on shift-and-add multiplication yields unacceptable area, power and memory access overheads compared to a conventional bit-parallel design. PRA incorporates a set of design decisions to yield a practical, area and energy efficient design.
   Measurements demonstrate that for convolutional layers, PRA is 4.31x faster than DaDianNao [5] (DaDN) using a 16-bit fixed-point representation. While PRA requires 1.68x more area than DaDN, the performance gains yield a 1.70x increase in energy efficiency in a 65nm technology. With 8-bit quantized activations, PRA is 2.25x faster and 1.31x more energy efficient than an 8-bit version of DaDN.
C1 [Albericio, Jorge] NVIDIA, Santa Clara, CA 95051 USA.
   [Albericio, Jorge; Delmas, Alberto; Judd, Patrick; Sharify, Sayeh; O'Leary, Gerard; Genov, Roman; Moshovos, Andreas] Univ Toronto, Toronto, ON, Canada.
RP Albericio, J (corresponding author), NVIDIA, Santa Clara, CA 95051 USA.
EM jalbericiola@nvidia.com; delmasl1@ece.utoronto.ca;
   juddpatr@ece.utoronto.ca; sayeh@ece.utoronto.ca;
   gerard.oleary@eecg.utoronto.ca; roman@eecg.utoronto.ca;
   moshovos@ece.utoronto.ca
CR Albericio Jorge, 2016, 2016 IEEE ACM INT C
   Alemdar H., 2016, CORR
   [Anonymous], 2014, CORR
   [Anonymous], DES COMP
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   CHEN YH, 2016, DIGEST TECHNICAL PAP, V59, P262
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux Matthieu, 2015, ARXIV E PRINTS
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Girschick R., 2013, ARXIV13112524CS
   Gonzalez R, 1996, IEEE J SOLID-ST CIRC, V31, P1277, DOI 10.1109/4.535411
   Graybill R, 2002, S COMP SCI, P293
   Han  S., 2015, ARXIV151000149CS
   Han S., 2016, ARXIV160201528CS
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Judd P., 2015, ARXIV151105236V4CSLG
   Judd P., 2016, MICRO 49
   Judd P., 2016, COMPUTER ARCHITECTUR
   Judd P., 2016, WORKSH APPR COMP WAP
   Muralimanohar N., CACTI 6 0 TOOL UNDER
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Poremba M, 2015, DES AUT TEST EUROPE, P1543
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J., 2016, ARXIV160207360, P779
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Warden Peter, 2016, LOW PRECISION MATRIX
   YAO HH, 1993, CONFERENCE RECORD OF THE TWENTY-SEVENTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P359, DOI 10.1109/ACSSC.1993.342534
NR 28
TC 127
Z9 131
U1 2
U2 8
PY 2017
BP 382
EP 394
DI 10.1145/3123939.3123982
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Lin, JP
   Haberstroh, F
   Karsch, S
   Döpp, A
AF Lin, Jinpu
   Haberstroh, Florian
   Karsch, Stefan
   Doepp, Andreas
TI Applications of object detection networks in high-power laser systems
   and experiments
SO HIGH POWER LASER SCIENCE AND ENGINEERING
DT Article
DE high repetition rate; laser-plasma accelerators; machine learning;
   object detection; optical diagnostics
ID PETAWATT; DRIVEN; DYNAMICS; PW
AB The recent advent of deep artificial neural networks has resulted in a dramatic increase in performance for object classification and detection. While pre-trained with everyday objects, we find that a state-of-the-art object detection architecture can very efficiently be fine-tuned to work on a variety of object detection tasks in a high-power laser laboratory. In this paper, three exemplary applications are presented. We show that the plasma waves in a laser-plasma accelerator can be detected and located on the optical shadowgrams. The plasma wavelength and plasma density are estimated accordingly. Furthermore, we present the detection of all the peaks in an electron energy spectrum of the accelerated electron beam, and the beam charge of each peak is estimated accordingly. Lastly, we demonstrate the detection of optical damage in a high-power laser system. The reliability of the object detector is demonstrated over 1000 laser shots in each application. Our study shows that deep object detection networks are suitable to assist online and offline experimental analysis, even with small training sets. We believe that the presented methodology is adaptable yet robust, and we encourage further applications in Hz-level or kHz-level high-power laser facilities regarding the control and diagnostic tools, especially for those involving image data.
C1 [Lin, Jinpu; Haberstroh, Florian; Karsch, Stefan; Doepp, Andreas] Ludwig Maximilians Univ Munchen, Garching, Germany.
RP Lin, JP (corresponding author), Ludwig Maximilians Univ Munchen, Coulombwall 1, D-85748 Garching, Germany.
EM Lin.Jinpu@physik.uni-muenchen.de
CR Amorin C, 2019, STAT ANAL DATA MIN, V12, P505, DOI 10.1002/sam.11437
   Borneis S, 2021, HIGH POWER LASER SCI, V9, DOI 10.1017/hpl.2021.16
   cala-laser.de/, US
   Danson CN, 2004, NUCL FUSION, V44, pS239, DOI 10.1088/0029-5515/44/12/S15
   Danson CN, 2019, HIGH POWER LASER SCI, V7, DOI 10.1017/hpl.2019.36
   Ding H, 2020, PHYS REV E, V101, DOI 10.1103/PhysRevE.101.023209
   Downer MC, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.035002
   Englesbe A, 2021, APPL OPTICS, V60, pG113, DOI 10.1364/AO.426240
   Gales S, 2018, REP PROG PHYS, V81, DOI 10.1088/1361-6633/aacfe8
   Gaul EW, 2010, APPL OPTICS, V49, P1676, DOI 10.1364/AO.49.001676
   Gilljohann MF, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.011046
   Girshick R, 2016, IEEE T PATTERN ANAL, V38, P142, DOI 10.1109/TPAMI.2015.2437384
   github, HTTPS GITHUB COM ULT
   Gonoskov A, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-43465-3
   Gu JX, 2018, PATTERN RECOGN, V77, P354, DOI 10.1016/j.patcog.2017.10.013
   He ZH, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8156
   Hidding B, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132626
   Hsu A, 2020, PHYS PLASMAS, V27, DOI 10.1063/1.5130585
   Humbird KD, 2020, IEEE T PLASMA SCI, V48, P61, DOI 10.1109/TPS.2019.2955098
   Humbird KD, 2019, IEEE T NEUR NET LEAR, V30, P1286, DOI 10.1109/TNNLS.2018.2869694
   Kurz T, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5041755
   Li WQ, 2018, OPT LETT, V43, P5681, DOI 10.1364/OL.43.005681
   Li ZW, 2022, IEEE T NEUR NET LEAR, V33, P6999, DOI 10.1109/TNNLS.2021.3084827
   Li Z, 2020, OPT EXPRESS, V28, P10165, DOI 10.1364/OE.387987
   Lin J, 2019, OPT EXPRESS, V27, P10912, DOI 10.1364/OE.27.010912
   Lin JP, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0047940
   Nees J., 2020, 2020 C LAS EL OPT CL, P1
   Noaman-ul-Haq M, 2018, NUCL INSTRUM METH A, V883, P191, DOI 10.1016/j.nima.2017.11.075
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Sävert A, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.055002
   Shalloo RJ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-20245-6
   Smith JR, 2020, NEW J PHYS, V22, DOI 10.1088/1367-2630/abbfce
   Streeter MJV, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5027297
   STRICKLAND D, 1985, OPT COMMUN, V55, P447, DOI 10.1016/0030-4018(85)90151-8
   Sung JH, 2017, OPT LETT, V42, P2058, DOI 10.1364/OL.42.002058
   Tudor P., 2022, LPA ONL WORKSH CONTR
   Wenz J, 2019, NAT PHOTONICS, V13, P263, DOI 10.1038/s41566-019-0356-z
   Yamashita R, 2018, INSIGHTS IMAGING, V9, P611, DOI 10.1007/s13244-018-0639-9
   Zhang ZX, 2020, HIGH POWER LASER SCI, V8, DOI 10.1017/hpl.2020.3
NR 39
TC 3
Z9 3
U1 9
U2 9
PD JAN 13
PY 2023
VL 11
AR e7
DI 10.1017/hpl.2023.1
WC Optics
DA 2023-11-11
ER

PT J
AU Tahir, A
   Morison, G
   Skelton, DA
   Gibson, RM
AF Tahir, Ahsen
   Morison, Gordon
   Skelton, Dawn A.
   Gibson, Ryan M.
TI Hardware/Software Co-Design of Fractal Features Based Fall Detection
   System
SO SENSORS
DT Article
DE fall detection; wearable sensors; classification; machine learning;
   fractal features; hardware software co-design; FPGA; reconfigurable
   design; embedded system on chip
ID TIME-SERIES; UNIT-ROOT; LONG; DYNAMICS; TESTS
AB Falls are a leading cause of death in older adults and result in high levels of mortality, morbidity and immobility. Fall Detection Systems (FDS) are imperative for timely medical aid and have been known to reduce death rate by 80%. We propose a novel wearable sensor FDS which exploits fractal dynamics of fall accelerometer signals. Fractal dynamics can be used as an irregularity measure of signals and our work shows that it is a key discriminant for classification of falls from other activities of life. We design, implement and evaluate a hardware feature accelerator for computation of fractal features through multi-level wavelet transform on a reconfigurable embedded System on Chip, Zynq device for evaluating wearable accelerometer sensors. The proposed FDS utilises a hardware/software co-design approach with hardware accelerator for fractal features and software implementation of Linear Discriminant Analysis on an embedded ARM core for high accuracy and energy efficiency. The proposed system achieves 99.38% fall detection accuracy, 7.3x speed-up and 6.53x improvements in power consumption, compared to the software only execution with an overall performance per Watt advantage of 47.6x, while consuming low reconfigurable resources at 28.67%.
C1 [Tahir, Ahsen; Morison, Gordon; Gibson, Ryan M.] Glasgow Caledonian Univ, Sch Comp Engn & Built Environm, Glasgow G4 0BA, Lanark, Scotland.
   [Tahir, Ahsen] Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Punjab, Pakistan.
   [Skelton, Dawn A.] Glasgow Caledonian Univ, Sch Hlth & Life Sci, Glasgow G4 0BA, Lanark, Scotland.
RP Tahir, A (corresponding author), Glasgow Caledonian Univ, Sch Comp Engn & Built Environm, Glasgow G4 0BA, Lanark, Scotland.; Tahir, A (corresponding author), Univ Engn & Technol, Dept Elect Engn, Lahore 54890, Punjab, Pakistan.
EM ahsen.tahir@gcu.ac.uk; Gordon.Morison@gcu.ac.uk; Dawn.Skelton@gcu.ac.uk;
   Ryan.Gibson@gcu.ac.uk
CR Abdelwahab S., 2017, P 2 INT C COMPUTING, P1, DOI DOI 10.1145/3167486
   Akouaydi H, 2017, 2017 1ST INTERNATIONAL WORKSHOP ON ARABIC SCRIPT ANALYSIS AND RECOGNITION (ASAR), P153, DOI 10.1109/ASAR.2017.8067778
   Ali AAS, 2014, I C COMP SYST APPLIC, P685, DOI 10.1109/AICCSA.2014.7073266
   Ali SF, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18061918
   [Anonymous], DIG ACC ADXL345 EP
   [Anonymous], P SAI INT SYST C LON
   [Anonymous], P 2017 IEEE E W DES
   [Anonymous], INT J COMPUT ELECT A
   [Anonymous], 1973, P SECT INT S INF THE, DOI 10.1007/978-1-4612-1694-0
   Bizovska L, 2018, PLOS ONE, V13, DOI 10.1371/journal.pone.0197091
   Box G.E.P., 1976, TIME SERIES ANAL FOR, P575
   Chelli A, 2019, IEEE ACCESS, V7, P38670, DOI 10.1109/ACCESS.2019.2906693
   Coviello G, 2020, IEEE SENS J, V20, P8771, DOI 10.1109/JSEN.2020.2982744
   de Fontenay BP, 2020, IEEE SENS J, V20, P7783, DOI 10.1109/JSEN.2020.2982568
   DICKEY DA, 1979, J AM STAT ASSOC, V74, P427, DOI 10.2307/2286348
   Diebolt C, 2005, QUAL QUANT, V39, P827, DOI 10.1007/s11135-004-0436-z
   Doulamis A, 2018, 11TH ACM INTERNATIONAL CONFERENCE ON PERVASIVE TECHNOLOGIES RELATED TO ASSISTIVE ENVIRONMENTS (PETRA 2018), P558, DOI 10.1145/3197768.3201543
   FLANDRIN P, 1992, IEEE T INFORM THEORY, V38, P910, DOI 10.1109/18.119751
   Gibson RM, 2017, BIOMED SIGNAL PROCES, V33, P96, DOI 10.1016/j.bspc.2016.10.016
   Gibson RM, 2016, APPL SOFT COMPUT, V39, P94, DOI 10.1016/j.asoc.2015.10.062
   Gomez Rivera D., 2016, International Journal of Information and Electronics Engineering, V6, P313, DOI 10.18178/ijiee.2016.6.5.645
   Hausdorff JM, 2007, HUM MOVEMENT SCI, V26, P555, DOI 10.1016/j.humov.2007.05.003
   Hsieh CY, 2018, PROCEEDINGS OF 4TH IEEE INTERNATIONAL CONFERENCE ON APPLIED SYSTEM INNOVATION 2018 ( IEEE ICASI 2018 ), P818, DOI 10.1109/ICASI.2018.8394388
   Hsieh YZ, 2018, IEEE ACCESS, V6, P6048, DOI 10.1109/ACCESS.2017.2771389
   Hussain F, 2019, IEEE SENS J, V19, P4528, DOI 10.1109/JSEN.2019.2898891
   Iqbal S, 2015, INT CONF ELECTRO INF, P25, DOI 10.1109/EIT.2015.7293419
   Josinski H, 2015, LECT NOTES ARTIF INT, V9012, P317, DOI 10.1007/978-3-319-15705-4_31
   Kim S, 2018, PROC VLDB ENDOW, V12, P1, DOI 10.14778/3275536.3275537
   Koutsiana E, 2017, FRONT BIOENG BIOTECH, V5, DOI 10.3389/fbioe.2017.00049
   KWIATKOWSKI D, 1992, J ECONOMETRICS, V54, P159, DOI 10.1016/0304-4076(92)90104-Y
   Kwolek B, 2014, COMPUT METH PROG BIO, V117, P489, DOI 10.1016/j.cmpb.2014.09.005
   Liu KC, 2018, IEEE SENS J, V18, P9882, DOI 10.1109/JSEN.2018.2872835
   Lu N, 2019, IEEE J BIOMED HEALTH, V23, P314, DOI 10.1109/JBHI.2018.2808281
   MANDELBROT B, 1967, SCIENCE, V156, P636, DOI 10.1126/science.156.3775.636
   Margiotta N., 2016, P 2016 5 INT C EL DE, P1
   Mau Dung Nguyen, 2020, 2020 IEEE International Conference on Consumer Electronics (ICCE), DOI 10.1109/ICCE46568.2020.9042999
   Morbidoni C, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8080894
   NG S, 1995, J AM STAT ASSOC, V90, P268, DOI 10.2307/2291151
   Noury N, 2008, IRBM, V29, P340, DOI 10.1016/j.irbm.2008.08.002
   Ong PS, 2014, IEEE REGION 10 SYMP, P397, DOI 10.1109/TENCONSpring.2014.6863065
   Pang I, 2019, J GERIATR PHYS THER, V42, P48, DOI 10.1519/JPT.0000000000000181
   Park SH, 2020, PAEDIATR INT CHILD H, V40, P166, DOI 10.1080/20469047.2020.1747002
   Perc M, 2005, EUR J PHYS, V26, P525, DOI 10.1088/0143-0807/26/3/017
   Reynard F, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0100550
   Rossignol S, 2006, PHYSIOL REV, V86, P89, DOI 10.1152/physrev.00028.2005
   Saadeh W, 2019, IEEE T NEUR SYS REH, V27, P995, DOI 10.1109/TNSRE.2019.2911602
   Saadeh W, 2017, 2017 IEEE EMBS INTERNATIONAL CONFERENCE ON BIOMEDICAL & HEALTH INFORMATICS (BHI), P441, DOI 10.1109/BHI.2017.7897300
   Sahoo S, 2020, IEEE SENS J, V20, P8128, DOI 10.1109/JSEN.2020.2980863
   Schneider B, 2020, HEALTHC TECHNOL LETT, V7, P25, DOI 10.1049/htl.2019.0015
   Schwert GW, 2002, J BUS ECON STAT, V20, P5, DOI 10.1198/073500102753410354
   Sekine M, 2002, IEEE T NEUR SYS REH, V10, P188, DOI 10.1109/TNSRE.2002.802879
   Senouci B, 2016, J REAL-TIME IMAGE PR, V12, P649, DOI 10.1007/s11554-014-0456-4
   SOWELL F, 1992, J MONETARY ECON, V29, P277, DOI 10.1016/0304-3932(92)90016-U
   Stadnitski T, 2012, FRONT PHYSIOL, V3, DOI 10.3389/fphys.2012.00127
   Sucerquia A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17010198
   Sukor ASA, 2018, 2018 IEEE 14TH INTERNATIONAL COLLOQUIUM ON SIGNAL PROCESSING & ITS APPLICATIONS (CSPA 2018), P233, DOI 10.1109/CSPA.2018.8368718
   Tahir A, 2021, PROBAB ENG INFORM SC, V35, P37, DOI 10.1017/S0269964819000317
   Terrier P, 2011, J NEUROENG REHABIL, V8, DOI 10.1186/1743-0003-8-12
   Tian Y., 2013, EXPLORING SYSTEM WID
   Gia TN, 2018, MICROPROCESS MICROSY, V56, P34, DOI 10.1016/j.micpro.2017.10.014
   Nguyen TL, 2018, INT CONF KNOWL SYS, P129, DOI 10.1109/KSE.2018.8573328
   Vavoulas G, 2013, IEEE INT C BIOINF BI
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   WORNELL GW, 1992, IEEE T SIGNAL PROCES, V40, P611, DOI 10.1109/78.120804
   Xu T, 2018, INT J WAVELETS MULTI, V16, DOI 10.1142/S0219691318400052
   Zhang YD, 2016, IEEE ACCESS, V4, P5937, DOI 10.1109/ACCESS.2016.2611530
   Zhong ZC, 2018, IEEE ASME INT C ADV, P1039, DOI 10.1109/AIM.2018.8452687
NR 67
TC 2
Z9 2
U1 0
U2 5
PD APR
PY 2020
VL 20
IS 8
AR 2322
DI 10.3390/s20082322
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT C
AU Adavally, S
   Weaver, A
   Vasireddy, P
   Kavi, K
   Mehta, G
   Gulur, N
AF Adavally, Shashank
   Weaver, Alex
   Vasireddy, Pranathi
   Kavi, Krishna
   Mehta, Gayatri
   Gulur, Nagendra
GP IEEE Comp Soc
TI HETEROGENEOUS ARCHITECTURE FOR SPARSE DATA PROCESSING
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE Sparse matrices; DNN; Hardware Accelerators; RISCV
AB Sparse matrices are very common types of information used in scientific and machine learning applications including deep neural networks. Sparse data representations lead to storage efficiencies by avoiding storing zero values. However, sparse representations incur metadata computational overheads - software first needs to find row/column locations of non-zero values before performing necessary computations. Such metadata accesses involve indirect memory accesses (of the form a[b[i] ] where a[.] and b[.] are large arrays) and they are cache and prefetch-unfriendly, resulting in frequent load stalls.
   In this paper, we will explore a dedicated hardware for a memory-side accelerator called Hardware Helper Thread (HHT) that performs all the necessary index computations to fetch only the nonzero elements from sparse matrix and sparse vector and supply those values to the primary core, creating heterogeneity within a single CPU core. We show both performance gains and energy savings of HHT for sparse matrix-dense vector multiplication (SpMV) and sparse matrixsparse vector multiplication (SpMSpV). The ASIC HHT shows average performance gains ranging between 1.7 and 3.5 depending on the sparsity levels, vector-widths used by RISCV vector instructions and if the Vector (in Matrix-Vector multiplication) is sparse or dense. We also show energy savings of 19% on average when ASIC HHT is used compared to baseline (for SpMV), and the HHT requires 38.9% of a RISCV core area.
C1 [Adavally, Shashank; Weaver, Alex; Vasireddy, Pranathi; Kavi, Krishna; Mehta, Gayatri; Gulur, Nagendra] Univ North Texas, Denton, TX 76203 USA.
RP Adavally, S (corresponding author), Univ North Texas, Denton, TX 76203 USA.
CR Adavally S, 2020, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, MEMSYS 2020, P46, DOI 10.1145/3422575.3422777
   Agrawal SR, 2016, ACM SIGPLAN NOTICES, V51, P25, DOI 10.1145/2851141.2851144
   Azad A, 2018, NUCLEIC ACIDS RES, V46, DOI 10.1093/nar/gkx1313
   Azad A, 2017, INT PARALL DISTRIB P, P688, DOI 10.1109/IPDPS.2017.76
   Azad A, 2015, 2015 IEEE 29TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS, P804, DOI 10.1109/IPDPSW.2015.75
   Barredo A, 2019, INT CONFER PARA, P482, DOI 10.1109/PACT.2019.00056
   Bell N, 2009, PROCEEDINGS OF THE CONFERENCE ON HIGH PERFORMANCE COMPUTING NETWORKING, STORAGE AND ANALYSIS
   Buluc A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P721, DOI 10.1109/IPDPS.2011.73
   Buluç A, 2011, INT J HIGH PERFORM C, V25, P496, DOI 10.1177/1094342011403516
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Buluc Aydin., SIAM J SCI COMPUTING, V34
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Farzaneh A, 2009, COMMUN FAC SCI UNIV, V58, P1, DOI 10.1501/Commua1_0000000648
   Fox L.M, 2003, WORKSHOP COMPILERS T
   Gonzalez Abraham, 2019, RISC V ISA SIM
   Greathouse JL, 2014, INT CONF HIGH PERFOR, P769, DOI 10.1109/SC.2014.68
   Gremse F, 2015, SIAM J SCI COMPUT, V37, pC54, DOI 10.1137/130948811
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He Guoming, 2010, KDD, P543
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A, 2018, CVPR
   Howard Andrew G., 2017, arXiv
   Huang G, 2016, LECT NOTES COMPUT SC, V9908, P646, DOI 10.1007/978-3-319-46493-0_39
   Intel, 2019, OV INTR INT
   Kanellopoulos K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P600, DOI 10.1145/3352460.3358286
   Li W., 2006, IEEE COMPUT ARCHIT L, V5
   lowRISC, 2017, IBEX EMB 32 BIT RISC
   Moreau T., 2019, IEEE MICRO
   NXP, 2019, NXP MICR OV
   NXP, 2019, MICR MICR
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Raghavan UN, 2007, PHYS REV E, V76, DOI 10.1103/PhysRevE.76.036106
   Rawal A, 2019, IEEE SYM PARA DISTR, P47, DOI 10.1109/IPDPSW.2019.00016
   Rezaei M, 2006, J SYST ARCHITECT, V52, P41, DOI 10.1016/j.sysarc.2005.02.004
   RISCV Foundation, 2020, RISCV VECT EXT SPEC
   RISCV Foundation, 2020, RISC V FREE OP RISC
   Sadi F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P347, DOI 10.1145/3352460.3358330
   SCHAUMBURG K, 1980, COMPUT CHEM, V4, P1, DOI 10.1016/0097-8485(80)85003-0
   Simonyan K., 2015, ICLR
   Stephens N, 2017, IEEE MICRO, V37, P26, DOI 10.1109/MM.2017.35
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   TI, 2019, MSP432P401R MSP432P4
   Wu ZH, 2021, IEEE T NEUR NET LEAR, V32, P4, DOI 10.1109/TNNLS.2020.2978386
   Yavits Leonid, 2017, CORR
   Yu XY, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P178, DOI 10.1145/2830772.2830807
   Zhang Y., 2017, CORR
NR 48
TC 1
Z9 1
U1 1
U2 2
PY 2022
BP 6
EP 15
DI 10.1109/IPDPSW55747.2022.00012
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Meyers, V
   Gnad, D
   Tahoori, M
AF Meyers, Vincent
   Gnad, Dennis
   Tahoori, Mehdi
GP IEEE
TI Reverse Engineering Neural Network Folding with Remote FPGA Power
   Analysis
SO 2022 IEEE 30TH INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM
   COMPUTING MACHINES (FCCM 2022)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT IEEE 30th International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 15-18, 2022
CL New York, NY
ID GOLDEN-AGE
AB Specialized hardware accelerators in the form of FPGAs are widely being used for neural network implementations. By that, they also become the target of power analysis attacks that try to reverse engineer the embedded secret information, in the form of model parameters. However, most of these attacks assume rather simple implementations, not realistic frameworks. Layer folding is used in such accelerators to optimize the network under given area constraints with various degrees of parallel and sequential operations. In this paper, we show that folding does mislead existing power side-channel attacks on frameworks such as FINN. We show how we can extract the folding parameters successfully and use that information to subsequently also recover the number of neurons - something not reliably possible without knowing the folding information. Following the methodologies of both profiling side-channel attacks and machine learning, our approach can extract the amount of neurons with 98% accuracy on a test device, compared to 44-79% accuracy based on related work under the same test conditions and datasets. Furthermore, we show how a classifier that is based on regression can detect previously unknown parameters, which has not been shown before. To verify our results under different environmental conditions, we test the target device in a climate chamber under various temperature ranges and still reach accuracies of at least 93%.
C1 [Meyers, Vincent; Gnad, Dennis; Tahoori, Mehdi] Karlsruhe Inst Technol KIT, Chair Dependable Nano Comp CDNC, Karlsruhe, Germany.
RP Meyers, V (corresponding author), Karlsruhe Inst Technol KIT, Chair Dependable Nano Comp CDNC, Karlsruhe, Germany.
EM vincent.meyers@student.kit.edu; dennis.gnad@kit.edu;
   mehdi.tahoori@kit.edu
CR Amazon Web Services, EC2 EL COMP CLOUD
   [Anonymous], 2021, ALIBABA CLOUD CLOUD
   [Anonymous], 2018, IACR T CRYPTOGRAPHIC
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Breier J, 2022, IEEE T RELIAB, V71, P1527, DOI 10.1109/TR.2021.3105697
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Christ M, 2018, NEUROCOMPUTING, V307, P72, DOI 10.1016/j.neucom.2018.03.067
   Dean J, 2018, IEEE MICRO, V38, P21, DOI 10.1109/MM.2018.112130030
   Dubey A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415649
   Dubey A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P197, DOI [10.1109/HOST45689.2020.9300276, 10.1109/host45689.2020.9300276]
   Fahn PN, 1999, LECT NOTES COMPUT SC, V1717, P173
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Glamocanin O, 2020, DES AUT TEST EUROPE, P1007, DOI 10.23919/DATE48585.2020.9116481
   Guo P, 2018, I C FIELD PROG LOGIC, P51, DOI 10.1109/FPL.2018.00016
   Hennessy JL, 2019, COMMUN ACM, V62, P48, DOI 10.1145/3282307
   Heuser A, 2012, LECT NOTES COMPUT SC, V7178, P365, DOI 10.1007/978-3-642-27954-6_23
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Krautter J, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942094
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Li YX, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3154839
   Liu WY, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218577
   Masle A. L., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P14, DOI 10.1109/FPL.2012.6339235
   Moini S, 2021, IEEE J EM SEL TOP C, V11, P357, DOI 10.1109/JETCAS.2021.3074608
   Moreau T, 2019, Arxiv, DOI arXiv:1807.04188
   Murshed MGS, 2021, ACM COMPUT SURV, V54, DOI 10.1145/3469029
   Paszke A, 2019, ADV NEUR IN, V32
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Rakin AS, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1919
   Real MM, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11156790
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Tian SQ, 2021, ANN IEEE SYM FIELD P, P242, DOI 10.1109/FCCM51124.2021.00037
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Wolf S, 2021, IEEE COMP SOC ANN, P242, DOI 10.1109/ISVLSI51109.2021.00052
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zick K. M., 2013, P ACM SIGDA INT S FI, P101, DOI DOI 10.1145/2435264.2435283
NR 46
TC 1
Z9 1
U1 0
U2 3
PY 2022
BP 122
EP 131
DI 10.1109/FCCM53951.2022.9786107
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ardakani, A
   Condo, C
   Ahmadi, M
   Gross, WJ
AF Ardakani, Arash
   Condo, Carlo
   Ahmadi, Mehdi
   Gross, Warren J.
TI An Architecture to Accelerate Convolution in Deep Neural Networks
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Convolutional neural networks; deep neural network; machine learning;
   hardware implementation; pattern recognition; very large scale
   integration (VLSI)
AB In the past few years, the demand for real-time hardware implementations of deep neural networks (DNNs), especially convolutional neural networks (CNNs), has dramatically increased, thanks to their excellent performance on a wide range of recognition and classification tasks. When considering real-time action recognition and video/image classification systems, latency is of paramount importance. Therefore, applications strive to maximize the accuracy while keeping the latency under a given application-specific maximum: in most cases, this threshold cannot exceed a few hundred milliseconds. Until now, the research on DNNs has mainly focused on achieving a better classification or recognition accuracy, whereas very few works in literature take in account the computational complexity of the model. In this paper, we propose an efficient computational method, which is inspired by a computational core of fully connected neural networks, to process convolutional layers of state-of-the-art deep CNNs within strict latency requirements. To this end, we implemented our method customized for VGG and VGG-based networks which have shown state-of-the-art performance on different classification/recognition data sets. The implementation results in 65-nm CMOS technology show that the proposed accelerator can process convolutional layers of VGGNet up to 9.5 times faster than state-of-the-art accelerators reported to-date while occupying 3.5 mm(2).
C1 [Ardakani, Arash; Condo, Carlo; Gross, Warren J.] McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 0E9, Canada.
   [Ahmadi, Mehdi] Polytech Montreal, Dept Comp Engn, Montreal, PQ H3T 1J4, Canada.
RP Ardakani, A (corresponding author), McGill Univ, Dept Elect & Comp Engn, Montreal, PQ H3A 0E9, Canada.
EM arash.ardakani@mail.mcgill.ca; carlo.condo@mail.mcgill.ca;
   mehdi.ahmadi@polymtl.ca; warren.gross@mcgill.ca
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Ardakani A., 2016, ARXIV PREPRINT ARXIV, V3, P1
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Ardakani A, 2016, INT SYM TURBO CODES, P216, DOI 10.1109/ISTC.2016.7593108
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cavigelli L, 2017, IEEE T CIRC SYST VID, V27, P2461, DOI 10.1109/TCSVT.2016.2592330
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen TYH, 2015, SenSys'15: Proceedings of the 13th ACM Conference on Embedded Networked Sensor Systems, P155, DOI 10.1145/2809695.2809711
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chollet F., 2015, KERAS
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Han S., 2016, INT C LEARN REPR ICL
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Knag Phil, 2016, 2016 IEEE Symposium on VLSI Circuits (VLSI-Circuits), DOI 10.1109/VLSIC.2016.7573526
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Labs H. P., TECH REP, P1
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Mettler Toledo Inc, DDR4 SDRAM AUT
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Moreno Felix, 2008, IECON 2008 - 34th Annual Conference of IEEE Industrial Electronics Society, P2445, DOI 10.1109/IECON.2008.4758340
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   Pullini A, 2018, IEEE T CIRCUITS-II, V65, P1094, DOI 10.1109/TCSII.2017.2652982
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Smithson S. C., 2016, P 35 INT C COMP AID, P1, DOI DOI 10.1145/2966986.2967058
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Vedaldi A, 2015, MM'15: PROCEEDINGS OF THE 2015 ACM MULTIMEDIA CONFERENCE, P689, DOI 10.1145/2733373.2807412
   Wang S., 2017, CHAIN NN ENERGY EFFI
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Yang ZC, 2015, IEEE I CONF COMP VIS, P1476, DOI 10.1109/ICCV.2015.173
NR 41
TC 75
Z9 76
U1 1
U2 30
PD APR
PY 2018
VL 65
IS 4
BP 1349
EP 1362
DI 10.1109/TCSI.2017.2757036
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chikin, A
   Amaral, JN
   Ali, K
   Tiotto, E
AF Chikin, Artem
   Amaral, Jose Nelson
   Ali, Karim
   Tiotto, Ettore
GP IEEE
TI Toward an Analytical Performance Model to Select between GPU and CPU
   Execution
SO 2019 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS (IPDPSW)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 33rd IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 20-24, 2019
CL Rio de Janeiro, BRAZIL
DE Heterogeneous Computing; OpenMP; GPGPU; MIC; Static Analysis; Hybrid
   Analysis; Performance Model
ID PREDICTION
AB Automating the device selection in heterogeneous computing platforms requires the modelling of performance both on CPUs and on accelerators. This work argues for the use of a hybrid analytical performance modelling approach is a practical way to build fast and efficient methods to select an appropriate target for a given computation kernel. The target selection problem has been addressed in the literature, however there has been a strong emphasis on building empirical models with machine learning techniques. We argue that the applicability of such solutions is often limited in production systems. This paper focus on the issue of building a selector to decide if an OpenMP loop nest should be executed in a CPU or in a GPU. To this end, it offers a comprehensive comparison evaluation of the difference in GPU kernel performance on devices of multiple generations of architectures. The idea is to underscore the need for accurate analytical performance models and to provide insights in the evolution of GPU accelerators. This work also highlights a drawback of existing approaches to modelling GPU performance - accurate modelling of memory coalescing characteristics. To that end, we examine a novel application of an inter-thread difference analysis that can further improve analytical models. Finally, this work presents an initial study of an Open Multi-Processing (OpenMP) runtime framework for target-offloading target selection.
C1 [Chikin, Artem] Intel Corp, Toronto, ON, Canada.
   [Amaral, Jose Nelson; Ali, Karim] Univ Alberta, Edmonton, AB, Canada.
   [Tiotto, Ettore] IBM Canada, Markham, ON, Canada.
RP Chikin, A (corresponding author), Intel Corp, Toronto, ON, Canada.
EM artem.chikin@intel.com; jamaral@ualberta.ca; karim2@ualberta.ca;
   etiotto@ca.ibm.com
CR Aversa R, 2005, PARALLEL COMPUT, V31, P1013, DOI 10.1016/j.parco.2005.03.009
   BOLLINGER SW, 1991, IEEE T COMPUT, V40, P325, DOI 10.1109/12.76410
   Bull J., 1999, EUR WORKSH OPENMP
   Bull J. M., 2012, IWOMP 12
   Chennupati G, 2018, LECT NOTES COMPUT SC, V10724, P114, DOI 10.1007/978-3-319-72971-8_6
   Chikin A., 2018, pattent Application, Patent No. 15918334
   Dagum L., 1998, IEEE COMPUTATIONAL S
   Daoud MI, 2008, J PARALLEL DISTR COM, V68, P399, DOI 10.1016/j.jpdc.2007.05.015
   Eichenberger A. E., 2013, OPENMP ERA LOW POWER
   ELREWINI H, 1990, J PARALLEL DISTR COM, V9, P138, DOI 10.1016/0743-7315(90)90042-N
   Fauzia N, 2015, INT SYM CODE GENER, P12, DOI 10.1109/CGO.2015.7054183
   Gera P, 2018, INT SYM PERFORM ANAL, P139, DOI 10.1109/ISPASS.2018.00027
   Ghane M., 2015, OPENMP HETEROGENOUS
   Grobelny E, 2007, SIMUL-T SOC MOD SIM, V83, P721, DOI 10.1177/0037549707084939
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Ipek E, 2005, LECT NOTES COMPUT SC, V3648, P196
   Jia Z., 2018, DISSECTING NVIDIA VO
   Kaleem R, 2014, INT CONFER PARA, P151, DOI 10.1145/2628071.2628088
   Laukemann J., 2018, AUTOMATED INSTRUCTIO
   Lee BC, 2007, PROCEEDINGS OF THE 2007 ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING PPOPP'07, P249, DOI 10.1145/1229428.1229479
   Liao CH, 2007, CONCURR COMP-PRACT E, V19, P2317, DOI 10.1002/cpe.1174
   Liao S, 2007, I S BIOMED IMAGING, P5, DOI 10.1109/ISBI.2007.356774
   Lloyd T., 2018, WAMCA 2018
   Pallipuram VK, 2015, J SUPERCOMPUT, V71, P162, DOI 10.1007/s11227-014-1292-9
   Rolls Daniel, 2010, Proceedings of the 18th IEEE International Conference on Program Comprehension (ICPC 2010), P50, DOI 10.1109/ICPC.2010.36
   Singh K, 2007, CONCURR COMP-PRACT E, V19, P2219, DOI 10.1002/cpe.1171
   Snavely A, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P149, DOI 10.1109/WWC.2001.990754
   Valero-Lara P., 2014, COMPUTER PHYS COMMUN, V185
   Valero-Lara P., 2017, CONCURRENCY COMPUTAT, V29
   Wang Z., 2009, PRINCIPLES PRACTICE
   Wolf ME, 1996, PROCEEDINGS OF THE 29TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE - MICRO-29, P274, DOI 10.1109/MICRO.1996.566468
   Xingfu Wu, 2011, Proceedings of the 2011 IEEE 14th International Conference on Computational Science and Engineering (CSE 2011). 11th International Symposium on Pervasive Systems, Algorithms, Networks (I-SPAN 2011). 10th IEEE International Conference on Ubiquitous Computing and Communications (IUCC 2011), P181, DOI 10.1109/CSE.2011.42
NR 32
TC 5
Z9 5
U1 0
U2 0
PY 2019
BP 353
EP 362
DI 10.1109/IPDPSW.2019.00068
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Paim, G
   Amrouch, H
   da Costa, EAC
   Bampi, S
   Henkel, J
AF Paim, Guilherme
   Amrouch, Hussam
   da Costa, Eduardo Antonio Cesar
   Bampi, Sergio
   Henkel, Joerg
TI Bridging the Gap Between Voltage Over-Scaling and Joint Hardware
   Accelerator-Algorithm Closed-Loop
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
DT Article
DE Timing; Hardware; Logic gates; Encoding; Heuristic algorithms;
   Standards; Runtime; Voltage over-scaling; timing errors; closed-loops
ID DESIGN METHODOLOGY; ARCHITECTURE; IMAGE
AB Voltage over-scaling (VOS) optimizes energy while causing timing errors due to an unsustainable clock frequency. Many algorithms, such as in multimedia and machine learning applications, are capable of tolerating such errors. VOS has never been investigated in hardware accelerators running closed-loop algorithms. As the errors impact most decisions and actions in the subsequent steps, closed-loops dynamically change the execution flow. Timing errors should be evaluated by an accurate gate-level simulation, but a large gap still remains: how these timing errors propagate from the underlying hardware all the way up to the entire algorithm run, where they just may degrade the performance and quality of service of the application at stake? This paper tackles this issue showing a framework for VOS investigation, embracing any kind of application. Our framework simulates the VOS-induced timing errors at gate-level, dynamically linking the hardware result with the algorithm and vice versa during the evolution of the runtime of the application. The state-of-the-art VOS literature for video encoding application fails to assess the ultimate impacts of VOS-induced timing errors, as current works open the encoding loops. Unlike those, our work investigates the ultimate impact of a hardware accelerator dynamically carrying through to the video encoder all VOS-induced timing errors and preserving the full compliance to the standard. We employ a parallel sum of absolute differences (SAD) hardware accelerator as a case study. We assess the performance of the overall encoder under varying timing guardbands. Next, it is demonstrated that, under VOS, the ultimate impact in compression efficiency is related to the video's motion intensity. Additionally, the advantages of timing guardband controlled reduction are clearly quantified in our results by virtue of the framework. Reducing at maximum 9.5% the clock frequency, energy savings (up to 16.5% in energy/operation) are achieved in SAD for video compression.
C1 [Paim, Guilherme; Bampi, Sergio] Univ Fed Rio Grande Sul UFRGS, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
   [Amrouch, Hussam] Univ Stuttgart, Chair Semicond Test & Reliabil STAR, D-70174 Stuttgart, Germany.
   [da Costa, Eduardo Antonio Cesar] Univ Catolica Pelotas UCPel, Grad Program Elect & Comp, BR-96015560 Pelotas, RS, Brazil.
   [Henkel, Joerg] Karlsruhe Inst Technol KIT, Chair Embedded Syst CES, D-76131 Karlsruhe, Germany.
RP Paim, G (corresponding author), Univ Fed Rio Grande Sul UFRGS, Grad Program Microelect PGMICRO, BR-91501970 Porto Alegre, RS, Brazil.
EM gppaim@inf.ufrgs.br; amrouch@iti.uni-stuttgart.de;
   eduardo.costa@ucpel.edu.br; bampi@inf.ufrgs.br; henkel@kit.edu
CR Afzali-Kusha H, 2020, INT SYM QUAL ELECT, P67, DOI [10.1109/isqed48828.2020.9137039, 10.1109/ISQED48828.2020.9137039]
   Afzali-Kusha H, 2020, IEEE T VLSI SYST, V28, P1207, DOI 10.1109/TVLSI.2020.2978874
   Amrouch H, 2019, IEEE T COMPUT, V68, P1647, DOI 10.1109/TC.2019.2916869
   Amrouch H, 2017, DES AUT CON, DOI 10.1145/3061639.3062331
   [Anonymous], 2019, VLSI ARCHITECTURES F
   [Anonymous], 2019, DEGRADATION AWARE CE
   Bossen F., 2013, JCTVCK1100
   Brkic S, 2017, 2017 25TH TELECOMMUNICATION FORUM (TELFOR), P246
   Brkic S, 2017, IEEE T INFORM THEORY, V63, P6295, DOI 10.1109/TIT.2017.2741466
   Cai H, 2016, IEEE INT SYMP NANO, P203, DOI 10.1145/2950067.2950101
   Chen JA, 2013, IEEE T VLSI SYST, V21, P1322, DOI 10.1109/TVLSI.2012.2205953
   Chen MY, 2014, BIOMED CIRC SYST C, P628, DOI 10.1109/BioCAS.2014.6981804
   Enomoto T, 2013, ASIA S PACIF DES AUT, P75, DOI 10.1109/ASPDAC.2013.6509563
   Han J, 2016, IEEE T CIRCUITS-II, V63, P984, DOI 10.1109/TCSII.2016.2538158
   He K, 2013, IEEE T CIRC SYST VID, V23, P961, DOI 10.1109/TCSVT.2013.2243658
   Jeon D, 2012, IEEE T CIRCUITS-II, V59, P952, DOI 10.1109/TCSII.2012.2231036
   Kammoun A, 2020, IEEE T CIRC SYST VID, V30, P4340, DOI 10.1109/TCSVT.2019.2954749
   Liu RF, 2011, IEEE J EM SEL TOP C, V1, P343, DOI 10.1109/JETCAS.2011.2165749
   Liu Y, 2010, IEEE T VLSI SYST, V18, P517, DOI 10.1109/TVLSI.2009.2012863
   Masera M, 2017, IEEE T CIRC SYST VID, V27, P2714, DOI 10.1109/TCSVT.2016.2595320
   Mohanty BK, 2020, IEEE T CIRC SYST VID, V30, P4944, DOI 10.1109/TCSVT.2020.2966376
   Myers J, 2016, IEEE J SOLID-ST CIRC, V51, P31, DOI 10.1109/JSSC.2015.2477046
   Oliveira PAM, 2017, IEEE T CIRC SYST VID, V27, P1066, DOI 10.1109/TCSVT.2016.2515378
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Salamin S, 2019, I SYMPOS LOW POWER E
   Sedighi B, 2014, I SYMPOS LOW POWER E, P201, DOI 10.1145/2627369.2627638
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tu FB, 2019, IEEE T CIRC SYST VID, V29, P892, DOI 10.1109/TCSVT.2018.2812781
   Vangal S, 2020, J LOW POWER ELECT AP, V10, DOI 10.3390/jlpea10020016
   Varatkar GV, 2006, ISLPED '06: PROCEEDINGS OF THE 2006 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P113, DOI 10.1109/LPE.2006.4271817
   Varatkar GV, 2008, IEEE T VLSI SYST, V16, P1399, DOI 10.1109/TVLSI.2008.2000675
   Wang SH, 2017, IEEE T CIRC SYST VID, V27, P380, DOI 10.1109/TCSVT.2015.2511858
   Weibrich M., 2017, P 27 INT S POW TIM M, P1
   Weissbrich M., 2019, Integration, The VLSI Journal, V69, P120, DOI 10.1016/j.vlsi.2019.01.002
   Zervakis G, 2019, IEEE T CIRCUITS-II, V66, P607, DOI 10.1109/TCSII.2018.2869025
   Zervakis G, 2018, IEEE T VLSI SYST, V26, P1204, DOI 10.1109/TVLSI.2018.2803202
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
NR 42
TC 3
Z9 3
U1 2
U2 6
PD JAN
PY 2022
VL 32
IS 1
BP 398
EP 410
DI 10.1109/TCSVT.2021.3059229
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Diamantopoulos, D
   Hagleitner, C
AF Diamantopoulos, Dionysios
   Hagleitner, Christoph
GP IEEE
TI HelmGemm: Managing GPUs and FPGAs for transprecision GEMM workloads in
   containerized environments
SO 2019 IEEE 30TH INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2019)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 30th IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 15-17, 2019
CL Cornell Tech, New York, NY
HO Cornell Tech
DE cloud computing; coherent accelerators; container; energy saving; FPGA;
   transprecision computing
AB Major global vendors, including Google, IBM, Facebook and Amazon, have recently provided containerized system configurations as a competitive alternative to traditional hypervisor-based virtualization thanks to their rapid deployment, efficiency, compatibility, and maintainability. Similar to traditional cloud environments, energy consumption still constitutes the lion's share of overall infrastructure operating expenses. Most public and private cloud providers have coupled their datacenters with accelerators such as GPUs and FPGAs to improve the energy efficiency of their systems. However, it remains a challenging task to manage such heterogeneous systems and share resources in multi-tenant environments while improving energy efficiency. To address this need, we propose HelmGemm, a system-level component to support energy-efficient computing on CPU GPU FPGA heterogeneous architectures for container services. HelmGemm is application-specific to workloads featuring the BLAS3 GEMM routine and allows precision selection across the computational progress, i.e. a technique that recently gave rise to the term "transprecision computing". By evaluating HelmGemm on a POWER9 system with 4 x V100 GPUs and 2x9V3 FPGAs, we succeeded in improving the average energy efficiency by up to 2.3x in containerized configurations across three representative GEMM-based cloud applications in the field of machine learning, i.e. for speech recognition, language modeling, and deep neural networks.
C1 [Diamantopoulos, Dionysios; Hagleitner, Christoph] IBM Res, Zurich, Switzerland.
RP Diamantopoulos, D (corresponding author), IBM Res, Zurich, Switzerland.
EM did@zurich.ibm.com; hle@zurich.ibm.com
CR [Anonymous], 2015, ACM COMPUT SURV, DOI DOI 10.1145/
   Farhadi A, 2018, YOLOV3 INCREMENTAL I, DOI DOI 10.1109/TPAMI.2016.2577031
   Kang Dong-Ki, 2016, J MOBILE NETWORKS AP
   Kayiran O., 2014, 47 ANN IEEE ACM MICR
   Kim Daehyeok, 2019, NSDI
   Licht Johannes de Fine, 2018, TRANSFORMATIONS HIGH
   Malossi A. C. I., 2018, DATE
NR 7
TC 5
Z9 6
U1 0
U2 0
PY 2019
BP 71
EP 74
DI 10.1109/ASAP.2019.00-27
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Hrinivich, WT
   Lee, J
AF Hrinivich, William Thomas
   Lee, Junghoon
TI Artificial intelligence-based radiotherapy machine parameter
   optimization using reinforcement learning
SO MEDICAL PHYSICS
DT Article
DE artificial intelligence; deep&#8208; Q learning; optimization;
   reinforcement learning; treatment planning; volumetric modulated arc
   therapy
ID VOLUMETRIC MODULATED ARC; TREATMENT PLAN OPTIMIZATION; THERAPY; IMRT
AB Purpose To develop and evaluate a volumetric modulated arc therapy (VMAT) machine parameter optimization (MPO) approach based on deep-Q reinforcement learning (RL) capable of finding an optimal machine control policy using previous prostate cancer patient CT scans and contours, and applying the policy to new cases to rapidly produce deliverable VMAT plans in a simplified beam model.
   Methods A convolutional deep-Q network was employed to control the dose rate and multileaf collimator of a C-arm linear accelerator model using the current dose distribution and machine parameter state as input. A Q-value was defined as the discounted cumulative cost based on dose objectives, and experience-replay RL was performed to determine a policy to minimize the Q-value. A two-dimensional network design was employed which optimized each opposing leaf pair independently while monitoring the corresponding dose plane blocked by those leaves. This RL approach was applied to CT and contours from 40 retrospective prostate cancer patients. The dataset was split into training (15 patients) and validation (5 patients) groups to optimize the network, and its performance was tested in an independent cohort of 20 patients by comparing RL-based dose distributions to conformal arcs and clinical intensity modulated radiotherapy (IMRT) delivering a prescription dose of 78 Gy in 40 fractions.
   Results Mean +/- SD execution time of the RL VMAT optimization was 1.5 +/- 0.2 s per slice. In the test cohort, mean +/- SD (P-value) planning target volume (PTV), bladder, and rectum dose were 80.5 +/- 2.0 Gy (P < 0.001), 44.2 +/- 14.6 Gy (P < 0.001), and 43.7 +/- 11.1 Gy (P < 0.001) for RL VMAT compared to 81.6 +/- 1.1 Gy, 51.6 +/- 12.9 Gy, and 36.0 +/- 12.3 Gy for clinical IMRT.
   Conclusions RL was applied to VMAT MPO using clinical patient contours without independently optimized treatment plans for training and achieved comparable target and normal tissue dose to clinical plans despite the application of a relatively simple network design originally developed for video-game control. These results suggest that extending a RL approach to a full three-dimensional beam model could enable rapid artificial intelligence-based optimization of deliverable treatment plans, reducing the time required for radiotherapy planning without requiring previous plans for training.
C1 [Hrinivich, William Thomas; Lee, Junghoon] Johns Hopkins Univ, Dept Radiat Oncol & Mol Radiat Sci, Baltimore, MD 21287 USA.
RP Lee, J (corresponding author), Johns Hopkins Univ, Dept Radiat Oncol & Mol Radiat Sci, Baltimore, MD 21287 USA.
EM jun-ghoon@jhu.edu
CR Babier A, 2020, MED PHYS, V47, P297, DOI 10.1002/mp.13896
   Barkousaraie AS, 2020, MED PHYS, V47, P880, DOI 10.1002/mp.13986
   Bedford JL, 2013, J APPL CLIN MED PHYS, V14, P172, DOI 10.1120/jacmp.v14i2.4136
   Bertsekas D, 2019, REINFORCEMENT LEARNI
   Bohoudi O, 2017, RADIOTHER ONCOL, V125, P439, DOI 10.1016/j.radonc.2017.07.028
   Breedveld S, 2019, EUR J OPER RES, V277, P1, DOI 10.1016/j.ejor.2018.08.019
   Cui SN, 2020, MED PHYS, V47, pE127, DOI 10.1002/mp.14140
   Das IJ, 2008, TG106 THER PHYS COMM
   El Naqa I, 2020, MED PHYS, V47, pE125, DOI 10.1002/mp.14088
   Fan JW, 2019, MED PHYS, V46, P370, DOI 10.1002/mp.13271
   Good D, 2013, INT J RADIAT ONCOL, V87, P176, DOI 10.1016/j.ijrobp.2013.03.015
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Lamb J, 2017, CUREUS J MED SCIENCE, V9, DOI 10.7759/cureus.1618
   Lee HH, 2019, SCI REP-UK, V9, DOI [10.1038/s41598-019-39131-3, 10.1038/s41598-019-46417-z]
   Li XY, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba5eb
   McIntosh C, 2017, PHYS MED BIOL, V62, P5926, DOI 10.1088/1361-6560/aa71f8
   Men CH, 2010, MED PHYS, V37, P5787, DOI 10.1118/1.3491675
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Monz M, 2008, PHYS MED BIOL, V53, P985, DOI 10.1088/0031-9155/53/4/011
   Nguyen D, 2020, MED PHYS, V47, P837, DOI 10.1002/mp.13955
   Otto K, 2008, MED PHYS, V35, P310, DOI 10.1118/1.2818738
   Palma D, 2008, INT J RADIAT ONCOL, V72, P996, DOI 10.1016/j.ijrobp.2008.02.047
   Peng F, 2012, PHYS MED BIOL, V57, P4569, DOI 10.1088/0031-9155/57/14/4569
   Shen CY, 2020, MED PHYS, V47, P2329, DOI 10.1002/mp.14114
   SHEN CY, 2019, PHYS MED BIOL, V64
   Shiraishi S, 2016, MED PHYS, V43, P378, DOI 10.1118/1.4938583
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Tian Z, 2015, MED PHYS, V42, P2841, DOI 10.1118/1.4919742
   Unkelbach J, 2015, MED PHYS, V42, P1367, DOI 10.1118/1.4908224
   van Hasselt H, 2016, AAAI CONF ARTIF INTE, P2094
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wieser HP, 2017, MED PHYS, V44, P2556, DOI 10.1002/mp.12251
NR 34
TC 14
Z9 14
U1 5
U2 30
PD DEC
PY 2020
VL 47
IS 12
BP 6140
EP 6150
DI 10.1002/mp.14544
EA NOV 2020
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Zhou, Z
   Li, C
   Wei, XC
   Wang, XY
   Sun, GY
AF Zhou, Zhe
   Li, Cong
   Wei, Xuechao
   Wang, Xiaoyang
   Sun, Guangyu
GP ACM
TI GNNear: Accelerating Full-Batch Training of Graph Neural Networks with
   Near-Memory Processing
SO PROCEEDINGS OF THE 2022 31ST INTERNATIONAL CONFERENCE ON PARALLEL
   ARCHITECTURES AND COMPILATION TECHNIQUES, PACT 2022
DT Proceedings Paper
CT 31st International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY OCT 08-12, 2022
CL Discovery Partners Inst, Chicago, IL
HO Discovery Partners Inst
DE near-memory processing; graph neural networks; domain-specific
   accelerator; machine learning
AB Recently, Graph Neural Networks (GNNs) have become state-of-the-art algorithms for analyzing non-euclidean graph data. However, to realize efficient GNN training is challenging, especially on large graphs. The reasons are many-folded: 1) GNN training incurs a substantial memory footprint. Full-batch training on large graphs even requires hundreds to thousands of gigabytes of memory. 2) GNN training involves both memory-intensive and computation-intensive operations, challenging current CPU/GPU platforms. 3) The irregularity of graphs can result in severe resource underutilization and load-imbalance problems.
   This paper presents a GNNear accelerator to tackle these challenges. GNNear adopts a DIMM-based memory system to provide sufficient memory capacity. To match the heterogeneous nature of GNN training, we offload the memory-intensive Reduce operations to in-DIMM Near-Memory-Engines (NMEs), making full use of the high aggregated local bandwidth. We adopt a Centralized-Acceleration-Engine (CAE) to process the computation-intensive Update operations. We further propose several optimization strategies to deal with the irregularity of input graphs and improve GNNear's performance. Comprehensive evaluations on 16 GNN training tasks demonstrate that GNNear achieves 30.8x / 2.5x geomean speedup and 79.6x / 7.3x (geomean) higher energy efficiency compared to Xeon E5-2698-v4 CPU and NVIDIA V100 GPU.
C1 [Zhou, Zhe] Peking Univ, Sch Integrated Circuits, Sch Comp Sci, Beijing, Peoples R China.
   [Li, Cong] Peking Univ, Sch Integrated Circuits, Beijing, Peoples R China.
   [Wei, Xuechao] Peking Univ, Sch Comp Sci, Alibaba Grp, Beijing, Peoples R China.
   [Wang, Xiaoyang] Peking Univ, Sch Comp Sci, Beijing, Peoples R China.
   [Sun, Guangyu] Peking Univ, Sch Integrated Circuits, Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
RP Sun, GY (corresponding author), Peking Univ, Sch Integrated Circuits, Beijing Adv Innovat Ctr Integrated Circuits, Beijing, Peoples R China.
EM zhou.zhe@pku.edu.cn; leesou@pku.edu.cn; xuechao.wei@pku.edu.cn;
   yaoer@pku.edu.cn; gsun@pku.edu.cn
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Alandoli Mohammed, 2016, 2016 7 INT C COMP SC, P1, DOI DOI 10.1109/CSIT.2016.7549467
   [Anonymous], PYRAPL
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   Asghari-Moghaddam H, 2016, INT SYMP MICROARCH
   Bojchevski A, 2018, Arxiv, DOI arXiv:1707.03815
   Cai ZK, 2021, PROCEEDINGS OF THE SIXTEENTH EUROPEAN CONFERENCE ON COMPUTER SYSTEMS (EUROSYS '21), P130, DOI 10.1145/3447786.3456233
   Chen JX, 2021, SCI CHINA INFORM SCI, V64, DOI 10.1007/s11432-020-3248-y
   Chen J, 2018, Arxiv, DOI arXiv:1801.10247
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XB, 2020, Arxiv, DOI arXiv:2009.12495
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen Zhaodong, 2020, IEEE ACM INT C COMP
   Chi YZ, 2016, PROC INT CONF DATA, P409, DOI 10.1109/ICDE.2016.7498258
   Chiang WL, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P257, DOI 10.1145/3292500.3330925
   Cui ZY, 2020, IEEE T INTELL TRANSP, V21, P4883, DOI 10.1109/TITS.2019.2950416
   Dai GH, 2019, IEEE T COMPUT AID D, V38, P640, DOI 10.1109/TCAD.2018.2821565
   DGL, DGL FRAM
   Fan SH, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2478, DOI 10.1145/3292500.3330673
   Farmahini-Farahani A, 2015, INT S HIGH PERF COMP, P283, DOI 10.1109/HPCA.2015.7056040
   Fey M., ARXIV190302428, V2019
   Howard AG, 2017, Arxiv, DOI [arXiv:1704.04861, DOI 10.48550/ARXIV.1704.04861]
   Gandhi S, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P551
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Gao MY, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P807, DOI 10.1145/3297858.3304014
   Gao MY, 2015, INT CONFER PARA, P113, DOI 10.1109/PACT.2015.22
   Garcia-Duran Alberto, 2017, ADV NEURAL INFORM PR, V30, P5119
   Ge L, 2019, IEEE INT CONF MOB DA, P234, DOI 10.1109/MDM.2019.00-52
   Geng T, 2020, Arxiv, DOI arXiv:1908.10834
   Geng Tong, 2021, MICRO54 54 ANN IEEE, P1051
   Gibert J, 2012, PATTERN RECOGN, V45, P3072, DOI 10.1016/j.patcog.2012.01.009
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gu P, 2020, ANN I S COM, P804, DOI 10.1109/ISCA45697.2020.00071
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hamilton WL, 2017, ADV NEUR IN, V30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henrion Isaac, 2017, NEURAL MESSAGE PASSI
   Hewlett Packard, CACTI
   Hong B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P682, DOI 10.1109/MICRO.2018.00061
   Hsieh K, 2016, CONF PROC INT SYMP C, P204, DOI 10.1109/ISCA.2016.27
   Hu WH, 2021, Arxiv, DOI arXiv:2005.00687
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Intel, INT VTUN PROF
   Jia Zhihao, 2020, P MACH LEARN SYST ML, V2, P187
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jouppi Norman P, 2021, ANN INT S COMP ARCH
   Kalamkar D, 2019, Arxiv, DOI [arXiv:1905.12322, DOI 10.48550/ARXIV.1905.12322]
   Ke L., 2021, IEEE MICRO
   Ke L, 2020, ANN I S COM, P790, DOI 10.1109/ISCA45697.2020.00070
   Kim D, 2018, IEEE T COMPUT AID D, V37, P2360, DOI 10.1109/TCAD.2018.2858358
   Kim Jin Hyun, 2021, 2021 IEEE HOT CHIPS, P1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon YC, 2021, ISSCC DIG TECH PAP I, V64, P350, DOI 10.1109/ISSCC42613.2021.9365862
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lee YS, 2021, IEEE ACCESS, V9, P68561, DOI 10.1109/ACCESS.2021.3077294
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Li S, 2020, IEEE COMPUT ARCHIT L, V19, P106, DOI 10.1109/LCA.2020.2973991
   Liang SW, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415645
   Liang SW, 2021, IEEE T COMPUT, V70, P1511, DOI 10.1109/TC.2020.3014632
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Liu Liu, 2021, MICRO 54 54 ANN IEEE, P1309
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Liu X, 2022, IEEE-CAA J AUTOMATIC, V9, P205, DOI 10.1109/JAS.2021.1004311
   Lo YC, 2018, DRUG DISCOV TODAY, V23, P1538, DOI 10.1016/j.drudis.2018.05.010
   Ma LX, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P443
   Md V, 2021, Arxiv, DOI arXiv:2104.06700
   Meaney PJ, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2429031
   Micron, 32GB X72 ECC DR 288
   Minaee S, 2022, IEEE T PATTERN ANAL, V44, P3523, DOI 10.1109/TPAMI.2021.3059968
   Mirhoseini A, 2020, Arxiv, DOI arXiv:2004.10746
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Mohoney J, 2021, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '21), P533
   Nai LF, 2017, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2017.54
   Nie W, 2021, IEEE T MULTIMEDIA
   Park J., 2021, MICRO, P268
   Pytorch, PYT PROF
   Qian GC, 2021, PROC CVPR IEEE, P11678, DOI 10.1109/CVPR46437.2021.01151
   Stevens JR, 2021, Arxiv, DOI arXiv:2103.10836
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rjzamora, PYNVML
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Shchur Oleksandr, 2018, ARXIV
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song Xinkai, 2021, IEEE T COMPUT AID D
   Stokes JM, 2020, CELL, V180, P688, DOI 10.1016/j.cell.2020.01.021
   Sun WY, 2021, CONF PROC INT SYMP C, P237, DOI 10.1109/ISCA52012.2021.00027
   Szklarczyk D, 2019, NUCLEIC ACIDS RES, V47, pD607, DOI 10.1093/nar/gky1131
   Thorpe John, 2021, 15 SYSTEMS DESIGN IM, V21, P495
   Tripathy A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/sc41405.2020.00074
   Wang HR, 2020, Arxiv, DOI arXiv:2005.00406
   Wang L, 2019, PROC CVPR IEEE, P10288, DOI 10.1109/CVPR.2019.01054
   Wang X, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P950, DOI 10.1145/3292500.3330989
   Wang Y, 2018, IEEE T PARALL DISTR, V29, P1428, DOI 10.1109/TPDS.2018.2791440
   Wang YK, 2021, Arxiv, DOI arXiv:2006.06608
   Wang Zhao, 2020, C ADV COMP ARCH, P73
   Welling M., 2016, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Wu S, 2019, AAAI CONF ARTIF INTE, P346
   Xie XF, 2021, INT S HIGH PERF COMP, P570, DOI 10.1109/HPCA51647.2021.00055
   Xu K, 2019, PROC INT CONF PARAL, DOI 10.1145/3337821.3337923
   Xu QG, 2020, PROC CVPR IEEE, P5660, DOI 10.1109/CVPR42600.2020.00570
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yin SY, 2019, IEEE T PARALL DISTR, V30, P146, DOI 10.1109/TPDS.2018.2858230
   Ying R, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P974, DOI 10.1145/3219819.3219890
   Yu CQ, 2018, LECT NOTES COMPUT SC, V11217, P334, DOI 10.1007/978-3-030-01261-8_20
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zeng HQ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P255, DOI 10.1145/3373087.3375312
   Zeng Hanqing, 2020, 8 INT C LEARN REPR I
   Zhai ZL, 2020, IEEE ACCESS, V8, P65591, DOI 10.1109/ACCESS.2020.2985279
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang G, 2019, PR MACH LEARN RES, V97
   Zhang MX, 2018, INT S HIGH PERF COMP, P544, DOI 10.1109/HPCA.2018.00053
   Zhao J, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P2347, DOI 10.1145/3292500.3330686
   Zhao L, 2020, IEEE T INTELL TRANSP, V21, P3848, DOI 10.1109/TITS.2019.2935152
   Zhou Z, 2021, DES AUT CON, P1009, DOI 10.1109/DAC18074.2021.9586181
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
   Zhuo YW, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P712, DOI 10.1145/3352460.3358256
NR 123
TC 1
Z9 1
U1 1
U2 1
PY 2022
BP 54
EP 68
DI 10.1145/3559009.3569670
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Kang, D
   Oh, J
   Choi, J
   Yi, Y
   Ha, S
AF Kang, Duseok
   Oh, Jinwoo
   Choi, Jongwoo
   Yi, Youngmin
   Ha, Soonhoi
TI Scheduling of Deep Learning Applications Onto Heterogeneous Processors
   in an Embedded Device
SO IEEE ACCESS
DT Article
DE Deep learning scheduling; genetic algorithm; heterogeneous processor;
   mobile device
AB As the need for on-device machine learning is increasing recently, embedded devices tend to be equipped with heterogeneous processors that include a multi-core CPU, a GPU, and/or a DNN accelerator called a Neural Processing Unit (NPU). In the scheduling of multiple deep learning (DL) applications in such embedded devices, there are several technical challenges. First, a task can be mapped onto a single core or any number of available cores. So we need to consider various possible configurations of CPU cores. Second, embedded devices usually apply Dynamic Voltage and Frequency Scaling (DVFS) to reduce energy consumption at run-time. We need to consider the effect of DVFS in the profiling of task execution times. Third, to avoid overheat condition, it is recommended to limit the core utilization. Lastly, some cores will be shut-down at run-time if core utilization is not high enough, in case the hot-plugging option is turned on. In this paper, we propose a scheduling technique based on Genetic Algorithm to run DL applications on heterogeneous processors, considering all those issues. First, we aim to optimize the throughput of a single deep learning application. Next, we aim to find the Pareto optimal scheduling of multiple DL applications in terms of the response time of each DL application and overall energy consumption under the given throughput constraints of DL applications. The proposed technique is verified with real DL networks running on two embedded devices, Galaxy S9 and HiKey970.
C1 [Kang, Duseok; Oh, Jinwoo; Choi, Jongwoo; Ha, Soonhoi] Seoul Natl Univ, Dept Comp Engn, Seoul 08826, South Korea.
   [Yi, Youngmin] Univ Seoul, Dept Elect & Comp Engn, Seoul 02504, South Korea.
RP Ha, S (corresponding author), Seoul Natl Univ, Dept Comp Engn, Seoul 08826, South Korea.
EM sha@snu.ac.kr
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Ali HI, 2015, 23RD EUROMICRO INTERNATIONAL CONFERENCE ON PARALLEL, DISTRIBUTED, AND NETWORK-BASED PROCESSING (PDP 2015), P701, DOI 10.1109/PDP.2015.57
   Alzantot Moustafa, 2017, MobiSys, V2017, P7, DOI 10.1145/3089801.3089805
   [Anonymous], 2016, P 24 ACM INT C MULT
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   [Anonymous], [No title captured]
   Arabnejad H, 2014, IEEE T PARALL DISTR, V25, P682, DOI 10.1109/TPDS.2013.57
   BARUAH SK, 1990, PROCEEDINGS : 11TH REAL-TIME SYSTEMS SYMPOSIUM, P182, DOI 10.1109/REAL.1990.128746
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Frumusanu A., 2018, SAMSUNG GALAXY S9 S9
   Henan Zhao, 2006, Proceedings. 20th International Parallel and Distributed Processing Symposium (IEEE Cat. No.06TH8860)
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Huang GL, 2017, IEEE ICC
   Kang D., 2018, P INT C COMP AID DES, P1
   Lane Nicholas D, 2016, P 15 INT C INFORM PR, P1
   Liu Y, 2017, INT J EMBED SYST, V9, P147, DOI 10.1504/IJES.2017.083734
   O'Grady NP, 2002, CLIN INFECT DIS, V35, P1281, DOI 10.1086/344188
   Pangrle B. M., 1987, Proceedings of the 1987 IEEE International Conference on Computer Design: VLSI in Computers and Processors - ICCD '87 (Cat. No.87CH2473-7), P42
   Redmon J., 2016, ARXIV160207360, P779
   Roy SK, 2019, INT SYMP OBJECT COMP, P185, DOI 10.1109/ISORC.2019.00042
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sun K, 2019, 33RD INTERNATIONAL CONFERENCE ON INFORMATION NETWORKING (ICOIN 2019), P453, DOI [10.1109/ICOIN.2019.8718131, 10.1109/icoin.2019.8718131]
   Tae-ho Shin, 2011, 2011 16th Asia and South Pacific Design Automation Conference, ASP-DAC 2011, P165, DOI 10.1109/ASPDAC.2011.5722178
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Xie GQ, 2016, J SYST ARCHITECT, V70, P3, DOI 10.1016/j.sysarc.2016.04.008
   Yang H, 2009, DES AUT TEST EUROPE, P69
NR 29
TC 18
Z9 18
U1 1
U2 5
PY 2020
VL 8
BP 43980
EP 43991
DI 10.1109/ACCESS.2020.2977496
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Panchbhaiyye, V
   Ogunfunmi, T
AF Panchbhaiyye, Vineet
   Ogunfunmi, Tokunbo
TI An Efficient FIFO Based Accelerator for Convolutional Neural Networks
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Convolution neural networks; FPGA; Machine learning; Dataflow
AB Over the last decade, Convolutional Neural Networks (CNNs) have become the go to technique to perform tasks in deep learning applications such as computer vision, speech recognition, etc. LeCun et al (Nature 521(7553), 436-44) 2015. Even though CNNs are very efficient at these tasks they are not suitable for embedded applications due to the limited power budget. In this work we present an improved architecture to process the convolution layers in a CNN. This work is based on our earlier architecture which uses FIFO (First In First Out memory)s to accelerate CNNs. Panchbhaiyye and Ogunfunmi 2020. The architecture presented takes advantage of sparsity in CNN layer's inputs and outputs to achieve performance improvement. We evaluate the proposed improvement on 16 bit floating point and 8 bit integer data types and find that this leads to more than 13% improvement in the processing time of convolution layers for VGG16 with float16 data type. Also, we show how this architecture can be used to compute fully connected layers. Overall we are able to exceed the performance of state-of-the-art architectures by more than 1.65x using an inexpensive Pynq Z1 board running at 100Mhz.
C1 [Panchbhaiyye, Vineet; Ogunfunmi, Tokunbo] Santa Clara Univ, Dept Elect & Comp Engn, 500 El Camino Real, Santa Clara, CA 95053 USA.
RP Ogunfunmi, T (corresponding author), Santa Clara Univ, Dept Elect & Comp Engn, 500 El Camino Real, Santa Clara, CA 95053 USA.
EM vpanchbhaiyye@scu.edu; togunfunmi@scu.edu
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   [Anonymous], P 14 INT C ART INT S
   Ardakani A, 2018, IEEE T CIRCUITS-I, V65, P1349, DOI 10.1109/TCSI.2017.2757036
   ARM, 2010, AMBA 4 AXI4 STREAM P
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Digilent, 2019, PYNQ Z1 REF MAN
   Dumoulin V, 2018, ARXIV160307285
   Falk T, 2019, NAT METHODS, V16, P67, DOI 10.1038/s41592-018-0261-2
   Han S., 2016, INT C LEARN REPR ICL
   Han SY, 2018, INT J DIGIT EARTH, V11, P451, DOI 10.1080/17538947.2017.1330366
   Hennessy J.L., 2017, COMPUTER ARCHITECTUR
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Nair V., 2010, ICML, P807
   Panchbhaiyye V, 2020, INT CONF ACOUST SPEE, P1758, DOI [10.1109/icassp40776.2020.9053228, 10.1109/ICASSP40776.2020.9053228]
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Wang XF, 2020, IEEE COMMUN SURV TUT, V22, P869, DOI 10.1109/COMST.2020.2970550
   Xilinx, 2018, PYNQ PYTH LIB V2 4
   Xilinx, VIVADO DESIGN SUITE
NR 27
TC 4
Z9 4
U1 2
U2 21
PD OCT
PY 2021
VL 93
IS 10
SI SI
BP 1117
EP 1129
DI 10.1007/s11265-020-01632-0
EA FEB 2021
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Wöhrle, H
   Alvarez, MD
   Schlenke, F
   Walsemann, A
   Karagounis, M
   Kirchner, F
AF Woehrle, Hendrik
   Alvarez, Mariela De Lucas
   Schlenke, Fabian
   Walsemann, Alexander
   Karagounis, Michael
   Kirchner, Frank
GP IEEE
TI Surrogate Model based Co-Optimization of Deep Neural Network Hardware
   Accelerators
SO 2021 IEEE INTERNATIONAL MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS
   (MWSCAS)
SE Midwest Symposium on Circuits and Systems Conference Proceedings
DT Proceedings Paper
CT IEEE International Midwest Symposium on Circuits and Systems (MWSCAS)
CY AUG 09-11, 2021
CL ELECTR NETWORK
DE FDX/FDSOI; hardware acceleration; deep learning; bayesian optimization
AB In this paper, we present an ASIC based on 22FDX/FDSOI technology for the detection of atrial fibrillation in human electrocardiograms using neural networks. The ASIC consists of a RISC-V core for supporting software components and an application-specific machine learning IP core (ML-IP), which is used to implement the computationally intensive inference. The ASIC was designed for maximum energy efficiency. A special feature of the ML-IP is its modular, generic and scalable design of the ML-IP which allows to specify the quantization of each computational operation, the degree of parallelization and the architecture of the neural network. This in turn allows the use of ML-based optimization techniques to perform co-optimization for hardware design and architecture of the neural network (NNs). Here, a multi-objective optimization of the overall system is performed with respect to computational efficiency at a given classification accuracy and speed by using a multi-objective optimization, which is carried out using a probabilistic surrogate model. This model tries to find the optimal neural network architecture with a minimum number of training, simulation and evaluation steps.
C1 [Woehrle, Hendrik; Schlenke, Fabian] Dortmund Univ Appl Sci & Arts, Dept Informat Technol, Dortmund, Germany.
   [Alvarez, Mariela De Lucas; Kirchner, Frank] Univ Bremen, Dept Math & Comp Sci, Bremen, Germany.
   [Walsemann, Alexander; Karagounis, Michael] Dortmund Univ Appl Sci & Arts, Fac Elect Engn, Dortmund, Germany.
RP Wöhrle, H (corresponding author), Dortmund Univ Appl Sci & Arts, Dept Informat Technol, Dortmund, Germany.
EM hendrik.woehrle@fh-dortmund.de; delucas@uni-bremen.de;
   fabian.schlenke@fh-dortmund.de; alexander.walsemann@fh-dortmund.de;
   michael.karagounis@fh-dortmund.de; frank.kirchner@uni-bremen.de
CR Bader J, 2011, EVOL COMPUT, V19, P45, DOI 10.1162/EVCO_a_00009
   Bergstra J., 1994, ALGORITHMS HYPER PAR
   Bergstra J, 2012, RANDOM SEARCH HYPER
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Guerreiro AP, 2016, EVOL COMPUT, V24, P521, DOI 10.1162/EVCO_a_00188
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Ioffe S, 2015, PR MACH LEARN RES, V37, P448
   Koehler F, 2010, EUR J HEART FAIL, V12, P1354, DOI 10.1093/eurjhf/hfq199
   Kumar S, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9040626
   Lo CY, 2018, PROC INT CONF ADV, P105, DOI 10.1109/ATC.2018.8587580
   Magyar A, 2015, 2 RISC V WORKSH
   Ozaki Y., 2020, GENETIC EVOLUTIONARY, P9
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Snoek J., 2012, PROC INT C NEURAL IN, V25, P2951
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Wang ZG, 2017, IEEE IJCNN, P1578, DOI 10.1109/IJCNN.2017.7966039
   Wohrle H., 2017, SENSORS SWITZERLAND, V17
NR 18
TC 2
Z9 2
U1 0
U2 4
PY 2021
BP 40
EP 45
DI 10.1109/MWSCAS47672.2021.9531708
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Moshovos, A
   Albericio, J
   Judd, P
   Delmas, A
   Sharify, S
   Mahmoud, M
   Hetherington, T
   Nikolic, M
   Stuart, DM
   Siu, K
   Poulos, Z
   Aamodt, T
   Jerger, NE
AF Moshovos, Andreas
   Albericio, Jorge
   Judd, Patrick
   Delmas, Alberto
   Sharify, Sayeh
   Mahmoud, Mostafa
   Hetherington, Tayler
   Nikolic, Milos
   Stuart, Dylan Malone
   Siu, Kevin
   Poulos, Zissis
   Aamodt, Tor
   Jerger, Natalie Enright
GP IEEE
TI Identifying and Exploiting Ineffectual Computations to Enable Hardware
   Acceleration of Deep Learning
SO 2018 16TH IEEE INTERNATIONAL NEW CIRCUITS AND SYSTEMS CONFERENCE
   (NEWCAS)
SE IEEE International New Circuits and Systems Conference
DT Proceedings Paper
CT 16th IEEE International New Circuits and Systems Conference (NEWCAS)
CY JUN 24-27, 2018
CL Montreal, CANADA
AB This article summarizes somde of our work on hardware accelerators lir inference with Deep Learning Neural Networks (DNNs). Early success in hardware acceleration for DNNs exploited the computation structure and the significant reuse in their access stream. Our approach to further boost benefits has been to first identify properties in the value stream of DNNs which we can exploit at the hardware level to improve execution time, reduce off- and on-chip communication and storage, resulting in higher energy efficiency and execution time reduction. We have been focusing on properties that are difficult or impossible to discern in advance. These properties include values that are zero or near zero and that prove ineffectual, values that have reduced precision needs, or even the hit-level content of values that lead to ineffectual computations. The presented designs cover a spectrum of choices in terms of area cost, energy efficiency, and relative execution time performance and target a variety of hardware devices from embedded systems to server class machines. A key characteristic of these designs is that they reward but do not requires advances in model design that increase the aforementioned properties (such as reduced precision or sparsity) and thus provide a safe path to innovation.
C1 [Moshovos, Andreas; Judd, Patrick; Delmas, Alberto; Sharify, Sayeh; Mahmoud, Mostafa; Nikolic, Milos; Stuart, Dylan Malone; Siu, Kevin; Poulos, Zissis; Jerger, Natalie Enright] Univ Toronto, Toronto, ON, Canada.
   [Albericio, Jorge; Judd, Patrick] NVIDIA, Toronto, ON, Canada.
   [Hetherington, Tayler; Aamodt, Tor] Univ British Columbia, Vancouver, BC, Canada.
RP Moshovos, A (corresponding author), Univ Toronto, Toronto, ON, Canada.
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Courbariaux M, 2015, CORR, V28, P3123
   Delmas A., 2018, CORR
   Delmas Alberto, 2017, CORR
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Han S., 2016, ARXIV160201528CS
   Iandola F. N., 2016, ARXIV
   Jonghong Kim, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P7510, DOI 10.1109/ICASSP.2014.6855060
   Judd P., 2015, ARXIV151105236V4CSLG
   Judd P., 2016, MICRO 49
   Judd Patrick, 2016, P 2016 INT C SUPERCO, DOI 10.1145/2925426.2926294
   Lascorz A. D., 2018, CORR
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park J., 2017, INT C LEARN REPR
   Sharify S., 2018, CORR
   Sharify S., 2017, CORR
   Sharify S, 2018, DES AUT CON, DOI 10.1145/3195970.3196072
   Venkatesh G., 2016, CORR
   Warden Peter, 2016, LOW PRECISION MATRIX
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Zhang SJ, 2016, INT SYMP MICROARCH
NR 24
TC 1
Z9 1
U1 0
U2 1
PY 2018
BP 356
EP 360
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Alagappan, G
   Ong, JR
   Yang, ZF
   Ang, TYL
   Zhao, WJ
   Jiang, Y
   Zhang, WZ
   Png, CE
AF Alagappan, Gandhi
   Ong, Jun Rong
   Yang, Zaifeng
   Ang, Thomas Yong Long
   Zhao, Weijiang
   Jiang, Yang
   Zhang, Wenzu
   Png, Ching Eng
TI Leveraging AI in Photonics and Beyond
SO PHOTONICS
DT Article
DE AI; photonics; soft computing; inverse design; photonics computing;
   photonics accelerator; forward; inverse model; deep learning; machine
   learning; neural networks; electromagnetics; microwave; computational
   electromagnetics; EMC; EMI; quantum computing
ID NEURAL-NETWORK; MODELING APPROACH; GAUSSIAN PROCESS; INVERSE DESIGN;
   MICROWAVE; OPTIMIZATION; CLASSIFICATION; EQUIVALENT; CIRCUITS; HYBRID
AB Artificial intelligence (AI) techniques have been spreading in most scientific areas and have become a heated focus in photonics research in recent years. Forward modeling and inverse design using AI can achieve high efficiency and accuracy for photonics components. With AI-assisted electronic circuit design for photonics components, more advanced photonics applications have emerged. Photonics benefit a great deal from AI, and AI, in turn, benefits from photonics by carrying out AI algorithms, such as complicated deep neural networks using photonics components that use photons rather than electrons. Beyond the photonics domain, other related research areas or topics governed by Maxwell's equations share remarkable similarities in using the help of AI. The studies in computational electromagnetics, the design of microwave devices, as well as their various applications greatly benefit from AI. This article reviews leveraging AI in photonics modeling, simulation, and inverse design; leveraging photonics computing for implementing AI algorithms; and leveraging AI beyond photonics topics, such as microwaves and quantum-related topics.
C1 [Alagappan, Gandhi; Ong, Jun Rong; Yang, Zaifeng; Ang, Thomas Yong Long; Zhao, Weijiang; Jiang, Yang; Zhang, Wenzu; Png, Ching Eng] ASTAR, Inst High Performance Comp, Dept Elect & Photon, Singapore 138632, Singapore.
RP Png, CE (corresponding author), ASTAR, Inst High Performance Comp, Dept Elect & Photon, Singapore 138632, Singapore.
EM gandhi@ihpc.a-star.edu.sg; ongjr@ihpc.a-star.edu.sg;
   yang_zaifeng@ihpc.a-star.edu.sg; thomas-ang@ihpc.a-star.edu.sg;
   zhaow@ihpc.a-star.edu.sg; Jiang_Yang@ihpc.a-star.edu.sg;
   zhangwz@ihpc.a-star.edu.sg; pngce@ihpc.a-star.edu.sg
CR AI and Compute,, 2018, AI COMP
   Alagappan G, 2021, NEURAL COMPUT APPL, V33, P2195, DOI 10.1007/s00521-020-05061-9
   Alagappan G, 2019, J OPT SOC AM B, V36, P2636, DOI 10.1364/JOSAB.36.002636
   Alagappan G, 2019, J OPTICS-UK, V21, DOI 10.1088/2040-8986/ab00d5
   Alagappan G, 2019, J MOD OPTIC, V66, P557, DOI 10.1080/09500340.2018.1552331
   Alkhateeb A, 2018, IEEE ACCESS, V6, P37328, DOI 10.1109/ACCESS.2018.2850226
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambs Pierre, 2010, Advances in Optical Technologies, DOI 10.1155/2010/372652
   An SS, 2020, OPT EXPRESS, V28, P31932, DOI 10.1364/OE.401960
   [Anonymous], 2017, MAKING AI WORK EVERY
   [Anonymous], NEW YORK TIMES
   [Anonymous], 1997, NEURAL COMPUT
   Arjovsky M, 2016, PR MACH LEARN RES, V48
   August M, 2017, PHYS REV A, V95, DOI 10.1103/PhysRevA.95.012335
   Bangari V, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2945540
   Banner R., 2018, ADV NEURAL INFORM PR, P5151, DOI DOI 10.5555/3327345.3327421
   Barmada S, 2020, IEEE T MAGN, V56, DOI 10.1109/TMAG.2019.2957197
   Bhardwaj S, 2019, IEEE ANTENN WIREL PR, V18, P2244, DOI 10.1109/LAWP.2019.2933181
   BISHOP CM, 1995, NEURAL COMPUT, V7, P108, DOI 10.1162/neco.1995.7.1.108
   Boyd R. W., 2020, CONT NONLINEAR OPTIC
   Bulgarevich DS, 2021, SCI REP-UK, V11, P1
   Cao Y, 2003, SIAM J SCI COMPUT, V24, P1076, DOI 10.1137/S1064827501380630
   Cao ZW, 2019, IEEE ACCESS, V7, P135023, DOI 10.1109/ACCESS.2019.2932749
   CAULFIELD HJ, 1989, P IEEE, V77, P1573, DOI 10.1109/5.40669
   Cavin RK, 2012, P IEEE, V100, P1720, DOI 10.1109/JPROC.2012.2190155
   Ceperic V., 2012, P INT S EL COMP, P1
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chakraborty I, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.014063
   Chen J, 2018, PROC CVPR IEEE, P6286, DOI 10.1109/CVPR.2018.00658
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P4889, DOI 10.1109/TIP.2018.2839524
   Chen J, 2018, IEEE T IMAGE PROCESS, V27, P314, DOI 10.1109/TIP.2017.2750413
   Chen SYC, 2020, IEEE ACCESS, V8, P141007, DOI 10.1109/ACCESS.2020.3010470
   Chen X., 2018, COMPUTATIONAL METHOD
   Chen XD, 2020, PROG ELECTROMAGN RES, V167, P67
   Chen XZ, 2020, IEEE ACCESS, V8, P146450, DOI 10.1109/ACCESS.2020.3015043
   Chen Y., 2020, ARXIV200404815
   Chowdhury GG, 2003, ANNU REV INFORM SCI, V37, P51, DOI 10.1002/aris.1440370103
   Chu HS, 2007, 2007 WORKSHOP ON COMPUTATIONAL ELECTROMAGNETICS IN TIME-DOMAIN, P163
   Chu HS, 2007, INT J RF MICROW C E, V17, P179, DOI 10.1002/mmce.20212
   Coarer FDL, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2836985
   Colburn S, 2021, COMMUN PHYS-UK, V4, DOI 10.1038/s42005-021-00568-6
   Creswell A, 2018, IEEE SIGNAL PROC MAG, V35, P53, DOI 10.1109/MSP.2017.2765202
   De Ridder S, 2020, IEEE T ELECTROMAGN C, V62, P2538, DOI 10.1109/TEMC.2020.2980790
   Denholm SJ, 2020, J DAIRY SCI, V103, P9355, DOI 10.3168/jds.2020-18328
   Devabhaktuni V, 2013, IEEE T ELECTROMAGN C, V55, P385, DOI 10.1109/TEMC.2012.2214223
   DRAGONE C, 1989, J LIGHTWAVE TECHNOL, V7, P479, DOI 10.1109/50.16884
   Driscoll JB, 2018, IEEE INT CONF GROUP
   Elbir AM, 2020, IEEE T WIREL COMMUN, V19, P1677, DOI 10.1109/TWC.2019.2956146
   Erricolo D, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON ELECTROMAGNETICS IN ADVANCED APPLICATIONS (ICEAA), P1377, DOI [10.1109/ICEAA.2019.8879110, 10.1109/iceaa.2019.8879110]
   Es-saidi S., 2021, HYBRID FLATLAND META
   Ewe W.B., 2021, ARXIV210912279
   Fang MYS, 2019, OPT EXPRESS, V27, P14009, DOI 10.1364/OE.27.014009
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Feng F, 2016, IEEE T MICROW THEORY, V64, P60, DOI 10.1109/TMTT.2015.2504099
   Gao J, 2020, IEEE ACCESS, V8, P211380, DOI 10.1109/ACCESS.2020.3039269
   Gianfagna C, 2017, J ELECTRON MATER, V46, P4963, DOI 10.1007/s11664-017-5487-8
   Giannakis I., 2018, P 17 INT C GROUND PE, P1
   Giannakis I, 2019, IEEE T GEOSCI REMOTE, V57, P4417, DOI 10.1109/TGRS.2019.2891206
   Gibson W.C., 2021, METHOD MOMENTS ELECT
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Goodman J. W, 1996, INTRO FOURIER OPTICS
   Guo LS, 2019, 2019 INTERNATIONAL APPLIED COMPUTATIONAL ELECTROMAGNETICS SOCIETY SYMPOSIUM - CHINA (ACES), VOL 1, DOI 10.23919/aces48530.2019.9060707
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Harris NC, 2018, OPTICA, V5, P1623, DOI 10.1364/OPTICA.5.001623
   Haug T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/abc81f
   Hayt W.H., 2020, ENG ELECTROMAGNETICS
   He K., 2015, ARXIV
   Hecht E, 2017, OPTICS, V5th
   Home,, LUM COMP
   Huang AD, 2016, IEEE T MICROW THEORY, V64, P2519, DOI 10.1109/TMTT.2016.2586055
   Huang H, 2020, IEEE T VEH TECHNOL, V69, P1065, DOI 10.1109/TVT.2019.2949122
   Huang HJ, 2019, IEEE T VEH TECHNOL, V68, P3027, DOI 10.1109/TVT.2019.2893928
   Huang QL, 2018, IEEE T ELECTROMAGN C, V60, P1640, DOI 10.1109/TEMC.2018.2797132
   Huang ZH, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/685404
   Hubara I, 2018, J MACH LEARN RES, V18
   Hughes TW, 2018, ACS PHOTONICS, V5, P4781, DOI 10.1021/acsphotonics.8b01522
   Hung SY, 2020, IEEE T COMP PACK MAN, V10, P314, DOI 10.1109/TCPMT.2019.2956485
   Hunt JJ., 2015, CONTINUOUS CONTROL D
   Inampudi S, 2018, APPL PHYS LETT, V112, DOI 10.1063/1.5033327
   Isaksson M, 2005, IEEE T MICROW THEORY, V53, P3422, DOI 10.1109/TMTT.2005.855742
   Jain SK, 2016, INT J MICROW WIREL T, V8, P1111, DOI 10.1017/S1759078715000616
   Jiang JQ, 2021, NAT REV MATER, V6, P679, DOI 10.1038/s41578-020-00260-1
   Jiang JQ, 2019, ACS NANO, V13, P8872, DOI 10.1021/acsnano.9b02371
   Jiang JQ, 2019, NANO LETT, V19, P5366, DOI 10.1021/acs.nanolett.9b01857
   Jiang Y., 2021, PROC IEEE INT JOINT
   Jiang Y, 2019, IEEE T MICROW THEORY, V67, P565, DOI 10.1109/TMTT.2018.2882481
   Jin J. M., 2015, FINITE ELEMENT METHO, P243
   Jin J, 2020, IEEE ACCESS, V8, P82273, DOI 10.1109/ACCESS.2020.2991890
   Jin J, 2019, IEEE T MICROW THEORY, V67, P4140, DOI 10.1109/TMTT.2019.2932738
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kim C, 2020, IEEE ACCESS, V8, P188853, DOI 10.1109/ACCESS.2020.3031607
   Kim H, 2018, IEEE T ELECTROMAGN C, V60, P2049, DOI 10.1109/TEMC.2017.2782704
   Kingma D. P., 2013, ARXIV13126114
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Kong JA., 1975, THEORY ELECTROMAGNET
   Kudyshev ZA, 2021, ACS PHOTONICS, V8, P34, DOI 10.1021/acsphotonics.0c00960
   Kuo MJ, 2008, 2008 ASIA-PACIFIC SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY AND 19TH INTERNATIONAL ZURICH SYMPOSIUM ON ELECTROMAGNETIC COMPATIBILITY, VOLS 1 AND 2, P670, DOI 10.1109/APEMC.2008.4559964
   Lai P.Y., 2021, SCI REP-UK, V11, P1
   Larochelle H., 2011, AISTATS, P29
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li S., 2019, ARXIV191008721
   Li SH, 2019, ASIA PACIF MICROWAVE, P96, DOI [10.1109/APMC46564.2019.9038488, 10.1109/apmc46564.2019.9038488]
   Li YS, 2019, IEEE T COMP PACK MAN, V9, P1244, DOI 10.1109/TCPMT.2019.2920974
   Lim AEJ, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2293274
   Lin T, 2020, IEEE WIREL COMMUN LE, V9, P103, DOI 10.1109/LWC.2019.2943466
   Lio GE, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8030065
   Lio GE, 2021, ADV MATER, V33, DOI 10.1002/adma.202008644
   Liu, 2019, ARXIV190102069
   Liu W, 2020, IEEE WCNC, DOI 10.1109/wcnc45663.2020.9120755
   Liu WC, 2019, DES AUT TEST EUROPE, P1483, DOI [10.23919/date.2019.8715195, 10.23919/DATE.2019.8715195]
   Liu WY, 2017, IEEE T MICROW THEORY, V65, P2043, DOI 10.1109/TMTT.2017.2657501
   Liu ZC, 2018, NANO LETT, V18, P6570, DOI 10.1021/acs.nanolett.8b03171
   Liu ZH, 2021, PHOTONICS-BASEL, V8, DOI 10.3390/photonics8110489
   Lockwood O., 2020, P AAAI C ART INT INT, V16, P245, DOI DOI 10.1609/AIIDE.V16I1.7437
   Lu D, 2007, INT J REMOTE SENS, V28, P823, DOI 10.1080/01431160600746456
   Ma W, 2021, NAT PHOTONICS, V15, P77, DOI 10.1038/s41566-020-0685-y
   Ma W, 2018, ACS NANO, V12, P6326, DOI 10.1021/acsnano.8b03569
   Magerl M, 2015, 2015 10th International Workshop on the Electromagnetic Compatibility of Integrated Circuits, P258, DOI 10.1109/EMCCompo.2015.7358368
   Malkiel I, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0060-7
   Maniloff E, 2019, 2019 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXHIBITION (OFC)
   Mao LC, 2019, IEEE ACCESS, V7, P172231, DOI 10.1109/ACCESS.2019.2956508
   Massa A, 2019, IEEE ANTENN WIREL PR, V18, P2225, DOI 10.1109/LAWP.2019.2916369
   Mehrabian A, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2957443
   Mehrabian A, 2018, INT SOC DESIGN CONF, P169
   Mellit A, 2010, ENERG CONVERS MANAGE, V51, P771, DOI 10.1016/j.enconman.2009.10.034
   Mesaritakis C, 2019, OPT LETT, V44, P1218, DOI 10.1364/OL.44.001218
   Mesaritakis C, 2013, J OPT SOC AM B, V30, P3048, DOI 10.1364/JOSAB.30.003048
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Minkov M, 2020, ACS PHOTONICS, V7, P1729, DOI 10.1021/acsphotonics.0c00327
   Miscuglio M, 2019, APL MATER, V7, DOI 10.1063/1.5109689
   Mkadem F, 2011, IEEE T MICROW THEORY, V59, P913, DOI 10.1109/TMTT.2010.2098041
   Monzó-Cabrera J, 2008, IEEE T MICROW THEORY, V56, P2972, DOI 10.1109/TMTT.2008.2007318
   Nadell CC, 2019, OPT EXPRESS, V27, P27523, DOI 10.1364/OE.27.027523
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Nejadriahi H., 2017, ARXIV171102500
   Ohira M, 2021, IEEE MICROW WIREL CO, V31, P638, DOI 10.1109/LMWC.2021.3062874
   Ong JR, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2020.2982990
   Özbay AG, 2021, DATA-CENTRIC ENG, V2, DOI 10.1017/dce.2021.7
   Paudel U, 2020, OPT EXPRESS, V28, P1225, DOI 10.1364/OE.379264
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Pfau D, 2020, PHYS REV RES, V2, DOI 10.1103/PhysRevResearch.2.033429
   Pilozzi L, 2021, NANOTECHNOLOGY, V32, DOI 10.1088/1361-6528/abd508
   Pilozzi L, 2018, COMMUN PHYS-UK, V1, DOI 10.1038/s42005-018-0058-8
   Poulton CV, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2908555
   Pozar D.M., 2011, MICROWAVE ENG
   Qi ST, 2020, IEEE J MULTISCALE MU, V5, P83, DOI 10.1109/JMMCT.2020.2995811
   Qiang XG, 2018, NAT PHOTONICS, V12, P534, DOI 10.1038/s41566-018-0236-y
   Rayas-Sánchez JE, 2004, IEEE T MICROW THEORY, V52, P420, DOI 10.1109/TMTT.2003.820897
   RECK M, 1994, PHYS REV LETT, V73, P58, DOI 10.1103/PhysRevLett.73.58
   Regué JR, 2001, IEEE T ELECTROMAGN C, V43, P520, DOI 10.1109/15.974631
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Roshani S., 2021, J I ELECT COMPUT, V3, P1, DOI [10.33969/JIEC.2021.31001, DOI 10.33969/JIEC.2021.31001]
   Sacher WD, 2015, J LIGHTWAVE TECHNOL, V33, P901, DOI 10.1109/JLT.2015.2392784
   Saleh B., 2007, FUNDAMENTALS PHOTONI
   Sarma S.D., 2019, ARXIV190303516
   Schierholz M, 2021, IEEE ACCESS, V9, P34423, DOI 10.1109/ACCESS.2021.3061788
   Sekhri E, 2020, 15TH INTERNATIONAL CONFERENCE MECHATRONIC SYSTEMS AND MATERIALS, MSM'20, P147, DOI 10.1109/msm49833.2020.9202393
   Shanmukhappa T, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351818
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sherstinsky A, 2020, PHYSICA D, V404, DOI 10.1016/j.physd.2019.132306
   Shi D, 2021, IEEE T ELECTROMAGN C, V63, P443, DOI 10.1109/TEMC.2020.3019801
   Shi D, 2018, IEEE T ELECTROMAGN C, V60, P1621, DOI 10.1109/TEMC.2018.2797053
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Shu YF, 2019, IEEE T MICROW THEORY, V67, P1790, DOI 10.1109/TMTT.2019.2905238
   Steinbrecher GR, 2019, NPJ QUANTUM INFORM, V5, DOI 10.1038/s41534-019-0174-7
   Sun J., 2013, IEEE J SEL TOP QUANT, V20, P264, DOI [10.1109/JSTQE.2013.2293316, DOI 10.1109/JSTQE.2013.2293316]
   Taflove A, 2005, ELECTRICAL ENGINEERING HANDBOOK, P629, DOI 10.1016/B978-012170960-0/50046-3
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tak J, 2018, IEEE ANTENN WIREL PR, V17, P2008, DOI 10.1109/LAWP.2018.2857807
   Takiguchi K, 2011, OPT LETT, V36, P1140, DOI 10.1364/OL.36.001140
   Tangsopha W, 2017, INT ELECT ENG CONGR
   Trinchero R, 2018, IEEE T ELECTROMAGN C, V60, P1627, DOI 10.1109/TEMC.2018.2797481
   Tsang L., 2004, SCATTERING ELECTROMA, VVolume 27
   Tucker RS, 2010, NAT PHOTONICS, V4, P405, DOI 10.1038/nphoton.2010.162
   Ulaby F.T., 2015, FUNDAMENTALS APPL EL
   Vandoorne K, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4541
   Vaswani A, 2017, ADV NEUR IN, V30
   Waltman V.E, VOSVIEWER
   Wang ZY, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON CYBORG AND BIONIC SYSTEMS (CBS), P53, DOI 10.1109/CBS.2018.8612197
   Wang ZY, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO), P2145, DOI 10.1109/ROBIO.2015.7419091
   Watson PM, 1997, IEEE T MICROW THEORY, V45, P2515, DOI 10.1109/22.643868
   Wiecha PR, 2020, NANO LETT, V20, P329, DOI 10.1021/acs.nanolett.9b03971
   Williamson IAD, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2930455
   Wise DF, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.010316
   Wittek P, 2014, QUANTUM MACHINE LEARNING: WHAT QUANTUM COMPUTING MEANS TO DATA MINING, P1
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Yang L, 2012, OPT EXPRESS, V20, P13560, DOI 10.1364/OE.20.013560
   Yang ZF, 2021, 2021 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP 2021), P8578, DOI 10.1109/ICASSP39728.2021.9414745
   Yang ZF, 2020, IEEE I C VI COM I PR, P467, DOI [10.1109/VCIP49819.2020.9301791, 10.1109/vcip49819.2020.9301791]
   Yao HM, 2020, IEEE ACCESS, V8, P21028, DOI 10.1109/ACCESS.2020.2969569
   Yao HM, 2019, IEEE ANTENN WIREL PR, V18, P192, DOI 10.1109/LAWP.2018.2885570
   Yao HM, 2017, IEEE ANTENNAS PROP, P973, DOI 10.1109/APUSNCURSINRSM.2017.8072529
   Yao HM, 2016, IEEE C ELECTR PERFOR, P171, DOI 10.1109/EDAPS.2016.7893155
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   You J.B., 2021, ARXIV210900288
   Zhang S., 2016, IEEE MTT S INT MICRO, P1
   Zhang X.M., 2019, ARXIV190402165
   Zhao P, 2020, IEEE T MICROW THEORY, V68, P1390, DOI 10.1109/TMTT.2019.2963639
   Zhu L, 2016, IEEE MICROW WIREL CO, V26, P131, DOI 10.1109/LMWC.2016.2516761
NR 200
TC 5
Z9 5
U1 6
U2 44
PD FEB
PY 2022
VL 9
IS 2
AR 75
DI 10.3390/photonics9020075
WC Optics
DA 2023-11-11
ER

PT C
AU Delestrac, P
   Torres, L
   Novo, D
AF Delestrac, Paul
   Torres, Lionel
   Novo, David
BE Fabelo, H
   Ortega, S
   Skavhaug, A
TI Demystifying the TensorFlow Eager Execution of Deep Learning Inference
   on a CPU-GPU Tandem
SO 2022 25TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD)
SE EUROMICRO Conference Proceedings
DT Proceedings Paper
CT 25th Euromicro Conference on Digital System Design (DSD)
CY AUG 31-SEP 02, 2022
CL Maspalomas, SPAIN
DE ML frameworks; TensorFlow eager execution; profiling; CPU-GPU tandem
AB Machine Learning (ML) frameworks are tools that facilitate the development and deployment of ML models. These tools are major catalysts of the recent explosion in ML models and hardware accelerators thanks to their high programming abstraction. However, such an abstraction also obfuscates the runtime execution of the model and complicates the understanding and identification of performance bottlenecks. In this paper, we demystify how a modern ML framework manages code execution from a high-level programming language. We focus our work on the TensorFlow eager execution, which remains obscure to many users despite being the simplest mode of execution in TensorFlow. We describe in detail the process followed by the runtime to run code on a CPU-GPU tandem. We propose new metrics to analyze the framework's runtime performance overhead. We use our metrics to conduct in-depth analysis of the inference process of two Convolutional Neural Networks (CNNs) (LeNet-5 and ResNet-50) and a transformer (BERT) for different batch sizes. Our results show that GPU kernels execution need to be long enough to exploit thread parallelism, and effectively hide the runtime overhead of the ML framework.
C1 [Delestrac, Paul; Torres, Lionel; Novo, David] Univ Montpellier, CNRS, LIRMM, Montpellier, France.
RP Delestrac, P (corresponding author), Univ Montpellier, CNRS, LIRMM, Montpellier, France.
EM paul.delestrac@lirmm.fr; lionel.torres@lirmm.fr; david.novo@lirmm.fr
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Agrawal A., 2019, P MACHINE LEARNING S
   Chen TQ, 2015, Arxiv, DOI arXiv:1512.01274
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S, 2014, Arxiv, DOI [arXiv:1410.0759, 10.48550/arXiv.1410.0759]
   cloud.google.com, IN DEPTH LOOK GOOGLE
   developer.nvidia. com, CUDA RELEASE 10 2 89
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   docs.nvidia.com, NVIDIA CUPTI
   Elshawi R, 2021, CLUSTER COMPUT, V24, P2017, DOI 10.1007/s10586-021-03240-4
   gite.lirmm. fr, TENSORFLOW EAGER RUN
   github.com, TENSORFLOW LARGE SCA
   Gleeson J., 2021, P MACHINE LEARNING S
   Guennebaud G., 2010, EIGEN V3
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   huggingface. co, BERT BASE MODEL UNCA
   Kirk D, 2007, P INT S MEMORY MANAG
   Larsen Rasmus Munk, 2019, TENSORFLOW GRAPH OPT
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li C., 2020, 2020 IEEE 13 INT C C
   Li C, 2020, P INT PARALLEL DISTR
   mxnet.apache.org, MXNET DOCUMENTATION
   Paszke A., 2019, P ADV NEUR INF PROC, V32
   pytorch.org, PYTORCH PROFILER
   Tensorboard.dev, US
   tensorflow.org, TENSORFLOW PROFILER
   tensorflow.org, TENSORFLOW KERAS APP
   tensorflow.org, TENSORFLOW GUIDE CRE
   tensorflow.org, ALL SYMBOLS TENSORFL
NR 30
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 446
EP 455
DI 10.1109/DSD57027.2022.00066
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT C
AU Ding, RY
   Cheng, GY
   Wang, SY
   Ding, AA
   Fei, YS
AF Ding, Ruyi
   Cheng Gongye
   Wang, Siyue
   Ding, Aidong Adam
   Fei, Yunsi
GP ACM
TI EMShepherd: Detecting Adversarial Samples via Side-channel Leakage
SO PROCEEDINGS OF THE 2023 ACM ASIA CONFERENCE ON COMPUTER AND
   COMMUNICATIONS SECURITY, ASIA CCS 2023
DT Proceedings Paper
CT 18th ACM ASIA Conference on Computer and Communications Security (ASIA
   CCS)
CY JUL 10-14, 2023
CL Melbourne, AUSTRALIA
DE Side-channel attacks; Adversarial machine learning; Neural network
   hardware
AB Deep Neural Networks (DNN) are vulnerable to adversarial perturbations - small changes crafted deliberately on the input to mislead the model for wrong predictions. Adversarial attacks have disastrous consequences for deep learning empowered critical applications. Existing defense and detection techniques both require extensive knowledge of the model, testing inputs and even execution details. They are not viable for general deep learning implementations where the model internal is unknown, a common 'black-box' scenario for model users. Inspired by the fact that electromagnetic (EM) emanations of a model inference are dependent on both operations and data and may contain footprints of different input classes, we propose a framework, EMShepherd, to capture EM traces of model execution, perform processing on traces and exploit them for adversarial detection. Only benign samples and their EM traces are used to train the adversarial detector: a set of EM classifiers and class-specific unsupervised anomaly detectors. When the victim model system is under attack by an adversarial example, the model execution will be different from executions for the known classes, and the EM trace will be different. We demonstrate that our air-gapped EMShepherd can effectively detect different adversarial attacks on a commonly used FPGA deep learning accelerator for both Fashion MNIST and CIFAR-10 datasets. It achieves a 100% detection rate on most types of adversarial samples, which is comparable to the state-of-the-art 'white-box' software-based detectors.
C1 [Ding, Ruyi; Cheng Gongye; Wang, Siyue; Ding, Aidong Adam; Fei, Yunsi] Northeastern Univ, Boston, MA 02115 USA.
RP Ding, RY (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM ding.ruy@northeastern.edu; gongye.c@northeastern.edu;
   wang.siy@northeastern.edu; a.ding@northeastern.edu;
   y.fei@northeastern.edu
CR aaronia- shop, 2022, PROBE SET PBS 2 INCL
   Agrawal D, 2002, LECT NOTES COMPUT SC, V2523, P29
   Agrawal D., 2002, INT WKSHP CRYPTOGRAP
   [Anonymous], 2021, TENSORFLOW
   Avnet, 2022, ULTRA96 V2
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Bojarski M, 2016, Arxiv, DOI [arXiv:1604.07316, DOI 10.48550/ARXIV.1604.07316]
   Carlini N., 2017, AISEC CCS, P3
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chari S, 2002, LECT NOTES COMPUT SC, V2523, P13
   Chmielewski L, 2021, LECT NOTES COMPUT SC, V12809, P96, DOI 10.1007/978-3-030-81645-2_7
   Das D, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317934
   deepai, 2019, F SCORE DEFINITION D
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Feinman R, 2017, Arxiv, DOI arXiv:1703.00410
   Forsyth D.A., 2011, COMPUTER VISION MODE, V2nd ed.
   Foster KR, 2014, BIOMED ENG ONLINE, V13, DOI 10.1186/1475-925X-13-94
   Ganin Y, 2016, J MACH LEARN RES, V17
   Ghosal Deepanway, 2017, INT C IMAGE INFORM P, P1
   Grosse K, 2017, Arxiv, DOI arXiv:1702.06280
   He KM, 2015, Arxiv, DOI [arXiv:1512.03385, DOI 10.48550/ARXIV.1512.03385]
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Huang J, 2005, IEEE T KNOWL DATA EN, V17, P299, DOI 10.1109/TKDE.2005.50
   intel, 2020, RUNNING AVERAGE POWE
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jiang PT, 2021, IEEE T IMAGE PROCESS, V30, P5875, DOI 10.1109/TIP.2021.3089943
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kocher P., 1999, Advances in Cryptology - CRYPTO'99. 19th Annual International Cryptology Conference. Proceedings, P388
   Kurakin A., 2017, ADVERSARIAL EXAMPLES, P1
   Li X, 2017, IEEE I CONF COMP VIS, P5775, DOI 10.1109/ICCV.2017.615
   Lipp Moritz, 2021, 2021 IEEE Symposium on Security and Privacy (SP), P355, DOI 10.1109/SP40001.2021.00063
   Liu XQ, 2018, LECT NOTES COMPUT SC, V11211, P381, DOI 10.1007/978-3-030-01234-2_23
   Ma SQ, 2019, 26TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2019), DOI 10.14722/ndss.2019.23415
   Ma XJ, 2018, Arxiv, DOI arXiv:1801.02613
   Madry A, 2019, Arxiv, DOI [arXiv:1706.06083, DOI 10.48550/ARXIV.1706.06083]
   Manning Christopher, 1999, FDN STAT NATURAL PRO
   Meng DY, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P135, DOI 10.1145/3133956.3134057
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Bhagoji AN, 2017, Arxiv, DOI arXiv:1704.02654
   Parkhi O. M., 2015, P BMVC, V1, P6, DOI DOI 10.5244/C.29.41
   Rauber Jonas, 2017, WORKSHOP RELIABLE MA
   Redmon J, 2016, Arxiv, DOI [arXiv:1506.02640, DOI 10.48550/ARXIV.1506.02640]
   Richens JG, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17419-7
   Selvaraju R. R., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1611.07450
   Shokri R, 2017, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2017.41
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Szegedy C, 2014, Arxiv, DOI [arXiv:1409.4842, DOI 10.48550/ARXIV.1409.4842, 10.48550/arXiv.1409.4842]
   Tao GH, 2018, Arxiv, DOI arXiv:1810.11580
   Teledyne LeCroy, 2022, US
   Tramer F., 2020, ADV NEURAL INFORM PR, V33, P1633
   ultra96, 2021, WELCOME ULTRA96 PYNQ
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Vinogradova K, 2020, AAAI CONF ARTIF INTE, V34, P13943
   Wang SY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3264699
   Wang X, 2019, PROCEEDINGS OF THE TWENTY-EIGHTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P6013
   Wang ZB, 2019, IEEE INFOCOM SER, P2512, DOI [10.1109/infocom.2019.8737416, 10.1109/INFOCOM.2019.8737416]
   xilinx, 2020, ZYNQ DPU V3 2 IP PRO
   xilinx, 2022, VITIS
   Xu WL, 2017, Arxiv, DOI arXiv:1704.01155
   Yang YJ, 2022, Arxiv, DOI arXiv:2201.09650
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Zhang YC, 2021, IEEE T INF FOREN SEC, V16, P4377, DOI 10.1109/TIFS.2021.3106169
   Zhou D., 2021, P IEEE CVF INT C COM, P7878
   Zhu J, 2020, IEEE ACCESS, V8, P83224, DOI 10.1109/ACCESS.2020.2988311
NR 65
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 300
EP 313
DI 10.1145/3579856.3582827
WC Computer Science, Artificial Intelligence; Mathematics, Applied;
   Telecommunications
DA 2023-11-11
ER

PT J
AU Guo, Q
   Qian, YH
   Liang, XY
   Chen, JY
   Cheng, HH
AF Guo, Qian
   Qian, Yuhua
   Liang, Xinyan
   Chen, Junyu
   Cheng, Honghong
TI Multi-granulation Multi-scale Relation Network for Abstract Reasoning
SO INTERNATIONAL JOURNAL OF MACHINE LEARNING AND CYBERNETICS
DT Article
DE Multi-granulation; Multi-scale; Non-descending path; Abstract reasoning;
   Relation network
ID DECISION; ACCELERATOR
AB A Abstract reasoning, one of the representative works of logic learning, is to make machines intelligent. To test the intelligence of machines, researchers have proposed multiple benchmark data sets and these date sets mainly consist of a few simple geometries and traced reasoning paths. There are three issues for these data sets: (1) it is relatively easy for machines to reason the right answer from the simple geometries; (2) due to the limited number of geometric shapes, these data sets are prone to disclosure of information about reasoning; (3) all traced reasoning paths in these data sets have been known beforehand, some state-of-the-art reasoning models are specially designed according to these paths. Hence, these benchmark data sets cannot truly reflect the reasoning ability of reasoning models. To address these issues, we propose a Fashion Non-descending Path data set (FNP). FNP is designed using a mass of complex samples from Fashion-MNIST data set as objects of FNP and the non-descending path that is a more complex path as the variation directions of logical patterns. For gaining reasoning performance on FNP, inspired by the multi-granulation and multi-scale ideas, we propose a multi-granulation multi-scale relation network (M2RN) to consider the multi-wise relations rather than the simple pair-wise relations. Experimental results show that the M2RN is effective for abstract reasoning task.
C1 [Guo, Qian; Qian, Yuhua; Liang, Xinyan; Chen, Junyu; Cheng, Honghong] Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Shanxi, Peoples R China.
   [Qian, Yuhua] Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.
   [Guo, Qian; Qian, Yuhua; Liang, Xinyan; Chen, Junyu] Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
   [Cheng, Honghong] Shanxi Univ Finance & Econ, Sch Informat, Taiyuan 030012, Peoples R China.
RP Qian, YH (corresponding author), Shanxi Univ, Inst Big Data Sci & Ind, Taiyuan 030006, Shanxi, Peoples R China.; Qian, YH (corresponding author), Shanxi Univ, Key Lab Computat Intelligence & Chinese Informat, Minist Educ, Taiyuan 030006, Shanxi, Peoples R China.; Qian, YH (corresponding author), Shanxi Univ, Sch Comp & Informat Technol, Taiyuan 030006, Shanxi, Peoples R China.
EM czguoqian@163.com; jinchengqyh@126.com; liangxinyan48@163.com;
   jade199868@163.com; chhsxdx@163.com
CR [Anonymous], 2017, CORR
   [Anonymous], 2017, ARXIV171001692
   [成红红 Cheng Honghong], 2020, [中国科学. 信息科学, Scientia Sinica Informationis], V50, P824
   Dai WZ, 2019, ADV NEUR IN, V32
   Guo Q, 2019, 2019 IEEE INT C DAT, P620, DOI [10.1109/ICDMW.2019.00094, DOI 10.1109/ICDMW.2019.00094]
   Hou WH, 2021, INT J MACH LEARN CYB, V12, P859, DOI 10.1007/s13042-020-01206-3
   Huang YX, 2020, IEEE DATA MINING, P1070, DOI 10.1109/ICDM50108.2020.00127
   Jahrens M, 2020, IEEE IJCNN, DOI 10.1109/IJCNN48605.2020.9207319
   Jahrens M, 2019, PROCEEDINGS OF 2ND INTERNATIONAL CONFERENCE ON APPLICATIONS OF INTELLIGENT SYSTEMS (APPIS 2019), DOI 10.1145/3309772.3309782
   Jiang ZH, 2020, INT J APPROX REASON, V119, P122, DOI 10.1016/j.ijar.2019.12.013
   Li FJ, 2019, ARTIF INTELL, V273, P37, DOI 10.1016/j.artint.2018.12.007
   Liang, IEEE T PATTERN ANAL, DOI 10.1109/TPAMI.2021.3125995
   Liang XY, 2021, IEEE T EVOLUT COMPUT, V25, P883, DOI 10.1109/TEVC.2021.3064943
   Liu KY, 2020, INT J MACH LEARN CYB, V11, P2149, DOI 10.1007/s13042-020-01107-5
   Pang JF, 2020, INT J APPROX REASON, V117, P122, DOI 10.1016/j.ijar.2019.11.008
   Qian YH, 2017, INT J APPROX REASON, V82, P119, DOI 10.1016/j.ijar.2016.12.008
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Qian YH, 2010, INFORM SCIENCES, V180, P949, DOI 10.1016/j.ins.2009.11.023
   Santoro Adam, 2018, INT C MACH LEARN, P4477
   Tawhid MA, 2020, INT J MACH LEARN CYB, V11, P573, DOI 10.1007/s13042-019-00996-5
   Wang D, 2020, INT J APPROX REASON, V127, P33, DOI 10.1016/j.ijar.2020.08.010
   Wang JT, 2020, IEEE T FUZZY SYST, V28, P887, DOI 10.1109/TFUZZ.2019.2953024
   Wang Y, 2020, IEEE T FUZZY SYST, V28, P1395, DOI 10.1109/TFUZZ.2019.2936801
   Wu WZ, 2017, INFORM SCIENCES, V378, P282, DOI 10.1016/j.ins.2016.03.041
   Wu WZ, 2011, INFORM SCIENCES, V181, P3878, DOI 10.1016/j.ins.2011.04.047
   Xiao Han, 2017, ARXIV170807747, P4321
   Yang L, 2020, INT J APPROX REASON, V122, P47, DOI 10.1016/j.ijar.2020.04.003
   Ye DJ, 2021, INT J MACH LEARN CYB, V12, P661, DOI 10.1007/s13042-020-01195-3
   Yu H, 2020, INT J MACH LEARN CYB, V11, P1003, DOI 10.1007/s13042-019-00988-5
   Yu H, 2019, INT J APPROX REASON, V115, P32, DOI 10.1016/j.ijar.2019.09.001
   Zadeh LA, 1997, FUZZY SET SYST, V90, P111, DOI 10.1016/S0165-0114(97)00077-8
   Zhang C, 2019, PROC CVPR IEEE, P5312, DOI 10.1109/CVPR.2019.00546
   Zhao H, 2019, IEEE T FUZZY SYST, V27, P1891, DOI 10.1109/TFUZZ.2019.2892349
   Zheng K., 2019, NEURIPS, P5842
NR 34
TC 4
Z9 4
U1 4
U2 17
PD JUN
PY 2022
VL 13
IS 6
BP 1751
EP 1762
DI 10.1007/s13042-021-01484-5
EA JAN 2022
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT J
AU Yeung, GF
   Borowiec, D
   Yang, RY
   Friday, A
   Harper, R
   Garraghan, P
AF Yeung, Gingfung
   Borowiec, Damian
   Yang, Renyu
   Friday, Adrian
   Harper, Richard
   Garraghan, Peter
TI Horus: Interference-Aware and Prediction-Based Scheduling in Deep
   Learning Systems
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Graphics processing units; Interference; Kernel; Predictive models;
   Computational modeling; Production; Load modeling; Distributed systems;
   deep learning; interference; GPU utilization; cloud computing; workload
   prediction
ID SCALE
AB To accelerate the training of Deep Learning (DL) models, clusters of machines equipped with hardware accelerators such as GPUs are leveraged to reduce execution time. State-of-the-art resource managers are needed to increase GPU utilization and maximize throughput. While co-locating DL jobs on the same GPU has been shown to be effective, this can incur interference causing slowdown. In this article we propose Horus: an interference-aware and prediction-based resource manager for DL systems. Horus proactively predicts GPU utilization of heterogeneous DL jobs extrapolated from the DL model's computation graph features, removing the need for online profiling and isolated reserved GPUs. Through micro-benchmarks and job co-location combinations across heterogeneous GPU hardware, we identify GPU utilization as a general proxy metric to determine good placement decisions, in contrast to current approaches which reserve isolated GPUs to perform online profiling and directly measure GPU utilization for each unique submitted job. Our approach promotes high resource utilization and makespan reduction; via real-world experimentation and large-scale trace driven simulation, we demonstrate that Horus outperforms other DL resource managers by up to 61.5 percent for GPU resource utilization, 23.7-30.7 percent for makespan reduction and 68.3 percent in job wait time reduction.
C1 [Yeung, Gingfung; Borowiec, Damian; Friday, Adrian; Harper, Richard; Garraghan, Peter] Univ Lancaster, Sch Comp & Commun, Lancaster LA1 4YW, England.
   [Yang, Renyu] Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
RP Yang, RY (corresponding author), Univ Leeds, Sch Comp, Leeds LS2 9JT, W Yorkshire, England.
EM g.yeung1@lancaster.ac.uk; d.borowiec@lancaster.ac.uk;
   ryang1@leeds.ac.uk; a.friday@lancaster.ac.uk; r.harper@lancaster.ac.uk;
   p.garraghan@lancaster.ac.uk
CR A. M. T, SHAR TASK MACH TRANS
   Amazon Web Services Inc, 2020, AM EC2 P3 ID MACH LE
   [Anonymous], 2018, P 12 USENIX C OPERAT
   [Anonymous], 2011, P 2011 USENIX ANN TE
   [Anonymous], 2016, P INT C LEARN REPR I
   [Anonymous], 2012, P 21 INT S HIGHPERFO
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Cai H., 2018, P INT C LEARN REPR
   Chen Q, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P17, DOI 10.1145/3037697.3037700
   Chen Q, 2016, ACM SIGPLAN NOTICES, V51, P681, DOI 10.1145/2954679.2872368
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Cho K., 2014, P 19 C EMPIRICAL MET, P1, DOI [10.3115/v1/D14-1179, DOI 10.3115/V1/D14-1179, 10.3115]
   Chung E, 2018, IEEE MICRO, V38, P8, DOI 10.1109/MM.2018.022071131
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Dube P, 2019, INT SYM COMP ARCHIT, P160, DOI 10.1109/SBAC-PAD.2019.00035
   Gers FA, 1999, IEE CONF PUBL, P850, DOI [10.1162/089976600300015015, 10.1049/cp:19991218]
   Google, 2020, GOOGL CLOUD GPUS PRI
   Gu JC, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P485
   Guz Z, 2009, IEEE COMPUT ARCHIT L, V8, P25, DOI 10.1109/L-CA.2009.4
   Han D, 2017, PROC CVPR IEEE, P6307, DOI 10.1109/CVPR.2017.668
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hightower K, 2017, KUBERNETES RUNNING D
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Howard A, 2019, IEEE I CONF COMP VIS, P1314, DOI 10.1109/ICCV.2019.00140
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jeon M, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P947
   Jia Xianyan, 2018, ARXIV180711205
   Jog Adwait, 2014, GPGPU 7, DOI [10.1145/2576779.2576780, DOI 10.1145/2576779.2576780]
   Ke G., 2017, ADV NEURAL INFORM PR, V30, P3146, DOI DOI 10.5555/3294996.3295074
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Luo Liang, 2020, P MACH LEARN SYST 20, P82
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mars J, 2013, ISCA, P619
   Mars J, 2011, INT SYMP MICROARCH, P248
   Merity S., 2016, P INT C LEARN REPR
   Microsoft Corporation, 2020, AZ VM SIZ GPU AZ VIR
   Novakovic D, 2013, USENIX ATC, P219
   PAREKH AK, 1994, IEEE ACM T NETWORK, V2, P137, DOI 10.1109/90.298432
   Paszke A., 2019, NEURAL INFORM PROCES, V32, P8024
   Peng YH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P16, DOI 10.1145/3341301.3359642
   Peng YH, 2018, EUROSYS '18: PROCEEDINGS OF THE THIRTEENTH EUROSYS CONFERENCE, DOI 10.1145/3190508.3190517
   Redmon J., 2016, ARXIV160207360, P779
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen HC, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P322, DOI 10.1145/3341301.3359658
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Thinakaran P., 2019, P 2019 IEEE INT C CL, P1
   Ting-An Yeh, 2020, HPDC '20: Proceedings of the 29th International Symposium on High-Performance Parallel and Distributed Computing, P173, DOI 10.1145/3369583.3392679
   Ukidave Y, 2016, INT PARALL DISTRIB P, P353, DOI 10.1109/IPDPS.2016.73
   Vavilapalli Vinod Kumar, 2013, SOCC, P1
   Wang H, 2020, IEEE INT ON LINE, DOI [10.1109/iolts50870.2020.9159708, 10.1109/ISCAS45731.2020.9180522]
   Wang MD, 2019, I S WORKL CHAR PROC, P189, DOI 10.1109/IISWC47752.2019.9042047
   Wang SQ, 2021, IEEE T PARALL DISTR, V32, P2144, DOI 10.1109/TPDS.2021.3062721
   Wang Y.E., 2020, 3 C MACH LEARN SYST
   Xiao WC, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P533
   Xiao WC, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P595
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Xu X., 2019, P 11 USENIX C HOT TO, P14
   Yan S., 2017, ADV NEURAL INFORM PR, P4470, DOI DOI 10.5555/3294996.3295200
   Yang RY, 2020, IEEE T PARALL DISTR, V31, P1499, DOI 10.1109/TPDS.2020.2970013
   Yangrui Chen, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P507, DOI 10.1145/3419111.3421307
   Yeung G, 2020, LECT NOTES COMPUT SC, V12453, P492, DOI 10.1007/978-3-030-60239-0_33
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang DL, 2020, PROC VLDB ENDOW, V13, P3125, DOI 10.14778/3415478.3415539
NR 67
TC 19
Z9 19
U1 3
U2 18
PD JAN 1
PY 2022
VL 33
IS 1
BP 88
EP 100
DI 10.1109/TPDS.2021.3079202
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Marchisio, A
   Mrazek, V
   Massa, A
   Bussolino, B
   Martina, M
   Shafique, M
AF Marchisio, Alberto
   Mrazek, Vojtech
   Massa, Andrea
   Bussolino, Beatrice
   Martina, Maurizio
   Shafique, Muhammad
TI RoHNAS: A Neural Architecture Search Framework With Conjoint
   Optimization for Adversarial Robustness and Hardware Efficiency of
   Convolutional and Capsule Networks
SO IEEE ACCESS
DT Article
DE Robustness; Perturbation methods; Optimization; Computer architecture;
   Security; Routing; Graphics processing units; Adversarial machine
   learning; Deep learning; High performance computing; Hardware
   acceleration; Adversarial robustness; energy efficiency; latency;
   memory; hardware-aware neural architecture search; evolutionary
   algorithm; deep neural networks; capsule networks
ID LEARNING-SYSTEMS; CHALLENGES; TRENDS
AB Neural Architecture Search (NAS) algorithms aim at finding efficient Deep Neural Network (DNN) architectures for a given application under given system constraints. DNNs are computationally-complex as well as vulnerable to adversarial attacks. In order to address multiple design objectives, we propose RoHNAS, a novel NAS framework that jointly optimizes for adversarial-robustness and hardware-efficiency of DNNs executed on specialized hardware accelerators. Besides the traditional convolutional DNNs, RoHNAS additionally accounts for complex types of DNNs such as Capsule Networks. For reducing the exploration time, RoHNAS analyzes and selects appropriate values of adversarial perturbation for each dataset to employ in the NAS flow. Extensive evaluations on multi - Graphics Processing Unit (GPU) - High Performance Computing (HPC) nodes provide a set of Pareto-optimal solutions, leveraging the tradeoff between the above-discussed design objectives. For example, a Pareto-optimal DNN for the CIFAR-10 dataset exhibits 86.07% accuracy, while having an energy of 38.63 mJ, a memory footprint of 11.85 MiB, and a latency of 4.47 ms.
C1 [Marchisio, Alberto] Tech Univ Wien TU Wien, Inst Comp Engn, Embedded Comp Syst Grp, A-1040 Vienna, Austria.
   [Mrazek, Vojtech] Brno Univ Technol, Fac Informat Technol, Evolvable Hardware Res Grp, Brno 60190, Czech Republic.
   [Massa, Andrea; Bussolino, Beatrice; Martina, Maurizio] Politecn Torino, VLSI Lab, Dept Elect & Telecommun, I-10129 Turin, Italy.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Div Engn, eBrain Lab, Abu Dhabi, U Arab Emirates.
RP Marchisio, A (corresponding author), Tech Univ Wien TU Wien, Inst Comp Engn, Embedded Comp Syst Grp, A-1040 Vienna, Austria.
EM alberto.marchisio@tuwien.ac.at
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Achararit P, 2020, IEEE ACCESS, V8, P165319, DOI 10.1109/ACCESS.2020.3022327
   Barata C, 2019, I S BIOMED IMAGING, P841, DOI [10.1109/isbi.2019.8759561, 10.1109/ISBI.2019.8759561]
   Capra M, 2020, IEEE ACCESS, V8, P225134, DOI 10.1109/ACCESS.2020.3039858
   Capra M, 2020, FUTURE INTERNET, V12, DOI 10.3390/fi12070113
   Cheng CH, 2018, DES AUT TEST EUROPE, P1005
   Dave S., 2022, ABS220409514 CORR, P1
   Deb K, 2002, IEEE T EVOLUT COMPUT, V6, P182, DOI 10.1109/4235.996017
   Goodfellow I. J., 2014, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR.2016.90
   Goodfellow Ian, 2016, NIPS 2016 TUTORIAL G
   Grigorescu S, 2020, J FIELD ROBOT, V37, P362, DOI 10.1002/rob.21918
   Guesmi A, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P990, DOI 10.1145/3445814.3446747
   Guo MH, 2020, PROC CVPR IEEE, P628, DOI 10.1109/CVPR42600.2020.00071
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Jiang WW, 2020, IEEE T COMPUT AID D, V39, P4154, DOI 10.1109/TCAD.2020.3012863
   Jiang WW, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317757
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kotyan S., 2021, PROC WORKSHOP ARTIF, V2640, P1
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kurakin A., 2018, INT C LEARNING REPRE, P99
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Liu Q, 2018, ASIA S PACIF DES AUT, P721, DOI 10.1109/ASPDAC.2018.8297407
   Lu Q., 2019, ABS191100105, P1
   Madry A., 2018, INT C LEARN REPR, P1
   Marchisio Alberto, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P553, DOI 10.1109/ISVLSI.2019.00105
   Marchisio A, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415731
   Marchisio A, 2021, IEEE T VLSI SYST, V29, P716, DOI 10.1109/TVLSI.2021.3059518
   Marchisio A, 2021, IEEE T COMPUT AID D, V40, P1768, DOI 10.1109/TCAD.2020.3030610
   Marchisio A, 2019, DES AUT TEST EUROPE, P964, DOI [10.23919/DATE.2019.8714922, 10.23919/date.2019.8714922]
   Marcus Mitchell P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Pearson K., 1895, P R SOC LOND, V58, P240, DOI [10.1098/rspl.1895.0041, DOI 10.1098/RSPL.1895.0041]
   Pham H, 2018, PR MACH LEARN RES, V80
   Rajasegaran J, 2019, PROC CVPR IEEE, P10717, DOI 10.1109/CVPR.2019.01098
   Sabour S., 2017, ADV NEURAL INFORM PR, P3856
   Sekanina L, 2021, IEEE ACCESS, V9, P151337, DOI 10.1109/ACCESS.2021.3126685
   Sha~que M., 2021, PROC IEEEACM INT C C, P1, DOI [10.1109/ICCAD51958.2021.9643539, DOI 10.1109/ICCAD51958.2021.9643539]
   Shafique M, 2020, IEEE DES TEST, V37, P30, DOI 10.1109/MDAT.2020.2971217
   Stamoulis D, 2020, LECT NOTES ARTIF INT, V11907, P481, DOI 10.1007/978-3-030-46147-8_29
   Sun K, 2020, IEEE ACCESS, V8, P96920, DOI 10.1109/ACCESS.2020.2996282
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Venkatraman S. R., 2020, CORR, P1
   Wang DL, 2021, PROC CVPR IEEE, P6414, DOI 10.1109/CVPR46437.2021.00635
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zanc R, 2019, INT C INTELL COMP CO, P459, DOI [10.1109/ICCP48234.2019.8959715, 10.1109/iccp48234.2019.8959715]
   Zhang, 2019, P 56 ANN DES AUT C
   Zhang LJ, 2020, CURR PSYCHOL, V39, P1138, DOI 10.1007/s12144-019-0155-1
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
   Zoph Barret, 2017, INT C LEARNING REPRE
NR 53
TC 2
Z9 2
U1 0
U2 2
PY 2022
VL 10
BP 109043
EP 109055
DI 10.1109/ACCESS.2022.3214312
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Fagbohungbe, O
   Qian, LJ
AF Fagbohungbe, Omobayode
   Qian, Lijun
GP IEEE
TI Impact of <i>L</i><sub>1</sub> Batch Normalization on Analog Noise
   Resistant Property of Deep Learning Models
SO 2022 INTERNATIONAL JOINT CONFERENCE ON NEURAL NETWORKS (IJCNN)
SE IEEE International Joint Conference on Neural Networks (IJCNN)
DT Proceedings Paper
CT IEEE International Conference on Fuzzy Systems (FUZZ-IEEE) / IEEE World
   Congress on Computational Intelligence (IEEE WCCI) / International Joint
   Conference on Neural Networks (IJCNN) / IEEE Congress on Evolutionary
   Computation (IEEE CEC)
CY JUL 18-23, 2022
CL Padua, ITALY
DE Batch Normalization; Deep Learning; Hardware Implemented Neural Network;
   Analog Device; Additive White Gaussian Noise
ID ACCELERATORS
AB Analog hardware has become a popular choice for machine learning on resource-constrained devices recently due to its fast execution and energy efficiency. However, the inherent presence of noise in analog hardware and the negative impact of the noise on deployed deep neural network (DNN) models limit their usage. The degradation in performance due to the noise calls for the novel design of DNN models that have excellent noise-resistant property, leveraging the properties of the fundamental building block of DNN models. In this work, the use of L-1 or TopK BatchNorm type, a fundamental DNN model building block, in designing DNN models with excellent noise-resistant property is proposed. Specifically, a systematic study has been carried out by training DNN models with L-1/TopK BatchNorm type, and the performance is compared with DNN models with L-2 BatchNorm types. The resulting model noise-resistant property is tested by injecting additive noise to the model weights and evaluating the new model inference accuracy due to the noise. The results show that L-1 and TopK BatchNorm type has excellent noise-resistant property, and there is no sacrifice in performance due to the change in the BatchNorm type from L-2 to L-1/TopK BatchNorm type.
C1 [Fagbohungbe, Omobayode; Qian, Lijun] Prairie View A&M Univ, Texas A&M Univ Syst, CREDIT Ctr, Prairie View, TX 77446 USA.
   [Fagbohungbe, Omobayode; Qian, Lijun] Prairie View A&M Univ, Texas A&M Univ Syst, Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
RP Fagbohungbe, O (corresponding author), Prairie View A&M Univ, Texas A&M Univ Syst, CREDIT Ctr, Prairie View, TX 77446 USA.; Fagbohungbe, O (corresponding author), Prairie View A&M Univ, Texas A&M Univ Syst, Dept Elect & Comp Engn, Prairie View, TX 77446 USA.
EM ofagbohungbe@pvamu.edu
CR [Anonymous], 2017, NIPS
   [Anonymous], 2018, NEURIPS
   BJORCK J, 2018, NEURIPS, V31
   Bo GM, 2000, IEEE IJCNN, P66, DOI 10.1109/IJCNN.2000.860751
   Burr Geoffrey W., 2021, IEEE Spectrum, V58, P44, DOI 10.1109/MSPEC.2021.9641759
   Chang HY, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934050
   Charan G, 2020, IEEE J EXPLOR SOLID-, V6, P27, DOI 10.1109/JXCDC.2020.2987605
   Chen A, 2020, 2020 IEEE ELECTRON DEVICES TECHNOLOGY AND MANUFACTURING CONFERENCE (EDTM 2020), DOI 10.1109/edtm47692.2020.9117896
   Fagbohungbe O., 2021, EFFECT BATCH NORMALI
   Fagbohungbe O., 2022, IMPACT LEARNING RATE
   Fagbohungbe O., 2021, IEEE T EMERGING TOPI
   Fagbohungbe O. I., 2020, BENCHMARKING INFEREN
   Han S., 2015, ARXIV151000149
   He K., 2015, ARXIV
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Huang G., 2018, DENSELY CONNECTED CO, V3, P4
   HUANG K, 2020, FUNCTIONAL ERROR COR
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Joshi V., 2019, ACCURATE DEEP NEURAL
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kariyappa S, 2021, IEEE T ELECTRON DEV, V68, P4356, DOI 10.1109/TED.2021.3089987
   Klachko M., 2019, IMPROVING NOISE TOLE
   Kourtis K., 2020, COMPILING NEURAL NET
   Li HC, 2019, ADV MATER SCI ENG, V2019, DOI 10.1155/2019/2190627
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Maghazeh A, 2013, 2013 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (IC-SAMOS), P1, DOI 10.1109/SAMOS.2013.6621099
   Merolla P., 2016, DEEP NEURAL NETWORKS
   Onasami O., 2022, UNDERWATER ACOUSTIC
   Qiao S., 2019, MICROBATCH TRAINING
   Qin M., 2018, JOIG, V6, P181, DOI DOI 10.18178/JOIG.6.2.181-186
   SALIMANS T, 2016, NIPS, V29
   Schmid A, 1999, IEE P-CIRC DEV SYST, V146, P345, DOI 10.1049/ip-cds:19990685
   Upadhyaya P., 2019, ERROR CORRECTION NOI, V10
   Upadhyaya P., 2019, ERROR CORRECTION HAR
   Wu S, 2019, IEEE T NEUR NET LEAR, V30, P2043, DOI 10.1109/TNNLS.2018.2876179
   Wu YX, 2020, INT J COMPUT VISION, V128, P742, DOI [10.1109/CSTIC.2018.8369274, 10.1007/s11263-019-01198-w]
   Xiao TP, 2020, APPL PHYS REV, V7, DOI 10.1063/1.5143815
   XIE S, 2017, AGGREGATED RESIDUAL
   Yang B, 2022, IEEE T IND INFORM, V18, P531, DOI 10.1109/TII.2021.3075444
   Zhang J, 2019, IEEE DES TEST, V36, P44, DOI 10.1109/MDAT.2019.2915656
   Zhou C., 2001, NOISY MACHINES UNDER
   Zhou C., 2021, ANALOGNETS ML HW COD
NR 42
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1109/IJCNN55064.2022.9892222
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic; Neurosciences
DA 2023-11-11
ER

PT J
AU Cho, W
   Kim, H
   Kim, D
   Kim, S
   Kwon, I
AF Cho, Woosung
   Kim, Hyeonmin
   Kim, Duckhyun
   Kim, SongHyun
   Kwon, Inyong
TI Reproduction strategy of radiation data with compensation of data loss
   using a deep learning technique
SO NUCLEAR ENGINEERING AND TECHNOLOGY
DT Article
DE Deep learning; U-net algorithm; Radiation map; Sensor network system;
   Reproduction
ID CIRCUIT; DAMAGE
AB In nuclear-related facilities, such as nuclear power plants, research reactors, accelerators, and nuclear waste storage sites, radiation detection, and mapping are required to prevent radiation overexposure. Sensor network systems consisting of radiation sensor interfaces and wxireless communication units have become promising tools that can be used for data collection of radiation detection that can in turn be used to draw a radiation map. During data collection, malfunctions in some of the sensors can occasionally occur due to radiation effects, physical damage, network defects, sensor loss, or other reasons. This paper proposes a reproduction strategy for radiation maps using a U-net model to compensate for the loss of radiation detection data. To perform machine learning and verification, 1,561 simulations and 417 measured data of a sensor network were performed. The reproduction results show an accuracy of over 90%. The proposed strategy can offer an effective method that can be used to resolve the data loss problem for conventional sensor network systems and will specifically contribute to making initial responses with preserved data and without the high cost of radiation leak accidents at nuclear facilities.
   (c) 2021 Korean Nuclear Society, Published by Elsevier Korea LLC. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Cho, Woosung; Kim, SongHyun] POSTECH, Dept Adv Nucl Engn, 77 Cheongam Ro, Pohang 37673, South Korea.
   [Kim, Hyeonmin; Kim, Duckhyun; Kwon, Inyong] Korea Atom Energy Res Inst, 111 Daedeok Daero,989 Beon Gil, Daejeon 34057, South Korea.
RP Kwon, I (corresponding author), Korea Atom Energy Res Inst, 111 Daedeok Daero,989 Beon Gil, Daejeon 34057, South Korea.
EM ikwon@kaeri.re.kr
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2017, ARXIV170404861V1CSCV
   [Anonymous], 2017, METHOD STOCHASTIC OP
   BRUCKER G, 1965, IEEE T NUCL SCI, VNS12, P69, DOI 10.1109/TNS.1965.4323901
   Choi K, 2019, SEMISUPERVISED LEARN
   Fetahovic I, 2013, INT J PHOTOENERGY, V2013, DOI 10.1155/2013/170269
   Fleetwood DM, 2013, IEEE T NUCL SCI, V60, P1706, DOI 10.1109/TNS.2013.2259260
   Goodfellow I.J., 2014, NIPS NEWS PHYSL SCI, V27
   He K., 2015, ARXIV151203385V1CSCV
   Jeon H, 2020, IEEE T NUCL SCI, V67, P1738, DOI 10.1109/TNS.2020.3002421
   Kim D, 2020, NUCL INSTRUM METH A, V954, DOI 10.1016/j.nima.2018.10.205
   Kim S, 2020, NUCL INSTRUM METH A, V954, DOI 10.1016/j.nima.2018.10.151
   Kwon I, 2014, IEEE J SOLID-ST CIRC, V49, P2054, DOI 10.1109/JSSC.2014.2328658
   Lee C, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20102765
   Lehtinen J., 2018, ARXIV180304189V3CSCV
   Liu G., 2018, ARXIV ARXIV180407723
   Long J., 2015, P IEEE C COMP VIS PA, P3431
   MCNP Team, 2017, LAUR1729011 MCNP TEA
   Nazeri K., 2019, ARXIV190100212V3
   Pavlovsky R., 2018, ARXIV190105038V1PHYS
   Ronneberger O., 2015, RECOGNIT CVPR, DOI 10.1007/978-3-319-24574-4MedicalImageComputingandComputer-AssistedIntervention
   Tan M., 2019, ARXIV190511946V3CSLG
   Towler J, 2012, REMOTE SENS-BASEL, V4, P1995, DOI 10.3390/rs4071995
   Ware A. R., 1988, Nuclear Europe, V8, P20
   Zakaria A, 2017, PROCEDIA COMPUT SCI, V105, P81, DOI 10.1016/j.procs.2017.01.203
   Zisserman, 2014, CORR
NR 26
TC 0
Z9 0
U1 1
U2 2
PD JUL
PY 2021
VL 53
IS 7
BP 2229
EP 2236
DI 10.1016/j.net.2021.01.012
WC Nuclear Science & Technology
DA 2023-11-11
ER

PT J
AU Chen, YG
   Zhang, LH
   Ai, ZH
   Long, YF
   Weldengus, TM
   Zheng, XB
   Wang, D
   Wang, HW
   Zhai, YT
   Huang, YQ
   Le, X
   Peng, YX
   Jiang, J
AF Chen, Yangguan
   Zhang, Longhan
   Ai, Zhehong
   Long, Yifan
   Weldengus, Temesgen Muruts
   Zheng, Xubin
   Wang, Di
   Wang, Haowen
   Zhai, Yiteng
   Huang, Yuqing
   Le, Xiao
   Peng, Yaxuan
   Jiang, Jing
TI Robot-accelerated development of a colorimetric CO2 sensing array with
   wide ranges and high sensitivity via multi-target Bayesian optimizations
SO SENSORS AND ACTUATORS B-CHEMICAL
DT Article
DE Colorimetric sensor; Design -Build -Test -Machine learning process; High
   -throughput; Algorithm -driven autonomous system; Multi -target
   optimization
ID CARBON-DIOXIDE; POLYETHYLENE-GLYCOL; HEALTH; NH3
AB The one-variable-at-a-time method for sensor R&D has received extensive research effort, yet it has reached the local maxima for specific sensing characteristics. To achieve the quasi-global maxima for suitable sensors, we developed the Design-Build-Test-Machine learning (DBTM) method for efficiently developing sensors on de-mand. In addition, the automation of the preparation and characterization processes frees researchers from labor-intensive work, generates adequate high-quality data, and enables researchers to discover valuable information in high-dimensional space. As a proof-of-concept, we built a high-throughput algorithm-driven autonomous system (HAAS) that supports the DBTM approach for developing a CO2 sensor. With the DBTM approach, we can simultaneously optimize multiple sensor units, each for a specific concentration interval. Therefore, such array can achieve an extensive range and sound sensitivity. Our work demonstrates the superiority of the DBTM method for multi-target and multi-variable sensor development. In contrast to single target optimization in other research areas, multiple characteristics should be improved for sensors. Our multi-target optimization algorithm optimizes four sensor characteristics. Our sensor array could rapidly detect CO2 concentrations from 400 ppm 30 % with a root mean square error (RMSE) of 0.27 %. The DBTM method is anticipated to be a new paradigm and accelerator of practical application for sensors after the initial proof of the sensing mechanism.
C1 [Chen, Yangguan; Zhang, Longhan; Ai, Zhehong; Long, Yifan; Weldengus, Temesgen Muruts; Jiang, Jing] Zhejiang Lab, Res Ctr Intelligent Sensing Syst, Hangzhou 311100, Zhejiang, Peoples R China.
   [Ai, Zhehong] Univ Chinese Acad Sci, Hangzhou Inst Adv Study, Hangzhou 310024, Zhejiang, Peoples R China.
   [Zheng, Xubin; Wang, Di] Zhejiang Lab, Res Ctr Sensing Mat & Devices, Hangzhou 311100, Zhejiang, Peoples R China.
   [Wang, Haowen] AntGroup, Alipay, Intelligence Dept Merchants Operat, Shanghai 201299, Peoples R China.
   [Zhai, Yiteng] Zhejiang Lab, Res Ctr Fintech, Hangzhou 311100, Zhejiang, Peoples R China.
   [Huang, Yuqing; Le, Xiao; Peng, Yaxuan] MegaRobo Technol Co Ltd, Shanghai 201210, Peoples R China.
RP Jiang, J (corresponding author), Zhejiang Lab, Res Ctr Intelligent Sensing Syst, Hangzhou 311100, Zhejiang, Peoples R China.
EM jiangj@zhejianglab.com
CR Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Chao HJ, 2003, ENVIRON HEALTH PERSP, V111, P1242, DOI 10.1289/ehp.5697
   Chaterjee S, 2019, ENVIRON CHEM LETT, V17, P465, DOI 10.1007/s10311-018-0774-z
   Chatterjee C, 2015, J MATER CHEM A, V3, P5642, DOI 10.1039/c4ta06321j
   Chen Y, 2015, BIOSENS BIOELECTRON, V67, P477, DOI 10.1016/j.bios.2014.09.010
   Chugh T, 2020, IEEE C EVOL COMPUTAT
   Davey AK, 2021, SENSOR ACTUAT B-CHEM, V344, DOI 10.1016/j.snb.2021.130313
   Fisk WJ, 2000, ANNU REV ENERG ENV, V25, P537, DOI 10.1146/annurev.energy.25.1.537
   Guo Z, 2012, J AM CHEM SOC, V134, P17846, DOI 10.1021/ja306891c
   Gupta A, 2018, IEEE TETCI, V2, P51, DOI 10.1109/TETCI.2017.2769104
   HamediRad M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13189-z
   Huang WW, 2022, ENVIRON TECHNOL, V43, P4545, DOI 10.1080/09593330.2021.1958012
   Kaya GG, 2021, TURK J CHEM, V45, P2013, DOI 10.3906/kim-2101-45
   Knowles J, 2006, IEEE T EVOLUT COMPUT, V10, P50, DOI 10.1109/TEVC.2005.851274
   Ko K, 2020, SCI TOTAL ENVIRON, V729, DOI 10.1016/j.scitotenv.2020.138786
   Lee JY, 2022, J ENVIRON MANAGE, V312, DOI 10.1016/j.jenvman.2022.114893
   Leibovich-Raveh T., 2018, J NUMER COGN, V4, P429, DOI [10.5964/jnc.v4i2.74, DOI 10.5964/JNC.V4I2.74]
   Li Z, 2019, CHEM REV, V119, P231, DOI 10.1021/acs.chemrev.8b00226
   Lin YQ, 2020, MAT SCI SEMICON PROC, V107, DOI 10.1016/j.mssp.2019.104820
   Liu Z, 2022, JOULE, V6, P834, DOI 10.1016/j.joule.2022.03.003
   MacLeod BP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz8867
   Milan A, 2014, IEEE T PATTERN ANAL, V36, P58, DOI 10.1109/TPAMI.2013.103
   Miller DD, 2016, J PHYS CHEM C, V120, P25489, DOI 10.1021/acs.jpcc.6b09506
   Molina A, 2020, SYNTHETIC MET, V270, DOI 10.1016/j.synthmet.2020.116602
   Raccuglia P, 2016, NATURE, V533, P73, DOI 10.1038/nature17439
   Ramachandran RP, 2022, J STORED PROD RES, V96, DOI 10.1016/j.jspr.2022.101950
   Rezk MY, 2020, NANOMATERIALS-BASEL, V10, DOI 10.3390/nano10112251
   Saleh TA, 2021, TRENDS ENVIRON ANAL, V32, DOI 10.1016/j.teac.2021.e00142
   Saliu F, 2018, SENSOR ACTUAT B-CHEM, V258, P1117, DOI 10.1016/j.snb.2017.12.007
   Seifrid M, 2022, ACCOUNTS CHEM RES, DOI [10.1021/acs.accounts.2c00220, 10.1021/acs.accounts.2c002202454]
   Shevlin M, 2017, ACS MED CHEM LETT, V8, P601, DOI 10.1021/acsmedchemlett.7b00165
   Steiner S, 2019, SCIENCE, V363, P144, DOI 10.1126/science.aav2211
   Wang LX, 2019, ACS SUSTAIN CHEM ENG, V7, P14785, DOI 10.1021/acssuschemeng.9b02798
   Xia GM, 2017, SENSOR ACTUAT B-CHEM, V244, P252, DOI 10.1016/j.snb.2016.12.143
   Zhang YN, 2018, SENSOR ACTUAT B-CHEM, V255, P3216, DOI 10.1016/j.snb.2017.09.148
   Zhu Q, 2022, NATL SCI REV, V9, DOI 10.1093/nsr/nwac190
NR 36
TC 0
Z9 0
U1 7
U2 7
PD SEP 1
PY 2023
VL 390
AR 133942
DI 10.1016/j.snb.2023.133942
EA MAY 2023
WC Chemistry, Analytical; Electrochemistry; Instruments & Instrumentation
DA 2023-11-11
ER

PT J
AU Wang, K
   Song, TT
   Wang, YT
   Fang, CW
   He, JY
   Nirmalathas, A
   Lim, C
   Wong, E
   Kandeepan, S
AF Wang, Ke
   Song, Tingting
   Wang, Yitong
   Fang, Chengwei
   He, Jiayuan
   Nirmalathas, Ampalavanapillai
   Lim, Christina
   Wong, Elaine
   Kandeepan, Sithamparanathan
TI Evolution of Short-Range Optical Wireless Communications
SO JOURNAL OF LIGHTWAVE TECHNOLOGY
DT Article
DE Wireless communication; Optical transmitters; Optical receivers;
   High-speed optical techniques; Optical fibers; Communication system
   security; Wireless fidelity; Optical wireless communications; optical
   MIMO; machine learning; underwater optical wireless communications;
   optical wireless vehicular communications
ID VISIBLE-LIGHT COMMUNICATION; GENERALIZED SPATIAL MODULATION; PERFORMANCE
   ANALYSIS; ORTHOGONAL-FILTERS; DATA-TRANSMISSION; POWER-EFFICIENT;
   MULTIUSER MIMO; SYSTEM; VLC; LINKS
AB The optical wireless communication (OWC) technology explores the broad unregulated optical spectrum to provide high-speed wireless communications, and the visible, ultraviolet and near-infrared wavelength ranges all have been investigated. Compared with the conventional radio frequency (RF) band, the spectrum in OWC systems is much less congested and the interference is much lower. The OWC technology also provides enhanced physical layer security due to the natural confinement of optical beams that makes it difficult to intercept the transmitted signal. Hence, the OWC technology has been widely studied and considered as a promising candidate in future beyond-5G communications. The OWC technology has been considered for both long-range and short-range applications, and in this paper we will introduce the fundamentals and recent developments of short-range OWC systems. In particular, we will focus on the key short-range OWC applications in indoor personal or local area communications, underwater wireless communications, wireless data center networks, and vehicular communications. We will also introduce some recent widely studied advanced techniques to boost the performance of short-range OWC systems, including the spatial domain diversity, multiplexing and modulation principles to improve the system robustness and data rate, and the machine learning algorithms and hardware accelerators to suppress both linear and nonlinear effects to improve OWC signal quality and bit-error-rate performance.
C1 [Wang, Ke; Song, Tingting; Fang, Chengwei; Kandeepan, Sithamparanathan] RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
   [He, Jiayuan] RMIT Univ, Sch Comp Technol, Melbourne, Vic 3000, Australia.
   [Song, Tingting; Nirmalathas, Ampalavanapillai; Lim, Christina; Wong, Elaine] Univ Melbourne, Dept Elect & Elect Engn, Melbourne, Vic 3010, Australia.
RP Wang, K (corresponding author), RMIT Univ, Sch Engn, Melbourne, Vic 3000, Australia.
EM ke.wang@rmit.edu.au; tingtings@unimelb.edu.au;
   s3587959@student.rmit.edu.au; s3643273@student.rmit.edu.au;
   jiayuan.he@rmit.edu.au; nirmalat@unimelb.edu.au;
   chrislim@unimelb.edu.au; ewon@unimelb.edu.au;
   kandeepan.sithamparanathan@rmit.edu.au
CR Aboagye S, 2021, IEEE COMMUN LETT, V25, P3913, DOI 10.1109/LCOMM.2021.3114594
   Abu Bakar AH, 2021, IEEE T INSTRUM MEAS, V70, DOI 10.1109/TIM.2020.3024526
   Al-Ghamdi AG, 2004, IEEE T COMMUN, V52, P37, DOI 10.1109/TCOMM.2003.822160
   Ali W, 2019, IEEE PHOTONIC TECH L, V31, P805, DOI 10.1109/LPT.2019.2905647
   Aljada M, 2006, OPT EXPRESS, V14, P6823, DOI 10.1364/OE.14.006823
   Alresheedi MT, 2011, IEEE J SEL AREA COMM, V29, P1328, DOI 10.1109/JSAC.2011.110620
   [Anonymous], 2018, 2018 11 INT S COMM S
   Arvanitakis GN, 2020, IEEE PHOTONICS J, V12, DOI 10.1109/JPHOT.2019.2959656
   Bariah L, 2020, IEEE ACCESS, V8, P174792, DOI 10.1109/ACCESS.2020.3019590
   Bechadergue Bastien, 2019, 2019 Global LIFI Congress (GLC), DOI 10.1109/GLC.2019.8864116
   Berenguer PW, 2018, IEEE J SEL AREA COMM, V36, P185, DOI 10.1109/JSAC.2017.2774618
   Bergen MH, 2017, J LIGHTWAVE TECHNOL, V35, P3877, DOI 10.1109/JLT.2017.2723978
   Bian R, 2019, J LIGHTWAVE TECHNOL, V37, P2418, DOI 10.1109/JLT.2019.2906464
   Biswas Abhijit, 2019, OSA LAS C 2019 LTH1B, DOI 10.1055/s-0039-1695666
   Bober KL, 2021, J LIGHTWAVE TECHNOL, V39, P3420, DOI 10.1109/JLT.2021.3069186
   Buzzi S, 2019, IEEE T COMMUN, V67, P3323, DOI 10.1109/TCOMM.2019.2896122
   Cailean AM, 2017, IEEE COMMUN SURV TUT, V19, P2681, DOI 10.1109/COMST.2017.2706940
   Cailean AM, 2015, IEEE SENS J, V15, P4632, DOI 10.1109/JSEN.2015.2425473
   Cao ZZ, 2019, LIGHT-SCI APPL, V8, DOI 10.1038/s41377-019-0177-3
   Chaudhry AU, 2021, IEEE CONSUM ELECTR M, V10, P21, DOI 10.1109/MCE.2020.3029772
   Chaudhry AU, 2021, IEEE VEH TECHNOL MAG, V16, P48, DOI 10.1109/MVT.2021.3063706
   Chen C, 2021, IEEE T COMMUN, V69, P1175, DOI 10.1109/TCOMM.2020.3035405
   Chen HJ, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2017.2748152
   Chen J., 2022, IEEE PHOTON J, V14, P1
   Cheng CL, 2019, IEEE ANTENNAS PROP, P2145, DOI [10.1109/apusncursinrsm.2019.8889030, 10.1109/APUSNCURSINRSM.2019.8889030]
   Chi N, 2020, IEEE VEH TECHNOL MAG, V15, P93, DOI 10.1109/MVT.2020.3017153
   Chi N, 2018, OPT EXPRESS, V26, P26700, DOI 10.1364/OE.26.026700
   CHU TS, 1987, IEEE COMMUN MAG, V25, P4, DOI 10.1109/MCOM.1987.1093675
   Cossu G, 2015, OPT EXPRESS, V23, P15700, DOI 10.1364/OE.23.015700
   Cui Y, 2011, IEEE WIREL COMMUN, V18, P46, DOI 10.1109/MWC.2011.6108333
   Dabiri MT, 2021, IEEE T VEH TECHNOL, V70, P8926, DOI 10.1109/TVT.2021.3098389
   Dang SP, 2020, NAT ELECTRON, V3, P20, DOI 10.1038/s41928-019-0355-6
   Dhatchayeny DR, 2019, IEEE SENS J, V19, P5594, DOI 10.1109/JSEN.2019.2906898
   Di YJ, 2021, 2021 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Do TH, 2019, IEEE ACCESS, V7, P95797, DOI 10.1109/ACCESS.2019.2928600
   Du J, 2021, OPT EXPRESS, V29, P783, DOI 10.1364/OE.416117
   Elzanaty A, 2020, IEEE T COMMUN, V68, P6388, DOI 10.1109/TCOMM.2020.3006575
   Eso E, 2021, IEEE PHOTONIC TECH L, V33, P908, DOI 10.1109/LPT.2021.3086836
   Fath T, 2013, IEEE T COMMUN, V61, P733, DOI 10.1109/TCOMM.2012.120512.110578
   Feng F, 2019, OPT LETT, V44, P6009, DOI 10.1364/OL.44.006009
   Fu CF, 2022, OPT EXPRESS, V30, P18743, DOI 10.1364/OE.457784
   GFELLER FR, 1979, P IEEE, V67, P1474, DOI 10.1109/PROC.1979.11508
   Haas H., 2018, REV PHYS, P26, DOI [10.1016/j.revip.2017.10.001, DOI 10.1016/J.REVIP.2017.10.001]
   Haas H, 2016, J LIGHTWAVE TECHNOL, V34, P1533, DOI 10.1109/JLT.2015.2510021
   Halawi S, 2019, IEEE T COMMUN, V67, P4252, DOI 10.1109/TCOMM.2019.2904503
   Hamza AS, 2019, IEEE COMMUN SURV TUT, V21, P1346, DOI 10.1109/COMST.2018.2876805
   Hasan MK, 2022, IEEE T INTELL TRANSP, V23, P6260, DOI 10.1109/TITS.2021.3086409
   He JY, 2020, PHOTONICS-BASEL, V7, DOI 10.3390/photonics7040105
   He JY, 2020, J LIGHTWAVE TECHNOL, V38, P4632, DOI 10.1109/JLT.2020.2994576
   He JY, 2019, OPT LETT, V44, P3745, DOI 10.1364/OL.44.003745
   Hong Y, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Hu M, 2019, J LIGHTWAVE TECHNOL, V37, P4940, DOI 10.1109/JLT.2019.2926218
   Huang SM, 2022, IEEE WCNC, P2316, DOI 10.1109/WCNC51071.2022.9771959
   Huang XH, 2021, J LIGHTWAVE TECHNOL, V39, P4351, DOI 10.1109/JLT.2021.3073395
   Jamali MV, 2017, IEEE PHOTONIC TECH L, V29, P462, DOI 10.1109/LPT.2017.2657228
   Jiang R, 2020, IEEE ACCESS, V8, P20363, DOI 10.1109/ACCESS.2020.2967461
   Jungnickel V, 2002, IEEE J SEL AREA COMM, V20, P631, DOI 10.1109/49.995522
   Jungnickel V, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Kahn JM, 1998, IEEE COMMUN MAG, V36, P88, DOI 10.1109/35.735884
   Kahn JM, 1997, P IEEE, V85, P265, DOI 10.1109/5.554222
   Kaymak Y, 2019, IEEE COMMUN LETT, V23, P814, DOI 10.1109/LCOMM.2019.2904031
   Khalighi MA, 2014, IEEE COMMUN SURV TUT, V16, P2231, DOI 10.1109/COMST.2014.2329501
   Khan FN, 2019, J LIGHTWAVE TECHNOL, V37, P493, DOI 10.1109/JLT.2019.2897313
   Koonen T, 2018, J LIGHTWAVE TECHNOL, V36, P4486, DOI 10.1109/JLT.2018.2834374
   Koonen T, 2018, J LIGHTWAVE TECHNOL, V36, P1459, DOI 10.1109/JLT.2017.2787614
   Koonen T, 2016, J LIGHTWAVE TECHNOL, V34, P4802, DOI 10.1109/JLT.2016.2574855
   Kumar CR, 2017, IEEE PHOTONIC TECH L, V29, P921, DOI 10.1109/LPT.2017.2694462
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee H, 2018, OPT EXPRESS, V26, P18131, DOI 10.1364/OE.26.018131
   Lee H, 2018, OPT EXPRESS, V26, P6222, DOI 10.1364/OE.26.006222
   Lee J, 2021, OPT EXPRESS, V29, P26165, DOI 10.1364/OE.427250
   Lee J, 2020, OPT EXPRESS, V28, P13384, DOI 10.1364/OE.391050
   Li MF, 2017, CHIN OPT LETT, V15, DOI 10.3788/COL201715.050604
   Li XB, 2017, IEEE COMMUN LETT, V21, P382, DOI 10.1109/LCOMM.2016.2625300
   Lian J, 2017, J LIGHTWAVE TECHNOL, V35, P5024, DOI 10.1109/JLT.2017.2765462
   Lin BJ, 2017, IEEE PHOTONIC TECH L, V29, P579, DOI 10.1109/LPT.2017.2669079
   Liu L., 2020, P 2020 OPT FIB COMM, DOI DOI 10.1364/OFC.2020.M1J.4
   Liu YF, 2018, 2018 IEEE 18TH INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P509, DOI 10.1109/ICCT.2018.8599895
   Lorrière N, 2020, J LIGHTWAVE TECHNOL, V38, P3822, DOI 10.1109/JLT.2020.2981554
   Ma S, 2019, IEEE ACCESS, V7, P30588, DOI 10.1109/ACCESS.2019.2903375
   Mamun SA, 2018, IEEE T GREEN COMMUN, V2, P1174, DOI 10.1109/TGCN.2018.2838525
   MARSH GW, 1994, IEEE PHOTONIC TECH L, V6, P1268, DOI 10.1109/68.329659
   Matheus LEM, 2019, IEEE COMMUN SURV TUT, V21, P3204, DOI 10.1109/COMST.2019.2913348
   Miao P, 2019, IEEE ACCESS, V7, P71436, DOI 10.1109/ACCESS.2019.2919983
   Thieu MD, 2019, IEEE ACCESS, V7, P69873, DOI 10.1109/ACCESS.2019.2918338
   Musumeci F, 2019, IEEE COMMUN SURV TUT, V21, P1383, DOI 10.1109/COMST.2018.2880039
   Narmanlioglu O, 2018, COMPUT COMMUN, V120, P138, DOI 10.1016/j.comcom.2018.02.003
   Naser S, 2022, IEEE WIREL COMMUN, V29, P48, DOI 10.1109/MWC.005.00334
   Ning J, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3089781
   Nirmalathas Ampalavanapillai, 2021, IEEE/OSA Journal of Optical Communications and Networking, V13, pA178, DOI 10.1364/JOCN.403485
   Nirmalathas TA, 2020, 2020 OPTICAL FIBER COMMUNICATIONS CONFERENCE AND EXPOSITION (OFC)
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Ozyurt AB, 2023, IEEE SYST J, V17, P1591, DOI 10.1109/JSYST.2022.3179183
   Park KH, 2013, IEEE T COMMUN, V61, P1535, DOI 10.1109/TCOMM.2013.012913.110290
   Pathak PH, 2015, IEEE COMMUN SURV TUT, V17, P2047, DOI 10.1109/COMST.2015.2476474
   Perera A., 2021, PROC IEEE 16 INT C I, P58
   Pohl V, 2000, PIMRC 2000: 11TH IEEE INTERNATIONAL SYMPOSIUM ON PERSONAL, INDOOR AND MOBILE RADIO COMMUNICATIONS, VOLS 1 AND 2, PROCEEDINGS, P297, DOI 10.1109/PIMRC.2000.881437
   Qiu Y, 2018, IEEE WIREL COMMUN, V25, P178, DOI 10.1109/MWC.2017.1700051
   Rajagopal S, 2012, IEEE COMMUN MAG, V50, P72, DOI 10.1109/MCOM.2012.6163585
   Safi H, 2020, J LIGHTWAVE TECHNOL, V38, P5036, DOI 10.1109/JLT.2020.2997806
   Shah SAA, 2018, IEEE COMMUN MAG, V56, P111, DOI 10.1109/MCOM.2018.1700467
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Shen SQ, 2022, IEEE T WIREL COMMUN, V21, P6271, DOI 10.1109/TWC.2022.3148169
   Shi P, 2020, OPT EXPRESS, V28, P38733, DOI 10.1364/OE.410283
   Song HJ, 2021, IEEE MICROW MAG, V22, P88, DOI 10.1109/MMM.2021.3056935
   Song TL, 2019, J LIGHTWAVE TECHNOL, V37, P5170, DOI 10.1109/JLT.2019.2929801
   Song TT, 2020, J LIGHTWAVE TECHNOL, V38, P4250, DOI 10.1109/JLT.2020.2988669
   Stepniak G, 2015, J LIGHTWAVE TECHNOL, V33, P4413, DOI 10.1109/JLT.2015.2472575
   Sun C, 2019, IEEE T COMMUN, V67, P2188, DOI 10.1109/TCOMM.2018.2883622
   Sun X, 2021, IEEE ACCESS, V9, P80897, DOI 10.1109/ACCESS.2021.3085117
   Sung JY, 2022, J LIGHTWAVE TECHNOL, V40, P4150, DOI 10.1109/JLT.2022.3158733
   Tanaka Y, 2003, IEICE T COMMUN, VE86B, P2440
   Tawfik MM, 2021, IEEE PHOTONICS J, V13, DOI 10.1109/JPHOT.2021.3104819
   Teli S, 2017, IEEE COMMUN MAG, V55, P156, DOI 10.1109/MCOM.2017.1600923
   Nguyen T, 2018, IEEE COMMUN MAG, V56, P213, DOI 10.1109/MCOM.2018.1700134
   Turan B, 2022, IEEE T VEH TECHNOL, V71, P10110, DOI 10.1109/TVT.2022.3181160
   Turan B, 2021, IEEE T VEH TECHNOL, V70, P9659, DOI 10.1109/TVT.2021.3107835
   Uysal M., 2018, IEEE 802 11BB REFERE
   Wang J., 2017, 2017 IEEE International Magnetics Conference (INTERMAG), DOI 10.1109/INTMAG.2017.8007838
   Wang JM, 2019, OPT EXPRESS, V27, P12171, DOI 10.1364/OE.27.012171
   Wang K, 2022, IEEE PHOTONIC TECH L, V34, P455, DOI 10.1109/LPT.2022.3165162
   Wang K, 2021, OPT EXPRESS, V29, P4582, DOI 10.1364/OE.409395
   Wang K, 2020, IEEE PHOTONIC TECH L, V32, P1373, DOI 10.1109/LPT.2020.3026343
   Wang K, 2020, OPT LETT, V45, P4980, DOI 10.1364/OL.396718
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P5988, DOI 10.1109/JLT.2019.2944639
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P619, DOI 10.1109/JLT.2018.2889252
   Wang K, 2019, J LIGHTWAVE TECHNOL, V37, P627, DOI 10.1109/JLT.2018.2881728
   Wang K, 2014, OPT LETT, V39, P5717, DOI 10.1364/OL.39.005717
   Wang K, 2011, OPT EXPRESS, V19, P21321, DOI 10.1364/OE.19.021321
   Wang L, 2021, LASER PHOTONICS REV, V15, DOI 10.1002/lpor.202000406
   Wang TQ, 2013, J LIGHTWAVE TECHNOL, V31, P3302, DOI 10.1109/JLT.2013.2281592
   Wang X, 2018, IEEE COMMUN SURV TUT, V20, P1616, DOI 10.1109/COMST.2018.2844322
   Wang YG, 2014, IEEE COMMUN LETT, V18, P1719, DOI 10.1109/LCOMM.2014.2349990
   Wang YL, 2017, IEEE T COMMUN, V65, P1708, DOI 10.1109/TCOMM.2017.2654249
   Wei ZX, 2022, J LIGHTWAVE TECHNOL, V40, P5083, DOI 10.1109/JLT.2022.3172921
   Werfli K, 2018, J LIGHTWAVE TECHNOL, V36, P1944, DOI 10.1109/JLT.2018.2796503
   Wu XP, 2020, IEEE T WIREL COMMUN, V19, P8211, DOI 10.1109/TWC.2020.3020160
   Xiao L, 2019, IEEE T COMMUN, V67, P6994, DOI 10.1109/TCOMM.2019.2930247
   Xie EY, 2020, IEEE PHOTONIC TECH L, V32, P499, DOI 10.1109/LPT.2020.2981827
   Xing FY, 2020, IEEE T WIREL COMMUN, V19, P251, DOI 10.1109/TWC.2019.2943867
   You Q, 2021, CHIN OPT LETT, V19, DOI 10.3788/COL202119.120602
   Younus SH, 2019, IEEE ACCESS, V7, P1126, DOI 10.1109/ACCESS.2018.2886398
   Zeadally Sherali, 2020, IEEE Communications Standards Magazine, V4, P11, DOI 10.1109/MCOMSTD.001.1900044
   Zeng ZQ, 2017, IEEE COMMUN SURV TUT, V19, P204, DOI 10.1109/COMST.2016.2618841
   Zhang SJ, 2021, IEEE PHOTONIC TECH L, V33, P773, DOI 10.1109/LPT.2021.3095163
   Zhang XB, 2018, OPT LETT, V43, P723, DOI 10.1364/OL.43.000723
   Zhang Y, 2019, IEEE J SEL TOP QUANT, V25, DOI 10.1109/JSTQE.2019.2910415
   Zhao X, 2018, IEEE ACCESS, V6, P34004, DOI 10.1109/ACCESS.2018.2847744
   Zhao XS, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2020.2991756
   Zinda T., 2018, PROC INT S COMMUN SY, P1
NR 150
TC 2
Z9 2
U1 8
U2 8
PD FEB 15
PY 2023
VL 41
IS 4
BP 1019
EP 1040
DI 10.1109/JLT.2022.3215590
WC Engineering, Electrical & Electronic; Optics; Telecommunications
DA 2023-11-11
ER

PT C
AU Yu, J
   Kim, J
   Seo, E
AF Yu, Junyeol
   Kim, Jongseok
   Seo, Euiseong
GP IEEE
TI Know Your Enemy To Save Cloud Energy: Energy-Performance
   Characterization of Machine Learning Serving
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
ID POWER
AB The proportion of machine learning (ML) inference in modern cloud workloads is rapidly increasing, and graphic processing units (GPUs) are the most preferred computational accelerators for it. The massively parallel computing capability of GPUs is well-suited to the inference workloads but consumes more power than conventional CPUs. Therefore, GPU servers contribute significantly to the total power consumption of a data center. However, despite their heavy power consumption, GPU power management in cloud-scale has not yet been actively researched. In this paper, we reveal three findings about energy efficiency of ML inference clusters in the cloud. (1) GPUs of different architectures have comparative advantages in energy efficiency to each other for a set of ML models. (2) The energy efficiency of a GPU set may significantly vary depending on the number of active GPUs and their clock frequencies even when producing the same level of throughput. (3) The service level objective(SLO)-blind dynamic voltage and frequency scaling (DVFS) driver of commercial GPUs maintain an immoderately high clock frequency. Based on these implications, we propose a hierarchical GPU resource management approach for cloudscale inference services. The proposed approach consists of energy-aware cluster allocation, intra-cluster node scaling, intranode GPU scaling and GPU clock scaling schemes considering the inference service architecture hierarchy. We evaluated our approach with its prototype implementation and cloud-scale simulation. The evaluation with real-world traces showed that the proposed schemes can save up to 28.3% of the cloud-scale energy consumption when serving five ML models with 105 servers having three different kinds of GPUs.
C1 [Yu, Junyeol; Kim, Jongseok; Seo, Euiseong] Sungkyunkwan Univ, Dept Comp Sci & Engn, Seoul, South Korea.
RP Yu, J (corresponding author), Sungkyunkwan Univ, Dept Comp Sci & Engn, Seoul, South Korea.
EM junyeol.yu@skku.edu; ks77sj@skku.edu; euiseong@skku.edu
CR Abe Y, 2014, INT PARALL DISTRIB P, DOI 10.1109/IPDPS.2014.23
   Abe Yuki, 2012, WORKSH POW AW COMP S
   Ali A, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00073
   [Anonymous], 2021, NVIDIA TRIT INF SERV
   [Anonymous], 2021, ARCH TEAM TWITT STRE
   [Anonymous], 2021, OR TOOLS GOOGL OPT T
   Arafa Y, 2020, 17TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2020 (CF 2020), P60, DOI 10.1145/3387902.3392613
   Bari MAS, 2018, PROCEEDINGS OF 2018 IEEE/ACM PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH PERFORMANCE COMPUTER SYSTEMS (PMBS 2018), P83, DOI [10.1109/PMBS.2018.8641666, 10.1109/PMBS.2018.00013]
   Brewer EA, 2015, P 6 ACM S CLOUD COMP, P167, DOI [10.1145/2806777.2809955, DOI 10.1145/2806777.2809955]
   Bridges RA, 2016, ACM COMPUT SURV, V49, DOI 10.1145/2962131
   Crankshaw Daniel, 2020, SoCC '20: Proceedings of the 11th ACM Symposium on Cloud Computing, P477, DOI 10.1145/3419111.3421285
   Crankshaw D, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P613
   Dakkak A, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P46, DOI 10.1145/3330345.3331057
   DEMERS A, 1989, COMP COMM R, V19, P1, DOI 10.1145/75247.75248
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Fan D, 2020, AWS MACHINE LEARNING
   Frazelle J., 2020, ACM QUEUE, V18, P5
   Ge R, 2013, PROC INT CONF PARAL, P826, DOI 10.1109/ICPP.2013.98
   Gebhart M, 2012, INT SYMP MICROARCH, P96, DOI 10.1109/MICRO.2012.18
   Gebhart M, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P235, DOI 10.1145/2024723.2000093
   Gueyoung Jung, 2013, 2013 IEEE Ninth World Congress on Services (SERVICES), P456, DOI 10.1109/SERVICES.2013.55
   Gujarati A, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P443
   Gujarati A, 2017, PROCEEDINGS OF THE 2017 INTERNATIONAL MIDDLEWARE CONFERENCE (MIDDLEWARE'17), P109, DOI 10.1145/3135974.3135993
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Hodak M, 2019, IEEE INT CONF BIG DA, P1814, DOI 10.1109/BigData47090.2019.9005632
   Jahanshahi A, 2020, IEEE COMPUT ARCHIT L, V19, P139, DOI 10.1109/LCA.2020.3023723
   Kleinschmidt SP, 2018, IEEE INT SYMP SAFE
   Koo G, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P307, DOI 10.1145/3079856.3080239
   Krumke SO, 2013, EUR J OPER RES, V228, P46, DOI 10.1016/j.ejor.2013.01.027
   Kundakcioglu OE., 2009, ENCY OPTIMIZATION, P1153, DOI [DOI 10.1007/978-0-387-74759-0_200, DOI 10.1007/978-0-387-74759-0200]
   Lashgar A, 2013, LECT NOTES COMPUT SC, V7767, P134, DOI 10.1007/978-3-642-36424-2_12
   Li Y, 2020, IEEE INFOCOM SER, P1668, DOI [10.1109/INFOCOM41043.2020.9155267, 10.1109/infocom41043.2020.9155267]
   Masanet E, 2020, SCIENCE, V367, P984, DOI 10.1126/science.aba3758
   Mei X., 2013, P WORKSHOP POWER AWA, DOI [10.1145/2525526.2525852, DOI 10.1145/2525526.2525852]
   Mei XX, 2017, DIGIT COMMUN NETW, V3, P89, DOI 10.1016/j.dcan.2016.10.001
   Minsoo Rhu, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P86, DOI 10.1145/2540708.2540717
   Mittal S, 2015, ACM COMPUT SURV, V47, DOI 10.1145/2636342
   Nabavinejad SM, 2019, IEEE COMPUT ARCHIT L, V18, P136, DOI 10.1109/LCA.2019.2942020
   Narayanan D., 2020, P WORKSHOP DISTRIBUT
   Petrillo F, 2016, LECT NOTES COMPUT SC, V9936, P157, DOI 10.1007/978-3-319-46295-0_10
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Seo W, 2021, ACM T ARCHIT CODE OP, V18, DOI 10.1145/3460352
   Shehabi A., 2016, US DATA CTR ENERGY U
   Shen K, 2013, ACM SIGPLAN NOTICES, V48, P65, DOI 10.1145/2499368.2451124
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Spetko M, 2021, ENERGIES, V14, DOI 10.3390/en14020376
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Tang ZH, 2019, E-ENERGY'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON FUTURE ENERGY SYSTEMS, P315, DOI 10.1145/3307772.3328315
   Taylor Richard N., 2000, ARCHITECTURAL STYLES, V7
   Wang Y, 2012, DES AUT TEST EUROPE, P300
   Yadwadkar NJ, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC '17), P452, DOI 10.1145/3127479.3131614
   Yao CR, 2021, CONCURR COMP-PRACT E, V33, DOI 10.1002/cpe.6064
   Yeung G., 2020, 12 USENIX WORKSH HOT
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang MJ, 2019, PROCEEDINGS OF THE 2019 USENIX CONFERENCE ON OPERATIONAL MACHINE LEARNING, P5
   Zhao JS, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2541228.2541231
NR 58
TC 0
Z9 0
U1 1
U2 1
PY 2023
BP 842
EP 854
DI 10.1109/HPCA56546.2023.10070943
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Koo, Y
   Kim, S
   Ha, YG
AF Koo, Yongbon
   Kim, Sunghoon
   Ha, Young-guk
TI OpenCL-Darknet: implementation and optimization of OpenCL-based deep
   learning object detection framework
SO WORLD WIDE WEB-INTERNET AND WEB INFORMATION SYSTEMS
DT Article
DE deep learning; image processing; object detection; parallel programming;
   OpenCL
ID HISTOGRAMS
AB Object detection is a technology that deals with recognizing classes of objects and their location. It is used in many different areas, such as in face-detecting systems [16, 34, 37], surveillance tools [9], human-machine interfaces [17], and self-driving cars [18, 23, 25, 26, 30]. These days, deep learning object detection approaches have achieved significantly better performance than the classical feature-based algorithms. Darknet [31] is a deep learning object detection framework, which is well known for its fast speed and simple structure. Unfortunately, Darknet can only work with Nvidia CUDA [6] for accelerating its deep learning calculations. For this reason, users have only limited options of selecting appropriate graphic cards. Open computing language (OpenCL) [35], an open standard for cross-platform, parallel programming of heterogeneous systems, is available for the general hardware accelerators. However, many deep learning frameworks including Darknet have no support for OpenCL. In our previous paper, we presented OpenCL-Darknet [19], which transformed the CUDA-based Darknet into an open standard OpenCL backend. The original OpenCL-Darknet successfully showed its ability for the general graphics processing unit (GPU) hardware. However, it could not achieve competitive performance compared with the CUDA version, and it only supported a limited platform. In this study, we improved the performance of OpenCL-Darknet with several optimization techniques and added support for various architectures. We also evaluated OpenCL-Darknet not only in AMD R7 accelerated processing unit (APU) with OpenCL 2.0, but also in Nvidia GPU and ARM Mali embedded GPU with OpenCL 1.2 Profile. The evaluation using the standard object detection datasets showed that our advanced OpenCL-Darknet reduced the processing time by at most 50% on average for various deep learning object detection networks compared with our original implementation. We also showed that our OpenCL deep learning framework has competitiveness compared with the CUDA-based one.
C1 [Koo, Yongbon; Kim, Sunghoon] Elect & Telecommun Res Inst, 218 Gajeong Ro, Daejeon, South Korea.
   [Ha, Young-guk] Konkuk Univ, 120 Neungdong Ro, Seoul, South Korea.
RP Ha, YG (corresponding author), Konkuk Univ, 120 Neungdong Ro, Seoul, South Korea.
EM ybkoo@etri.re.kr; saint@etri.re.kr; ygha@konkuk.ac.kr
CR [Anonymous], CLBLAS
   [Anonymous], DARKNET OPEN SOURCE
   [Anonymous], CUBLAS
   [Anonymous], CLRNG
   Badía JM, 2019, J SUPERCOMPUT, V75, P1284, DOI 10.1007/s11227-018-2422-6
   Barry D., 2019, XYOLO MODEL REAL TIM
   Beck Kent, 2003, TEST DRIVEN DEV EXAM
   Cook S, 2013, CUDA PROGRAMMING: A DEVELOPER'S GUIDE TO PARALLEL COMPUTING WITH GPUS, P1
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Dalal N, 2006, LECT NOTES COMPUT SC, V3952, P428, DOI 10.1007/11744047_33
   Everingham M., PASCAL VISUAL OBJECT
   Geiger A., 2012, Proc. IEEE Comput. Soc. Conf. Comput. Vis. Pattern. Recognit
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Gu J., 2016, P 4 INT WORKSH OPENC
   Haseljic H., 2018, P 2018 IEEE INT C IM
   Hendry, 2019, IMAGE VISION COMPUT, V87, P47, DOI 10.1016/j.imavis.2019.04.007
   Ji Y, 2018, ETRI J, V40, P435, DOI 10.4218/etrij.2018-0066
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Kim J, 2015, ETRI J, V37, P793, DOI 10.4218/etrij.15.0114.0076
   Koo Y., 2018, P 1 INT WORKSH DRIV
   Koo Y, 2015, IEEE INT VEH SYM, P394, DOI 10.1109/IVS.2015.7225717
   Lee W, 2018, INT J WEB GRID SERV, V14, P273
   Liao LL, 2018, PROC INT CONF PARAL, DOI 10.1145/3225058.3225107
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Montemerlo M, 2008, J FIELD ROBOT, V25, P569, DOI 10.1002/rob.20258
   Neubeck A, 2006, INT C PATT RECOG, P850, DOI 10.1109/icpr.2006.479
   Noh S, 2018, IEEE T INTELL TRANSP, V19, P58, DOI 10.1109/TITS.2017.2691346
   Noh S, 2015, ETRI J, V37, P1032, DOI 10.4218/etrij.15.0114.0095
   Nugteren C., 2017, CLTUNE GENERIC AUTOT
   Nugteren C., 2017, CLBLAST TUNED OPENCL
   Papageorgiou CP, 1998, SIXTH INTERNATIONAL CONFERENCE ON COMPUTER VISION, P555, DOI 10.1109/ICCV.1998.710772
   Park M, 2015, ETRI J, V37, P617
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rowley HA, 1998, IEEE T PATTERN ANAL, V20, P23, DOI 10.1109/34.655647
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
NR 37
TC 6
Z9 6
U1 3
U2 17
PD JUL
PY 2021
VL 24
IS 4
SI SI
BP 1299
EP 1319
DI 10.1007/s11280-020-00778-y
EA FEB 2020
WC Computer Science, Information Systems; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Shah, M
   Neff, R
   Wu, HC
   Minutoli, M
   Tumeo, A
   Becchi, M
AF Shah, Milan
   Neff, Reece
   Wu, Hancheng
   Minutoli, Marco
   Tumeo, Antonino
   Becchi, Michela
GP ACM
TI Accelerating Random Forest Classification on GPU and FPGA
SO 51ST INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING, ICPP 2022
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 51st International Conference on Parallel Processing (ICPP)
CY AUG 29-SEP 01, 2022
CL ELECTR NETWORK
DE random forest classification; GPU; FPGA
AB Random Forests (RFs) are a commonly used machine learning method for classification and regression tasks spanning a variety of application domains, including bioinformatics, business analytics, and software optimization. While prior work has focused primarily on improving performance of the training of RFs, many applications, such as malware identification, cancer prediction, and banking fraud detection, require fast RF classification.
   In this work, we accelerate RF classification on GPU and FPGA. In order to provide efficient support for large datasets, we propose a hierarchical memory layout suitable to the GPU/FPGA memory hierarchy. We design three RF classification code variants based on that layout, and we investigate GPU- and FPGA-specific considerations for these kernels. Our experimental evaluation, performed on an Nvidia Xp GPU and on a Xilinx Alveo U250 FPGA accelerator card using publicly available datasets on the scale of millions of samples and tens of features, covers various aspects. First, we evaluate the performance benefits of our hierarchical data structure over the standard compressed sparse row (CSR) format. Second, we compare our GPU implementation with cuML, a machine learning library targeting Nvidia GPUs. Third, we explore the performance/accuracy tradeoff resulting from the use of different tree depths in the RF. Finally, we perform a comparative performance analysis of our GPU and FPGA implementations. Our evaluation shows that, while reporting the best performance on GPU, our code variants outperform the CSR baseline both on GPU and FPGA. For high accuracy targets, our GPU implementation yields a 5-9x speedup over CSR, and up to a 2x speedup over Nvidia's cuML library.
C1 [Shah, Milan; Neff, Reece; Wu, Hancheng; Becchi, Michela] North Carolina State Univ, Raleigh, NC 27695 USA.
   [Minutoli, Marco; Tumeo, Antonino] Pacific Northwest Natl Lab, Richland, WA USA.
RP Shah, M (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.
EM mkshah5@ncsu.edu; rwneff@ncsu.edu; hwu16@ncsu.edu;
   marco.minutoli@pnnl.gov; Antonino.Tumeo@pnnl.gov; mbecchi@ncsu.edu
CR Baldi P, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5308
   Black Paul E, 2020, DADS ON LINE DICT AL
   Buluç A, 2009, SPAA'09: PROCEEDINGS OF THE TWENTY-FIRST ANNUAL SYMPOSIUM ON PARALLELISM IN ALGORITHMS AND ARCHITECTURES, P233
   Cheng C, 2013, I C FIELD PROG LOGIC
   Dheeru D., 2017, UCI MACHINE LEARNING
   Goldfarb M, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503223
   Hastie T., 2009, ELEMENTS STAT LEARNI, Vsecond
   Karras Tero, 2012, THINKING PARALLEL 2
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lin X, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P415, DOI 10.1145/3060403.3060416
   Marron Diego, 2014, P 21 EUR C ART INT
   Mei XX, 2017, IEEE T PARALL DISTR, V28, P72, DOI 10.1109/TPDS.2016.2549523
   Melikoglu O, 2019, Arxiv, DOI [arXiv:1912.01556, 10.48550/ARXIV.1912.01556, DOI 10.48550/ARXIV.1912.01556]
   Nakahara H, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P289, DOI 10.1109/FPT.2016.7929555
   Pavlyk Oleksandr, 2020, ACCELERATE YOUR SCIK
   Raschka S, 2020, Arxiv, DOI arXiv:2002.04803
   SINGH JP, 1995, J PARALLEL DISTR COM, V27, P118, DOI 10.1006/jpdc.1995.1077
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Wen ZY, 2020, J MACH LEARN RES, V21
   Wu HC, 2017, INT C PAR DISTRIB SY, P586, DOI 10.1109/ICPADS.2017.00082
NR 21
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3545008.3545067
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Huang, BH
   Gonzalez-Zacarias, C
   Guitron, SS
   Aslam, A
   Biedron, SG
   Brown, K
   Bolin, T
AF Huang, Bohong
   Gonzalez-Zacarias, Clio
   Guitron, Salvador Sosa
   Aslam, Aasma
   Biedron, Sandra G.
   Brown, Kevin
   Bolin, Trudy
TI Artificial Intelligence-Assisted Design and Virtual Diagnostic for the
   Initial Condition of a Storage-Ring-Based Quantum Information System
SO IEEE ACCESS
DT Article
DE Curve fitting; ion beams; lasers; machine learning; nonlinear equations;
   particle accelerators; phonons; quantum computing; storage rings
ID NEURAL-NETWORKS; ION; PHYSICS
AB Developments in Artificial Intelligence (AI) are helping to solve complex physical problems that otherwise may be too computationally demanding to solve using traditional approaches. Universal Approximation Theorems tell us that we can model any physical system if we can approximate the system with some continuous function (i.e., compact convergence topology and algorithmically generated sets of functions, such as the convolutional neural network), whether for an arbitrary depth or arbitrary width neural network. We consider the problem of solving a set of N coupled algebraic equations as N becomes very large and apply machine learning (ML) to solve this problem for any value of N. The physical problem we are focusing on is to model the equilibrium positions of ions in an ion trap. A storage ring quantum computer could contain well over tens of thousands of ions. Quickly determining the equilibrium positions will be important to minimize the time to target and observe each ion. As each ion serves as a single qubit, this is important for setting and measuring the individual qubit states. The phonon modes from a collection of ions acts as another qubit, useful for gate operations. Measuring the phonon modes, where ions are oscillating around their respective equilibrium positions also means understanding the equilibrium positions very well. Turning all of this into a virtual diagnostic allows real time prediction and comparison to ensure unique definition of each ion.
C1 [Huang, Bohong] SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
   [Gonzalez-Zacarias, Clio] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Guitron, Salvador Sosa; Aslam, Aasma; Biedron, Sandra G.; Bolin, Trudy] Univ New Mexico, Elect & Comp Engn Dept, Albuquerque, NM 87106 USA.
   [Biedron, Sandra G.] Univ New Mexico, Mech Engn Dept, Albuquerque, NM 87106 USA.
   [Biedron, Sandra G.; Bolin, Trudy] Element Aero, Chicago, IL 60643 USA.
   [Brown, Kevin] SUNY Stony Brook, Dept Elect & Comp Engn, Stony Brook, NY 11794 USA.
   [Brown, Kevin] Brookhaven Natl Lab, Collider Accelerator Dept, Upton, NY 11973 USA.
RP Huang, BH (corresponding author), SUNY Stony Brook, Dept Appl Math & Stat, Stony Brook, NY 11794 USA.
EM bohong.huang@stonybrook.edu
CR [Anonymous], 2018, NATL STRATEGIC OVERV
   [Anonymous], 2000, QUANTUM COMPUTATION
   [Anonymous], 1994, PRINCIPLES QUANTUM M
   [Anonymous], 2005, NEURAL NETWORKS METH, DOI DOI 10.1007/3-540-28847-3
   Bar-Sinai Y, 2019, P NATL ACAD SCI USA, V116, P15344, DOI 10.1073/pnas.1814058116
   Biedron S. G., 2019, P 10 INT PART ACC C, P1
   Biedron S. G., 2018, P 12 INT WORKSH PERS, P1
   Bollinger J., 1991, LASER COOLING TRAPPE
   Brown KA, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.054701
   BROWN LS, 1986, REV MOD PHYS, V58, P233, DOI 10.1103/RevModPhys.58.233
   Dirac P. A. M, 1981, PRINCIPLES QUANTUM M, V27
   Drewsen M, 2015, PHYSICA B, V460, P105, DOI 10.1016/j.physb.2014.11.050
   Edelen A., 2018, ARXIV181103172
   Edelen AL, 2016, IEEE T NUCL SCI, V63, P878, DOI 10.1109/TNS.2016.2543203
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Foot C. J., 2007, ATOMIC PHYS
   Grif ~ths D. J., 2004, INTRO QUANTUM MECH, V2nd
   Gyongyosi L, 2019, COMPUT SCI REV, V31, P51, DOI 10.1016/j.cosrev.2018.11.002
   Hanuka A, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-021-82473-0
   James DFV, 1998, APPL PHYS B-LASERS O, V66, P181, DOI 10.1007/s003400050373
   King DB, 2015, ACS SYM SER, V1214, P1
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Marquet C, 2003, APPL PHYS B-LASERS O, V76, P199, DOI 10.1007/s00340-003-1097-7
   More J. J., 1980, FORTRAN, DOI DOI 10.2172/6997568, Patent No. CMP00068642
   Newville M., 2014, ZENODO
   Paszke A, 2019, ADV NEUR IN, V32
   PAUL W, 1990, REV MOD PHYS, V62, P531, DOI 10.1103/RevModPhys.62.531
   RAFAC R, 1991, P NATL ACAD SCI USA, V88, P483, DOI 10.1073/pnas.88.2.483
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   SCHIFFER JP, 1993, PHYS REV LETT, V70, P818, DOI 10.1103/PhysRevLett.70.818
   Schramm U, 2002, PLASMA PHYS CONTR F, V44, pB375, DOI 10.1088/0741-3335/44/12B/326
   Sessler A. M., 1996, LBL38278, V7, P93
   Steane A, 1997, APPL PHYS B-LASERS O, V64, P623, DOI 10.1007/s003400050225
   Stevens R., 2020, REPORT DEP ENERGY DO
   Tennant C, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.114601
NR 36
TC 1
Z9 1
U1 1
U2 5
PY 2022
VL 10
BP 14350
EP 14358
DI 10.1109/ACCESS.2022.3147727
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Hsia, SC
   Wang, SH
   Yeh, JY
   Chang, CY
AF Hsia, Shih-Chang
   Wang, Szu-Hong
   Yeh, Jen-Yu
   Chang, Chuan-Yu
TI A Smart Leaf Blow Robot Based on Deep Learning Model
SO IEEE ACCESS
DT Article
DE Leaf recognition; robot; blow machine; recognition; convolutional neural
   networks (CNNs)
ID RECOGNITION; CIRCUIT; MEMORY
AB Although leaves are everywhere in the world, and they also play a vital role in our daily life, they tend to fall all over the ground in due course, thereby making it difficult for pedestrians and vehicles to move. In this paper, an automatic leaf blower was designed and based on the concept of convolutional neural network(CNN). This system can automatically collect leaves into a garbage bag. A four-wheel driving robot was implemented to drive a blow machine. The control sensors of this robot mainly include a camera, ultrasound, the electronic compass and acceleration. Besides, an ultra-wide band located module was used to obtain the position of the current robot during the working process. Also, the computer vision was employed to recognize whether the leaves are on the ground. For this, ResNet50 deep CNN was used as the training model to recognize the fallen leaves. Since there are many kinds of trees, their leaves are different shape. We collected the images of these leaves as dataset for training, and the recognition rate achieved 92.5%. The obtained result was sent to the controller to control the moving direction of the robot. For the real-time operation, the embedded system was used to sense the leaf data to decide the movement made by the machine based on a control algorithm. The CNN model was implemented with an accelerator on the embedded system for the real-time purpose, which the recognition speed can achieve 20 frames per second form the camera. The automatic leaf blow machine can be possibly used in an effective way instead of human power.
C1 [Hsia, Shih-Chang; Wang, Szu-Hong; Yeh, Jen-Yu; Chang, Chuan-Yu] Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu 64002, Yunlin, Taiwan.
RP Hsia, SC (corresponding author), Natl Yunlin Univ Sci & Technol, Dept Elect Engn, Touliu 64002, Yunlin, Taiwan.
EM hsia@yuntech.edu.tw
CR alldatasheet, US
   decawave.com, UWB MANUAL
   Gargade A, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P267, DOI [10.1109/iccmc.2019.8819867, 10.1109/ICCMC.2019.8819867]
   Ghosh P, 2020, IEEE T MOBILE COMPUT, V19, P1260, DOI 10.1109/TMC.2019.2909020
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hsia S.-C., 2020, IEEE ACCESS, V8
   Hu RX, 2012, IEEE T IMAGE PROCESS, V21, P4667, DOI 10.1109/TIP.2012.2207391
   itdaan.com, US
   Jiang HX, 2020, IEEE ACCESS, V8, P68828, DOI 10.1109/ACCESS.2020.2986946
   Kim J, 2016, IEEE T IND ELECTRON, V63, P3616, DOI 10.1109/TIE.2016.2523460
   leafsnap.com, LEAFSNAP DATASET
   Lim J, 2015, INT CONF ELECTRO INF, P621, DOI 10.1109/EIT.2015.7293407
   Codizar AL, 2016, INT CONF INFORM INTE
   makita.com, ELECT BLOW MACHINE D
   Suchitra S, 2020, 2020 5 INT C COMM EL, P979, DOI [10.1109/ICCES48766.2020.9137986, DOI 10.1109/ICCES48766.2020.9137986]
   Sun JW, 2021, IEEE T BIOMED CIRC S, V15, P606, DOI 10.1109/TBCAS.2021.3090786
   youtu.be, US
   Zhang LK, 2018, 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION TECHNOLOGY ROBOTICS (ICT-ROBOT)
   Zhang YT, 2021, IEEE T BIOMED CIRC S, V15, P978, DOI 10.1109/TBCAS.2021.3108354
   Zhao YF, 2022, IEEE ACM T COMPUT BI, V19, P1817, DOI 10.1109/TCBB.2021.3056683
NR 20
TC 0
Z9 0
U1 1
U2 1
PY 2023
VL 11
BP 111956
EP 111962
DI 10.1109/ACCESS.2023.3307136
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Yantir, HE
   Eltawil, AM
   Kurdahi, FJ
AF Yantir, Hasan Erdem
   Eltawil, Ahmed M.
   Kurdahi, Fadi J.
TI Hybrid Approximate Computing Approach for Associative In-Memory
   Processors
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Meroristor; in-memory computing; resistive associative processor (RAP);
   approximate computing; memristance scaling; approximate computing;
   approximate storage; architecture
AB The complexity of the computational problems is rising faster than the computational platforms' capabilities which are also becoming increasingly costly to operate due to their increased need for energy. This forces researchers to find alternative paradigms and methods for efficient computing. One promising paradigm is accelerating compute-intensive kernels using in-memory computing accelerators, where data movements are significantly reduced. Another increasingly popular method for improving energy efficiency is approximate computing. In this paper, we propose a methodology for efficient approximate in-memory computing. To maximize energy savings for a given approximation constraints, a hybrid approach is presented combining both voltage and precision scaling. This can be applied to an associative memory-based architecture that can be implemented today using CMOS memories (SRAM) but can be seamlessly scaled to emerging ReRAM-based memory technology later with minimal effort. For the evaluation of the proposed methodology, a diverse set of domains is covered, such as image processing, machine learning, machine vision, and digital signal processing. When compared to full-precision, unsealed implementations, average energy savings of 5.17x and 59.11x, and speedups of 2.1x and 3.24x in SRAM-based and ReRAM-based architectures, respectively, are reported.
C1 [Yantir, Hasan Erdem; Eltawil, Ahmed M.; Kurdahi, Fadi J.] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
RP Yantir, HE (corresponding author), Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
EM hyantir@uci.edu; aeltawil@uci.edu; kurdahi@uci.edu
CR Agrawal A., 2016, P IEEE INT C REB COM, P1, DOI DOI 10.1109/ICRC.2016.7738674
   [Anonymous], CISC VIS NETW IND GL
   [Anonymous], 1968, 3X3 ISOTROPIC GRADIE
   [Anonymous], 2011, P DATE
   [Anonymous], 1991, ASS COMPUTING PROGRA
   [Anonymous], ACM COMPUT SURV
   [Anonymous], TECH REP
   [Anonymous], 4M 512 K 8 BIT SPI M
   [Anonymous], 1T1R PROD PIC EMB RE
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Borkar S, 2013, INT PARALL DISTRIB P, P3, DOI 10.1109/IPDPS.2013.121
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Esmaeilzadeh H, 2012, INT SYMP MICROARCH, P449, DOI 10.1109/MICRO.2012.48
   Foster C. C., 1976, CONTENT ADDRESSABLE
   Imani M, 2018, IEEE T MULTI-SCALE C, V4, P17, DOI 10.1109/TMSCS.2017.2665462
   Imani M, 2019, IEEE T EMERG TOP COM, V7, P271, DOI 10.1109/TETC.2016.2642057
   Imani M, 2016, DES AUT TEST EUROPE, P1327
   Karpuzcu U.R., 2012, DEPENDABLE SYSTEMS N, P1
   Karpuzcu UR, 2013, IEEE MICRO, V33, P6, DOI 10.1109/MM.2013.71
   Kim KM, 2016, SCI REP-UK, V6, DOI 10.1038/srep20085
   Kim Y, 2017, ICCAD-IEEE ACM INT, P25, DOI 10.1109/ICCAD.2017.8203756
   Li J, 2014, IEEE J SOLID-ST CIRC, V49, P896, DOI 10.1109/JSSC.2013.2292055
   Miao F, 2011, ADV MATER, V23, P5633, DOI 10.1002/adma.201103379
   Misailovic S., 2010, P 32 ACMIEEE INT C S, V1, P25, DOI DOI 10.1145/1806799.1806808
   Pinckney Nathaniel, 2013, 2013 Symposium on VLSI Circuits, pC290
   Rahimi A, 2015, DES AUT TEST EUROPE, P1497
   Roy K, 2013, IEEE INT SYMP DESIGN, P5, DOI 10.1109/DDECS.2013.6549776
   SCHERSON ID, 1989, J PARALLEL DISTR COM, V6, P69, DOI 10.1016/0743-7315(89)90043-9
   Schinkel D., 2007, IEEE INT SOLID STATE, P314, DOI DOI 10.1109/ISSCC.2007.373420
   Sidiroglou-Douskos S., 2011, 19 ACM SIGSOFT, P124, DOI DOI 10.1145/2025113.2025133
   Sinha S, 2012, DES AUT CON, P283
   Taha MMA, 2016, IEEE INT SYMP NANO, P159
   Venkataramani S, 2012, DES AUT CON, P796
   Yakopcic C, 2013, IEEE T COMPUT AID D, V32, P1201, DOI 10.1109/TCAD.2013.2252057
   Yantir HE, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126526
   Yantir HE, 2016, PR IEEE COMP DESIGN, P49, DOI 10.1109/ICCD.2016.7753260
   Yavits L, 2015, IEEE COMPUT ARCHIT L, V14, P148, DOI 10.1109/LCA.2014.2374597
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
   Yazdanbakhsh A, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P482, DOI 10.1145/2830772.2830810
   Yazdanbakhsh A, 2015, DES AUT TEST EUROPE, P812
   Zhao HY, 2017, ICCAD-IEEE ACM INT, P268, DOI 10.1109/ICCAD.2017.8203788
NR 41
TC 17
Z9 18
U1 0
U2 6
PD DEC
PY 2018
VL 8
IS 4
BP 758
EP 769
DI 10.1109/JETCAS.2018.2852701
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Turkkan, G
   Bilici, N
   Sertel, H
   Keskus, Y
   Alkaya, S
   Tavli, B
   Ozkirim, M
   Fayda, M
AF Turkkan, Gorkem
   Bilici, Nazli
   Sertel, Huseyin
   Keskus, Yavuz
   Alkaya, Sercan
   Tavli, Busra
   Ozkirim, Muge
   Fayda, Merdan
TI Clinical utility of a 1.5 T magnetic resonance imaging-guided linear
   accelerator during conventionally fractionated and hypofractionated
   prostate cancer radiotherapy
SO FRONTIERS IN ONCOLOGY
DT Article
DE adaptive radiotherapy; fractionated radiotherapy; MRI-guided
   radiotherapy; MRI-LINAC; prostate cancer
AB PurposeTo report our initial experience with 1.5 T magnetic resonance imaging (MRI) linear accelerator (LINAC) in prostate cancer radiotherapy in terms of its use in a radiation oncology clinic. MethodsThe medical records of 14 prostate cancer patients treated with MRI-guided radiotherapy were retrospectively evaluated. The fraction time, adapt-to-position (ATP):adapt-to-shape (ATS) usage rate, machine-associated treatment interruption rate, median gamma pass rate, the percentage of planning target volume receiving at least 95% of the prescription dose coverage value of each ATS fraction, the effect of the learning curve on the fraction time and radiation-related acute gastrointestinal and genitourinary toxicities were evaluated. ResultsFourteen patients have completed their treatment receiving a total of 375 fractions. Six patients (42%) were treated with the moderately hypofractionated regimen, five patients (36%) with conventionally fractionated, and three patients (22%) with the ultra-hypofractionated radiotherapy regimens. The ATP : ATS usage ratio was 3:372. The median fraction time was 46 min (range, 24-81 min). For the 3%/3 mm criterion, median gamma pass rate was 99.4% (range, 94.6-100%). Machine-related treatment interruptions were observed in 11 (2.9%) of 375 fractions, but this interruption rate decreased from 4.1% to 0.8%, after an upgrade. Three patients (22%) had gastrointestinal and five patients (36%) had genitourinary toxicity. No >= grade 3 toxicity was observed. Conclusion1.5 T MRI-LINAC device could be used as a conventional LINAC device, when the conditions of the radiotherapy center are appropriate. MRI-guided prostate radiotherapy is safe and feasible, and high-quality studies with a larger number of patients and long-term results are needed to better evaluate this new technology.
C1 [Turkkan, Gorkem; Fayda, Merdan] Istinye Univ, Fac Med, Dept Radiat Oncol, Istanbul, Turkey.
   [Turkkan, Gorkem; Bilici, Nazli; Sertel, Huseyin; Keskus, Yavuz; Alkaya, Sercan; Tavli, Busra; Ozkirim, Muge; Fayda, Merdan] Liv Hosp Ulus, Dept Radiat Oncol, Istanbul, Turkey.
RP Turkkan, G (corresponding author), Istinye Univ, Fac Med, Dept Radiat Oncol, Istanbul, Turkey.; Turkkan, G (corresponding author), Liv Hosp Ulus, Dept Radiat Oncol, Istanbul, Turkey.
EM gorkemturkkan@gmail.com
CR Alongi F, 2020, RADIAT ONCOL, V15, DOI 10.1186/s13014-020-01510-w
   Bertelsen AS, 2019, ACTA ONCOL, V58, P1352, DOI 10.1080/0284186X.2019.1627417
   Brand DH, 2019, LANCET ONCOL, V20, P1531, DOI 10.1016/S1470-2045(19)30569-8
   de Leon J, 2022, J MED IMAG RADIAT ON, V66, P138, DOI 10.1111/1754-9485.13336
   Felisi M, 2021, TUMORI J, V107, pNP41, DOI 10.1177/0300891621997549
   Keizer DMD, 2020, RADIOTHER ONCOL, V151, P88, DOI 10.1016/j.radonc.2020.06.044
   Kontaxis C, 2017, MED PHYS, V44, P5034, DOI 10.1002/mp.12467
   Mahmood F, 2017, PHYS MED BIOL, V62, P2990, DOI 10.1088/1361-6560/aa5249
   Marks LB, 2010, INT J RADIAT ONCOL, V76, pS10, DOI 10.1016/j.ijrobp.2009.07.1754
   Mönnich D, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba5ec
   Murray J, 2019, CLIN TRANSL RAD ONCO, V18, P68, DOI 10.1016/j.ctro.2019.03.006
   Pathmanathan AU, 2018, INT J RADIAT ONCOL, V100, P361, DOI 10.1016/j.ijrobp.2017.10.020
   Siegel RL, 2017, CA-CANCER J CLIN, V67, P7, DOI [10.3322/caac.21387, 10.3322/caac.20006, 10.3322/caac.21601, 10.3322/caac.20073, 10.3322/caac.21332, 10.3322/caac.21254]
   Winkel D, 2019, CLIN TRANSL RAD ONCO, V18, P54, DOI 10.1016/j.ctro.2019.04.001
   Yang B, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abfa80
NR 15
TC 1
Z9 1
U1 0
U2 1
PD AUG 16
PY 2022
VL 12
AR 909402
DI 10.3389/fonc.2022.909402
WC Oncology
DA 2023-11-11
ER

PT C
AU Andriyanov, NA
AF Andriyanov, N. A.
GP IEEE
TI Analysis of the Acceleration of Neural Networks Inference on Intel
   Processors Based on OpenVINO Toolkit
SO 2020 SYSTEMS OF SIGNAL SYNCHRONIZATION, GENERATING AND PROCESSING IN
   TELECOMMUNICATIONS (SYNCHROINFO)
DT Proceedings Paper
CT Conference on Systems of Signal Synchronization, Generating and
   Processing in Telecommunications (SYNCHROINFO)
CY JUL 01-03, 2020
CL Svetlogorsk, RUSSIA
DE object detection; pattern recognition; neural networks; machine
   learning; neural network inference; CPU; Intel; OpenVINO; Toolkit;
   SSD_MobileNet; COCO dataset
AB The article studies the performance of a trained neural network SSD_MobileNet_V2_COCO. It is proposed to use the OpenVINO Toolkit to increase network performance. Performance evaluation is calculated by the reciprocal of the frame processing time, which characterizes the number of frames processed per second. Dataset COCO ( by Microsoft) was used as the source dataset. In this case, 200 images were selected from this dataset, and during processing all images were reduced to the same sizes 300x300. Studies shown that the use of OpenVINO has increased the performance of the neural network SSD_MobileNet_V2_COCO by 130 times on average. At the same time, in contrast to starting a network using TensorFlow only, the variance of network performance using OpenVINO is significantly increased. However, the use of such an accelerator remains appropriate on Intel processors.
C1 [Andriyanov, N. A.] JSC RPC Istok, Fryazino, Russia.
   [Andriyanov, N. A.] Ulyanovsk State Tech Univ, Ulyanovsk, Russia.
RP Andriyanov, NA (corresponding author), JSC RPC Istok, Fryazino, Russia.; Andriyanov, NA (corresponding author), Ulyanovsk State Tech Univ, Ulyanovsk, Russia.
EM nikita-and-nov@mail.ru
CR Albawi S, 2017, I C ENG TECHNOL
   Almakady Y, 2020, COMPUT VIS IMAGE UND, V194, DOI 10.1016/j.cviu.2020.102931
   Andriyanov N. A., 2018, Journal of Physics: Conference Series, V1096, DOI 10.1088/1742-6596/1096/1/012036
   Andriyanov N.A., 2018, CEUR WORKSHOP PROC, V2210, P219
   [Anonymous], E RESOURSE
   Song G, 2020, COMPUT VIS IMAGE UND, V193, DOI 10.1016/j.cviu.2020.102916
   Vasilev K. K., 2020, INTELL SYST REF LIB, V175, P11, DOI [10.1007/978-3-030-33795-7_2, DOI 10.1007/978-3-030-33795-7_2]
   Vasiliev K, 2018, PROCEDIA COMPUT SCI, V126, P49, DOI 10.1016/j.procs.2018.07.208
   Wu Q, 2017, CHIN AUTOM CONGR, P6522, DOI 10.1109/CAC.2017.8243952
   Zheltov S.Yu., 2020, IMAGE PROCESSING ANA
NR 10
TC 15
Z9 15
U1 0
U2 0
PY 2020
DI 10.1109/synchroinfo49631.2020.9166067
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Luo, YY
   Wang, XY
   Ogrenci-Memik, S
   Memik, G
   Yoshii, K
   Beckman, P
AF Luo, Yingyi
   Wang, Xiaoyang
   Ogrenci-Memik, Seda
   Memik, Gokhan
   Yoshii, Kazutomo
   Beckman, Pete
GP IEEE
TI Minimizing Thermal Variation in Heterogeneous HPC Systems with FPGA
   Nodes
SO 2018 IEEE 36TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD)
SE Proceedings IEEE International Conference on Computer Design
DT Proceedings Paper
CT 36th IEEE International Conference on Computer Design (ICCD)
CY OCT 07-10, 2018
CL Orlando, FL
AB The presence of FPGAs in data centers has been growing due to their superior performance as accelerators. Thermal management, particularly battling the cooling cost in these high performance systems, is a primary concern. Introduction of new heterogeneous components only adds further complexities to thermal modeling and management. The thermal behavior of multi-FPGA systems deployed within large compute clusters is little explored. In this paper, we first show that the thermal behaviors of different FPGAs of the same generation can vary due to their physical locations in a rack and process variation, even though they are running the same tasks. We present a machine learning based model to capture the thermal behavior of a multi-node FPGA cluster. We then propose to mitigate thermal variation and hotspots across the cluster by proactive task placement guided by our thermal model. Our experiments show that through proper placement of tasks on the multi-FPGA system, we can reduce the peak temperature by up to 11.50 degrees C with no impact on performance.
C1 [Luo, Yingyi; Wang, Xiaoyang; Ogrenci-Memik, Seda; Memik, Gokhan] Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
   [Yoshii, Kazutomo; Beckman, Pete] Argonne Natl Lab, Math & Comp Sci Div, Argonne, IL 60439 USA.
RP Luo, YY (corresponding author), Northwestern Univ, Dept Elect Engn & Comp Sci, Evanston, IL 60208 USA.
EM yingyi@u.northwestern.edu; xiaoyangwang2018@u.northwestern.edu;
   seda@eecs.northwestern.edu; memik@eecs.northwestern.edu;
   kazutomo@mcs.anl.gov; beckman@anl.gov
CR [Anonymous], 2006, TECH REP
   Augonnet C, 2011, CONCURR COMP-PRACT E, V23, P187, DOI 10.1002/cpe.1631
   Bauer Michael, 2012, P INT C HIGH PERFORM, P66
   Caulfield AM, 2016, INT SYMP MICROARCH
   Coskun AK, 2007, DES AUT TEST EUROPE, P1659
   Dai Jun, 2014, OPTIMUM COOLING DATA, P1
   Diamos Gregory F., 2008, P 17 INT S HIGH PERF, P197, DOI DOI 10.1145/1383422.1383447
   Ebrahimi K, 2014, RENEW SUST ENERG REV, V31, P622, DOI 10.1016/j.rser.2013.12.007
   I. Corp, 2017, INT FPGA SDK OPENCL
   Jing C, 2013, MICROPROCESS MICROSY, V37, P590, DOI 10.1016/j.micpro.2013.05.001
   Kleinberg EM, 1996, ANN STAT, V24, P2319
   Kleinberg EM, 2000, IEEE T PATTERN ANAL, V22, P473, DOI 10.1109/34.857004
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Lian Tuu Yeh R. C. C., 2002, THERMAL MANAGEMENT M
   Mambretti J, 2015, 2015 INTERNATIONAL CONFERENCE ON CLOUD COMPUTING RESEARCH AND INNOVATION (ICCCRI), P73, DOI 10.1109/ICCCRI.2015.10
   Mangalagiri Prasanth, 2008, 2008 IEEE/ACM International Conference on Computer-Aided Design (ICCAD), P722, DOI 10.1109/ICCAD.2008.4681656
   Murali S., 2007, 2007 5th IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P111
   Ogrenci-Memik S., 2016, MAT CIRCUITS DEVICES
   Pelley S., 2009, P WORKSH EN EFF DES
   Smoyer J.L., 2018, HEAT TRANSFER ENG, V0, P1
   Spitaels J., 2005, DYNAMIC POWER VARIAT, V5
   Tang QH, 2008, IEEE T PARALL DISTR, V19, P1458, DOI 10.1109/TPDS.2008.111
   Topcuoglu H, 2002, IEEE T PARALL DISTR, V13, P260, DOI 10.1109/71.993206
   Zhang K., 2017, IEEE T PARALLEL DIST
   Zhang KC, 2015, INT PARALL DISTRIB P, P1139, DOI 10.1109/IPDPS.2015.37
NR 25
TC 3
Z9 3
U1 0
U2 1
PY 2018
BP 537
EP 544
DI 10.1109/ICCD.2018.00086
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Choi, WH
   Chiu, PF
   Ma, W
   Hemink, G
   Hoang, TT
   Lueker-Boden, M
   Bandic, Z
AF Choi, Won Ho
   Chiu, Pi-Feng
   Ma, Wen
   Hemink, Gertjan
   Tung Thanh Hoang
   Lueker-Boden, Martin
   Bandic, Zvonimir
GP IEEE
TI An In-flash Binary Neural Network Accelerator with SLC NAND Flash Array
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY OCT 10-21, 2020
CL ELECTR NETWORK
DE NAND Flash; Binarized Neural Network (BNN); In-Memory Computing; Machine
   Learning
AB An SLC NAND array based in-flash computing core is proposed for enabling vector-matrix multiplications in binarized neural network (BNN) and binary weight network (BWN). Two SLC NAND floating gate (FG) cells in the same string store complementary data to encode binarized weight value of a single synapse for realizing the BNN algorithm. By activating multiple BLs and WLs across block and/or plane levels, the performance of vector-matrix multiplications is significantly accelerated.
   The system architecture using in-flash computing core for BNN/BWN acceleration is introduced. A wide range of BNN/BWN models can be efficiently mapped to a scalable array of in-flash computing core. An in-flash computing core is able to achieve an estimated peak energy efficiency of 2.56 TOP/s/W for BNN, 292.6 GOP/s/W for 8-b input based BWN by customizing the numbers of word-lines (WLs)/BLs/blocks/planes.
C1 [Choi, Won Ho; Chiu, Pi-Feng; Ma, Wen; Hemink, Gertjan; Tung Thanh Hoang; Lueker-Boden, Martin; Bandic, Zvonimir] Western Digital Res, Milpitas, CA 95035 USA.
RP Choi, WH (corresponding author), Western Digital Res, Milpitas, CA 95035 USA.
CR [Anonymous], 2019, NVIDIA T4 TENSOR COR
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cheong W, 2018, ISSCC DIG TECH PAP I, P338, DOI 10.1109/ISSCC.2018.8310322
   Chiu PF, 2019, IEEE INT SYMP CIRC S
   Gonugondla SK, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351458
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Mohan V, 2013, IEEE T COMPUT AID D, V32, P1031, DOI 10.1109/TCAD.2013.2249557
   Rastegari Mohammad, 2018, ARXIV160305279V4
   Wang PN, 2019, IEEE T VLSI SYST, V27, P988, DOI 10.1109/TVLSI.2018.2882194
NR 10
TC 7
Z9 8
U1 1
U2 1
PY 2020
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Rasoori, S
   Akella, V
AF Rasoori, Sandeep
   Akella, Venkatesh
GP ACM
TI Scalable Hardware Accelerator for Mini-Batch Gradient Descent
SO PROCEEDINGS OF THE 2018 GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI'18)
SE Proceedings - Great Lakes Symposium on VLSI
DT Proceedings Paper
CT Great Lakes Symposium on VLSI (GLSVLSI)
CY MAY 23-25, 2018
CL Chicago, IL
DE Stochastic Gradient Descent; Mini-Batch Gradient Descent; Machine
   Learning; FPGA; CPU; Embedded Memories; Caches
AB Iterative first-order methods that use gradient information form the core computation kernels of modern statistical data analytic engines, such as MADLib, Impala, Google Brain, GraphLab, MLlib in Spark, among others. Even the most advanced parallel stochastic gradient descent algorithm, such as Hogwild is not very scalable on conventional chip multiprocessors because of the bottlenecks induced by the memory system when sharing large model vectors. We propose a scalable architecture for large scale parallel gradient descent on a Field Programmable Gate Array (FPGA) by taking advantage of the large amount of embedded memory in modern FPGAs. We propose a novel data layout mechanism that eliminates the need for expensive synchronization and locking of shared data, which makes the architecture scalable. A 32-PE system on the Stratix V FPGA shows about 5x improvement in performance compared to state-of-the-art implementation on a 14 core/28 thread Intel Xeon CPU with 64 GB memory and operating at 2.6 GHz.
C1 [Rasoori, Sandeep; Akella, Venkatesh] Univ Calif Davis, Elect & Comp Engn Dept, Davis, CA 95616 USA.
RP Rasoori, S (corresponding author), Univ Calif Davis, Elect & Comp Engn Dept, Davis, CA 95616 USA.
EM srasoori@ucdavis.edu; akella@ucdavis.edu
CR [Anonymous], 2015, ACCELERATING DEEP CO
   [Anonymous], 2015, 32 ICML
   [Anonymous], 1985, CALIFORNIA U SAN DIE, DOI DOI 10.21236/ADA164453
   [Anonymous], 2017, ARXIV170103534
   Bottou L, 2010, COMPSTAT'2010: 19TH INTERNATIONAL CONFERENCE ON COMPUTATIONAL STATISTICS, P177, DOI 10.1007/978-3-7908-2604-3_16
   Choi YJ, 2016, BIOMED RES INT, V2016, DOI 10.1155/2016/3286191
   Li HY, 2016, STEM CELLS INT, V2016, DOI 10.1155/2016/6786184
   Li M, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P661, DOI 10.1145/2623330.2623612
   Mutnury B., 2010, 2010 IEEE 19th Conference on Electrical Performance of Electronic Packaging and Systems (EPEPS 2010), P265, DOI 10.1109/EPEPS.2010.5642789
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Recht B., 2011, ADV NEURAL INFORM PR, V24
   Sallinen S, 2016, INT PARALL DISTRIB P, P873, DOI 10.1109/IPDPS.2016.107
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang C, 2014, PROC VLDB ENDOW, V7, P1283, DOI 10.14778/2732977.2733001
   Zhang C, 2016, IEEE SYM PARA DISTR, P148, DOI 10.1109/IPDPSW.2016.117
   Zhang H., 2016, HOGWILD NEW MECH DEC
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Ziakas Dimitrios, 2010, HIGH PERF INT HOTI 2, P1
NR 23
TC 1
Z9 1
U1 0
U2 1
PY 2018
BP 159
EP 164
DI 10.1145/3194554.3194559
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sun, Z
   Pedretti, G
   Ielmini, D
AF Sun, Zhong
   Pedretti, Giacomo
   Ielmini, Daniele
GP IEEE
TI Fast solution of linear systems with analog resistive switching memory
   (RRAM)
SO PROCEEDINGS OF THE 2019 FOURTH IEEE INTERNATIONAL CONFERENCE ON
   REBOOTING COMPUTING (ICRC)
DT Proceedings Paper
CT 4th IEEE International Conference on Rebooting Computing (ICRC)
CY NOV 06-08, 2019
CL San Mateo, CA
DE in-memory computing; linear system; resistive memory; time complexity
AB The in-memory solution of linear systems with analog resistive switching memory in one computational step has been recently reported. In this work, we investigate the time complexity of solving linear systems with the circuit, based on the feedback theory of amplifiers. The result shows that the computing time is explicitly independent on the problem size N, rather it is dominated by the minimal eigenvalue of an associated matrix. By addressing the Toeplitz matrix and the Wishart matrix, we show that the computing time increases with log(N) or N-1/2, respectively, thus indicating a significant speed-up of in-memory computing over classical digital computing for solving linear systems. For sparse positive-definite matrix that is targeted by a quantum computing algorithm, the in-memory computing circuit also shows a computing time superiority. These results support in-memory computing as a strong candidate for fast and energy-efficient accelerators of big data analytics and machine learning.
C1 [Sun, Zhong; Pedretti, Giacomo; Ielmini, Daniele] Politecn Milan, DEIB, Milan, Italy.
   [Sun, Zhong; Pedretti, Giacomo; Ielmini, Daniele] IU NET, Milan, Italy.
RP Sun, Z (corresponding author), Politecn Milan, DEIB, Milan, Italy.; Sun, Z (corresponding author), IU NET, Milan, Italy.
EM zhong.sun@polimi.it; giacomo.pedretti@polimi.it;
   daniele.ielmini@polimi.it
CR Bhatia R, 2007, PRINC SER APPL MATH, P1
   Golub G.H., 2013, MATRIX COMPUTATIONS, V4th ed., DOI DOI 10.56021/9781421407944
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Press W., 1986, NUMERICAL RECIPES AR, DOI DOI 10.2277/052143064X
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Razavi B, 2001, DESIGN ANALOG CMOS I
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shewchuk JR., 1994, INTRO CONJUGATE GRAD
   SILVERSTEIN JW, 1985, ANN PROBAB, V13, P1364, DOI 10.1214/aop/1176992819
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
NR 15
TC 1
Z9 1
U1 0
U2 3
PY 2019
BP 120
EP 124
DI 10.1109/icrc.2019.8914709
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Abdelouahab, K
   Pelcat, M
   Berry, F
AF Abdelouahab, Kamel
   Pelcat, Maxime
   Berry, Francois
GP ACM
TI PhD Forum: Why TanH is a Hardware Friendly Activation Function for CNNs
SO 11TH INTERNATIONAL CONFERENCE ON DISTRIBUTED SMART CAMERAS (ICDSC 2017)
DT Proceedings Paper
CT 11th International Conference on Distributed Smart Cameras (ICDSC)
CY SEP 05-07, 2017
CL Stanford Univ, Palo Alto, CA
HO Stanford Univ
AB Convolutional Neural Networks (CNNs) [1] are the state of the art of image classification that improved accuracy and robustness of machine vision systems at the price of a very high computational cost. This motivated multiple research efforts to investigate the applicability of approximate computing and more particularly, fixed point-arithmetic for CNNs. In all this approaches, a recurrent problem is that the learned parameters in deep fraCNN layers have a significantly lower numerical dynamic range when compared to the feature maps, which prevents from using of a low bit-width representation in deep layers. In this paper, we demonstrate that using the TanH activation function is way to prevent this issue. To support this demonstration, three benchmark CNN models are trained with the TanH function. These models are then quantized using the same bit-width across all the layers. In the case of FPGA based accelerators, this approach infers the minimal amount of logic elements to deploy CNNs.
C1 [Abdelouahab, Kamel; Berry, Francois] Inst Pascal, Clermont Ferrand, France.
   [Pelcat, Maxime] IETR, Rennes, France.
RP Abdelouahab, K (corresponding author), Inst Pascal, Clermont Ferrand, France.
CR Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Courbariaux Matthieu., 2014, TRAINING DEEP NEURAL
   DARRYLDLIN Darryl D Lin, FIXED POINT QUANTIZA
   David JP, 2007, IEEE T COMPUT, V56, P1308, DOI 10.1109/TC.2007.1084.
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Yuval N., 2011, NIPS WORKSH DEEP LEA
NR 14
TC 7
Z9 8
U1 0
U2 2
PY 2017
BP 199
EP 201
DI 10.1145/3131885.3131937
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic; Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT J
AU Giraldo, JSP
   Lauwereins, S
   Badami, K
   Verhelst, M
AF Giraldo, Juan Sebastian P.
   Lauwereins, Steven
   Badami, Komail
   Verhelst, Marian
TI Vocell: A 65-nm Speech-Triggered Wake-Up SoC for 10-μW Keyword Spotting
   and Speaker Verification
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Keyword spotting (KWS); machine learning (ML) hardware; speaker
   verification (SV); speech recognition
ID RECOGNITION
AB The use of speech-triggered wake-up interfaces has grown significantly in the last few years for use in ubiquitous and mobile devices. Since these interfaces must always be active, power consumption is one of their primary design metrics. This article presents a complete mixed-signal system-on-chip, capable of directly interfacing to an analog microphone and performing keyword spotting (KWS) and speaker verification (SV), without any need for further external accesses. Through the use of: 1) an integrated single-chip digital-friendly design; b) hardware-aware algorithmic optimization; and c) memory- and power-optimized accelerators, ultra-low power is achieved while maintaining high accuracy for speech recognition tasks. The 65-nm implementation achieves 18.3- $\mu \text{W}$ worst case power consumption or 10.6- $\mu \text{W}$ power for typical real-time scenarios, $10\times $ below state of the art (SoA).
C1 [Giraldo, Juan Sebastian P.; Verhelst, Marian] KU Leuven ICTS, Dept Elect Engn, B-3001 Heverlee, Belgium.
   [Lauwereins, Steven] Televic Rail, B-8870 Izegem, Belgium.
   [Badami, Komail] CSEM Zurich, CH-8005 Zurich, Switzerland.
RP Giraldo, JSP (corresponding author), KU Leuven ICTS, Dept Elect Engn, B-3001 Heverlee, Belgium.
EM giraldo@esat.kuleuven.be
CR [Anonymous], P IEEE TRENDS SPEECH
   [Anonymous], 2007, PATTERN RECOGN, V16
   [Anonymous], P C SYST MACH LEARN
   Badami K, 2018, SYMP VLSI CIRCUITS, P241, DOI 10.1109/VLSIC.2018.8502343
   Badami KMH, 2016, IEEE J SOLID-ST CIRC, V51, P291, DOI 10.1109/JSSC.2015.2487276
   Baljekar P, 2014, IEEE W SP LANG TECH, P536, DOI 10.1109/SLT.2014.7078631
   Bang S, 2017, ISSCC DIG TECH PAP I, P250, DOI 10.1109/ISSCC.2017.7870355
   Chen ZH, 2018, SPEECH COMMUN, V102, P100, DOI 10.1016/j.specom.2018.08.001
   Dehak N, 2011, IEEE T AUDIO SPEECH, V19, P788, DOI 10.1109/TASL.2010.2064307
   Dehak N, 2009, INT CONF ACOUST SPEE, P4237, DOI 10.1109/ICASSP.2009.4960564
   Dufaux Alain, 2000, P 10 EUR SIGN PROC C, P1
   Giraldo JSP, 2018, PROC EUR SOLID-STATE, P166, DOI 10.1109/ESSCIRC.2018.8494342
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Harpe P, 2015, ISSCC DIG TECH PAP I, V58, P382, DOI 10.1109/ISSCC.2015.7063086
   Hubara I, 2018, J MACH LEARN RES, V18
   Kumari R. S. S., 2016, INDIAN J SCI TECHNOL, V9, P1, DOI DOI 10.17485/ijst/2016/v9i19/93870
   Lane ND, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P117, DOI 10.1145/2699343.2699349
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Qiu HQ, 2018, INT CONF INFO SCI, P138, DOI 10.1109/ICIST.2018.8426169
   Reynolds DA, 2002, INT CONF ACOUST SPEE, P4072
   Shahriari M., 2018, 2018 IEEE 8 INT C CO, P1, DOI DOI 10.1109/IROS.2018.8593841
   Su Y, 2007, IEEE I CONF COMP VIS, P1815
   Sun M, 2016, IEEE W SP LANG TECH, P474, DOI 10.1109/SLT.2016.7846306
   Wang JC, 2015, IEEE T VLSI SYST, V23, P1355, DOI 10.1109/TVLSI.2014.2335112
   Yuan M, 2006, MICROPROCESS MICROSY, V30, P155, DOI 10.1016/j.micpro.2005.10.001
NR 25
TC 44
Z9 44
U1 2
U2 7
PD APR
PY 2020
VL 55
IS 4
BP 868
EP 878
DI 10.1109/JSSC.2020.2968800
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Biswas, A
   Chandrakasan, AP
AF Biswas, Avishek
   Chandrakasan, Anantha P.
TI CONV-SRAM: An Energy-Efficient SRAM With In-Memory Dot-Product
   Computation for Low-Power Convolutional Neural Networks
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article; Proceedings Paper
CT 65th IEEE International Solid-State Circuits Conference (ISSCC)
CY FEB 11-15, 2018
CL San Francisco, CA
DE Analog computing; binary weights; convolutional neural networks (CNNs);
   dot-product; edge-computing; energy-efficient SRAM; in-memory
   computation; machine learning (ML)
ID ACCELERATOR; PROCESSOR
AB This paper presents an energy-efficient static random access memory (SRAM) with embedded dot-product computation capability, for binary-weight convolutional neural networks. A 10T bit-cell-based SRAM array is used to store the 1-b filter weights. The array implements dot-product as a weighted average of the bitline voltages, which are proportional to the digital input values. Local integrating analogto- digital converters compute the digital convolution outputs, corresponding to each filter. We have successfully demonstrated functionality (> 98% accuracy) with the 10 000 test images in the MNIST hand-written digit recognition data set, using 6-b inputs/outputs. Compared to conventional full-digital implementations using small bitwidths, we achieve similar or better energy efficiency, by reducing data transfer, due to the highly parallel in-memory analog computations.
C1 [Biswas, Avishek] Texas Instruments Inc, Kilby Labs, Dallas, TX 75243 USA.
   [Chandrakasan, Anantha P.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
RP Biswas, A (corresponding author), Texas Instruments Inc, Kilby Labs, Dallas, TX 75243 USA.
EM avishek.biswas@alum.mit.edu
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Biswas A., 2018, THESIS
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Biswas A, 2016, PROC EUR SOLID-STATE, P433, DOI 10.1109/ESSCIRC.2016.7598334
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Duan CH, 2017, IEEE J SOLID-ST CIRC, V52, P2703, DOI 10.1109/JSSC.2017.2731814
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Moons B, 2018, IEEE CUST INTEGR CIR
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 24
TC 180
Z9 184
U1 4
U2 32
PD JAN
PY 2019
VL 54
IS 1
SI SI
BP 217
EP 230
DI 10.1109/JSSC.2018.2880918
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Mao, WD
   Yang, PX
   Wang, ZF
AF Mao, Wendong
   Yang, Peixiang
   Wang, Zhongfeng
TI FTA-GAN: A Computation-Efficient Accelerator for GANs With Fast
   Transformation Algorithm
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Deconvolution; Generative adversarial networks; Convolution; Kernel;
   Hardware; Generators; Memory management; Deconvolution; fast algorithm;
   generative adversarial network (GAN); hardware architecture; transposed
   convolution
ID NEURAL-NETWORKS; ARCHITECTURE
AB Nowadays, generative adversarial network (GAN) is making continuous breakthroughs in many machine learning tasks. The popular GANs usually involve computation-intensive deconvolution operations, leading to limited real-time applications. Prior works have brought several accelerators for deconvolution, but all of them suffer from severe problems, such as computation imbalance and large memory requirements. In this article, we first introduce a novel fast transformation algorithm (FTA) for deconvolution computation, which well solves the computation imbalance problem and removes the extra memory requirement for overlapped partial sums. Besides, it can reduce the computation complexity for various types of deconvolutions significantly. Based on FTA, we develop a fast computing core (FCC) and the corresponding computing array so that the deconvolution can be efficiently computed. We next optimize the dataflow and storage scheme to further reuse on-chip memory and improve the computation efficiency. Finally, we present a computation-efficient hardware architecture for GANs and validate it on several GAN benchmarks, such as deep convolutional GAN (DCGAN), energy-based GAN (EBGAN), and Wasserstein GAN (WGAN). The experimental results show that our design can reach 2211 GOPS under 185-MHz working frequency on Intel Stratix 10SX field-programmable gate array (FPGA) board with satisfactory visual results. In brief, the proposed design can achieve more than 2x hardware efficiency improvement over previous designs, and it can reduce the storage requirement drastically.
C1 [Mao, Wendong; Yang, Peixiang; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Peoples R China.
RP Wang, ZF (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210008, Peoples R China.
EM wdmao@smail.nju.edu.cn; pxyang@smail.nju.edu.cn; zfwang@nju.edu.cn
CR Arjovsky M, 2017, PR MACH LEARN RES, V70
   Brophy E., 2019, ARXIV190205624
   Chang JW, 2020, IEEE T CIRC SYST VID, V30, P281, DOI 10.1109/TCSVT.2018.2888898
   Chang JW, 2018, ASIA S PACIF DES AUT, P343, DOI 10.1109/ASPDAC.2018.8297347
   Chen YD, 2018, IEEE WCNC
   Courbariaux M., 2016, J MACH LEARN RES
   Di XK, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9020286
   Dong C, 2016, LECT NOTES COMPUT SC, V9906, P391, DOI 10.1007/978-3-319-46475-6_25
   Dosovitskiy Alexey, 2016, ADV NEURAL INFORM PR, V29, P658, DOI DOI 10.5555/3157096.3157170
   Esteban Cristobal, 2017, ARXIV170602633
   Gudovskiy D. A., 2017, SHIFTCNN GEN LOW PRE
   [何新智 He Xinzhi], 2019, [真空科学与技术学报, Chinese Journal of Vacuum Science and Technology], V39, P361
   He Y, 2019, PROC CVPR IEEE, P4335, DOI 10.1109/CVPR.2019.00447
   Huang D, 2020, AAAI CONF ARTIF INTE, V34, P4174
   Im D. J., 2016, ARXIV160205110
   Jung-Woo Chang, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P283, DOI 10.1109/ASP-DAC47756.2020.9045214
   Kim T, 2017, PR MACH LEARN RES, V70
   Kodali N., 2017, ARXIV
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   Li J., 2016, ARXIV161208220
   Liu SL, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242900
   Liu WJ, 2019, IEEE INT SYMP CIRC S
   Liu X., 2018, ARXIV PREPRINT ARXIV
   Liu ZW, 2015, IEEE I CONF COMP VIS, P3730, DOI 10.1109/ICCV.2015.425
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Lu LQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196120
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Mao WD, 2020, IEEE T VLSI SYST, V28, P1867, DOI 10.1109/TVLSI.2020.3000519
   Mao WG, 2019, MOBICOM'19: PROCEEDINGS OF THE 25TH ANNUAL INTERNATIONAL CONFERENCE ON MOBILE COMPUTING AND NETWORKING, DOI 10.1145/3300061.3345439
   Parhi K. K., 1999, VLSI DIGITAL SIGNAL, P228
   Qian BA, 2021, IEEE T IMAGE PROCESS, V30, P4894, DOI 10.1109/TIP.2021.3076275
   Radford A., 2015, ARXIV151106434
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shi WZ, 2016, PROC CVPR IEEE, P1874, DOI 10.1109/CVPR.2016.207
   Tonfat J, 2012, IEEE 3 LAT AM S CIRC, P1
   Wang HN, 2019, INT CONF ACOUST SPEE, P1448, DOI 10.1109/ICASSP.2019.8683512
   Wang JC, 2018, IEEE T CIRCUITS-I, V65, P1941, DOI 10.1109/TCSI.2017.2767204
   Xu DW, 2020, IEEE T COMPUT, V69, P1172, DOI 10.1109/TC.2020.3001033
   Xu DW, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240810
   Xu WH, 2020, IEEE T COMPUT AID D, V39, P4894, DOI 10.1109/TCAD.2020.2973355
   Yan JL, 2018, IEEE T COMPUT AID D, V37, P2519, DOI 10.1109/TCAD.2018.2857258
   Yang PX, 2020, IEEE INT NEW CIRC, P210, DOI [10.1109/NEWCAS49341.2020.9159773, 10.1109/newcas49341.2020.9159773]
   Zeiler MD, 2011, IEEE I CONF COMP VIS, P2018, DOI 10.1109/ICCV.2011.6126474
   Zhang X, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07334-1
   Zhao J., 2017, P 5 INT C LEARN REPR, P100, DOI DOI 10.1109/TCSVT.2017.2710120
   Zhao RZ, 2017, LECT NOTES COMPUT SC, V10216, P255, DOI 10.1007/978-3-319-56258-2_22
   Zhu JY, 2017, IEEE I CONF COMP VIS, P2242, DOI 10.1109/ICCV.2017.244
NR 47
TC 1
Z9 2
U1 1
U2 14
PD JUN
PY 2023
VL 34
IS 6
BP 2978
EP 2992
DI 10.1109/TNNLS.2021.3110728
EA SEP 2021
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Shi, YB
   Wang, MQ
   Chen, SY
   Wei, JH
   Wang, ZF
AF Shi, Yubo
   Wang, Meiqi
   Chen, Siyi
   Wei, Jinghe
   Wang, Zhongfeng
GP IEEE
TI Transform-Based Feature Map Compression for CNN Inference
SO 2021 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 22-28, 2021
CL Daegu, SOUTH KOREA
DE CNN; Feature Map; Compression; Hardware Accelerator; Inference
AB To achieve higher accuracy in machine learning tasks, very deep convolutional neural networks (CNNs) are designed recently. However, the large memory access of deep CNNs will lead to high power consumption. A variety of hardware-friendly compression methods have been proposed to reduce the data transfer bandwidth by exploiting the sparsity of feature maps. Most of them focus on designing a specialized encoding format to increase the compression ratio. Differently, we observe and exploit the sparsity distinction between activations in earlier and later layers to improve the compression ratio. We propose a novel hardware-friendly transform-based method named 1D-Discrete Cosine Transform on Channel dimension with Masks (DCT-CM), which intelligently combines DCT, masks, and a coding format to compress activations. The proposed algorithm achieves an average compression ratio of 2.9x (53% higher than the state-of-the-art transform-based feature map compression works) during inference on ResNet-50 with an 8-bit quantization scheme.
C1 [Shi, Yubo; Wang, Meiqi; Chen, Siyi; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
   [Wei, Jinghe] China Key Syst & Integrated Circuit Co Ltd, Wuxi, Jiangsu, Peoples R China.
RP Shi, YB (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM mf1923134@smail.nju.edu.cn; mqwang@smail.nju.edu.cn;
   mg1923066@smail.nju.edu.cn; pume1975_cnjs@sina.co; zfwang@nju.edu.cn
CR Aimar A, 2019, IEEE T NEUR NET LEAR, V30, P644, DOI 10.1109/TNNLS.2018.2852335
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   Cavigelli L, 2019, 2019 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2019), P279, DOI [10.1109/AICAS.2019.8771562, 10.1109/aicas.2019.8771562]
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   El-Banna H, 2003, INT C MICROELECTRON, P278
   Evans RD, 2020, ANN I S COM, P860, DOI 10.1109/ISCA45697.2020.00075
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Goodfellow Ian J, 2014, INT C LEARN REPRESEN
   Gudovskiy Denis, 2018, ARXIV180805285
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hauck Edward L., 1986, DATA COMPRESSION USI
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Huang J, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596541
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Le Q. V., 2016, ARXIV161101578
   Loeffer C., 1989, ICASSP-89: 1989 International Conference on Acoustics, Speech and Signal Processing (IEEE Cat. No.89CH2673-2), P988, DOI 10.1109/ICASSP.1989.266596
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   MOFFAT A, 1992, SIGIR 92 : PROCEEDINGS OF THE FIFTEENTH ANNUAL INTERNATIONAL ACM SIGIR CONFERENCE ON RESEARCH AND DEVELOPMENT IN INFORMATION RETRIEVAL, P274
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rhu M, 2016, 2016 49 ANN IEEEACM, P1, DOI [DOI 10.1109/MICRO.2016.7783721, 10.1109/MICRO.2016.7783721]
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Saito, 2018, CHAINER CIFAR10 VARI
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tumeo A, 2007, IEEE COMP SOC ANN, P331, DOI 10.1109/ISVLSI.2007.13
   WALLACE GK, 1991, COMMUN ACM, V34, P30, DOI 10.1145/103085.103089
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zeng X, 2020, IEEE T COMPUT, V69, P968, DOI 10.1109/TC.2020.2978475
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang Y, 2014, PROC CVPR IEEE, P907, DOI 10.1109/CVPR.2014.121
NR 34
TC 0
Z9 0
U1 2
U2 5
PY 2021
DI 10.1109/ISCAS51556.2021.9401133
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ang, JA
   Barker, KJ
   Vrabie, DL
   Kestor, G
AF Ang, James A.
   Barker, Kevin J.
   Vrabie, Draguna L.
   Kestor, Gokcen
TI Codesign for Extreme Heterogeneity: Integrating Custom Hardware With
   Commodity Computing Technology to Support Next-Generation HPC Converged
   Workloads
SO IEEE INTERNET COMPUTING
DT Article
DE Computational modeling; Data models; Biological system modeling;
   Computer architecture; Software engineering; Heterogeneous networks;
   Hardware
ID NETWORK
AB The future of high-performance computing (HPC) will be driven by the convergence of physical simulation, artificial intelligence, machine learning, and data science computing capabilities. While computational performance gains afforded by technology scaling, as predicted by Moore's Law, have enabled large-scale HPC system design and deployment using commodity CPU and GPU processing components, emerging technologies will be required to effectively support such converged workloads. These emerging technologies will integrate commodity computing components with custom processing and networking accelerators into ever-more heterogeneous architectures resulting in a diverse ecosystem of industry technology developers, university, and U.S. Government researchers. In this article, we describe efforts at the U.S. Department of Energy's Pacific Northwest National Laboratory to construct an end-to-end codesign framework that lays a groundwork for such an ecosystem, including notable outcomes, remaining challenges, and future opportunities.
C1 [Ang, James A.; Barker, Kevin J.; Vrabie, Draguna L.; Kestor, Gokcen] Pacific Northwest Natl Lab, Richland, WA 99354 USA.
RP Ang, JA (corresponding author), Pacific Northwest Natl Lab, Richland, WA 99354 USA.
EM ang@pnnl.gov; kevin.barker@pnnl.gov; draguna.vrabie@pnnl.gov;
   gokcen.kestor@pnnl.gov
CR Ang J. A., 2021, 1822199 OSTI US DOE, DOI [10.2172/1822199, DOI 10.2172/1822199]
   [Anonymous], 2020, US
   Ghosh Sreedip, 2021, 2021 6th International Conference for Convergence in Technology (I2CT), DOI 10.1109/I2CT51068.2021.9418065
   Gioiosa R, 2020, GPGPU'20: PROCEEDINGS OF THE 13TH ANNUAL WORKSHOP ON GENERAL PURPOSE PROCESSING USING GRAPHICS PROCESSING UNIT (GPU), P1, DOI 10.1145/3366428.3380770
   Guan S, 2021, PROC VLDB ENDOW, V14, P2875, DOI 10.14778/3476311.3476367
   King E, 2022, 2022 AMERICAN CONTROL CONFERENCE (ACC), P2194, DOI 10.23919/ACC53348.2022.9867379
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lattner C, 2021, INT SYM CODE GENER, P2, DOI 10.1109/CGO51591.2021.9370308
   Lin HQ, 2018, IEEE ACCESS, V6, P18345, DOI 10.1109/ACCESS.2018.2817921
   Mutlu E., 2020, PROC 33 INT WORKSHOP, P87
   Nandanoori SP, 2021, IEEE DECIS CONTR P, P5059, DOI 10.1109/CDC45484.2021.9682872
   Nandanoori SP, 2022, IEEE ACCESS, V10, P32337, DOI 10.1109/ACCESS.2022.3160710
   Pernot P, 2022, J CHEM PHYS, V156, DOI 10.1063/5.0084302
   Pidko EA, 2017, ACS CATAL, V7, P4230, DOI 10.1021/acscatal.7b00290
   Spurgeon SR, 2021, NAT MATER, V20, P274, DOI 10.1038/s41563-020-00833-z
   Stinis P., 2020, PROC AAAI SPRING S C
   Tallent Nathan R., 2016, 2016 IEEE International Conference on Networking, Architecture and Storage (NAS), P1, DOI 10.1109/NAS.2016.7549392
   Tan C, 2020, PR IEEE COMP DESIGN, P381, DOI 10.1109/ICCD50377.2020.00070
NR 18
TC 0
Z9 0
U1 1
U2 1
PD JAN 1
PY 2023
VL 27
IS 1
BP 7
EP 14
DI 10.1109/MIC.2022.3217423
WC Computer Science, Software Engineering
DA 2023-11-11
ER

PT C
AU Gambardella, G
   Kappauf, J
   Blott, M
   Doehring, C
   Kumm, M
   Zip, P
   Vissers, K
AF Gambardella, Giulio
   Kappauf, Johannes
   Blott, Michaela
   Doehring, Christoph
   Kumm, Martin
   Zip, Peter
   Vissers, Kees
GP IEEE
TI Efficient Error-Tolerant Quantized Neural Network Accelerators
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON DEFECT AND FAULT TOLERANCE IN VLSI
   AND NANOTECHNOLOGY SYSTEMS (DFT)
SE IEEE International Symposium on Defect and Fault Tolerance in VLSI
   Systems
DT Proceedings Paper
CT IEEE International Symposium on Defect and Fault Tolerance in VLSI and
   Nanotechnology Systems (DFT)
CY OCT 02-04, 2019
CL European Space Res& Technol Ctr, Noordwijk, NETHERLANDS
HO European Space Res& Technol Ctr
DE neural networks; safety; automotive; FPGA; quantized neural networks
AB Neural Networks are currently one of the most widely deployed machine learning algorithms. In particular, Convolutional Neural Networks (CNNs), are gaining popularity and are evaluated for deployment in safety critical applications such as self driving vehicles. Modern CNNs feature enormous memory bandwidth and high computational needs, challenging existing hardware platforms to meet throughput, latency and power requirements. Functional safety and error tolerance need to be considered as additional requirement in safety critical systems. In general, fault tolerant operation can be achieved by adding redundancy to the system, which is further exacerbating the computational demands. Furthermore, the question arises whether pruning and quantization methods for performance scaling turn out to be counterproductive with regards to fail safety requirements. In this work we present a methodology to evaluate the impact of permanent faults affecting Quantized Neural Networks (QNNs) and how to effectively decrease their effects in hardware accelerators. We use FPGA-based hardware accelerated error injection, in order to enable the fast evaluation. A detailed analysis is presented showing that QNNs containing convolutional layers are by far not as robust to faults as commonly believed and can lead to accuracy drops of up to 10%. To circumvent that, we propose two different methods to increase their robustness: 1) selective channel replication which adds significantly less redundancy than used by the common triple modular redundancy and 2) a fault-aware scheduling of processing elements for folded implementations.
C1 [Gambardella, Giulio; Kappauf, Johannes; Blott, Michaela; Vissers, Kees] Xilinx Res Labs, Dublin, Ireland.
   [Doehring, Christoph] Coburg Univ, Coburg, Germany.
   [Kumm, Martin] Fulda Univ Appl Sci, Fulda, Germany.
   [Zip, Peter] Univ Kassel, Digital Technol Grp, Kassel, Germany.
RP Gambardella, G (corresponding author), Xilinx Res Labs, Dublin, Ireland.
EM giuliog@xilinx.com; ohannes@xilinx.com; mblott@xilinx.com;
   doch1501@stud.hs-coburg.de; martin.kumm@cs.hs-fulda.de;
   zipf@uni-kassel.de; kees.vissers@xilinx.com
CR Blott M., 2018, FINN R END TO END DE
   Bosio A., 2018, ARC 18, P1
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   dos Santos FF, 2017, I C DEPENDABLE SYST, P169, DOI 10.1109/DSN-W.2017.47
   Gehr T, 2018, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2018.00058
   Goble WM, 1999, RELIAB ENG SYST SAFE, V66, P145, DOI 10.1016/S0951-8320(99)00031-9
   Guo K., 2017, SURVEY FPGA BASED NE
   Howard A. G., 2017, ARXIV
   Jha S, 2018, ARC 18, P1, DOI [DOI 10.15398/JLM.V7I2.214, 10.15398/jlm.v7i2.214]
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Mittal S, 2020, NEURAL COMPUT APPL, V32, P1109, DOI 10.1007/s00521-018-3761-1
   Nunez-Yanez J, 2019, IEEE T COMPUT, V68, P676, DOI 10.1109/TC.2018.2879333
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Singh AP, 2009, 2009 FIRST INTERNATIONAL CONFERENCE ON ADVANCES IN SYSTEM TESTING AND VALIDATION LIFECYCLE, P7, DOI 10.1109/VALID.2009.32
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Wu B., 2017, CORR
NR 17
TC 11
Z9 12
U1 0
U2 0
PY 2019
DI 10.1109/dft.2019.8875314
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Nanoscience &
   Nanotechnology
DA 2023-11-11
ER

PT C
AU Tine, BP
   Yalamanchili, S
   Kim, H
AF Tine, Blaise-Pascal
   Yalamanchili, Sudhakar
   Kim, Hyesoon
BE DiNatale, G
   Bolchini, C
   Vatajelu, EI
TI Tango: An Optimizing Compiler for Just-In-Time RTL Simulation
SO PROCEEDINGS OF THE 2020 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE 2020)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY MAR 09-13, 2020
CL Grenoble, FRANCE
AB With Moore's law coming to an end, the advent of hardware specialization presents a unique challenge for a much tighter software and hardware co-design environment to exploit domain-specific optimizations and increase design efficiency. This trend is further accentuated by rapid-pace of innovations in Machine Learning and Graph Analytic, calling for a faster product development cycle for hardware accelerators and the importance of addressing the increasing cost of hardware verification. The productivity of software-hardware co-design relies upon better integration between the software and hardware design methodologies, but more importantly in the effectiveness of the design tools and hardware simulators at reducing the development time. In this work, we developed Tango, an Optimizing compiler for Just-in-Time RTL simulation. Tango implements unique hardware-centric compiler transformations to speed up runtime code generation in a software-hardware co-design environment where hardware simulation speed is critical. Tango achieves a 6x average speedup compared to the state-of-the-art simulators.
C1 [Tine, Blaise-Pascal; Yalamanchili, Sudhakar; Kim, Hyesoon] Georgia Tech, Atlanta, GA 30332 USA.
RP Tine, BP (corresponding author), Georgia Tech, Atlanta, GA 30332 USA.
EM blaise.tine@gatech.edu; sudah@gatech.edu; hyesoon@cc.gatech.edu
CR Bachrach J., DAC 12
   DARPA, 2017, INT DES EL ASS ID
   *IEEE, 2006, 13642005 IEEE
   Kim D., DATE 11
   Korobeynikov A., 2007, IMPROVING SWITCH LOW
   Kupriyanov A., SCOPES 07
   Kupriyanov F. H. Alexey, 2004, AUTOMATIC OPTIMIZED
   Kupriyanov F. H. Alexey, 2004, HIGH SPEED EVENT DRI
   Li L., PADS 07
   Lockhart D, 2014, INT SYMP MICROARCH, P280, DOI 10.1109/MICRO.2014.50
   Panda PR, 2001, ISSS'01: 14TH INTERNATIONAL SYMPOSIUM ON SYSTEM SYNTHESIS, P75, DOI 10.1109/ISSS.2001.957916
   Qian H., ICCAD 11
   Snyder W., VERILATOR
   Synopsys, VCS IND HIGH PERF SI
   Williams Stephen, ICARUS VERILOG
NR 15
TC 0
Z9 0
U1 0
U2 0
PY 2020
BP 157
EP 162
WC Automation & Control Systems; Computer Science, Theory & Methods;
   Engineering, Industrial; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Leon, V
   Makris, G
   Xydis, S
   Pekmestzi, K
   Soudris, D
AF Leon, Vasileios
   Makris, Georgios
   Xydis, Sotirios
   Pekmestzi, Kiamal
   Soudris, Dimitrios
GP IEEE
TI MAx-DNN: Multi-Level Arithmetic Approximation for Energy-Efficient DNN
   Hardware Accelerators
SO 2022 IEEE 13TH LATIN AMERICAN SYMPOSIUM ON CIRCUITS AND SYSTEMS (LASCAS)
DT Proceedings Paper
CT 13th Latin America Symposium on Circuits and System (LASCAS)
CY APR 01-04, 2022
CL Puerto Varas, CHILE
DE Approximate Computing; Inexact Multipliers; ASIC; Deep Neural Networks;
   ResNet; CIFAR-10; TensorFlow
ID DESIGN
AB Nowadays, the rapid growth of Deep Neural Network (DNN) architectures has established them as the defacto approach for providing advanced Machine Learning tasks with excellent accuracy. Targeting low-power DNN computing, this paper examines the interplay of fine-grained error resilience of DNN workloads in collaboration with hardware approximation techniques, to achieve higher levels of energy efficiency. Utilizing the state-of-the-art ROUP approximate multipliers, we systematically explore their fine-grained distribution across the network according to our layer-, filter-, and kernel-level approaches, and examine their impact on accuracy and energy. We use the ResNet-8 model on the CIFAR-10 dataset to evaluate our approximations. The proposed solution delivers up to 54% energy gains in exchange for up to 4% accuracy loss, compared to the baseline quantized model, while it provides 2x energy gains with better accuracy versus the state-of-the-art DNN approximations.
C1 [Leon, Vasileios; Makris, Georgios; Pekmestzi, Kiamal; Soudris, Dimitrios] Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
   [Xydis, Sotirios] Harokopio Univ Athens, Dept Informat & Telemat, Athens 17778, Greece.
RP Leon, V (corresponding author), Natl Tech Univ Athens, Sch Elect & Comp Engn, Athens 15780, Greece.
EM vleon@microlab.ntua.gr; gmakris@microlab.ntua.gr; sxydis@hua.gr;
   pekmes@microlab.ntua.gr; dsoudris@microlab.ntua.gr
CR Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Hernández-Araya D, 2020, IEEE LAT AMER SYMP
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Lentaris G, 2020, IEEE I C ELECT CIRC, DOI 10.1109/icecs49266.2020.9294869
   LEON V, 2021, IEEE INT C ELECT CIR, P1, DOI DOI 10.1109/ICECS53924.2021.9665462
   Leon V, 2021, 2021 10TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST), DOI 10.1109/MOCAST52088.2021.9493421
   Leon V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317793
   Leon V, 2018, IEEE T VLSI SYST, V26, P421, DOI 10.1109/TVLSI.2017.2767858
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Venkataramani S, 2020, P IEEE, V108, P2232, DOI 10.1109/JPROC.2020.3029453
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
NR 13
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 61
EP 64
DI 10.1109/LASCAS53948.2022.9789055
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Song, J
   Jeong, H
   Jeong, J
AF Song, Jaehyun
   Jeong, Hwanjin
   Jeong, Jinkyu
TI Performance Optimization of Object Tracking Algorithms in OpenCV on GPUs
SO APPLIED SCIENCES-BASEL
DT Article
DE GPU; OpenCL; OpenCV; optimization; kernel occupancy
AB Machine-learning-based computer vision is increasingly versatile and being leveraged by a wide range of smart devices. Due to the limited performance/energy budget of computing units in smart devices, the careful implementation of computer vision algorithms is critical. In this paper, we analyze the performance bottleneck of two well-known computer vision algorithms for object tracking: object detection and optical flow in the Open-source Computer Vision library (OpenCV). Based on our in-depth analysis of their implementation, we found the current implementation fails to utilize Open Computing Language (OpenCL) accelerators (e.g., GPUs). Based on the analysis, we propose several optimization strategies and apply them to the OpenCL implementation of object tracking algorithms. Our evaluation results demonstrate the performance of the object detection is improved by up to 86% and the performance of the optical flow by up to 10%. We believe our optimization strategies can be applied to other computer vision algorithms implemented in OpenCL.
C1 [Song, Jaehyun; Jeong, Hwanjin; Jeong, Jinkyu] Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
   [Jeong, Hwanjin] Woowabros, Seoul 05544, South Korea.
RP Jeong, J (corresponding author), Sungkyunkwan Univ, Coll Informat & Commun Engn, Suwon 16419, South Korea.
EM jaehyun.song@csi.skku.edu; hwanjinjeong@woowahan.com; jinkyu@skku.edu
CR Aby P. K., 2011, Proceedings 2011 International Conference on Signal Processing, Communication, Computing and Networking Technologies (ICSCCN 2011), P250, DOI 10.1109/ICSCCN.2011.6024553
   [Anonymous], AMD GPU PROFILER
   [Anonymous], 2015, OPEN SOURCE COMPUTER
   [Anonymous], 2013, KHRONOS OPENCL REFER
   [Anonymous], OPENGPU CODEXL
   [Anonymous], AMD ACCELERATED PARA
   [Anonymous], OPENCV 3 0
   [Anonymous], 2016, NVIDIA CUDA PROGR GU
   [Anonymous], CISC VIS NETW IND GL
   [Anonymous], NVIDIA GPU PROFILER
   Arya Z., 2020, INT J ENG RES APPL, V10, P13
   Bastani F, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1907, DOI 10.1145/3318464.3389692
   Battaglia F, 2009, IEEE T CONSUM ELECTR, V55, P2436, DOI 10.1109/TCE.2009.5373821
   Chai Y, 2010, IEEE T CONSUM ELECTR, V56, P510, DOI 10.1109/TCE.2010.5505963
   Cho J, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143217
   Chun JB, 2008, IEEE T CONSUM ELECTR, V54, P1479, DOI 10.1109/TCE.2008.4711190
   Coelho F, 1997, ACM SIGPLAN NOTICES, V32, P168, DOI 10.1145/263767.263786
   de Melo A. C., 2010, LINUX K
   Farnebäck G, 2003, LECT NOTES COMPUT SC, V2749, P363, DOI 10.1007/3-540-45103-x_50
   Gaster B., 2012, HETEROGENEOUS COMPUT
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   HE DC, 1990, IEEE T GEOSCI REMOTE, V28, P509
   Itseez, 2016, OP SOURC COMP VIS LI
   Kadir K, 2014, 2014 4TH INTERNATIONAL CONFERENCE ON ENGINEERING TECHNOLOGY AND TECHNOPRENEURSHIP (ICE2T), P335, DOI 10.1109/ICE2T.2014.7006273
   Karimi-Mansoub S., 2019, P 4 INT C ADV SIGNAL, P23
   Li N, 2016, OPEN SOURCE COMPUTER
   Li SS, 2021, IEEE T CONSUM ELECTR, V67, P129, DOI 10.1109/TCE.2021.3077241
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Mistry P., 2019, P INT WORKSH OPENCL
   Munshi A., 2011, OPENCL PROGRAMMING G
   NVIDIA, 2021, NVIDIA CUDA C PROGR
   Ping Gao, 2010, 2010 International Conference on Image Analysis and Signal Processing (IASP 2010), P620, DOI 10.1109/IASP.2010.5476045
   Poudel Pramod, 2010, 2010 42nd Southeastern Symposium on System Theory (SSST 2010), P51, DOI 10.1109/SSST.2010.5442803
   Rabbah R.M., 2003, ACM T EMBED COMPUT S, V2, P186, DOI [10.1145/643470.643474, DOI 10.1145/643470.643474]
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saez-Mingorance B, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21175923
   Singhal N, 2010, IEEE IMAGE PROC, P4481, DOI 10.1109/ICIP.2010.5651740
   Soo S., 2014, OBJECT DETECTION USI, V2, P1
   Sung HW, 2016, INT CONF PARA PROC, P59, DOI 10.1109/ICPPW.2016.24
   Ullah MB, 2020, IEEE REGION 10 SYMP, P552
   Viola P, 2001, PROC CVPR IEEE, P511, DOI 10.1109/cvpr.2001.990517
   WANG L, 1990, PATTERN RECOGN, V23, P905, DOI 10.1016/0031-3203(90)90135-8
NR 43
TC 0
Z9 0
U1 5
U2 14
PD AUG
PY 2022
VL 12
IS 15
AR 7801
DI 10.3390/app12157801
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Cisbani, E
   Del Dotto, A
   Fanelli, C
   Williams, M
   Alfred, M
   Barbosa, F
   Barion, L
   Berdnikov, V
   Brooks, W
   Cao, T
   Contalbrigo, M
   Danagoulian, S
   Datta, A
   Demarteau, M
   Denisov, A
   Diefenthaler, M
   Durum, A
   Fields, D
   Furletova, Y
   Gleason, C
   Grosse-Perdekamp, M
   Hattawy, M
   He, X
   van Hecke, H
   Higinbotham, D
   Horn, T
   Hyde, C
   Ilieva, Y
   Kalicy, G
   Kebede, A
   Kim, B
   Liu, M
   McKisson, J
   Mendez, R
   Nadel-Turonski, P
   Pegg, I
   Romanov, D
   Sarsour, M
   da Silva, CL
   Stevens, J
   Sun, X
   Syed, S
   Towell, R
   Xie, J
   Zhao, ZW
   Zihlmann, B
   Zorn, C
AF Cisbani, E.
   Del Dotto, A.
   Fanelli, C.
   Williams, M.
   Alfred, M.
   Barbosa, F.
   Barion, L.
   Berdnikov, V
   Brooks, W.
   Cao, T.
   Contalbrigo, M.
   Danagoulian, S.
   Datta, A.
   Demarteau, M.
   Denisov, A.
   Diefenthaler, M.
   Durum, A.
   Fields, D.
   Furletova, Y.
   Gleason, C.
   Grosse-Perdekamp, M.
   Hattawy, M.
   He, X.
   van Hecke, H.
   Higinbotham, D.
   Horn, T.
   Hyde, C.
   Ilieva, Y.
   Kalicy, G.
   Kebede, A.
   Kim, B.
   Liu, M.
   McKisson, J.
   Mendez, R.
   Nadel-Turonski, P.
   Pegg, I
   Romanov, D.
   Sarsour, M.
   da Silva, C. L.
   Stevens, J.
   Sun, X.
   Syed, S.
   Towell, R.
   Xie, J.
   Zhao, Z. W.
   Zihlmann, B.
   Zorn, C.
TI AI-optimized detector design for the future Electron-Ion Collider: the
   dual-radiator RICH case
SO JOURNAL OF INSTRUMENTATION
DT Article
DE Detector design and construction technologies and materials; Cherenkov
   detectors
AB Advanced detector R&D requires performing computationally intensive and detailed simulations as part of the detector-design optimization process. We propose a general approach to this process based on Bayesian optimization and machine learning that encodes detector requirements. As a case study, we focus on the design of the dual-radiator Ring Imaging Cherenkov (dRICH) detector under development as a potential component of the particle-identification system at the future Electron-Ion Collider (EIC). The EIC is a US-led frontier accelerator project for nuclear physics, which has been proposed to further explore the structure and interactions of nuclear matter at the scale of sea quarks and gluons. We show that the detector design obtained with our automated and highly parallelized framework outperforms the baseline dRICH design within the assumptions of the current model. Our approach can be applied to any detector R&D, provided that realistic simulations are available.
C1 [Cisbani, E.] INFN, Sez Roma, I-00185 Rome, Italy.
   [Cisbani, E.] Ist Super Sanita, I-00161 Rome, Italy.
   [Del Dotto, A.] Lab Nazl Frascati, Via Enrico Fermi 40, I-00044 Frascati, Italy.
   [Fanelli, C.; Barbosa, F.; Diefenthaler, M.; Furletova, Y.; Higinbotham, D.; McKisson, J.; Romanov, D.; Zihlmann, B.; Zorn, C.] Jefferson Lab, Newport News, VA 23606 USA.
   [Fanelli, C.; Williams, M.] MIT, Lab Nucl Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Alfred, M.] Howard Univ, Washington, DC 20059 USA.
   [Barion, L.; Contalbrigo, M.] INFN, Sez Ferrara, I-44100 Ferrara, Italy.
   [Berdnikov, V; Horn, T.; Kalicy, G.; Pegg, I] Catholic Univ Amer, Washington, DC 20064 USA.
   [Brooks, W.; Mendez, R.] Univ Tecn Federico Santa Maria, Valparaiso, Chile.
   [Cao, T.] Univ New Hampshire, Durham, NH 03824 USA.
   [Danagoulian, S.; Kebede, A.] North Carolina A&T State Univ, Greensboro, NC 27411 USA.
   [Datta, A.; Fields, D.] Univ New Mexico, Albuquerque, NM 87131 USA.
   [Demarteau, M.] Oak Ridge Natl Lab, Oak Ridge, TN 37830 USA.
   [Denisov, A.; Durum, A.] Inst High Energy Phys, Protvino, Russia.
   [Gleason, C.; Ilieva, Y.] Univ South Carolina, Columbia, SC 29208 USA.
   [Grosse-Perdekamp, M.] Univ Illinois, Urbana, IL 61801 USA.
   [Hattawy, M.; Hyde, C.] Old Dominion Univ, Norfolk, VA 23529 USA.
   [He, X.; Sarsour, M.; Sun, X.; Syed, S.] Georgia State Univ, Atlanta, GA 30303 USA.
   [van Hecke, H.; Liu, M.; da Silva, C. L.] Los Alamos Natl Lab, Los Alamos, NM 87545 USA.
   [Kim, B.] CUNY City Coll, New York, NY 10031 USA.
   [Nadel-Turonski, P.] SUNY Stony Brook, Stony Brook, NY 11794 USA.
   [Stevens, J.] Coll William & Mary, Williamsburg, VA USA.
   [Towell, R.] Abilene Christian Univ, Abilene, TX 79601 USA.
   [Xie, J.] Argonne Natl Lab, Argonne, IL 60439 USA.
   [Zhao, Z. W.] Duke Univ, Durham, NC 27708 USA.
RP Fanelli, C (corresponding author), Jefferson Lab, Newport News, VA 23606 USA.; Fanelli, C (corresponding author), MIT, Lab Nucl Sci, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM cfanelli@mit.edu
CR Abadi M., 2016, ARXIV160304467
   ABJEAN R, 1995, NUCL INSTRUM METH A, V354, P417, DOI 10.1016/0168-9002(94)01006-4
   Accardi A, 2016, EUR PHYS J A, V52, DOI 10.1140/epja/i2016-16268-9
   Adinolfi M, 2013, EUR PHYS J C, V73, DOI 10.1140/epjc/s10052-013-2431-9
   Akopov N, 2002, NUCL INSTRUM METH A, V479, P511, DOI 10.1016/S0168-9002(01)00932-9
   [Anonymous], 2013, P 12 PYTH SCI C
   [Anonymous], JINST
   [Anonymous], 2012, NEURIPS, DOI DOI 10.5555/2999325.2999464
   Aschenauer E., 2019, ELECT ION COLLIDER D
   BELLMAN R, 1952, P NATL ACAD SCI USA, V38, P716, DOI 10.1073/pnas.38.8.716
   Bergstra J, 2012, J MACH LEARN RES, V13, P281
   Brochu E., 2010, COMPUT SCI
   Brochu Eric, 2010, P 2010 ACM SIGGRAPH, P103, DOI DOI 10.2312/SCA/SCA10/103-112
   Contalbrigo M, 2017, NUCL INSTRUM METH A, V876, P168, DOI 10.1016/j.nima.2017.02.068
   Del Dotto A, 2017, NUCL INSTRUM METH A, V876, P237, DOI 10.1016/j.nima.2017.03.032
   Eric Brochu, 2008, ADV NEURAL INFORM PR, V20, P409
   Friedman JH, 2001, ANN STAT, V29, P1189, DOI 10.1214/aos/1013203451
   Hutter Frank, 2011, Learning and Intelligent Optimization. 5th International Conference, LION 5. Selected Papers, P507, DOI 10.1007/978-3-642-25566-3_40
   Ilten P, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/04/P04028
   Jones DR, 1998, J GLOBAL OPTIM, V13, P455, DOI 10.1023/A:1008306431147
   Kalicy G, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/04/C04018
   Knudde N., 2017, ARXIV PREPRINT ARXIV
   LHCb collaboration, 2003, CERNLHCC2003030 LHCB
   Lizotte D, 2007, 20TH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P944
   Nappi E, 2005, RIV NUOVO CIMENTO, V28, P1, DOI 10.1393/ncr/i2006-10004-6
   National Academies of Sciences, ASS US BAS EL COLL S, DOI DOI 10.17226/25171
   Ngatchou P, 2005, P 13 INT C INT SYST, p84 , DOI DOI 10.1109/ISAP.2005.1599245
   Pereira SA, 2016, EUR PHYS J A, V52, DOI 10.1140/epja/i2016-16023-4
   Rasmussen CE, 2005, ADAPT COMPUT MACH LE, P1
   Romanov D., 2019, JLEIC DETECTOR SIMUL
   Snoek J, 2015, PR MACH LEARN RES, V37, P2171
   Srinivas N, 2012, IEEE T INFORM THEORY, V58, P3250, DOI 10.1109/TIT.2011.2182033
   Ungaro M., GEANT4 M CARLO GEMC
   Wong CP, 2017, NUCL INSTRUM METH A, V871, P13, DOI 10.1016/j.nima.2017.07.001
   YPSILANTIS T, 1994, NUCL INSTRUM METH A, V343, P30, DOI 10.1016/0168-9002(94)90532-0
NR 35
TC 11
Z9 11
U1 2
U2 7
PD MAY
PY 2020
VL 15
IS 5
AR P05009
DI 10.1088/1748-0221/15/05/P05009
WC Instruments & Instrumentation
DA 2023-11-11
ER

PT J
AU Weidner, J
   Horn, J
   Kabat, CN
   Stathakis, S
   Geissler, P
   Wolf, U
   Poppinga, D
AF Weidner, Jan
   Horn, Julian
   Kabat, Christopher Nickolas
   Stathakis, Sotirios
   Geissler, Philipp
   Wolf, Ulrich
   Poppinga, Daniela
TI Artificial intelligence based deconvolving on megavoltage photon beam
   profiles for radiotherapy applications
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE artificial intelligence; profile measurement; dosimetry; deconvolution
ID RESPONSE FUNCTIONS; DECONVOLUTION; CONVOLUTION; DOSIMETRY; SIZE
AB Objective. The aim of this work is an AI based approach to reduce the volume effect of ionization chambers used to measure high energy photon beams in radiotherapy. In particular for profile measurements, the air-filled volume leads to an inaccurate measurement of the penumbra. Approach. The AI-based approach presented in this study was trained with synthetic data intended to cover a wide range of realistic linear accelerator data. The synthetic data was created by randomly generating profiles and convolving them with the lateral response function of a Semiflex 3D ionization chamber. The neuronal network was implemented using the open source tensorflow.keras machine learning framework and a U-Net architecture. The approach was validated on three accelerator types (Varian TrueBeam, Elekta VersaHD, Siemens Artiste) at FF and FFF energies between 6 MV and 18 MV at three measurement depths. For each validation, a Semiflex 3D measurement was compared against a microDiamond measurement, and the AI processed Semiflex 3D measurement was compared against the microDiamond measurement. Main results. The AI approach was validated with dataset containing 306 profiles measured with Semiflex 3D ionization chamber and microDiamond. In 90% of the cases, the AI processed Semiflex 3D dataset agrees with the microDiamond dataset within 0.5 mm/2% gamma criterion. 77% of the AI processed Semiflex 3D measurements show a penumbra difference to the microDiamond of less than 0.5 mm, 99% of less than 1 mm. Significance. This AI approach is the first in the field of dosimetry which uses synthetic training data. Thus, the approach is able to cover a wide range of accelerators and the whole specified field size range of the ionization chamber. The application of the AI approach offers an quality improvement and time saving for measurements in the water phantom, in particular for large field sizes.
C1 [Weidner, Jan; Horn, Julian; Poppinga, Daniela] PTW Freiburg GmbH, Freiburg, Germany.
   [Kabat, Christopher Nickolas; Stathakis, Sotirios] Univ Texas Hlth San Antonio, Dept Radiat Oncol, Div Med Phys, San Antonio, TX USA.
   [Geissler, Philipp; Wolf, Ulrich] Univ Hosp Leipzig, Dept Radiotherapy, Div Med Phys, Leipzig, Germany.
RP Weidner, J; Poppinga, D (corresponding author), PTW Freiburg GmbH, Freiburg, Germany.
EM jan.weidner@ptwdosimetry.com; daniela.poppinga@ptwdosimetry.com
CR [Anonymous], Z MED PHYS
   Bednarz G, 2002, PHYS MED BIOL, V47, P3643, DOI 10.1088/0031-9155/47/20/306
   Delfs B, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aadd3d
   Fox C, 2010, MED PHYS, V37, P477, DOI 10.1118/1.3284529
   Garcia-Vicente F, 1998, MED PHYS, V25, P202, DOI 10.1118/1.598182
   Herrup D, 2005, MED PHYS, V32, P3636, DOI 10.1118/1.2128086
   King DB, 2015, ACS SYM SER, V1214, P1
   Laub WU, 2003, MED PHYS, V30, P341, DOI 10.1118/1.1544678
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Looe HK, 2010, PHYS MED BIOL, V55, P3981, DOI 10.1088/0031-9155/55/14/003
   Looe HK, 2013, Z MED PHYS, V23, P129, DOI 10.1016/j.zemedi.2012.12.010
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Mund K, 2021, J APPL CLIN MED PHYS, V22, P161, DOI 10.1002/acm2.13411
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Schönfeld AB, 2021, J APPL CLIN MED PHYS, V22, P64, DOI 10.1002/acm2.13447
   Ulmer W, 2003, PHYS MED BIOL, V48, P707, DOI 10.1088/0031-9155/48/6/302
NR 17
TC 0
Z9 0
U1 1
U2 3
PD MAR 21
PY 2022
VL 67
IS 6
AR 06NT01
DI 10.1088/1361-6560/ac594d
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Kang, MG
   Lim, S
   Gonugondla, S
   Shanbhag, NR
AF Kang, Mingu
   Lim, Sungmin
   Gonugondla, Sujan
   Shanbhag, Naresh R.
TI An In-Memory VLSI Architecture for Convolutional Neural Networks
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Convolutional neural networks (CNN); in-memory computing; machine
   learning; analog processing; accelerator
ID ENERGY-EFFICIENT; PROCESSOR; MODE
AB This paper presents an energy-efficient and high throughput architecture for convolutional neural networks (CNN). Architectural and circuit techniques are proposed to address the dominant energy and delay costs associated with data movement in CNNs. The proposed architecture employs a deep in-memory architecture, to embed energy-efficient low swing mixed-signal computations in the periphery of the SRAM bitcell array. An efficient data access pattern and a mixed-signal multiplier are proposed to exploit data reuse opportunities in convolution. Silicon-validated energy, delay, and behavioral models of the proposed architecture are developed and employed to perform large-scale system simulations. System-level simulations using these models show >97% detection accuracy on the MNIST data set, along with 4.9x and 2.4x improvements in energy efficiency and throughput, respectively, leading to 11.9x reduction in energy-delay product as compared with a conventional (SRAM + digital processor) architecture.
C1 [Kang, Mingu] IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
   [Lim, Sungmin; Gonugondla, Sujan; Shanbhag, Naresh R.] Univ Illinois, Coordinated Sci Lab, Champaign, IL 61801 USA.
RP Kang, MG (corresponding author), IBM Thomas J Watson Res Ctr, Yorktown Hts, NY 10598 USA.
EM supermingu@gmail.com; sungmin3@illinois.edu; gonugon2@illinois.edu;
   shanbhag@illinois.edu
CR Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Ernst D, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P7
   Farabet C, 2009, I C FIELD PROG LOGIC, P32, DOI 10.1109/FPL.2009.5272559
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Jung Kuk Kim, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC50, DOI 10.1109/VLSIC.2015.7231323
   Kang M., 2016, 481 PJ DECISION 3 4
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Kang MG, 2016, IEEE T BIOMED CIRC S, V10, P855, DOI 10.1109/TBCAS.2016.2545402
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kang MG, 2015, IEEE INT SYMP CIRC S, P2505, DOI 10.1109/ISCAS.2015.7169194
   Kaul H, 2016, ISSCC DIG TECH PAP I, V59, P260, DOI 10.1109/ISSCC.2016.7418006
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kim K, 2009, IEEE J SOLID-ST CIRC, V44, P136, DOI 10.1109/JSSC.2008.2007157
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lenin Y, 1995, P INT C ART NEUR NET, V60, P53
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moons B, 2016, SYMP VLSI CIRCUITS
   Murmann B, 2015, 2015 49TH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS AND COMPUTERS, P1341, DOI 10.1109/ACSSC.2015.7421361
   Oh J, 2013, IEEE J SOLID-ST CIRC, V48, P2894, DOI 10.1109/JSSC.2013.2280238
   Park S, 2015, 2015 IEEE 4TH GLOBAL CONFERENCE ON CONSUMER ELECTRONICS (GCCE), P81, DOI 10.1109/GCCE.2015.7398741
   Price M, 2017, ISSCC DIG TECH PAP I, P244, DOI 10.1109/ISSCC.2017.7870352
   Rieutort-Louis W, 2016, IEEE J SOLID-ST CIRC, V51, P281, DOI 10.1109/JSSC.2015.2489842
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yamaoka M, 2005, IEEE J SOLID-ST CIRC, V40, P186, DOI 10.1109/JSSC.2004.838014
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 34
TC 39
Z9 42
U1 0
U2 10
PD SEP
PY 2018
VL 8
IS 3
SI SI
BP 494
EP 505
DI 10.1109/JETCAS.2018.2829522
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zeng, SL
   Guo, KY
   Fang, SX
   Kang, JL
   Xie, DL
   Shan, Y
   Wang, Y
   Yang, HZ
AF Zeng, Shulin
   Guo, Kaiyuan
   Fang, Shaoxia
   Kang, Junlong
   Xie, Dongliang
   Shan, Yi
   Wang, Yu
   Yang, Huazhong
GP IEEE
TI An Efficient Reconfigurable Framework for General Purpose CNN-RNN Models
   on FPGAs
SO 2018 IEEE 23RD INTERNATIONAL CONFERENCE ON DIGITAL SIGNAL PROCESSING
   (DSP)
SE International Conference on Digital Signal Processing
DT Proceedings Paper
CT 23rd IEEE International Conference on Digital Signal Processing (DSP)
CY NOV 19-21, 2018
CL Shanghai, PEOPLES R CHINA
DE framework; FPGA; CNN; RNN; optimization
AB Convolutional Neural Network (CNN) and Recurrent Neural Network (RNN) have made great progress in machine learning community. Combining CNN and RNN can accomplish more general and complex tasks. Many specially designed hardware accelerators on FPGA or ASIC have been proposed for CNN or RNN, yet few of them focus on CNN-RNN-based models for general purpose applications. In this paper, we propose a complete design framework for deploying general-purpose CNN-RNN-based models on FPGAs. We use Deephi Aristotle and Descartes IPs to build an efficient and reconfigurable hardware system with the support of Deephi's toolchains and Xilinx SDSoC environment. We also design a CNN-RNN-based co-optimization method which can find the IP configuration to achieve the maximum throughput under the given FPGA resources and neural network models. Our implementation on the Xilinx MEG FPGA achieves the throughput of 690.76GOPS and the energy efficiency of 86.34GOPS/W on LRCN network.
C1 [Zeng, Shulin; Guo, Kaiyuan; Wang, Yu; Yang, Huazhong] Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.
   [Zeng, Shulin; Guo, Kaiyuan; Wang, Yu; Yang, Huazhong] Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.
   [Zeng, Shulin; Fang, Shaoxia; Kang, Junlong; Xie, Dongliang; Shan, Yi; Wang, Yu] Deephi Technol Co Ltd, Beijing, Peoples R China.
RP Zeng, SL (corresponding author), Tsinghua Univ, Dept Elect Engn, Beijing, Peoples R China.; Zeng, SL (corresponding author), Beijing Natl Res Ctr Informat Sci & Technol BNRis, Beijing, Peoples R China.; Zeng, SL (corresponding author), Deephi Technol Co Ltd, Beijing, Peoples R China.
EM cengsl14@mails.tsinghua.edu.cn; yu-wang@tsinghua.edu.cn
CR Chen LC., 2014, COMPLEX VARIABLES TH, V7, P357, DOI 10.1080/17476938708814211
   Donahue B, 2015, 2015 IEEE AEROSPACE CONFERENCE
   Graves A, 2013, INT CONF ACOUST SPEE, P6645, DOI 10.1109/ICASSP.2013.6638947
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guo Kaiwen, 2017, IEEE T VISUALIZATION, V99, P1
   Han S., 2017, ESE EFFICIENT SPEECH
   Han Song, 2016, ICLR
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Kathail V, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P4, DOI 10.1145/2847263.2847284
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Yin SY, 2017, SYMP VLSI CIRCUITS, pC26, DOI 10.23919/VLSIC.2017.8008534
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Xiaofan, 2017, 2017 27 INT C FIELD, P1
NR 16
TC 4
Z9 4
U1 1
U2 6
PY 2018
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Huang, XM
   Zhou, YT
AF Huang, Xinming
   Zhou, Yuteng
GP IEEE
TI A 20 TOp/s/W Binary Neural Network Accelerator
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
AB This paper presents the hardware architecture and VLSI implementation of a binarized neural network (BNN). As a modification of convolutional neural network (CNN), BNN constrains all activations and weights to be +1 or -1, making it very appealing to low-power ASIC design. In this paper, BNN is proven to be highly power efficient and accurate for computer vision tasks. We use pedestrian and car detections as examples to showcase the capability of the BNN chip design. The total memory use of all weights in the BNN is only 22K bytes, which is significantly less than a typical convolutional neural network. Evaluated using INRIA and CIFAR-10 datasets, our BNN chip can achieve an average accuracy of 96.5%, which is much higher than traditional computer vision approaches such as histogram of oriented gradients with support vector machine. Our design achieves a power efficiency of 20 TOp/s/w, far exceeding most of the mainstream CNN chips. Therefore, the proposed low power hardware architecture of BNN enables deep learning on mobile embedded platforms.
C1 [Huang, Xinming; Zhou, Yuteng] Worcester Polytech Inst, Dept Elect & Comp Engn, Worcester, MA 01609 USA.
   [Huang, Xinming] Nantong Univ, Sch Informat & Elect, Nantong, Peoples R China.
RP Huang, XM (corresponding author), Worcester Polytech Inst, Dept Elect & Comp Engn, Worcester, MA 01609 USA.; Huang, XM (corresponding author), Nantong Univ, Sch Informat & Elect, Nantong, Peoples R China.
EM xhuang@wpi.edu; ytchou@wpi.edu
CR B. - P. Network, 1989, HANDWR DIG REC
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Han S., 2015, ARXIV151000149
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hosang J. H., 2014, CORR
   Iandola F. N., 2016, SQUEEZENET ALEXNET L
   Kang MG, 2015, INT CONF ACOUST SPEE, P1037, DOI 10.1109/ICASSP.2015.7178127
   Kim L. W., 2017, IEEE T NEURAL NETWOR
   lotte S, 2015, ARXIV150203167
   Okuda N, 2014, SPRINGERBRIEF BIOL, P1, DOI 10.1007/978-4-431-54150-9
   Patel VM, 2015, IEEE SIGNAL PROC MAG, V32, P53, DOI 10.1109/MSP.2014.2347059
   Pham PH, 2012, MIDWEST SYMP CIRCUIT, P1044, DOI 10.1109/MWSCAS.2012.6292202
   Qadeer W., 2013, P 40 ANN INT S COMP, P24, DOI DOI 10.1145/2485922.2485925
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   STOICA G. V., 2015, HIGH PERFORMANCE CUD
   Uijlings JRR, 2013, INT J COMPUT VISION, V104, P154, DOI 10.1007/s11263-013-0620-5
   Zitnick CL, 2014, LECT NOTES COMPUT SC, V8693, P391, DOI 10.1007/978-3-319-10602-1_26
NR 23
TC 0
Z9 0
U1 0
U2 2
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Hsiao, PY
   Lin, SY
   Huang, SS
AF Hsiao, Pei-Yung
   Lin, Shih-Yu
   Huang, Shih-Shinh
TI An FPGA based human detection system with embedded platform
SO MICROELECTRONIC ENGINEERING
DT Article
DE FPGA circuit design; Real-time embedded system; Human detection; HOG;
   SVM; Adaboost
AB Focusing on the computing speed of the practical machine learning based human detection system at the testing (detecting) stage to reach the real-time requirement in an embedded platform, the idea of iterative computing HOG with FPGA circuit design is proposed. The completed HOG accelerator contains gradient calculation circuit module and histogram accumulation circuit module. The linear SVM classification algorithm producing a number of necessary weak classifiers is combined with Adaboost algorithm to establish a strong classifier. The human detection is successfully implemented on a portable embedded platform to reduce the system cost and size. Experimental result shows that the performance error of accuracy appears merely about 0.1-0.4% in comparison between the presented FPGA based HW/SW co-design and the PC based pure software. Meanwhile, the computing speed achieves the requirement of a real-time embedded system, 15 fps. (C) 2015 Elsevier B.V. All rights reserved.
C1 [Hsiao, Pei-Yung; Lin, Shih-Yu] Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
   Natl Kaohsiung First Univ Sci & Technol, Dept Comp & Commun Engn, Kaohsiung, Taiwan.
RP Hsiao, PY (corresponding author), Natl Univ Kaohsiung, Dept Elect Engn, Kaohsiung, Taiwan.
EM pyhsiao@nuk.edu.tw
CR Anguita D, 2003, IEEE T NEURAL NETWOR, V14, P993, DOI 10.1109/TNN.2003.816033
   [Anonymous], 2009, INTELLIGENT INFORM H, DOI [10.1109/IIH-MSP.2009.216, DOI 10.1109/IIH-MSP.2009.216]
   Bauer S., 2009, P MPC WORKSHOP, P49
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Fan RE, 2008, J MACH LEARN RES, V9, P1871
   Gerónimo D, 2010, IEEE T PATTERN ANAL, V32, P1239, DOI 10.1109/TPAMI.2009.122
   Gokhan K.G., 2013, MICROPROCESS MICROSY, V37, P270
   Hsiao P.Y., 2006, IEE P-COMPUT DIG T, V153, P1871
   Zhu Q., 2006, IEEE COMP SOC C COMP, V2, P1491, DOI DOI 10.1109/CVPR.2006.119
NR 10
TC 17
Z9 18
U1 0
U2 6
PD APR 20
PY 2015
VL 138
BP 42
EP 46
DI 10.1016/j.mee.2015.01.018
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Das, IJ
   Morales, J
   Francescon, P
AF Das, Indra J.
   Morales, Johnny
   Francescon, Paolo
BE MassillonJL, G
   Fossion, R
   RosadoMendez, IM
   AvilaRodriguez, MA
   LopezPerez, DA
TI Small Field Dosimetry: What Have We Learnt?
SO MEDICAL PHYSICS: FOURTEENTH MEXICAN SYMPOSIUM ON MEDICAL PHYSICS
SE AIP Conference Proceedings
DT Proceedings Paper
CT 14th Mexican Symposium on Medical Physics
CY MAR 18-21, 2016
CL Mexico City, MEXICO
ID SIMULATED CORRECTION FACTORS; OUTPUT FACTOR MEASUREMENT; DETECTOR
   DOSE-RESPONSE; TOTAL SCATTER FACTORS; FOCAL SPOT SIZE; MONTE-CARLO;
   PHOTON FIELDS; RELATIVE DOSIMETRY; RADIOSURGERY SYSTEM;
   LINEAR-ACCELERATOR
AB Small field x-ray beam dosimetry is difficult due to a number of challenges that include a lack of lateral electronic equilibrium, source occlusion, high dose gradients, and detector volume averaging. This has become more apparent with a rapid increase in the number of treatment machines that deliver small x-ray fields which are used for precision radiotherapy techniques such as stereotactic radiosurgery (SRS) and SBRT. A large body of literature is now in small fields, but with a lot of contradiction. There is also a large collection of micro-detectors that are being advocated for dosimetry. This review provides an update on small field dosimetry, recommendations for measurements and updates on recent commercial detectors on the market. It is recommended that detectors that are small volume and tissue equivalent are best suited for small field dosimetry which are plastic scintillators, synthetic diamond detectors and possibly Gafchromic films.
C1 [Das, Indra J.] NYU, Langone Med Ctr, Dept Radiat Oncol, 160 East,34th St, New York, NY 10016 USA.
   [Morales, Johnny] Chris OBrien Lifehouse, Dept Radiat Oncol, Missenden Rd, Camperdown, NSW 2050, Australia.
   [Francescon, Paolo] Osped Vicenza, Dept Radiat Oncol, Viale Rodolfi, I-36100 Vicenza, Italy.
RP Das, IJ (corresponding author), NYU, Langone Med Ctr, Dept Radiat Oncol, 160 East,34th St, New York, NY 10016 USA.
EM indra.das@nyumc.org; johnny.morales@lh.org.au;
   paolo.francescon@ulssvicenza.it
CR Alfonso R, 2008, MED PHYS, V35, P5179, DOI 10.1118/1.3005481
   Almond PR, 1999, MED PHYS, V26, P1847, DOI 10.1118/1.598691
   [Anonymous], 2013, MED PHYS, DOI DOI 10.1118/1.4814982
   Araki F, 2006, MED PHYS, V33, P2955, DOI 10.1118/1.2219774
   Azangwe G, 2014, MED PHYS, V41, DOI 10.1118/1.4883795
   Bassinet C, 2013, MED PHYS, V40, DOI 10.1118/1.4811139
   Beddar A.S., 2009, CLIN DOSIMETRY MEASU, P891
   Benmakhlouf H, 2015, PHYS MED BIOL, V60, P3959, DOI 10.1088/0031-9155/60/10/3959
   Benmakhlouf H, 2014, MED PHYS, V41, DOI 10.1118/1.4868695
   Bogdanich W, 2010, NY TIMES
   Bouchard H, 2004, MED PHYS, V31, P2454, DOI 10.1118/1.1781333
   Bouchard H, 2015, MED PHYS, V42, P6048, DOI 10.1118/1.4930798
   Bouchard H, 2015, MED PHYS, V42, P6033, DOI 10.1118/1.4930053
   Bouchard H, 2012, PHYS MED BIOL, V57, P3333, DOI 10.1088/0031-9155/57/11/3333
   Bouchard H, 2012, MED PHYS, V39, P1473, DOI 10.1118/1.3684952
   Bouchard H, 2011, PHYS MED BIOL, V56, P2617, DOI 10.1088/0031-9155/56/8/018
   Bouchard H, 2009, MED PHYS, V36, P4654, DOI 10.1118/1.3213518
   Chalkley A, 2014, BRIT J RADIOL, V87, DOI 10.1259/bjr.20130768
   Cranmer-Sargison G, 2013, PHYS MED BIOL, V58, P7343, DOI 10.1088/0031-9155/58/20/7343
   Cranmer-Sargison G, 2011, MED PHYS, V38, P6592, DOI 10.1118/1.3658572
   Cranmer-Sargison G, 2011, RADIOTHER ONCOL, V100, P429, DOI 10.1016/j.radonc.2011.09.002
   Czarnecki D, 2012, METROLOGIA, V49, pS215, DOI 10.1088/0026-1394/49/5/S215
   Das I.J., MED PHYS IN PRESS
   Das I J, 2000, J RADIOSURG, V3, P177, DOI DOI 10.1023/A:1009594509115
   Das IJ, 1996, RADIOTHER ONCOL, V38, P61, DOI 10.1016/0167-8140(95)01674-0
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Das IJ, 2008, MED PHYS, V35, P206, DOI 10.1118/1.2815356
   Dieterich S, 2011, MED PHYS, V38, P4166, DOI 10.1118/1.3592647
   Fenwick JD, 2013, PHYS MED BIOL, V58, P2901, DOI 10.1088/0031-9155/58/9/2901
   Francescon P, 2014, PHYS MED BIOL, V59, pN11, DOI 10.1088/0031-9155/59/6/N11
   Francescon P, 2012, PHYS MED BIOL, V57, P3741, DOI 10.1088/0031-9155/57/12/3741
   Francescon P, 2011, MED PHYS, V38, P6513, DOI 10.1118/1.3660770
   Francescon P, 2008, MED PHYS, V35, P504, DOI 10.1118/1.2828195
   Francescon P, 2014, MED PHYS, V41, DOI 10.1118/1.4895978
   Francescon P, 2009, J APPL CLIN MED PHYS, V10, P147, DOI 10.1120/jacmp.v10i1.2939
   Gago-Arias A, 2013, MED PHYS, V40, DOI 10.1118/1.4773047
   Gambaccini M, 2011, NUCL INSTRUM METH B, V269, P1157, DOI 10.1016/j.nimb.2011.02.089
   García-Garduño OA, 2014, MED PHYS, V41, DOI 10.1118/1.4892176
   IAEA, 2000, TECHN REP SER IAEA
   Kamio Y, 2014, PHYS MED BIOL, V59, P4973, DOI 10.1088/0031-9155/59/17/4973
   Kumar S, 2015, PHYS MED BIOL, V60, P8187, DOI 10.1088/0031-9155/60/20/8187
   Lárraga-Gutiérrez JM, 2012, MED PHYS, V39, P6111, DOI 10.1118/1.4752211
   Liu PZY, 2014, RADIOTHER ONCOL, V112, P442, DOI 10.1016/j.radonc.2014.08.009
   LUTZ WR, 1988, MED PHYS, V15, P614, DOI 10.1118/1.596214
   Mancosu P, 2015, MED PHYS, V42, P5035, DOI 10.1118/1.4927569
   Moignier C, 2014, MED PHYS, V41, DOI 10.1118/1.4881098
   Morales JE, 2014, MED PHYS, V41, DOI 10.1118/1.4895827
   Morin J, 2013, MED PHYS, V40, DOI 10.1118/1.4772190
   MUNRO P, 1988, MED PHYS, V15, P517, DOI 10.1118/1.596295
   Pantelis E, 2008, MED PHYS, V35, P2312, DOI 10.1118/1.2919099
   Papaconstadopoulos P, 2014, PHYS MED BIOL, V59, P5937, DOI 10.1088/0031-9155/59/19/5937
   Sauer OA, 2007, MED PHYS, V34, P1983, DOI 10.1118/1.2734383
   Scott AJD, 2009, MED PHYS, V36, P3132, DOI 10.1118/1.3152866
   Sham E, 2008, MED PHYS, V35, P3317, DOI 10.1118/1.2936335
   Sterpin E, 2012, MED PHYS, V39, P4066, DOI 10.1118/1.4722752
   Sterpin E, 2010, RADIOTHER ONCOL, V94, P229, DOI 10.1016/j.radonc.2009.12.018
   Tyler M, 2013, PHYS MED BIOL, V58, P7595, DOI 10.1088/0031-9155/58/21/7595
   Underwood TSA, 2015, PHYS MED BIOL, V60, P6669, DOI 10.1088/0031-9155/60/17/6669
   Wang LLW, 2007, MED PHYS, V34, P485, DOI 10.1118/1.2426407
   Wilcox EE, 2007, MED PHYS, V34, P1967, DOI 10.1118/1.2734384
NR 60
TC 21
Z9 21
U1 0
U2 10
PY 2016
VL 1747
AR 060001
DI 10.1063/1.4954111
WC Biophysics; Physics, Applied; Radiology, Nuclear Medicine & Medical
   Imaging
DA 2023-11-11
ER

PT C
AU Nosova, S
   Norkina, A
   Medvedeva, O
   Abramov, A
   Makar, S
   Lozik, N
   Fadeicheva, G
AF Nosova, Svetlana
   Norkina, Anna
   Medvedeva, Olga
   Abramov, Andrey
   Makar, Svetlana
   Lozik, Nina
   Fadeicheva, Galina
BE Klimov, VV
   Kelley, DJ
TI Artificial Intelligence Technology as an Economic Accelerator of
   Business Process
SO BIOLOGICALLY INSPIRED COGNITIVE ARCHITECTURES 2021
SE Studies in Computational Intelligence
DT Proceedings Paper
CT 12th Annual International Conference of the
   Biologically-Inspired-Cognitive-Architectures-Society (BICA) on
   Biologically Inspired Cognitive Architectures
CY SEP 12-19, 2021
CL ELECTR NETWORK
DE Artificial intelligence; Digital economy; Business processes; Strategy
AB The article covers a range of problems related to the need to use artificial intelligence (AI) technology, on the one hand, as an economic accelerator of business processes in conditions of high competition in the global market, and as conditions for the growth of the economy as a whole. The main purpose of the article is to prove the feasibility of developing a conceptual framework that reveals the value of AI technology in areas such as probabilistic thinking, machine learning and computer vision to help managers better understand how promising achievements can be achieved that can eliminate some limitations in business growth and create a new wave of opportunities in the socio-economic development of the country. The results of the study confirmed that AI technology: firstly, helps to create an innovative product, better serve customers, allocate employees to solve more creative tasks, reduce costs and get high results; secondly, it gives a clear incentive to its developers, companies, politicians and users to solve the socio-economic problems facing them; thirdly, removes restrictions in obtaining massive datasets based on global cooperation in the field of digital transformation. An assessment of the possibility of using the experience of AI technology development in advanced countries has been proposed and a number of measures have been developed to adapt the development of foreign AI technology to meet the requirements of the national program of the digital economy of Russia in response to the COVID-19 pandemic.
C1 [Nosova, Svetlana; Norkina, Anna] Natl Res Nucl Univ MEPHI, Kashirskoe Shossestr 31, Moscow 115409, Russia.
   [Medvedeva, Olga; Abramov, Andrey] State Univ Management, Ryazansky Prospektstr 99, Moscow 109542, Russia.
   [Makar, Svetlana; Lozik, Nina] Financial Univ Govt Russian Federat, Leningradsky Prospectstr 49, Moscow 125599, Russia.
   [Fadeicheva, Galina] Acad Lab & Social Relat, Lobachevskystr 90, Moscow 119454, Russia.
RP Nosova, S (corresponding author), Natl Res Nucl Univ MEPHI, Kashirskoe Shossestr 31, Moscow 115409, Russia.
EM SSNosova@mephi.ru
CR Abercrombie C., 2017, ACCELERATING ENTERPR
   Agrawal A, 2017, MIT SLOAN MANAGE REV, V58, P23
   [Anonymous], NATL STRATEGY DEV AR
   [Anonymous], 2017, CNBC
   [Anonymous], 2020, KEY INDICATORS THERU
   [Anonymous], 2021, RUSSIA GLOBAL POLITI, V2, DOI [10.31278/1810-6439-2021-19-2-106-119, DOI 10.31278/1810-6439-2021-19-2-106-119]
   Bataller C., 2016, TODAY
   Brock JKU, 2019, CALIF MANAGE REV, V61, P110, DOI 10.1177/1536504219865226
   Brynjolfsson E., 2017, HARVARD BUSINESS REV, P3
   Brynjolfsson E, 2017, SCIENCE, V358, P1530, DOI 10.1126/science.aap8062
   Chui M., 2018, MCKINSEY GLOBAL I
   Chui M., 2018, MCKIN Q
   Gillham J., 2018, MACROECONOMIC IMPACT
   Gouvernement Artificial intelligence, 2018, MAK FRANC LEAD
   High-Level Expert Group on Artificial Intelligence, 2019, ETH GUID TRUSTW AI
   Huang MH, 2019, CALIF MANAGE REV, V61, P43, DOI 10.1177/0008125619863436
   Huang MH, 2018, J SERV RES-US, V21, P155, DOI 10.1177/1094670517752459
   Jordan MI, 2015, SCIENCE, V349, P255, DOI 10.1126/science.aaa8415
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Leitch J., 2016, LEADERSHIP-LONDON
   Nosova S., 2021, PROCEDIA COMPUT SCI, V190, P651, DOI [10.1016/j.procs.2021.06.076, DOI 10.1016/J.PROCS.2021.06.076]
   Nosova S.S., 2018, ESPACIOS, V39, P11
   Nosova S.S., 2021, FUNDAMENTALS DIGITAL, P378
   Nosova S.S., 2019, EC ENTREPRENEURSHIP, V13, P1204
   Nosova Svetlana, 2021, PROCEDIA COMPUT SCI, V190, P657, DOI [10.1016/j.procs.2021.06.077, DOI 10.1016/J.PROCS.2021.06.077]
   Russell S, 2010, ARTIF INTELL, V3rd
   Samsonovich A.V., 2016, SCI VERGE CREATING E
NR 27
TC 1
Z9 1
U1 5
U2 6
PY 2022
VL 1032
BP 355
EP 366
DI 10.1007/978-3-030-96993-6_39
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Golcarenarenji, G
   Martinez-Alpiste, I
   Wang, Q
   Alcaraz-Calero, JM
AF Golcarenarenji, Gelayol
   Martinez-Alpiste, Ignacio
   Wang, Qi
   Alcaraz-Calero, Jose Maria
TI Robust real-time traffic light detector on small-form platform for
   autonomous vehicles
SO JOURNAL OF INTELLIGENT TRANSPORTATION SYSTEMS
DT Article; Early Access
DE Autonomous vehicle; computer vision; modified YOLO; traffic light
   detection
ID RECOGNITION; NETWORK
AB Timely and accurate detection and recognition of traffic lights are critical for Autonomous Vehicles (AVs) to avoid crashes due to red light running. This paper integrates a new robust machine learning based solution by combining a Convolutional Neural Network (CNN) with computer vision techniques to achieve a real-time traffic light detector. The proposed detection and recognition algorithm is capable of recognizing traffic lights on low-power small-form platforms, which are lightweight, portable, and can be mounted on AVs in daylight scenarios. The LISA open-source dataset is utilized with augmentation methods to increase the accuracy of the solution. The proposed approach achieves 93.42% of accuracy at a speed of 30.01 Frames Per Second (FPS) on an NVIDIA Jetson Xavier platform without using hardware accelerators such as FPGA. This solution is expected to promote the quicker adoption and wider deployment of AVs by increasing the chances of avoiding crashes and ultimately saving lives.
C1 [Golcarenarenji, Gelayol; Martinez-Alpiste, Ignacio; Wang, Qi; Alcaraz-Calero, Jose Maria] Univ West Scotland, Sch Comp Engn & Phys Sci, Paisley, Scotland.
   [Golcarenarenji, Gelayol] Univ Portsmouth, Sch Comp, Portsmouth, England.
   [Golcarenarenji, Gelayol] Univ West Scotland, Sch Comp Engn & Phys Sci, High St, Paisley, Scotland.
RP Golcarenarenji, G (corresponding author), Univ West Scotland, Sch Comp Engn & Phys Sci, High St, Paisley, Scotland.
EM gollygolkar@gmail.com
CR Alexey, 2017, YOLOMARK
   Alexey, 2020, DARKNET
   Binangkit J.L., 2016, 10 INT C TEL SYST SE, P1, DOI DOI 10.1109/TSSA.2016.7871074
   Bochkovskiy A., 2020, PREPRINT
   Chen XF, 2021, J INTELL TRANSPORT S, V25, P533, DOI 10.1080/15472450.2021.1871611
   Chen ZL, 2016, IEEE INTEL TRANSP SY, V8, P28, DOI 10.1109/MITS.2016.2605381
   Dai JF, 2016, Arxiv, DOI [arXiv:1605.06409, DOI 10.48550/ARXIV.1605.06409]
   Fernández C, 2018, IEEE INT C INTELL TR, P248, DOI 10.1109/ITSC.2018.8569914
   Girshick R, 2015, IEEE I CONF COMP VIS, P1440, DOI 10.1109/ICCV.2015.169
   Gouda M, 2023, J INTELL TRANSPORT S, V27, P643, DOI 10.1080/15472450.2022.2074792
   He WP, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9163225
   Hirabayashi M, 2019, ROBOT AUTON SYST, V111, P62, DOI 10.1016/j.robot.2018.10.004
   IIHS, 2012, RED LIGHT RUNNING
   INRIA's project-team IMARA Mines ParisTech's CAOR, 2009, TRAFFIC LIGHT RECOGN
   Jensen MB, 2017, IEEE COMPUT SOC CONF, P882, DOI 10.1109/CVPRW.2017.122
   John V, 2014, 2014 IEEE 17TH INTERNATIONAL CONFERENCE ON INTELLIGENT TRANSPORTATION SYSTEMS (ITSC), P2286, DOI 10.1109/ITSC.2014.6958056
   John V, 2016, 2016 ASIA-PACIFIC CONFERENCE ON INTELLIGENT ROBOT SYSTEMS (ACIRS 2016), P204, DOI 10.1109/ACIRS.2016.7556213
   Ju MR, 2019, IEEE ACCESS, V7, P85771, DOI 10.1109/ACCESS.2019.2924960
   Kim HK, 2018, J ADV TRANSPORT, DOI 10.1155/2018/2365414
   Kim J, 2018, IEEE INT C INTELL TR, P280, DOI 10.1109/ITSC.2018.8569575
   Kohavi R., 1995, P 14 INT JOINT C ART, P5
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu W, 2016, LECT NOTES COMPUT SC, V9905, P21, DOI 10.1007/978-3-319-46448-0_2
   Loshchilov I., 2017, 5 INT C LEARNING REP, P1
   Martinez-Alpiste I, 2019, IEEE WCNC
   Martinez-Alpiste I, 2020, J FIELD ROBOT, V37, P404, DOI 10.1002/rob.21921
   Mogelmose A, 2012, IEEE T INTELL TRANSP, V13, P1484, DOI 10.1109/TITS.2012.2209421
   Müller J, 2018, IEEE INT C INTELL TR, P266, DOI 10.1109/ITSC.2018.8569683
   Oliveira-Santos, 2019, P 2019 INT JOINT C N, P1
   Ou Yangze, 2022, Proceedings of the 12th International Conference on Computer Engineering and Networks. Lecture Notes in Electrical Engineering (961), P1354, DOI 10.1007/978-981-19-6901-0_143
   Ouyang ZC, 2020, IEEE T MOBILE COMPUT, V19, P300, DOI 10.1109/TMC.2019.2892451
   Ozcelik Z, 2017, 2017 INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND ENGINEERING (UBMK), P424, DOI 10.1109/UBMK.2017.8093430
   Pon AD, 2018, 2018 15TH CONFERENCE ON COMPUTER AND ROBOT VISION (CRV), P102, DOI 10.1109/CRV.2018.00024
   Redmon J., 2018, ARXIV, DOI DOI 10.48550/ARXIV.1804.02767
   Redmon J, 2017, PROC CVPR IEEE, P6517, DOI 10.1109/CVPR.2017.690
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Saini S, 2017, IEEE INT VEH SYM, P606, DOI 10.1109/IVS.2017.7995785
   Tsai MY, 2022, 2022 IEEE 31ST INTERNATIONAL SYMPOSIUM ON INDUSTRIAL ELECTRONICS (ISIE), P594, DOI 10.1109/ISIE51582.2022.9831510
   Vaidya B., 2019, P COMPUTER VISION IM, P82
   Van Etten A, 2018, Arxiv, DOI [arXiv:1805.09512, DOI 10.48550/ARXIV.1805.09512]
   Wang C.Y., 2022, ARXIV
   Wang CY, 2019, IEEE INT CONF COMP V, P2477, DOI 10.1109/ICCVW.2019.00303
   Weber M, 2018, IEEE INT C INTELL TR, P255, DOI 10.1109/ITSC.2018.8569794
   Weber M, 2016, IEEE INT VEH SYM, P342, DOI 10.1109/IVS.2016.7535408
   Yudin D, 2018, MEDD C EMBED COMPUT, P242
NR 46
TC 0
Z9 0
U1 11
U2 11
PD 2023 APR 24
PY 2023
DI 10.1080/15472450.2023.2205018
EA APR 2023
WC Transportation; Transportation Science & Technology
DA 2023-11-11
ER

PT C
AU Miro-Panades, I
   Tain, B
   Christmann, JF
   Coriat, D
   Lemaire, R
   Jany, C
   Martineau, B
   Chaix, F
   Quelen, A
   Pluchart, E
   Noel, JP
   Boumchedda, R
   Makosiej, A
   Montoya, M
   Bacles-Min, S
   Briand, D
   Philippe, JM
   Valentian, A
   Heitzmann, F
   Beigne, E
   Clermidy, F
AF Miro-Panades, Ivan
   Tain, Benoit
   Christmann, Jean-Frederic
   Coriat, David
   Lemaire, Romain
   Jany, Clement
   Martineau, Baudouin
   Chaix, Fabrice
   Quelen, Anthony
   Pluchart, Emmanuel
   Noel, Jean-Philippe
   Boumchedda, Reda
   Makosiej, Adam
   Montoya, Maxime
   Bacles-Min, Simone
   Briand, David
   Philippe, Jean-Marc
   Valentian, Alexandre
   Heitzmann, Frederic
   Beigne, Edith
   Clermidy, Fabien
GP IEEE
TI SamurAI: a 1.7MOPS-36GOPS Adaptive Versatile IoT Node with 15,000x
   Peak-to-Idle Power Reduction, 207ns Wake-up Time and 1.3TOPS/W ML
   Efficiency
SO 2020 IEEE SYMPOSIUM ON VLSI CIRCUITS
SE Symposium on VLSI Circuits-Digest of Papers
DT Proceedings Paper
CT IEEE Symposium on VLSI Circuits
CY JUN 15-19, 2020
CL ELECTR NETWORK
AB IoT node application requirements are torn between sporadic data-logging and energy-hungry data processing (e.g. image classification). This paper presents a versatile IoT node covering this gap in processing and energy by leveraging two on-chip sub-systems: a low power, clock-less, event-driven Always-Responsive (AR) part and an energy-efficient On-Demand (OD) part. The AR contains a 1.7MOPS event-driven, asynchronous Wake-up Controller (WuC) with 207ns wake-up time optimized for short sporadic computing. OD combines a deep-sleep RISC-V CPU and 1.3TOPS/W Machine Learning (ML) and crypto accelerators for more complex tasks. The node can perform up to 36GOPS while achieving 15,000x reduction from peak-to-idle power consumption. The interest of this versatile architecture is demonstrated with 105 mu W daily average power on an applicative classification scenario.
C1 [Miro-Panades, Ivan; Christmann, Jean-Frederic; Coriat, David; Lemaire, Romain; Pluchart, Emmanuel; Noel, Jean-Philippe; Bacles-Min, Simone; Valentian, Alexandre; Clermidy, Fabien] Univ Grenoble Alpes, LIST, CEA, Grenoble, France.
   [Tain, Benoit; Briand, David; Philippe, Jean-Marc] Univ Paris Saclay, LIST, CEA, Gif Sur Yvette, France.
   [Jany, Clement; Martineau, Baudouin; Chaix, Fabrice; Quelen, Anthony; Boumchedda, Reda; Makosiej, Adam; Montoya, Maxime; Heitzmann, Frederic; Beigne, Edith] Univ Grenoble Alpes, LETI, CEA, Grenoble, France.
   [Boumchedda, Reda] STMicroelectronics, Crolles, France.
RP Miro-Panades, I (corresponding author), Univ Grenoble Alpes, LIST, CEA, Grenoble, France.
EM ivan.miro-panades@cea.fr
CR Bang S., 2017, ISSCC
   Boumchedda R., 2018, L SSC
   Carbon A., 2018, DATE
   Christmann J.-F., 2019, JLPEA
   Lallement G., 2018, JSSC
   Myers J., 2016, JSSC
   Paul S., 2017, JSSC
   Pletcher N. M., 2008, ISSCC
   Pu Yu, 2018, JSSC
   Pullini A., 2019, JSSC
NR 10
TC 11
Z9 11
U1 0
U2 0
PY 2020
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Vandebon, J
   Coutinho, JGF
   Luk, W
   Nurvitadhi, E
   Naik, M
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
   Nurvitadhi, Eriko
   Naik, Mishali
BE Hannig, F
   Navaridas, J
   Koch, D
   Abdelhadi, A
TI SLATE: Managing Heterogeneous Cloud Functions
SO 2020 IEEE 31ST INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2020)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 31st IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 06-08, 2020
CL Univ Manchester, Dept Comp Sci, Manchester, ENGLAND
HO Univ Manchester, Dept Comp Sci
AB This paper presents SLATE, a fully-managed, heterogeneous Function-as-a-Service (FaaS) system for deploying serverless functions onto heterogeneous cloud infrastructures. We extend the traditional homogeneous FaaS execution model to support heterogeneous functions, automating and abstracting runtime management of heterogeneous compute resources in order to improve cloud tenant accessibility to specialised, accelerator resources, such as FPGAs and GPUs. In particular, we focus on the mechanisms required for heterogeneous scaling of deployed function instances to guarantee latency objectives while minimising cost. We develop a simulator to validate and evaluate our approach, considering case-study functions in three application domains: machine learning, bio-informatics, and physics. We incorporate empirically derived performance models for each function implementation targeting a hardware platform with combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to homogeneous CPU and homogeneous FPGA functions, simulation results achieve respectively a cost improvement for non-uniform task traffic of up to 8.7 times and 1.7 times, while maintaining specified latency objectives.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
   [Nurvitadhi, Eriko; Naik, Mishali] Intel Corp, San Jose, CA USA.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk; eriko.nurvitadhi@intel.com; mishali.naik@intel.com
CR Amazon Web Services, AMAZON EC2
   Amazon Web Services, AWS LAMBDA SERVERLES
   Apache Software Foundation, OPEN SOURCE SERVERLE
   Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Asiatici M, 2017, IEEE ACCESS, V5, P1900, DOI 10.1109/ACCESS.2017.2661582
   Google Cloud Platform, CLOUD FUNCTIONS
   Graepel Thore, 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Kubeless, KUBERNETES NATIVE SE
   Maxeler, 2015, N BODY PARTICLE SIMU
   Mbongue JM, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P862, DOI 10.1109/CLOUD.2018.00122
   Microsoft Azure, AZURE FUNCTIONS SERV
   Vandebon J, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P162, DOI 10.1109/ICFPT47387.2019.00027
NR 12
TC 2
Z9 2
U1 0
U2 1
PY 2020
BP 141
EP 148
DI 10.1109/ASAP49362.2020.00032
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Riera, M
   Arnau, JM
   González, A
AF Riera, Marc
   Arnau, Jose Maria
   Gonzalez, Antonio
TI CREW: Computation reuse and efficient weight storage for
   hardware-accelerated MLPs and RNNs
SO JOURNAL OF SYSTEMS ARCHITECTURE
DT Article
DE Machine learning; Deep neural networks; Computation reuse; Accelerators;
   Low energy
ID NEURAL-NETWORKS
AB Deep Neural Networks (DNNs) have achieved tremendous success for cognitive applications. The core operation in a DNN is the dot product between quantized inputs and weights. Prior works exploit the weight/input repetition that arises due to quantization to avoid redundant computations in Convolutional Neural Networks (CNNs). However, in this paper we show that their effectiveness is severely limited when applied to FullyConnected (FC) layers, which are commonly used in state-of-the-art DNNs, as it is the case of modern Recurrent Neural Networks (RNNs) and Transformer models. To improve energy-efficiency of FC computation we present CREW, a hardware accelerator that implements Computation Reuse and an Efficient Weight Storage mechanism to exploit the large number of repeated weights in FC layers. CREW first performs the multiplications of the unique weights by their respective inputs and stores the results in an on-chip buffer. The storage requirements are modest due to the small number of unique weights and the relatively small size of the input compared to convolutional layers. Next, CREW computes each output by fetching and adding its required products. To this end, each weight is replaced offline by an index in the buffer of unique products. Indices are typically smaller than the quantized weights, since the number of unique weights for each input tends to be much lower than the range of quantized weights, which reduces storage and memory bandwidth requirements. Overall, CREW greatly reduces the number of multiplications and provides significant savings in model memory footprint and memory bandwidth usage. We evaluate CREW on a diverse set of modern DNNs. On average, CREW provides 2.61x speedup and 2.42x energy savings over a TPU-like accelerator. Compared to UCNN, a state-of-art computation reuse technique, CREW achieves 2.10x speedup and 2.08x energy savings on average.
C1 [Riera, Marc; Arnau, Jose Maria; Gonzalez, Antonio] Univ Politecn Catalunya UPC, Barcelona, Spain.
RP Riera, M (corresponding author), Univ Politecn Catalunya UPC, Barcelona, Spain.
EM mriera@ac.upc.edu
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Amodei D, 2016, PR MACH LEARN RES, V48
   Bahdanau D, 2016, Arxiv, DOI arXiv:1409.0473
   Chatterjee Rajen, 2016, P WMT, V2, P131, DOI DOI 10.18653/V1/W16-2301
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cho K., 2014, P 19 C EMPIRICAL MET, P1, DOI [10.3115/v1/D14-1179, DOI 10.3115/V1/D14-1179, 10.3115]
   Tran D, 2015, IEEE I CONF COMP VIS, P4489, DOI 10.1109/ICCV.2015.510
   Garland J, 2018, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3233300
   Gong YC, 2014, LECT NOTES COMPUT SC, V8695, P392, DOI 10.1007/978-3-319-10584-0_26
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hegde K, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P933, DOI [10.1109/MICR0.2018.00080, 10.1109/MICRO.2018.00080]
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Imani M, 2020, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA47549.2020.00011
   Jiao X, 2018, DES AUT TEST EUROPE, P1223, DOI 10.23919/DATE.2018.8342202
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuchaiev O, 2018, NLP OPEN SOURCE SOFTWARE (NLP-OSS), P41
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   KUNG SY, 1989, J PARALLEL DISTR COM, V6, P358, DOI 10.1016/0743-7315(89)90065-8
   Li S, 2011, ICCAD-IEEE ACM INT, P694, DOI 10.1109/ICCAD.2011.6105405
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Luong M.T., 2015, P 2015 C EMP METH NA, P1412, DOI DOI 10.18653/V1/D15-1166
   Micron, 2001, MICR LPDDR4 SYST POW
   Mittal S, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.102041
   Moolchandani D, 2021, J SYST ARCHITECT, V113, DOI 10.1016/j.sysarc.2020.101887
   Ning L, 2019, INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS 2019), P438, DOI 10.1145/3330345.3330384
   Panayotov V, 2015, INT CONF ACOUST SPEE, P5206, DOI 10.1109/ICASSP.2015.7178964
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Paszke A, 2019, ADV NEUR IN, V32
   Pattanayak S, 2021, J SYST ARCHITECT, V116, DOI 10.1016/j.sysarc.2021.102031
   Povey D., 2011, IEEE 2011 WORKSHOP A, P1
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Riera M, 2022, J SYST ARCHITECT, V122, DOI 10.1016/j.sysarc.2021.102336
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Samajdar Ananda, 2018, ARXIV
   Synopsys, 1986, SYN DES COMP DES LIB
   Vaswani A, 2017, ADV NEUR IN, V30
   Widrow B, 1996, IEEE T INSTRUM MEAS, V45, P353, DOI 10.1109/19.492748
   Wu Y., 2016, ARXIV
   Xia M, 2021, J SYST ARCHITECT, V115, DOI 10.1016/j.sysarc.2021.101991
   Yasoubi A, 2017, IEEE COMPUT ARCHIT L, V16, P72, DOI 10.1109/LCA.2016.2521654
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zaremba W., 2014, PREPRINT
   Zhang DQ, 2018, LECT NOTES COMPUT SC, V11212, P373, DOI 10.1007/978-3-030-01237-3_23
   Zhang JJ, 2015, IEEE INTELL SYST, V30, P16, DOI 10.1109/MIS.2015.69
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhang XH, 2014, INT CONF ACOUST SPEE
   Zhou A, 2017, ARXIV
   Zhou S., 2016, ARXIV
   Zhu C., 2017, P INT C LEARN REPR I
NR 54
TC 0
Z9 0
U1 0
U2 0
PD AUG
PY 2022
VL 129
AR 102604
DI 10.1016/j.sysarc.2022.102604
EA JUN 2022
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Shin, G
   Kim, J
   Kim, JY
AF Shin, Gyeongcheol
   Kim, Junsoo
   Kim, Joo-Young
TI OpenMDS: An Open-Source Shell Generation Framework for High-Performance
   Design on Xilinx Multi-Die FPGAs
SO IEEE COMPUTER ARCHITECTURE LETTERS
DT Article
DE Field programmable gate arrays; Kernel; Hardware; Pipeline processing;
   Timing; Routing; Registers; FPGA; shell; design automation; open-source;
   high-performance design; multi-die FPGA
AB FPGA is a promising platform in designing hardware due to its design flexibility and fast development cycle, despite the device's limited hardware resources. To address this, latest FPGAs have adopted a multi-die architecture that employs multiple dies in a single device to provide abundant hardware resources. However, the multi-die architecture causes critical timing issues when signal paths cross the die-to-die boundaries, adding another design challenge in using FPGA. We propose OpenMDS, an open-source shell generation framework for high-performance design on Xilinx multi-die FPGAs. Based on the user's design requirements, it generates an optimized shell for the target FPGA via die-level kernel encapsulation, automated bus pipelining, and customized floorplanning. To evaluate our shell generation, we compare its implementation results against Xilinx's Vitis framework. As a result, OpenMDS uses average 20% less logic resources than Vitis for the same shell functionality. To show its practicality, we use OpenMDS for the design of machine learning accelerator that contains multiple systolic-array processors. OpenMDS achieves 247MHz and 235MHz kernel frequency and 400MHz and 429MHz memory bus frequency for U50 and U280, respectively, for the accelerator design over 90% logic utilization, claiming up to 12.27% and 22.92% higher kernel and memory bus frequency over Vitis.
C1 [Shin, Gyeongcheol; Kim, Junsoo; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
RP Kim, JY (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon 34141, South Korea.
EM skc228@kaist.ac.kr; junsoo999@kaist.ac.kr; jooyoung1203@kaist.ac.kr
CR [Anonymous], AMAZON EC2 F1 INSTAN
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Dua A, 2020, ANN IEEE SYM FIELD P, P231, DOI 10.1109/FCCM48280.2020.00064
   Hao C, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317829
   Kathail V, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P173, DOI 10.1145/3373087.3375887
   Licheng Guo, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P81, DOI 10.1145/3431920.3439289
   Nasiri E, 2016, IEEE T VLSI SYST, V24, P1821, DOI 10.1109/TVLSI.2015.2478280
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Voss N, 2019, ANN IEEE SYM FIELD P, P78, DOI 10.1109/FCCM.2019.00021
   Yang Q, 2019, ACM T INTEL SYST TEC, V10, DOI 10.1145/3298981
NR 10
TC 0
Z9 0
U1 0
U2 0
PD JUL-DEC
PY 2022
VL 21
IS 2
BP 101
EP 104
DI 10.1109/LCA.2022.3202016
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Zhang, YC
   Yasaei, R
   Chen, H
   Li, Z
   Al Faruque, MA
AF Zhang, Yicheng
   Yasaei, Rozhin
   Chen, Hao
   Li, Zhou
   Al Faruque, Mohammad Abdullah
TI Stealing Neural Network Structure Through Remote FPGA Side-Channel
   Analysis
SO IEEE TRANSACTIONS ON INFORMATION FORENSICS AND SECURITY
DT Article
DE Field programmable gate arrays; Cloud computing; Computational modeling;
   Analytical models; Integrated circuit modeling; Hardware; Inverters;
   Deep neural network; cloud FPGA; side-channel analysis; hardware trojan
ID ATTACKS
AB Deep Neural Network (DNN) models have been extensively developed by companies for a wide range of applications. The development of a customized DNN model with great performance requires costly investments, and its structure (layers and hyper-parameters) is considered intellectual property and holds immense value. However, in this paper, we found the model secret is vulnerable when a cloud-based FPGA accelerator executes it. We demonstrate an end-to-end attack based on remote power side-channel analysis and machine-learning-based secret inference against different DNN models. The evaluation result shows that an attacker can reconstruct the layer and hyper-parameter sequence at over 90% accuracy using our method, which can significantly reduce her model development workload. We believe the threat presented by our attack is tangible, and new defense mechanisms should be developed against this threat.
C1 [Zhang, Yicheng; Yasaei, Rozhin; Chen, Hao; Li, Zhou; Al Faruque, Mohammad Abdullah] Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92617 USA.
RP Zhang, YC (corresponding author), Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92617 USA.
EM yichez16@uci.edu
CR Ahmed Qazi Arbab, 2019, Applied Reconfigurable Computing. 15th International Symposium, ARC 2019. Proceedings: Lecture Notes in Computer Science (LNCS 11444), P127, DOI 10.1007/978-3-030-17227-5_10
   Ahmed QA, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1490, DOI 10.23919/DATE51398.2021.9474026
   Al-Aghbari AA, 2019, IEEE ACCESS, V7, P38009, DOI 10.1109/ACCESS.2019.2906910
   Amazon, AMAZON EC2 F1 INSTAN
   Amazon, AWS EC2 FPGA HDK SDK
   [Anonymous], 2015, TINY IMAGENET VISUAL
   Batina L, 2019, PROCEEDINGS OF THE 28TH USENIX SECURITY SYMPOSIUM, P515
   Breiman L., 2001, Machine Learning, V45, P5, DOI 10.1023/A:1010933404324
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chen F., 2014, PES GEN M C EXP JUL, P1
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Christ M, 2018, NEUROCOMPUTING, V307, P72, DOI 10.1016/j.neucom.2018.03.067
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dai GH, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P330, DOI 10.1109/FPT.2014.7082811
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dubey A, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P197, DOI [10.1109/HOST45689.2020.9300276, 10.1109/host45689.2020.9300276]
   Duddu V., 2018, CORR
   Elnaggar R, 2019, DES AUT TEST EUROPE, P7, DOI [10.23919/DATE.2019.8714904, 10.23919/date.2019.8714904]
   Faezi S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1484, DOI 10.23919/DATE51398.2021.9474076
   Faezi S, 2021, IEEE T INF FOREN SEC, V16, P2697, DOI 10.1109/TIFS.2021.3062989
   Friedman JH, 2002, COMPUT STAT DATA AN, V38, P367, DOI 10.1016/S0167-9473(01)00065-2
   Giechaskiel I., 2019, ACM T RECONFIGURABLE, V12, P1
   Giechaskiel I, 2020, P IEEE S SECUR PRIV, P1728, DOI 10.1109/SP40000.2020.00070
   Giechaskiel I, 2019, PR IEEE COMP DESIGN, P1, DOI 10.1109/ICCD46524.2019.00010
   Gnad Dennis R. E., 2018, 2018 International Conference on Field-Programmable Technology (FPT). Proceedings, P286, DOI 10.1109/FPT.2018.00055
   Google, GOOGLE COMPUTE ENGIN
   Hong S., 2018, ARXIV PREPRINT ARXIV
   Hu X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P385, DOI 10.1145/3373376.3378460
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   King DB, 2015, ACS SYM SER, V1214, P1
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Krautter J., 2019, P IEEEACM INT C COMP, P1
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kurakin A., 2016, P USENIX SECUR S, P601
   La TM, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3402937
   Lippmann R. P., 1987, IEEE ASSP Magazine, V4, P4, DOI 10.1145/44571.44572
   Liu ZQ, 2017, ACM T RECONFIG TECHN, V10, DOI 10.1145/3079758
   Mangard S, 2004, LECT NOTES COMPUT SC, V2964, P222
   Mangard S, 2002, LECT NOTES COMPUT SC, V2587, P343
   Mbongue JM, 2020, IEEE INT CONF ASAP, P125, DOI 10.1109/ASAP49362.2020.00030
   Mbongue JM, 2018, PR IEEE COMP DESIGN, P242, DOI 10.1109/ICCD.2018.00044
   Microsoft, AZURE FPGA INFERENCE
   Moini S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1639, DOI 10.23919/DATE51398.2021.9473915
   Moini S, 2021, IEEE J EM SEL TOP C, V11, P357, DOI 10.1109/JETCAS.2021.3074608
   Muja M, 2009, VISAPP 2009: PROCEEDINGS OF THE FOURTH INTERNATIONAL CONFERENCE ON COMPUTER VISION THEORY AND APPLICATIONS, VOL 1, P331
   Naghibijouybari H, 2018, PROCEEDINGS OF THE 2018 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (CCS'18), P2139, DOI 10.1145/3243734.3243831
   Papernot N, 2018, 2018 3RD IEEE EUROPEAN SYMPOSIUM ON SECURITY AND PRIVACY (EUROS&P 2018), P399, DOI 10.1109/EuroSP.2018.00035
   Popp T, 2007, IEEE DES TEST COMPUT, V24, P535, DOI 10.1109/MDT.2007.200
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Rish I., 2001, J U COMPUT SCI, V3, P41, DOI DOI 10.1002/9781118721957.CH4
   Ristenpart T, 2009, CCS'09: PROCEEDINGS OF THE 16TH ACM CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P199
   SAFAVIAN SR, 1991, IEEE T SYST MAN CYB, V21, P660, DOI 10.1109/21.97458
   Schellenberg F, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240841
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sugawara T, 2019, ELECTRON LETT, V55, P640, DOI 10.1049/el.2019.0163
   Tarafdar Naif, 2019, HARDWARE ACCELERATOR, P9
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Tramèr F, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P601
   Vaishnav A, 2018, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2018.00031
   Wang BH, 2018, P IEEE S SECUR PRIV, P36, DOI 10.1109/SP.2018.00038
   Weerasinghe J, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1078, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.199
   Wei JY, 2020, I C DEPEND SYS NETWO, P125, DOI 10.1109/DSN48063.2020.00031
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   xilinx, ZEDBOARD
   Xillybus, XILLYBUS PRODUCT BRI
   Yan MJ, 2020, PROCEEDINGS OF THE 29TH USENIX SECURITY SYMPOSIUM, P2003
   Yasaei R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1504, DOI 10.23919/DATE51398.2021.9474174
   Yasaei R, 2021, DES AUT CON, P217, DOI 10.1109/DAC18074.2021.9586150
   Yasaei R, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415672
   Yoshida K, 2019, ANN IEEE SYM FIELD P, P318, DOI 10.1109/FCCM.2019.00059
   Yu HG, 2020, 27TH ANNUAL NETWORK AND DISTRIBUTED SYSTEM SECURITY SYMPOSIUM (NDSS 2020), DOI 10.14722/ndss.2020.24178
   Yu HG, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P209, DOI [10.1109/HOST45689.2020.9300274, 10.1109/host45689.2020.9300274]
   Yuan X., 2020, ARXIV200909560
   Zeiler MD, 2014, LECT NOTES COMPUT SC, V8689, P818, DOI 10.1007/978-3-319-10590-1_53
   Zhang K, 2019, SIGCSE '19: PROCEEDINGS OF THE 50TH ACM TECHNICAL SYMPOSIUM ON COMPUTER SCIENCE EDUCATION, P927, DOI 10.1145/3287324.3287475
   Zhang YQ, 2011, P IEEE S SECUR PRIV, P313, DOI 10.1109/SP.2011.31
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhu J, 2009, STAT INTERFACE, V2, P349
   Zhu YK, 2021, PROCEEDINGS OF THE 30TH USENIX SECURITY SYMPOSIUM, P1973
NR 81
TC 14
Z9 14
U1 0
U2 12
PY 2021
VL 16
BP 4377
EP 4388
DI 10.1109/TIFS.2021.3106169
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Wijeratne, S
   Kannan, R
   Prasanna, V
AF Wijeratne, Sasindu
   Kannan, Rajgopal
   Prasanna, Viktor
GP IEEE
TI Reconfigurable Low-latency Memory System for Sparse Matricized Tensor
   Times Khatri-Rao Product on FPGA
SO 2021 IEEE HIGH PERFORMANCE EXTREME COMPUTING CONFERENCE (HPEC)
SE IEEE High Performance Extreme Computing Conference
DT Proceedings Paper
CT IEEE High Performance Extreme Computing Conference (HPEC)
CY SEP 20-24, 2021
CL ELECTR NETWORK
DE MTTKRP; Memory Systems; Shared Memory; FPGA; Tensor Decomposition
AB Tensor decomposition has become an essential tool in many applications in various domains, including machine learning. Sparse Matricized Tensor Times Khatri-Rao Product (MTTKRP) is one of the most computationally expensive kernels in tensor computations. Despite having significant computational parallelism, MTTKRP is a challenging kernel to optimize due to its irregular memory access characteristics. This paper focuses on a multi-faceted memory system, which explores the spatial and temporal locality of the data structures of MTTKRP. Further, users can reconfigure our design depending on the behavior of the compute units used in the FPGA accelerator. Our system efficiently accesses all the MTTKRP data structures while reducing the total memory access time, using a distributed cache and Direct Memory Access (DMA) subsystem. Moreover, our work improves the memory access time by 3.5x compared with commercial memory controller IPs. Also, our system shows 2x and 1.26x speedups compared with cache-only and DMA-only memory systems, respectively.
C1 [Wijeratne, Sasindu; Prasanna, Viktor] Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Kannan, Rajgopal] US Army Res Lab, Los Angeles, CA USA.
RP Wijeratne, S (corresponding author), Univ Southern Calif, Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
EM kangaram@usc.edu; rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR Ahmed N. K., 2020, ABS201006277 CORR
   Asiatici M, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P310, DOI 10.1145/3289602.3293901
   Asiatici M, 2019, I C FIELD PROG LOGIC, P254, DOI 10.1109/FPL.2019.00049
   Bader BW, 2007, SIAM J SCI COMPUT, V30, P205, DOI 10.1137/060676489
   Bennett James, 2007, SIGKDD EXPLOR NEWSL, V9, P51, DOI DOI 10.1145/1345448.1345459
   Carlson A, 2010, AAAI CONF ARTIF INTE, P1306
   Chen Z., 2021, DEEP TRANSFER TENSOR
   Cheng ZY, 2020, INT CONF ACOUST SPEE, P3292, DOI [10.1109/icassp40776.2020.9053292, 10.1109/ICASSP40776.2020.9053292]
   Fernandes S, 2021, ARTIF INTELL REV, V54, P2891, DOI 10.1007/s10462-020-09916-4
   Gil A. D. S., 2010, Proceedings 2010 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2010), P250, DOI 10.1109/ReConFig.2010.26
   Hong D, 2020, SIAM REV, V62, P133, DOI 10.1137/18M1203626
   Intel, EXT MEM INT INT ARR
   Kjolstad F, 2019, INT SYM CODE GENER, P180, DOI [10.1109/CGO.2019.8661185, 10.1109/cgo.2019.8661185]
   Kolda TG, 2020, SIAM J MATH DATA SCI, V2, P1066, DOI 10.1137/19M1266265
   LAM MS, 1991, SIGPLAN NOTICES, V26, P63, DOI 10.1145/106973.106981
   Ma XY, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P227, DOI 10.1145/3020078.3021743
   McKee S A., 2004, COMPUTING FRONTIERS, P162, DOI DOI 10.1145/977091.977115
   Mondelli M., 2019, 22 INT C ARTIFICIAL, P1051
   Nisa I, 2019, INT PARALL DISTRIB P, P123, DOI 10.1109/IPDPS.2019.00023
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Taguchi Y, 2019, BMC BIOINFORMATICS, V19, DOI 10.1186/s12859-018-2395-8
   Volos S., 2016, EFFECTIVE DRAM CACHE
   Wen FX, 2020, INT CONF ACOUST SPEE, P4572, DOI [10.1109/icassp40776.2020.9053619, 10.1109/ICASSP40776.2020.9053619]
   Wijeratne S., 2021, PROGRAMMABLE FPGA BA
   Xilinx, ALV U250 DAT CTR ACC
   Xilinx, ULTR ARCH FPGAS MEM
   Zhang R., HARDWARE IMPLEMENTAT
   Zhang RZ, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286199
NR 30
TC 1
Z9 1
U1 1
U2 1
PY 2021
DI 10.1109/HPEC49654.2021.9622851
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Jiang, HW
   Huang, SS
   Li, WT
   Yu, SM
AF Jiang, Hongwu
   Huang, Shanshi
   Li, Wantong
   Yu, Shimeng
TI ENNA: An Efficient Neural Network Accelerator Design Based on ADC-Free
   Compute-In-Memory Subarrays
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Compute-in-memory; ADC-free; pulse-width-modulation; heterogeneous 3D
   integration
AB Compute-in-memory (CIM) is an attractive solution for machine learning hardware acceleration since it merges computation directly into memory arrays, performing parallel multiply-and-accumulate (MAC) operations. The primary challenge in the reported CIM designs is the analog-to-digital converters (ADCs) that digitize analog MAC values for further processing, causing accuracy loss, excessive power dissipation, latency penalty, and area overhead. In this work, we propose ENNA, a novel CIM architecture based on an ADC-free subarray design, implementing inter-array data processing in an analog manner. A lightweight input encoding scheme based on pulse-width modulation (PWM) is proposed to improve the throughput. We taped-out a prototype macro and validated the proposed ADC-free RRAM array design in TSMC 40nm process. Based on the measured silicon data, we explore the system-level performance with a partition between analog and digital processing at a level higher than the sub-array. The evaluation results show that the proposed accelerator can achieve 73.6 similar to 46.4 TOPS/VV energy efficiency and 2.3 similar to 7 TOPS throughput (normalized to binary operation) tested on various DNN models. Furthermore, we project the proposed design using a heterogeneous 3D integration (H3D) scheme, showing a 3x similar to 37x throughput improvement depending on different tasks and similar to 50% reduced area overhead compared to 2D design.
C1 [Jiang, Hongwu; Huang, Shanshi; Li, Wantong; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Jiang, HW (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM hjiang318@gatech.edu; shimeng.yu@ece.gatech.edu
CR Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Cheng-Xin Xue, 2021, 2021 IEEE International Solid- State Circuits Conference (ISSCC), P245, DOI 10.1109/ISSCC42613.2021.9365769
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hubara I, 2016, ADV NEUR IN, V29
   Jia HY, 2021, ISSCC DIG TECH PAP I, V64, P236, DOI 10.1109/ISSCC42613.2021.9365788
   Jiang Hongwu, 2022, 2022 IEEE Symposium on VLSI Technology and Circuits (VLSI Technology and Circuits), P266, DOI 10.1109/VLSITechnologyandCir46769.2022.9830211
   Jiang HW, 2022, IEEE DES TEST, V39, P48, DOI 10.1109/MDAT.2021.3050715
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jourdain A, 2020, ELEC COMP C, P42, DOI 10.1109/ECTC32862.2020.00020
   Khaddam-Aljameh R, 2022, IEEE J SOLID-ST CIRC, V57, P1027, DOI 10.1109/JSSC.2022.3140414
   Kim T, 2020, IEEE T ELECTRON DEV, V67, P1394, DOI 10.1109/TED.2020.2964640
   Li WT, 2021, PROC EUR S-STATE DEV, P79, DOI 10.1109/ESSDERC53440.2021.9631810
   Li WT, 2021, IEEE CUST INTEGR CIR, DOI 10.1109/CICC51472.2021.9431558
   Lu A., 2021, FRONTIERS ARTIF INTE, V4, P70
   Mikolajick T, 2020, IEEE T ELECTRON DEV, V67, P1434, DOI 10.1109/TED.2020.2976148
   Peng X., 2020, IEDM, P30, DOI DOI 10.1109/TCSI.2018.2828611
   Peng XC, 2019, INT EL DEVICES MEET
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Wu P.-C., 2022, IEEE INT SOLID STATE, V65, P1
   Xue CX, 2020, ISSCC DIG TECH PAP I, P244, DOI 10.1109/isscc19947.2020.9063078
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang J, 2019, ISSCC DIG TECH PAP I, V62, P394, DOI 10.1109/ISSCC.2019.8662435
   Yoon JH, 2021, ISSCC DIG TECH PAP I, V64, P404, DOI 10.1109/ISSCC42613.2021.9365926
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
   Yue JS, 2021, ISSCC DIG TECH PAP I, V64, P238, DOI 10.1109/ISSCC42613.2021.9365958
   Zhu Z., 2019, PROC 56 ANN DESIGN A, P1
NR 31
TC 2
Z9 2
U1 9
U2 24
PD JAN
PY 2023
VL 70
IS 1
BP 353
EP 363
DI 10.1109/TCSI.2022.3208755
EA OCT 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Jiang, ZW
   Yin, SH
   Seo, JS
   Seok, M
AF Jiang, Zhewei
   Yin, Shihui
   Seo, Jae-Sun
   Seok, Mingoo
TI C3SRAM: An In-Memory-Computing SRAM Macro Based on Robust Capacitive
   Coupling Computing Mechanism
SO IEEE JOURNAL OF SOLID-STATE CIRCUITS
DT Article
DE Transistors; Capacitors; Random access memory; Computer architecture;
   Neural networks; Couplings; Acceleration; Analog-mixed-signal (AMS)
   computing; capacitive coupling; in-memory computing (IMC); machine
   learning accelerator; neural network; SRAM
ID ACCELERATOR; NETWORK
AB This article presents C3SRAM, an in-memory-computing SRAM macro. The macro is an SRAM module with the circuits embedded in bitcells and peripherals to perform hardware acceleration for neural networks with binarized weights and activations. The macro utilizes analog-mixed-signal (AMS) capacitive-coupling computing to evaluate the main computations of binary neural networks, binary-multiply-and-accumulate operations. Without the need to access the stored weights by individual row, the macro asserts all its rows simultaneously and forms an analog voltage at the read bitline node through capacitive voltage division. With one analog-to-digital converter (ADC) per column, the macro realizes fully parallel vector-matrix multiplication in a single cycle. The network type that the macro supports and the computing mechanism it utilizes are determined by the robustness and error tolerance necessary in AMS computing. The C3SRAM macro is prototyped in a 65-nm CMOS. It demonstrates an energy efficiency of 672 TOPS/W and a speed of 1638 GOPS (20.2 TOPS/mm(2)), achieving 3975x better energy-delay product than the conventional digital baseline performing the same operation. The macro achieves 98.3% accuracy for MNIST and 85.5% for CIFAR-10, which is among the best in-memory computing works in terms of energy efficiency and inference accuracy tradeoff.
C1 [Jiang, Zhewei; Seok, Mingoo] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
   [Yin, Shihui; Seo, Jae-Sun] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85287 USA.
RP Seok, M (corresponding author), Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
EM ms4415@columbia.edu
CR [Anonymous], 2017, 2017 S VLSI CIRC
   [Anonymous], ARXIV170905306
   [Anonymous], REL PHYS S IRPS 2011
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Eckert C, 2019, IEEE MICRO, V39, P11, DOI 10.1109/MM.2019.2908101
   Gambardella G., 2019, P IEEE INT S DEF FAU, P1
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kang MG, 2018, IEEE J EM SEL TOP C, V8, P494, DOI 10.1109/JETCAS.2018.2829522
   Kang MG, 2017, ESSCIRC 2017 - 43RD IEEE EUROPEAN SOLID STATE CIRCUITS CONFERENCE, P263, DOI 10.1109/ESSCIRC.2017.8094576
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Parveen F, 2018, ASIA S PACIF DES AUT, P361, DOI 10.1109/ASPDAC.2018.8297350
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Si X, 2019, IEEE T CIRCUITS-I, V66, P4172, DOI 10.1109/TCSI.2019.2928043
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Valavi H, 2019, IEEE J SOLID-ST CIRC, V54, P1789, DOI 10.1109/JSSC.2019.2899730
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Wang JC, 2019, ISSCC DIG TECH PAP I, V62, P224, DOI 10.1109/ISSCC.2019.8662419
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Yin SH, 2020, IEEE T VLSI SYST, V28, P48, DOI 10.1109/TVLSI.2019.2940649
   Zabihi M, 2019, IEEE T COMPUT, V68, P1159, DOI 10.1109/TC.2018.2858251
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
   Zhao Y, 2017, ADVANCES IN ENERGY AND ENVIRONMENT RESEARCH, P345
   Zhou S., 2016, ARXIV160606160
NR 43
TC 107
Z9 110
U1 2
U2 20
PD JUL
PY 2020
VL 55
IS 7
BP 1888
EP 1897
DI 10.1109/JSSC.2020.2992886
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ullah, S
   Rehman, S
   Shafique, M
   Kumar, A
AF Ullah, Salim
   Rehman, Semeen
   Shafique, Muhammad
   Kumar, Akash
TI High-Performance Accurate and Approximate Multipliers for FPGA-Based
   Hardware Accelerators
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Field programmable gate arrays; Table lookup; Delays; Computer
   architecture; Performance gain; IP networks; Reed-Solomon codes;
   Accelerators; approximate computing; high performance; multipliers;
   neural networks; reduced area
ID DESIGN; POWER
AB Multiplication is one of the widely used arithmetic operations in a variety of applications, such as image/video processing and machine learning. FPGA vendors provide high-performance multipliers in the form of DSP blocks. These multipliers are not only limited in number and have fixed locations on FPGAs but can also create additional routing delays and may prove inefficient for smaller bit-width multiplications. Therefore, FPGA vendors additionally provide optimized soft IP cores for multiplication. However, in this work, we advocate that these soft multiplier IP cores for FPGAs still need better designs to provide high-performance and resource efficiency. Toward this, we present generic area-optimized, low-latency accurate, and approximate softcore multiplier architectures, which exploit the underlying architectural features of FPGAs, i.e., lookup table (LUT) structures and fast-carry chains to reduce the overall critical path delay (CPD) and resource utilization of multipliers. Compared to Xilinx multiplier LogiCORE IP, our proposed unsigned and signed accurate architecture provides up to 25% and 53% reduction in LUT utilization, respectively, for different sizes of multipliers. Moreover, with our unsigned approximate multiplier architectures, a reduction of up to 51% in the CPD can be achieved with an insignificant loss in output accuracy when compared with the LogiCORE IP. For illustration, we have deployed the proposed multiplier architecture in accelerators used in image and video applications, and evaluated them for area and performance gains. Our library of accurate and approximate multipliers is opensource and available online at https://cfaed.tu-dresden.de/pd-downloads to fuel further research and development in this area, facilitate reproducible research, and thereby enabling a new research direction for the FPGA community.
C1 [Ullah, Salim; Kumar, Akash] Tech Univ Dresden, Chair Processor Design, D-01062 Dresden, Germany.
   [Rehman, Semeen] Tech Univ Wien, Inst Comp Technol, A-1040 Vienna, Austria.
   [Shafique, Muhammad] New York Univ Abu Dhabi, Div Engn, Abu Dhabi, U Arab Emirates.
RP Kumar, A (corresponding author), Tech Univ Dresden, Chair Processor Design, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; semeen.rehman@tuwien.ac.at;
   muhammad.shafique@nyu.edu; akash.kumar@tu-dresden.de
CR [Anonymous], 2013, P 23 INT C FIELD PRO
   [Anonymous], 2017, VIVADO DESIGN SUITE
   [Anonymous], 2015, LOGICORE IP V12 0
   [Anonymous], 2016, MNIST CNN
   [Anonymous], 2019, SIPI IMAGE DATABASE
   [Anonymous], 2020, INTEGER ARITHMETIC I
   [Anonymous], 2016, 7 SERIES FPGAS CONFI
   [Anonymous], 2018, 7 SER DSP48E1 SLIC
   BAUGH CR, 1973, IEEE T COMPUT, VC 22, P1045, DOI 10.1109/T-C.1973.223648
   Beuchat JL, 2008, IEEE T COMPUT, V57, P1600, DOI 10.1109/TC.2008.102
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   BOOTH AD, 1951, Q J MECH APPL MATH, V4, P236, DOI 10.1093/qjmam/4.2.236
   Brunie N., 2013, P 23 INT C FIELD PRO, P1
   Chippa VK, 2013, DES AUT CON
   Dadda L., 1965, ALTA FREQ, V34, P349
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Kahng AB, 2012, DES AUT CON, P820
   Kakacak A, 2017, INTEGRATION, V57, P147, DOI 10.1016/j.vlsi.2016.12.012
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Kumm M, 2017, P S COMP ARITHM, P131, DOI 10.1109/ARITH.2017.35
   Kumm M, 2015, P S COMP ARITHM, P18, DOI 10.1109/ARITH.2015.17
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Lin CH, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P33, DOI 10.1109/ICCD.2013.6657022
   Liu C, 2014, DES AUT TEST EUROPE
   MILLER B, 1992, PROCEEDINGS OF THE 35TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1 AND 2, P158, DOI 10.1109/MWSCAS.1992.271307
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mody J, 2015, PROCEEDINGS OF 2015 ONLINE INTERNATIONAL CONFERENCE ON GREEN ENGINEERING AND TECHNOLOGIES (IC-GET)
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Parandeh-Afshar H., 2011, 2011 International Conference on Field Programmable Logic and Applications, P225, DOI 10.1109/FPL.2011.48
   Parandeh-Afshar H, 2009, I C FIELD PROG LOGIC, P242, DOI 10.1109/FPL.2009.5272301
   Parhami B., 2010, COMPUTER ARITHMETIC
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Ullah S, 2021, IEEE EMBED SYST LETT, V13, P41, DOI 10.1109/LES.2020.2995053
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3195996
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   WALLACE CS, 1964, IEEE T COMPUT, VEC13, P14, DOI 10.1109/PGEC.1964.263830
   Walters EG, 2016, COMPUTERS, V5, DOI 10.3390/computers5040020
   Zitzler E, 2007, LECT NOTES COMPUT SC, V4403, P862
NR 44
TC 13
Z9 13
U1 1
U2 8
PD FEB
PY 2022
VL 41
IS 2
BP 211
EP 224
DI 10.1109/TCAD.2021.3056337
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ryan, J
   Okazaki, D
   Dallow, M
   Dezfouli, B
AF Ryan, John
   Okazaki, Daniel
   Dallow, Michael
   Dezfouli, Behnam
GP IEEE
TI NavSense: A Navigation Tool for Visually Impaired
SO 2019 IEEE GLOBAL HUMANITARIAN TECHNOLOGY CONFERENCE (GHTC)
SE IEEE Global Humanitarian Technology Conference Proceedings
DT Proceedings Paper
CT 9th Annual IEEE Global Humanitarian Technology Conference (IEEE GHTC)
CY OCT 17-20, 2019
CL IEEE Reg 6, Seattle Sect, Seattle, WA
HO IEEE Reg 6, Seattle Sect
DE Blindness; Accessibility; Computer Vision; Machine Learning; Object
   Recognition; Image Classification
AB The visually impaired rely heavily on hearing and touching (with their cane) to navigate through life. These senses cannot make up for the loss of vision when identifying objects in the user's path. In this paper, we propose NavSense, an assistive device that supplements existing technology to improve navigation and peace of mind in day to day life. NavSense relies on range detection, computer vision, and hardware acceleration mechanisms to provide real-time object identification and context to the user through auditory feedback. In particular, we use four hardware platforms - Raspberry Pi 3 B+, Coral Accelerator, Coral Development Board, and Intel Neural Computer Stick - to compare the efficiency of object detection in terms of time and energy during setup and inference phases. Based on these results, it is possible to tailor the design for specific energy accuracy requirements. Also, we have implemented and used NavSense in real-world scenarios to show its effectiveness.
C1 [Ryan, John; Okazaki, Daniel; Dallow, Michael; Dezfouli, Behnam] Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
RP Ryan, J (corresponding author), Santa Clara Univ, Dept Comp Sci & Engn, Santa Clara, CA 95053 USA.
EM jcryan@scu.edu; dtokazaki@scu.edu; mdallow@scu.edu; bdezfouli@scu.edu
CR Amirtharaj I., 2018, J AMB INTEL HUM COMP, P1
   [Anonymous], 2019, GETTING STARTED ULTR
   [Anonymous], YOLO REAL TIME OBJEC
   [Anonymous], 2018, OPENCV LIB
   [Anonymous], 2018, INTEL NEURAL COMPUTE
   [Anonymous], 2018, VIS IMP BLINDN
   [Anonymous], 2018, INTEL DISTRIBUTION O
   [Anonymous], 2019, YOLO VS SSD DEEP LEA
   chuanqi305, 2018, MOBILENETV2 SSDLITE
   Dezfouli B., 2018, J NETW COMPUT APPL, V121
   Elmannai W, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17030565
   Hollemans M., MOBILENET VERSION 2
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Magid S. A., 2019, ARXIV190211119
   Manduchi R., 2011, RES PRACTICE VISUAL, V4, P1
   RapidWareTech, 2016, RAPIDWARETECH PYTTSX
   Thorne B., 2009, PYTHON PAPERS MONOGR, V1
   Torres R. Mastachi, 2018, COMMUNICATION
   Xilinx, 2019, XIL BNN PYNQ
   Xilinx, 2018, XIL QNN MO PYNQ
   Xilinx, 2019, XIL FINN
   Xilinx, 2019, XIL PYNQ COMP VIS
NR 22
TC 1
Z9 1
U1 0
U2 1
PY 2019
BP 71
EP 78
DI 10.1109/ghtc46095.2019.9033125
WC Computer Science, Interdisciplinary Applications; Green & Sustainable
   Science & Technology; Engineering, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Anwar, A
   Raychowdhury, A
   Hatcher, R
   Rakshit, T
AF Anwar, Aqeel
   Raychowdhury, Arijit
   Hatcher, Ryan
   Rakshit, Titash
GP IEEE
TI XBAROPT - Enabling ultra-pipelined, novel STT MRAM based
   processing-in-memory DNN accelerator
SO 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE
   CIRCUITS AND SYSTEMS (AICAS 2020)
DT Proceedings Paper
CT 2nd IEEE International Conference on Artificial Intelligence Circuits
   and Systems (AICAS)
CY AUG 31-SEP 04, 2020
CL ELECTR NETWORK
AB An explosion in big data driven machine learning (ML) applications in conjunction with a severe slowdown of Moore's Law are prompting the search for alternative application-specific hardware fabrics. With its focus on bringing the compute inside memory bitcells, processing-in-memory (PIM) has been proposed to accelerate ML inference applications. In this paper, we present a modular, end-to-end simulation framework that is required to find a power-performance optimized solution for PIM based architectures for a given application. Our simulation framework encompasses multiple levels of hierarchies including device bitcell, array, memory hierarchy, dataflow, data re-use and algorithm-to-system mapping. Novel concepts at two levels of the hierarchy are introduced and evaluated: 1. Logic embeddable, high Ion/Ioff Magnetic Tunnel Junction (MTJ) bitcell and 2. Cycle accurate inter and intra layer pipelined operation for high performance and low power operations. Results are compared to pure digital custom ASIC implementation showing orders of magnitude improvements in power-performance on widely accepted MLPerf benchmarks.
C1 [Anwar, Aqeel; Raychowdhury, Arijit] Georgia Inst Technol, Atlanta, GA 30332 USA.
   [Hatcher, Ryan; Rakshit, Titash] Samsung Semicond Inc, San Jose, CA USA.
RP Anwar, A (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
CR Jain K. R. A. R. Shubham, 2019, ARXIV PREPRINT ARXIV
   Jiang ZZ, 2016, IEEE T ELECTRON DEV, V63, P1884, DOI 10.1109/TED.2016.2545412
   Lee YK, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P181, DOI 10.1109/VLSIT.2018.8510623
   Liu XX, 2015, DES AUT CON, DOI 10.1145/2744769.2744900
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Noguchi H., 2013, S VLSI CIRCUITS, pC108
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Samajdar A., 2018, COMPUTING RES REPOSI
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Taha TM, 2013, IEEE IJCNN
   Yakopcic C, 2013, IEEE IJCNN
   Yongtae Kim, 2012, 2012 IEEE 25th International SOC Conference (SOCC), P328, DOI 10.1109/SOCC.2012.6398336
NR 13
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 36
EP 40
DI 10.1109/aicas48895.2020.9073792
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lou, WQ
   Wang, C
   Gong, L
   Zhou, XH
AF Lou, Wenqi
   Wang, Chao
   Gong, Lei
   Zhou, Xuehai
BE Yew, PC
   Stenstrom, P
   Wu, J
   Gong, X
   Li, T
TI RV-CNN: Flexible and Efficient Instruction Set for CNNs Based on RISC-V
   Processors
SO ADVANCED PARALLEL PROCESSING TECHNOLOGIES (APPT 2019)
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 13th International Symposium on Advanced Parallel Processing
   Technologies (APPT)
CY AUG 15-16, 2019
CL Tianjin, PEOPLES R CHINA
DE CNN; RISC-V; Domain-specific instructions; FPGA
AB Convolutional Neural Network (CNN) has gained significant attention in the field of machine learning, particularly due to its high accuracy in character recognition and image classification. Nevertheless, due to the computation-intensive and memory-intensive character of CNN, general-purpose processors which usually need to support various workloads are not efficient for CNN implementation. Therefore, a great deal of emerging CNN-specific hardware accelerators is able to improve efficiency. Although existing accelerators are significantly efficient, they are often inflexible or require complex controllers to handle calculations and data transfer. In this paper, we analyze classical CNN applications and design a domain-specific instruction set of 9 matrix instructions, called RV-CNN, based on the promising RISC-V architecture. By abstracting CNN into instructions, our design possesses a higher code density and provides sufficient flexibility and efficiency for CNN than general-purpose ISAs. Specifically, the proposed instructions are extended to RISC-V ISA as custom instructions. Besides, we also introduce micro-architectural optimizations to increase computational density and reduce the required memory bandwidth. Finally, we implement the architecture with the extended ISA and evaluate it with LeNet-5 on the datasets (MNIST, Caltech101, and Cifar-10). Results show that compared with the Intel Core i7 processor and Tesla k40c GPU, our design has 36.09x and 11.42x energy efficiency ratio and 6.70x and 1.25x code density respectively.
C1 [Lou, Wenqi; Wang, Chao; Gong, Lei; Zhou, Xuehai] Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
RP Lou, WQ (corresponding author), Univ Sci & Technol China, Sch Comp Sci, Hefei, Peoples R China.
EM louwenqi@mail.ustc.edu.cn; cswang@ustc.edu.cn;
   leigong0203@mail.ustc.edu.cn; xhzhou@ustc.edu.cn
CR Banakar R., 2002, INT S HARDW SOFTW CO
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Conti F, 2016, J SIGNAL PROCESS SYS, V84, P339, DOI 10.1007/s11265-015-1070-9
   Flamand E, 2018, IEEE INT CONF ASAP, P69
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gong L, 2018, IEEE T COMPUT AID D, V37, P2601, DOI 10.1109/TCAD.2018.2857078
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   Sun Yi, 2014, NEURIPS
   Wang C, 2017, IEEE T PARALL DISTR, V28, P2993, DOI 10.1109/TPDS.2017.2701828
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zisserman A., 2014, 14091556 ARXIV
NR 17
TC 7
Z9 7
U1 0
U2 17
PY 2019
VL 11719
BP 3
EP 14
DI 10.1007/978-3-030-29611-7_1
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tortorella, Y
   Bertaccini, L
   Benini, L
   Rossi, D
   Conti, F
AF Tortorella, Yvan
   Bertaccini, Luca
   Benini, Luca
   Rossi, Davide
   Conti, Francesco
TI RedMule: A mixed-precision matrix-matrix operation engine for flexible
   and energy-efficient on-chip linear algebra and TinyML training
   acceleration
SO FUTURE GENERATION COMPUTER SYSTEMS-THE INTERNATIONAL JOURNAL OF ESCIENCE
DT Article
DE General Matrix-Matrix Multiplication; General Matrix-Matrix Operations;
   Hardware accelerator; Embedded-systems; Online-learning; TinyML
ID HIGH-PERFORMANCE; ARCHITECTURE; FRAMEWORK
AB The increasing interest in TinyML, i.e., near-sensor machine learning on power budgets of a few tens of mW, is currently pushing toward enabling TinyML-class training as opposed to inference only. Current training algorithms, based on various forms of error and gradient backpropagation, rely on floatingpoint matrix operations to meet the precision and dynamic range requirements. So far, the energy and power cost of these operations has been considered too high for TinyML scenarios. This paper addresses the open challenge of near-sensor training on a few mW power budget and presents RedMulE - Reduced-Precision Matrix Multiplication Engine, a low-power specialized accelerator conceived for multi-precision floating-point General Matrix-Matrix Operations (GEMM-Ops) acceleration, supporting FP16, as well as hybrid FP8 formats, with {sign, exponent, mantissa} = ({1, 4, 3}, {1, 5, 2}). We integrate RedMule into a Parallel Ultra-Low-Power (PULP) cluster containing eight energy-efficient RISC-V cores sharing a tightly-coupled data memory and implement the resulting system in a 22 nm technology. At its best efficiency point (@ 470 MHz, 0.65 V), the RedMulE-augmented PULP cluster achieves 755 GFLOPS/W and 920 GFLOPS/W during regular General Matrix-Matrix Multiplication (GEMM), and up to 1.19 TFLOPS/W and 1.67 TFLOPS/W when executing GEMM-Ops, respectively, for FP16 and FP8 input/output tensors. In its best performance point (@ 613 MHz, 0.8 V), RedMulE achieves up to 58.5 GFLOPS and 117 GFLOPS for FP16 and FP8, respectively, with 99.4% utilization of the array of Computing Elements and consuming less than 60 mW on average, thus enabling on-device training of deep learning models in TinyML application scenarios while retaining the flexibility to tackle other classes of common linear algebra problems efficiently.& COPY; 2023 Elsevier B.V. All rights reserved.
C1 [Tortorella, Yvan; Benini, Luca; Rossi, Davide; Conti, Francesco] Univ Bologna, Bologna, Italy.
   [Bertaccini, Luca; Benini, Luca] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Tortorella, Y (corresponding author), Univ Bologna, Bologna, Italy.
EM yvan.tortorella@unibo.it; lbertaccini@iis.ee.ethz.ch;
   lbenini@iis.ee.ethz.ch; davide.rossi@unibo.it; f.conti@unibo.it
CR Agrawal A, 2021, ISSCC DIG TECH PAP I, V64, P144, DOI 10.1109/ISSCC42613.2021.9365791
   Aleskog C, 2022, ALGORITHMS, V15, DOI 10.3390/a15110419
   Anders M, 2018, SYMP VLSI CIRCUITS, P39, DOI 10.1109/VLSIC.2018.8502333
   Banbury C, 2021, arXiv
   Bertaccini L, 2022, P S COMP ARITHM, P1, DOI 10.1109/ARITH54963.2022.00010
   Bian HD, 2021, FUTURE GENER COMP SY, V116, P371, DOI 10.1016/j.future.2020.10.036
   Burrello A, 2021, I SYMPOS LOW POWER E, DOI 10.1109/ISLPED52811.2021.9502494
   Cioflan C, 2022, 2022 IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2022): INTELLIGENT TECHNOLOGY IN THE POST-PANDEMIC ERA, P82, DOI 10.1109/AICAS54282.2022.9869990
   Conti F, 2018, IEEE T COMPUT AID D, V37, P2940, DOI 10.1109/TCAD.2018.2857019
   Fox S., 2021, INT C LEARNING REPRE
   Frenkel C, 2021, FRONT NEUROSCI-SWITZ, V15, DOI 10.3389/fnins.2021.629892
   Garofalo Angelo, 2022, IEEE Open Journal of the Solid-State Circuits Society, V2, P231, DOI 10.1109/OJSSCS.2022.3210082
   Gilbert JR, 2008, COMPUT SCI ENG, V10, P20, DOI 10.1109/MCSE.2008.45
   Gilbert JR, 2007, LECT NOTES COMPUT SC, V4699, P260
   Gonzalez A, 2021, PROC EUR SOLID-STATE, P259, DOI 10.1109/ESSCIRC53450.2021.9567768
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Heo J, 2022, IEEE J SOLID-ST CIRC, DOI 10.1109/JSSC.2022.3220195
   Houshmand Pouya, 2023, IEEE Journal of Solid-State Circuits, P203, DOI 10.1109/JSSC.2022.3214064
   Jin Y, 2021, FUTURE GENER COMP SY, V125, P908, DOI 10.1016/j.future.2021.07.010
   Kim S, 2022, IEEE T CIRCUITS-I, V69, P1494, DOI 10.1109/TCSI.2021.3138092
   Lee J, 2019, ISSCC DIG TECH PAP I, V62, P142, DOI 10.1109/ISSCC.2019.8662302
   Mach S, 2021, IEEE T VLSI SYST, V29, P774, DOI 10.1109/TVLSI.2020.3044752
   Mazumder AN, 2021, IEEE J EM SEL TOP C, V11, P532, DOI 10.1109/JETCAS.2021.3129415
   Mehrooz G., 2020, INT C GEOGRAPHICAL I
   Micikevicius P, 2022, Arxiv, DOI arXiv:2209.05433
   Mohri M., 2002, Journal of Automata, Languages and Combinatorics, V7, P321
   Nadalini D, 2022, LECT NOTES COMPUT SC, V13511, P200, DOI 10.1007/978-3-031-15074-6_13
   Noune Badreddine, 2022, ARXIV
   NVIDIA, 2022, NVID H100 TENS COR G
   NVIDIA, 2021, TRAIN MIX PREC NVID
   Oh J, 2020, SYMP VLSI CIRCUITS, DOI 10.1109/vlsicircuits18222.2020.9162917
   Park J, 2022, IEEE J SOLID-ST CIRC, V57, P965, DOI 10.1109/JSSC.2021.3103603
   Pedram A, 2012, IEEE T COMPUT, V61, P1724, DOI 10.1109/TC.2012.132
   Ramanathan V., 2020, ONLINE ON DEVICE MCU
   Ravaglia L, 2021, IEEE J EM SEL TOP C, V11, P789, DOI 10.1109/JETCAS.2021.3121554
   Ravaglia L, 2020, IEEE WRK SIG PRO SYS, P53, DOI 10.1109/sips50750.2020.9195220
   Ren HY, 2021, Arxiv, DOI arXiv:2103.08295
   Reuther A, 2022, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC55821.2022.9926331
   Rodriguez Perez A.F., 2018, LOWER NUMERICAL PREC
   Rossi D, 2022, IEEE J SOLID-ST CIRC, V57, P127, DOI 10.1109/JSSC.2021.3114881
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Satyanarayanan M, 2017, COMPUTER, V50, P30, DOI 10.1109/MC.2017.9
   Sedukhin SG, 2012, LECT NOTES COMPUT SC, V7203, P225, DOI 10.1007/978-3-642-31464-3_23
   Shin D, 2018, IEEE MICRO, V38, P85, DOI 10.1109/MM.2018.053631145
   Suk S., 1983, COMPUT VIS GRAPH IMA, P400, DOI [10.1016/0734-189X(84)90221-4, DOI 10.1016/0734-189X(84)90221-4]
   Sun X., 2019, HYBRID 8 BIT FLOATIN
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Tortorella Y, 2022, DES AUT TEST EUROPE, P1099, DOI 10.23919/DATE54114.2022.9774759
   Van Baalen M, 2023, Arxiv, DOI arXiv:2303.17951
   Venkataramani S, 2021, CONF PROC INT SYMP C, P153, DOI 10.1109/ISCA52012.2021.00021
   Wang Naigang, 2018, ARXIV181208011, P7686
   Wang Y, 2022, IEEE J SOLID-ST CIRC, V57, P3164, DOI 10.1109/JSSC.2022.3174411
   Zhang Y., 2022, ISCA 22 P 49 ANN INT
   Zhao YW, 2021, CONF PROC INT SYMP C, P706, DOI 10.1109/ISCA52012.2021.00061
   Zhou Z, 2019, P IEEE, V107, P1738, DOI 10.1109/JPROC.2019.2918951
NR 55
TC 0
Z9 0
U1 1
U2 1
PD DEC
PY 2023
VL 149
BP 122
EP 135
DI 10.1016/j.future.2023.07.002
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Gao, C
   Xu, XF
   Yang, ZZ
   Lin, LW
   Li, J
AF Gao, Chi
   Xu, Xiaofei
   Yang, Zhizou
   Lin, Liwei
   Li, Jian
TI QZRAM: A Transparent Kernel Memory Compression System Design for
   Memory-Intensive Applications with QAT Accelerator Integration
SO APPLIED SCIENCES-BASEL
DT Article
DE memory compression; memory-intensive application; NLP; OOM; QAT
ID PERFORMANCE
AB In recent decades, memory-intensive applications have experienced a boom, e.g., machine learning, natural language processing (NLP), and big data analytics. Such applications often experience out-of-memory (OOM) errors, which cause unexpected processes to exit without warning, resulting in negative effects on a system's performance and stability. To mitigate OOM errors, many operating systems implement memory compression (e.g., Linux's ZRAM) to provide flexible and larger memory space. However, these schemes incur two problems: (1) high-compression algorithms consume significant CPU resources, which inevitably degrades application performance; and (2) compromised compression algorithms with low latency and low compression ratios result in insignificant increases in memory space. In this paper, we propose QZRAM, which achieves a high-compression-ratio algorithm without high computing consumption through the integration of QAT (an ASIC accelerator) into ZRAM. To enhance hardware and software collaboration, a page-based parallel write module is introduced to serve as a more efficient request processing flow. More importantly, a QAT offloading module is introduced to asynchronously offload compression to the QAT accelerator, reducing CPU computing resource consumption and addressing two challenges: long CPU idle time and low usage of the QAT unit. The comprehensive evaluation validates that QZRAM can reduce CPU resources by up to 49.2% for the FIO micro-benchmark, increase memory space (1.66x) compared to ZRAM, and alleviate the memory overflow phenomenon of the Redis benchmark.
C1 [Gao, Chi] Chengdu Aircraft Design Inst, Dept 15, Chengdu 610041, Peoples R China.
   [Xu, Xiaofei] China Aeronaut Radio Elect Res Inst, Elect Dept, Shanghai 200233, Peoples R China.
   [Yang, Zhizou; Li, Jian] Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200240, Peoples R China.
   [Lin, Liwei] Fujian Key Lab Big Data Min & Applicat, Fuzhou 350118, Peoples R China.
   [Lin, Liwei] Fujian Univ Technol, Sch Comp Sci & Math, Fuzhou 350118, Peoples R China.
RP Li, J (corresponding author), Shanghai Jiao Tong Univ, Shanghai Key Lab Scalable Comp & Syst, Shanghai 200240, Peoples R China.
EM li-jian@sjtu.edu.cn
CR Abel D.I.J., 2020, CALGARY CORPUS
   Burrows M., 1994, P DIG SRC RES REP CI
   Choi H, 2021, INT C PATT RECOG, P5482, DOI 10.1109/ICPR48806.2021.9412102
   Collet Y., 2016, FACEBOOK CODE, V1
   Collet Y., 2020, LZ4 COMPRESSION ALGO
   Eddelbuettel D, 2022, Arxiv, DOI arXiv:2203.06559
   Ekman M, 2005, CONF PROC INT SYMP C, P74, DOI 10.1109/ISCA.2005.6
   Gupta N., 2020, ZRAM PROJECT LINUX F
   Harnik D, 2014, IEEE DATA COMPR CONF, P223, DOI 10.1109/DCC.2014.66
   Hu XK, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P163
   Intel Intel® QAT, 2022, INT QAT PERF SCAL EF
   Jennings S., 2013, ZSWAP COMPRESSED SWA
   kernel.org, 2009, ZPOOL
   Kim S, 2017, INT CONFER PARA, P206, DOI 10.1109/PACT.2017.12
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Lee S, 2011, IEEE T CONSUM ELECTR, V57, P1732, DOI 10.1109/TCE.2011.6131148
   Liu PF, 2023, ACM COMPUT SURV, V55, DOI 10.1145/3560815
   Mittal S, 2016, IEEE T PARALL DISTR, V27, P1524, DOI 10.1109/TPDS.2015.2435788
   Oberhumer M., 2013, DATA COMPRESSION LIB
   Owens JD, 2008, P IEEE, V96, P879, DOI 10.1109/JPROC.2008.917757
   Panwar G, 2022, INT SYMP MICROARCH, P992, DOI 10.1109/MICRO56248.2022.00073
   Park S, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P52, DOI 10.1145/3445814.3446722
   Pekhimnko Gennady, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P172, DOI 10.1145/2540708.2540724
   Plauth M., 2018, P 2018 6 INT S COMP
   Qian C., 2018, P 15 ACM INT C COMP, P121
   Sanchez D., 2010, Proceedings 2010 43rd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2010), P187, DOI 10.1109/MICRO.2010.20
   Siddiq ML, 2022, 2022 IEEE/ACM 1ST INTERNATIONAL WORKSHOP ON NATURAL LANGUAGE-BASED SOFTWARE ENGINEERING (NLBSE 2022), P33, DOI 10.1145/3528588.3528660
   Smith M.J.S., 1997, APPL SPECIFIC INTEGR, VVolume 7
   Tremaine RB, 2001, IBM J RES DEV, V45, P271, DOI 10.1147/rd.452.0271
   Zhao JS, 2015, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2808233
   ZIV J, 1977, IEEE T INFORM THEORY, V23, P337, DOI 10.1109/TIT.1977.1055714
NR 31
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 13
IS 18
AR 10526
DI 10.3390/app131810526
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT C
AU Plagwitz, P
   Hannig, F
   Ströbel, M
   Strohmeyer, C
   Teich, J
AF Plagwitz, Patrick
   Hannig, Frank
   Stroebel, Martin
   Strohmeyer, Christoph
   Teich, Juergen
GP IEEE Comp Soc
TI A Safari through FPGA-based Neural Network Compilation and Design
   Automation Flows
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
ID LANGUAGE; COMPILER
AB Thanks to the enormous computing power of GPUs, Machine Learning (ML) based on artificial neural networks has found its way into many important application fields. Sophisticated compiler infrastructures facilitate the task of mapping neural networks onto these accelerators. Recently, new developments have also led to compilation and design automation flows that target FPGA-based accelerators. Although not being as mature as their GPU counterparts, there exists a multitude of published and actively developed approaches with differing support levels for network classes, file formats, and target platforms. Neural network exchange file formats advance jointly with the modeling frameworks. In this paper, we take a quick safari through the jungle of neural network compilation flows for FPGA-based targets by reporting qualitative and quantitative metrics. For comparison, we study the classes of supported neural network architectures of each approach, and the corresponding compatibility of exchange formats, emphasizing ONNX, by examining available conversion tools. Besides, we look at several non-functional properties, including FPGA resource utilization and performance numbers for selected neural networks, but also soft criteria such as licensing, community support, and development activity. Finally, we also assess and discuss some deficiencies currently still affecting some approaches. We hope that our study supports interested readers to orient themselves in the jungle of available flows concerning both functionality and usability, as well as to guide further development and research activities in the endeavor of automated ML acceleration on FPGAs.
C1 [Plagwitz, Patrick; Hannig, Frank; Teich, Juergen] Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Comp Sci, Erlangen, Germany.
   [Stroebel, Martin; Strohmeyer, Christoph] Schaeffler Technol AG & Co KG, Herzogenaurach, Germany.
RP Plagwitz, P (corresponding author), Friedrich Alexander Univ Erlangen Nurnberg FAU, Dept Comp Sci, Erlangen, Germany.
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   [Anonymous], ZYNQ 7000 SOC
   Blott M, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3242897
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   FINN, VERS AF783DB8D COMM
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Lattice Semiconductor, ICE40 LP HX LM LOW P
   Lattice Semiconductor, LATT SENSAI STACK
   Lemieux G. G. F., 2019, COMPUTING RES REPOSI
   Li ZS, 2017, IEEE INT SYMP PARAL, P143, DOI 10.1109/ISPA/IUCC.2017.00030
   MathWorks, HDLCODER
   MathWorks, DEEP LEARN PROC IP C
   Membarth R, 2016, IEEE T PARALL DISTR, V27, P210, DOI 10.1109/TPDS.2015.2394802
   Moreau T., 2019, COMPUTING RES REPOSI
   Paszke A, 2019, ADV NEUR IN, V32
   Petrica L, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P48, DOI 10.1109/ICFPT51103.2020.00016
   Plagwitz P, 2019, 2019 INT C RECONFIGU, P1, DOI [10. 1109 / ReConFig48160.2019.8994778, DOI 10.1109/RECONFIG48160.2019.8994778]
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Reiche O, 2017, ICCAD-IEEE ACM INT, P1026, DOI 10.1109/ICCAD.2017.8203894
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Seo M., 2016, COMPUTING RES REPOSI
   Shawahna A, 2019, IEEE ACCESS, V7, P7823, DOI 10.1109/ACCESS.2018.2890150
   Simons T, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8060661
   Simonyan K., 2015, ICLR
   Streit F, 2020, PROD ENG-RES DEV, V14, P365, DOI 10.1007/s11740-020-00964-x
   Symbiotic EDA, MARLANN SIMPL FPGA M
   The Linux Foundation, OP NEUR NETW EXCH ON
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Xilinx, GETT START FINN DOC
   xilinx, VITIS
   Xilinx, VIT AI MOD ZOO
   Xing Y, 2020, IEEE T COMPUT AID D, V39, P2668, DOI 10.1109/TCAD.2019.2930577
   Xu JW, 2018, MICROPROCESS MICROSY, V60, P196, DOI 10.1016/j.micpro.2018.03.007
   Zhan C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967011
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhou S., 2016, DOREFANET TRAINING L
NR 41
TC 7
Z9 7
U1 0
U2 0
PY 2021
BP 10
EP 19
DI 10.1109/FCCM51124.2021.00010
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Abeed, MA
   Bandyopadhyay, S
AF Abeed, Md. Ahsanul
   Bandyopadhyay, Supriyo
TI Low Energy Barrier Nanomagnet Design for Binary Stochastic Neurons:
   Design Challenges for Real Nanomagnets With Fabrication Defects
SO IEEE MAGNETICS LETTERS
DT Article
DE Spin electronics; low energy barrier magnets; binary stochastic neurons;
   correlation time; pinning currents; effect of defects
AB Much attention has been focused on the design of low energy barrier nanomagnets (LBMs), whose magnetizations vary randomly in time owing to thermal noise, for use in binary stochastic neurons (BSNs) that serve as hardware accelerators for machine learning. The performance of BSNs depends on two important parameters: the correlation time tau(c) associated with the random magnetization dynamics in an LBM, and the spin-polarized pinning current I-p, which stabilizes the magnetization of an LBM in a chosen direction within a chosen time. We show that common fabrication defects in LBMs make these two parameters unpredictable because they are strongly sensitive to the defects. That makes the design of BSNs with real LBMs very challenging. Unless the LBMs are fabricated with extremely tight control, the BSNs that use them could be unreliable or suffer from poor yield.
C1 [Abeed, Md. Ahsanul; Bandyopadhyay, Supriyo] Virginia Commonwealth Univ, Dept Elect & Comp Engn, Med Coll Virginia Campus, Richmond, VA 23284 USA.
RP Bandyopadhyay, S (corresponding author), Virginia Commonwealth Univ, Dept Elect & Comp Engn, Med Coll Virginia Campus, Richmond, VA 23284 USA.
EM sbandy@vcu.edu
CR Abeed MA, 2017, IEEE T ELECTRON DEV, V64, P2417, DOI 10.1109/TED.2017.2679604
   Ahmad H, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/40/401001
   [Anonymous], 1964, PHYS MAGNETISM
   Bass J, 2007, J PHYS-CONDENS MAT, V19, DOI 10.1088/0953-8984/19/18/183201
   Bautin VA, 2017, AIP ADV, V7, DOI 10.1063/1.4979889
   Bhanja S, 2016, NAT NANOTECHNOL, V11, P177, DOI [10.1038/nnano.2015.245, 10.1038/NNANO.2015.245]
   Biswas AK, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/28/285201
   Biswas AK, 2014, SCI REP-UK, V4, DOI 10.1038/srep07553
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Chakraborty I, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2839097
   D'Souza N, 2016, NANO LETT, V16, P1069, DOI 10.1021/acs.nanolett.5b04205
   D'Souza N, 2012, IEEE T NANOTECHNOL, V11, P896, DOI 10.1109/TNANO.2012.2204769
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Faria R, 2017, IEEE MAGN LETT, V8, DOI 10.1109/LMAG.2017.2685358
   Hassan O, 2019, IEEE MAGN LETT, V10, DOI 10.1109/LMAG.2019.2910787
   Khasanvis S, 2015, COMPUTER, V48, P54, DOI 10.1109/MC.2015.367
   Khasanvis S, 2015, IEEE T NANOTECHNOL, V14, P980, DOI 10.1109/TNANO.2015.2439618
   Liu LQ, 2012, SCIENCE, V336, P555, DOI 10.1126/science.1218197
   Mellnik AR, 2014, NATURE, V511, P449, DOI 10.1038/nature13534
   Miron IM, 2010, NAT MATER, V9, P230, DOI [10.1038/NMAT2613, 10.1038/nmat2613]
   Munira K, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/24/245202
   Nasrin S, 2019, IEEE ELECTR DEVICE L, V40, P345, DOI 10.1109/LED.2018.2889881
   Patil A. D., ARXIV170206119
   Pervaiz AZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11011-8
   Ralph DC, 2008, J MAGN MAGN MATER, V320, P1190, DOI 10.1016/j.jmmm.2007.12.019
   Roy K, 2011, APPL PHYS LETT, V99, DOI 10.1063/1.3624900
   Roy U, 2016, IEEE T MAGN, V52, DOI 10.1109/TMAG.2016.2580532
   Sharad M, 2014, IEEE T NANOTECHNOL, V13, P23, DOI 10.1109/TNANO.2013.2286424
   Shiota Y, 2017, APPL PHYS LETT, V111, DOI 10.1063/1.4990680
   Shiota Y, 2009, APPL PHYS EXPRESS, V2, DOI 10.1143/APEX.2.063001
   Sutton B, 2017, SCI REP-UK, V7, DOI 10.1038/srep44370
   Vansteenkiste A, 2014, AIP ADV, V4, DOI 10.1063/1.4899186
   Winters D, 2019, ARXIV190509322
   Yamanouchi M, 2004, NATURE, V428, P539, DOI 10.1038/nature02441
NR 34
TC 20
Z9 20
U1 0
U2 11
PY 2019
VL 10
DI 10.1109/LMAG.2019.2929484
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT J
AU Liu, LL
   Shen, LY
   Yang, Y
   Schüler, E
   Zhao, W
   Wetzstein, G
   Xing, L
AF Liu, Lianli
   Shen, Liyue
   Yang, Yong
   Schueler, Emil
   Zhao, Wei
   Wetzstein, Gordon
   Xing, Lei
TI Modeling linear accelerator (Linac) beam data by implicit neural
   representation learning for commissioning and quality assurance
   applications
SO MEDICAL PHYSICS
DT Article; Early Access
DE beam data modeling; Linac commissioning; machine learning; quality
   assurance
ID QUANTITATIVE-EVALUATION; DOSE CALCULATIONS; PHOTON; ORGANS; QA
AB BackgroundLinear accelerator (Linac) beam data commissioning and quality assurance (QA) play a vital role in accurate radiation treatment delivery and entail a large number of measurements using a variety of field sizes. How to optimize the effort in data acquisition while maintaining high quality of medical physics practice has been sought after. PurposeWe propose to model Linac beam data through implicit neural representation (NeRP) learning. The potential of the beam model in predicting beam data from sparse measurements and detecting data collection errors was evaluated, with the goal of using the beam model to verify beam data collection accuracy and simplify the commissioning and QA process. Materials and MethodsNeRP models with continuous and differentiable functions parameterized by multilayer perceptrons (MLPs) were used to represent various beam data including percentage depth dose (PDD) and profiles of 6 MV beams with and without flattening filter. Prior knowledge of the beam data was embedded into the MLP network by learning the NeRP of a vendor-provided "golden" beam dataset. The prior-embedded network was then trained to fit clinical beam data collected at one field size and used to predict beam data at other field sizes. We evaluated the prediction accuracy by comparing network-predicted beam data to water tank measurements collected from 14 clinical Linacs. Beam datasets with intentionally introduced errors were used to investigate the potential use of the NeRP model for beam data verification, by evaluating the model performance when trained with erroneous beam data samples. ResultsLinac beam data predicted by the model agreed well with water tank measurements, with averaged Gamma passing rates (1%/1 mm passing criteria) higher than 95% and averaged mean absolute errors less than 0.6%. Beam data samples with measurement errors were revealed by inconsistent beam predictions between networks trained with correct versus erroneous data samples, characterized by a Gamma passing rate lower than 90%. ConclusionA NeRP beam data modeling technique has been established for predicting beam characteristics from sparse measurements. The model provides a valuable tool to verify beam data collection accuracy and promises to simplify commissioning/QA processes by reducing the number of measurements without compromising the quality of medical physics service.
C1 [Liu, Lianli; Yang, Yong; Schueler, Emil; Zhao, Wei; Xing, Lei] Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94304 USA.
   [Shen, Liyue; Wetzstein, Gordon; Xing, Lei] Stanford Univ, Dept Elect Engn, Palo Alto, CA 94304 USA.
RP Liu, LL (corresponding author), Stanford Univ, Dept Radiat Oncol, Palo Alto, CA 94304 USA.
EM llliu@stanford.edu; lei@stanford.edu
CR Beyer GP, 2013, J APPL CLIN MED PHYS, V14, P273, DOI 10.1120/jacmp.v14i1.4077
   Chan MF, 2020, FRONT ARTIF INTELL, V3, DOI 10.3389/frai.2020.577620
   Chen YB, 2021, PROC CVPR IEEE, P8624, DOI 10.1109/CVPR46437.2021.00852
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Das IJ, 2012, MED PHYS, V39, P569, DOI 10.1118/1.3658740
   Dupont E, 2021, Arxiv, DOI arXiv:2103.03123
   Dupont E, 2022, Arxiv, DOI [arXiv:2102.04776, 10.1016/j.lwt.2022.113600]
   Eslami SMA, 2018, SCIENCE, V360, P1204, DOI 10.1126/science.aar6170
   Fan JW, 2020, PHYS MED BIOL, V65, DOI 10.1088/1361-6560/aba165
   Hrbacek J, 2007, MED PHYS, V34, P2917, DOI 10.1118/1.2745239
   Ibbott GS, 2008, INT J RADIAT ONCOL, V71, pS71, DOI 10.1016/j.ijrobp.2007.08.083
   Ibragimov B, 2017, MED PHYS, V44, P547, DOI 10.1002/mp.12045
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Liu LL, 2022, MED PHYS, V49, P6110, DOI 10.1002/mp.15822
   Liu LL, 2021, PHYS MED BIOL, V66, DOI 10.1088/1361-6560/ac1f37
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Narayanasamy G, 2016, J APPL CLIN MED PHYS, V17, P179, DOI 10.1120/jacmp.v17i1.5799
   Netherton T, 2019, MED PHYS, V46, P4304, DOI 10.1002/mp.13723
   Qureshi AH, 2021, Arxiv, DOI arXiv:2106.01352
   Shen LY, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3177134
   Shen LY, 2019, NAT BIOMED ENG, V3, P880, DOI 10.1038/s41551-019-0466-4
   Shen Tianchang, 2021, ADV NEURAL INFORM PR
   Sitzmann V., 2020, ARXIV200609661
   Sitzmann V, 2019, ADV NEUR IN, V32
   Smilowitz JB, 2015, J APPL CLIN MED PHYS, V16, P14, DOI 10.1120/jacmp.v16i5.5768
   Song Y, 2020, RADIOTHER ONCOL, V145, P186, DOI 10.1016/j.radonc.2020.01.020
   Tancik Matthew, 2020, ADV NEURAL INFORM PR, P2, DOI DOI 10.48550/ARXIV.2006.10739
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Vasudevan V, 2022, PHYS MED BIOL, V67, DOI 10.1088/1361-6560/ac6b10
   Venselaar J, 2001, RADIOTHER ONCOL, V60, P191, DOI 10.1016/S0167-8140(01)00377-2
   Zhao W, 2020, RADIOTHER ONCOL, V153, P122, DOI 10.1016/j.radonc.2020.09.057
   Zhao W, 2019, INT J RADIAT ONCOL, V105, P432, DOI 10.1016/j.ijrobp.2019.05.071
NR 32
TC 0
Z9 0
U1 4
U2 8
PD 2023 JAN 14
PY 2023
DI 10.1002/mp.16212
EA JAN 2023
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Al Badawi, A
   Veeravalli, B
   Aung, KMM
   Hamadicharef, B
AF Al Badawi, Ahmad
   Veeravalli, Bharadwaj
   Aung, Khin Mi Mi
   Hamadicharef, Brahim
TI Accelerating subset sum and lattice based public-key cryptosystems with
   multi-core CPUs and GPUs
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article
DE Lattice cryptography; Post-quantum cryptography; Public-key
   cryptosystem; Subset sum; Learning with errors; GPGPU programming;
   Parallel polynomial multiplier
AB Post-quantum cryptosystems based on subset sum and lattice problems have gained much attention from researchers due to their simple construction, their resistance to quantum attacks, the new potential applications they provide, and above all, the mathematical security proofs that rigorously relate them to computational hard problems. However, the computational complexity of these cryptosystems is still high compared to classic number-theoretical ones, which may impede their adoption on a large scale. We studied the performance of three public-key cryptosystems based on subset sum, learning with errors and ring learning with errors problems. We provide a systematic study for choosing their parameters to guarantee sufficient security levels and detail an asymptotic comparison between them in terms of storage and running time complexities. We accelerate the running time of these cryptosystems by exploiting the inherent parallelism in computations through a GPGPU-based parallel implementation. The cryptosystems are implemented using C++ on Intel(R) Xeon(R) multi-core 64-bit processors machine with CUDA-enabled Tesla K80 GPUs. The parallel implementation is based on OpenCL framework and can run on arbitrary hardware platform accelerators with minor changes. Several optimizations and efficient algorithms were used to compute the core operations in each cryptosystem to achieve optimum performance. The ring learning with errors based cryptosystem showed the best performance while the Subset Sum cryptosystem showed the highest speedup gain for the encryption primitive. (C) 2018 Elsevier Inc. All rights reserved.
C1 [Al Badawi, Ahmad; Veeravalli, Bharadwaj] Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
   [Al Badawi, Ahmad; Aung, Khin Mi Mi; Hamadicharef, Brahim] ASTAR, DSI, Connexis North Lobby 1 Fusionopolis Way, Singapore 138632, Singapore.
RP Al Badawi, A (corresponding author), Natl Univ Singapore, Dept Elect & Comp Engn, 4 Engn Dr 3, Singapore 117576, Singapore.
EM ahmad@u.nus.edu; elebv@nus.edu.sg; mi_mi_aung@dsi.a-star.edu.sg;
   brahim-hamad@dsi.a-star.edu.sg
CR Aguilar-Melchor C, 2016, LECT NOTES COMPUT SC, V9610, P341, DOI 10.1007/978-3-319-29485-8_20
   Ajtai M., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P99, DOI 10.1145/237814.237838
   Akavik A, 2009, LECT NOTES COMPUT SC, V5444, P474
   Albrecht MR, 2015, J MATH CRYPTOL, V9, P169, DOI 10.1515/jmc-2015-0016
   [Anonymous], 1996, POLYNOMIAL ALGORITHM, DOI DOI 10.1007/978-3-7091-6571-3
   [Anonymous], 2019, NIST SPECIAL PUBLICA, DOI DOI 10.6028/NIST.SP.800-57PT1R4
   [Anonymous], 2016, NAS LAUNCH QUANT COM
   [Anonymous], 2012, IEEE C HIGH PERFORMA, DOI [10.1109/HPEC.2012.6408660, DOI 10.1109/PEAM.2012.6612493]
   Baladron J, 2012, COMPUT SCI ENG, V14, P40, DOI 10.1109/MCSE.2011.119
   Bennett CH, 1997, SIAM J COMPUT, V26, P1510, DOI 10.1137/S0097539796300933
   Bernstein D. J., 2009, POSTQUANTUM CRYPTOGR, P1, DOI [DOI 10.1007/978-3-540-88702-7_1, DOI 10.1007/978-3-540-88702-7]
   CHOR B, 1988, IEEE T INFORM THEORY, V34, P901, DOI 10.1109/18.21214
   Coster MJ, 1992, COMPUT COMPLEX, V2, P111, DOI DOI 10.1007/BF01201999
   Crandall R., 2006, PRIME NUMBERS COMPUT
   de Clercq R, 2015, DES AUT TEST EUROPE, P339
   Du CH, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P9, DOI 10.1145/2902961.2902969
   Garey M. R., 1979, COMPUTERS INTRACTABI
   Gentry C, 2009, ACM S THEORY COMPUT, P169, DOI 10.1145/1536414.1536440
   Halderman JA, 2009, COMMUN ACM, V52, P91, DOI 10.1145/1506409.1506429
   Hallgren Sven, 2008, POSTQUANTUM CRYPTOGR, P15, DOI [10.1007/978-3-540-88702-7_2, DOI 10.1007/978-3-540-88702-7_2]
   Hamasho S, 2014, IEICE T FUND ELECTR, VE97A, P298, DOI 10.1587/transfun.E97.A.298
   Jain A, 2014, ADV INTELL SYST, V299, P375, DOI 10.1007/978-3-319-07995-0_37
   Laine K., 2015, IACR CRYPTOL, V2015, P176
   LENSTRA AK, 1982, MATH ANN, V261, P515, DOI 10.1007/BF01457454
   Lindner R., 2016, TU DARMSTADT LATTICE
   Liu Z, 2015, LECT NOTES COMPUT SC, V9293, P663, DOI 10.1007/978-3-662-48324-4_33
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Lyubashevsky V, 2013, LECT NOTES COMPUT SC, V7881, P35, DOI 10.1007/978-3-642-38348-9_3
   Lyubashevsky V, 2010, LECT NOTES COMPUT SC, V5978, P382, DOI 10.1007/978-3-642-11799-2_23
   Lyubashevsky V, 2009, LECT NOTES COMPUT SC, V5677, P577, DOI 10.1007/978-3-642-03356-8_34
   MERKLE RC, 1978, IEEE T INFORM THEORY, V24, P525, DOI 10.1109/TIT.1978.1055927
   Michalakes J, 2008, PARALLEL PROCESS LET, V18, P531, DOI 10.1142/S0129626408003557
   Mingjie Liu, 2013, Topics in Cryptology - CT-RSA 2013. The Cryptographers Track at the RSA Conference 2013. Proceedings, P293, DOI 10.1007/978-3-642-36095-4_19
   Poppelmann Thomas, 2012, Progress in Cryptology - LATINCRYPT 2012. Proceedings of the 2nd International Conference on Cryptology and Information Security in Latin America, P139, DOI 10.1007/978-3-642-33481-8_8
   Regev O., 2010, CCC
   Regev O, 2009, J ACM, V56, DOI 10.1145/1568318.1568324
   Rehman T., 2011, OPENCL OPTIMIZATION
   Rupp K., 2012, GPU ACCELERATED NONN, P77
   SCHNORR CP, 1994, MATH PROGRAM, V66, P181, DOI 10.1007/BF01581144
   Shamir A., 1983, Advances in Cryptology, Proceedings of Crypto 82, P279
   Shor P. W., 1994, Proceedings. 35th Annual Symposium on Foundations of Computer Science (Cat. No.94CH35717), P124, DOI 10.1109/SFCS.1994.365700
   Shoup V., 2009, COMPUTATIONAL INTRO, DOI [10.1017/CB0978051181, DOI 10.1017/CB0978051181]
   Shoup V., 2001, NTL LIB DOING NUMBER
   Vaudenay S, 1998, LECT NOTES COMPUT SC, V1462, P243, DOI 10.1007/BFb0055732
   Walter J., 2002, UBLAS BOOST BASIC LI
NR 45
TC 4
Z9 4
U1 0
U2 8
PD SEP
PY 2018
VL 119
BP 179
EP 190
DI 10.1016/j.jpdc.2018.04.014
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Park, YR
   Kim, JH
   Do, J
   Kim, JY
AF Park, Yeo-Reum
   Kim, Ji-Hoon
   Do, Jaeyoung
   Kim, Joo-Young
GP IEEE
TI A Dual-Mode Similarity Search Accelerator based on Embedding Compression
   for Online Cross-Modal Image-Text Retrieval
SO 2022 IEEE 30TH INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM
   COMPUTING MACHINES (FCCM 2022)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT IEEE 30th International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 15-18, 2022
CL New York, NY
AB Image-text retrieval (ITR) that identifies the relevant images for a given text query, or vice versa, is the fundamental task in emerging vision-and-language machine learning applications. Recently, the cross-modal approach that extracts image and text features in separate reasoning pipelines but performs the similarity search on the same embedding representation is proposed for the real-time ITR system. However, the similarity search that finds the most relevant data in huge data embeddings for a given query becomes the bottleneck of the ITR system. In this paper, we propose a dual-mode similarity search accelerator that can solve the computational hurdle for online image-to-text and text-to-image retrieval service. We propose an embedding compression scheme that removes the sparsity in the text embeddings, further eliminating the time-consuming masking operations in the later processing pipeline. Combining with the data quantization from 32-bit floating-point to 8bit integer, we reduce the target dataset size by 95.1% with less than 0.1% accuracy loss for 1024-dimensional embedding features. In addition, we propose a streamlined similarity search data flow for both query types, which minimizes the required memory bandwidth with maximal data reuse. The query and data embeddings are guaranteed to be fetched only once from the external memory with the optimized data flow. Based on the proposed data representation and flow, we design a scalable similarity search accelerator that includes multiple ITR kernels. Each ITR kernel has modular design, composed of a separate memory access module and a computing module. The computing module supports pipelined operations of the four similarity search tasks: dot product calculation, data reordering, partial score aggregation, and ranking. We double the number of processing operations in the computing module with the DSP packing technique. Finally, we implement the proposed accelerator with six ITR kernels on the Xilinx Alveo U280 FPGA card. It shows 2.98 tera operations per second (TOPS) performance at 186 MHz, achieving 526/144 and 1163/306 queries per second (QPS) performance for image-to-text and text-to-image retrieval on MS-COCO 1K/5K benchmark. It is up to 359.0x and 13.9x faster and 503.6x and 68.7x more energy-efficient than the baseline and optimized GPU implementation on Nvidia Titan RTX, respectively.
C1 [Park, Yeo-Reum; Kim, Ji-Hoon; Kim, Joo-Young] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daegeon, South Korea.
   [Do, Jaeyoung] Amazon Alexa AI, Kirkland, WA 98033 USA.
RP Park, YR (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daegeon, South Korea.
EM summerpark@kaist.ac.kr; jihoon0708@kaist.ac.kr; domjae@amazon.com;
   jooyoung1203@kaist.ac.kr
CR Aneja J, 2018, PROC CVPR IEEE, P5561, DOI 10.1109/CVPR.2018.00583
   Antol S, 2015, IEEE I CONF COMP VIS, P2425, DOI 10.1109/ICCV.2015.279
   DeMicheli G, 1997, P IEEE, V85, P349, DOI 10.1109/5.558708
   Devlin J., 2018, PREPRINT
   Google, GOOGL IM
   Guo KY, 2016, IEEE HOT CHIP SYMP
   Kiros R, 2014, PR MACH LEARN RES, V32, P595
   Li X., 2020, LNCS, P121
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JY, 2017, IEEE I CONF COMP VIS, P4866, DOI 10.1109/ICCV.2017.520
   Lu J., 2019, ARXIV
   Messina, 2020, TERAN
   Messina N, 2021, ACM T MULTIM COMPUT, V17, DOI 10.1145/3451390
   Messina N, 2021, INT C PATT RECOG, P5222, DOI 10.1109/ICPR48806.2021.9413172
   Microsoft, BING IM TREND
   Monmasson E, 2007, IEEE T IND ELECTRON, V54, P1824, DOI 10.1109/TIE.2007.898281
   Paszke A, 2019, ADV NEUR IN, V32
   Qi D., 2020, ARXIV
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Shih KJ, 2016, PROC CVPR IEEE, P4613, DOI 10.1109/CVPR.2016.499
   Teich J, 2012, P IEEE, V100, P1411, DOI 10.1109/JPROC.2011.2182009
   Vaswani A, 2017, ADV NEUR IN, V30
   Xilinx, 2017, DEEP LEARN INT8 OPT
   Yang YF, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P23, DOI 10.1145/3289602.3293902
   Yao T, 2017, IEEE I CONF COMP VIS, P4904, DOI 10.1109/ICCV.2017.524
   Yen-Chun Chen, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12375), P104, DOI 10.1007/978-3-030-58577-8_7
   You QZ, 2016, PROC CVPR IEEE, P4651, DOI 10.1109/CVPR.2016.503
   Yu LC, 2018, PROC CVPR IEEE, P1307, DOI 10.1109/CVPR.2018.00142
NR 28
TC 0
Z9 0
U1 0
U2 1
PY 2022
BP 99
EP 107
DI 10.1109/FCCM53951.2022.9786159
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ibrahim, KZ
   Nguyen, T
   Nam, HA
   Bhimji, W
   Farrell, S
   Oliker, L
   Rowan, M
   Wright, NJ
   Williams, S
AF Ibrahim, Khaled Z.
   Tan Nguyen
   Hai Ah Nam
   Bhimji, Wahid
   Farrell, Steven
   Oliker, Leonid
   Rowan, Michael
   Wright, Nicholas J.
   Williams, Samuel
GP IEEE Comp Soc
TI Architectural Requirements for Deep Learning Workloads in HPC
   Environments
SO PROCEEDINGS OF PERFORMANCE MODELING, BENCHMARKING AND SIMULATION OF HIGH
   PERFORMANCE COMPUTER SYSTEMS (PMBS 2021)
DT Proceedings Paper
CT 12th International Workshop on Performance Modeling, Benchmarking and
   Simulation of High Performance Computer Systems held as part of the 33rd
   ACM/IEEE International Conference for High Performance Computing,
   Networking, Storage and Analysis
CY NOV 14-19, 2021
CL St Louis, MO
AB Scientific machine learning (SciML) promises to have a transformational impact on scientific exploration, by combining state-of-the-art AI methods with the latest generation of supercomputers. However, to efficiently leverage ML techniques on high-performance computing (HPC) systems, it is critical to understand the performance characteristics of the underlying algorithms on modern computational systems. In this work, we present a new methodology for developing a detailed performance understanding of ML benchmarks. To demonstrate our approach we investigate two emerging SciML benchmark applications from cosmology and climate, ComsoFlow and DeepCAM, as well as ResNet-50, a well-known image classification model. We develop and validate performance models that explore the key architectural artifacts, including memory requirements, data reuse, and performance efficiency across both single- and multiple-GPU computations. Our methodology also focuses on the complexity of data-movement across storage and memory hierarchies, and leverages our performance models to capture key components of runtime execution while highlighting design tradeoffs. Although our work focuses on image-processing methods on GPU-based HPC systems, our approach is applicable to a variety of ML algorithmic domains and emerging AI accelerators. Overall, our insights will help computer architects and data scientists understand performance bottlenecks and optimization opportunities to improve SciML design and system efficiency.
C1 [Ibrahim, Khaled Z.; Tan Nguyen; Hai Ah Nam; Bhimji, Wahid; Farrell, Steven; Oliker, Leonid; Rowan, Michael; Wright, Nicholas J.; Williams, Samuel] Lawrence Berkeley Natl Lab, NERSC CRD, Berkeley, CA 94720 USA.
RP Ibrahim, KZ (corresponding author), Lawrence Berkeley Natl Lab, NERSC CRD, Berkeley, CA 94720 USA.
CR Adolf R, 2016, I S WORKL CHAR PROC, P148
   [Anonymous], 1995, LOGGP INCORPORATING
   [Anonymous], 2021, HYPERION RES
   Baker Nathan, 2019, WORKSH REP BAS RES N, V2
   Ben-Nun T, 2019, INT PARALL DISTRIB P, P66, DOI 10.1109/IPDPS.2019.00018
   Chen L, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3278067
   Cordery M., 2013, PMBS SC
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dongarra J., HPL AI MIXED PRECISI, P2021
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Jiang Z., 2020, HPC AI500 METHODOLOG
   Kurth T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Li C, 2020, INT PARALL DISTRIB P, P326, DOI 10.1109/IPDPS47924.2020.00042
   Mathuriya A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Mattson Peter, 2020, MLSYS, V2, P336
   Patel T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356183
   Ren Y., 2019, PERFORMANCE ANAL DEE
   Tesla NVIDIA, 2017, NVIDIA, P108
   Vazhkudai SS, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Wang Y., 2020, HIERARCHICAL ROOFLIN
   Wang Y E, 2019, ARXIV190710701
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
NR 22
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 7
EP 17
DI 10.1109/PMBS54543.2021.00007
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Xue, RX
   Wang, MQ
   Wang, ZF
AF Xue, Ruixin
   Wang, Meiqi
   Wang, Zhongfeng
BE Pimenidis, E
   Angelov, P
   Jayne, C
   Papaleonidas, A
   Aydin, M
TI Boosting Both Robustness and Hardware Efficiency via Random Pruning Mask
   Selection
SO ARTIFICIAL NEURAL NETWORKS AND MACHINE LEARNING - ICANN 2022, PT I
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 31st International Conference on Artificial Neural Networks (ICANN)
CY SEP 06-09, 2022
CL Univ W England, Bristol, ENGLAND
HO Univ W England
DE Model compression; Network pruning; Adversarial machine learning; Deep
   learning
AB Deep neural networks (DNNs) are notorious for two key drawbacks: the vulnerability against adversarial attacks and the prohibitive cost of storage and computation, which greatly hinders DNNs' deployment on safety-critical yet resource-limited platforms. Although researchers have proposed adversary-aware pruning methods where adversarial training and network pruning are studied jointly to improve the robustness of pruned networks, they failed to attain a double-win, i.e., the achieved robustness is still limited and cannot surpass that of dense networks. In this work, pursuing a win-win in robustness and efficiency, we demonstrate that the robustness of pruned networks can be easily boosted by leveraging the stochastic policy. More specifically, we propose a Random Mask Selection (RMS) strategy where pruning masks are randomly sampled during inference to confuse attackers. Furthermore, a necessary hardware-aware algorithm optimization is introduced to eliminate the potential hardware overhead of RMS, and thus ensures a convenient implementation of RMS on existing hardware accelerators without sacrificing processing speed or power efficiency. Extensive experiments show that our approach achieves a double-win in robustness and compactness compared to dense models and outperforms the SOTA adversary-aware pruning method in terms of robustness.
C1 [Xue, Ruixin; Wang, Meiqi; Wang, Zhongfeng] Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
RP Wang, MQ; Wang, ZF (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing, Peoples R China.
EM rxxue@smail.nju.edu.cn; mqwang@smail.nju.edu.cn; zfwang@nju.edu.cn
CR [Anonymous], 2015, P IEEE INT C COMPUTE
   Devlin J, 2019, Arxiv, DOI [arXiv:1810.04805, DOI 10.48550/ARXIV.1810.04805]
   Feinman R, 2017, Arxiv, DOI arXiv:1703.00410
   Figurnov M, 2017, PROC CVPR IEEE, P1790, DOI 10.1109/CVPR.2017.194
   Fu Y., 2021, ADV NEURAL INF PROCE, V34, P20
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Guo YW, 2018, ADV NEUR IN, V31
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Goodfellow IJ, 2015, Arxiv, DOI [arXiv:1412.6572, DOI 10.48550/ARXIV.1412.6572]
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Madry A, 2019, Arxiv, DOI [arXiv:1706.06083, DOI 10.48550/ARXIV.1706.06083]
   Osborne M.J., 1994, COURSE GAME THEORY, DOI DOI 10.1016/j.neuropsychologia.2004.04.015
   Sehwag Vikash, 2020, ARXIV200210509
   Rakin AS, 2019, Arxiv, DOI arXiv:1905.13074
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Wang L, 2015, IEEE T IMAGE PROCESS, V24, P1424, DOI 10.1109/TIP.2015.2403231
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Ye SK, 2019, IEEE I CONF COMP VIS, P111, DOI 10.1109/ICCV.2019.00020
   Zhao Y, 2020, INT CONF ACOUST SPEE, P1593, DOI [10.1109/ICASSP40776.2020.9053977, 10.1109/icassp40776.2020.9053977]
NR 19
TC 0
Z9 0
U1 1
U2 1
PY 2022
VL 13529
BP 49
EP 60
DI 10.1007/978-3-031-15919-0_5
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Huang, LY
   Zang, X
   Gong, Y
   Yuan, B
AF Huang, Lingyi
   Zang, Xiao
   Gong, Yu
   Yuan, Bo
GP IEEE
TI Hardware Architecture of Graph Neural Network-enabled Motion Planner
   (Invited Paper)
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
DE Motion Planning; Neural Network; Hardware Accelerator
ID PROCESSOR
AB Motion planning aims to find a collision-free trajectory from the start to goal configurations of a robot. As a key cognition task for all the autonomous machines, motion planning is fundamentally required in various real-world robotic applications, such as 2-D/3-D autonomous navigation of unmanned mobile and aerial vehicles and high degree-of-freedom (DoF) autonomous manipulation of industry/medical robot arms and graspers.
   Motion planning can be performed using either non-learning-based classical algorithms or learning-based neural approaches. Most recently, the powerful capabilities of deep neural networks (DNNs) make neural planners become very attractive because of their superior planning performance over the classical methods. In particular, graph neural network (GNN)-enabled motion planner has demonstrated the state-of-the-art performance across a set of challenging high-dimensional planning tasks, motivating the efficient hardware acceleration to fully unleash its potential and promote its widespread deployment in practical applications.
   To that end, in this paper we perform preliminary study of the efficient accelerator design of the GNN-based neural planner, especially for the neural explorer as the key component of the entire planning pipeline. By performing in-depth analysis on the different design choices, we identify that the hybrid architecture, instead of the uniform sparse matrix multiplication (SpMM)-based solution that is popularly adopted in the existing GNN hardware, is more suitable for our target neural explorer. With a set of optimization on microarchitecture and dataflow, several design challenges incurred by using hybrid architecture, such as extensive memory access and imbalanced workload, can be efficiently mitigated. Evaluation results show that our proposed customized hardware architecture achieves order-of-magnitude performance improvement over the CPU/GPU-based implementation with respect to area and energy efficiency in various working environments.
C1 [Huang, Lingyi; Zang, Xiao; Gong, Yu; Yuan, Bo] Rutgers State Univ, Piscataway, NJ 08854 USA.
RP Huang, LY (corresponding author), Rutgers State Univ, Piscataway, NJ 08854 USA.
EM lingyi.huang@rutgers.edu; xz514@scarletmail.rutgers.edu;
   yg430@scarletmail.rutgers.edu; bo.yuan@soe.rutgers.edu
CR Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Bency MJ, 2019, IEEE INT C INT ROBOT, P3965, DOI [10.1109/IROS40897.2019.8968089, 10.1109/iros40897.2019.8968089]
   Chen BH, 2020, Arxiv, DOI arXiv:1903.00070
   Choset H., 2005, PRINCIPLES ROBOT MOT
   Chung CE, 2020, ISSCC DIG TECH PAP I, P324
   Deng CH, 2021, CONF PROC INT SYMP C, P1110, DOI 10.1109/ISCA52012.2021.00090
   Deng CH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P264, DOI 10.1145/3307650.3322258
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Duchon F, 2014, PROCEDIA ENGINEER, V96, P59, DOI 10.1016/j.proeng.2014.12.098
   Everson LR, 2021, IEEE J SOLID-ST CIRC, V56, P2281, DOI 10.1109/JSSC.2020.3048726
   Geng T, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P922, DOI 10.1109/MICRO50266.2020.00079
   Han S, 2016, Arxiv, DOI [arXiv:1510.00149, DOI 10.48550/ARXIV.1510.00149]
   Huang Lingyi, 2022, GLSVLSI '22: Proceedings of the Great Lakes Symposium on VLSI 2022, P373, DOI 10.1145/3526241.3530367
   Karaman S, 2011, IEEE INT CONF ROBOT, P1478
   Karaman S, 2011, INT J ROBOT RES, V30, P846, DOI 10.1177/0278364911406761
   Kavraki LE, 1996, IEEE T ROBOTIC AUTOM, V12, P566, DOI 10.1109/70.508439
   Khan A, 2020, Arxiv, DOI arXiv:2006.06248
   Kim Y, 2016, ISSCC DIG TECH PAP I, V59, P258, DOI 10.1109/ISSCC.2016.7418005
   Kuffner J. J.  Jr., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P995, DOI 10.1109/ROBOT.2000.844730
   LaValle SM, 2001, ALGORITHMIC AND COMPUTATIONAL ROBOTICS: NEW DIRECTIONS, P293
   Li JJ, 2021, INT S HIGH PERF COMP, P775, DOI 10.1109/HPCA51647.2021.00070
   Lian SQ, 2018, DES AUT CON, DOI 10.1145/3195970.3196020
   Liao SY, 2019, AAAI CONF ARTIF INTE, P4287
   Murray S, 2016, INT SYMP MICROARCH
   Nair R.S., 2020, 11 INT C COMP COMM N, P1
   Qureshi AH, 2019, IEEE INT CONF ROBOT, P2118, DOI [10.1109/icra.2019.8793889, 10.1109/ICRA.2019.8793889]
   Rodríguez S, 2006, IEEE INT CONF ROBOT, P895
   Tamosiunaite Minija, 2020, ARXIV
   Toma AI, 2021, Arxiv, DOI arXiv:2105.00312
   Xiao S., 2017, P IEEE INT C FIELD P, P1
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Yang X, 2020, Arxiv, DOI arXiv:1809.04070
   Yin M, 2021, PROC CVPR IEEE, P10669, DOI 10.1109/CVPR46437.2021.01053
   Yin M, 2021, PROC CVPR IEEE, P12080, DOI 10.1109/CVPR46437.2021.01191
   Yin Miao, 2022, P IEEECVF C COMPUTER, P12299
   Yu C, 2021, PROC IEEE CUSTOM INT, P1
   Yu C., 2021, ADV NEURAL INFORM PR, P4274
   Zang Xiao, 2022, 2022 IEEERSJ INT C I
   Zhang BY, 2020, IEEE INT CONF ASAP, P61, DOI 10.1109/ASAP49362.2020.00019
   Zhang Z, 2014, INT J SMART HOME, V8, P75
NR 41
TC 0
Z9 0
U1 0
U2 0
PY 2022
DI 10.1145/3508352.3561113
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Wang, Z
   Xiao, YH
   Liao, K
   Li, TT
   Song, H
   Chen, HS
   Uddin, SMZ
   Mao, D
   Wang, FF
   Zhou, ZP
   Yuan, B
   Jiang, W
   Fontaine, NK
   Agrawal, A
   Willner, AE
   Hu, XY
   Gu, TY
AF Wang, Zi
   Xiao, Yahui
   Liao, Kun
   Li, Tiantian
   Song, Hao
   Chen, Haoshuo
   Uddin, S. M. Zia
   Mao, Dun
   Wang, Feifan
   Zhou, Zhiping
   Yuan, Bo
   Jiang, Wei
   Fontaine, Nicolas K.
   Agrawal, Amit
   Willner, Alan E.
   Hu, Xiaoyong
   Gu, Tingyi
TI Metasurface on integrated photonic platform: from mode converters to
   machine learning
SO NANOPHOTONICS
DT Review
DE deep learning; metasurface; silicon photonics
ID INVERSE DESIGN; WAVE-GUIDE; DIFFRACTIVE OPTICS; NEURAL-NETWORK; SILICON;
   POLARIZATION; PHASE; RESOLUTION; GENERATION; PROJECTION
AB Integrated photonic circuits are created as a stable and small form factor analogue of fiber-based optical systems, from wavelength-division multiplication transceivers to more recent mode-division multiplexing components. Silicon nanowire waveguides guide the light in a way that single and few mode fibers define the direction of signal flow. Beyond communication tasks, on-chip cascaded interferometers and photonic meshes are also sought for optical computing and advanced signal processing technology. Here we review an alternative way of defining the light flow in the integrated photonic platform, using arrays of subwavelength meta-atoms or metalines for guiding the diffraction and interference of light. The integrated metasurface system mimics free-space optics, where on-chip analogues of basic optical components are developed with foundry compatible geometry, such as low-loss lens, spatial-light modulator, and other wavefront shapers. We discuss the role of metasurface in integrated photonic signal processing systems, introduce the design principles of such metasurface systems for low loss compact mode conversion, mathematical operation, diffractive optical systems for hyperspectral imaging, and tuning schemes of metasurface systems. Then we perceive reconfigurability schemes for metasurface framework, toward optical neural networks and analog photonic accelerators.
C1 [Wang, Zi; Xiao, Yahui; Uddin, S. M. Zia; Mao, Dun; Gu, Tingyi] Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19711 USA.
   [Wang, Zi; Agrawal, Amit] NIST, Phys Measurement Lab, Gaithersburg, MD 20899 USA.
   [Liao, Kun; Wang, Feifan; Zhou, Zhiping; Hu, Xiaoyong] Peking Univ, Beijing 100871, Peoples R China.
   [Li, Tiantian] Xian Univ Posts & Telecommun, Sch Elect Engn, Xian 710121, Peoples R China.
   [Song, Hao; Willner, Alan E.] Univ South Calif, Dept Elect & Comp Engn, Los Angeles, CA 90089 USA.
   [Willner, Alan E.] Univ South Calif, Dept Phys & Astron, Los Angeles, CA 90089 USA.
   [Chen, Haoshuo; Fontaine, Nicolas K.] Nokia Bell Labs, 600 Mt Ave, Murray Hill, NJ 07974 USA.
   [Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
   [Jiang, Wei] Nanjing Univ, Coll Engn & Appl Sci, Nanjing 210093, Peoples R China.
RP Gu, TY (corresponding author), Univ Delaware, Dept Elect & Comp Engn, Newark, DE 19711 USA.
EM tingyigu@udel.edu
CR Abbas MA, 2022, NANOSCALE, V14, P6425, DOI 10.1039/d1nr08400c
   Abdollahramezani S, 2020, NANOPHOTONICS-BERLIN, V9, P4075, DOI 10.1515/nanoph-2020-0285
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Arbabi A, 2017, NAT PHOTONICS, V11, P415, DOI [10.1038/NPHOTON.2017.96, 10.1038/nphoton.2017.96]
   Arbabi A, 2015, NAT NANOTECHNOL, V10, P937, DOI [10.1038/NNANO.2015.186, 10.1038/nnano.2015.186]
   Arbabi A, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8069
   Arbabi E, 2017, OPTICA, V4, P625, DOI 10.1364/OPTICA.4.000625
   Asgari B, 2021, INT S HIGH PERF COMP, P908, DOI 10.1109/HPCA51647.2021.00080
   Backer AS, 2019, OPT EXPRESS, V27, P30308, DOI 10.1364/OE.27.030308
   Buhler FN, 2017, SYMP VLSI CIRCUITS, pC30, DOI 10.23919/VLSIC.2017.8008536
   Chandrasekar R, 2019, OPT ENG, V58, DOI 10.1117/1.OE.58.2.020901
   Chang J, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-30619-y
   Chen C, 2021, NANOPHOTONICS-BERLIN, V10, P2481, DOI 10.1515/nanoph-2021-0137
   Chen HL, 2023, INTERACT LEARN ENVIR, V31, P3018, DOI [10.1109/ICCCI51764.2021.9486782, 10.1080/10494820.2021.1916765]
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XZ, 2012, NAT COMMUN, V3, DOI 10.1038/ncomms2207
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cheng M, 2017, DES AUT CON, DOI 10.1145/3061639.3062326
   Chih YD, 2021, ISSCC DIG TECH PAP I, V64, P252, DOI 10.1109/ISSCC42613.2021.9365766
   Choi C, 2021, ADV FUNCT MATER, V31, DOI 10.1002/adfm.202007210
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   Delaney M, 2021, SCI ADV, V7, DOI 10.1126/sciadv.abg3500
   Domínguez A, 2015, IEEE PULSE, V6, P38, DOI 10.1109/MPUL.2014.2366903
   Fan YL, 2017, ACS NANO, V11, P4599, DOI 10.1021/acsnano.7b00150
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feng CH, 2022, Arxiv, DOI arXiv:2111.06705
   Feng L, 2013, NAT MATER, V12, P108, DOI [10.1038/NMAT3495, 10.1038/nmat3495]
   Gok G, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.233904
   Guo C, 2018, OPTICA, V5, P251, DOI 10.1364/OPTICA.5.000251
   Guo JS, 2020, LASER PHOTONICS REV, V14, DOI 10.1002/lpor.202000058
   Happ TD, 2001, OPT LETT, V26, P1102, DOI 10.1364/OL.26.001102
   Huang LL, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3808
   Jahani S, 2016, NAT NANOTECHNOL, V11, P23, DOI [10.1038/nnano.2015.304, 10.1038/NNANO.2015.304]
   Jalali B, 2006, J LIGHTWAVE TECHNOL, V24, P4600, DOI 10.1109/JLT.2006.885782
   Jin ZW, 2021, ELIGHT, V1, P5, DOI DOI 10.1186/S43593-021-00005-9
   Khaddam-Aljameh R, 2021, 2021 S VLSI CIRCUITS, P1, DOI 10.23919/VLSICircuits52068.2021.9492362
   Khorasaninejad M, 2016, NANO LETT, V16, P3732, DOI 10.1021/acs.nanolett.6b01097
   Khorasaninejad M, 2016, SCIENCE, V352, P1190, DOI 10.1126/science.aaf6644
   Kitayama K, 2019, APL PHOTONICS, V4, DOI 10.1063/1.5108912
   Knag P. C., 2020, 2020 IEEE S VLSI CIR, P1
   Kruk S., 2018, C LASERS ELECTRO OPT
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lassaline N, 2020, NATURE, V582, P506, DOI 10.1038/s41586-020-2390-x
   Lee BG, 2010, 2010 23RD ANNUAL MEETING OF THE IEEE PHOTONICS SOCIETY, P564, DOI 10.1109/PHOTONICS.2010.5699012
   Lee BG, 2012, J LIGHTWAVE TECHNOL, V30, P886, DOI 10.1109/JLT.2012.2183853
   Lee D., 2022, ELIGHT, V2, P1, DOI [DOI 10.1186/S43593-021-00008-6, 10.1186/s43593-021-00008-6]
   Li CL, 2019, NANOPHOTONICS-BERLIN, V8, P227, DOI 10.1515/nanoph-2018-0161
   Li JX, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-17390-3
   Li L., 2022, ELIGHT, V2, P7, DOI 10.1186/s43593-022-00013-3
   Li T., 2021, C LASERS ELECTRO OPT
   Li ZY, 2017, NAT NANOTECHNOL, V12, P675, DOI [10.1038/nnano.2017.50, 10.1038/NNANO.2017.50]
   Liao K, 2020, NANOPHOTONICS-BERLIN, V9, P3315, DOI 10.1515/nanoph-2020-0069
   Lin DM, 2014, SCIENCE, V345, P298, DOI 10.1126/science.1253213
   Lin J, 2013, SCIENCE, V340, P331, DOI 10.1126/science.1233746
   Liu C, 2021, ACS PHOTONICS, V8, P716, DOI 10.1021/acsphotonics.0c01929
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Liu Y., 2021, OPTICAL FIBER COMMUN, pF4A
   Liu YZ, 2017, OPT EXPRESS, V25, P17201, DOI 10.1364/OE.25.017201
   Luo LW, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4069
   MARR D, 1980, PROC R SOC SER B-BIO, V207, P187, DOI 10.1098/rspb.1980.0020
   Miscuglio M, 2020, OPTICA, V7, P1812, DOI 10.1364/OPTICA.408659
   Molesky S, 2018, NAT PHOTONICS, V12, P659, DOI 10.1038/s41566-018-0246-9
   Neshev D, 2018, LIGHT-SCI APPL, V7, DOI 10.1038/s41377-018-0058-1
   Ni XJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3807
   Osgood R., 2021, PRINCIPLES PHOTONIC
   Pang K, 2021, NANO LETT, V21, P5907, DOI 10.1021/acs.nanolett.1c00550
   Piggott AY, 2015, NAT PHOTONICS, V9, P374, DOI [10.1038/nphoton.2015.69, 10.1038/NPHOTON.2015.69]
   Pors A, 2015, NANO LETT, V15, P791, DOI 10.1021/nl5047297
   Ren YX, 2016, SCI REP-UK, V6, DOI 10.1038/srep33306
   Richardson DJ, 2013, NAT PHOTONICS, V7, P354, DOI [10.1038/NPHOTON.2013.94, 10.1038/nphoton.2013.94]
   Saito D., 2021, PROC S VLSI CIRCUITS, P1, DOI DOI 10.23919/VLSICIRCUITS52068.2021.9492479
   Sanchis P, 2002, OPT EXPRESS, V10, P1391, DOI 10.1364/OE.10.001391
   Sayal A, 2019, ISSCC DIG TECH PAP I, V62, P228, DOI 10.1109/ISSCC.2019.8662510
   Shen B, 2015, NAT PHOTONICS, V9, P378, DOI [10.1038/NPHOTON.2015.80, 10.1038/nphoton.2015.80]
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Silva A, 2014, SCIENCE, V343, P160, DOI [10.1126/science.1242818, 10.1126/science.124405]
   Skivesen N, 2007, OPT EXPRESS, V15, P3169, DOI 10.1364/OE.15.003169
   Soref R, 2006, IEEE J SEL TOP QUANT, V12, P1678, DOI 10.1109/JSTQE.2006.883151
   Soref R, 2010, NAT PHOTONICS, V4, P495, DOI 10.1038/nphoton.2010.171
   Stern B, 2015, OPTICA, V2, P530, DOI 10.1364/OPTICA.2.000530
   Sun SL, 2012, NAT MATER, V11, P426, DOI [10.1038/nmat3292, 10.1038/NMAT3292]
   Sun WJ, 2016, LIGHT-SCI APPL, V5, DOI 10.1038/lsa.2016.3
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tu FB, 2018, CONF PROC INT SYMP C, P340, DOI 10.1109/ISCA.2018.00037
   Vakil A, 2011, SCIENCE, V332, P1291, DOI 10.1126/science.1202691
   Wada K, 2002, PROC SPIE, V4870, P437, DOI 10.1117/12.475558
   Wang C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02189-6
   Wang FF, 2020, CONF LASER ELECTR
   Wang HW, 2019, ADV OPT MATER, V7, DOI 10.1002/adom.201801191
   Wang L, 2018, NANO LETT, V18, P3978, DOI 10.1021/acs.nanolett.8b01460
   Wang NN, 2021, OPT LETT, V46, P4088, DOI 10.1364/OL.427386
   Wang ZW, 2021, 2021 5TH IEEE ELECTRON DEVICES TECHNOLOGY & MANUFACTURING CONFERENCE (EDTM), DOI 10.1109/EDTM50988.2021.9420957
   Wang Z, 2017, OPT LETT, V42, P2746, DOI 10.1364/OL.42.002746
   Wang Z, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-29856-7
   Wang Z, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11578-y
   Wu C., 2021, HARNESSING OPTOELECT
   Xiao YH, 2021, J OPT MICROSYST, V1, DOI 10.1117/1.JOM.1.2.024001
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yamamoto K, 2021, IEEE J SOLID-ST CIRC, V56, P165, DOI 10.1109/JSSC.2020.3027702
   Yan BN, 2017, ICCAD-IEEE ACM INT, P541, DOI 10.1109/ICCAD.2017.8203824
   Yang R, 2020, OPT LETT, V45, P5640, DOI 10.1364/OL.405446
   Yao CN, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.202000529
   Yao K, 2019, NANOPHOTONICS-BERLIN, V8, P339, DOI 10.1515/nanoph-2018-0183
   Yu NF, 2014, NAT MATER, V13, P139, DOI [10.1038/nmat3839, 10.1038/NMAT3839]
   Yulaev A, 2019, ACS PHOTONICS, V6, P2902, DOI 10.1021/acsphotonics.9b01000
   Zarei S, 2020, OPT EXPRESS, V28, P36668, DOI 10.1364/OE.404386
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang JH, 2021, OPT EXPRESS, V29, P32196, DOI 10.1364/OE.439106
   Zhang JF, 2019, SYMP VLSI CIRCUITS, pC306, DOI 10.23919/VLSIC.2019.8778193
   Zheng GX, 2015, NAT NANOTECHNOL, V10, P308, DOI [10.1038/NNANO.2015.2, 10.1038/nnano.2015.2]
   Zhou Y, 2020, ADV OPT MATER, V8, DOI 10.1002/adom.201901523
   Zhou Y, 2020, NAT PHOTONICS, V14, P316, DOI 10.1038/s41566-020-0591-3
   Zhu R., 2022, ELIGHT, V2, P10
   Zhu TF, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15391
NR 114
TC 5
Z9 6
U1 61
U2 200
PD AUG 17
PY 2022
VL 11
IS 16
BP 3531
EP 3546
DI 10.1515/nanoph-2022-0294
EA JUL 2022
WC Nanoscience & Nanotechnology; Materials Science, Multidisciplinary;
   Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Jang, H
   Kim, J
   Jo, JE
   Lee, J
   Kim, J
AF Jang, Hanhwi
   Kim, Joonsung
   Jo, Jae-Eon
   Lee, Jaewon
   Kim, Jangwoo
GP ACM
TI MnnFast: A Fast and Scalable System Architecture for Memory-Augmented
   Neural Networks
SO PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA '19)
DT Proceedings Paper
CT 46th International Symposium on Computer Architecture (ISCA) / Workshop
   on Computer Architecture Education (WCAE)
CY JUN 22-26, 2019
CL Phoenix, AZ
DE Memory Networks; Attention-based Neural Networks; Machine Learning;
   Parallel Algorithm; Computation/Dataflow Optimization; Accelerator;
   Algorithm-Hardware Co-Design; Architecture
ID ACCELERATOR
AB Memory-augmented neural networks are getting more attention from many researchers as they can make an inference with the previous history stored in memory. Especially, among these memory-augmented neural networks, memory networks are known for their huge reasoning power and capability to learn from a large number of inputs rather than other networks. As the size of input datasets rapidly grows, the necessity of large-scale memory networks continuously arises. Such large-scale memory networks provide excellent reasoning power; however, the current computer infrastructure cannot achieve scalable performance due to its limited system architecture.
   In this paper, we propose MnnFast, a novel system architecture for large-scale memory networks to achieve fast and scalable reasoning performance. We identify the performance problems of the current architecture by conducting extensive performance bottleneck analysis. Our in-depth analysis indicates that the current architecture suffers from three major performance problems: high memory bandwidth consumption, heavy computation, and cache contention. To overcome these performance problems, we propose three novel optimizations. First, to reduce the memory bandwidth consumption, we propose a new column-based algorithm with streaming which minimizes the size of data spills and hides most of the offchip memory accessing overhead. Second, to decrease the high computational overhead, we propose a zero-skipping optimization to bypass a large amount of output computation. Lastly, to eliminate the cache contention, we propose an embedding cache dedicated to efficiently cache the embedding matrix.
   Our evaluations show that MnnFast is significantly effective in various types of hardware: CPU, GPU, and FPGA. MnnFast improves the overall throughput by up to 5.38x, 4.34x, and 2.01x on CPU, GPU, and FPGA respectively. Also, compared to CPU-based MnnFast, our FPGA-based MnnFast achieves 6.54x higher energy efficiency.
C1 [Jang, Hanhwi; Jo, Jae-Eon] POSTECH Pohang, Dept Comp Sci & Engn, Pohang, South Korea.
   [Kim, Joonsung; Lee, Jaewon; Kim, Jangwoo] Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
RP Kim, J (corresponding author), Seoul Natl Univ, Dept Elect & Comp Engn, Seoul, South Korea.
EM hanhwi@postech.ac.kr; joonsung90@snu.ac.kr; jojaeeon@postech.ac.kr;
   lee.jaewon@snu.ac.kr; jangwoo@snu.ac.kr
CR Akhlaghi V, 2018, CONF PROC INT SYMP C, P662, DOI 10.1109/ISCA.2018.00061
   Akram R, 2017, I S WORKL CHAR PROC, P116, DOI 10.1109/IISWC.2017.8167765
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   [Anonymous], 2018, ICCAD IEEE ACM INT, DOI DOI 10.1145/3240765.3240796
   [Anonymous], 2018, CONF PROC INT SYMP C, DOI DOI 10.1109/ISCA.2018.00068
   [Anonymous], 6 INT C LEARN REPR I
   [Anonymous], 2018, ARXIV181006807
   [Anonymous], 6 INT C LEARN REPR I
   [Anonymous], ICCAD IEEE ACM INT
   [Anonymous], P 14 EUROSYST C 2019
   [Anonymous], INT 64 LA 32 ARCH SO
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2018, P 36 INT C MACH LEAR
   [Anonymous], CORR
   [Anonymous], 49 ANN IEEE ACM INT
   [Anonymous], 2018, CORR
   [Anonymous], 2011, BREAKING COPPERSMITH
   [Anonymous], CORR
   [Anonymous], 7 INT C LEARN REPR I
   [Anonymous], CORR
   [Anonymous], CORR
   [Anonymous], 2018, CONF PROC INT SYMP C, DOI DOI 10.1109/ISCA.2018.00051
   [Anonymous], 2016, CORR
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Bertran R, 2017, PR IEEE COMP DESIGN, P601, DOI 10.1109/ICCD.2017.105
   Bin Altaf MS, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P375, DOI [10.1145/3079856.3080216, 10.1145/3140659.3080216]
   Boston B, 2015, ACM SIGPLAN NOTICES, V50, P470, DOI [10.1145/2858965.2814301, 10.1145/2814270.2814301]
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chin T.-W., 2018, ARXIV181000518
   Davies Mark, 2008, CORPUS CONT AM ENGLI
   De Sa C, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P561, DOI 10.1145/3079856.3080248
   Ding RZ, 2017, PROCEEDINGS OF THE GREAT LAKES SYMPOSIUM ON VLSI 2017 (GLSVLSI' 17), P35, DOI 10.1145/3060403.3060465
   Donato M, 2018, DES AUT CON, DOI 10.1145/3195970.3196083
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Franchetti F, 2018, P IEEE, V106, P1935, DOI 10.1109/JPROC.2018.2873289
   Fuchs A, 2018, CONF PROC INT SYMP C, P353, DOI 10.1109/ISCA.2018.00038
   Gadioli D, 2019, IEEE T COMPUT, V68, P713, DOI 10.1109/TC.2018.2883597
   Goto K, 2008, ACM T MATH SOFTWARE, V34, DOI 10.1145/1356052.1356053
   Gysel P., 2016, ARXIV160403168
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harris ZS, 1954, WORD, V10, P146, DOI 10.1080/00437956.1954.11659520
   Hegde K, 2018, CONF PROC INT SYMP C, P674, DOI 10.1109/ISCA.2018.00062
   Hill P, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P786, DOI 10.1145/3123939.3123970
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   Ji HX, 2018, DES AUT TEST EUROPE, P237, DOI 10.23919/DATE.2018.8342009
   Kung J, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P403, DOI 10.1145/3079856.3080252
   Lee JH, 2018, IEEE T COMPUT, V67, P861, DOI 10.1109/TC.2017.2780237
   Lin MY, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240800
   Lin SC, 2018, ACM SIGPLAN NOTICES, V53, P751, DOI [10.1145/3296957.3173191, 10.1145/3173162.3173191]
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Miller A. H., 2016, ACL, P1400, DOI [10.18653/v1/D16-1147, 10.18653/v1/d16-1147]
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park E, 2018, CONF PROC INT SYMP C, P688, DOI 10.1109/ISCA.2018.00063
   Perais A, 2014, INT S HIGH PERF COMP, P428, DOI 10.1109/HPCA.2014.6835952
   Reagen, 2017, ARXIV PREPRINT ARXIV
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Reagen B, 2017, I SYMPOS LOW POWER E
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J., 2016, ARXIV160207360, P779
   Riera M, 2018, CONF PROC INT SYMP C, P57, DOI 10.1109/ISCA.2018.00016
   Sampson A., 2015, SUMMIT ADV PROGRAMMI, P262, DOI DOI 10.4230/LIPICS.SNAPL.2015.262
   San Miguel J, 2014, INT SYMP MICROARCH, P127, DOI 10.1109/MICRO.2014.22
   Shao YS, 2015, IEEE MICRO, V35, P58, DOI 10.1109/MM.2015.50
   Song MC, 2018, INT S HIGH PERF COMP, P92, DOI 10.1109/HPCA.2018.00018
   Song MC, 2018, INT S HIGH PERF COMP, P66, DOI 10.1109/HPCA.2018.00016
   Stamoulis D, 2018, DES AUT TEST EUROPE, P19
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Venkatagiri R, 2018, I C DEPEND SYS NETWO, P598, DOI 10.1109/DSN.2018.00067
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wang Q, 2013, INT CONF HIGH PERFOR, DOI 10.1145/2503210.2503219
   Weston J., 2015, ARXIV150205698
   Weston Jason, 2014, ARXIV14103916
   Wu CP, 2017, PROC CVPR IEEE, P761, DOI 10.1109/CVPR.2017.88
   Xianyi Z., 2012, 2012 IEEE 18 INT C P, P684, DOI DOI 10.1109/ICPADS.2012.97
   Yazdanbakhsh A, 2018, CONF PROC INT SYMP C, P650, DOI 10.1109/ISCA.2018.00060
   Yazdanbakhsh A, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2836168
   Yazdani R, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P69, DOI [10.1145/3123939.3124542, 10.1145/3123939.31.24542]
   Yazdani R, 2018, CONF PROC INT SYMP C, P790, DOI 10.1109/ISCA.2018.00071
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhu YH, 2017, IEEE MICRO, V37, P15
NR 87
TC 27
Z9 27
U1 0
U2 0
PY 2019
BP 250
EP 263
DI 10.1145/3307650.3322214
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Eldafrawy, M
   Boutros, A
   Yazdanshenas, S
   Betz, V
AF Eldafrawy, Mohamed
   Boutros, Andrew
   Yazdanshenas, Sadegh
   Betz, Vaughn
TI FPGA Logic Block Architectures for Efficient Deep Learning Inference
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Deep neural networks; FPGA; CAD tools
AB Reducing the precision of deep neural network (DNN) inference accelerators can yield large efficiency gains with little or no accuracy degradation compared to half or single precision floating-point by enabling more multiplication operations per unit area. A wide range of precisions fall on the pareto-optimal curve of hardware efficiency vs. accuracy with no single precision dominating, making the variable precision capabilities of FPGAs very valuable. We propose three types of logic block architectural enhancements and fully evaluate a total of six architectures that improve the area efficiency of multiplications and additions implemented in the soft fabric. Increasing the LUT fracturability and adding two adders to the ALM (4-bit Adder Double Chain architecture) leads to a 1.5x area reduction for arithmetic heavy machine learning (ML) kernels, while increasing their speed. In addition, this architecture also reduces the logic area of general applications by 6%, while increasing the critical path delay by only 1%. However, our highest impact option, which adds a 9-bit shadow multiplier to the logic clusters, reduces the area and critical path delay of ML kernels by 2.4x and 1.2x, respectively. These large gains come at a cost of 15% logic area increase for general applications.
C1 [Eldafrawy, Mohamed; Boutros, Andrew; Yazdanshenas, Sadegh; Betz, Vaughn] Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
RP Eldafrawy, M (corresponding author), Univ Toronto, Dept Elect & Comp Engn, 10 Kings Coll Rd, Toronto, ON M5S 3G4, Canada.
EM mohamed.eldafrawy@mail.utoronto.ca; andrew.boutros@mail.utoronto.ca;
   sadegh.yazdanshenas@mail.utoronto.ca; vaughn@ece.utoronto.ca
CR Ahmed E, 2004, IEEE T VLSI SYST, V12, P288, DOI 10.1109/TVLSI.2004.824300
   [Anonymous], 2015, P ACMSIGDA INT S FIE, DOI DOI 10.1145/2684746.2689071
   [Anonymous], 2019, INTEL STRATIX 10 MX
   [Anonymous], 2018, ARXIV180201548
   [Anonymous], 2001, P 2001 ACMSIGDA 9 IN
   [Anonymous], 2018, ADV NEUR IN
   BAUGH CR, 1973, IEEE T COMPUT, VC 22, P1045, DOI 10.1109/T-C.1973.223648
   Betz V, 1998, IEEE DES TEST COMPUT, V15, P10, DOI 10.1109/54.655177
   Betz V, 1997, PROCEEDINGS OF THE IEEE 1997 CUSTOM INTEGRATED CIRCUITS CONFERENCE, P551, DOI 10.1109/CICC.1997.606687
   Boutin A, 2019, FETAL DIAGN THER, V45, P69, DOI 10.1159/000487301
   Boutros A., 2018, TRETS, V11, P3
   Boutros A, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P94, DOI 10.1145/3289602.3293912
   Burich M., 2012, P INT S FIELD PROGR
   Cao Y., 2018, PREDICTIVE TECHNOLOG
   Chandrakar S., 2015, P 2015 ACM SIGDA INT, P108
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Intel Corporation, 2017, UGS10LAB INT CORP
   Intel Corporation, 2005, STRAT GX TRANS US GU
   Jamieson P, 2006, 2006 IEEE INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P1, DOI 10.1109/FPT.2006.270384
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kuon I, 2011, IEEE T VLSI SYST, V19, P71, DOI 10.1109/TVLSI.2009.2031318
   Langhammer M, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P202, DOI 10.1145/3289602.3293927
   Lewis D, 2005, HLTH INFORMAT SER, P1
   Lewis D, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P159, DOI 10.1145/2847263.2847267
   Lewis David, 2003, P 2003 ACM SIGDA 11, P12, DOI [10.1145/611817.611821, DOI 10.1145/611817.611821]
   Luu J, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2617593
   Masson C, 2013, PROCEEDINGS OF THE 2013 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P34, DOI 10.1109/FPT.2013.6718327
   Mike W., 2019, VIRTEX ULTRASCALE HB
   Mishra Asit, 2017, WRPN WIDE REDUCED PR
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   ROSE J, 1993, P IEEE, V81, P1013, DOI 10.1109/5.231340
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Trimberger SM, 2015, P IEEE, V103, P318, DOI 10.1109/JPROC.2015.2392104
   Xilinx Corporation, 2007, VIRT 2 PRO VIRT 2 PR
   Xilinx Corporation, 2007, VIRT 2 PLATF FPGA US
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
   Yazdanshenas S, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P9, DOI 10.1109/FPT.2017.8280115
NR 42
TC 11
Z9 11
U1 0
U2 6
PD SEP
PY 2020
VL 13
IS 3
AR 12
DI 10.1145/3393668
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Liu, GD
   Wang, S
   Bao, YG
AF Liu, Guodong
   Wang, Sa
   Bao, Yungang
BE Lee, J
   Cohen, A
TI SEER: A Time Prediction Model for CNNs from GPU Kernel's View
SO 30TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2021)
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT 30th International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY SEP 26-29, 2021
CL ELECTR NETWORK
DE machine learning; neural network; performance model; GPU
AB With the deepening of research and increasing size of data sets, deep neural networks have become larger and larger. To reduce the training time of large neural networks, researchers propose to optimize neural networks from different levels. When performing optimizations, prior knowledge about execution time of each part of the network can help avoid repeatedly time-consuming testing and profiling process. However it is quite challenging to build an accurate iteration time prediction model, due to opaque underlying implementation of network operators and complex architecture of accelerators. In this paper, we propose SEER, an iteration time prediction model for CNNs, targeting on GPU platforms. We propose to categorize convolution kernels into three different types: Compute-bound, DRAM-bound and Under-utilized, then we build performance model for each type respectively. We combined analytical models and learning-based models to make the performance model accurate and in line with GPU execution model. Experimental results show that, our model achieves 14.71% prediction error on convolution kernels and up to 1.79% prediction error for the overall computation time in one iteration of common CNNs. Besides, when used for selecting the best convolution algorithm, our model shows 7.14% lower error rate than cuDNN's official algorithm picker.
C1 [Liu, Guodong; Wang, Sa; Bao, Yungang] Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.
   [Liu, Guodong; Wang, Sa; Bao, Yungang] Univ Chinese Acad Sci, Beijing, Peoples R China.
   [Bao, Yungang] Peng Cheng Lab, Shenzhen, Peoples R China.
   [Wang, Sa] Chinese Acad Sci, Inst Comp Technol Nanjing, Nanjing, Peoples R China.
RP Liu, GD (corresponding author), Inst Comp Technol, State Key Lab Comp Architecture, Beijing, Peoples R China.; Liu, GD (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM liuguodong19z@ict.ac.cn; wangsa@ict.ac.cn; baoyg@ict.ac.cn
CR Abadi M, 2016, 12 USENIX S OP SYST, P265, DOI 10.5555/3026877.3026899
   [Anonymous], 1984, CLASSIFICATION REGRE, DOI DOI 10.1201/9781315139470
   [Anonymous], 2017, ACML
   Baghdadi R., 2021, P MACH LEARNING SYST, V3
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571, DOI DOI 10.1108/01439911111122716
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hong S, 2009, CONF PROC INT SYMP C, P152, DOI 10.1145/1555815.1555775
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jia ZH, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P47, DOI 10.1145/3341301.3359630
   Justus D, 2018, IEEE INT CONF BIG DA, P3873, DOI 10.1109/BigData.2018.8622396
   Kaufman S., 2021, P MACH LEARNING SYST, V3
   Kothapalli K, 2009, 16TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING (HIPC), PROCEEDINGS, P463, DOI 10.1109/HIPC.2009.5433179
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A, 2014, ABS14045997 CORR, Vabs/1404.5997
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LeCun Y., 2013, ARXIV PREPRINT ARXIV
   Li M, 2014, 11 USENIX S OP SYST, P583, DOI DOI 10.1145/2640087.2644155
   LITTLE JDC, 1961, OPER RES, V9, P383, DOI 10.1287/opre.9.3.383
   Mendis C, 2019, PR MACH LEARN RES, V97
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   NVIDIA, CUDA OCC CAL
   NVIDIA, 2020, CUDA PROGR GUID
   NVIDIA, 2020, GPU PERF BACKGR USER
   Paszke A., 2017, NEURIPS
   Pei Z., 2019, IEEE ACCESS, V7, p64 788
   Qi H., 2017, P 5 INT C LEARN REPR
   Seber GAF., 2003, NONLINEAR REGRESSION
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Volkov Vasily, 2016, THESIS UC BERKELEY
   Williams S, 2009, COMMUN ACM, V52, P65, DOI 10.1145/1498765.1498785
   Zhang Y, 2011, INT S HIGH PERF COMP, P382, DOI 10.1109/HPCA.2011.5749745
NR 35
TC 1
Z9 1
U1 0
U2 0
PY 2021
BP 173
EP 185
DI 10.1109/PACT52795.2021.00020
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Di Guglielmo, G
   Fahim, F
   Herwig, C
   Valentin, MB
   Duarte, J
   Gingu, C
   Harris, P
   Hirschauer, J
   Kwok, M
   Loncar, V
   Luo, YY
   Miranda, L
   Ngadiuba, J
   Noonan, D
   Ogrenci-Memik, S
   Pierini, M
   Summers, S
   Tran, N
AF Di Guglielmo, Giuseppe
   Fahim, Farah
   Herwig, Christian
   Valentin, Manuel Blanco
   Duarte, Javier
   Gingu, Cristian
   Harris, Philip
   Hirschauer, James
   Kwok, Martin
   Loncar, Vladimir
   Luo, Yingyi
   Miranda, Llovizna
   Ngadiuba, Jennifer
   Noonan, Daniel
   Ogrenci-Memik, Seda
   Pierini, Maurizio
   Summers, Sioni
   Tran, Nhan
TI A Reconfigurable Neural Network ASIC for Detector Front-End Data
   Compression at the HL-LHC
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article
DE Detectors; Artificial neural networks; Task analysis; Training; Field
   programmable gate arrays; Data compression; Computer architecture;
   Application-specific integrated circuit (ASIC); artificial intelligence
   (AI); autoencoder; hardware accelerator; high-level synthesis (HLS);
   Large Hadron Collider (LHC); machine learning (ML); single-event effect
   (SEE) mitigation
AB Despite advances in the programmable logic capabilities of modern trigger systems, a significant bottleneck remains in the amount of data to be transported from the detector to off-detector logic where trigger decisions are made. We demonstrate that a neural network (NN) autoencoder model can be implemented in a radiation-tolerant application-specific integrated circuit (ASIC) to perform lossy data compression alleviating the data transmission problem while preserving critical information of the detector energy profile. For our application, we consider the high-granularity calorimeter from the Compact Muon Solenoid (CMS) experiment at the CERN Large Hadron Collider. The advantage of the machine learning approach is in the flexibility and configurability of the algorithm. By changing the NN weights, a unique data compression algorithm can be deployed for each sensor in different detector regions and changing detector or collider conditions. To meet area, performance, and power constraints, we perform quantization-aware training to create an optimized NN hardware implementation. The design is achieved through the use of high-level synthesis tools and the hls4ml framework and was processed through synthesis and physical layout flows based on a low-power (LP)-CMOS 65-nm technology node. The flow anticipates 200 Mrad of ionizing radiation to select gates and reports a total area of 3.6 mm(2) and consumes 95 mW of power. The simulated energy consumption per inference is 2.4 nJ. This is the first radiation-tolerant on-detector ASIC implementation of an NN that has been designed for particle physics applications.
C1 [Di Guglielmo, Giuseppe] Columbia Univ, Comp Sci Dept, New York, NY 10027 USA.
   [Fahim, Farah; Herwig, Christian; Gingu, Cristian; Hirschauer, James; Miranda, Llovizna; Tran, Nhan] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Fahim, Farah; Valentin, Manuel Blanco; Luo, Yingyi; Ogrenci-Memik, Seda; Tran, Nhan] Northwestern Univ, Elect & Comp Engn Dept, Evanston, IL 60208 USA.
   [Duarte, Javier] Univ Calif San Diego, Phys Dept, La Jolla, CA 92093 USA.
   [Harris, Philip] MIT, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
   [Kwok, Martin] Brown Univ, Phys Dept, Providence, RI 02912 USA.
   [Loncar, Vladimir; Pierini, Maurizio; Summers, Sioni] CERN, CH-1211 Geneva, Switzerland.
   [Loncar, Vladimir] Inst Phys Belgrade, Belgrade 11080, Serbia.
   [Ngadiuba, Jennifer] CALTECH, Pasadena, CA 91125 USA.
   [Noonan, Daniel] Florida Inst Technol, Melbourne, FL 32901 USA.
RP Tran, N (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM ntran@fnal.gov
CR Albertsson K, 2018, J PHYS CONF SER, V1085, DOI 10.1088/1742-6596/1085/2/022008
   Alía RG, 2018, IEEE T NUCL SCI, V65, P448, DOI 10.1109/TNS.2017.2776107
   [Anonymous], 2015, COGNITIVE SCI, DOI DOI 10.1111/COGS.12280
   Bourilkov D, 2019, INT J MOD PHYS A, V34, DOI 10.1142/S0217751X19300199
   Carleo G, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.045002
   Casas LMJ, 2017, J INSTRUM, V12, DOI 10.1088/1748-0221/12/02/C02039
   Chatrchyan S., 2008, P JINST, V3
   CMS Collaboration, 2017, PHASE 2 UPGRADE CMS, DOI DOI 10.17181/CERN.IV8M.1JY2
   CMS collaboration, 2020, CERNLHCC2020004 CMS
   CMS Team, CMSSW GITHUB
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dodd PE, 2010, IEEE T NUCL SCI, V57, P1747, DOI 10.1109/TNS.2010.2042613
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Fulkerson D., 2006, U.S. Patent, Patent No. [11 136 920, 11136920]
   Gong R, 2008, J ELECTRON TEST, V24, P57, DOI 10.1007/s10836-007-5029-z
   Habinc S., 2002, FPGA00301 GAISL RES
   Huhtinen M, 1996, THESIS HELSINKI U TE
   Karbachevsky A., SUSTAINABILITY-BASEL, V13, P717
   Komiske PT, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.041801
   Kuboyama S., 2009, U.S. Patent, Patent No. [7 504 850, 7504850]
   LYONS RE, 1962, IBM J RES DEV, V6, P200, DOI 10.1147/rd.62.0200
   Maharrey JA, 2018, IEEE T NUCL SCI, V65, P1872, DOI 10.1109/TNS.2017.2783239
   Mentor/Siemens, 2020, CAT HIGH LEV SYNTH V
   Mentor/Siemens, 2020, HLSLIBS OP SOURC HIG
   Mentor/Siemens, 2020, CAT HIGH LEV SYNTH
   Nair V, 2010, INT C MACH LEARN HAI, V27, P807
   OSHWA, 2020, RES RED SPI SIGN NAM
   Radovic A, 2018, NATURE, V560, P41, DOI 10.1038/s41586-018-0361-2
   Schrimpf R.D., 2004, RAD EFFECTS SOFT ERR, V12
   Summers, 2020, ARXIV200610159
   Xavier Glorot, 2011, P 14 INT C ARTIFICIA, P315, DOI DOI 10.1002/ECS2.1832
   Xilinx, 2020, VIV HIGH LEV SYNTH
NR 32
TC 16
Z9 16
U1 2
U2 8
PD AUG
PY 2021
VL 68
IS 8
BP 2179
EP 2186
DI 10.1109/TNS.2021.3087100
PN 1-3
WC Engineering, Electrical & Electronic; Nuclear Science & Technology
DA 2023-11-11
ER

PT C
AU Goswami, P
   Shahshahani, M
   Bhatia, D
AF Goswami, Pingakshya
   Shahshahani, Masoud
   Bhatia, Dinesh
GP IEEE Comp Soc
TI Robust Estimation of FPGA Resources and Performance from CNN Models
SO 2022 35TH INTERNATIONAL CONFERENCE ON VLSI DESIGN (VLSID 2022) HELD
   CONCURRENTLY WITH 2022 21ST INTERNATIONAL CONFERENCE ON EMBEDDED SYSTEMS
   (ES 2022)
SE International Conference on VLSI Design
DT Proceedings Paper
CT 35th International Conference on VLSI Design (VLSID) / 21st
   International Conference on Embedded Systems (ES)
CY FEB 26-MAR 02, 2022
CL ELECTR NETWORK
DE High Level Synthesis; Machine Learning; Convolution Neural Network;
   Estimation
AB Field-Programmable Gate Arrays (FPGAs) are becoming increasingly popular for implementing convolutional neural networks (CNNs) due to their low latency and very high energy efficiency. However, most FPGAs are resource-scarce and efficient mapping of CNN can quickly become a challenging task. The requirement of FPGA resources, latency, and power is affected by many parameters, including the CNN architecture and the level of computational parallelism. In practice, a software designer first explores various CNN architectures in software to improve architecture's validation accuracy. Once an architecture is finalized, the designer ports the architecture design to FPGA for inference acceleration. The mapping process undergoes performance optimization by tweaking many design-related parameters during the design space exploration and changing the operating frequencies. The entire process is highly time-consuming. In this paper, we have presented a machine learning-based two-stage estimator for assisting in designing an FPGA-based CNN accelerator. Our Global Predictor assists in making accurate estimates of FPGA resource requirements and design latency from CNN architecture and hyperparameters expressed in Python. This assists in choosing a subset of high validation accuracy and feasible designs for mapping on FPGA. Our Detailed Predictor assists in making accurate estimates of FPGA post-route resource requirements, design latency, and final clock period for the chosen subset of designs after applying high-level synthesis level (pragma and frequency) optimizations. Our proposed estimation methodology enables a software engineer to obtain rapid and accurate estimates of the final implementation Quality of Results without executing FPGA design flows. We trained and tested our model for Xilinx Zynq Ultrascale+ and Kintex-7 devices. We achieved an average prediction error of less than 9% and 4% for stages one and two, respectively.
C1 [Goswami, Pingakshya; Shahshahani, Masoud; Bhatia, Dinesh] Univ Texas Dallas, Dept Elect Engn, Richarson, TX 75080 USA.
RP Goswami, P (corresponding author), Univ Texas Dallas, Dept Elect Engn, Richarson, TX 75080 USA.
EM pingakshya.goswami@utdallas.edu; masoud.shahshahani@utdallas.edu;
   dinesh@utdallas.edu
CR [Anonymous], 2021, COMETML
   Dai S, 2018, ANN IEEE SYM FIELD P, P129, DOI 10.1109/FCCM.2018.00029
   Lattner C, 2004, INT SYM CODE GENER, P75, DOI 10.1109/cgo.2004.1281665
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Makrani HM, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P727, DOI 10.1145/3287624.3288756
   Makrani HM, 2019, I C FIELD PROG LOGIC, P397, DOI 10.1109/FPL.2019.00069
   Meeuws R., 2011, 2011 International Conference on Embedded Computer Systems: Architectures, Modeling, and Simulation (SAMOS XI), P140, DOI 10.1109/SAMOS.2011.6045455
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   pytorch, PYTORCH
   Shahshahani M, 2021, I CONF VLSI DESIGN, P322, DOI 10.1109/VLSID51830.2021.00060
   tensorflow, TENSORFLOW
   XGBoost, 2021, XGBOOST DOCUMENTATIO
   Xu PF, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P40, DOI 10.1145/3373087.3375306
   Ye H., 2020, HYBRIDDNN FRAMEWORK
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhao JR, 2017, ICCAD-IEEE ACM INT, P430, DOI 10.1109/ICCAD.2017.8203809
   Zuo W., 2013, P ACMSIGDA FPGA
NR 17
TC 1
Z9 1
U1 1
U2 4
PY 2022
BP 144
EP 149
DI 10.1109/VLSID2022.2022.00038
WC Automation & Control Systems; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Abdelsalam, AM
   Elsheikh, A
   David, JP
   Langlois, JMP
AF Abdelsalam, Ahmed M.
   Elsheikh, Ahmed
   David, Jean-Pierre
   Langlois, J. M. Pierre
GP IEEE
TI POLYBiNN: A Scalable and Efficient Combinatorial Inference Engine for
   Neural Networks on FPGA
SO 2018 CONFERENCE ON DESIGN AND ARCHITECTURES FOR SIGNAL AND IMAGE
   PROCESSING (DASIP)
SE Conference on Design and Architectures for Signal and Image Processing
DT Proceedings Paper
CT 12th Conference on Design and Architectures for Signal and Image
   Processing (DASIP)
CY OCT 10-12, 2018
CL Porto, PORTUGAL
DE Deep Learning; FPGAs; Decision Trees; Hardware Accelerators; Binary
   Classifiers
AB Deep Neural Networks (DNNs) and Convolutional Neural Networks (CNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of deep NN architectures pose particular challenges for their FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider deep learning user community and to improve DNN design efficiency, we introduce POLYBiNN, a scalable and efficient combinatorial inference engine for DNNs and CNNs. POLYBiNN is composed of a stack of decision trees, which are binary classifiers by nature, and utilizes AND-OR gates instead of multipliers and accumulators. POLYBiNN drastically cuts the hardware consumption down while maintaining high accuracy, and it is a memory free inference engine. We also propose a tool that generates automatically a low-level hardware description of the trained POLYBiNN for a given application. We evaluate POLYBiNN for the MNIST dataset when implemented in a ZYNQ-7000 ZC706 FPGA platform. The system achieves a throughput of up to 100 million image classifications per second with 90 ns latency on the MNIST dataset with 97.18% accuracy. The power consumption of PLOYBiNN is less than 1.2 W. We also show how POLYBiNN can be used in the fully connected layers of a CNN and apply this approach to the CIFAR-10 dataset.
C1 [Abdelsalam, Ahmed M.; Langlois, J. M. Pierre] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
   [Elsheikh, Ahmed] Polytech Montreal, Dept Math & Ind Engn, Montreal, PQ, Canada.
   [David, Jean-Pierre] Polytech Montreal, Dept Elect Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; ahmed.elsheikh@polymtl.ca;
   jean-pierre.david@polymtl.ca; pierre.langlois@polymtl.ca
CR Akers S. B., 1978, IEEE T COMPUTERS
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], 1998, P IEEE
   [Anonymous], 2012, PATTERN CLASSIFICATI
   Cheng Y., 2017, 171009282 ARXIV
   Courbariaux M., 2016, 160202830 ARXIV
   Deng L., 2017, 170509283 ARXIV
   Han Song, 2016, ICLR
   Hunter D., 2012, IEEE T IND INFORM
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lecun Yann, 2015, NATURE
   Lorena A. C., 2008, ARTIFICIAL INTELLIGE
   Misra J., 2010, NEUROCOMPUTING
   Nakahara H., 2017, IEEE INT C FIELD PRO
   Nurvitadhi E., 2017, ACM SIGDA INT S FIEL
   Rastegari M., 2016, SPRING EUR C COMP VI
   Robert C., 2014, MACHINE LEARNING PRO
   Struharik J.R., 2011, IEEE INT S INT SYST
   Sze V., 2017, P IEEE
   Tang P. T. P., 1991, IEEE S COMP AR JUN
   Umuroglu Y., 2017, ACM SIGDA INT S FIEL
   Zhao R., 2017, ACM SIGDA INT S FIEL
NR 23
TC 3
Z9 3
U1 0
U2 2
PY 2018
BP 19
EP 24
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Seal, SK
   Lim, SH
   Wang, DL
   Hinkle, J
   Lunga, D
   Tsaris, A
AF Seal, Sudip K.
   Lim, Seung-Hwan
   Wang, Dali
   Hinkle, Jacob
   Lunga, Dalton
   Tsaris, Aristeidis
GP ACM
TI Toward Large-Scale Image Segmentation on Summit
SO PROCEEDINGS OF THE 49TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING,
   ICPP 2020
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 49th International Conference on Parallel Processing (ICPP)
CY AUG 17-20, 2020
CL Edmonton, CANADA
DE applied machine learning; scalable data analytics; deep neural networks;
   model parallel; image segmentation; U-Net; pipeline
AB Semantic segmentation of images is an important computer vision task that emerges in a variety of application domains such as medical imaging, robotic vision and autonomous vehicles to name a few. While these domain-specific image analysis tasks involve relatively small image sizes (similar to 10(2) x 10(2)), there are many applications that need to train machine learning models on image data with extents that are orders of magnitude larger (similar to 10(4) x 10(4)). Training deep neural network (DNN) models on large extent images is extremely memory-intensive and often exceeds the memory limitations of a single graphical processing unit, a hardware accelerator of choice for computer vision workloads. Here, an efficient, sample parallel approach to train U-Net models on large extent image data sets is presented. Its advantages and limitations are analyzed and near-linear strong-scaling speedup demonstrated on 256 nodes (1536 GPUs) of the Summit supercomputer. Using a single node of the Summit supercomputer, an early evaluation of a recently released model parallel framework called GPipe is demonstrated to deliver similar to 2X speedup in executing a U-Net model with an order of magnitude larger number of trainable parameters than reported before. Performance bottlenecks for pipelined training of U-Net models are identified and mitigation strategies to improve the speedups are discussed. Together, these results open up the possibility of combining both approaches into a unified scalable pipelined and data parallel algorithm to efficiently train U-Net models with very large receptive fields on data sets of ultra-large extent images.
C1 [Seal, Sudip K.; Lim, Seung-Hwan] Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37830 USA.
   [Wang, Dali] Oak Ridge Natl Lab, Environm Sci Div, Oak Ridge, TN USA.
   [Hinkle, Jacob] Oak Ridge Natl Lab, Computat Sci & Engn Div, Oak Ridge, TN USA.
   [Lunga, Dalton] Oak Ridge Natl Lab, Natl Secur Emerging Technol, Oak Ridge, TN USA.
   [Tsaris, Aristeidis] Oak Ridge Natl Lab, Natl Ctr Computat Sci, Oak Ridge, TN USA.
RP Seal, SK (corresponding author), Oak Ridge Natl Lab, Comp Sci & Math Div, Oak Ridge, TN 37830 USA.
CR Chen TQ, 2016, Arxiv, DOI [arXiv:1604.06174, DOI 10.48550/ARXIV.1604.06174]
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Dryden N, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356207
   Huang Yanping, 2019, 33 C NEUR INF PROC S
   Kim C, 2020, Arxiv, DOI arXiv:2004.09910
   Luo WJ, 2016, ADV NEUR IN, V29
   Milletari F, 2016, INT CONF 3D VISION, P565, DOI 10.1109/3DV.2016.79
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Ronneberger O, 2015, LECT NOTES COMPUT SC, V9351, P234, DOI 10.1007/978-3-319-24574-4_28
   Shazeer Noam, 2018, 32RD C NEUR INF PROC
   Zhang ZP, 2019, IEEE ACM T COMPUT BI, V16, P407, DOI 10.1109/TCBB.2017.2704587
   Zhou ZW, 2018, LECT NOTES COMPUT SC, V11045, P3, DOI 10.1007/978-3-030-00889-5_1
NR 12
TC 1
Z9 1
U1 0
U2 0
PY 2020
AR 27
DI 10.1145/3404397.3404468
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Zhao, M
   Agarwal, N
   Basant, A
   Gedik, B
   Pan, S
   Ozdal, M
   Komuravelli, R
   Pan, J
   Bao, TS
   Lu, HW
   Narayanan, S
   Langman, J
   Wilfong, K
   Rastogi, H
   Wu, CJ
   Kozyrakis, C
   Pol, P
AF Zhao, Mark
   Agarwal, Niket
   Basant, Aarti
   Gedik, Bugra
   Pan, Satadru
   Ozdal, Mustafa
   Komuravelli, Rakesh
   Pan, Jerry
   Bao, Tianshu
   Lu, Haowei
   Narayanan, Sundaram
   Langman, Jack
   Wilfong, Kevin
   Rastogi, Harsha
   Wu, Carole-Jean
   Kozyrakis, Christos
   Pol, Parik
GP ACM
TI Understanding Data Storage and Ingestion for Large-Scale Deep
   Recommendation Model Training
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE Machine learning systems; databases; distributed systems; data
   ingestion; data storage
AB Datacenter-scale AI training clusters consisting of thousands of domain-specific accelerators (DSA) are used to train increasingly-complex deep learning models. These clusters rely on a data storage and ingestion (DSI) pipeline, responsible for storing exabytes of training data and serving it at tens of terabytes per second. As DSAs continue to push training efficiency and throughput, the DSI pipeline is becoming the dominating factor that constrains the overall training performance and capacity. Innovations that improve the efficiency and performance of DSI systems and hardware are urgent, demanding a deep understanding of DSI characteristics and infrastructure at scale.
   This paper presents Meta's end-to-end DSI pipeline, composed of a central data warehouse built on distributed storage and a Data PreProcessing Service that scales to eliminate data stalls. We characterize how hundreds of models are collaboratively trained across geo-distributed datacenters via diverse and continuous training jobs. These training jobs read and heavily filter massive and evolving datasets, resulting in popular features and samples used across training jobs. We measure the intense network, memory, and compute resources required by each training job to preprocess samples during training. Finally, we synthesize key takeaways based on our production infrastructure characterization. These include identifying hardware bottlenecks, discussing opportunities for heterogeneous DSI hardware, motivating research in datacenter scheduling and benchmark datasets, and assimilating lessons learned in optimizing DSI infrastructure.
C1 [Zhao, Mark; Agarwal, Niket; Basant, Aarti; Gedik, Bugra; Pan, Satadru; Ozdal, Mustafa; Komuravelli, Rakesh; Pan, Jerry; Bao, Tianshu; Lu, Haowei; Narayanan, Sundaram; Langman, Jack; Wilfong, Kevin; Rastogi, Harsha; Wu, Carole-Jean; Pol, Parik] Meta, Menlo Pk, CA 94025 USA.
   [Kozyrakis, Christos] Stanford Univ, Stanford, CA USA.
RP Zhao, M (corresponding author), Meta, Menlo Pk, CA 94025 USA.
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Acun B, 2021, INT S HIGH PERF COMP, P802, DOI 10.1109/HPCA51647.2021.00072
   Agrawal P, 2019, INT CONF MANAGE DATA, P1803, DOI 10.1145/3299869.3314050
   Akidau T, 2015, PROC VLDB ENDOW, V8, P1792
   [Anonymous], 2008, OSDI 08
   [Anonymous], 2022, MILAN CORES AMD
   [Anonymous], 2022, MODULE TF DATA EXPT
   [Anonymous], 2022, INTRO RES SUPERCLUST
   [Anonymous], 2022, DATASETS DEEP LEARNI
   [Anonymous], 2022, ENTERPRISE FEATURE S
   [Anonymous], 2022, VELOX
   [Anonymous], 2022, TORCHARROW
   [Anonymous], 2022, TFRECORD
   [Anonymous], 2022, PERSISTENT KEY VALUE
   [Anonymous], 2022, DOWNLOAD CRITEO 1TB
   Apache arrow, US
   Apache Avro, 2022, US
   Apache ORC, 2022, US
   Apache Parquet, 2022, US
   Armbrust M, 2020, PROC VLDB ENDOW, V13, P3411, DOI 10.14778/3415478.3415560
   AWS, 2022, AWS EC2 TRN1 INST
   Barroso Luiz Andre, 2018, SYNTHESIS LECT COMPU, V13, pi
   Carole-JeanWu Robin, 2020, ARXIV
   Chen DH, 2016, INT SYM CODE GENER, P12, DOI 10.1145/2854038.2854044
   Choi D, 2020, ARXIV
   Cubuk ED, 2020, IEEE COMPUT SOC CONF, P3008, DOI 10.1109/CVPRW50498.2020.00359
   Cubuk ED, 2019, PROC CVPR IEEE, P113, DOI 10.1109/CVPR.2019.00020
   Dageville B, 2016, SIGMOD'16: PROCEEDINGS OF THE 2016 INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P215, DOI 10.1145/2882903.2903741
   DALI, 2022, SUPP OP
   Das T., 2012, P 9 USENIX C NETWORK, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dunn J., 2016, INTRO FBLEARNER FLOW
   Farrington N, 2013, OPT INTERCONNECT C, P49
   Gupta U, 2020, ANN I S COM, P982, DOI 10.1109/ISCA45697.2020.00084
   Gupta U, 2020, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA47549.2020.00047
   Habana, 2022, HAB HOM
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   He Xinran, 2014, P 8 INT WORKSH DAT M, V5, P1, DOI DOI 10.1145/2648584.2648589
   Jiarui Fang, 2021, PPoPP '21: Proceedings of the 26th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming, P389, DOI 10.1145/3437801.3441578
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kakaraparthy A., 2019, P 11 USENIX WORKSH H
   Kanev S, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P158, DOI 10.1145/2749469.2750392
   Karpathiotakis Manolis, 2019, SCRIBE TRANSPORTING
   Kaufman S, 2012, ACM T KNOWL DISCOV D, V6, DOI 10.1145/2382577.2382579
   Knowles S., 2021, 2021 IEEE HOT CHIPS, P1
   Krizhevsky A, 2014, ARXIV
   Kumar AV, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P283
   Kumar S, 2021, ARXIV
   Lee G, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P537
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Maeng Kiwan, 2021, P MACHINE LEARNING S, V3, P637
   Marchukov Mark, 2017, LOGDEVICE DISTRIBUTE
   Mattson Peter, 2020, MLSYS, V2, P336
   Medvedev I., 2019, POWERED INSTAGRAMS E
   Melnik S, 2010, PROC VLDB ENDOW, V3, P330
   MLCommons, 2021, MLPERF TRAIN V1 1 RE
   Mohan Jayashree, PROC VLDB ENDOW
   Moore Samuel, 2021, HERES GOOGLES TPU V4
   Mudigere Dheevatsa, 2022, 2022 ACM IEEE 49 ANN
   Murray DG, 2021, PROC VLDB ENDOW, V14, P2945, DOI 10.14778/3476311.3476374
   Murray DG, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P439, DOI 10.1145/2517349.2522738
   Nakandala S, 2020, PROC VLDB ENDOW, V13, P2159, DOI 10.14778/3407790.3407816
   Naumov Maxim, ARXIV
   NVIDIA, 2021, DAT LOAD LIB DALI
   Pan Satadru, 19 USENIX C FILE STO, P217
   Paszke A, 2019, ADV NEUR IN, V32
   Petrov Alexander, 2020, SCAL 2020 MAST COOK
   Prabhakar R., 2021, HOT CHIPS, P1, DOI DOI 10.1109/HCS52781.2021.9567250
   Roy A, 2015, SIGCOMM'15: PROCEEDINGS OF THE 2015 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION, P123, DOI 10.1145/2785956.2787472
   Ruder, 2017, OVERVIEW MULTI TASK
   Sethi Geet, 2022, P 27 ACM INT C ARCHI
   Sethi R, 2019, PROC INT CONF DATA, P1802, DOI 10.1109/ICDE.2019.00196
   SINGH A, 2015, COMPUT COMMUN REV, P15
   Sriraman A, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P733, DOI 10.1145/3373376.3378450
   TensTorrent, 2022, TENST
   Tesla, 2022, TESL ART INT
   Thusoo A, 2009, PROC VLDB ENDOW, V2, P1626, DOI 10.14778/1687553.1687609
   Wang LP, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404472
   Wang Y.E., 2020, 3 C MACH LEARN SYST
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Xin D, 2021, INT CONF MANAGE DATA, P2639, DOI 10.1145/3448016.3457566
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zhang Cyril, 2020, ADV NEURAL INFORM PR, V33, P10282
   Zhao WJ, 2019, PROCEEDINGS OF THE 28TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT (CIKM '19), P319, DOI 10.1145/3357384.3358045
   Zhu Y, 2019, IEEE INT C CL COMP, P34, DOI 10.1109/cluster.2019.8891023
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
NR 88
TC 1
Z9 1
U1 0
U2 0
PY 2022
BP 1042
EP 1057
DI 10.1145/3470496.3533044
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Cruz-Chú, ER
   Hosseinizadeh, A
   Mashayekhi, G
   Fung, R
   Ourmazd, A
   Schwander, P
AF Cruz-Chu, Eduardo R.
   Hosseinizadeh, Ahmad
   Mashayekhi, Ghoncheh
   Fung, Russell
   Ourmazd, Abbas
   Schwander, Peter
TI Selecting XFEL single-particle snapshots by geometric machine learning
SO STRUCTURAL DYNAMICS-US
DT Article
ID IMAGING EXPERIMENTS; MAXIMUM-LIKELIHOOD; ALGORITHMS; CLASSIFICATION;
   PERSPECTIVES; SYMMETRIES
AB A promising new route for structural biology is single-particle imaging with an X-ray Free-Electron Laser (XFEL). This method has the advantage that the samples do not require crystallization and can be examined at room temperature. However, high-resolution structures can only be obtained from a sufficiently large number of diffraction patterns of individual molecules, so-called single particles. Here, we present a method that allows for efficient identification of single particles in very large XFEL datasets, operates at low signal levels, and is tolerant to background. This method uses supervised Geometric Machine Learning (GML) to extract low-dimensional feature vectors from a training dataset, fuse test datasets into the feature space of training datasets, and separate the data into binary distributions of "single particles" and "non-single particles." As a proof of principle, we tested simulated and experimental datasets of the Coliphage PR772 virus. We created a training dataset and classified three types of test datasets: First, a noise-free simulated test dataset, which gave near perfect separation. Second, simulated test datasets that were modified to reflect different levels of photon counts and background noise. These modified datasets were used to quantify the predictive limits of our approach. Third, an experimental dataset collected at the Stanford Linear Accelerator Center. The single-particle identification for this experimental dataset was compared with previously published results and it was found that GML covers a wide photon-count range, outperforming other single-particle identification methods. Moreover, a major advantage of GML is its ability to retrieve single particles in the presence of structural variability.
C1 [Cruz-Chu, Eduardo R.; Hosseinizadeh, Ahmad; Mashayekhi, Ghoncheh; Fung, Russell; Ourmazd, Abbas; Schwander, Peter] Univ Wisconsin, Dept Phys, 3135 N Maryland Ave, Milwaukee, WI 53211 USA.
RP Schwander, P (corresponding author), Univ Wisconsin, Dept Phys, 3135 N Maryland Ave, Milwaukee, WI 53211 USA.
EM pschwan@uwm.edu
CR Allahgholi A, 2019, J SYNCHROTRON RADIAT, V26, P74, DOI 10.1107/S1600577518016077
   Aquila A, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4918726
   Assalauova D., 2020, ARXIV200608345
   Ayyer K, 2016, J APPL CRYSTALLOGR, V49, P1320, DOI 10.1107/S1600576716008165
   Ayyer K, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4919301
   Bielecki J, 2020, STRUCT DYNAM-US, V7, DOI 10.1063/4.0000024
   Bobkov SA, 2015, J SYNCHROTRON RADIAT, V22, P1345, DOI 10.1107/S1600577515017348
   Bogan MJ, 2008, NANO LETT, V8, P310, DOI 10.1021/nl072728k
   Bohne S, 2019, REV SCI INSTRUM, V90, DOI 10.1063/1.5080428
   Coifman RR, 2006, APPL COMPUT HARMON A, V21, P5, DOI 10.1016/j.acha.2006.04.006
   Damiani D, 2016, J APPL CRYSTALLOGR, V49, P672, DOI 10.1107/S1600576716004349
   Daurer BJ, 2016, J APPL CRYSTALLOGR, V49, P1042, DOI 10.1107/S1600576716005926
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   DePonte DP, 2008, J PHYS D APPL PHYS, V41, DOI 10.1088/0022-3727/41/19/195505
   Ekeberg T, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.098102
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Ferguson AL, 2010, P NATL ACAD SCI USA, V107, P13597, DOI 10.1073/pnas.1003293107
   FIENUP JR, 1982, APPL OPTICS, V21, P2758, DOI 10.1364/AO.21.002758
   Fung R, 2020, LANCET DIGIT HEALTH, V2, pE368, DOI 10.1016/S2589-7500(20)30131-X
   Giannakis D, 2012, OPT EXPRESS, V20, P12799, DOI 10.1364/OE.20.012799
   Gisriel C, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12955-3
   Halavanau A, 2019, J SYNCHROTRON RADIAT, V26, P635, DOI 10.1107/S1600577519002492
   Hosseinizadeh A, 2015, STRUCT DYNAM-US, V2, DOI 10.1063/1.4919740
   Hosseinizadeh A, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0326
   Hosseinizadeh A, 2017, NAT METHODS, V14, P877, DOI [10.1038/NMETH.4395, 10.1038/nmeth.4395]
   Ignatenko A., 2020, ARXIV200807288
   Lafon S, 2006, IEEE T PATTERN ANAL, V28, P1784, DOI 10.1109/TPAMI.2006.223
   Loh ND, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.225501
   Loh NTD, 2009, PHYS REV E, V80, DOI 10.1103/PhysRevE.80.026705
   Lundholm IV, 2018, IUCRJ, V5, P531, DOI 10.1107/S2052252518010047
   Maia FRNC, 2012, NAT METHODS, V9, P854, DOI 10.1038/nmeth.2110
   Marchesini S, 2003, PHYS REV B, V68, DOI 10.1103/PhysRevB.68.140101
   Munke A, 2016, SCI DATA, V3, DOI 10.1038/sdata.2016.64
   Pandey S, 2020, NAT METHODS, V17, P73, DOI 10.1038/s41592-019-0628-z
   Peplow M, 2017, NATURE, V544, P408, DOI 10.1038/544408a
   Poudyal I, 2020, STRUCT DYN-US, V7, DOI 10.1063/1.5144516
   Reddy HKN, 2017, SCI DATA, V4, DOI 10.1038/sdata.2017.79
   Rose M, 2018, IUCRJ, V5, P727, DOI 10.1107/S205225251801120X
   Scheres SHW, 2005, J MOL BIOL, V348, P139, DOI 10.1016/j.jmb.2005.02.031
   Schwander P, 2014, PHILOS T R SOC B, V369, DOI 10.1098/rstb.2013.0567
   Schwander P, 2010, NEW J PHYS, V12, DOI 10.1088/1367-2630/12/3/035007
   Schwander P, 2012, OPT EXPRESS, V20, P12827, DOI 10.1364/OE.20.012827
   Shi YC, 2019, IUCRJ, V6, P331, DOI 10.1107/S2052252519001854
   Sobolev E, 2020, COMMUN PHYS-UK, V3, DOI 10.1038/s42005-020-0362-y
   Spence JCH, 2012, REP PROG PHYS, V75, DOI 10.1088/0034-4885/75/10/102601
   Strüder L, 2010, NUCL INSTRUM METH A, V614, P483, DOI 10.1016/j.nima.2009.12.053
   Yoon CH, 2011, OPT EXPRESS, V19, P16542, DOI 10.1364/OE.19.016542
   Zimmermann J, 2019, PHYS REV E, V99, DOI 10.1103/PhysRevE.99.063309
NR 48
TC 5
Z9 5
U1 1
U2 7
PD JAN
PY 2021
VL 8
IS 1
AR 014701
DI 10.1063/4.0000060
WC Chemistry, Physical; Physics, Atomic, Molecular & Chemical
DA 2023-11-11
ER

PT J
AU Kaspi, O
   Israelsohn-Azulay, O
   Zidon, Y
   Rosengarten, H
   Krmpotic, M
   Gouasmia, S
   Radovic, IB
   Jalkanen, P
   Liski, A
   Mizohata, K
   Räisänen, J
   Girshevitz, O
   Senderowitz, H
AF Kaspi, Omer
   Israelsohn-Azulay, Osnat
   Zidon, Yigal
   Rosengarten, Hila
   Krmpotic, Matea
   Gouasmia, Sabrina
   Radovic, Iva Bogdanovic
   Jalkanen, Pasi
   Liski, Anna
   Mizohata, Kenichiro
   Raisanen, Jyrki
   Girshevitz, Olga
   Senderowitz, Hanoch
TI Inter-laboratory workflow for forensic applications: Classification of
   car glass fragments
SO FORENSIC SCIENCE INTERNATIONAL
DT Article
DE PIXE; Car window glass fragments; Machine Learning; Forensics
ID REFRACTIVE-INDEX
AB The International Atomic Energy Agency (IAEA) has coordinated a research project titled "Enhancing Nuclear Analytical Techniques to Meet the Needs of Forensics Sciences" (CRP F11021) with the aim of empowering accelerator and reactor based techniques for applications in forensic sciences. One of the key topics of this project was the analysis and classification of forensic glass specimens using Ion Beam Analysis (IBA) techniques and in particular, Particle Induced X-ray Emission (PIXE).
   To this end, glass fragments from car windows from different car models and manufacturers provided by the Israeli police force were subjected to PIXE measurements at three laboratories to determine their elemental compositions and possible glass corrosion. Major and trace elements were measured and given as an input to machine learning (ML) algorithms in order to develop classification models to determine the origin of the glass samples.
   First, we have developed ML models based on the results obtained at each lab. These models successfully classified glass fragments into different car models with an accuracy > 80% on external test sets. Next, we demonstrated that following an appropriate pre-processing step, results from different labs could be combined into a single unified database for the derivation of a classification model. This model demonstrates good performances that matches or surpasses the performances of models derived from the individual labs. This finding paves the way towards establishing an international database that is composed of measurements from various PIXE labs. We believe that using this methodology of combining various sources of measurements will improve models' performances and generality and will make the models accessible to law enforcement agencies around the world. (C) 2022 Elsevier B.V. All rights reserved.
C1 [Kaspi, Omer; Senderowitz, Hanoch] Bar Ilan Univ, Dept Chem, IL-5290002 Ramat Gan, Israel.
   [Israelsohn-Azulay, Osnat; Zidon, Yigal; Rosengarten, Hila] Israel Police HQ, Toolmarks & Mat Lab, Tel Aviv, Israel.
   [Krmpotic, Matea; Gouasmia, Sabrina; Radovic, Iva Bogdanovic] Rudjer Boskovic Inst, Div Expt Phys, Lab Ion Beam Interact, Bijenicka Cesta 54, HR-10000 Zagreb, Croatia.
   [Jalkanen, Pasi; Liski, Anna; Mizohata, Kenichiro; Raisanen, Jyrki] Univ Helsinki, Dept Phys, POB 43, FI-00014 Helsinki, Finland.
   [Girshevitz, Olga] Bar Ilan Univ, Bar Ilan Inst Nanotechnol & Adv Mat, IL-5290002 Ramat Gan, Israel.
RP Senderowitz, H (corresponding author), Bar Ilan Univ, Dept Chem, IL-5290002 Ramat Gan, Israel.; Girshevitz, O (corresponding author), Bar Ilan Univ, Bar Ilan Inst Nanotechnol & Adv Mat, IL-5290002 Ramat Gan, Israel.
EM Olga.Girshevitz@biu.ac.il; Hanoch.Senderowitz@biu.ac.il
CR Aitken CGG, 2006, COMPUT STAT DATA AN, V50, P2571, DOI 10.1016/j.csda.2005.04.005
   Aitken CGG, 2004, J ROY STAT SOC C, V53, P109, DOI 10.1046/j.0035-9254.2003.05271.x
   Aitken CGG, 2007, J FORENSIC SCI, V52, P412, DOI 10.1111/j.1556-4029.2006.00358.x
   Caddy B., 2001, FORENSIC EXAMINATION
   Civici N, 2013, ROM REP PHYS, V65, P1265
   Embrechts P., 1996, MW J AM STAT ASS, V91
   Erlich Y, 2018, SCIENCE, V362, P690, DOI 10.1126/science.aau4832
   Han Liu, 2019, Journal of Non-Crystalline Solids: X, V4, P43, DOI 10.1016/j.nocx.2019.100036
   Iqbal S.A. A. Salman, 2016, INTECHOPEN NO FORENS, P13
   Kaspi O, 2021, TALANTA, V234, DOI 10.1016/j.talanta.2021.122608
   Kraus MA, 2020, GLASS STRUCT ENG, V5, P247, DOI 10.1007/s40940-020-00132-8
   Maxwell V. M., 2001, J FORENSIC IDENT, V51, P597
   Park S, 2019, FORENSIC SCI INT, V305, DOI 10.1016/j.forsciint.2019.110003
   Park S, 2019, ANN APPL STAT, V13, P1068, DOI 10.1214/18-AOAS1211
   Pawluk-Kolc M, 2008, FORENSIC SCI INT, V174, P222, DOI 10.1016/j.forsciint.2007.04.229
   Pawluk-Kolc M, 2006, FORENSIC SCI INT, V160, P53, DOI 10.1016/j.forsciint.2005.08.016
   Pfaender H.G., 2012, SCHOTT GUIDE GLASS
   Rossy Q, 2013, FORENSIC SCI INT, V230, P137, DOI 10.1016/j.forsciint.2012.10.010
   Scholes S., 1975, MODERN GLASS PRACTIC
   Stone J.V., 2018, INDEP COMPON ANAL, DOI [10.7551/mitpress/3717.003.0017, DOI 10.7551/MITPRESS/3717.003.0017]
   Tallón-Ballesteros AJ, 2014, STUD COMPUT INTELL, V555, P413, DOI 10.1007/978-3-319-05885-6_17
   Tin Kam Ho, 1995, Proceedings of the Third International Conference on Document Analysis and Recognition, P278, DOI 10.1109/ICDAR.1995.598994
   van der Maaten L, 2008, J MACH LEARN RES, V9, P2579
   Zadora G., 2001, Z ZAGADNIEN NAUK SAD, V45, P36
NR 24
TC 4
Z9 4
U1 1
U2 7
PD APR
PY 2022
VL 333
AR 111216
DI 10.1016/j.forsciint.2022.111216
EA FEB 2022
WC Medicine, Legal
DA 2023-11-11
ER

PT J
AU Yang, YS
   Gong, NY
   Xie, KY
   Liu, QF
AF Yang, Yushan
   Gong, Nuoya
   Xie, Keying
   Liu, Qingfei
TI Predicting Gasoline Vehicle Fuel Consumption in Energy and Environmental
   Impact Based on Machine Learning and Multidimensional Big Data
SO ENERGIES
DT Article
DE fuel consumption; energy and environmental; machine learning
ID DRIVER BEHAVIOR; CO2 EMISSIONS; MODELS; TORQUE
AB The underestimation of fuel consumption impacts various aspects. In the vehicle market, manufacturers often advertise fuel economy for marketing. In fact, the fuel consumption reference value provided by the manufacturer is quite different from the real-world fuel consumption of the vehicles. The divergence between reference fuel consumption and real-world fuel consumption also has negative effect on the aspects of policy and environment. In order to effectively promote the sustainable development of transport, it is urged to recognize the real-world fuel consumption of vehicles. The gaps in previous studies includes small sample size, single data dimension, and lack of feature weight evaluation. To fill the research gap, in this study, we conduct a comparative analysis through building five regression models to forecast the real-world fuel consumption rate of light-duty gasoline vehicles in China based on big data from the perspectives of vehicle factors, environment factors, and driving behavior factors. Results show that the random forest regression model performs best among the five candidate models, with a mean absolute error of 0.630 L/100 km, a mean absolute percentage error of 7.5%, a mean squared error of 0.805, an R squared of 0.776, and a 10-fold cross-validation score of 0.791. Further, we capture the most important features affecting fuel consumption among the 25 factors from the above three perspectives. According to the relative weight of each factor in the most optimal model, the three most important factors are brake and accelerator habits, engine power, and the fuel economy consciousness of vehicle owners in sequence.
C1 [Yang, Yushan] Beijing Univ Posts & Telecommun, Sch Econ & Management, Beijing 100876, Peoples R China.
   [Gong, Nuoya] Beijing Int Studies Univ, Coll Japanese, Beijing 100024, Peoples R China.
   [Xie, Keying] Beijing Wuzi Univ, Sch Econ, Beijing 101149, Peoples R China.
   [Xie, Keying] Beijing Inst Fash Technol, Sch Fash Commun, Beijing 100029, Peoples R China.
   [Liu, Qingfei] Natl Univ Def Technol, Undergrad Sch, Changsha 410073, Peoples R China.
RP Liu, QF (corresponding author), Natl Univ Def Technol, Undergrad Sch, Changsha 410073, Peoples R China.
EM yangyushan@bupt.edu.cn; 2020220207@stu.bisu.edu.cn;
   2019103026@bwu.edu.cn; shenliulei12@nudt.edu.cn
CR Agarap A. F., 2018, ARXIV PREPRINT ARXIV, DOI [10.48550/arXiv.1803.08375, DOI 10.48550/ARXIV.1803.08375]
   Ahn KG, 2008, TRANSPORT RES D-TR E, V13, P151, DOI 10.1016/j.trd.2008.01.005
   Barth Matthew, 2007, 2007 IEEE Intelligent Transportation Systems Conference, P684, DOI 10.1109/ITSC.2007.4357672
   Ben Dror M, 2019, ENERG POLICY, V128, P8, DOI 10.1016/j.enpol.2018.12.039
   Ben-Chaim M, 2013, ENERGIES, V6, P117, DOI 10.3390/en6010117
   Biggs D., 1988, ARFCOM MODELS ESTIMA
   Chai T, 2014, GEOSCI MODEL DEV, V7, P1247, DOI 10.5194/gmd-7-1247-2014
   Chen KD, 2021, INT J ENV RES PUB HE, V18, DOI 10.3390/ijerph18063199
   Christoffersen P, 2004, J FINANC ECON, V72, P291, DOI 10.1016/j.jfineco.2003.02.001
   Duarte GO, 2016, TRANSPORT RES D-TR E, V44, P43, DOI 10.1016/j.trd.2016.02.009
   Ehsani M, 2016, RENEW SUST ENERG REV, V53, P1638, DOI 10.1016/j.rser.2015.08.062
   EI-Shawarby I, 2005, TRANSPORT RES D-TR E, V10, P13, DOI 10.1016/j.trd.2004.09.002
   Ericsson E, 2001, TRANSPORT RES D-TR E, V6, P325, DOI 10.1016/S1361-9209(01)00003-7
   EVANS L, 1979, HUM FACTORS, V21, P389, DOI 10.1177/001872087902100401
   Fontaras G, 2017, PROG ENERG COMBUST, V60, P97, DOI 10.1016/j.pecs.2016.12.004
   Gao YC, 2020, SUSTAINABILITY-BASEL, V12, DOI 10.3390/su12041492
   Greenwood ID, 2007, J TRANSP ENG-ASCE, V133, P96, DOI 10.1061/(ASCE)0733-947X(2007)133:2(96)
   Haworth N., 2001, P AUSTR ROAD SAF RES
   He CR, 2016, J COMPUT NONLIN DYN, V11, DOI 10.1115/1.4033895
   Heywood J.B., 2018, INTERNAL COMBUSTION
   Hjellvik MA, 2019, IN C IND ENG ENG MAN, P1067, DOI [10.1109/ieem44572.2019.8978605, 10.1109/IEEM44572.2019.8978605]
   HOOKER JN, 1988, TRANSPORT RES A-POL, V22, P183, DOI 10.1016/0191-2607(88)90036-2
   Jahirul M., 2009, INT J MECH MATER ENG, V4, P249
   Joumard R., 1995, 01487191 SAE INT, DOI [10.4271/950928, DOI 10.4271/950928]
   Kamal MAS, 2011, IEEE T INTELL TRANSP, V12, P783, DOI 10.1109/TITS.2011.2112648
   Karagöz Y, 2019, INT J HYDROGEN ENERG, V44, P31621, DOI 10.1016/j.ijhydene.2019.10.019
   Kashinath K, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0093
   Ke GL, 2017, ADV NEUR IN, V30
   Li YW, 2019, IEEE ACCESS, V7, P63395, DOI 10.1109/ACCESS.2019.2914378
   Liu Y., 2018, P SAE INT WCX WORLD, P1
   Luján JM, 2019, ENERG CONVERS MANAGE, V199, DOI 10.1016/j.enconman.2019.111987
   Masters T., 1993, PRACTICAL NEURAL NET
   Ostrouchov N., 1978, P SAE INT 1978 AUT E, P1
   Parlak A, 2006, APPL THERM ENG, V26, P824, DOI 10.1016/j.applthermaleng.2005.10.006
   Pavlovic J, 2016, APPL ENERG, V177, P661, DOI 10.1016/j.apenergy.2016.05.110
   Pekula N., 2003, SAE TRANSACTIONS, V112, P148
   Perrotta F, 2017, IEEE INT CONF BIG DA, P3810, DOI 10.1109/BigData.2017.8258382
   Ping P, 2019, IEEE ACCESS, V7, P78515, DOI 10.1109/ACCESS.2019.2920489
   Plotkin SE, 2001, ENERG POLICY, V29, P1073, DOI 10.1016/S0301-4215(01)00051-9
   Rahimi-Gorji M, 2017, J BRAZ SOC MECH SCI, V39, P375, DOI 10.1007/s40430-016-0539-1
   Rahman A, 2017, ENERG BUILDINGS, V152, P341, DOI 10.1016/j.enbuild.2017.07.017
   Redsell M., 1993, P I MECH ENG D-J AUT, DOI [10.1243/PIME_PROC_1993_207_155_02, DOI 10.1243/PIME_PROC_1993_207_155_02]
   Renouf M., 1979, PREDICTION FUEL CONS
   Sánchez M, 2006, 2006 6TH INTERNATIONAL CONFERENCE ON ITS TELECOMMUNICATIONS PROCEEDINGS, P331, DOI 10.1109/ITST.2006.288906
   Silva CM, 2006, TRANSPORT RES D-TR E, V11, P377, DOI 10.1016/j.trd.2006.07.004
   Sriwardene A.S., 2016, P 2016 13 INT C EL E, P1
   Syahputra Ramadoni, 2016, Journal of Theoretical and Applied Information Technology, V86, P138
   Tietge U, 2017, ENERG POLICY, V103, P212, DOI 10.1016/j.enpol.2017.01.021
   Togun N, 2010, APPL ENERG, V87, P3401, DOI 10.1016/j.apenergy.2010.04.027
   Togun NK, 2010, APPL ENERG, V87, P349, DOI 10.1016/j.apenergy.2009.08.016
   Van Mierlo J, 2004, P I MECH ENG D-J AUT, V218, P43, DOI 10.1243/095440704322829155
   Walnum HJ, 2015, TRANSPORT RES D-TR E, V36, P107, DOI 10.1016/j.trd.2015.02.016
   Wang JH, 2016, APPL ENERG, V170, P394, DOI 10.1016/j.apenergy.2016.02.124
   Wang YC, 2020, FUEL, V278, DOI 10.1016/j.fuel.2020.118340
   Wickramanayake S, 2016, 2ND INTERNATIONAL MERCON 2016 MORATUWA ENGINEERING RESEARCH CONFERENCE, P90, DOI 10.1109/MERCon.2016.7480121
   Wu T, 2020, ENERGY, V190, DOI 10.1016/j.energy.2019.116388
   Yao Y, 2020, J ADV TRANSPORT, V2020, DOI 10.1155/2020/9263605
   Ying X, 2018, CHINA PERSPECT-SER, P1, DOI 10.1088/1742-6596/1168/2/022022
   Zeng IY, 2021, ENERGIES, V14, DOI 10.3390/en14237915
   Zhao X, 2022, RESOUR CONSERV RECY, V176, DOI 10.1016/j.resconrec.2021.105959
   Zhou BY, 2018, MITIG ADAPT STRAT GL, V23, P735, DOI 10.1007/s11027-017-9757-9
   Zhou M, 2016, TRANSPORT RES D-TR E, V49, P203, DOI 10.1016/j.trd.2016.09.008
   Ziólkowski J, 2021, ENERGIES, V14, DOI 10.3390/en14092639
   Zou FY, 2019, PROC CVPR IEEE, P1119, DOI 10.1109/CVPR.2019.01138
NR 64
TC 4
Z9 4
U1 10
U2 31
PD MAR
PY 2022
VL 15
IS 5
AR 1602
DI 10.3390/en15051602
WC Energy & Fuels
DA 2023-11-11
ER

PT J
AU Athreyas, N
   Song, W
   Perot, B
   Xia, QF
   Mathew, A
   Gupta, J
   Gupta, D
   Yang, JJ
AF Athreyas, Nihar
   Song, Wenhao
   Perot, Blair
   Xia, Qiangfei
   Mathew, Abbie
   Gupta, Jai
   Gupta, Dev
   Yang, J. Joshua
TI Memristor-CMOS Analog Coprocessor for Acceleration of High-Performance
   Computing Applications
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Analog coprocessor; crossbar; electronic design automation; hardware
   accelerator; machine vision; memristor; modeling and simulation; partial
   differential equations; PSpice systems option; vector matrix
   multiplication
AB Vector matrix multiplication computation underlies major applications in machine vision, deep learning, and scientific simulation. These applications require high computational speed and are run on platforms that are size, weight, and power constrained. With the transistor scaling coming to an end, existing digital hardware architectures will not be able to meet this increasing demand. Analog computation with its rich set of primitives and inherent parallel architecture can be faster, more efficient, and compact for some of these applications. One such primitive is a memristor-CMOS crossbar array-based vector matrix multiplication. In this article, we develop a memristor-CMOS analog coprocessor architecture that can handle floating-point computation. To demonstrate the working of the analog coprocessor at a system level, we use a new electronic design automation tool called PSpice Systems Option, which performs integrated cosimulation of MATLAB/Simulink and PSpice. It is shown that the analog coprocessor has a superior performance when compared to other processors, and a speedup of up to 12 x when compared to projected GPU performance is observed. Using the new PSpice Systems Option tool, various application simulations for image processing and solutions to partial differential equations are performed on the analog coprocessor model.
C1 [Athreyas, Nihar] Univ Massachusetts, Dept Elect & Comp Engn, Amherst & Spero Devices, 318 Codman Hill Rd,Apt 26E, Boxboro, MA 01719 USA.
   [Perot, Blair] Univ Massachusetts, Dept Mech Engn, Boxboro, MA 01719 USA.
   [Song, Wenhao; Xia, Qiangfei; Yang, J. Joshua] Univ Massachusetts, Dept Elect & Comp Engn, Boxboro, MA 01719 USA.
   [Mathew, Abbie; Gupta, Jai] Spero Devices, Acton, MA USA.
RP Athreyas, N (corresponding author), Univ Massachusetts, Dept Elect & Comp Engn, Amherst & Spero Devices, 318 Codman Hill Rd,Apt 26E, Boxboro, MA 01719 USA.
EM nathreya@umass.edu; wrong@umass.edu; perot@umass.edu; qxia@umass.edu;
   amathew@sperodevices.com; jgupta@sperodevices.com; jjyang@umass.edu
CR [Anonymous], 2011, 2011 DESIGN AUTOMATI
   [Anonymous], 2005, DIGITAL VIDEO QUALIT
   Athreyas N, 2019, J REAL-TIME IMAGE PR, V16, P1607, DOI 10.1007/s11554-017-0669-4
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   BOSER BE, 1991, IEEE J SOLID-ST CIRC, V26, P2017, DOI 10.1109/4.104196
   Chen P.-Y., 2015, IEEE DESIGN AUTOMATI
   Chi P., 2016, P INT S COMP ARCH IS
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   Chua LO, 2012, P IEEE, V100, P1920, DOI 10.1109/JPROC.2012.2190814
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Chung F, 2000, J COMB THEORY A, V91, P191, DOI 10.1006/jcta.2000.3094
   De Simone F., 2008, SPIE OPTICS PHOTONIC
   Devereux V. G., 1989, Limiting of YUV digital video signals
   Dosselmann R, 2011, SIGNAL IMAGE VIDEO P, V5, P81, DOI 10.1007/s11760-009-0144-1
   Genov R, 2003, IEEE T NEURAL NETWOR, V14, P1426, DOI 10.1109/TNN.2003.816345
   Genov R, 2001, IEEE T CIRCUITS-II, V48, P930, DOI 10.1109/82.974781
   Gonzalez R.C., 2002, DIGITAL IMAGE PROCES, Vsecond
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harpe P., 2012, 2012 IEEE International Solid-State Circuits Conference (ISSCC), P472, DOI 10.1109/ISSCC.2012.6177096
   HESTENES MR, 1952, J RES NAT BUR STAND, V49, P409, DOI 10.6028/jres.049.044
   Hu M., 2016, P DAC 53
   Jain A. K., 1989, FUNDAMENTALS DIGITAL, P150
   Jiang H., 2016, SCI REPORTS, V6
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KUB FJ, 1990, IEEE J SOLID-ST CIRC, V25, P207, DOI 10.1109/4.50305
   Lewis D., 2004, DESIGNCON
   Lin WT, 2014, IEEE J SOLID-ST CIRC, V49, P708, DOI 10.1109/JSSC.2014.2301769
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Mitchell L., 1993, JPEG STILL IMAGE DAT
   Moon K. K., 1990, P IEEE CUST INT CIRC
   Nvidia, 2016, NVID TESL P100
   Pan X., 2011, ICMAT, V52, p[8, 1559]
   Parvizi M, 2016, IEEE T MICROW THEORY, V64, P1843, DOI 10.1109/TMTT.2016.2562003
   Shafiee A., P ISCA, P14
   Sheridan P. M., 2016, IEEE T NEURAL NETWOR, V27, p[11, 1]
   Sheridan P, 2014, IEEE INT SYMP CIRC S, P1078, DOI 10.1109/ISCAS.2014.6865326
   Sohmers T., 2017, REX NEOARCHITECTURE
   Stam J., P SIGGRAPH, P121
   Strachan JP, 2013, IEEE T ELECTRON DEV, V60, P2194, DOI 10.1109/TED.2013.2264476
   Tang H-Z, 2012, THESIS
   Vatanjou AA, 2015, PROCEEDINGS OF THE SIXTH ASIA SYMPOSIUM ON QUALITY ELECTRONIC DESIGN ASQED 2015, P7, DOI 10.1109/ACQED.2015.7273999
   Yang BD, 2015, IEEE T CIRCUITS-I, V62, P1564, DOI 10.1109/TCSI.2015.2418837
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang S, 2015, IEEE INT CONF COMMUN
   Yi Wei, 2014, NATURE COMMUNICATION, V7, P1
NR 45
TC 5
Z9 5
U1 2
U2 31
PD OCT
PY 2018
VL 14
IS 3
AR 38
DI 10.1145/3269985
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Moolchandani, D
   Kundu, J
   Ruelens, F
   Vrancx, P
   Evenblij, T
   Perumkunnil, M
AF Moolchandani, Diksha
   Kundu, Joyjit
   Ruelens, Frederik
   Vrancx, Peter
   Evenblij, Timon
   Perumkunnil, Manu
GP IEEE
TI AMPeD: An Analytical Model for Performance in Distributed Training of
   Transformers
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON PERFORMANCE ANALYSIS OF SYSTEMS AND
   SOFTWARE, ISPASS
DT Proceedings Paper
CT IEEE International Symposium on Performance Analysis of Systems and
   Software (ISPASS)
CY APR 23-25, 2023
CL Raleigh, NC
AB Transformers are a class of machine learning models that have piqued high interest recently due to a multitude of reasons. They can process multiple modalities efficiently and have excellent scalability. Despite these obvious advantages, training these large models is very time-consuming. Hence, there have been efforts to speed up the training process using efficient distributed implementations. Many different types of parallelism have been identified that can be employed standalone or in combination. However, naively combining different parallelization schemes can incur significant communication overheads, thereby potentially defeating the purpose of distributed training. Thus, it becomes vital to predict the right mapping of different parallelisms to the underlying system architecture. In this work, we propose AMPeD, an analytical model for performance in distributed training of transformers. It exposes all the transformer model parameters, potential parallelism choices (along with their mapping onto the system), the accelerator as well as system architecture specifications as tunable knobs, thereby enabling hardware-software co-design. With the help of 3 case studies, we show that the combinations of parallelisms predicted to be efficient by AMPeD conform with the results from the state-of-the-art literature. Using AMPeD, we also show that future distributed systems consisting of optical communication substrates can train large models up to 4x faster as compared to the current state-of-the-art systems without modifying the peak computational power of the accelerators. Finally, we validate AMPeD with in-house experiments on real systems and via published literature. The max. observed error is limited to 12%. The model is available here: https://github.com/CSA-infra/AMPeD
C1 [Moolchandani, Diksha; Kundu, Joyjit; Ruelens, Frederik; Vrancx, Peter; Evenblij, Timon; Perumkunnil, Manu] Interuniv Microelect Ctr IMEC, Leuven, Belgium.
RP Moolchandani, D (corresponding author), Interuniv Microelect Ctr IMEC, Leuven, Belgium.
EM diksha.moolchandani@imec.be; joyjit.kundu@imec.be;
   frederik.ruelens@imec.be; peter.vrancx@imec.be; timon.evenblij@imec.be;
   manu.perumkunnil@imec.be
CR Arnab A., 2021, ARXIV, DOI DOI 10.48550/ARXIV.2103.15691
   Bouzidi H, 2021, PROCEEDINGS OF THE 18TH ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS 2021 (CF 2021), P54, DOI 10.1145/3457388.3458666
   Choquette J., 2022, 2022 IEEE HOT CHIPS, P1
   Du N., 2022, ICML
   G. V. Research, 2022, DEEP LEARN MARK SIZ
   Geoffrey X. Y., 2021, USENIX ATC, V21
   Gianniti E., 2018, SBAC PAD
   Goyal P, 2018, Arxiv, DOI [arXiv:1706.02677, DOI 10.48550/ARXIV.1706.02677]
   Gulati A, 2020, Arxiv, DOI [arXiv:2005.08100, DOI 10.48550/ARXIV.2005.08100]
   Harris N. C., 2022, 2022 IEEE HOT CHIPS, P1
   He JA, 2021, Arxiv, DOI arXiv:2103.13262
   Huang YP, 2019, Arxiv, DOI arXiv:1811.06965
   Karpathy A., 2022, MINGPT PYTORCH RE IM
   Kim C, 2020, Arxiv, DOI arXiv:2004.09910
   Krizhevsky A, 2014, Arxiv, DOI [arXiv:1404.5997, DOI 10.48550/ARXIV.1404.5997]
   Lepikhin D, 2020, Arxiv, DOI arXiv:2006.16668
   Lym S, 2019, INT SYM PERFORM ANAL, P293, DOI 10.1109/ISPASS.2019.00041
   Ma ZX, 2022, PPOPP'22: PROCEEDINGS OF THE 27TH ACM SIGPLAN SYMPOSIUM ON PRINCIPLES AND PRACTICE OF PARALLEL PROGRAMMING, P192, DOI 10.1145/3503221.3508417
   Moolchandani D., 2022, ACM T ARCHIT CODE OP, V19, P1
   Moralis-Pegios M, 2021, IET OPTOELECTRON, V15, P102, DOI 10.1049/ote2.12018
   Narayanan D, 2021, INT CONF HIGH PERFOR, DOI 10.1145/3458817.3476209
   Naseem U, 2020, FUTURE GENER COMP SY, V113, P58, DOI 10.1016/j.future.2020.06.050
   Nvidia, 2022, OPT LIN FULL CONN LA
   NVIDIA, 2020, NVID A100 TENS COR G
   Pati S, 2022, I S WORKL CHAR PROC, P296, DOI 10.1109/IISWC55918.2022.00033
   Qi Hang, 2016, PALEO PERFORMANCE MO
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Rashidi S, 2020, INT SYM PERFORM ANAL, P81, DOI 10.1109/ISPASS48437.2020.00018
   Shaheen Z, 2020, Arxiv, DOI [arXiv:2010.12871, 10.48550/arXiv.2010.12871]
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Van Campenhout J., 2021, 2021 ACMIEEE SLIP
   Vaswani A., 2017, ARXIV, DOI DOI 10.48550/ARXIV.1706.03762
   Wang Q, 2019, Arxiv, DOI [arXiv:1906.01787, DOI 10.48550/ARXIV.1906.01787]
   Wang XH, 2022, Arxiv, DOI arXiv:2110.05722
   Wolf T, 2020, Arxiv, DOI [arXiv:1910.03771, DOI 10.48550/ARXIV.1910.03771]
   Yan F, 2015, KDD'15: PROCEEDINGS OF THE 21ST ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1355, DOI 10.1145/2783258.2783270
   Yu M., 2022, ARXIV
   Zhang Y., 2012, IEEE ISORCW
NR 38
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 306
EP 315
DI 10.1109/ISPASS57527.2023.00037
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Liu, LB
   Wang, Q
   Zhu, WP
   Mo, HY
   Wang, TC
   Yin, SY
   Shi, YY
   Wei, SJ
AF Liu, Leibo
   Wang, Qiang
   Zhu, Wenping
   Mo, Huiyu
   Wang, Tianchen
   Yin, Shouyi
   Shi, Yiyu
   Wei, Shaojun
TI A Face Alignment Accelerator Based on Optimized Coarse-to-Fine Shape
   Searching
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS FOR VIDEO TECHNOLOGY
DT Article
DE Cascaded regression; face alignment; landmark detection
ID REGRESSION; ROBUST
AB The coarse-to-fine shape searching (CFSS) framework is a recently developed algorithm that achieves relatively high accuracy in face alignment by alleviating the poor initialization problem facing traditional cascaded regression approaches. However, its high computational complexity and memory access demands make it difficult for CFSS to satisfy the requirements of real-time processing. To address this issue, a fast shape searching face alignment (F-SSFA) accelerator is presented based on the optimization of the CFSS algorithm and an efficient hardware implementation. First, the learning-based low-dimensional speeded-up robust features method, based on the correlations between the SURF features and the regression targets, is introduced to distill the feature set down to the only most distinct features to reduce the computing load. Second, the partial keypoints Euclidean distance and shape affine transformation are introduced to replace feature extraction and support vector machine classification, thereby accelerating the shape searching process. Compared with CFSS, F-SSFA achieves a 5.8x speedup while achieving similar accuracy. Moreover, a VLSI architecture is proposed to realize the fixed-point F-SSFA algorithm. Multiple descriptors located in adjacent regions are simultaneously generated in a single access to the corresponding image data. Therefore, repeated memory access operations are avoided. The optimal parameter configuration for hardware implementation is also exploited based on a tradeoff between accuracy and hardware performance. Simulated with TSMC 65-nm 1P8M technology within a 3.6 mm(2) area, a post-layout simulation shows that 700 fps can be achieved while consuming 300 mW at 200 MHz.
C1 [Liu, Leibo; Wang, Qiang; Mo, Huiyu; Yin, Shouyi; Wei, Shaojun] Tsinghua Univ, Inst Microelect, Beijing 100084, Peoples R China.
   [Zhu, Wenping] Univ Chinese Acad Sci, Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
   [Wang, Tianchen; Shi, Yiyu] Univ Notre Dame, Dept Comp Sci & Engn, Notre Dame, IN 46556 USA.
   [Wang, Tianchen; Shi, Yiyu] Univ Notre Dame, Dept Elect Engn, Notre Dame, IN 46556 USA.
RP Zhu, WP (corresponding author), Univ Chinese Acad Sci, Chinese Acad Sci, Inst Semicond, Beijing 100083, Peoples R China.
EM zhuwp@semi.ac.cn
CR Alabort-i-Medina J, 2014, PROC CVPR IEEE, P3438, DOI 10.1109/CVPR.2014.439
   An L, 2012, INT C PATT RECOG, P2885
   [Anonymous], FACIAL FEATURE POINT
   Ashraf AB, 2009, IMAGE VISION COMPUT, V27, P1788, DOI 10.1016/j.imavis.2009.05.007
   Asthana A, 2013, PROC CVPR IEEE, P3444, DOI 10.1109/CVPR.2013.442
   Belhumeur PN, 2011, PROC CVPR IEEE, P545, DOI 10.1109/CVPR.2011.5995602
   Bong K, 2017, ISSCC DIG TECH PAP I, P248, DOI 10.1109/ISSCC.2017.7870354
   Burgos-Artizzu XP, 2013, IEEE I CONF COMP VIS, P1513, DOI 10.1109/ICCV.2013.191
   Cao XD, 2012, PROC CVPR IEEE, P2887, DOI 10.1109/CVPR.2012.6248015
   Chen CR, 2011, IEEE T VLSI SYST, V19, P1937, DOI 10.1109/TVLSI.2010.2069575
   Chen HC, 2013, INTELL SYST SER, P1, DOI [10.1007/978-3-642-38868-2_1, 10.1016/B978-0-12-404702-0.00001-X, 10.1155/2013/213234]
   Chen PY, 2014, IEEE T INTELL TRANSP, V15, P656, DOI 10.1109/TITS.2013.2284666
   Cootes TF, 2001, IEEE T PATTERN ANAL, V23, P681, DOI 10.1109/34.927467
   Cristinacce D., 2006, P BRIT MACH VIS C, V1, P3, DOI [DOI 10.5244/C.20.95.CITESEER, DOI 10.5244/C.20.95]
   Dollár P, 2010, PROC CVPR IEEE, P1078, DOI 10.1109/CVPR.2010.5540094
   Dongsuk Jeon, 2015, 2015 Symposium on VLSI Circuits (VLSI Circuits), pC48, DOI 10.1109/VLSIC.2015.7231322
   Fan X, 2018, IEEE T MULTIMEDIA, V20, P567, DOI 10.1109/TMM.2017.2751143
   Gao XB, 2010, IEEE T SYST MAN CY C, V40, P145, DOI 10.1109/TSMCC.2009.2035631
   GOWER JC, 1975, PSYCHOMETRIKA, V40, P33, DOI 10.1007/BF02291478
   Hemmati M, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P543, DOI 10.1109/DSD.2014.60
   Hori Y, 2007, IEEE J SOLID-ST CIRC, V42, P790, DOI 10.1109/JSSC.2007.891675
   Jourabloo A, 2016, PROC CVPR IEEE, P4188, DOI 10.1109/CVPR.2016.454
   Kim HI, 2014, INT CONF DIGIT SIG, P562, DOI 10.1109/ICDSP.2014.6900728
   Le V, 2012, LECT NOTES COMPUT SC, V7574, P679, DOI 10.1007/978-3-642-33712-3_49
   Li J, 2016, IEEE T CIRCUITS SYST, V27, P907
   Lindner C, 2015, IEEE T PATTERN ANAL, V37, P1862, DOI 10.1109/TPAMI.2014.2382106
   Liu SF, 2013, PROCEEDINGS OF 2013 IEEE INTERNATIONAL CONFERENCE ON GREY SYSTEMS AND INTELLIGENT SERVICES (GSIS), P1, DOI 10.1109/GSIS.2013.6714728
   Lv JJ, 2017, PROC CVPR IEEE, P3691, DOI 10.1109/CVPR.2017.393
   Pavan M, 2007, IEEE T PATTERN ANAL, V29, P167, DOI 10.1109/TPAMI.2007.250608
   Ren SQ, 2014, PROC CVPR IEEE, P1685, DOI 10.1109/CVPR.2014.218
   Roth J, 2016, PROC CVPR IEEE, P4197, DOI 10.1109/CVPR.2016.455
   Sagonas C, 2013, 2013 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOPS (ICCVW), P397, DOI 10.1109/ICCVW.2013.59
   Sun Y, 2013, PROC CVPR IEEE, P3476, DOI 10.1109/CVPR.2013.446
   Tzimiropoulos G, 2014, PROC CVPR IEEE, P1851, DOI 10.1109/CVPR.2014.239
   Valstar M, 2010, PROC CVPR IEEE, P2729, DOI 10.1109/CVPR.2010.5539996
   Wu Y, 2017, PROC CVPR IEEE, P5719, DOI 10.1109/CVPR.2017.606
   Xiong XH, 2013, PROC CVPR IEEE, P532, DOI 10.1109/CVPR.2013.75
   Yang JL, 2009, IEEE T CIRC SYST VID, V19, P945, DOI 10.1109/TCSVT.2009.2020252
   Yu X, 2013, IEEE I CONF COMP VIS, P1944, DOI 10.1109/ICCV.2013.244
   Zhan J, 2014, DES AUT CON, DOI 10.1145/2593069.2593165
   Zhang ZP, 2014, LECT NOTES COMPUT SC, V8694, P94, DOI 10.1007/978-3-319-10599-4_7
   Zhu SZ, 2016, PROC CVPR IEEE, P3409, DOI 10.1109/CVPR.2016.371
   Zhu SZ, 2015, PROC CVPR IEEE, P4998, DOI 10.1109/CVPR.2015.7299134
   Zhu XX, 2012, PROC CVPR IEEE, P2879, DOI 10.1109/CVPR.2012.6248014
   Zhu XY, 2016, PROC CVPR IEEE, P146, DOI 10.1109/CVPR.2016.23
NR 45
TC 6
Z9 6
U1 1
U2 7
PD AUG
PY 2019
VL 29
IS 8
BP 2467
EP 2481
DI 10.1109/TCSVT.2018.2867499
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Yang, XK
   Sha, S
AF Yang, Xiaokun
   Sha, Shi
TI Exploiting Energy-Quality (E-Q) Tradeoffs: A Case Study on
   Color-to-Grayscale Converters with Approximate Design on FPGA
SO JOURNAL OF CIRCUITS SYSTEMS AND COMPUTERS
DT Article
DE Approximate design; energy-quality (E-Q) tradeoff; field programmable
   gate array (FPGA); register-transfer level (RTL)
AB Today, field programmable gate array (FPGA) is becoming widely used as computational accelerators in many application domains such as image/video processing, machine learning, and data mining. The inherent tolerance to the imprecise computation in such domains potentially provides an opportunity to trade quality of the results for higher energy efficiency. Therefore, this paper proposes a systematic methodology aiming to find the optimal energy saving corresponding to different quality bound, by approximating register-transfer level (RTL) designs on FPGA. As a case study, first, we investigate imprecise design on two submodules - adders and multipliers. By integrating the two combinational submodules with finite state machines (FSMs), several designs on a sequential circuit - color-to-grayscale converter - are further presented to offer a diverse range of energy consumption related to different quality constrains. Through this, we are able to set energy-quality (E-Q) parameters of our proposed methodology and configure the approximation knobs, capable of maximizing energy savings within different application-based quality margins. Experimental result demonstrates that leveraging E-Q leads to an average 1.37-2.16x savings in energy for modest loss in application output quality (<3%), and 2.31-2.50x energy savings for impact on relaxed quality constraints (3-7.5%).
C1 [Yang, Xiaokun] Univ Houston Clear Lake, Engn Dept, 2700 Bay Area Blvd, Houston, TX 77058 USA.
   [Sha, Shi] Wilkes Univ, Elect Engn, 84 West South St, Wilkes Barre, PA 18766 USA.
RP Yang, XK (corresponding author), Univ Houston Clear Lake, Engn Dept, 2700 Bay Area Blvd, Houston, TX 77058 USA.
EM YangXia@uhcl.edu; shi.sha@wilkes.edu
CR Angizi S., 2017, 2017 18 INT S QUAL E, P1
   Anusha G, 2020, MICROPROCESS MICROSY, V72, DOI 10.1016/j.micpro.2019.102940
   Bose S., 2019, IEEE T CIRCUITS SYST, V67, P1
   Caulfield Adrian M., 2016, MICROARCHITECTURE MI, P1, DOI DOI 10.1109/MICRO.2016.7783710
   Ebrahimi-Azandaryani F, 2020, IEEE T CIRCUITS-II, V67, P137, DOI 10.1109/TCSII.2019.2901060
   Gara B., 2017, J ELECT TEST, V33, P479
   He H., 2019, 21 INT C ARTIFICIAL, P129
   Hu JJ, 2019, INTEGRATION, V65, P370, DOI 10.1016/j.vlsi.2017.09.003
   Imani S.M., 2019, 2019 DES AUT TEST EU, P1
   Jung M, 2016, DES AUT CON, DOI 10.1145/2897937.2905002
   Leipnitz M. T., 2019, 2019 56 ACM IEEE DES, P1
   Leipnitz MT, 2019, ACM T EMBED COMPUT S, V18, DOI 10.1145/3358182
   Li BJ, 2016, PROCEEDINGS OF THE 2016 ACM CONFERENCE ON SPECIAL INTEREST GROUP ON DATA COMMUNICATION (SIGCOMM '16), P1, DOI 10.1145/2934872.2934897
   Liu B, 2019, IEEE ACCESS, V7, P82453, DOI 10.1109/ACCESS.2019.2924340
   Liu SL, 2019, 2019 8TH INTERNATIONAL CONFERENCE ON INFORMATICS, ENVIRONMENT, ENERGY AND APPLICATIONS (IAEA 2019), P1, DOI [10.1145/3323716.3323717, 10.1109/globalsip45357.2019.8969491]
   Lotfi A, 2016, DES AUT TEST EUROPE, P1279
   Mahapatra A, 2019, INTEGRATION, V64, P1, DOI 10.1016/j.vlsi.2018.03.011
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Padma A, 2020, MICROPROCESSORS, V73, P1
   Raghunathan V., 2015, DES AUT TEST EUR C E, P89
   Raha A, 2017, DES AUT CON, DOI 10.1145/3061639.3062333
   Raha A, 2016, IEEE T VLSI SYST, V24, P846, DOI 10.1109/TVLSI.2015.2424212
   Sinha S, 2016, IEEE T VLSI SYST, V24, P2665, DOI 10.1109/TVLSI.2016.2520979
   Vaca Kevin, 2019, 2019 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P378, DOI 10.1109/ISVLSI.2019.00075
   Vahdat S, 2019, IEEE T VLSI SYST, V27, P1161, DOI 10.1109/TVLSI.2018.2890712
   Van Toan N, 2020, IEEE ACCESS, V8, P25481, DOI 10.1109/ACCESS.2020.2970968
   Xu WB, 2018, IEEE T VLSI SYST, V26, P1112, DOI 10.1109/TVLSI.2018.2803081
   Yang TX, 2018, INT SYM QUAL ELECT, P347, DOI 10.1109/ISQED.2018.8357311
   Yang X., INT C ALG COMP SYST, P138
   Yang XK, 2019, INT SYM QUAL ELECT, P110, DOI 10.1109/ISQED.2019.8697816
   Yang XK, 2016, INTEGRATION, V52, P23, DOI 10.1016/j.vlsi.2015.07.012
   Zhang YX, 2019, IEEE COMP SOC ANN, P373, DOI 10.1109/ISVLSI.2019.00074
   Zhang YX, 2018, PROCEEDINGS OF THE 2018 2ND INTERNATIONAL CONFERENCE ON ALGORITHMS, COMPUTING AND SYSTEMS (ICACS 2018), P138, DOI 10.1145/3242840.3242852
NR 33
TC 1
Z9 1
U1 0
U2 1
PD MAR 30
PY 2021
VL 30
IS 4
AR 2150062
DI 10.1142/S0218126621500626
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Saragada, PK
   Manna, S
   Singh, A
   Das, BP
AF Saragada, Prasanna Kumar
   Manna, Subhashish
   Singh, Amandeep
   Das, Bishnu Prasad
TI A Configurable 10T SRAM-Based IMC Accelerator With Scaled-Voltage-Based
   Pulse Count Modulation for MAC and High-Throughput XAC
SO IEEE TRANSACTIONS ON NANOTECHNOLOGY
DT Article
DE Random access memory; Discharges (electric); Computer architecture;
   Capacitors; Voltage; Phase change materials; Transistors; Hardware
   accelerator; In-memory computation (IMC); machine learning algorithm;
   multiply-and-accumulate (MAC); SRAM; XNOR-and-accumulate (XAC)
ID MEMORY; ARCHITECTURE; WEIGHT; TOPS/W; ARRAY
AB This work proposes a 10T SRAM-based in-memory computation (IMC) architecture that can be configured to perform linear multiply-and-accumulate (MAC) operations and high-throughput XNOR-and-accumulate (XAC) operations. The IMC-MAC operation is performed by using the proposed scaled-voltage-based pulse count modulation (PCM) technique, which improves the linearity and signal margin of the MAC operation. The IMC-XAC operation is performed by using the proposed single capacitor discharge (SCD) approach with various advantages such as no deterministic error in XAC output, low latency, and less variation compared to the traditional charge sharing (TCS)-based XAC operation. The post-layout simulations of the proposed IMC architecture in a 65-nm CMOS process shows that the IMC architecture achieves a signal margin of 44.3 mV using the proposed scaled-voltage-based PCM approach in IMC-MAC mode whereas 37% less variation using the proposed SCD approach in IMC-XAC mode. In IMC-MAC mode, we achieve a 54.6 GOPS, 273 TOPS/W, and 98.67%/88.72% classification accuracy on MNIST/CIFAR-10 dataset using the convolution neural network (CNN)/ResNet20 algorithm. In IMC-XAC mode, we achieve a 3276.8 GOPS, 1092.2 TOPS/W, and 97.12% classification accuracy on the MNIST dataset using the binary neural network (BNN) algorithm.
C1 [Saragada, Prasanna Kumar; Manna, Subhashish; Singh, Amandeep; Das, Bishnu Prasad] Indian Inst Technol IIT Roorkee, Dept Elect & Commun Engn, Roorkee 247667, India.
RP Das, BP (corresponding author), Indian Inst Technol IIT Roorkee, Dept Elect & Commun Engn, Roorkee 247667, India.
EM skumar1@ec.iitr.ac.in; s_manna@ece.iitr.ac.in; a_singh@ece.iitr.ac.in;
   bishnu.das@ece.iitr.ac.in
CR Agrawal A, 2019, IEEE T CIRCUITS-I, V66, P3064, DOI 10.1109/TCSI.2019.2907488
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Giacomin E, 2021, IEEE T NANOTECHNOL, V20, P873, DOI 10.1109/TNANO.2021.3132224
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Jain S, 2021, IEEE J SOLID-ST CIRC, V56, P2981, DOI 10.1109/JSSC.2021.3092759
   Jiang ZW, 2019, PROC EUR SOLID-STATE, P131, DOI 10.1109/LSSC.2019.2934831
   Lee E, 2021, IEEE T CIRCUITS-I, V68, P3305, DOI 10.1109/TCSI.2021.3080042
   Lin ZT, 2021, IEEE J SOLID-ST CIRC, V56, P2550, DOI 10.1109/JSSC.2021.3063719
   Luo YC, 2021, IEEE T NANOTECHNOL, V20, P243, DOI 10.1109/TNANO.2021.3066319
   Mu J, 2022, IEEE T CIRCUITS-I, V69, P2412, DOI 10.1109/TCSI.2022.3152653
   Okumura S, 2019, S VLSI TECH, pC248
   Saragada PK, 2022, IEEE T VLSI SYST, V30, P1473, DOI 10.1109/TVLSI.2022.3199396
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Sinangil ME, 2021, IEEE J SOLID-ST CIRC, V56, P188, DOI 10.1109/JSSC.2020.3031290
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yu CS, 2020, IEEE CUST INTEGR CIR
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2023
VL 22
BP 222
EP 227
DI 10.1109/TNANO.2023.3269946
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology;
   Materials Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Huang, SS
   Jiang, HW
   Peng, XC
   Li, WT
   Yu, SM
AF Huang, Shanshi
   Jiang, Hongwu
   Peng, Xiaochen
   Li, Wantong
   Yu, Shimeng
TI Secure XOR-CIM Engine: Compute-In-Memory SRAM Architecture With Embedded
   XOR Encryption
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Cryptography; Engines; Computational modeling; Random access memory;
   System-on-chip; Encryption; Computer architecture; Compute-in-memory
   (CIM); hardware accelerator; machine learning security; static
   random-access memory (SRAM); XOR encryption
ID MACRO; NETWORKS
AB Compute-in-memory (CIM), where information can be processed and stored at the same locations, is emerging as a promising paradigm to address the memory wall bottleneck in traditional Von Neumann architectures. Static random-access memory (SRAM) has been demonstrated as a mature candidate for CIM accelerator for deep neural networks (DNNs) due to its availability in advanced technology nodes. However, as SRAM is volatile and could not hold weight after power down, the necessity for downloading models from the cloud to inference engine causes potential threats such as model leaking. Also, saving raw weights of the DNN model stationary in the memory cells will increase the vulnerabilities. This work aims at developing a secure inference engine with a lightweight yet effective countermeasure to protect the DNN models in SRAM-based CIM architecture. We propose a secure XOR-CIM engine with a modified reverse secure sketch protocol to enable on-chip authentication and key processing for XOR-based stream cipher encrypted models. In the XOR-CIM core, we modify the six-transistor SRAM bit cell with dual wordlines to implement XOR decryption without sacrificing the parallel computation's efficiency. The evaluations at 28 nm show that the XOR-CIM could enhance security, achieving comparable energy efficiency and no throughput loss, with negligible area overhead compared with the normal-CIM design without encryption.
C1 [Huang, Shanshi; Jiang, Hongwu; Peng, Xiaochen; Li, Wantong; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shuang406@gatech.edu; shimeng.yu@ece.gatech.edu
CR Arnaud F, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371934
   Baldanzi L, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20071869
   Barker E, 2015, RECOMMENDATION RANDO, DOI DOI 10.6028/NIST.SP.800-90AR1
   Biswas A, 2019, IEEE J SOLID-ST CIRC, V54, P217, DOI 10.1109/JSSC.2018.2880918
   Cai Y, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942041
   Chang J, 2017, ISSCC DIG TECH PAP I, P206, DOI 10.1109/ISSCC.2017.7870333
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chou CC, 2018, ISSCC DIG TECH PAP I, P478
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Deng L, 2020, P IEEE, V108, P485, DOI 10.1109/JPROC.2020.2976475
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Helfmeier C, 2013, 2013 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE-ORIENTED SECURITY AND TRUST (HOST), P1, DOI 10.1109/HST.2013.6581556
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Huang SS, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415678
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Jiang HW, 2020, IEEE T COMPUT, V69, P944, DOI 10.1109/TC.2020.2980533
   Jindal K, 2014, INT C ADV COMPUT COM, P398, DOI 10.1109/ACCT.2014.46
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Liu R, 2018, DES AUT CON, DOI [10.1109/INTMAG.2018.8508758, 10.1145/3195970.3196089]
   Lu MY, 2018, IEEE TRUST BIG, P1464, DOI 10.1109/TrustCom/BigDataSE.2018.00204
   Matt C, 2013, IEEE INT SYMP INFO, P2706, DOI 10.1109/ISIT.2013.6620718
   Peng XC, 2019, INT EL DEVICES MEET
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Roel M, 2012, PHYS UNCLONABLE FUNC
   Shiu YS, 2011, IEEE WIREL COMMUN, V18, P66, DOI 10.1109/MWC.2011.5751298
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Simonyan K., 2015, P 3 INT C LEARN REPR, P1
   Song T, 2018, ISSCC DIG TECH PAP I, P198, DOI 10.1109/ISSCC.2018.8310252
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   van de Leest Vincent, 2012, Cryptography and Security: From Theory to Applications. Essays Dedicated to Jean-Jacques Quisquater on the Occasion of His 65th Birthday: LNCS 6805, P300, DOI 10.1007/978-3-642-28368-0_20
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yang CF, 2020, IEEE T COMPUT AID D, V39, P2192, DOI 10.1109/TCAD.2019.2937817
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Zhou S., 2016, ARXIV160606160
NR 41
TC 5
Z9 5
U1 2
U2 8
PD DEC
PY 2021
VL 29
IS 12
BP 2027
EP 2039
DI 10.1109/TVLSI.2021.3120296
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Xydis, S
   Christoforidis, E
   Soudris, D
AF Xydis, Sotirios
   Christoforidis, Eleftherios
   Soudris, Dimitrios
GP IEEE
TI DDOT: Data Driven Online Tuning for energy efficient acceleration
SO PROCEEDINGS OF THE 2020 57TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 57th ACM/IEEE Design Automation Conference (DAC)
CY JUL 20-24, 2020
CL ELECTR NETWORK
DE Auto-tuning; data-driven energy optimization; manycore architectures;
   accelerated computing
ID PARETO ITERATIVE REFINEMENT
AB Modern accelerator platforms, are characterised by high micro-architectural complexity that affects both performance and energy consumption. Programmers usually are facing the problem of reasoning on differing trade-offs among the set of various code variants and their parameters configuration. While maximal configurations are usually adequate for performance optimization, this is not the case when optimizing for energy efficiency. Thus, efficient tuning methodologies accompanied with automated tools are of great importance for a quick and concrete evaluation of the explored design space. However, existing tuning frameworks are usually application-specific, i.e. performing well only on a priori known applications/workloads, and requiring heavy offline exploration and sampling procedures. In this paper, we present DDOT an online and scalable auto-tuning framework that enables the extraction of energy efficient tuning, with minimal online application characterisation. Instead of analyzing every application against every tuning configuration, it adopts a data driven approach, utilizing collaborative filtering, that quickly and with high accuracy configures the compilerand runtime-tuning parameters by identifying similarities to previously optimized applications. We evaluate DDOT efficiency utilizing as driving vehicle the Intel Phi accelerator platform, and compare it with state-of-art iterative and machine-learning tuning strategies as well with the exact optimal configurations of the derived solution space, through which we show that with minimal online characterisation, e.g. only either two or four online evaluations, DDOT finds tuning configurations that achieve more than 94% in respect to the optimal.
C1 [Xydis, Sotirios] Harokopio Univ Athens, Dept Informat & Telemat, Athens, Greece.
   [Christoforidis, Eleftherios; Soudris, Dimitrios] Natl Tech Univ Athens, Elect & Comp Engn, Athens, Greece.
RP Xydis, S (corresponding author), Harokopio Univ Athens, Dept Informat & Telemat, Athens, Greece.
EM sxydis@hua.gr; eleftherios.christoforidis@gmail.com;
   dsoudris@microlab.ntua.gr
CR [Anonymous], 2010, 23TH INT C ARCHITECT
   [Anonymous], 2013, ISCA
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Ashouri AH, 2016, ACM T ARCHIT CODE OP, V13, DOI 10.1145/2928270
   BAILEY DH, 1991, SUPERCOMPUTING 91, P158
   Cavazos J, 2007, INT SYM CODE GENER, P185
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen Y, 2012, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2355585.2355594
   Delimitrou C, 2013, ACM SIGPLAN NOTICES, V48, P77, DOI 10.1145/2499368.2451125
   Fursin G, 2011, INT J PARALLEL PROG, V39, P296, DOI 10.1007/s10766-010-0161-2
   Ganapathi Archana, 2009, P 1 USENIX C HOT TOP, P1
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kulkarni PA, 2009, ACM T ARCHIT CODE OP, V6, DOI 10.1145/1509864.1509865
   Kwon J, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3323919
   Leather H, 2014, ACM T ARCHIT CODE OP, V11, DOI 10.1145/2536688
   Leskovec J, 2014, MINING OF MASSIVE DATASETS, 2ND EDITION, P1
   Luk CK, 2011, IEEE SOFTWARE, V28, P39, DOI 10.1109/MS.2011.2
   Mishra N, 2015, ACM SIGPLAN NOTICES, V50, P267, DOI [10.1145/2694344.2694373, 10.1145/2775054.2694373]
   Muralidharan S, 2016, ACM SIGPLAN NOTICES, V51, P325, DOI 10.1145/2954679.2872411
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Putt J, 2008, TRENDS ISS CRIME CRI, P1
   Radojkovic P, 2016, IEEE T COMPUT, V65, P256, DOI 10.1109/TC.2015.2417533
   Tiwari A., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P879, DOI 10.1109/IPDPS.2011.86
   Tiwari A, 2009, INT PARALL DISTRIB P, P796
   Treibig J., 2010, 2010 39th International Conference on Parallel Processing Workshops (ICPPW), P207, DOI 10.1109/ICPPW.2010.38
   Triantafyllis S, 2003, INT SYM CODE GENER, P204, DOI 10.1109/CGO.2003.1191546
   Xydis S, 2015, IEEE T COMPUT AID D, V34, P155, DOI 10.1109/TCAD.2014.2363392
NR 27
TC 0
Z9 0
U1 0
U2 0
PY 2020
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Moini, S
   Tian, SQ
   Holcomb, D
   Szefer, J
   Tessier, R
AF Moini, Shayan
   Tian, Shanquan
   Holcomb, Daniel
   Szefer, Jakub
   Tessier, Russell
TI Power Side-Channel Attacks on BNN Accelerators in Remote FPGAs
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Field programmable gate arrays; Convolution; Neural networks; Kernel;
   Feature extraction; Circuits and systems; Side-channel attacks; Remote
   attacks; deep neural networks; convolutional neural networks;
   side-channel attacks; power attacks; time-to-digital converters (TDCs)
ID NEURAL-NETWORKS
AB To lower cost and increase the utilization of Cloud Field-Programmable Gate Arrays (FPGAs), researchers have recently been exploring the concept of multi-tenant FPGAs, where multiple independent users simultaneously share the same remote FPGA. Despite its benefits, multi-tenancy opens up the possibility of malicious users co-locating on the same FPGA as a victim user, and extracting sensitive information. This issue becomes especially serious when the user is running a machine learning algorithm that is processing sensitive or private information. To demonstrate the dangers, this paper presents a remote, power-based side-channel attack on a deep neural network accelerator running in a variety of Xilinx FPGAs and also on Cloud FPGAs using Amazon Web Services (AWS) F1 instances. This work in particular shows how to remotely obtain voltage estimates as a deep neural network inference circuit executes, and how the information can be used to recover the inputs to the neural network. The attack is demonstrated with a binarized convolutional neural network used to recognize handwriting images from the MNIST handwritten digit database. With the use of precise time-to-digital converters for remote voltage estimation, the MNIST inputs can be successfully recovered with a maximum normalized cross-correlation of 79% between the input image and the recovered image on local FPGA boards and 72% on AWS F1 instances. The attack requires no physical access nor modifications to the FPGA hardware.
C1 [Moini, Shayan; Holcomb, Daniel; Tessier, Russell] Univ Massachusetts Amherst, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
   [Tian, Shanquan; Szefer, Jakub] Yale Univ, Dept Elect Engn, New Haven, CT 06511 USA.
RP Moini, S (corresponding author), Univ Massachusetts Amherst, Dept Elect & Comp Engn, Amherst, MA 01003 USA.
EM smoini@umass.edu; shanquan.tian@yale.edu; dholcomb@umass.edu;
   jakub.szefer@yale.edu; tessier@umass.edu
CR Amazon, 2020, AM AWS F1
   [Anonymous], 2008, P 2 INT WORKSH HIGH
   [Anonymous], 2018, P DES AUT TEST EUR C
   Boutros A, 2020, INT C FIELD PROGR TE, P1
   Byma S, 2014, ANN IEEE SYM FIELD P, P109, DOI 10.1109/FCCM.2014.42
   Chen F., 2014, PES GEN M C EXP JUL, P1
   Chen Y, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P73, DOI 10.1145/3289602.3293915
   Ding K, 2020, BINARIZED DENSE CONV
   Giechaskiel I, 2020, P IEEE S SECUR PRIV, P1728, DOI 10.1109/SP40000.2020.00070
   Giechaskiel I, 2019, I C FIELD PROG LOGIC, P45, DOI 10.1109/FPL.2019.00017
   Giechaskiel I, 2018, PROCEEDINGS OF THE 2018 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIACCS'18), P15, DOI 10.1145/3196494.3196518
   Giechaskil I, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3322483
   Glamocanin O, 2020, DES AUT TEST EUROPE, P1007, DOI 10.23919/DATE48585.2020.9116481
   Gnad D. R. E, 2019, VOLTAGE BASED COVERT
   Hashimoto, 2020, P 13 INN SOFTW ENG C, P1
   Hua WZ, 2018, DES AUT CON, DOI 10.1145/3195970.3196105
   Hubara I., 2016, P 30 INT C NEUR INF, P4114, DOI DOI 10.5555/3157382.3157557
   Khawaja A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P107
   Krautter J., 2019, P IEEEACM INT C COMP, P1
   Moini S, 2017, IEEE T CIRCUITS-II, V64, P1217, DOI 10.1109/TCSII.2017.2690919
   NewAE Technology, 2020, CW1173 CHIPWHISPERER
   NewAE Technology, 2020, CW305 CHIPWHISPERER
   O'Flynn C, 2014, LECT NOTES COMPUT SC, V8622, P243, DOI 10.1007/978-3-319-10175-0_17
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Ramesh Chethan, 2018, 2018 IEEE 26th Annual International Symposium on Field-Programmable Custom Computing Machines (FCCM), P45, DOI 10.1109/FCCM.2018.00016
   RUDIN LI, 1992, PHYSICA D, V60, P259, DOI 10.1016/0167-2789(92)90242-F
   Satoh, 2020, SAKURA G FPGA BOARD
   Satoh, 2016, SAKURA X FPGA BOARD
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Szefer J., 2021, P DES AUT TEST EUR C, P1
   Vaishnav A, 2018, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2018.00031
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Weerasinghe J., 2015, P IEEE 12 INT C UB I, P1
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xiao Han, 2017, ARXIV170807747, P4321
   Xilinx, 2020, VCU118 EV BOARD
   Xilinx, 2020, ZCU104 EV BOARD
   Xilinx, 2019, UG973 VIV DES SUIT U
   Yoshida K, 2019, ANN IEEE SYM FIELD P, P318, DOI 10.1109/FCCM.2019.00059
   Zeng SL, 2020, ANN IEEE SYM FIELD P, P102, DOI 10.1109/FCCM48280.2020.00023
   Zhao M, 2018, P IEEE S SECUR PRIV, P229, DOI 10.1109/SP.2018.00049
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu W, 2019, ADV COMPUT MATH, V45, P3217, DOI 10.1007/s10444-019-09734-5
   Zick K. M., 2013, P ACM SIGDA INT S FI, P101, DOI DOI 10.1145/2435264.2435283
NR 44
TC 20
Z9 20
U1 0
U2 10
PD JUN
PY 2021
VL 11
IS 2
BP 357
EP 370
DI 10.1109/JETCAS.2021.3074608
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Lee, J
   Watanabe, Y
   Sato, M
AF Lee, Jinpil
   Watanabe, Yutaka
   Sato, Mitsuhisa
BE Fan, X
   DeSupinski, BR
   Sinnen, O
   Giacaman, N
TI OpenMP Task Generation for Batched Kernel APIs
SO OPENMP: CONQUERING THE FULL HARDWARE SPECTRUM, IWOMP 2019
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 15th International Workshop on OpenMP (IWOMP)
CY SEP 11-13, 2019
CL Auckland, NEW ZEALAND
DE OpenMP; Task parallelism; Accelerator; Batched BLAS
AB The demand for calculating many small computation kernels is getting significantly important in the HPC area not only for the traditional numerical applications but also recent machine learning applications. While many-core accelerators such as GPUs are power-efficient compute platforms, a large amount of code modification is required. Batched kernel APIs such as batched BLAS can schedule numerical kernels efficiently on the target hardware while it still needs manual code modification. In this paper, we propose a code translation technique to generate batched kernel APIs in a high-level programming model. We use OpenMP task parallelism to specify dependency among numerical kernels. The user adds the task directives to specify tasks so that the compiler can recognize numerical kernels. The compiler detects conventional numerical kernels in the code and creates a unique batch ID for each kernel. When the task runtime detects tasks with the same batch ID, they are merged into a batch. The current implementation supports NVIDIA GPUs and batched BLAS in cuBLAS. DGEMM kernels can be detected and translated into batched DGEMM. A trivial DGEMM loop and blocked Cholesky decomposition code are used for performance evaluation. The evaluation result shows that batched DGEMM improves the performance when the matrix size is small and the number of DGEMM kernels is large. The time for DGEMMs in blocked Cholesky decomposition is 4 times faster than sequential execution when using batched DGEMM (4096x4096 matrix, tile size 128), however the overall performance is improved 36% because of task/batch management overhead.
C1 [Lee, Jinpil; Sato, Mitsuhisa] RIKEN Ctr Computat Sci, Kobe, Hyogo, Japan.
   [Watanabe, Yutaka; Sato, Mitsuhisa] Univ Tsukuba, Grad Sch Syst & Informat Engn, Tsukuba, Ibaraki, Japan.
RP Lee, J (corresponding author), RIKEN Ctr Computat Sci, Kobe, Hyogo, Japan.
EM jinpil.lee@riken.jp; ywatanabe@hpcs.cs.tsukuba.ac.jp; msato@riken.jp
CR [Anonymous], ARGOBOTS OFFICIAL RE
   [Anonymous], Omni Compiler Infrastructure
   Dongarra J., 2018, BATCHED BLAS BASIC L
   Dongarra J, 2016, PROPOSED API BATCHED
   Dongarra J, 2017, PROCEDIA COMPUT SCI, V108, P495, DOI 10.1016/j.procs.2017.05.138
   Jin C, 2018, PROCEEDINGS OF 2018 IEEE/ACM 4TH INTERNATIONAL WORKSHOP ON EXTREME SCALE PROGRAMMING MODELS AND MIDDLEWARE (ESPM2 2018), P62, DOI 10.1109/ESPM2.2018.00012
   Muddukrishna Ananya, 2013, OpenMP in the Era of Low Power Devices and Accelerators. 9th International Workshop on OpenMP, IWOMP 2013. Proceedings: LNCS 8122, P156, DOI 10.1007/978-3-642-40698-0_12
   Olivier SL, 2009, LECT NOTES COMPUT SC, V5568, P63, DOI 10.1007/978-3-642-02303-3_6
   Relton S.D., 2016, COMP POTENTIAL INTER
   Watanabe Y, 2018, LECT NOTES COMPUT SC, V11128, P96, DOI 10.1007/978-3-319-98521-3_7
NR 10
TC 0
Z9 0
U1 0
U2 0
PY 2019
VL 11718
BP 262
EP 273
DI 10.1007/978-3-030-28596-8_18
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Ko, GG
   Chai, Y
   Rutenbar, RA
   Brooks, D
   Wei, GY
AF Ko, Glenn G.
   Chai, Yuji
   Rutenbar, Rob A.
   Brooks, David
   Wei, Gu-Yeon
BE Sourdis, I
   Bouganis, CS
   Alvarez, C
   Toledo, L
   Valero, P
   Martorell, X
TI Accelerating Bayesian Inference on Structured Graphs Using Parallel
   Gibbs Sampling
SO 2019 29TH INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE LOGIC AND
   APPLICATIONS (FPL)
SE International Conference on Field Programmable Logic and Applications
DT Proceedings Paper
CT 29th International Conference on Field-Programmable Logic and
   Applications (FPL)
CY SEP 09-13, 2019
CL Barcelona, SPAIN
DE bayesian inference; markov chain monte carlo; gibbs sampling; hardware
   accelerator; markov random field
AB Bayesian models and inference is a class of machine learning that is useful for solving problems where the amount of data is scarce and prior knowledge about the application allows you to draw better conclusions. However, Bayesian models often requires computing high-dimensional integrals and finding the posterior distribution can be intractable. One of the most commonly used approximate methods for Bayesian inference is Gibbs sampling, which is a Markov chain Monte Carlo (MCMC) technique to estimate target stationary distribution. The idea in Gibbs sampling is to generate posterior samples by iterating through each of the variables to sample from its conditional given all the other variables fixed. While Gibbs sampling is a popular method for probabilistic graphical models such as Markov Random Field (MRF), the plain algorithm is slow as it goes through each of the variables sequentially. In this work, we describe a binary label MRF Gibbs sampling inference architecture and extend it to 64-label version capable of running multiple perceptual applications, such as sound source separation and stereo matching. The described accelerator employs a chromatic scheduling of variables to parallelize all the conditionally independent variables to 257 samplers, implemented on the FPGA portion of a CPU-FPGA SoC. For real-time streaming sound source separation task, we show the hybrid CPU-FPGA implementation is 230x faster than a commercial mobile processor, while maintaining a recommended latency under 50 ms. The 64-label version showed 137x and 679x speedups for binary label MRF Gibbs sampling inference and 64 labels, respectively.
C1 [Ko, Glenn G.; Chai, Yuji; Brooks, David; Wei, Gu-Yeon] Harvard Univ, Cambridge, MA 02138 USA.
   [Rutenbar, Rob A.] Univ Pittsburgh, Pittsburgh, PA USA.
RP Ko, GG (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM gko@seas.harvard.edu; yuc927@g.harvard.edu; rutenbar@pitt.edu;
   dbrooks@eecs.harvard.edu; guyeon@eecs.harvard.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], P VLDB ENDOW
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   Das S, 2015, IEEE INT SYMP CIRC S, P2704, DOI 10.1109/ISCAS.2015.7169244
   De Sa C., 2018, ARXIV180606086
   De Sa C, 2016, PR MACH LEARN RES, V48
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Gonzalez J., 2011, P 14 INT C ARTIFICIA, P324
   Goodfellow IJ, 2014, ADV NEUR IN, V27, P2672
   Johnson M. J., 2013, PROC INT C NEURAL IN, V2, P2715
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim S, 2012, IEEE INT SYMP INTELL, P1, DOI 10.1109/ISIC.2012.6398245
   Kingma D. P., 2013, ARXIV13126114
   Ko GG, 2019, ANN IEEE SYM FIELD P, P334, DOI 10.1109/FCCM.2019.00075
   Ko GG, 2018, ACM J EMERG TECH COM, V14, DOI 10.1145/3183351
   Ko GG, 2017, INT CONF ACOUST SPEE, P2477, DOI 10.1109/ICASSP.2017.7952602
   Koller D., 2009, PROBABILISTIC GRAPHI
   LI SZ, 1995, MARKOV RANDOM FIELD
   Mansinghka V. K., 2008, STOCHASTIC DIGITAL C, V2069
   Newman D, 2009, J MACH LEARN RES, V10, P1801
   Rezende DJ, 2014, PR MACH LEARN RES, V32, P1278
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI [10.1109/SMBV.2001.988771, 10.1023/A:1014573219977]
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Terenin A., 2015, ASYNCHRONOUS DISTRIB
   Terenin A., STAT COMPUTING, P1
   Tkacik TE, 2002, LECT NOTES COMPUT SC, V2523, P450
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Wilson R, 2003, IEEE T PATTERN ANAL, V25, P42, DOI 10.1109/TPAMI.2003.1159945
NR 30
TC 4
Z9 4
U1 0
U2 0
PY 2019
BP 159
EP 165
DI 10.1109/FPL.2019.00033
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT C
AU Liu, SL
   Zeng, CL
   Fan, HX
   Ng, HC
   Meng, JX
   Que, ZQ
   Niu, XY
   Luk, W
AF Liu, Shuanglong
   Zeng, Chenglong
   Fan, Hongxiang
   Ng, Ho-Cheung
   Meng, Jiuxi
   Que, Zhiqiang
   Niu, Xinyu
   Luk, Wayne
GP IEEE
TI Memory-Efficient Architecture for Accelerating Generative Networks on
   FPGA
SO 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT
   2018)
DT Proceedings Paper
CT 17th International Conference on Field-Programmable Technology (FPT)
CY DEC 10-14, 2018
CL Naha, JAPAN
AB Generative adversarial networks (GANs) are a class of artificial intelligence algorithms used in unsupervised machine learning, implemented by a system of two neural networks: a generative network (generator) and a discriminative network (discriminator). These two networks compete with each other to perform better at their respective tasks. The generator is typically a deconvolutional neural network and the discriminator is a convolutional neural network (CNN). Deconvolution performs a fundamentally new type of mathematical operation which differs from convolution. While the FPGA-based CNN accelerators have been widely studied in prior work, the acceleration of deconvolutional networks on FPGA is rarely explored. This paper proposes a novel parametrized deconvolutional architecture based on an FPGA-friendly method, in contrast to the transposed convolution implementation in CPUs and GPUs. Hardware design templates which map this architecture to FPGAs are provided with configurable deconvolutional layer parameters. Furthermore, a memory-efficient architecture with a new tiling method is proposed to accelerate the generator of GANs, by storing all intermediate data in on-chip memories to significantly reduce off-chip data transfers. The performance of the proposed accelerator is evaluated using a variety of GANs on a Xilinx Zynq 706 board, which shows 2.3x higher speed and 8.2x offchip memory access reduction than an optimized Vanilla FPGA design. Compared to the respective implementations on CPUs and GPUs, the achieved improvements are in the range of 30x92x in speed over an Intel 8-core i7-950 CPU, and 8x-108x in terms of Performance-per-Watt over an NVIDIA Titan X GPU.
C1 [Liu, Shuanglong; Fan, Hongxiang; Ng, Ho-Cheung; Meng, Jiuxi; Que, Zhiqiang; Luk, Wayne] Imperial Coll London, Dept Comp, London, England.
   [Zeng, Chenglong] Tianjin Univ, Sch Microelect, Tianjin, Peoples R China.
   [Niu, Xinyu] Corerain Technol Ltd, Shenzhen, Peoples R China.
RP Liu, SL; Fan, HX (corresponding author), Imperial Coll London, Dept Comp, London, England.
EM s.liu13@imperial.ac.uk; zengchenglong@tju.edu.cn;
   h.fan17@imperial.ac.uk; h.ng16@imperial.ac.uk;
   jiuxi.meng16@imperial.ac.uk; z.que@imperial.ac.uk;
   xinyu.niu@corerain.com; w.luk@imperial.ac.uk
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2017, ARXIV170704993
   [Anonymous], 2017, FPGA 17 P 2017 ACMSI, DOI DOI 10.1145/3020078.3021738
   Chang JW, 2018, ASIA S PACIF DES AUT, P343, DOI 10.1109/ASPDAC.2018.8297347
   Dosovitskiy A, 2017, IEEE T PATTERN ANAL, V39, P692, DOI 10.1109/TPAMI.2016.2567384
   Dumoulin V, 2018, Arxiv, DOI [arXiv:1603.07285, DOI 10.48550/ARXIV.1603.07285]
   Ghasemzadeh M., 2018, FCCM
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Jalalifar S. A., 2018, ARXIV180307461
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kreutz-Delgado K., 2017, ARXIV170502583
   Li G, 2018, DES AUT TEST EUROPE, P1163, DOI 10.23919/DATE.2018.8342188
   Liu S., 2018, FPGA, P293
   Liu S., 2018, ACM T RECONFIGURABLE
   Liu SL, 2017, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2017.9
   Liu SL, 2017, IEEE T COMPUT, V66, P745, DOI 10.1109/TC.2016.2630682
   Liu SL, 2014, PROCEEDINGS OF THE 2014 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P191, DOI 10.1109/FPT.2014.7082775
   Liu SL, 2015, 2015 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (FPT), P120, DOI 10.1109/FPT.2015.7393138
   Lu LQ, 2017, ANN IEEE SYM FIELD P, P101, DOI 10.1109/FCCM.2017.64
   Mirza M., 2014, ARXIV14111784, P1, DOI DOI 10.48550/ARXIV.1411.1784
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Radford A., 2015, ARXIV151106434
   Yazdanbakhsh A, 2018, ANN IEEE SYM FIELD P, P65, DOI 10.1109/FCCM.2018.00019
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhao R., 2018, ASAP
NR 25
TC 13
Z9 13
U1 0
U2 5
PY 2018
BP 33
EP 40
DI 10.1109/FPT.2018.00016
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Rybaniec, R
   Przygoda, K
   Cichalewski, W
   Ayvazyan, V
   Branlard, J
   Butkowski, L
   Pfeiffer, S
   Schmidt, C
   Schlarb, H
   Sekutowicz, J
AF Rybaniec, Radoslaw
   Przygoda, Konrad
   Cichalewski, Wojciech
   Ayvazyan, Valeri
   Branlard, Julien
   Butkowski, Lukasz
   Pfeiffer, Sven
   Schmidt, Christian
   Schlarb, Holger
   Sekutowicz, Jacek
TI FPGA-Based RF and Piezocontrollers for SRF Cavities in CW Mode
SO IEEE TRANSACTIONS ON NUCLEAR SCIENCE
DT Article
DE Control systems; field programmable gate arrays (FPGAs); superconducting
   accelerators
ID ACTIVE NOISE-CONTROL; CONTROL SYSTEMS
AB Modern digital low level radio frequency (RF) control systems used to stabilize the accelerating field in facilities, such as free electron laser in Hamburg or the European X-ray free electron laser, are based on the field programmable gate array (FPGA) technology. Presently, these accelerator facilities are operated with pulsed RF. In the future, these facilities will operate with the continuous wave (CW), which requires significant modifications on the real-time feedbacks realized within the FPGA. For example, higher loaded quality factor of the superconducting RF cavities operated in the CW mode requires sophisticated resonance control methods. However, iterative learning techniques widely used for machines operated in pulsed mode are not applicable for the CW. In addition, the mechanical characteristic of the cavities now have a much more important impact on the choice of the feedback scheme. To overcome the limitations of classical proportional-integral controllers, a novel real-time adaptive feed-forward algorithm is implemented in the FPGA. Also, the high power RF amplifier, which is an inductive output tube (IOT) for CW operation instead of a klystron for the pulsed mode, has a major impact on the design and implementation of the firmware for regulation. In this paper, we report on our successful approach to control the multicavity vector sum with an ultrahigh precision (amplitude error <0.01% rms and phase stability <0.02 degrees rms), using a single IOT source and the individual resonance control through piezoactuators. Performance measurements of the proposed solution were conducted at the cryomodule test bench facility.
C1 [Rybaniec, Radoslaw] Warsaw Univ Technol, PL-00661 Warsaw, Poland.
   [Rybaniec, Radoslaw; Przygoda, Konrad; Ayvazyan, Valeri; Branlard, Julien; Butkowski, Lukasz; Pfeiffer, Sven; Schmidt, Christian; Schlarb, Holger; Sekutowicz, Jacek] DESY, D-22607 Hamburg, Germany.
   [Cichalewski, Wojciech] Lodz Univ Technol, PL-90924 Lodz, Poland.
RP Rybaniec, R (corresponding author), Warsaw Univ Technol, PL-00661 Warsaw, Poland.
EM rrybanie@mion.elka.pw.edu.pl
CR Branlard J., 2013, P 14 INT C ACCELERAT, P1239
   Branlard J, 2013, MIXED DESIGN OF INTEGRATED CIRCUITS AND SYSTEMS, MIXDES 2013, P109
   Brinkmann R., 2006, XFEL EUR XRAY FREE E
   Butkowski L., 2015, P 15 INT C ACC LARG, DOI [10.18429/JACoW-ICALEPCS2015-WEPGF074, DOI 10.18429/JACOW-ICALEPCS2015-WEPGF074]
   Carcagno R., 2003, THP39 FERM NAT ACC L, P726
   Cichalewski W., 2008, THESIS
   DESY. Hamburg, 2007, FLASH THE FREE EL LA
   Kandil TH, 2005, NUCL INSTRUM METH A, V550, P514, DOI 10.1016/j.nima.2005.05.060
   Kugeler O., 2007, P 41 ADV ICFA BEAM D, P85
   Kuo SM, 2006, IEEE T AUDIO SPEECH, V14, P1857, DOI 10.1109/TSA.2005.858524
   Kuo SM, 1996, IEEE T SPEECH AUDI P, V4, P96, DOI 10.1109/89.486059
   Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   Kuo SM., 1995, ACTIVE NOISE CONTROL
   Ljung L., 1999, SYSTEM IDENTIFICATIO, V2nd
   Neumann A., 2007, P WORKSH RF SUP BEIJ, P377
   Przygoda K., 2011, THESIS
   Przygoda K., 2012, MEAS AUTOM MONITOR, V58, P668
   Przygoda K., IEEE T NUCL IN PRESS
   Rutkowski I, 2015, IEEE T NUCL SCI, V62, P3186, DOI 10.1109/TNS.2015.2499382
   Rutkowski I, 2013, IEEE T NUCL SCI, V60, P3609, DOI 10.1109/TNS.2013.2278372
   Rybaniec R., 2014, P 5 INT PART ACC C, P2456
   Rybaniec R., 2015, P 6 INT PART ACC C, P15
   Schilcher T., 1998, THESIS
   Schmidt C., 2010, THESIS
   Sekutowicz J, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.050701
   Volder J. E., 1959, IRE T ELECT COMPUT, VEC-8, P330, DOI [10.1109/TEC.1959.5222693, DOI 10.1109/TEC.1959.5222693]
   Xilinx Inc, 2014, UG479 XIL INC
   [No title captured]
NR 28
TC 12
Z9 12
U1 1
U2 9
PD JUN
PY 2017
VL 64
IS 6
BP 1382
EP 1388
DI 10.1109/TNS.2017.2687981
PN 1
WC Engineering, Electrical & Electronic; Nuclear Science & Technology
DA 2023-11-11
ER

PT J
AU Puente, V
   Gregorio, JA
AF Puente, Valentin
   Angel Gregorio, Jose
TI CLASSIC: A cortex-inspired hardware accelerator
SO JOURNAL OF PARALLEL AND DISTRIBUTED COMPUTING
DT Article
DE Cortex; Cortical learning algorithm; Packet-switched network;
   Neuroscience; Computer architecture
ID NEURONS; SPARSE; MICROCIRCUITS; PLASTICITY
AB This work explores the feasibility of specialized hardware implementing the Cortical Learning Algorithm (CLA) in order to fully exploit its inherent advantages. This algorithm, which is inspired by the current understanding of the mammalian neo-cortex, is the basis of the Hierarchical Temporal Memory (HTM). In contrast to other machine learning (ML) approaches, the structure is not application dependent and relies on fully unsupervised continuous learning. We hypothesize that a hardware implementation will be able not only to extend the existing practical uses of these ideas to broader scenarios but also to exploit CLA's hardware-friendly characteristics.
   The architecture proposed will enable the system size to be scaled up compared to a state-of-the-art CLA software implementation. It may be possible to improve performance by 4 orders of magnitude and energy efficiency by up to 8 orders of magnitude.
   Given the problem's complex nature, we found that the most demanding issue, from a scalability standpoint, is the massive degree of connectivity required. We propose to use a packet-switched network to tackle this. The paper addresses the fundamental issues of such an approach, proposing solutions to achieve a scalable proposal. We will analyze cost and performance when using well-known architectural techniques and tools. The results obtained suggest that even with CMOS technology, under constrained cost, it might be possible to implement a large-scale system. We found that the proposed solutions enable a saving of similar to 90% of the original communication costs running either synthetic or realistic workloads. (C) 2019 Elsevier Inc. All rights reserved.
C1 [Puente, Valentin; Angel Gregorio, Jose] Univ Cantabria, Comp Architecture, Dept Comp & Elect, Santander, Spain.
RP Puente, V (corresponding author), Univ Cantabria, Comp Architecture, Dept Comp & Elect, Santander, Spain.
EM vpuente@unican.es
CR Abad P., 2012, 2012 Sixth IEEE/ACM International Symposium on Networks-on-Chip (NoCS), P99, DOI 10.1109/NOCS.2012.19
   Anderson CT, 2010, NAT NEUROSCI, V13, P739, DOI 10.1038/nn.2538
   [Anonymous], 2014, CUDNN EFFICIENT PRIM
   [Anonymous], 2016, IEEE SPECTRUM
   [Anonymous], 2015, DEEP LEARNING LTD NU
   [Anonymous], 2015, PROPERTIES SPARSE DI
   [Anonymous], 2016, EIE EFFICIENT INFERE
   Bahrampour S., 2015, COMP STUDY CAFFE NEO
   BLOOM BH, 1970, COMMUN ACM, V13, P422, DOI 10.1145/362686.362692
   Briggs F, 2010, FRONT NEURAL CIRCUIT, V4, DOI 10.3389/neuro.04.003.2010
   Bruno RM, 2002, J NEUROSCI, V22, P10966
   Buxhoeveden DP, 2002, BRAIN, V125, P935, DOI 10.1093/brain/awf110
   Caporale N, 2008, ANNU REV NEUROSCI, V31, P25, DOI 10.1146/annurev.neuro.31.060407.125639
   Cassidy AS, 2014, INT CONF HIGH PERFOR, P27, DOI 10.1109/SC.2014.8
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen Z., 2016, P 12 USENIX S OP SYS, P265, DOI 10.5555/ 3026877.3026899
   Clascá F, 2012, EUR J NEUROSCI, V35, P1524, DOI 10.1111/j.1460-9568.2012.08033.x
   Cui YW, 2017, FRONT COMPUT NEUROSC, V11, DOI 10.3389/fncom.2017.00111
   Cui YW, 2016, NEURAL COMPUT, V28, P2474, DOI 10.1162/NECO_a_00893
   de Nó RL, 1934, J PSYCHOL NEUROL, V46, P113
   DeSieno D., 1988, IEEE International Conference on Neural Networks (IEEE Cat. No.88CH2632-8), P117, DOI 10.1109/ICNN.1988.23839
   Ding L, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P201
   Duato J., 1997, INTERCONNECTION NETW
   El-Boustani S, 2018, SCIENCE, V360, P1349, DOI 10.1126/science.aao0862
   Grienberger C, 2015, TRENDS NEUROSCI, V38, P45, DOI 10.1016/j.tins.2014.11.002
   Hawkins J, 2017, FRONT NEURAL CIRCUIT, V11, DOI 10.3389/fncir.2017.00081
   Hawkins J, 2016, FRONT NEURAL CIRCUIT, V10, DOI 10.3389/fncir.2016.00023
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jerger NE, 2008, CONF PROC INT SYMP C, P229, DOI 10.1109/ISCA.2008.12
   Kumar A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/2976742
   Lavin A, 2015, 2015 IEEE 14TH INTERNATIONAL CONFERENCE ON MACHINE LEARNING AND APPLICATIONS (ICMLA), P38, DOI 10.1109/ICMLA.2015.141
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lewis M, 2019, FRONT NEURAL CIRCUIT, V13, DOI 10.3389/fncir.2019.00022
   Mnatzaganian J., 2016, MATH FORMALIZATION H, P1
   Mountcastle VB, 1997, BRAIN, V120, P701, DOI 10.1093/brain/120.4.701
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Olshausen BA, 2004, CURR OPIN NEUROBIOL, V14, P481, DOI 10.1016/j.conb.2004.07.007
   Olshausen BA, 1996, NATURE, V381, P607, DOI 10.1038/381607a0
   Pietron M, 2016, LECT NOTES ARTIF INT, V9920, P396, DOI 10.1007/978-3-319-47160-0_36
   Puente V, 2004, CONF PROC INT SYMP C, P198, DOI 10.1109/ISCA.2004.1310775
   Puente V, 2001, J PARALLEL DISTR COM, V61, P1180, DOI 10.1006/jpdc.2001.1746
   Rinkus GJ, 2014, FRONT COMPUT NEUROSC, V8, DOI 10.3389/fncom.2014.00160
   Sherman SM, 2014, NEUROSCIENTIST, V20, P136, DOI 10.1177/1073858413478490
   Sin W., 2002, NATURE, V2112, P2108
   Theophilou I., 2015, GEN PAULI CONSTRAINT
   Thomson AM, 2010, FRONT NEUROANAT, V4, DOI 10.3389/fnana.2010.00013
   VanEssen DC, 1997, J NEUROSCI, V17, P7079
   Vélez-Fort M, 2014, NEURON, V83, P1431, DOI 10.1016/j.neuron.2014.08.001
   Walter F, 2017, IEEE INT SYMP CIRC S, P2715
   Wixted JT, 2014, P NATL ACAD SCI USA, V111, P9621, DOI 10.1073/pnas.1408365111
NR 50
TC 1
Z9 1
U1 0
U2 3
PD DEC
PY 2019
VL 134
BP 140
EP 152
DI 10.1016/j.jpdc.2019.08.009
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Arora, A
   Bhamburkar, A
   Borda, A
   Anand, T
   Sehgal, R
   Hanindhito, B
   Gaillardon, PE
   Kulkarni, J
   John, LK
AF Arora, Aman
   Bhamburkar, Atharva
   Borda, Aatman
   Anand, Tanmay
   Sehgal, Rishabh
   Hanindhito, Bagus
   Gaillardon, Pierre-Emmanuel
   Kulkarni, Jaydeep
   John, Lizy K.
TI CoMeFa: Deploying Compute-in-Memory on FPGAs for Deep Learning
   Acceleration
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE FPGA; Processing-In-Memory; Compute-In-Memory; Block RAM; Deep Learning;
   Machine Learning
ID SRAM; RAM; NM
AB Block random access memories (BRAMs) are the storage houses of FPGAs, providing extensive on-chip memory bandwidth to the compute units implemented using logic blocks and digital signal processing slices. We propose modifying BRAMs to convert them to CoMeFa (Compute-in-Memory Blocks for FPGAs) random access memories (RAMs). These RAMs provide highly parallel compute-in-memory by combining computation and storage capabilities in one block. CoMeFa RAMs utilize the true dual-port nature of FPGA BRAMs and contain multiple configurable single-bit bit-serial processing elements. CoMeFa RAMs can be used to compute with any precision, which is extremely important for applications like deep learning (DL). Adding CoMeFa RAMs to FPGAs significantly increases their compute density while also reducing data movement. We explore and propose two architectures of these RAMs: CoMeFa-D (optimized for delay) and CoMeFa-A (optimized for area). Compared to existing proposals, CoMeFa RAMs do not require changing the underlying static RAM technology like simultaneously activating multiple wordlines on the same port, and are practical to implement. CoMeFa RAMs are especially suitable for parallel and compute-intensive applications like DL, but these versatile blocks find applications in diverse applications like signal processing and databases, among others. By augmenting an Intel Arria 10-like FPGA with CoMeFa-D (CoMeFa-A) RAMs at the cost of 3.8% (1.2%) area, and with algorithmic improvements and efficient mapping, we observe a geomean speedup of 2.55x (1.85x) across microbenchmarks from various applications and a geomean speedup of up to 2.5x across multiple deep neural networks. Replacing all or some BRAMs with CoMeFa RAMs in FPGAs can make them better accelerators of DL workloads.
C1 [Arora, Aman; Sehgal, Rishabh; Hanindhito, Bagus; Kulkarni, Jaydeep; John, Lizy K.] Univ Texas, Elect & Comp Engn, 2501 Speedway C0803, Austin, TX 78712 USA.
   [Bhamburkar, Atharva] Birla Inst Technol & Sci, Dept Elect & Elect Engn, Pilani KK Birla Goa Campus,NH 17B, Zuarinagar 403726, Goa, India.
   [Borda, Aatman; Anand, Tanmay] Birla Inst Technol & Sci, Dept Elect & Elect Engn, VidyaVihar Campus, Pilani 333031, Rajasthan, India.
   [Gaillardon, Pierre-Emmanuel] Dept Elect & Comp Engn, 50 S Cent Campus Dr,Rm 2110 MEB, Salt Lake City, UT 84112 USA.
RP Arora, A (corresponding author), Univ Texas, Elect & Comp Engn, 2501 Speedway C0803, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; f20190456@goa.bits-pilani.ac.in;
   borda.aatman@gmail.com; tanmay.anand29@gmail.com;
   sehgal.rish@utexas.edu; hanindhito@bagus.my.id;
   pierre-emmanuel.gaillardon@utah.edu; jaydeep@austin.utexas.edu;
   ljohn@ece.utexas.edu
CR Achronix, 2019, SPEEDSTER7T FPGAS
   Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Agrawal A, 2018, IEEE T CIRCUITS-I, V65, P4219, DOI 10.1109/TCSI.2018.2848999
   Altera, 2015, DES FILT HIGH PERF
   Arizona State University, 2012, PREDICTIVE TECHNOLOG
   Arora Aman, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P23, DOI 10.1145/3431920.3439282
   ARORA A, 2021, P 2021 31 INT C FIEL, DOI DOI 10.1109/FPL53798.2021.00068
   ARORA A, 2022, P 2022 IEEE 30 ANN I, P1, DOI DOI 10.1109/FCCM53951.2022.9786179
   Arora A, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3529650
   Arora Aman, 2021, P 2021 55 ASILOMAR C, P1156, DOI [10.1109/IEEECONF53345.2021.9723277, DOI 10.1109/IEEECONF53345.2021.9723277]
   Boutros A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P10, DOI 10.1109/ICFPT51103.2020.00011
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   Eldafrawy M, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3393668
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Gauchi R., 2020, P ACMIEEE INT S LOW, P121, DOI [10.1145/3370748.3406550, DOI 10.1145/3370748.3406550]
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Intel, 2020, INT ARR 10 DEV DAT
   Intel, 2021, INT ARR 10 TRANSC PH
   Intel, 2021, INT ARR 10 DEV OV
   Intel, 2021, INT ARR 10 PROD TABL
   Intel, 2016, HYBR MEM CUB CONTR I
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Ju L, 2018, IEEE T COMPUT AID D, V37, P2661, DOI 10.1109/TCAD.2018.2857261
   Kang MG, 2020, P IEEE, V108, P2251, DOI 10.1109/JPROC.2020.3034117
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Landy A, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/2996459
   Landy A, 2015, ANN IEEE SYM FIELD P, P9, DOI 10.1109/FCCM.2015.53
   Langhammer Martin, 2021, FPGA '21: The 2021 ACM/SIGDA International Symposium on Field-Programmable, P57, DOI 10.1145/3431920.3439293
   Lewis D., 2013, P ACMSIGDA INT S FIE, P147, DOI 10.1145
   Li SC, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P288, DOI 10.1145/3123939.3123977
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Narang S., 2016, BAIDU DEEPBENCH
   NCSU, 2018, FREEPDK45
   Prakash Shvetank, 2022, ARXIV
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Sun X, 2019, ADV NEUR IN, V32
   Tatsumura K, 2018, ACM T RECONFIG TECHN, V11, DOI 10.1145/3154425
   TYHACH J, 2015, P 2015 IEEE CUST INT, P1, DOI DOI 10.1109/CICC.2015.7338368
   Wang JC, 2020, IEEE J SOLID-ST CIRC, V55, P76, DOI 10.1109/JSSC.2019.2939682
   Wang XW, 2021, ANN IEEE SYM FIELD P, P88, DOI 10.1109/FCCM51124.2021.00018
   Xilinx, 2018, AI ENG THEIR APPL
   Xilinx, 2021, ULTRASCALE ARCHITECT
   Yazdanshenas S, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3301298
   Yazdanshenas S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P115, DOI 10.1145/3020078.3021731
   Yi-Chung Chen, 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P367, DOI 10.1109/FPL.2012.6339206
NR 56
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 16
IS 3
AR 50
DI 10.1145/3603504
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Mahon, S
   Varrette, S
   Plugaru, V
   Pinel, F
   Bouvry, P
AF Mahon, Sean
   Varrette, Sebastien
   Plugaru, Valentin
   Pinel, Frederic
   Bouvry, Pascal
BE Lefevre, L
   Varela, CA
   Pallis, G
   Toosi, AN
   Rana, O
   Buyya, R
TI Performance Analysis of Distributed and Scalable Deep Learning
SO 2020 20TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON CLUSTER, CLOUD AND
   INTERNET COMPUTING (CCGRID 2020)
DT Proceedings Paper
CT 20th IEEE/ACM International Symposium on Cluster, Cloud and Internet
   Computing (CCGrid)
CY MAY 11-14, 2020
CL Melbourne, AUSTRALIA
AB With renewed global interest for Artificial Intelligence (AI) methods, the past decade has seen a myriad of new programming models and tools that enable better and faster Machine Learning (ML). More recently, a subset of ML known as Deep Learning (DL) raised an increased interest due to its inherent ability to tackle efficiently novel cognitive computing applications. DL allows computational models that are composed of multiple processing layers to learn in an automated way representations of data with multiple levels of abstraction, and can deliver higher predictive accuracy when trained on larger data sets. Based on Artificial Neural Networks (ANN), DL is now at the core of state of the art voice recognition systems (which enable easy control over e.g. Internet-of- Things (IoT) smart home appliances for instance), self-driving car engine, online recommendation systems. The ecosystem of DL frameworks is fast evolving, as well as the DL architectures that are shown to perform well on specialized tasks and to exploit GPU accelerators. For this reason, the frequent performance evaluation of the DL ecosystem is required, especially since the advent of novel distributed training frameworks such as Horovod allowing for scalable training across multiple computing resources.
   In this paper, the scalability evaluation of the reference DL frameworks (Tensorflow, Keras, MXNet, and PyTorch) is performed over up-to-date High Performance Computing (HPC) resources to compare the efficiency of different implementations across several hardware architectures (CPU and GPU). Experimental results demonstrate that the DistributedDataParallel features in the Pytorch library seem to be the most efficient framework for distributing the training process across many devices, allowing to reach a throughput speedup of 10.11 when using 12 NVidia Tesla V100 GPUs when training Resnet44 on the CIFAR10 dataset.
C1 [Mahon, Sean] Trinity Coll Dublin, Dublin, Ireland.
   [Varrette, Sebastien; Bouvry, Pascal] Univ Luxembourg, Interdisciplinary Ctr Secur Reliabil & Trust SnT, 2 Ave Univ, L-4365 Esch Sur Alzette, Luxembourg.
   [Plugaru, Valentin; Pinel, Frederic] Univ Luxembourg, Comp Sci & Commun CSC Res Unit, 2 Ave Univ, L-4365 Esch Sur Alzette, Luxembourg.
RP Mahon, S (corresponding author), Trinity Coll Dublin, Dublin, Ireland.
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, EMPIRICALLY
   Banko M, 2001, 39TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P26, DOI 10.3115/1073012.1073017
   Ben-Nun T, 2019, INT PARALL DISTRIB P, P66, DOI 10.1109/IPDPS.2019.00018
   Chollet F., 2015, KERAS
   Coleman CA, 2017, DAWNBENCH END TO END
   Collobert R., 2011, BIGLEARN
   Goyal P, 2017, IEEE I CONF COMP VIS, P5104, DOI 10.1109/ICCV.2017.545
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2009, TECH REP
   Paszke A, 2019, ADV NEUR IN, V32
   Patarasuk P, 2009, J PARALLEL DISTR COM, V69, P117, DOI 10.1016/j.jpdc.2008.09.002
   Poess M, 2019, COMPANION OF THE 2019 ACM/SPEC INTERNATIONAL CONFERENCE ON PERFORMANCE ENGINEERING (ICPE '19), P17, DOI 10.1145/3302541.3313098
   Russell S, 2009, ARTIFICIAL INTELLIGE
   Sergeev A., 2018, HOROVOD FAST EASY DI
   Varrette S, 2014, 2014 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS), P959, DOI 10.1109/HPCSim.2014.6903792
   Vaswani A, 2017, ADV NEUR IN, V30
   Verma S., 2019, DEMYSTIFYING MLPERF
NR 19
TC 3
Z9 3
U1 1
U2 3
PY 2020
BP 760
EP 766
DI 10.1109/CCGrid49817.2020.00-13
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Crafton, B
   Spetalnick, S
   Murali, G
   Krishna, T
   Lim, SK
   Raychowdhury, A
AF Crafton, Brian
   Spetalnick, Samuel
   Murali, Gauthaman
   Krishna, Tushar
   Lim, Sung-Kyu
   Raychowdhury, Arijit
GP IEEE
TI Breaking Barriers: Maximizing Array Utilization for Compute In-Memory
   Fabrics
SO 2020 IFIP/IEEE 28TH INTERNATIONAL CONFERENCE ON VERY LARGE SCALE
   INTEGRATION (VLSI-SOC)
SE IEEE-IFIP International Conference on VLSI and System-on-Chip
DT Proceedings Paper
CT IFIP/IEEE 28th International Conference on Very Large Scale Integration
   (VLSI-SOC)
CY OCT 05-09, 2020
CL ELECTR NETWORK
AB Compute in-memory (CIM) is a promising technique that minimizes data transport, the primary performance bottleneck and energy cost of most data intensive applications. This has found wide-spread adoption in accelerating neural networks for machine learning applications. Utilizing a crossbar architecture with emerging non-volatile memories (eNVM) such as dense resistive random access memory (RRAM) or phase change random access memory (PCRAM), various forms of neural networks can be implemented to greatly reduce power and increase on chip memory capacity. However, compute in-memory faces its own limitations at both the circuit and the device levels. Although compute in-memory using the crossbar architecture can greatly reduce data transport, the rigid nature of these large fixed weight matrices forfeits the flexibility of traditional CMOS and SRAM based designs. In this work, we explore the different synchronization barriers that occur from the CIM constraints. Furthermore, we propose a new allocation algorithm and data flow based on input data distributions to maximize utilization and performance for compute-in memory based designs. We demonstrate a 7.47x performance improvement over a naive allocation method for CIM accelerators on ResNet18.
C1 [Crafton, Brian; Spetalnick, Samuel; Murali, Gauthaman; Krishna, Tushar; Lim, Sung-Kyu; Raychowdhury, Arijit] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Crafton, B (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM brian.crafton@gatech.edu; arijit.raychowdhury@ece.gatech.edu
CR Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Crafton B., 2020, ARXIV PREPRINT ARXIV
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Peng XC, 2020, IEEE T CIRCUITS-I, V67, P1333, DOI 10.1109/TCSI.2019.2958568
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Wu JY., 2018, 2018 IEEE INT EL DEV, P27
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
NR 9
TC 3
Z9 3
U1 2
U2 4
PY 2020
BP 123
EP 128
DI 10.1109/VLSI-SOC46417.2020.9344086
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Milojicic, D
   Bresniker, K
   Campbell, G
   Faraboschi, P
   Strachan, JP
   Williams, S
AF Milojicic, Dejan
   Bresniker, Kirk
   Campbell, Gary
   Faraboschi, Paolo
   Strachan, John Paul
   Williams, Stan
GP IEEE
TI Computing In-Memory, Revisited
SO 2018 IEEE 38TH INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING SYSTEMS
   (ICDCS)
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 38th IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY JUL 02-05, 2018
CL Vienna Univ Technol, Vienna, AUSTRIA
HO Vienna Univ Technol
DE Architecture; computing; memory; interconnects; accelerators;
   programming; configuring; performance; scaling
ID ARCHITECTURE
AB The Von Neumann's architecture has been the dominant computing paradigm ever since its inception in the mid-forties. It revolves around the concept of a "stored program" in memory, and a central processing unit that executes the program. As an alternative, Processing-In-Memory (PIM) ideas have been around for at least two decades, however with very limited adoption. Today, three trends are creating a compelling motivation to take a second look. Novel devices such as memristor blur the boundary between memory and compute, effectively providing both in the same element. Power efficiency has become very important, both in the datacenter and at the edge. Machine learning applications driven by a data-flow model have become ubiquitous. In this paper, we sketch our Computing-In-Memory (CIM) vision, and its substantial performance and power improvement potential. Compared to PIM models, CIM more clearly separates computing from memory. We then discuss the programming model, which we consider the biggest challenge. We close by describing how CIM impacts non-functional characteristics, such as reliability, scale, and configurability.
C1 [Milojicic, Dejan; Campbell, Gary; Faraboschi, Paolo; Strachan, John Paul; Williams, Stan] Hewlett Packard Labs, Syst Lab, Palo Alto, CA 94304 USA.
   [Bresniker, Kirk] Hewlett Packard Labs, Off CTO, Palo Alto, CA USA.
RP Milojicic, D (corresponding author), Hewlett Packard Labs, Syst Lab, Palo Alto, CA 94304 USA.
EM dejan.milojicic@hpe.com; kirk.bresniker@hpe.com; gary.campbell@hpe.com;
   paolo.faraboschi@hpe.com; john-paul.strachan@hpe.com;
   stan.williams@hpe.com
CR Achermann R., P ACM 16 WORKSH HOT, P118
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], IEEE COMPUTER ARCHIT
   [Anonymous], 2013, SIGPLAN WORKSH MEM S
   [Anonymous], 2018, IEEE TECHNOLOGY TREN
   [Anonymous], 2004, PROC WMPI
   [Anonymous], 1965, ELECTRONICS
   Asanovic K., 2006, LANDSCAPE PARALLEL C
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Bruel P., 2017, 2 INT C REB COMP WAS
   Budiu M, 2004, ACM SIGPLAN NOTICES, V39, P14, DOI 10.1145/1037187.1024396
   Chacos Brad, PC WORLD
   Chen W. H., 2017, IEDM, DOI [10.1109/IEDM.2017.8268468, DOI 10.1109/IEDM.2017.8268468]
   Cong J, 2014, IEEE T VLSI SYST, V22, P864, DOI 10.1109/TVLSI.2013.2259512
   Conte Thomas A., 2018, COMPUTER, V51
   Culler D., 1999, PARALLEL COMPUTER AR
   Dally W. J., 2004, PRINCIPLES PRACTICES
   DeBenedictis EP, 2017, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC.2017.8091044
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Dou CM, 2017, INT CONF ASIC, P140, DOI 10.1109/ASICON.2017.8252431
   Elliott DG, 1999, IEEE DES TEST COMPUT, V16, P32, DOI 10.1109/54.748803
   Farabet C., 2011, CVPR 2011 WORKSH, P109, DOI [10.1109/CVPRW.2011.5981829, DOI 10.1109/CVPRW.2011.5981829]
   Faraboschi Paolo, 2015, 15 WORKSH HOT TOP OP
   Foster C. C., 1976, CONTENT ADDRESSABLE
   Goldstein SC, 2000, COMPUTER, V33, P70, DOI 10.1109/2.839324
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Hall Mary, P 1999 ACM IEEE C SU, P57
   Hsieh K., 2016, TRANSPARENT OFFLOADI
   Hsueh F.-K., 2017, INT EL DEVICES MEET
   Hwu W-m., 2016, HETEROGENEOUS SYSTEM
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Khodabandehloo G, 2012, IEEE T VLSI SYST, V20, P750, DOI 10.1109/TVLSI.2011.2109404
   Khoram S, 2017, ISPD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P43, DOI 10.1145/3036669.3038242
   Kogge PM, WORKSH MIX LOG DRAM
   Kogge PM, INN ARCH FUT GEN HIG, P35
   Krommydas K, 2016, J SIGNAL PROCESS SYS, V85, P373, DOI 10.1007/s11265-015-1051-z
   Leibin Ni, 2017, ACM Journal on Emerging Technologies in Computing Systems, V13, DOI 10.1145/2996192
   McMenamin Adrian, 2013, END DENNARD SCALING
   Mei B., 2003, LECT NOTES COMPUTER, V2778
   Milojicic Dejan, 2016, Computer, V49, P43, DOI 10.1109/MC.2016.19
   Milojicic DS, 2000, ACM COMPUT SURV, V32, P241, DOI 10.1145/367701.367728
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Moghaddam H. A., 2016, INT S MICROARCHITECT, P1
   Moore GE, 2006, UNDERSTANDING MOORES, P67
   Morad A, 2016, ACM T ARCHIT CODE OP, V12, DOI 10.1145/2845084
   Patterson D, 1997, IEEE MICRO, V17, P34, DOI 10.1109/40.592312
   Patterson D. A., 2013, COMPUTER ORG DESIGN
   Pell O., 2013, MAXIMUM PERFORMANCE, P747
   Picorel J, 2017, INT CONFER PARA, P303, DOI 10.1109/PACT.2017.56
   Schaller B., 1996, ORIGIN NATURE IMPLIC
   SCHERSON ID, 1989, J PARALLEL DISTR COM, V6, P69, DOI 10.1016/0743-7315(89)90043-9
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Singh H., 2000, IEEE T COMPUTERS, V49
   Skarlatos D, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P302, DOI 10.1145/3123939.3124540
   The OpenSPL Consortium, 2013, TECHNICAL REPORT
   Torrellas J., 2012, COMP DES ICCD 2012 I, P3
   Trancoso P., 2015, ACM INT C COMP FRONT
   vonNeumann J., 1945, REPORT EDVAC
   Watson Robert N. M., 2015, P 36 IEEE S SEC PRIV
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Yang SS, 2015, ATMOS POLLUT RES, V6, P52, DOI 10.5094/APR.2015.007
   Yavits L, 2015, IEEE COMPUT ARCHIT L, V14, P148, DOI 10.1109/LCA.2014.2374597
   Yavits L, 2015, IEEE T COMPUT, V64, P368, DOI 10.1109/TC.2013.220
   Yu JY, 2017, AEBMR ADV ECON, V48, P71
   Zha Y, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967069
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang J, 2016, 2016 3RD INTERNATIONAL CONFERENCE ON ADVANCED EDUCATION AND TECHNOLOGY AND MANAGEMENT SCIENCE (AETMS 2016), P1, DOI 10.1109/ICSSSM.2016.7538472
NR 70
TC 10
Z9 10
U1 1
U2 4
PY 2018
BP 1300
EP 1309
DI 10.1109/ICDCS.2018.00130
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Majernik, N
   Andonian, G
   Lynn, W
   Kim, S
   Lorch, C
   Roussel, R
   Doran, S
   Wisniewski, E
   Whiteford, C
   Piot, P
   Power, J
   Rosenzweig, JB
AF Majernik, N.
   Andonian, G.
   Lynn, W.
   Kim, S.
   Lorch, C.
   Roussel, R.
   Doran, S.
   Wisniewski, E.
   Whiteford, C.
   Piot, P.
   Power, J.
   Rosenzweig, J. B.
TI Beam shaping using an ultrahigh vacuum multileaf collimator and
   emittance exchange beamline
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB We report the development of a multileaf collimator (MLC) for charged particle beams, based on independently actuated tungsten strips that can selectively scatter unwanted particles. The MLC is used in conjunction with an emittance exchange beamline to rapidly generate highly variable longitudinal bunch profiles. The developed MLC consists of 40 independent leaves that are 2 mm wide and can move up to 10 mm and operates in an ultrahigh vacuum environment, enabled by novel features such as magnetically coupled actuation. An experiment at the Argonne Wakefield Accelerator, which previously used inflexible, laser-cut masks for beam shaping before an emittance exchange beamline, was conducted to test functionality. The experiment demonstrated myriad transverse mask silhouettes, as measured on a scintillator downstream of the MLC, and the corresponding longitudinal profiles after emittance exchange, as measured using a transverse-deflecting cavity. Rapidly changing between mask shapes enables expeditious execution of various experiments without the downtime associated with traditional methods. The many degrees of freedom of the MLC can enable the optimization of experimental figures of merit using feed-forward control and advanced machine learning methods.
C1 [Majernik, N.; Andonian, G.; Lynn, W.; Lorch, C.; Rosenzweig, J. B.] Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
   [Kim, S.; Doran, S.; Wisniewski, E.; Whiteford, C.; Piot, P.; Power, J.] Argonne Natl Lab, Lemont, IL 60439 USA.
   [Roussel, R.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
   [Piot, P.] Northern Illinois Univ, De Kalb, IL 60115 USA.
RP Majernik, N (corresponding author), Univ Calif Los Angeles, Los Angeles, CA 90095 USA.
EM NMajernik@g.ucla.edu
CR Adelmann A., 2009, P 23 PARTICLE ACCELE
   Andonian G, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.054802
   Andonian G, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3592579
   Antipov S, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.134802
   Bane K. L., 1985, SLACPUB3662
   Barber S. K., 2015, THESIS U CALIFORNIA
   BOYER AL, 1992, MED PHYS, V19, P1255, DOI 10.1118/1.596757
   Chiadroni E, 2017, NUCL INSTRUM METH A, V865, P139, DOI 10.1016/j.nima.2017.01.017
   Ding Y, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.100703
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Emma P, 2006, PHYS REV SPEC TOP-AC, V9, DOI 10.1103/PhysRevSTAB.9.100702
   England RJ, 2008, PHYS REV LETT, V100, DOI 10.1103/PhysRevLett.100.214802
   Ferrari E, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.080701
   Gao Q, 2018, PHYS REV LETT, V120, DOI 10.1103/PhysRevLett.120.114801
   Ge YY, 2014, MED PHYS, V41, DOI 10.1118/1.4873682
   Ha G, 2022, REV MOD PHYS, V94, DOI 10.1103/RevModPhys.94.025006
   Ha G, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.104801
   Ha G, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.121301
   JORDAN TJ, 1994, PHYS MED BIOL, V39, P231, DOI 10.1088/0031-9155/39/2/002
   Lemery F, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.081301
   Loisch G, 2018, NUCL INSTRUM METH A, V909, P107, DOI 10.1016/j.nima.2018.02.043
   Loisch G, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.064801
   Majernik N, 2021, Arxiv, DOI arXiv:2107.00125
   Mitchell C, 2013, PHYS REV SPEC TOP-AC, V16, DOI 10.1103/PhysRevSTAB.16.060703
   Muggli P, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.054801
   Piot P, 2012, PHYS REV LETT, V108, DOI 10.1103/PhysRevLett.108.034801
   Rosenzweig JB, 2010, AIP CONF PROC, V1299, P500, DOI 10.1063/1.3520373
   Roussel R, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.044802
   Scheinker A, 2022, IEEE T CONTR SYST T, V30, P2261, DOI 10.1109/TCST.2021.3136133
   Sudar N, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.051301
   Sun YE, 2010, PHYS REV LETT, V105, DOI 10.1103/PhysRevLett.105.234801
   Sun Y.-E, 2007, 2007 IEEE Particle Accelerator Conference, P3441, DOI 10.1109/PAC.2007.4440452
   Xiang D, 2011, PHYS REV SPEC TOP-AC, V14, DOI 10.1103/PhysRevSTAB.14.114001
   Yakimenko V, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101301
NR 34
TC 0
Z9 0
U1 2
U2 3
PD FEB 22
PY 2023
VL 26
IS 2
AR 022801
DI 10.1103/PhysRevAccelBeams.26.022801
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Krulis, M
   Kratochvíl, M
AF Krulis, Martin
   Kratochvil, Miroslav
GP ACM
TI Detailed Analysis and Optimization of CUDA K-means Algorithm
SO PROCEEDINGS OF THE 49TH INTERNATIONAL CONFERENCE ON PARALLEL PROCESSING,
   ICPP 2020
SE Proceedings of the International Conference on Parallel Processing
DT Proceedings Paper
CT 49th International Conference on Parallel Processing (ICPP)
CY AUG 17-20, 2020
CL Edmonton, CANADA
DE k-means; clustering; cuda; performance optimization
ID MEANS CLUSTERING-ALGORITHM
AB K-means is one of the most frequently used algorithms for unsupervised clustering data analysis. Individual steps of the k-means algorithm include nearest neighbor finding, efficient distance computation, and cluster-wise reduction, which may be generalized to many other purposes in data analysis, visualization, and machine learning. Efficiency of the available implementations of k-means computation steps therefore directly affect many other applications. In this work, we examine the performance limits in the context of modern massively parallel GPU accelerators. Despite the existence of many published papers on this topic, we have found that crucial performance aspects of the GPU implementations remain unaddressed, including the optimizations for memory bandwidth, cache limits, and workload dispatching on problem instances of varying cluster count, dataset size, and dimensionality. We present a detailed analysis of individual computation steps and propose several optimizations that improve the overall performance on contemporary GPU architectures. Our open-source prototype exhibits significant speedup over the current state-of-the-art implementations in virtually all practical scenarios.
C1 [Krulis, Martin; Kratochvil, Miroslav] Charles Univ Prague, Dept Software Engn, Fac Math & Phys, Prague, Czech Republic.
RP Krulis, M (corresponding author), Charles Univ Prague, Dept Software Engn, Fac Math & Phys, Prague, Czech Republic.
EM krulis@ksi.mff.cuni.cz; kratochvil@ksi.mff.cuni.cz
CR Aghaeepour N, 2011, CYTOM PART A, V79A, P6, DOI 10.1002/cyto.a.21007
   Arthur D, 2007, PROCEEDINGS OF THE EIGHTEENTH ANNUAL ACM-SIAM SYMPOSIUM ON DISCRETE ALGORITHMS, P1027
   Chiranjeevi K, 2018, IMAGE ANAL STEREOL, V37, P35, DOI 10.5566/ias.1611
   Cuomo S, 2019, COMPUT ELECTR ENG, V75, P262, DOI 10.1016/j.compeleceng.2017.12.002
   Dafonte C, 2018, SENSORS-BASEL, V18, DOI 10.3390/s18051419
   Dhanachandra N, 2015, PROCEDIA COMPUT SCI, V54, P764, DOI 10.1016/j.procs.2015.06.090
   Ding YF, 2015, PR MACH LEARN RES, V37, P579
   Farivar Reza, 2008, Proceedings of the 2008 International Conference on Parallel and Distributed Processing Techniques and Applications. (PDPTA 2008), P340
   Jain AK., 1988, ALGORITHMS CLUSTERIN
   Kaufman L., 2009, FINDING GROUPS DATA, V344
   Kohonen T, 1996, P IEEE, V84, P1358, DOI 10.1109/5.537105
   Kratochvíl M, 2020, LECT NOTES COMPUT SC, V11962, P790, DOI 10.1007/978-3-030-37734-2_71
   Krulis M, 2017, MULTIMED TOOLS APPL, V76, P11859, DOI 10.1007/s11042-016-3677-7
   Krulis M, 2016, MULTIMED TOOLS APPL, V75, P8071, DOI 10.1007/s11042-015-2726-y
   Li SR, 2015, LECT NOTES COMPUT SC, V9371, P259, DOI 10.1007/978-3-319-25087-8_25
   Li Y, 2013, J COMPUT SYST SCI, V79, P216, DOI 10.1016/j.jcss.2012.05.004
   Lutz Clemens, 2018, Datenbank-Spektrum, V18, P157, DOI 10.1007/s13222-018-0293-x
   Mahajan M, 2012, THEOR COMPUT SCI, V442, P13, DOI 10.1016/j.tcs.2010.05.034
   Nelson J, 2019, PROCEEDINGS OF THE TENTH INTERNATIONAL WORKSHOP ON PROGRAMMING MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM 2019), P11, DOI 10.1145/3303084.3309488
   Ng HP, 2006, 7TH IEEE SOUTHWEST SYMPOSIUM ON IMAGE ANALYSIS AND INTERPRETATION, P61
   Park HS, 2009, EXPERT SYST APPL, V36, P3336, DOI 10.1016/j.eswa.2008.01.039
   Redmond SJ, 2007, PATTERN RECOGN LETT, V28, P965, DOI 10.1016/j.patrec.2007.01.001
   Shalom SAA, 2008, LECT NOTES COMPUT SC, V5182, P166, DOI 10.1007/978-3-540-85836-2_16
   Van Gassen S, 2015, CYTOM PART A, V87A, P636, DOI 10.1002/cyto.a.22625
   Zheng X, 2018, EURASIP J IMAGE VIDE, DOI 10.1186/s13640-018-0309-3
NR 25
TC 3
Z9 3
U1 0
U2 0
PY 2020
AR 69
DI 10.1145/3404397.3404426
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Rakka, M
   Fouda, ME
   Kanj, R
   Kurdahi, F
AF Rakka, Mariam
   Fouda, Mohammed E.
   Kanj, Rouwaida
   Kurdahi, Fadi
TI DT2CAM: A Decision Tree to Content Addressable Memory Framework
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Ternary content addressable memory; decision tree; machine learning;
   hardware compiler; synthesizer
AB Decision trees are powerful tools for data classification. Accelerating the decision tree search is crucial for on-theedge applications with limited power and latency budget. In this article, we propose a content-addressable memory compiler for decision tree inference acceleration. We propose a novel '' adaptiveprecision '' scheme that results in a compact implementation and enables an efficient bijective mapping to ternary content addressable memories while maintaining high inference accuracies. We also develop a resistive-based functional synthesizer to map the decision tree to resistive content addressable memory arrays and perform functional simulations for energy, latency, and accuracy evaluations. We study the decision tree accuracy under hardware non-idealities including device defects, manufacturing variability, and input encoding noise. We test our framework on various decision tree datasets including Give Me Some Credit, Titanic, and COVID-19. Our results reveal up to 42.4% energy savings and up to 17.8x better energy-delay-area product compared to the state-ofart hardware accelerators, and up to 333 million decisions per sec for the pipelined implementation.
C1 [Rakka, Mariam; Fouda, Mohammed E.; Kurdahi, Fadi] Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.
   [Fouda, Mohammed E.] Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza 3247010, Egypt.
   [Kanj, Rouwaida] Amer Univ Beirut, ECE Dept, Beirut 11072020, Lebanon.
RP Fouda, ME (corresponding author), Univ Calif Irvine, Ctr Embedded & Cyber Phys Syst, Irvine, CA 92697 USA.; Fouda, ME (corresponding author), Nile Univ, Nanoelect Integrated Syst Ctr NISC, Giza 3247010, Egypt.
EM mrakka@uci.edu; foudam@uci.edu; rk105@aub.edu.lb; kurdahi@uci.edu
CR [Anonymous], TIT PROB
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Bussmann N, 2021, COMPUT ECON, V57, P203, DOI 10.1007/s10614-020-10042-0
   Chen TW, 2012, IEEE T VLSI SYST, V20, P2329, DOI 10.1109/TVLSI.2011.2170203
   Chiu PF, 2016, IEEE ASIAN SOLID STA, P181, DOI 10.1109/ASSCC.2016.7844165
   Dheeru D., 2017, UCI MACHINE LEARNING
   Fouda M. E., 2022, IN MEMORY ASSOCIATIV
   Kaggle, ABOUT US
   Kak S, 2016, CIRC SYST SIGNAL PR, V35, P1419, DOI 10.1007/s00034-015-0120-7
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P2126, DOI 10.1109/JSSC.2018.2822703
   Lee KJ, 2015, IEEE J SOLID-ST CIRC, V50, P1059, DOI 10.1109/JSSC.2014.2380790
   Lundberg SM, 2020, NAT MACH INTELL, V2, P56, DOI 10.1038/s42256-019-0138-9
   Pedretti G, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-25873-0
   Rakka M, 2021, IEEE T CIRCUITS-II, V68, P762, DOI 10.1109/TCSII.2020.3017477
   Rakka M., 2022, THESIS U CALIFORNIA
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Van Essen B, 2012, ANN IEEE SYM FIELD P, P232, DOI 10.1109/FCCM.2012.47
   Xu B, 2020, SCI DATA, V7, DOI 10.1038/s41597-020-0448-0
   Yeo I, 2019, IEEE T ELECTRON DEV, V66, P2937, DOI 10.1109/TED.2019.2914460
NR 20
TC 0
Z9 0
U1 0
U2 0
PD JUL-SEP
PY 2023
VL 11
IS 3
BP 805
EP 810
DI 10.1109/TETC.2023.3261748
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT J
AU Wang, GQ
   Zhang, PF
   Wang, DX
   Chen, HM
   Li, TR
AF Wang, Guoqiang
   Zhang, Pengfei
   Wang, Dexian
   Chen, Hongmei
   Li, Tianrui
TI Fast attribute reduction via inconsistent equivalence classes for
   large-scale data
SO INTERNATIONAL JOURNAL OF APPROXIMATE REASONING
DT Article
DE Rough set; Attribute reduction; Granular computing; Hash table; Big data
ID DEPENDENCY CALCULATION TECHNIQUE; ROUGH SET; FEATURE-SELECTION;
   INDISCERNIBILITY; UNCERTAINTY; ACCELERATOR; ALGORITHMS; ENTROPY
AB Feature selection, also known as attribute reduction, plays a crucial role in machine learning and data mining tasks. Rough set theory-based feature selection methods have gained popularity due to their ability to handle imprecise and inconsistent data, ease of implementation, and generation of highly interpretable results. However, these methods still suffer from high computational cost when dealing with large-scale datasets with high dimensions. To overcome this shortcoming, we propose a fast attribute reduction method based on inconsistent equivalence classes. The presented method can accelerate those attribute reduction algorithms whose importance measures used can be computed using only inconsistent equivalence classes. Our proposed method improves attribute reduction efficiency through three key aspects: 1) transforming the original dataset into an equivalently simplified version with fewer samples, 2) accelerating the computation of core attributes, and 3) expediting the forward selection process by removing redundant objects and attributes. Experimental results demonstrate the high computational efficiency of our proposed method.
C1 [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Inst Artificial Intelligence, Chengdu 611756, Peoples R China.
   [Wang, Guoqiang; Chen, Hongmei; Li, Tianrui] Southwest Jiaotong Univ, Natl Engn Lab Integrated Transportat Big Data Appl, Chengdu 611756, Peoples R China.
   [Zhang, Pengfei] Chengdu Univ Tradit Chinese Med, Sch Intelligent Med, Chengdu 611137, Peoples R China.
RP Li, TR (corresponding author), Southwest Jiaotong Univ, Sch Comp & Artificial Intelligence, Chengdu 611756, Peoples R China.
EM gqwang18@163.com; feifeihappy55@163.com; gqwang18@163.com;
   hmchen@swjtu.edu.cn; trli@swjtu.edu.cn
CR An S, 2021, INT J APPROX REASON, V139, P130, DOI 10.1016/j.ijar.2021.09.014
   Chen DG, 2012, IEEE T KNOWL DATA EN, V24, P2080, DOI 10.1109/TKDE.2011.89
   Chen Z, 2022, INT J APPROX REASON, V140, P75, DOI 10.1016/j.ijar.2021.09.016
   Dai JH, 2023, INFORM FUSION, V100, DOI 10.1016/j.inffus.2023.101951
   Dash M, 2003, ARTIF INTELL, V151, P155, DOI 10.1016/S0004-3702(03)00079-1
   Deng TQ, 2022, INT J APPROX REASON, V151, P251, DOI 10.1016/j.ijar.2022.09.012
   Fan J, 2017, INFORM SCIENCES, V397, P15, DOI 10.1016/j.ins.2017.02.032
   FAYYAD UM, 1993, IJCAI-93, VOLS 1 AND 2, P1022
   Ge H, 2017, INT J APPROX REASON, V82, P56, DOI 10.1016/j.ijar.2016.11.016
   Hu QH, 2007, LECT NOTES COMPUT SC, V4426, P96
   Hu QH, 2010, IEEE T SYST MAN CY B, V40, P137, DOI 10.1109/TSMCB.2009.2024166
   HU XH, 1995, COMPUT INTELL-US, V11, P323, DOI 10.1111/j.1467-8640.1995.tb00035.x
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Lei L, 2018, APPL SOFT COMPUT, V62, P923, DOI 10.1016/j.asoc.2017.09.029
   Leung Y, 2006, EUR J OPER RES, V168, P164, DOI 10.1016/j.ejor.2004.03.032
   Li Y, 2023, INT J APPROX REASON, V160, DOI 10.1016/j.ijar.2023.108974
   Liang JY, 2014, IEEE T KNOWL DATA EN, V26, P294, DOI 10.1109/TKDE.2012.146
   Liang JY, 2013, KNOWL-BASED SYST, V44, P90, DOI 10.1016/j.knosys.2013.01.027
   Liang JY, 2002, INT J GEN SYST, V31, P331, DOI 10.1080/0308107021000013635
   Liu KY, 2022, INT J APPROX REASON, V148, P57, DOI 10.1016/j.ijar.2022.05.011
   Liu Y, 2020, INT J APPROX REASON, V118, P1, DOI 10.1016/j.ijar.2019.11.010
   Luo C, 2023, EXPERT SYST APPL, V211, DOI 10.1016/j.eswa.2022.118554
   Mao H, 2023, EXPERT SYST APPL, V234, DOI 10.1016/j.eswa.2023.121062
   Meng ZQ, 2016, INFORM SCIENCES, V330, P226, DOI 10.1016/j.ins.2015.09.057
   Thuy NN, 2020, PATTERN RECOGN, V97, DOI 10.1016/j.patcog.2019.106999
   Thuy NN, 2019, EXPERT SYST APPL, V137, P308, DOI 10.1016/j.eswa.2019.06.071
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Qian J, 2011, INT J APPROX REASON, V52, P212, DOI 10.1016/j.ijar.2010.07.011
   Qian J, 2015, KNOWL-BASED SYST, V73, P18, DOI 10.1016/j.knosys.2014.09.001
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2018, INT J APPROX REASON, V97, P38, DOI 10.1016/j.ijar.2018.01.008
   Qian YH, 2015, FUZZY SET SYST, V258, P61, DOI 10.1016/j.fss.2014.04.029
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Raza MS, 2018, PATTERN RECOGN, V81, P309, DOI 10.1016/j.patcog.2018.04.009
   Raza MS, 2018, INT J APPROX REASON, V92, P175, DOI 10.1016/j.ijar.2017.10.012
   Raza MS, 2016, INFORM SCIENCES, V343, P41, DOI 10.1016/j.ins.2016.01.044
   Sang BB, 2022, IEEE T FUZZY SYST, V30, P1683, DOI 10.1109/TFUZZ.2021.3064686
   Skowron A., 1992, DISCERNIBILITY MATRI, V11, P331, DOI [10.1007/978-94-015-7975-9_21, DOI 10.1007/978-94-015-7975-9_21]
   Slezak D, 2002, FUND INFORM, V53, P365
   Sowkuntla P, 2021, KNOWL-BASED SYST, V213, DOI 10.1016/j.knosys.2020.106677
   Stanczyk U, 2020, INT J APPROX REASON, V125, P187, DOI 10.1016/j.ijar.2020.07.005
   Stepaniuk J, 2023, INT J APPROX REASON, V155, P1, DOI 10.1016/j.ijar.2023.01.003
   Teng SH, 2016, INFORM SCIENCES, V326, P297, DOI 10.1016/j.ins.2015.07.052
   Wang DX, 2023, INFORM FUSION, V99, DOI 10.1016/j.inffus.2023.101884
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GQ, 2021, INFORM SCIENCES, V571, P475, DOI 10.1016/j.ins.2021.05.007
   Wei W, 2015, KNOWL-BASED SYST, V86, P261, DOI 10.1016/j.knosys.2015.06.013
   Xiao JY, 2022, INT J APPROX REASON, V148, P117, DOI 10.1016/j.ijar.2022.05.012
   Yao JT, 2022, INT J APPROX REASON, V140, P1, DOI 10.1016/j.ijar.2021.09.011
   Yao YY, 2022, INT J APPROX REASON, V142, P231, DOI 10.1016/j.ijar.2021.11.012
   Yao YY, 2009, INFORM SCIENCES, V179, P867, DOI 10.1016/j.ins.2008.11.020
   Yu B, 2023, INT J APPROX REASON, V157, P88, DOI 10.1016/j.ijar.2023.03.002
   Zhang D, 2022, INT J APPROX REASON, V150, P98, DOI 10.1016/j.ijar.2022.08.005
   Zhang HY, 2023, INT J APPROX REASON, V154, P200, DOI 10.1016/j.ijar.2022.12.010
   Zhang PF, 2023, IEEE T FUZZY SYST, V31, P2975, DOI 10.1109/TFUZZ.2023.3238803
   Zhang PF, 2022, IEEE T NEUR NET LEAR, DOI 10.1109/TNNLS.2022.3193929
   Zhang PF, 2022, INT J APPROX REASON, V140, P7, DOI 10.1016/j.ijar.2021.09.017
   Zhao J, 2020, INFORM SCIENCES, V536, P431, DOI 10.1016/j.ins.2020.03.092
   Zhao J, 2020, PATTERN RECOGN, V107, DOI 10.1016/j.patcog.2020.107517
NR 59
TC 0
Z9 0
U1 0
U2 0
PD DEC
PY 2023
VL 163
AR 109039
DI 10.1016/j.ijar.2023.109039
EA OCT 2023
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT J
AU Mannocci, P
   Pedretti, G
   Giannone, E
   Melacarne, E
   Sun, Z
   Ielmini, D
AF Mannocci, Piergiulio
   Pedretti, Giacomo
   Giannone, Elisabetta
   Melacarne, Enrico
   Sun, Zhong
   Ielmini, Daniele
TI A Universal, Analog, In-Memory Computing Primitive for Linear Algebra
   Using Memristors
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Linear systems; Integrated circuit modeling; Linear regression;
   Mathematical models; Covariance matrices; Bandwidth; SPICE; In-memory
   computing; resistive memory; hardware accelerator; linear regression;
   linear systems
ID LEAST-SQUARES ESTIMATE
AB The increasing demand for data-intensive computing applications, such as artificial intelligence (AI) and more specifically machine learning (ML), raises the need for novel computing hardware architectures capable of massive parallelism in performing core algebraic operations. Among the new paradigms, in-memory computing (IMC) with analogue devices is attracting significant interest for its large-scale integration potential, together with unrivaled speed and energy performance. Here, we present a fully-analogue, universal primitive capable of executing linear algebra operations such as regression, generalized least-square minimization and linear system solution with and without preconditioning. We study the impact of the main circuit parameters on accuracy and bandwidth with analytical closed-form expressions and SPICE simulations. Scaling challenges due to parasitic resistance/capacitance and their impact on key parameters such as bandwidth and accuracy are discussed. Finally, a comparison with existing solvers belonging to the same IMC framework is made to assess advantages and disadvantages of the proposed circuit.
C1 [Mannocci, Piergiulio; Giannone, Elisabetta; Melacarne, Enrico; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
   [Pedretti, Giacomo] Hewlett Packard Labs, Milpitas, CA 95035 USA.
   [Sun, Zhong] Peking Univ PKU, Sch Integrated Circuits, Inst Artificial Intelligence, Beijing 100871, Peoples R China.
RP Mannocci, P; Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
EM piergiulio.mannocci@polimi.it; daniele.ielmini@polimi.it
CR [Anonymous], 2013, INT TECHNOLOGY ROADM
   [Anonymous], 2012, MATRIX ANAL, DOI DOI 10.1017/CBO9781139020411
   [Anonymous], 1989, ANALOG VLSI NEURAL S
   Barthelemy H, 1997, ELECTRON LETT, V33, P1662, DOI 10.1049/el:19971170
   BUNCH JR, 1980, LINEAR ALGEBRA APPL, V34, P341, DOI 10.1016/0024-3795(80)90172-X
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Fouda ME, 2018, IEEE T CIRCUITS-I, V65, P270, DOI 10.1109/TCSI.2017.2714101
   Golub GH, 2000, J COMPUT APPL MATH, V123, P35, DOI 10.1016/S0377-0427(00)00413-1
   Golub GH, 1998, SIAM J SCI COMPUT, V19, P530, DOI 10.1137/S106482759529382X
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Ielmini D, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.202000040
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   LOVELL MC, 1963, J AM STAT ASSOC, V58, P993, DOI 10.2307/2283327
   Luo YCA, 2019, INT WORKSH QUAL SERV, DOI 10.1145/3326285.3329062
   Min DB, 2014, IEEE T IMAGE PROCESS, V23, P5638, DOI 10.1109/TIP.2014.2366600
   MUCHA I, 1992, ELECTRON LETT, V28, P2071, DOI 10.1049/el:19921327
   Nocedal J, 2006, SPRINGER SER OPER RE, P1, DOI 10.1007/978-0-387-40065-5
   Parthipan A, 2019, PROCEEDINGS OF THE 2019 3RD INTERNATIONAL CONFERENCE ON COMPUTING METHODOLOGIES AND COMMUNICATION (ICCMC 2019), P702, DOI [10.1109/iccmc.2019.8819641, 10.1109/ICCMC.2019.8819641]
   Pedretti G, 2021, IEEE T ELECTRON DEV, V68, P4379, DOI 10.1109/TED.2021.3095430
   Pedretti G, 2020, IEEE J EXPLOR SOLID-, V6, P89, DOI 10.1109/JXCDC.2020.2992691
   Small J. S., 2013, ANALOGUE ALTERNATIVE, P1930
   Truong SN, 2019, MICROMACHINES-BASEL, V10, DOI 10.3390/mi10100671
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P2945, DOI 10.1109/TED.2020.2992435
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Tisseur F, 2001, SIAM REV, V43, P235, DOI 10.1137/S0036144500381988
   UYENOYAMA MK, 1995, GENETICS, V139, P975
   Wang AL, 2018, INTEGRATION, V62, P246, DOI 10.1016/j.vlsi.2018.03.010
   Williams M. R, 1985, PRENTICE HALL SERIES
   Wu W, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P103, DOI 10.1109/VLSIT.2018.8510690
   Yalavarthy PK, 2007, MED PHYS, V34, P2085, DOI 10.1118/1.2733803
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 39
TC 9
Z9 9
U1 5
U2 15
PD DEC
PY 2021
VL 68
IS 12
BP 4889
EP 4899
DI 10.1109/TCSI.2021.3122278
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Rolandi, PA
AF Rolandi, Pablo A.
BE Munoz, SG
   Laird, CD
   Realff, MJ
TI THE UNREASONABLE EFFECTIVENESS OF EQUATIONS: ADVANCED MODELING FOR
   BIOPHARMACEUTICAL PROCESS DEVELOPMENT
SO PROCEEDINGS OF THE 9TH INTERNATIONAL CONFERENCE ON FOUNDATIONS OF
   COMPUTER-AIDED PROCESS DESIGN
SE Computer Aided Chemical Engineering
DT Proceedings Paper
CT 9th International Conference on the Foundations of Computer Aided
   Process Design (FOCAPD)
CY JUL 14-18, 2019
CL CO
DE Biotechnology; biopharmaceutical product and process development;
   process systems engineering; first principles modeling; computer-aided
   product and process design; community of practice
ID DESIGN; SYSTEMS; CHROMATOGRAPHY; OPTIMIZATION; UNCERTAINTY; STRATEGIES;
   PREDICTION; FRAMEWORK; BEHAVIOR; PRODUCT
AB Advanced modeling based on first principles approaches is an effective methodology for designing biopharmaceutical process and product systems that are reliable, efficient, agile, and differentiated. However, the industrial modeling practice has stagnated despite significant advances in other fields, and the digital accelerators (computing power, storage capacity, and bandwidth) have created a shifting landscape for the foundations of process systems engineering. This article argues for a stronger emphasis on modeling lifecycle frameworks as well as a clear focus on systematic value creation through greater immediate application and sustained utilization of models and advanced modeling methodologies. Convergence between first principles modeling, experimental methods, and machine learning techniques is postulated as the main direction for innovation. Modeling patterns are presented as a novel mechanism to create and reuse effective modeling abstractions. A community-centric approach to collaboration between industry, vendors, and academia is required to deliver these significant innovation needs.
C1 [Rolandi, Pablo A.] Amgen Inc, Proc Dev, Digital Integrat & Predict Technol, Cambridge, MA 02142 USA.
RP Rolandi, PA (corresponding author), Amgen Inc, Proc Dev, Digital Integrat & Predict Technol, Cambridge, MA 02142 USA.
CR [Anonymous], 2011, DAKOTA MULTILEVEL PA
   Au SK, 2001, PROBABILIST ENG MECH, V16, P263, DOI 10.1016/S0266-8920(01)00019-4
   Banerjee S, 2017, J CHROMATOGR A, V1511, P45, DOI 10.1016/j.chroma.2017.06.059
   Basu P, 2013, LEADING PHARM OPERAT, P445
   Betancourt M., 2017, ARXIV170102434STATME
   Bonvin D, 2016, IND ENG CHEM RES, V55, P6891, DOI 10.1021/acs.iecr.5b04801
   CHEN R. T., 2018, ADV NEURAL INFORM PR, P6571
   Cickovski T, 2005, 27 INT C SOFTW ENG
   Close EJ, 2014, CHEM ENG SCI, V116, P284, DOI 10.1016/j.ces.2014.03.010
   Coley CW, 2017, J CHEM INF MODEL, V57, P1757, DOI 10.1021/acs.jcim.6b00601
   Coley CW, 2017, ACS CENTRAL SCI, V3, P434, DOI 10.1021/acscentsci.7b00064
   Cooney B., 2016, BIOPROCESS INT, P28
   Courtois F, 2016, MABS-AUSTIN, V8, P99, DOI 10.1080/19420862.2015.1112477
   Crowell LE, 2018, NAT BIOTECHNOL, V36, P988, DOI 10.1038/nbt.4262
   Diedrich J, 2017, J CHROMATOGR A, V1525, P60, DOI 10.1016/j.chroma.2017.09.039
   DONALDSON JR, 1987, TECHNOMETRICS, V29, P67, DOI 10.2307/1269884
   Estefan J. A, 2008, INCOSE MBSE INITIATI, V25
   European Medicines Agency, 2012, POINTS CONS ICH Q8 Q
   Foss BA, 1998, J PROCESS CONTR, V8, P325, DOI 10.1016/S0959-1524(98)00018-3
   Galleguillos SN, 2017, COMPUT STRUCT BIOTEC, V15, P212, DOI 10.1016/j.csbj.2017.01.005
   Gamma E, 1995, DESIGN PATTERNS ELEM
   García-Muñoz S, 2015, ORG PROCESS RES DEV, V19, P1012, DOI 10.1021/acs.oprd.5b00158
   Gilsing V, 2006, RES POLICY, V35, P1, DOI 10.1016/j.respol.2005.06.007
   Glen KE, 2018, BIOCHEM ENG J, V133, P28, DOI 10.1016/j.bej.2018.01.033
   Goodman J, 2010, COMM APP MATH COM SC, V5, P65, DOI 10.2140/camcos.2010.5.65
   Guyon I., 2018, HAL01906197
   Halevy A., 2009, IEEE INTELLIGENT SYS
   Hariharan P, 2017, PLOS ONE, V12, DOI 10.1371/journal.pone.0178749
   Hase F., 2019, CHEM SCI
   Hefzi H, 2016, CELL SYST, V3, P434, DOI 10.1016/j.cels.2016.10.020
   Hong MS, 2018, COMPUT CHEM ENG, V110, P106, DOI 10.1016/j.compchemeng.2017.12.007
   Johnson FT, 2005, COMPUT FLUIDS, V34, P1115, DOI 10.1016/j.compfluid.2004.06.005
   Klatt KU, 2009, COMPUT CHEM ENG, V33, P536, DOI 10.1016/j.compchemeng.2008.09.002
   KLEIJNEN JPC, 1995, EUR J OPER RES, V82, P145, DOI 10.1016/0377-2217(94)00016-6
   Kreutz C, 2012, BMC SYST BIOL, V6, DOI 10.1186/1752-0509-6-120
   Lee JH, 2018, COMPUT CHEM ENG, V114, P111, DOI 10.1016/j.compchemeng.2017.10.008
   Lee SL, 2015, J PHARM INNOV, V10, P191, DOI 10.1007/s12247-015-9215-8
   LeVeque RJ, 2012, COMPUT SCI ENG, V14, P13, DOI 10.1109/MCSE.2012.38
   Leweke S, 2018, COMPUT CHEM ENG, V113, P274, DOI 10.1016/j.compchemeng.2018.02.025
   Love KR, 2018, CURR OPIN BIOTECH, V53, P50, DOI 10.1016/j.copbio.2017.12.010
   Marzouk YM, 2007, J COMPUT PHYS, V224, P560, DOI 10.1016/j.jcp.2006.10.010
   Miller D.C., 2018, COMPUT AIDED CHEM EN, V44, P2209, DOI DOI 10.1016/B978-0-444-64241-7.50363-3
   Mockus L, 2011, INFORMATICA-LITHUAN, V22, P537
   Morresi T., 2018, ADV THEOR SIMUL, P1
   Muñoz SG, 2016, CHEM ENG RES DES, V109, P532, DOI 10.1016/j.cherd.2016.03.005
   Nagy ZK, 2007, J PROCESS CONTR, V17, P229, DOI 10.1016/j.jprocont.2006.10.008
   Olofsson S, 2018, ARXIV181002561V2SCMS
   Papaioannou V, 2016, FLUID PHASE EQUILIBR, V416, P104, DOI 10.1016/j.fluid.2015.12.041
   Patterson EA, 2017, PROG BIOPHYS MOL BIO, V129, P13, DOI 10.1016/j.pbiomolbio.2016.08.007
   Rios LM, 2013, J GLOBAL OPTIM, V56, P1247, DOI 10.1007/s10898-012-9951-y
   Rodríguez-Gómez G, 2004, Proceedings of the Fourth IASTED International Conference on Modelling, Simulation, and Optimization, P247
   Saltelli A, 2006, RELIAB ENG SYST SAFE, V91, P1109, DOI 10.1016/j.ress.2005.11.014
   Samsatli NJ, 2001, AICHE J, V47, P2277, DOI 10.1002/aic.690471013
   Sculley D, 2015, ADV NEURAL INFORM PR, V28, P1
   Seely J. E, 2012, BIOPROCESS INT
   Sharp Phillip. A., 2011, 3 REVOLUTION CONVERG
   Shen DYE, 2016, AICHE J, V62, P3310, DOI 10.1002/aic.15373
   Shukla AA, 2017, BIOENG TRANSL MED, V2, P58, DOI 10.1002/btm2.10061
   Simulation Interoperability Standards Organization, 2012, GUID GEN METH VER VA, V2
   Smith RL, 2009, J AM STAT ASSOC, V104, P97, DOI 10.1198/jasa.2009.0007
   Stephanopoulos G, 2011, CHEM ENG SCI, V66, P4272, DOI 10.1016/j.ces.2011.05.049
   Storer T. I. M, 2017, BRIDGING CHASM SURVE, V50, P4
   Teeters M, 2011, BIOTECHNOL BIOENG, V108, P1338, DOI 10.1002/bit.23067
   Tinner F., 2016, BLENDED FINANCE BLEN, P1
   Van Norman Gail A, 2016, JACC Basic Transl Sci, V1, P399, DOI 10.1016/j.jacbts.2016.06.003
   Vasileiadis M, 2015, CHEM ENG SCI, V121, P60, DOI 10.1016/j.ces.2014.08.058
   Venkatasubramanian V., 2019, AICHE J, V65, P1
   Villaverde AF, 2015, BMC SYST BIOL, V9, DOI 10.1186/s12918-015-0144-4
   Welch CJ, 2017, ORG PROCESS RES DEV, V21, P414, DOI 10.1021/acs.oprd.6b00427
   WIGNER EP, 1960, COMMUN PUR APPL MATH, V13, P1, DOI 10.1002/cpa.3160130102
   Yu LX, 2008, PHARM RES, V25, P781, DOI 10.1007/s11095-007-9511-1
NR 71
TC 5
Z9 5
U1 0
U2 4
PY 2019
VL 47
BP 137
EP 150
DI 10.1016/B978-0-12-818597-1.50023-0
WC Computer Science, Interdisciplinary Applications; Engineering, Chemical
DA 2023-11-11
ER

PT C
AU Jaswal, MK
   Roy, SK
AF Jaswal, Manpreet Kaur
   Roy, Subir Kumar
GP IEEE
TI DynRP- Non-Intrusive Profiler for Dynamic Reconfigurability
SO 2020 24TH INTERNATIONAL SYMPOSIUM ON VLSI DESIGN AND TEST (VDAT)
SE International Symposium on VLSI Design and Test-VDAT
DT Proceedings Paper
CT 24th International Symposium on VLSI Design and Test (VDAT)
CY JUL 23-25, 2020
CL Bhubaneswar, INDIA
DE Dynamic reconfiguration; FPGA; non-intrusive profiling;
   hardware-software partitioning
AB Emerging technological areas such as machine learning, speech recognition, computer vision, autonomous robots, AI, bioinformatics involving big data, require implementation in complex heterogeneous accelerator platforms, to be able to handle data explosion with higher efficiency, lower power, and better performance. Dynamic reconfiguration in such platforms can help in run-time optimization to meet the design goals. The required optimal platform configuration can be achieved by a flexible design space exploration and appropriate task partitioning obtained through profiling computation and communication of processes in application code. This paper focuses on profiling, it being the key to the success of obtaining optimal platform configurations. It points to existing profiling techniques, their pros and cons vis-a-vis dynamic reconfigurable architectures, and the challenges in their design for obtaining optimal profiling performance. It further outlines desirable specifications for a profiler to allow dynamic real-time profiling for effective use of dynamic reconfiguration. DynRP, a non-intrusive hardware profiler for dynamic reconfiguration is proposed based on the desirable specifications, followed by its design and implementation details.
C1 [Jaswal, Manpreet Kaur; Roy, Subir Kumar] Int Inst Informat Technol Bangalore, Bangalore, Karnataka, India.
RP Jaswal, MK (corresponding author), Int Inst Informat Technol Bangalore, Bangalore, Karnataka, India.
EM manpreet.jaswal@iiitb.org; subir@iiitb.ac.in
CR [Anonymous], 2007, P 4 INT C COMP FRONT
   [Anonymous], POW BENCHM SUIT
   [Anonymous], 2004, PROC ACMSIGDA 12 INT
   [Anonymous], CHSTONE BENCHM SUIT
   Belwal Meena, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7294022
   Compton K, 2002, ACM COMPUT SURV, V34, P171, DOI 10.1145/508352.508353
   Gajski DD, 2009, EMBEDDED SYSTEM DESIGN: MODELING, SYNTHESIS AND VERIFICATION, P1, DOI 10.1007/978-1-4419-0504-8_1
   Gericota MG, 2008, IEEE T VLSI SYST, V16, P1545, DOI 10.1109/TVLSI.2008.2001141
   Kumar N. P., 2016, THESIS
   Mu JQ, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2442116.2442135
   Shannon L, 2004, 2004 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P231, DOI 10.1109/FPT.2004.1393273
   Tessier R, 2015, P IEEE, V103, P332, DOI 10.1109/JPROC.2014.2386883
   Tong J. G., 2007, P 19 INT C MICR DEC, P253
   Wang C., 2017, ARXIV171204771
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/vdat50263.2020.9190415
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Lumpkin, AH
   Thurman-Keup, R
   Edstrom, D
   Prieto, P
   Ruan, J
   Jacobson, B
   Sikora, J
   Diaz-Cruz, J
   Edelen, A
   Zhou, F
AF Lumpkin, A. H.
   Thurman-Keup, R.
   Edstrom, D.
   Prieto, P.
   Ruan, J.
   Jacobson, B.
   Sikora, J.
   Diaz-Cruz, J.
   Edelen, A.
   Zhou, F.
TI Submacropulse electron-beam dynamics correlated with higher-order modes
   in a Tesla-type cryomodule
SO PHYSICAL REVIEW ACCELERATORS AND BEAMS
DT Article
AB Experiments were performed at the Fermilab Accelerator Science and Technology facility to elucidate the effects of long-range wakefields in TESLA-type superconducting rf cavities. In particular, we investigated the higher-order modes (HOMs) generated in the eight, nine-cell cavities of a cryomodule (CM) due to off-axis steering with correctors located -4 m upstream of the CM. We have observed correlated submacropulse centroid slews of a few hundred microns and centroid oscillations at -240 kHz in the rf beam-position-monitor data after the CM. The entrance energy into the CM was 25 MeV, and the exit energy was 100 MeV with 125 pC/bunch and 400 pC/bunch in 50-bunch pulse trains. These experimental results were evaluated for machine learning training aspects which will be used to inform the commissioning plan for the Linac Coherent Light Source-II injector CM. With an entrance beam energy of < 1 MeV in this case (or for -6 MeV at the European X-ray Free-electron Laser injector), the HOM-effect mitigation would be particularly critical.
C1 [Lumpkin, A. H.; Thurman-Keup, R.; Edstrom, D.; Prieto, P.; Ruan, J.] Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
   [Jacobson, B.; Sikora, J.; Diaz-Cruz, J.; Edelen, A.; Zhou, F.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94720 USA.
   [Diaz-Cruz, J.] Univ New Mexico, Albuquerque, NM 87131 USA.
RP Lumpkin, AH (corresponding author), Fermilab Natl Accelerator Lab, POB 500, Batavia, IL 60510 USA.
EM lumpkin@fnal.gov
CR Church M., 2013, TM2568 FERM NAT ACC
   Diaz-Cruz Jorge, 2021, P 12 INT PARTICLE AC
   Eddy N., 2011, P 10 EUR WORKSH BEAM
   Edelen A., ARXIV181103172
   Emma P., 2017, PROCEEDINGSOF 38 INT
   Fartoukh S., 1999, Proceedings of the 1999 Particle Accelerator Conference (Cat. No.99CH36366), P922, DOI 10.1109/PAC.1999.795401
   Frisch J, 2006, AIP CONF PROC, V868, P313
   Hellert T, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.123501
   Hellert Thorsten, 2017, P DESY SEMINAR
   Junhao Wei, 2021, NUCL INSTRUM METHO A, V1000, P165246
   Lumpkin AH, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.054401
   Lumpkin AH, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.064401
   Lumpkin A. H., 2021, P 12 INT PARTICLE AC
   Lumpkin A. H., 2021, P 12 INT PARTICLE AC
   Ruan J., 2013, P IPAC 13 SHANGH CHI, P3061
   Seeman J. T., P 1987 PARTICLE ACCE, P1349
   Sikora J., 2021, P 12 INT PARTICLE AC
   Thurman-Keup R., 2021, P 12 INT PARTICLE AC
   Wanzenberg R., 2001, DESYTESLA200133
   Wanzenberg Rainer, 2009, P SPL HOM WORKSHOP
   Wei JH, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.082804
   Weise H., 2017, P 2017 FREE EL LAS C, P9, DOI 10.18429/JACoW-FEL2017-MOC03
   Zhang P, 2012, REV SCI INSTRUM, V83, DOI 10.1063/1.4748517
   Zhou F., 2017, P INT PARTICLE ACCEL
NR 24
TC 2
Z9 2
U1 0
U2 1
PD JUN 24
PY 2022
VL 25
IS 6
AR 064402
DI 10.1103/PhysRevAccelBeams.25.064402
WC Physics, Nuclear; Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Zhang, KQ
   Zhang, XY
   Zhang, Z
AF Zhang, Kaiqi
   Zhang, Xiyuan
   Zhang, Zheng
GP IEEE
TI Tucker Tensor Decomposition on FPGA
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
ID UNCERTAINTY QUANTIFICATION; SINGULAR-VALUE
AB Tensor computation has emerged as a powerful mathematical tool for solving high-dimensional and/or extreme-scale problems in science and engineering. The last decade has witnessed tremendous advancement of tensor computation and its applications in machine learning and big data. However, its hardware optimization on resource-constrained devices remains an (almost) unexplored field. This paper presents an hardware accelerator for a classical tensor computation framework, Tucker decomposition. We study three modules of this architecture: tensor-times-matrix (TTM), matrix singular value decomposition (SVD), and tensor permutation, and implemented them on Xilinx FPGA for prototyping. In order to further reduce the computing time, a warm-start algorithm for the Jacobi iterations in SVD is proposed. A fixed-point simulator is used to evaluate the performance of our design. Some synthetic data sets and a real MRI data set are used to validate the design and evaluate its performance. We compare our work with state-of-the-art software toolboxes running on both CPU and GPU, and our work shows 2.16-30.2x speedup on the cardiac MRI data set.
C1 [Zhang, Kaiqi; Zhang, Xiyuan; Zhang, Zheng] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
RP Zhang, KQ (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM kzhang70@ucsb.edu; xiyuanzhang@ucsb.edu; zhengzhang@ece.ucsb.edu
CR Ahmedsaid A, 2003, 2003 IEEE INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), PROCEEDINGS, P35, DOI 10.1109/FPT.2003.1275729
   Amira A., 2001, Field Programmable Logic and Applications. 11th International Conference, FPL 2001. Proceedings (Lecture Notes in Computer Science Vol.2147), P101
   [Anonymous], 2005, PROC ACM SIGDA 13 IN
   Bader B.W., 2015, MATLAB TENSOR TOOLBO
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   BRENT RP, 1985, SIAM J SCI STAT COMP, V6, P69, DOI 10.1137/0906007
   Chien JT, 2018, IEEE T NEUR NET LEAR, V29, P1998, DOI 10.1109/TNNLS.2017.2690379
   De Lathauwer L, 2000, SIAM J MATRIX ANAL A, V21, P1324, DOI 10.1137/S0895479898346995
   DEMMEL J, 1992, SIAM J MATRIX ANAL A, V13, P1204, DOI 10.1137/0613074
   Ding HS, 2017, PROC INT CONF DOC, P507, DOI 10.1109/ICDAR.2017.89
   HANSEN ER, 1963, J SOC IND APPL MATH, V11, P448, DOI 10.1137/0111032
   Hawkins C., 2019, ARXIV190510478
   HEMKUMAR ND, 1992, 1992 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOLS 1-6, P1061, DOI 10.1109/ISCAS.1992.230297
   Hitchcock F. L., 1927, J MATH PHYS, V6, P164, DOI [10.1002/sapm192761164, DOI 10.1002/SAPM192761164]
   Irick KM, 2008, ANN IEEE SYM FIELD P, P304, DOI 10.1109/FCCM.2008.40
   Jing Li, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166928
   KAPTEYN A, 1986, PSYCHOMETRIKA, V51, P269, DOI 10.1007/BF02293984
   Kaya O, 2016, PROC INT CONF PARAL, P103, DOI 10.1109/ICPP.2016.19
   Kim YD, 2015, ARXIV151106530
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Kolda TG, 2008, IEEE DATA MINING, P363, DOI 10.1109/ICDM.2008.89
   Kossaifi Jean, 2018, CORR
   KROONENBERG PM, 1980, PSYCHOMETRIKA, V45, P69, DOI 10.1007/BF02293599
   Lebedev V., 2014, ARXIV14126553
   Li J, 2011, INT J MACH LEARN CYB, V2, P89, DOI 10.1007/s13042-011-0017-0
   Lingala SG, 2011, IEEE T MED IMAGING, V30, P1042, DOI 10.1109/TMI.2010.2100850
   Novikov A., 2015, ADV NEURAL INFORM PR, P442, DOI DOI 10.5555/2969239.2969289
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Rahmati M, 2008, IEEE INT CONF ASAP, P185, DOI 10.1109/ASAP.2008.4580176
   Roohi SF, 2016, IEEE IMAGE PROC, P1769, DOI 10.1109/ICIP.2016.7532662
   Saito D., 2011, P INT C SPEECH COMM
   Sidiropoulos ND, 2017, IEEE T SIGNAL PROCES, V65, P3551, DOI 10.1109/TSP.2017.2690524
   Smith S, 2017, INT PARALL DISTRIB P, P1058, DOI 10.1109/IPDPS.2017.84
   Stanislaus J. L. V. M., 2013, 2013 International Conference on Computing, Networking and Communications (ICNC 2013), P671, DOI 10.1109/ICCNC.2013.6504167
   Tucker L. R., 1963, PROBLEMS MEASURING C, V15, P3
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Vasilescu MAO, 2002, INT C PATT RECOG, P511, DOI 10.1109/ICPR.2002.1048350
   Volder J. E., 1959, IRE T ELECT COMPUT, VEC-8, P330, DOI [10.1109/TEC.1959.5222693, DOI 10.1109/TEC.1959.5222693]
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Yang YC, 2017, PR MACH LEARN RES, V70
   Zhang Z, 2017, IEEE T COMP PACK MAN, V7, P687, DOI 10.1109/TCPMT.2016.2628703
   Zhang Z, 2015, IEEE T COMPUT AID D, V34, P63, DOI 10.1109/TCAD.2014.2369505
   Zhu JH, 2003, LECT NOTES COMPUT SC, V2778, P1062
NR 43
TC 70
Z9 70
U1 0
U2 0
PY 2019
DI 10.1109/iccad45719.2019.8942103
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Deng, CH
   Yin, M
   Liu, XY
   Wang, XD
   Yuan, B
AF Deng, Chunhua
   Yin, Miao
   Liu, Xiao-Yang
   Wang, Xiaodong
   Yuan, Bo
GP IEEE
TI High-performance Hardware Architecture for Tensor Singular Value
   Decomposition
SO 2019 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 38th IEEE/ACM International Conference on Computer-Aided Design (ICCAD)
CY NOV 04-10, 2019
CL Westminster, CO
DE Tensor decomposition; t-SVD; hardware architecture
AB Tensor provides a brief and natural representation for large-scale multidimensional data by way of appropriate low-rank approximations, thus we can discover significant latent structures of complex data and generalize data representation. To date, tensor has gained tremendous success in various science and technology fields, especially in machine learning and big data applications. However, tensor computation, especially tensor decomposition, is usually expensive due to the inherent large-size characteristic of tensors, and hence would potentially hinder their future wide deployment. In this paper, we develop a hardware architecture to accelerate tensor singular value decomposition (t-SVD), which is a new tensor decomposition technique that has been successfully applied to high-dimensional data classification and video recovery. Specifically, design consideration of each key computing unit is analyzed and discussed. Then, the proposed t-SVD hardware architecture is implemented and synthesized using CMOS 28nm technology. Comparison with real-world CPU-based implementations shows that the proposed hardware accelerator is expected to provide average 14x speedup on various t-SVD workloads.
C1 [Deng, Chunhua; Yin, Miao; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08901 USA.
   [Liu, Xiao-Yang; Wang, Xiaodong] Columbia Univ, Dept Elect Engn, New York, NY 10027 USA.
RP Deng, CH (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, New Brunswick, NJ 08901 USA.
EM chunhua.deng@rutgers.edu; miao.yin@rutgers.edu; xl2427@columbia.edu;
   xw2008@columbia.edu; bo.yuan@soe.rutgers.edu
CR Brent R. P., 1982, TECH REP
   CARROLL JD, 1970, PSYCHOMETRIKA, V35
   Cavallaro J. R., 1988, J PARALLEL DISTRIBUT, V5
   Dongarra J, 2018, SIAM REV, V60, P808, DOI 10.1137/17M1117732
   HARSHMAN R. A., 1970, UCLA WORKING PAPERS, V16, P1, DOI DOI 10.1134/S0036023613040165
   Hu Y., 2015, P 23 ACM INT C MULT
   Jia C., 2016, IEEE T IMAGE PROCESS, V25
   Jiang F, 2018, AAAI CONF ARTIF INTE, P3326
   Kilmer M. E., 2011, LINEAR ALGEBRA ITS A, V435
   Kilmer ME, 2013, SIAM J MATRIX ANAL A, V34, P148, DOI 10.1137/110837711
   Kim YD, 2015, ARXIV151106530
   Koniusz P, 2016, LECT NOTES COMPUT SC, V9908, P37, DOI 10.1007/978-3-319-46493-0_3
   Lebedev V., 2014, ARXIV14126553
   Li S., 2015, INT C IM PROC ICIP
   Liao S., 2019, INT C AC SPEECH SIGN
   Lim L.-H., 2010, COMPTES RENDUS MECAN, V338
   Liu X.-Y., 2015, IEEE T MOBILE COMPUT, V15
   Novikov A., 2015, ADV NEURAL INFORM PR, P442, DOI DOI 10.5555/2969239.2969289
   Oseledets I. V., 2011, SIAM J SCI COMPUTING, V33
   Tao D., 2017, IEEE T IMAGE PROCESS, V27
   Tucker L. R., 1966, PSYCHOMETRIKA, V31
   Wang WQ, 2018, PROC CVPR IEEE, P9329, DOI 10.1109/CVPR.2018.00972
   Yang Y., 2017, P 34 INT C MACH LEAR, V70
   Zhang Z., 2014, P IEEE C COMP VIS PA
   Zhao Q., 2016, ARXIV
NR 25
TC 0
Z9 0
U1 0
U2 0
PY 2019
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Barbareschi, M
   De Benedictis, A
   Mazzeo, A
   Vespoli, A
AF Barbareschi, Mario
   De Benedictis, Alessandra
   Mazzeo, Antonino
   Vespoli, Antonino
BE Xhafa, F
   Barolli, L
   Li, J
   Yoshihisa, T
   Ogiela, MR
TI Mobile Traffic Analysis exploiting a Cloud Infrastructure and Hardware
   Accelerators
SO 2014 NINTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND
   INTERNET COMPUTING (3PGCIC)
DT Proceedings Paper
CT NINTH INTERNATIONAL CONFERENCE ON P2P, PARALLEL, GRID, CLOUD AND
   INTERNET COMPUTING (3PGCIC)
CY NOV 08-10, 2014
CL BWCCA, Guangzhou, PEOPLES R CHINA
HO BWCCA
AB Recently, traffic analysis and measurements have been used to characterize, from a security point of view, applications' and network behavior to avoid intrusion attempts, malware injections and data theft. Since most of the generated data traffic is from the embedded mobile devices, the analysis techniques have to cope on the one hand with the scarce computing capabilities and battery limitation of the devices, and on the other hand with tight performance constraints due to the huge generated traffic. In recent years, several machine learning approaches have been proposed in the literature, providing different levels of accuracy and requiring high computation resources to extract the analytic model from available training set. In this paper, we discuss a traffic analysis architecture that exploits FPGA technology to efficiently implement a hardware traffic analyzer on mobile devices, and a cloud infrastructure for the dynamic generation and updating of the data model based on ongoing mis-classification events. Finally, we provide a case study based on the implementation of the proposed traffic analyzer on a Xilinx Zynq 7000 architecture and Android OS, and show an overview of the proposed cloud infrastructure.
C1 [Barbareschi, Mario; De Benedictis, Alessandra; Mazzeo, Antonino; Vespoli, Antonino] Univ Naples Federico II, Dept Elect Engn & Informat Technol, I-80125 Naples, NA, Italy.
RP Barbareschi, M (corresponding author), Univ Naples Federico II, Dept Elect Engn & Informat Technol, I-80125 Naples, NA, Italy.
EM mario.barbareschi@unina.it; alessandra.debenedictis@unina.it;
   antonino.mazzeo@unina.it; antonino.vespoli@unina.it
CR Amato Flora, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8286, P125, DOI 10.1007/978-3-319-03889-6_14
   Amato F, 2014, STUD COMPUT INTELL, V511, P289, DOI 10.1007/978-3-319-01571-2_34
   [Anonymous], 2000, ARCHITECTURAL STYLES
   [Anonymous], 2013, CISCO VISUAL NETWORK
   [Anonymous], 2010, 10 ACM SIGCOMM C INT
   [Anonymous], SOFT COMPUTING
   [Anonymous], FIELD PROGR LOG APPL
   Barbareschi Mario, 2013, Algorithms and Architectures for Parallel Processing. 13th International Conference, ICA3PP 2013. Proceedings: LNCS 8286, P141, DOI 10.1007/978-3-319-03889-6_16
   Barbareschi M., 2014, INF REUS INT IRI 201
   Barbareschi M., 2013, ZEDROID ANDROID 2 2
   Casola Valentina, 2013, 2013 IEEE 14th International Conference on Information Reuse & Integration (IRI), P22, DOI 10.1109/IRI.2013.6642449
   Casola V., 2014, INTEGRATION REUSABLE, P299
   G. Inc, 2007, ANDR SOURC WEB SIT
   Hongwei Luo, 2012, 2012 1st IEEE International Conference on Communications in China (ICCC 2012), P214, DOI 10.1109/ICCChina.2012.6356880
   Hur M, 2012, 2012 14 AS PAC NETW, P1
   Jeong H, 2014, MACH VISION APPL, V25, P1501, DOI 10.1007/s00138-014-0629-y
   Lee S., 2011, P 13 AS PAC NETW OP, P1, DOI [10.1109/ICISA.2011.5772401, DOI 10.1007/S11042-011-0850-X]
   Salah Saber, 2011, 2011 International Conference on Mobile IT Convergence (ICMIC), P15
NR 18
TC 3
Z9 3
U1 0
U2 0
PY 2014
BP 414
EP 419
DI 10.1109/3PGCIC.2014.86
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Zhang, JL
   Beckwith, N
   Li, J
AF Zhang, Jialiang
   Beckwith, Nicholas
   Li, Jing (Jane)
GP IEEE Comp Soc
TI GORDON: Benchmarking Optane DC Persistent Memory Modules on FPGAs
SO 2021 IEEE 29TH ANNUAL INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE
   CUSTOM COMPUTING MACHINES (FCCM 2021)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 29th IEEE Annual International Symposium on Field-Programmable Custom
   Computing Machines (FCCM)
CY MAY 09-12, 2021
CL ELECTR NETWORK
AB Scalable nonvolatile memory DIMMs become commercially available on FPGAs with the release of Intel's Optane DC Persistent Memory (DCPM) product. This new class of memory combines the benefits of DRAM-like solid-state memory (fast, byte addressable) and Flash-like persistent storage (cost-effective, non-volatile), making FPGA highly competitive in accelerating large-scale machine learning and data analytics applications. Despite of the great promise, the performance characteristics of Optane DCPM remains relatively alien to FPGA developers compared to conventional DDRx DRAM or SSD. Recent preliminary studies all use CPU-based systems running full OS stack that limits their ability to characterize the detailed performance characteristics of the Optane DCPM. To fully exploit the advantages of Optane DCPM in FPGA-based accelerator design, we present the first FPGA-based Optane DCPM profiling framework, named GORDON1 on Stratix 10 DX FPGA. By leveraging the flexibility of the FPGA in building custom logic and the FPGA-specific features for Optane DCPM, GORDON addresses the fundamental limitations of prior CPU-based profiling. The detailed understanding on Optane DCPM may also benefit system design and optimization beyond FPGAs using CPUs and GPUs.
C1 [Zhang, Jialiang; Beckwith, Nicholas; Li, Jing (Jane)] Univ Penn, Elect & Syst Engn, Philadelphia, PA 19104 USA.
RP Zhang, JL (corresponding author), Univ Penn, Elect & Syst Engn, Philadelphia, PA 19104 USA.
EM jlzhang@seas.upenn.edu; nickbeck@seas.upenn.edu; janeli@seas.upenn.edu
CR [Anonymous], 2019, 2019 IEEE HOT CHIPS, pI, DOI [10.1109/HOTCHIPS.2019.8875668, DOI 10.1109/HOTCHIPS.2019.8875668]
   [Anonymous], 2020, IPMCTL
   [Anonymous], 2019, INTEL OPTANE PERSIST
   [Anonymous], 2020, INTEL FPGA DDR T MEM
   Intel<(R)> stratix<(R), 2020, 10 DX DEV OV 10 DX DEV OV
   Intel<(R)> stratix<(R), 2020, 10 DX DEV KIT US GUI 10 DX DEV KIT US GUI
   Peng IB, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P304, DOI 10.1145/3357526.3357568
   Tuck J, 2006, INT SYMP MICROARCH, P409
   Wang ZX, 2020, 2020 53RD ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO 2020), P496, DOI 10.1109/MICRO50266.2020.00049
   Yang J, 2020, PROCEEDINGS OF THE 18TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P169
NR 10
TC 2
Z9 2
U1 0
U2 0
PY 2021
BP 97
EP 105
DI 10.1109/FCCM51124.2021.00019
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sivkov, I
   Seewald, P
   Lazzaro, A
   Hutter, J
AF Sivkov, Ilia
   Seewald, Patrick
   Lazzaro, Alfio
   Hutter, Jurg
BE Foster, I
   Joubert, GR
   Kucera, L
   Nagel, WE
   Peters, F
TI DBCSR: A Blocked Sparse Tensor Algebra Library
SO PARALLEL COMPUTING: TECHNOLOGY TRENDS
SE Advances in Parallel Computing
DT Proceedings Paper
CT Conference on Parallel Computing - Technology Trends (ParCo)
CY SEP 10-13, 2019
CL Charles Univ, Prague, CZECH REPUBLIC
HO Charles Univ
DE sparse matrix-matrix multiplications; sparse tensor algebra;
   multi-threading; MPI parallelization; accelerators
AB Advanced algorithms for large-scale electronic structure calculations are mostly based on processing multi-dimensional sparse data. Examples are sparse matrix-matrix multiplications in linear-scaling Kohn-Sham calculations or the efficient determination of the exact exchange energy. When going beyond mean field approaches, e.g. for Moller-Plesset perturbation theory, RPA and Coupled-Cluster methods, or the GW methods, it becomes necessary to manipulate higher-order sparse tensors. Very similar problems are also encountered in other domains, like signal processing, data mining, computer vision, and machine learning. With the idea that the most of the tensor operations can be mapped to matrices, we have implemented sparse tensor algebra functionalities in the frames of the sparse matrix linear algebra library DBCSR (Distributed Block Compressed Sparse Row). DBCSR has been specifically designed to efficiently perform blocked-sparse matrix operations, so it becomes natural to extend its functionality to include tensor operations. We describe the newly developed tensor interface and algorithms. In particular, we introduce the tensor contraction based on a fast rectangular sparse matrix multiplication algorithm.
C1 [Sivkov, Ilia; Seewald, Patrick; Lazzaro, Alfio; Hutter, Jurg] Univ Zurich, Dept Chem, Zurich, Switzerland.
   [Lazzaro, Alfio] Cray Switzerland GmbH, Zurich, Switzerland.
RP Sivkov, I (corresponding author), Univ Zurich, Dept Chem, Zurich, Switzerland.
EM ilia.sivkov@chem.uzh.ch; patrick.seewald@chem.uzh.ch; alazzaro@cray.com;
   hutter@chem.uzh.ch
CR [Anonymous], 1969, THESIS
   Bethune Iain, 2017, ADV PARALLEL COMPUTI, P47
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   CORMEN T, 2001, INTRO ALGORITHMS
   Demmel J, 2013, INT PARALL DISTRIB P, P261, DOI 10.1109/IPDPS.2013.80
   Epifanovsky E, 2013, J COMPUT CHEM, V34, P2293, DOI 10.1002/jcc.23377
   Heinecke A., 2016, P INT C HIGH PERF CO
   Hutter J, 2014, WIRES COMPUT MOL SCI, V4, P15, DOI 10.1002/wcms.1159
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Landry W., 2003, Scientific Programming, V11, P273
   Lazzaro Alfio, P PLATF ADV SCI COMP
   Lewis Cannada A, 2015, ARXIV151001156
   Rajbhandari S., 2013, PREPRINT
   Schutt Ole, 2015, ELECT STRUCTURE CALC
   Solomonik E., 2015, ETH ZURICH, V36
   Solomonik Edgar, 2015, ARXIV151200066
   VandeVondele J, 2012, J CHEM THEORY COMPUT, V8, P3565, DOI 10.1021/ct200897x
   Wilhelm J, 2016, J CHEM THEORY COMPUT, V12, P5851, DOI 10.1021/acs.jctc.6b00840
NR 18
TC 0
Z9 0
U1 0
U2 3
PY 2020
VL 36
BP 331
EP 340
DI 10.3233/APC200058
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Hanuka, A
   Emma, C
   Maxwell, T
   Fisher, AS
   Jacobson, B
   Hogan, MJ
   Huang, Z
AF Hanuka, A.
   Emma, C.
   Maxwell, T.
   Fisher, A. S.
   Jacobson, B.
   Hogan, M. J.
   Huang, Z.
TI Accurate and confident prediction of electron beam longitudinal
   properties using spectral virtual diagnostics
SO SCIENTIFIC REPORTS
DT Article
AB Longitudinal phase space (LPS) provides a critical information about electron beam dynamics for various scientific applications. For example, it can give insight into the high-brightness X-ray radiation from a free electron laser. Existing diagnostics are invasive, and often times cannot operate at the required resolution. In this work we present a machine learning-based Virtual Diagnostic (VD) tool to accurately predict the LPS for every shot using spectral information collected non-destructively from the radiation of relativistic electron beam. We demonstrate the tool's accuracy for three different case studies with experimental or simulated data. For each case, we introduce a method to increase the confidence in the VD tool. We anticipate that spectral VD would improve the setup and understanding of experimental configurations at DOE's user facilities as well as data sorting and analysis. The spectral VD can provide confident knowledge of the longitudinal bunch properties at the next generation of high-repetition rate linear accelerators while reducing the load on data storage, readout and streaming requirements.
C1 [Hanuka, A.; Emma, C.; Maxwell, T.; Fisher, A. S.; Jacobson, B.; Hogan, M. J.; Huang, Z.] SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
RP Hanuka, A (corresponding author), SLAC Natl Accelerator Lab, Menlo Pk, CA 94025 USA.
EM adiha@slac.stanford.edu
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Akutowicz EJ., 1957, P AM MATH SOC, V8, P234, DOI 10.2307/2033718
   [Anonymous], TECHNICAL DESIGN REP, DOI [10.2172/1340171, DOI 10.2172/1340171]
   [Anonymous], 1991, ITERATIVE CONSTRAINE, DOI [10.1016/0165-1684(91)90146-A, DOI 10.1016/0165-1684(91)90146-A]
   Behrens C, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms4762
   Borland M., ADV PHOTON SOURCE LS, DOI [10.2172/761286, DOI 10.2172/761286]
   Charles T.K., 2018, COMPACT LINEAR COLLI
   Chollet F., 2015, KERAS, P3, DOI [10.1063/1.4960070, DOI 10.1063/1.4960070]
   Christie F, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-66220-5
   Di Mitri S, 2014, PHYS REP, V539, P1, DOI 10.1016/j.physrep.2014.01.005
   Duris J, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.124801
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Emma C, 2018, PHYS REV ACCEL BEAMS, V21, DOI 10.1103/PhysRevAccelBeams.21.112802
   Emma C., 2019, IBIC, DOI [10.18429/JACoW-IBIC2019-THBO01, DOI 10.18429/JACOW-IBIC2019-THBO01]
   Emma P, 2010, NAT PHOTONICS, V4, P641, DOI [10.1038/nphoton.2010.176, 10.1038/NPHOTON.2010.176]
   Hanuka A., 2019, P MACH LEARN PHYS SC
   Hemsing E, 2014, REV MOD PHYS, V86, P897, DOI 10.1103/RevModPhys.86.897
   Huang Z, 2018, NUCL INSTRUM METH A, V907, P182, DOI 10.1016/j.nima.2018.02.030
   LAI R, 1994, PHYS REV E, V50, pR3342, DOI 10.1103/PhysRevE.50.R3342
   LAI R, 1994, PHYS REV E, V50, pR4294, DOI 10.1103/PhysRevE.50.R4294
   Leemann SC, 2019, PHYS REV LETT, V123, DOI 10.1103/PhysRevLett.123.194801
   Lockmann NM, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.112801
   Loos H., 2007, 2007 IEEE Particle Accelerator Conference, P4189, DOI 10.1109/PAC.2007.4440076
   Lu XH, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.032802
   Lykken J., 2007, ARXIV07091893
   Marcus G, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.080702
   Marx D, 2018, NUCL INSTRUM METH A, V909, P374, DOI 10.1016/j.nima.2018.02.037
   Maxwell TJ, 2013, PHYS REV LETT, V111, DOI 10.1103/PhysRevLett.111.184801
   Mo MZ, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4960070
   Neuman C. P., 2000, Physical Review Special Topics-Accelerators and Beams, V3, DOI 10.1103/PhysRevSTAB.3.030701
   Qiang J, 2017, PHYS REV ACCEL BEAMS, V20, DOI 10.1103/PhysRevAccelBeams.20.054402
   Ratner D, 2012, PHYS REV LETT, V109, DOI 10.1103/PhysRevLett.109.034801
   Raubenheimer TO., 2015, PROC 6 INT PARTICLE, P2434, DOI [10.18429/JACoW-IPAC2015-WEYC1, DOI 10.18429/JACOW-IPAC2015-WEYC1]
   Sanchez-Gonzalez A, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15461
   Scheinker A, 2018, PHYS REV LETT, V121, DOI 10.1103/PhysRevLett.121.044801
   Scheinker A, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.102801
   Schmidt B, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.062801
   Sekko E., 1996, 1996 8 EUR SIGN PROC, P1
   Snively EC, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.054801
   Sütterlin D, 2007, NUCL INSTRUM METH B, V264, P361, DOI 10.1016/j.nimb.2007.08.092
   Tang JY, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.134801
   Tenenbaum P., 2005, P 2005 PART ACC C, P4197, DOI [10.1109/PAC.2005.1591763, DOI 10.1109/PAC.2005.1591763]
   Wang Z, 2004, IEEE T IMAGE PROCESS, V13, P600, DOI 10.1109/TIP.2003.819861
   Wesch S, 2012, NUCL INSTRUM METH A, V665, P40, DOI 10.1016/j.nima.2011.11.037
   Yakimenko V, 2019, PHYS REV ACCEL BEAMS, V22, DOI 10.1103/PhysRevAccelBeams.22.101301
   YANG GZ, 1994, APPL OPTICS, V33, P209, DOI 10.1364/AO.33.000209
   Zhang Z, 2016, PHYS REV ACCEL BEAMS, V19, DOI 10.1103/PhysRevAccelBeams.19.050701
NR 47
TC 11
Z9 13
U1 1
U2 5
PD FEB 3
PY 2021
VL 11
IS 1
AR 2945
DI 10.1038/s41598-021-82473-0
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT C
AU Huynh, TV
AF Thang Viet Huynh
BE Vinh, L
   Hoang, TA
   Hai, DT
TI Deep Neural Network Accelerator based on FPGA
SO 2017 4TH NAFOSTED CONFERENCE ON INFORMATION AND COMPUTER SCIENCE (NICS)
DT Proceedings Paper
CT 4th National-Foundation-for-Science-and-Technology-Development
   (NAFOSTED) Conference on Information and Computer Science (NICS)
CY NOV 24-25, 2017
CL Hanoi, VIETNAM
DE machine learning; deep neural network; MNIST; FPGA; floating-point
AB In this work, we propose an efficient architecture for the hardware realization of deep neural networks on reconfigurable computing platforms like FPGA. The proposed neural network architecture employs only one single physical computing layer to perform the whole computational fabric of fully-connected feedforward deep neural networks with customizable number of layers, number of neurons per layer and number of inputs. The inputs, weights and outputs of the network are represented in 16-bit half-precision floating-point number format. The network weights are hard-coded using on-chip memory of FPGA devices, allowing for very fast computation. For performance evaluation, the handwritten digit recognition application with MNIST database is performed, which reported a recognition rate of 97.20% and a peak performance of 15.81 kFPS when using a deep neural network of size 784-40-40-10 on the Xilinx Virtex-5 XC5VLX-110T device. When implementing a deep neural network of size 784-126-126-10 for MNIST database on the Xilinx ZynQ-7000 XC7Z045 device, the recognition rate is 98.16% and the peak performance is 15.90 kFPS.
C1 [Thang Viet Huynh] Univ Danang, Danang Univ Sci & Technol, Da Nang, Vietnam.
RP Huynh, TV (corresponding author), Univ Danang, Danang Univ Sci & Technol, Da Nang, Vietnam.
EM thanghv@dut.udn.vn
CR Huynh T. V., 2017, INT J COMPUT DIGIT S, V6
   Misra J, 2010, NEUROCOMPUTING, V74, P239, DOI 10.1016/j.neucom.2010.03.021
   Nedjah N, 2012, EXPERT SYST APPL, V39, P9191, DOI 10.1016/j.eswa.2012.02.085
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Huynh TV, 2014, 2014 IEEE FIFTH INTERNATIONAL CONFERENCE ON COMMUNICATIONS AND ELECTRONICS (ICCE), P291, DOI 10.1109/CCE.2014.6916717
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
NR 6
TC 12
Z9 14
U1 0
U2 3
PY 2017
BP 254
EP 257
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Wang, H
   Chen, XH
   Chen, XJ
   Zang, PL
   Liu, YQ
   Wang, LR
AF Wang, Hui
   Chen, Xiaohe
   Chen, Xinjian
   Zang, Peilin
   Liu, Yunqing
   Wang, Lirong
GP IEEE
TI Fall Detection Based on KPCA and 3D KPCA
SO 2016 IEEE TRUSTCOM/BIGDATASE/ISPA
SE IEEE Trustcom
DT Proceedings Paper
CT 15th IEEE Int Conf on Trust, Security and Privacy in Comp and Commun /
   10th IEEE Int Conf on Big Data Science and Engineering / 14th IEEE Int
   Symposium on Parallel and Distributed Proc with Applicat (IEEE
   Trustcom/BigDataSE/ISPA)
CY AUG 23-26, 2016
CL Tianjin, PEOPLES R CHINA
DE fall detection; KPCA; 3D KPCA; statistical features; AdaBoost
AB Falls in elderly remain a very important public health care issue. Many different techniques for automatic fall detection have been developed. The wearable devices based on tri-axial accelerator prove to be an effective tool for fall detection in recent years. The popular methods are mainly based on threshold techniques and machine learning techniques, in this paper the threshold techniques and AdaBoost classifier are combined for detection. Additionally, we propose an approach based on nonlinear statistical features to distinguish falls from normal activities of daily living (ADL) in this paper. A novel method 3D Kernel Principal Component Analysis (3D KPCA) improved by Kernel Principal Component Analysis (KPCA) for feature extraction is proposed, which can extract the statistical features without the loss of 3D data structure information. The fall detection based on KPCA and 3D KPCA algorithm for feature extraction is firstly proposed in this paper and the experiment conducted on the public database (UCI) shows the efficiency of the approach, which can successfully distinguish falls from ADL with the accuracy 95.957%.
C1 [Wang, Hui; Chen, Xinjian; Zang, Peilin; Liu, Yunqing; Wang, Lirong] Soochow Univ, Sch Elect & Informat Engn, Suzhou, Peoples R China.
   [Chen, Xiaohe] Chinese Acad Sci, Suzhou Inst Biomed Engn & Technol, Beijing, Peoples R China.
RP Wang, LR (corresponding author), Soochow Univ, Sch Elect & Informat Engn, Suzhou, Peoples R China.
EM wanghuiliuwen@foxmail.com
CR Begga R., 2005, J BIOMECHANICS, V38
   Collins M, 2002, MACH LEARN, V48, P253, DOI 10.1023/A:1013912006537
   Conte V, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0034473
   Gibsona R. M., 2016, APPL SOFT COMPUTING, V39
   He J., 2016, INT J DISTRIBUTED SE, V10
   Huang S., 2011, ACIS INT S SOFTW NET
   Igual R, 2015, MED ENG PHYS, V37, P870, DOI 10.1016/j.medengphy.2015.06.009
   Kaluzal B., 2010, LECT NOTES COMPUTER
   Lustrek M., 2009, INFORMATICA, V33, P205
   Medrano C, 2014, PLOS ONE, V9, DOI 10.1371/journal.pone.0094811
   Ozdemirl A. T., 2014, SENSORS, V14
   Palmerini L., 2015, SENSORS, V15
   Wu J., 2007, HUMAN MOVEMENT SCI, V26
NR 13
TC 0
Z9 0
U1 1
U2 2
PY 2016
BP 2187
EP 2191
DI 10.1109/TrustCom.2016.334
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Xie, Y
   Deng, CH
   Liao, SY
   Yuan, B
AF Xie, Yi
   Deng, Chunhua
   Liao, Siyu
   Yuan, Bo
BE Matthews, MB
TI Area-efficient K-Nearest Neighbor Design using Stochastic Computing
SO 2018 CONFERENCE RECORD OF 52ND ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS,
   AND COMPUTERS
SE Conference Record of the Asilomar Conference on Signals Systems and
   Computers
DT Proceedings Paper
CT 52nd Asilomar Conference on Signals, Systems, and Computers
CY OCT 28-NOV 01, 2018
CL Pacific Grove, CA
DE Stochastic Computing; K-Nearest Neighbor; Area efficient
AB Among various machine learning techniques, K Nearest Neighbor (KNN) has been widely exploited for many artificial intelligence applications. However, due to the intensive use of multiplications during its computing procedure, KNN algorithm is typically computation -intensive and thereby posing severe challenge for its efficiency in hardware performance in terms of area and power consumption. To address this challenge, this paper proposes to design an area -efficient low -power stochastic KNN hardware accelerator. By leveraging stochastic computing (SC) technique, the basic computation components of KNN classifier are replaced by simple stochastic logic circuits such as XNOR and MUX gate. Moreover, we propose a low-cost architecture for binary -to -stochastic (B -to -S) interface and develop an Approximate Parallel Accumulator (APA) for stochastic -to -binary (S -to -B) module, which can further improve the hardware performance for the stochastic design. Experimental results demonstrate that the proposed stochastic KNN design achieves higher area efficiency and lower power consumption as compared to the non -stochastic design. Also, it remains high task accuracy with negligible performance loss.
C1 [Xie, Yi; Deng, Chunhua; Liao, Siyu; Yuan, Bo] Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
RP Xie, Y (corresponding author), Rutgers State Univ, Dept Elect & Comp Engn, Piscataway, NJ 08854 USA.
CR [Anonymous], 1951, APPL MATH SERIES
   [Anonymous], IEEE T NANOTECHNOLOG
   Boiman O, 2008, PROC CVPR IEEE, P1992, DOI 10.1109/CVPR.2008.4587598
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Gaines B. R., 1969, ADV INFORM SYSTEMS S, V2, P37
   Imandoust S.B., 2013, INT J ENG RES APPL, V3, P605, DOI DOI 10.1016/J.JTBI.2009.08.004
   Jabbar MA, 2013, PROC TECH, V10, P85, DOI 10.1016/j.protcy.2013.12.340
   Ting PS, 2014, 2014 17TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD), P356, DOI 10.1109/DSD.2014.75
   Xie Y, 2017, IEEE T CIRCUITS-II, V64, P1382, DOI 10.1109/TCSII.2017.2746749
NR 9
TC 7
Z9 7
U1 0
U2 1
PY 2018
BP 782
EP 786
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Lay, LM
   Chuang, KC
   Wu, YY
   Giles, W
   Adamson, J
AF Lay, Lam M.
   Chuang, Kai-Cheng
   Wu, Yuyao
   Giles, William
   Adamson, Justus
TI Virtual patient-specific QA with DVH-based metrics
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE AI; artificial intelligence; IMRT QA
ID TRAJECTORY LOG FILES; IMRT QA; PASSING RATES; VMAT; VERIFICATION;
   PREDICTION; ALGORITHM; ERRORS
AB We demonstrate a virtual pretreatment patient-specific QA (PSQA) procedure that is capable of quantifying dosimetric effect on patient anatomy for both intensity modulated radiotherapy (IMRT) and volumetric modulated arc therapy (VMAT). A machine learning prediction model was developed to use linear accelerator parameters derived from the DICOM-RT plan to predict delivery discrepancies at treatment delivery (defined as the difference between trajectory log file and DICOM-RT) and was coupled with an independent Monte Carlo dose calculation algorithm for dosimetric analysis. Machine learning models for IMRT and VMAT were trained and validated using 120 IMRT and 206 VMAT fields of prior patients, with 80% assigned for iterative training and testing, and 20% for post-training validation. Various prediction models were trained and validated, with the final models selected for clinical implementation being a boosted tree and bagged tree for IMRT and VMAT, respectively. After validation, these models were then applied clinically to predict the machine parameters at treatment delivery for 7 IMRT plans from various sites (61 fields) and 10 VMAT multi-target intracranial radiosurgery plans (35 arcs) and compared to the dosimetric effect calculated directly from trajectory log files. Dose indices tracked for targets and organs at risk included dose received by 99%, 95%, and 1% of the volume, mean dose, percent of volume receiving 25%-100% of the prescription dose. The average coefficient of determination (r(2)) when comparing intra-field predicted and actual delivery error was 0.987 +/- 0.012 for IMRT and 0.895 +/- 0.095 for VMAT, whereas r(2) when comparing inter-field predicted versus actual delivery error was 0.982 for IMRT and 0.989 for VMAT. Regarding dosimetric analysis, r(2) when comparing predicted versus actual dosimetric changes for all dose indices was 0.966 for IMRT and 0.907 for VMAT. Prediction models can be used to anticipate the dosimetric effect calculated from trajectory files and have potential as a "delivery-free" pretreatment analysis to enhance PSQA.
C1 [Lay, Lam M.] Duke Univ, Med Phys Grad Program, Durham, NC 27710 USA.
   [Chuang, Kai-Cheng; Wu, Yuyao] Duke Kunshan Univ, Med Phys Grad Program, Kunshan, Peoples R China.
   [Giles, William; Adamson, Justus] Duke Univ, Dept Radiat Oncol, Med Ctr, 200 Trent Dr, Durham, NC 27710 USA.
RP Adamson, J (corresponding author), Duke Univ, Dept Radiat Oncol, Med Ctr, 200 Trent Dr, Durham, NC 27710 USA.
EM justus.adamson@duke.edu
CR Acharya S, 2016, INT J RADIAT ONCOL, V94, P394, DOI 10.1016/j.ijrobp.2015.10.015
   Agnew A, 2014, PHYS MED BIOL, V59, pN49, DOI 10.1088/0031-9155/59/9/N49
   Agnew CE, 2014, J APPL CLIN MED PHYS, V15, P204, DOI 10.1120/jacmp.v15i6.4994
   Bailey DW, 2009, MED PHYS, V36, P4089, DOI 10.1118/1.3187785
   Blewitt ME, 2008, NAT GENET, V40, P663, DOI 10.1038/ng.142
   Boggula R, 2011, PHYS MED BIOL, V56, P7163, DOI 10.1088/0031-9155/56/22/011
   Carlson JNK, 2016, PHYS MED BIOL, V61, P2514, DOI 10.1088/0031-9155/61/6/2514
   Chuang KC, 2021, MED PHYS, V48, P978, DOI 10.1002/mp.14670
   Chuang KC, 2021, BIOMED PHYS ENG EXPR, V7, DOI 10.1088/2057-1976/abc86c
   Francis Kenney J., 1939, MATH STAT
   Gibbons JP, 2014, MED PHYS, V41, DOI 10.1118/1.4864244
   Granville DA, 2019, PHYS MED BIOL, V64, DOI 10.1088/1361-6560/ab142e
   Henke LE, 2019, ADV RADIAT ONCOL, V4, P201, DOI 10.1016/j.adro.2018.10.003
   Hoffmann L, 2018, MED PHYS, V45, P3909, DOI 10.1002/mp.13053
   Huq MS, 2008, INT J RADIAT ONCOL, V71, pS170, DOI 10.1016/j.ijrobp.2007.06.081
   Interian Y, 2018, MED PHYS, V45, P2672, DOI 10.1002/mp.12890
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Kry SF, 2019, MED PHYS, V46, P3700, DOI 10.1002/mp.13638
   Kry SF, 2014, INT J RADIAT ONCOL, V90, P1195, DOI 10.1016/j.ijrobp.2014.08.334
   KUTCHER GJ, 1994, MED PHYS, V21, P581, DOI 10.1118/1.597316
   Lam D, 2019, MED PHYS, V46, P4666, DOI 10.1002/mp.13752
   Lamb J, 2017, CUREUS J MED SCIENCE, V9, DOI 10.7759/cureus.1618
   Lechner W, 2017, RADIOTHER ONCOL, V123, pS429, DOI 10.1016/S0167-8140(17)31242-2
   Létourneau D, 2004, RADIOTHER ONCOL, V70, P199, DOI 10.1016/j.radonc.2003.10.014
   Li JQ, 2019, INT J RADIAT ONCOL, V105, P893, DOI 10.1016/j.ijrobp.2019.07.049
   McDonald DG, 2017, J APPL CLIN MED PHYS, V18, P170, DOI 10.1002/acm2.12025
   Men CH, 2010, PHYS MED BIOL, V55, P4309, DOI 10.1088/0031-9155/55/15/008
   Miften M, 2018, MED PHYS, V45, pE53, DOI 10.1002/mp.12810
   Neal B, 2016, MED PHYS, V43, P2933, DOI 10.1118/1.4949002
   Nelms BE, 2007, J APPL CLIN MED PHYS, V8, P76, DOI 10.1120/jacmp.v8i3.2448
   Nelms BE, 2011, MED PHYS, V38, P1037, DOI 10.1118/1.3544657
   Olasolo-Alonso J, 2017, PHYS MEDICA, V33, P87, DOI 10.1016/j.ejmp.2016.12.013
   Ono T, 2019, MED PHYS, V46, P3823, DOI 10.1002/mp.13669
   Osman AFI, 2020, MED PHYS, V47, P1421, DOI 10.1002/mp.14014
   Park JM, 2019, RADIAT ONCOL, V14, DOI 10.1186/s13014-019-1441-7
   Rangaraj D, 2013, PRACT RADIAT ONCOL, V3, P80, DOI 10.1016/j.prro.2012.05.002
   Stasi M, 2012, MED PHYS, V39, P7626, DOI 10.1118/1.4767763
   Stern RL, 2011, MED PHYS, V38, P504, DOI 10.1118/1.3521473
   Sun BZ, 2013, PRACT RADIAT ONCOL, V3, pE199, DOI 10.1016/j.prro.2012.11.013
   Valdes G, 2016, MED PHYS, V43, P4323, DOI 10.1118/1.4953835
   Valdes G, 2021, MED PHYS, V48, P2701, DOI 10.1002/mp.14870
   Valdes G, 2017, J APPL CLIN MED PHYS, V18, P279, DOI 10.1002/acm2.12161
   Vazquez-Quino Luis Alberto, 2017, Proc (Bayl Univ Med Cent), V30, P276
   Wall Phillip D. H., 2020, Informatics in Medicine Unlocked, V18, P190, DOI 10.1016/j.imu.2020.100292
   Zaila A., 2016, PHYS MED, V32, P292, DOI [10.1016/j.ejmp.2016.07.122, DOI 10.1016/J.EJMP.2016.07.122]
   Zayegh A., 2018, DIGITAL SYSTEMS INTE, DOI 10.5772/intechopen.80416
   Zhen HM, 2011, MED PHYS, V38, P5477, DOI 10.1118/1.3633904
   Zhou Zhi-Hua, 2009, ENCY BIOMETRICS, V1, P270, DOI [DOI 10.1007/978-0-387-73003-5_293, DOI 10.1007/978-0-387-73003-5293]
   Zhu TMC, 2021, MED PHYS, V48, pE808, DOI 10.1002/mp.15069
NR 49
TC 4
Z9 4
U1 0
U2 3
PD NOV
PY 2022
VL 23
IS 11
AR e13639
DI 10.1002/acm2.13639
EA MAY 2022
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Vargas, F
   Borba, D
   Benfica, JD
   Syed, RT
AF Vargas, Fabian
   Borba, Douglas
   Benfica, Juliano D'ornelas
   Syed, Rizwan Tariq
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI Artificial Neural Network Accelerator for Classification of In-Field
   Conducted Noise in Integrated Circuits' DC Power Lines
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Conducted noise; Electromagnetic interference (EMI); Transient fault;
   Machine learning; Signal integrity; Artificial neural networks; Robust
   embedded system
AB With the growing use of embedded systems in our daily lives and the increasing electromagnetic noise level in the environment in which these systems are exposed, the need for reliable operation is paramount. In this scenario, this work presents a study on the use of Artificial Neural Networks (ANNs) to perform in-field identification and classification of different types of noise conducted in the integrated circuit (IC) DC power lines according to a specific set of IEC standards. After identification, proactive actions can be taken to guarantee the expected IC robustness. Such actions can be, for instance, slow down IC clock frequency, increasing power supply voltage and/or activating error detection & correction (EDAC) functions during the period the system is operating under such noise exposition. Experimental results demonstrate that the ANN was able to identify and classify different types of conducted noise in power supply lines with a success rate ranging from 70 to 100% within a latency in the order of 995 ns.
C1 [Vargas, Fabian; Syed, Rizwan Tariq] IHP Leibniz Inst High Performance Microelect, Frankfurt, Germany.
   [Borba, Douglas] LABELO Specialized Elect Elect Labs, Porto Alegre, Brazil.
RP Vargas, F (corresponding author), IHP Leibniz Inst High Performance Microelect, Frankfurt, Germany.
EM vargas@ihp-microelectronics.com; douglasbeng@gmail.com;
   jbenfica@gmail.com; syed@ihp-microelectronics.com
CR Aarrestad T, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/ac0ea1
   Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Amrutha J., 2018, 2018 3rd IEEE International Conference on Recent Trends in Electronics, Information & Communication Technology (RTEICT), P1547, DOI 10.1109/RTEICT42901.2018.9012614
   [Anonymous], 2012, 6100044 IEC EMC
   [Anonymous], 2000, 61000429 IEC EMC, VFirst
   [Anonymous], 2000, 6100042 IEC EMC, VFirst
   [Anonymous], 2005, 6100045 IEC EMC, VFirst
   Benfica J, 2020, MICROELECTRON RELIAB, V114, DOI 10.1016/j.microrel.2020.113884
   Benfica J, 2016, IEEE T NUCL SCI, V63, P1294, DOI 10.1109/TNS.2016.2523458
   Crouch A., 1999, DESIGN TEST DIGITAL
   github, GITHUB COM PUBL ACC
   Goerl R, 2019, MICROELECTRON RELIAB, V100, DOI 10.1016/j.microrel.2019.06.033
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Jin H, 2017, ELEC DES ADV PACKAG
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Mas JF, 2008, INT J REMOTE SENS, V29, P617, DOI 10.1080/01431160701352154
   Medico R, 2019, IEEE T ELECTROMAGN C, V61, P352, DOI 10.1109/TEMC.2018.2821712
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224874
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Rahimi, R
   Sadredini, E
   Stan, M
   Skadron, K
AF Rahimi, Reza
   Sadredini, Elaheh
   Stan, Mircea
   Skadron, Kevin
GP IEEE Comp Soc
TI Grapefruit: An Open-Source, Full-Stack, and Customizable Automata
   Processing on FPGAs
SO 28TH IEEE INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE CUSTOM COMPUTING
   MACHINES (FCCM)
SE Annual IEEE Symposium on Field-Programmable Custom Computing Machines
DT Proceedings Paper
CT 28th IEEE International Symposium on Field-Programmable Custom Computing
   Machines (FCCM)
CY MAY 03-06, 2020
CL Fayetteville, AR
ID MATCHING ENGINE; ARCHITECTURE; EFFICIENT; MEMORY
AB Regular expressions have been widely used in various application domains such as network security, machine learning, and natural language processing. Increasing demand for accelerated regular expressions, or equivalently finite automata, has motivated many efforts in designing FPGA accelerators. However, there is no framework that is publicly available, comprehensive, parameterizable, general, full-stack, and easy-to-use, all in one, for design space exploration for a wide range of growing pattern matching applications on FPGAs. In this paper, we present Grapefruit, the first open-source, full-stack, efficient, scalable, and extendable automata processing framework on FPGAs. Grapefruit is equipped with an integrated compiler with many parameters for automata simulation, verification, minimization, transformation, and optimizations. Our modular and standard design allows researchers to add capabilities and explore various features for a target application. Our experimental results show that the hardware generated by Grapefruit performs 9%-80% better than prior work that is not fully end-to-end and has 3.4x higher throughput in a multi-stride solution than a single-stride solution.
C1 [Rahimi, Reza; Stan, Mircea] Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22904 USA.
   [Sadredini, Elaheh; Skadron, Kevin] Univ Virginia, Dept Comp Sci, Charlottesville, VA 22903 USA.
RP Rahimi, R (corresponding author), Univ Virginia, Dept Elect & Comp Engn, Charlottesville, VA 22904 USA.
EM rahimi@virginia.edu; elaheh@virginia.edu; mircea@virginia.edu;
   skadron@virginia.edu
CR [Anonymous], 2014, P 9 DOCT WORKSH MATH
   [Anonymous], 2007, P 3 ACM IEEE S ARCH, DOI DOI 10.1145/1323548.1323573
   [Anonymous], 1961, RUSSIAN MATH SURVEYS
   [Anonymous], 2019, P 24 INT C ARCH SUPP
   [Anonymous], 2018, IISWC
   [Anonymous], 2016, TECH REP
   Atasu K, 2013, INT PARALL DISTRIB P, P1254, DOI 10.1109/IPDPS.2013.54
   Avalle M, 2016, IEEE ACM T NETWORK, V24, P1704, DOI 10.1109/TNET.2015.2429918
   Becchi M., 2008, P 4 ACM IEEE S ARCH, P50, DOI DOI 10.1145/1477942.1477950
   Becchi M, 2013, ACM T ARCHIT CODE OP, V10, DOI 10.1145/2445572.2445576
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Bo C., 2018, 24 INT S HIGH PERF C
   Bo C, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3314576
   Bo CK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P311, DOI 10.1109/BigData.2016.7840617
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang Yu, 2006, ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS 2006), P93, DOI 10.1109/ANCS.2006.4579527
   Gogte V, 2016, INT SYMP MICROARCH
   Karakchi R, 2017, PROC INT CONF RECON
   Lenjani M, 2014, IET COMPUT DIGIT TEC, V8, P30, DOI 10.1049/iet-cdt.2011.0066
   Liu C., 2013, IEEE T COMPUTERS, V62
   Liu HY, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P251, DOI 10.1145/3373376.3378471
   Liu HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P908, DOI [10.1109/MICRO.2018.00078, 10.1109/MICR0.2018.00078]
   Liu TW, 2011, IEEE INFOCOM SER, P2129, DOI 10.1109/INFCOM.2011.5935024
   Paxson V, 1999, COMPUT NETW, V31, P2435, DOI 10.1016/S1389-1286(99)00112-7
   Putic M, 2017, IEEE MICRO, V37, P52, DOI 10.1109/MM.2017.6
   Roy I, 2016, IEEE ACM T COMPUT BI, V13, P99, DOI 10.1109/TCBB.2015.2430313
   Sadredini E., 2020, 25 INT C ARCH UNPUB
   Sadredini E., 2017, INT C SUP ICS
   Sadredini E, 2020, INT S HIGH PERF COMP, P86, DOI 10.1109/HPCA47549.2020.00017
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Hieu TT, 2013, INT CONF UBIQ FUTUR, P252, DOI 10.1109/ICUFN.2013.6614821
   Vespa L, 2011, COMPUT J, V54, P285, DOI 10.1093/comjnl/bxq077
   Wadden J., 2016, IISWC
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wang K., 2015, IPDPS
   Wang K., 2017, INT J PARALLEL PROGR
   Wang K, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P135, DOI 10.1145/2903150.2903172
   Wang X., 2014, TECHNIQUES EFFICIENT
   Wang X, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P631
   Xie T., 2018, 50 C GOV MICR APPL C
   Xie T, 2017, I C FIELD PROG LOGIC
   Yamagaki N, 2008, I C FIELD PROG LOGIC, P131, DOI 10.1109/FPL.2008.4629920
   Yang YHE, 2012, IEEE T COMPUT, V61, P1013, DOI 10.1109/TC.2011.129
   Zhang Y, 2010, ACM SIGCOMM COMP COM, V40, P20, DOI 10.1145/1880153.1880157
   Zhou K, 2015, IEEE INT C SEMANT CO, P236, DOI 10.1109/ICOSC.2015.7050812
NR 48
TC 13
Z9 13
U1 0
U2 4
PY 2020
BP 138
EP 147
DI 10.1109/FCCM48280.2020.00027
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Sen, S
   Jain, S
   Venkataramani, S
   Raghunathan, A
AF Sen, Sanchari
   Jain, Shubham
   Venkataramani, Swagath
   Raghunathan, Anand
TI SPARCE: Sparsity Aware General-Purpose Core Extensions to Accelerate
   Deep Neural Networks
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Deep learning; deep neural networks; sparsity; general purpose
   processors
AB Deep Neural Networks (DNNs) have emerged as the method of choice for solving a wide range of machine learning tasks. The enormous computational demand posed by DNNs is a key challenge for computing system designers and has most commonly been addressed through the design of DNN accelerators. However, these specialized accelerators utilize large quantities of multiply-accumulate units and on-chip memory and are prohibitive in area and cost constrained systems such as wearable devices and IoT sensors. In this work, we take a complementary approach and improve the performance of DNNs on general-purpose processor (GPP) cores. We do so by exploiting a key attribute of DNNs, viz. sparsity or the prevalence of zero values. We propose Sparsity-aware Core Extensions (SPARCE)-a set of low-overhead micro-architectural and ISA extensions that dynamically detect whether an operand (e. g., the result of a load instruction) is zero and subsequently skip a set of future instructions that use it. To maximize performance benefits, SPARCE ensures that the instructions to be skipped are prevented fromeven being fetched, as squashing instructions comeswith a penalty (e. g., a pipeline stall). SPARCE consists of 2 keymicro-architectural enhancements. First, a Sparsity Register File (SpRF) is utilized to track registers that are zero. Next, a Sparsity-Aware Skip Address (SASA) Table is used to indicate instruction sequences that can be skipped, and to specify conditions on SpRF registers that trigger instruction skipping. When an instruction is fetched, SPARCE dynamically pre-identifies whether the following instruction(s) can be skipped, and if so appropriatelymodifies the program counter, thereby skipping the redundant instructions and improving performance. We model SPARCE using the gem5 architectural simulator, and evaluate our approach on 6 state-of-the-art image-recognition DNNs in the context of both training and inference using the Caffe deep learning framework. On a scalar microprocessor, SPARCE achieves 1.11x-1.96x speedups across both convolution and fully-connected layers that exhibit 10-90 percent sparsity. These speedups translate to 19-31 percent reduction in execution time at the overall application-level. We also evaluate SPARCE on a 4-way SIMD ARMv8 processor using the OpenBLAS library, and demonstrate that SPARCE achieves 8-15 percent reduction in the application-level execution time.
C1 [Sen, Sanchari; Jain, Shubham; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Venkataramani, Swagath] IBM TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Sen, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM sen9@purdue.edu; jain130@purdue.edu; swagath.venkataramani@ibm.com;
   raghunathan@purdue.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, CORR
   [Anonymous], 2015, CORR
   [Anonymous], 2014, CORR
   [Anonymous], 2015, NIPS
   [Anonymous], 2015, DEEP RESIDUAL LEARNI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, CORR
   [Anonymous], 2014, CORR
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Iandola F.N., 2015, CORR
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3233231
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park H, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2968476
   Perais A, 2016, ACM T COMPUT SYST, V34, DOI 10.1145/2870632
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Sodani A, 1997, ACM COMP AR, P194, DOI 10.1145/384286.264200
   Szegedy C., 2015, P IEEE C COMP VIS PA, P1
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Wen W., 2016, ADV NEURAL INFORM PR, P2082, DOI DOI 10.1016/J.CCR.2008.06.009
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zisserman, 2014, CORR
NR 34
TC 19
Z9 19
U1 0
U2 6
PD JUN
PY 2019
VL 68
IS 6
BP 912
EP 925
DI 10.1109/TC.2018.2879434
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Abdelsalam, AM
   Elsheikh, A
   Chidambaram, S
   David, JP
   Langlois, JMP
AF Abdelsalam, Ahmed M.
   Elsheikh, Ahmed
   Chidambaram, Sivakumar
   David, Jean-Pierre
   Langlois, J. M. Pierre
TI POLYBiNN: Binary Inference Engine for Neural Networks using Decision
   Trees
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Deep learning; FPGAs; Decision trees; Hardware accelerators; Binary
   classifiers
AB Convolutional Neural Networks (CNNs) and Deep Neural Networks (DNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of DNN and CNN architectures pose particular challenges for their FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider deep learning user community and to improve DNN design efficiency, we introduce POLYBiNN, an efficient FPGA-based inference engine for DNNs and CNNs. POLYBiNN is composed of a stack of decision trees, which are binary classifiers in nature, and it utilizes AND-OR gates instead of multipliers and accumulators. POLYBiNN is a memory-free inference engine that drastically cuts hardware costs. We also propose a tool for the automatic generation of a low-level hardware description of the trained POLYBiNN for a given application. We evaluate POLYBiNN and the tool for several datasets that are normally solved using fully connected layers. On the MNIST dataset, when implemented in a ZYNQ-7000 ZC706 FPGA, the system achieves a throughput of up to 100 million image classifications per second with 90 ns latency and 97.26% accuracy. Moreover, POLYBiNN consumes 8x less power than the best previously published implementations, and it does not require any memory access. We also show how POLYBiNN can be used instead of the fully connected layers of a CNN and apply this approach to the CIFAR-10 dataset.
C1 [Abdelsalam, Ahmed M.; Langlois, J. M. Pierre] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
   [Elsheikh, Ahmed] Polytech Montreal, Dept Math & Ind Engn, Montreal, PQ, Canada.
   [Chidambaram, Sivakumar; David, Jean-Pierre] Polytech Montreal, Dept Elect Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; ahmed.elsheikh@polymtl.ca;
   sivakumar.Chidambaram@polymtl.ca; jean-pierre.david@polymtl.ca;
   pierre.langlois@polymtl.ca
CR Abdelsalam A.M., 2018, IEEE DESIGN ARCHITEC
   Abdelsalam AM, 2018, PROC INT CONF RECON
   Akers S. B., 1978, IEEE T COMPUTERS
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, ADV NEURAL INFORM PR
   [Anonymous], WORLD SCI
   [Anonymous], 1998, P IEEE
   [Anonymous], 2012, PATTERN CLASSIFICATI
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   Breiman L., 1984, BIOMETRICS, P357
   Cheng Y., 2017, ARXIV171009282
   Courbariaux M., 2016, ARXIV160202830 COMP
   Deng L., 2017, ARXIV170509283
   Furnkranz J., 2012, FDN RULE LEARNING
   Han Song, 2016, ICLR
   Hastie T, 2008, ELEMENTS STAT LEARNI
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hunter D., 2012, IEEE T IND INFORM
   Lecun Yann, 2015, NATURE
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Lorena A.C., 2008, REV COMBINATION BINA
   Misra J., 2010, NEUROCOMPUTING
   Nakahara H., 2017, IEEE INT C FIELD PRO
   Nurvitadhi E., 2017, ACM SIGDA INT S FIEL
   Rastegari M., 2016, SPRING EUR C COMP VI
   Robert C., 2014, MACHINE LEARNING PRO
   Struharik J.R., 2011, IEEE INT S INT SYST
   Sze V., 2017, P IEEE
   Tang P.T., 1991, IEEE S COMP AR
   Umuroglu Y., 2017, ACM SIGDA INT S FIEL
   Zhao R., 2017, ACM SIGDA INT S FIEL
NR 33
TC 2
Z9 2
U1 0
U2 6
PD JAN
PY 2020
VL 92
IS 1
BP 95
EP 107
DI 10.1007/s11265-019-01453-w
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Xu, Y
   Afshar, S
   Wang, RC
   Cohen, G
   Thakur, CS
   Hamilton, TJ
   van Schaik, A
AF Xu, Ying
   Afshar, Saeed
   Wang, Runchun
   Cohen, Gregory
   Singh Thakur, Chetan
   Hamilton, Tara Julia
   van Schaik, Andre
TI A Biologically Inspired Sound Localisation System Using a Silicon
   Cochlea Pair
SO APPLIED SCIENCES-BASEL
DT Article
DE electronic cochlea; neuromorphic engineering; sound localisation; onset
   detection; process innovation; ITD; ELM; CNN
ID CNN ACCELERATOR; SUPERIOR OLIVE; IMPLEMENTATION; DELAYS; MODEL
AB We present a biologically inspired sound localisation system for reverberant environments using the Cascade of Asymmetric Resonators with Fast-Acting Compression (CAR-FAC) cochlear model. The system exploits a CAR-FAC pair to pre-process binaural signals that travel through the inherent delay line of the cascade structures, as each filter acts as a delay unit. Following the filtering, each cochlear channel is cross-correlated with all the channels of the other cochlea using a quantised instantaneous correlation function to form a 2-D instantaneous correlation matrix (correlogram). The correlogram contains both interaural time difference and spectral information. The generated correlograms are analysed using a regression neural network for localisation. We investigate the effect of the CAR-FAC nonlinearity on the system performance by comparing it with a CAR only version. To verify that the CAR/CAR-FAC and the quantised instantaneous correlation provide a suitable basis with which to perform sound localisation tasks, a linear regression, an extreme learning machine, and a convolutional neural network are trained to learn the azimuthal angle of the sound source from the correlogram. The system is evaluated using speech data recorded in a reverberant environment. We compare the performance of the linear CAR and nonlinear CAR-FAC models with current sound localisation systems as well as with human performance.
C1 [Xu, Ying; Afshar, Saeed; Wang, Runchun; Cohen, Gregory; van Schaik, Andre] Western Sydney Univ, MARCS Inst Brain Behav & Dev, Int Ctr Neuromorph Syst, Kingswood, NSW 2751, Australia.
   [Singh Thakur, Chetan] Indian Inst Sci, Dept Elect Syst Engn, Bangalore 560012, Karnataka, India.
   [Hamilton, Tara Julia] Univ Technol Sydney, Sch Elect & Data Engn, Sydney, NSW 2000, Australia.
RP Xu, Y; van Schaik, A (corresponding author), Western Sydney Univ, MARCS Inst Brain Behav & Dev, Int Ctr Neuromorph Syst, Kingswood, NSW 2751, Australia.
EM ying.xu@westernsydney.edu.au; S.Afshar@westernsydney.edu.au;
   mark.wang@westernsydney.edu.au; G.Cohen@westernsydney.edu.au;
   csthakur@iisc.ac.in; tara.hamilton@uts.edu.au;
   a.vanschaik@westernsydney.edu.au
CR Al-Rfou Rami, 2016, ABS160502688 ARXIV
   Ashida G, 2011, CURR OPIN NEUROBIOL, V21, P745, DOI 10.1016/j.conb.2011.05.008
   BATRA R, 1989, J NEUROPHYSIOL, V61, P257, DOI 10.1152/jn.1989.61.2.257
   BHADKAMKAR N, 1993, 1993 IEEE INTERNATIONAL CONFERENCE ON NEURAL NETWORKS, VOLS 1-3, P1902, DOI 10.1109/ICNN.1993.298847
   Burnham D, 2011, 12TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2011 (INTERSPEECH 2011), VOLS 1-5, P848
   Carlile S, 1997, HEARING RES, V114, P179, DOI 10.1016/S0378-5955(97)00161-5
   CASSEDAY JH, 1973, J ACOUST SOC AM, V54, P365, DOI 10.1121/1.1913586
   Escudero EC, 2018, NEUROCOMPUTING, V283, P129, DOI 10.1016/j.neucom.2017.12.041
   Chan VYS, 2010, FRONT NEUROSCI-SWITZ, V4, DOI 10.3389/fnins.2010.00196
   Chi T, 2005, J ACOUST SOC AM, V118, P887, DOI 10.1121/1.1945807
   Cox F.M., P 2008 HCSNET WORKSH, P96
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   Finger H, 2011, IEEE INT SYMP CIRC S, P2461
   Grech I, 2004, ANALOG INTEGR CIRC S, V41, P167, DOI 10.1023/B:ALOG.0000041634.92147.0d
   GREENWOOD DD, 1990, J ACOUST SOC AM, V87, P2592, DOI 10.1121/1.399052
   Grothe B, 2000, J COMP PHYSIOL A, V186, P413, DOI 10.1007/s003590050441
   Grothe B, 2010, PHYSIOL REV, V90, P983, DOI 10.1152/physrev.00026.2009
   Heckmann M, 2006, 2006 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-12, P368, DOI 10.1109/IROS.2006.281758
   HENNING GB, 1974, J ACOUST SOC AM, V55, P84, DOI 10.1121/1.1928135
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Iwasa K, 2007, IEEE IJCNN, P902, DOI 10.1109/IJCNN.2007.4371078
   JEFFRESS LA, 1948, J COMP PHYSIOL PSYCH, V41, P35, DOI 10.1037/h0061495
   Jiang SL, 2020, J ENG-JOE, V2020, P511, DOI 10.1049/joe.2019.1207
   Joris PX, 2019, ANNU REV NEUROSCI, V42, P433, DOI 10.1146/annurev-neuro-080317-061925
   Joris PX, 1996, J NEUROPHYSIOL, V76, P2137, DOI 10.1152/jn.1996.76.4.2137
   Julián P, 2006, IEEE T VLSI SYST, V14, P207, DOI 10.1109/TVLSI.2005.863740
   Kala S, 2019, IEEE T VLSI SYST, V27, P2816, DOI 10.1109/TVLSI.2019.2941250
   Katsiamis AG, 2007, EURASIP J AUDIO SPEE, DOI 10.1155/2007/63685
   Ko T, 2015, 16TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION (INTERSPEECH 2015), VOLS 1-5, P3586
   Kugler M, 2008, LECT NOTES COMPUT SC, V4985, P577
   Kuwada S., 2012, LIMITS LIMITS EVERYW
   Lazzaro J, 1989, NEURAL COMPUT, V1, P47, DOI 10.1162/neco.1989.1.1.47
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Rayleigh,, 1907, PHILOS MAG, V13, P214, DOI 10.1080/14786440709463595
   Lyon RF, 2017, HUMAN AND MACHINE HEARING: EXTRACTING MEANING FROM SOUND, DOI 10.1017/9781139051699
   Lyon R. F., 1983, Proceedings of ICASSP 83. IEEE International Conference on Acoustics, Speech and Signal Processing, P1148
   Lyon RF, 2011, J ACOUST SOC AM, V130, P3893, DOI 10.1121/1.3658470
   Ma N, 2017, IEEE-ACM T AUDIO SPE, V25, P2444, DOI 10.1109/TASLP.2017.2750760
   McDonnell MD, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0134254
   MEAD CA, 1991, IEEE T NEURAL NETWOR, V2, P230, DOI 10.1109/72.80333
   MIDDLEBROOKS JC, 1991, ANNU REV PSYCHOL, V42, P135, DOI 10.1146/annurev.ps.42.020191.001031
   Park TJ, 2004, J NEUROPHYSIOL, V92, P289, DOI 10.1152/jn.00961.2003
   Ponca M, 2001, SPRING COMP SCI, P212
   Ruder S, 2016, ARXIV160904747, P1
   Schauer C, 2000, INT CONF ACOUST SPEE, P865
   Seidner D, 2008, 2008 IEEE INTERNATIONAL CONFERENCE ON MICROWAVES, COMMUNICATIONS, ANTENNAS AND ELECTRONIC SYSTEMS, P146
   SHAMMA SA, 1989, J ACOUST SOC AM, V86, P989, DOI 10.1121/1.398734
   Singh RK, 2019, IEEE T CIRCUITS-I, V66, P1805, DOI 10.1109/TCSI.2018.2868247
   Singh RK, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351394
   Sun J.(, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   The Theano Development Team, 2016, THEANO PYTHON FRAMEW
   van Schaik A, 2004, ANALOG INTEGR CIRC S, V39, P267, DOI 10.1023/B:ALOG.0000029662.37528.c7
   van Schaik A, 2015, NEUROCOMPUTING, V149, P233, DOI 10.1016/j.neucom.2014.01.071
   WALLACH H, 1949, AM J PSYCHOL, V62, P315, DOI 10.2307/1418275
   Wang J, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-0171-y
   Wang R, 2016, BIOMED CIRC SYST C, P560, DOI 10.1109/BioCAS.2016.7833856
   Wühle T, 2019, J AUDIO ENG SOC, V67, P92, DOI 10.17743/jaes.2018.0074
   Xiao Y., 2013, P IEEE 9 INT C SOGN
   Xu Y., 2016, IET 13 INT C DEV POW, P1
   Xu Y, 2019, IEEE INT SYMP CIRC S, DOI 10.1109/iscas.2019.8702345
   Xu Y, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351367
   Xu Y, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00198
   Yin TCT, 2002, SPR HDB AUD, V15, P99
   Youssef K, 2013, IEEE INT C INT ROBOT, P2927, DOI 10.1109/IROS.2013.6696771
   Zhou J, 2016, IEEE COMPUT SOC CONF, P1535, DOI 10.1109/CVPRW.2016.191
   ZWISLOCKI J, 1956, J ACOUST SOC AM, V28, P860, DOI 10.1121/1.1908495
NR 66
TC 4
Z9 4
U1 3
U2 6
PD FEB
PY 2021
VL 11
IS 4
AR 1519
DI 10.3390/app11041519
WC Chemistry, Multidisciplinary; Engineering, Multidisciplinary; Materials
   Science, Multidisciplinary; Physics, Applied
DA 2023-11-11
ER

PT J
AU Wu, N
   Deng, L
   Li, GQ
   Xie, Y
AF Wu, Nan
   Deng, Lei
   Li, Guoqi
   Xie, Yuan
TI Core Placement Optimization for Multi-chip Many-core Neural Network
   Systems with Reinforcement Learning
SO ACM TRANSACTIONS ON DESIGN AUTOMATION OF ELECTRONIC SYSTEMS
DT Article
DE Multi-chip many-core architecture; neural network accelerator; core
   placement optimization; machine learning for system
ID DESIGN SPACE; ON-CHIP; REGRESSION
AB Multi-chip many-core neural network systems are capable of providing high parallelism benefited from decentralized execution, and they can be scaled to very large systems with reasonable fabrication costs. As multi-chip many-core systems scale up, communication latency related effects will take a more important portion in the system performance. While previous work mainly focuses on the core placement within a single chip, there are two principal issues still unresolved: the communication-related problems caused by the non-uniform, hierarchical on/off-chip communication capability in multi-chip systems, and the scalability of these heuristic-based approaches in a factorially growing search space. To this end, we propose a reinforcement-learning-based method to automatically optimize core placement through deep deterministic policy gradient, taking into account information of the environment by performing a series of trials (i.e., placements) and using convolutional neural networks to extract spatial features of different placements. Experimental results indicate that compared with a naive sequential placement, the proposed method achieves 1.99x increase in throughput and 50.5% reduction in latency; compared with the simulated annealing, an effective technique to approximate the global optima in an extremely large search space, our method improves the throughput by 1.22x and reduces the latency by 18.6%. We further demonstrate that our proposed method is capable to find optimal placements taking advantages of different communication properties caused by different system configurations, and work in a topology-agnostic manner.
C1 [Wu, Nan; Deng, Lei; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Li, Guoqi] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM nanwu@ucsb.edu; leideng@ucsb.edu; liguoqi@mail.tsinghua.edu.cn;
   yuanxie@ucsb.edu
CR Addanki R., 2018, P NIPS MACH LEARN SY
   Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2019, P 36 INT C MACH LEAR
   [Anonymous], 2016, THE 49TH ANNUAL IEEE
   [Anonymous], ABS151203385 CORR
   [Anonymous], 2010, PROC ANN IEEE INDIA
   [Anonymous], 2016, NAT METHODS, DOI DOI 10.1038/nmeth.3707
   [Anonymous], 2018, ARXIV180904070
   [Anonymous], 2015, P ACM GREAT LAKES S
   Bailey PE, 2014, PROC INT CONF PARAL, P371, DOI 10.1109/ICPP.2014.46
   Beckmann N, 2017, INT S HIGH PERF COMP, P109, DOI 10.1109/HPCA.2017.43
   BELLMAN R, 1957, J MATH MECH, V6, P679, DOI 10.1512/iumj.1957.6.56038
   Beukema T, 2005, IEEE J SOLID-ST CIRC, V40, P2633, DOI 10.1109/JSSC.2005.856584
   Bhatia E, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P1, DOI 10.1145/3307650.3322207
   Boni A, 2001, IEEE J SOLID-ST CIRC, V36, P706, DOI 10.1109/4.913751
   Carrillo S, 2013, IEEE T PARALL DISTR, V24, P2451, DOI 10.1109/TPDS.2012.289
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Demme John, 2013, SIGARCH COMPUT ARCHI, P559, DOI [10.1145/2485922.2485970, DOI 10.1145/2508148.2485970]
   Deng L, 2020, IEEE J SOLID-ST CIRC, V55, P2228, DOI 10.1109/JSSC.2020.2970709
   Deng L, 2020, IEEE T COMPUT AID D, V39, P117, DOI 10.1109/TCAD.2018.2883959
   Ding Y, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P39, DOI 10.1145/3307650.3326633
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Fettes Q, 2019, IEEE T COMPUT, V68, P375, DOI 10.1109/TC.2018.2875476
   Gao Y., 2018, P INT C MACH LEARN, V80, P1662
   Gao Yuanxiang, 2018, ADV NEURAL INFORM PR, P9971
   Garey M. R., 1979, COMPUTERS INTRACTABI
   Garza E, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P27, DOI 10.1145/3307650.3322217
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hashemi Milad, 2018, P INT C MACH LEARN, P1924
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hoffmann H, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P198, DOI 10.1145/2815400.2815403
   Hu JC, 2005, IEEE T COMPUT AID D, V24, P551, DOI 10.1109/TCAD.2005.844106
   Hu JC, 2003, ASP-DAC 2003: PROCEEDINGS OF THE ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE, P233, DOI 10.1109/ASPDAC.2003.1195022
   Hunt JJ., 2015, CONTINUOUS CONTROL D
   Hwangbo J, 2019, SCI ROBOT, V4, DOI 10.1126/scirobotics.aau5872
   Ipek Engin, 2006, EFFICIENTLY EXPLORIN, V41
   Jiménez DA, 2011, 2011 IEEE 29TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P113, DOI 10.1109/ICCD.2011.6081385
   Jooya A, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P659, DOI 10.1109/HPCSim.2016.7568398
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim J, 2008, CONF PROC INT SYMP C, P77, DOI 10.1109/ISCA.2008.19
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y., 2010, MNIST HANDWRITTEN DI
   Lee BC, 2007, INT S HIGH PERF COMP, P340
   Lee BC, 2008, INT SYMP MICROARCH, P270, DOI 10.1109/MICRO.2008.4771797
   Lee MKF, 2019, ACM T ARCHIT CODE OP, V15, DOI 10.1145/3291054
   Lei T, 2003, EUROMICRO SYMPOSIUM ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P180
   Lin TR, 2019, IEEE COMPUT ARCHIT L, V18, P51, DOI 10.1109/LCA.2019.2905587
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Mendis C., 2019, ADV NEURAL INFORM PR, P14598
   Mirhoseini A, 2017, PR MACH LEARN RES, V70
   Mirhoseini Azalia, 2018, P 35 INT C MACH LEAR
   Mishra N, 2017, 2017 IEEE INTERNATIONAL CONFERENCE ON AUTOMATIC COMPUTING (ICAC), P125, DOI 10.1109/ICAC.2017.29
   Murali S, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P896, DOI 10.1109/DATE.2004.1269002
   Ozsoy M, 2016, IEEE T COMPUT, V65, P3332, DOI 10.1109/TC.2016.2540634
   Painkras E, 2013, IEEE J SOLID-ST CIRC, V48, P1943, DOI 10.1109/JSSC.2013.2259038
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Pei J, 2019, NATURE, V572, P106, DOI 10.1038/s41586-019-1424-8
   Rao N, 2018, INT SYM COMP ARCHIT, P1, DOI [10.1109/CAHPC.2018.8645914, 10.1109/SBAC-PAD.2018.00015]
   Schulman J, 2017, PROXIMAL POLICY OPTI
   Shao YKS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P14, DOI 10.1145/3352460.3358302
   Sharma PK, 2019, MICROPROCESS MICROSY, V64, P88, DOI 10.1016/j.micpro.2018.10.008
   Shen WT, 2007, NOCS 2007: FIRST INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, PROCEEDINGS, P317
   Shi Z, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P413, DOI 10.1145/3352460.3358319
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Silver D, 2014, P 31 INT C INT C MAC, V32
   Silver D, 2017, NATURE, V550, P354, DOI 10.1038/nature24270
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2019, INT S HIGH PERF COMP, P56, DOI 10.1109/HPCA.2019.00027
   Stock K, 2012, ACM T ARCHIT CODE OP, V8, DOI 10.1145/2086696.2086729
   Sutskever I., 2014, ADV NEUR IN, P3104
   Sutton RS, 2018, ADAPT COMPUT MACH LE, P1
   Sutton RS, 2000, ADV NEUR IN, V12, P1057
   Teran E, 2016, P 49 ANN IEEE ACM IN, P1
   Uhlenbeck GE, 1930, PHYS REV, V36, P0823, DOI 10.1103/PhysRev.36.823
   Urgese G, 2018, IEEE T EMERG TOP COM, V6, P317, DOI 10.1109/TETC.2016.2579605
   Van Laarhoven Peter JM, 1987, SIMULATED ANNEALING, P3, DOI DOI 10.1007/978-94-015-7744-1_2
   Vinyals O, 2019, NATURE, V575, P350, DOI 10.1038/s41586-019-1724-z
   Volodymyr Mnih, 2013, ARXIV PREPRINT ARXIV, DOI DOI 10.48550/ARXIV.1312.5602
   Wang K, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P589, DOI 10.1145/3307650.3322274
   WATKINS CJCH, 1992, MACH LEARN, V8, P279, DOI 10.1007/BF00992698
   Wenhao Jia, 2012, 2012 IEEE International Symposium on Performance Analysis of Systems & Software (ISPASS), P2, DOI 10.1109/ISPASS.2012.6189201
   WHITLEY D, 1994, STAT COMPUT, V4, P65, DOI 10.1007/BF00175354
   WILLIAMS RJ, 1992, MACH LEARN, V8, P229, DOI 10.1007/BF00992696
   Wilson JM, 2018, ISSCC DIG TECH PAP I, P276, DOI 10.1109/ISSCC.2018.8310291
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
   Yigitbasi N, 2013, I S MOD ANAL SIM COM, P11, DOI 10.1109/MASCOTS.2013.9
   Yogamani, 2017, ELECT IMAGING, P70
   Zeng Y, 2017, MEMSYS 2017: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P305, DOI 10.1145/3132402.3132405
   Zhang Haitao, 2018, P 47 INT C PAR PROC, P32
   Zimmer B, 2019, SYMP VLSI CIRCUITS, pC300, DOI [10.23919/VLSIC.2019.8778056, 10.23919/vlsic.2019.8778056]
NR 96
TC 7
Z9 8
U1 2
U2 13
PD FEB
PY 2021
VL 26
IS 2
AR 11
DI 10.1145/3418498
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering
DA 2023-11-11
ER

PT J
AU Que, ZQ
   Zhu, YX
   Fan, HX
   Meng, JX
   Niu, XY
   Luk, W
AF Que, Zhiqiang
   Zhu, Yongxin
   Fan, Hongxiang
   Meng, Jiuxi
   Niu, Xinyu
   Luk, Wayne
TI Mapping Large LSTMs to FPGAs with Weight Reuse
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE LSTM; FPGA; Hardware architecture
AB Long-Short Term Memory (LSTM) can retain memory and learn from data sequences. It gives state-of-the-art accuracy in many applications such as speech recognition, natural language processing and video classifications. Field-Programmable Gate Arrays (FPGAs) have been used to speed up the inference of LSTMs, but FPGA-based LSTM accelerators are limited by the size of on-chip memory and the bandwidth of external memory on FPGA boards. We propose a novel hardware architecture to overcome data dependency and a new blocking-batching strategy to reuse the LSTM weights fetched from external memory to optimize the performance of systems with size-limited on-chip memory for large machine learning models. Evaluation results show that our architecture can achieve 20.8 GOPS/W, which is among the highest for the FPGA-based LSTM designs storing weights in off-chip memory. Our design achieves 1.65 times higher performance-per-watt efficiency and 2.48 times higher performance-per-DSP efficiency when compared with the current state-of-the-art designs of LSTM using weights stored in off-chip memory. Compared with CPU and GPU implementations, our FPGA implementation is 23.7 and 1.3 times faster while consuming 208 and 19.2 times lower energy respectively, which shows that our approach enables large LSTM systems to be processed efficiently on FPGAs with high performance and low power consumption.
C1 [Que, Zhiqiang; Fan, Hongxiang; Meng, Jiuxi; Luk, Wayne] Imperial Coll London, London, England.
   [Zhu, Yongxin] Chinese Acad Sci, Shanghai Adv Res Inst, Beijing, Peoples R China.
   [Niu, Xinyu] Corerain Technol Ltd, Shenzhen, Peoples R China.
RP Que, ZQ (corresponding author), Imperial Coll London, London, England.
EM z.que@imperial.ac.uk; zhuyongxin@sari.ac.cn; h.fan17@imperial.ac.uk;
   jiuxi.meng16@imperial.ac.uk; xinyu.niu@corerain.com;
   w.luk@imperial.ac.uk
CR Amin H, 1997, IEE P-CIRC DEV SYST, V144, P313, DOI 10.1049/ip-cds:19971587
   [Anonymous], 2016, RECURRENT BATCH NORM
   Ardakani A., 2018, LEARNING SKIP INEFFE
   Chang Andre Xian Ming, 2015, ARXIV151105552
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Eyben F., 2009, AUTOMATIC SPEECH REC
   Fan H., 2018, 28 INT C FIELD PROGR
   Fan H., 2019, IEEE 30 INT C APPL S
   Fan HX, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P17, DOI 10.1109/FPT.2018.00014
   Ferreira JC, 2016, PROC INT CONF RECON
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Guan YJ, 2017, ANN IEEE SYM FIELD P, P152, DOI 10.1109/FCCM.2017.25
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Li Z, 2019, INT S HIGH PERF COMP, P69, DOI 10.1109/HPCA.2019.00028
   Liu ZS, 2018, PROCEEDINGS OF THE ASME TURBO EXPO: TURBOMACHINERY TECHNICAL CONFERENCE AND EXPOSITION, 2018, VOL 2D
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Nurvitadhi E., 2017, P ACM INT S FIELD PR
   Nurvitadhi E, 2019, ANN IEEE SYM FIELD P, P199, DOI 10.1109/FCCM.2019.00035
   Nurvitadhi E, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577314
   Que Z., 2019, INT C FIELD PROGR TE
   Que ZQ, 2020, ANN IEEE SYM FIELD P, P10, DOI 10.1109/FCCM48280.2020.00011
   Que ZQ, 2019, IEEE INT CONF ASAP, P17, DOI 10.1109/ASAP.2019.00-42
   Rizakis M., 2018, APPROXIMATE FPGA BAS
   Rybalkin V., 2017, P C DES AUT TEST EUR
   Rybalkin V, 2018, I C FIELD PROG LOGIC, P89, DOI 10.1109/FPL.2018.00024
   Sun Z., 2018, IEEE INT C SMART CLO
   Wang S, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P11, DOI 10.1145/3174243.3174253
   Xiong P, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON SMART CLOUD (SMARTCLOUD), P13, DOI 10.1109/SmartCloud.2018.00011
   Zamir A. R., 2012, UCF101 DATASET 101 H
   Zhang C., 2019, P 2019 ACMSIGDA INT, DOI [10.1145/3289602.3293898, DOI 10.1145/3289602.3293898]
   Zhang M., 2018, 2018 USENIX ANN TECH
   Zhang Xiaofan, 2017, 2017 27 INT C FIELD, P1
   Zhao RZ, 2017, LECT NOTES COMPUT SC, V10216, P255, DOI 10.1007/978-3-319-56258-2_22
NR 36
TC 17
Z9 18
U1 0
U2 10
PD SEP
PY 2020
VL 92
IS 9
SI SI
BP 965
EP 979
DI 10.1007/s11265-020-01549-8
EA JUL 2020
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ko, GG
   Rutenbar, RA
AF Ko, Glenn G.
   Rutenbar, Rob A.
TI Real-Time and Low-Power Streaming Source Separation Using Markov Random
   Field
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE Real-time streaming; blind source separation; Markov random field;
   maximum a posteriori inference; Gibbs sampling
ID BLIND SIGNAL SEPARATION; FPGA; IMPLEMENTATION; ALGORITHM
AB Machine learning (ML) has revolutionized a wide range of recognition tasks, ranging from text analysis to speech to vision, most notably in cloud deployments. However, mobile deployment of these ideas involves a very different category of design problems. In this article, we develop a hardware architecture for a sound source separation task, intended for deployment on a mobile phone. We focus on a novel Markov random field (MRF) sound source separation algorithm that uses expectation-maximization and Gibbs sampling to learn MRF parameters on the fly and infer the best separation of sources. The intrinsically iterative algorithm suggests challenges for both speed and power. A real-time streaming FPGA implementation runs at 150MHz with 207KB RAM, achieves a speed-up of 22x over a software reference, performs with an SDR of up to 7.021dB with 1.601ms latency, and exhibits excellent perceived audio quality. A 45nm CMOS ASIC virtual prototype simulated at 20MHz shows that this architecture is small (<10 million gates) and consumes only 70mW, which is less than 2% of the power of an ARM Cortex-A9 software version. To the best of our knowledge, this is the first Gibbs sampling inference accelerator designed in conventional FPGA/ASIC technology that targets a realistic mobile perceptual application.
C1 [Ko, Glenn G.; Rutenbar, Rob A.] Univ Illinois, Urbana, IL 61801 USA.
   [Ko, Glenn G.] Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.
   [Rutenbar, Rob A.] Univ Pittsburgh, Pittsburgh, PA 15260 USA.
RP Ko, GG (corresponding author), Univ Illinois, Urbana, IL 61801 USA.; Ko, GG (corresponding author), Harvard Univ, 33 Oxford St, Cambridge, MA 02138 USA.
EM gko@seas.harvard.edu; rutenbar@pitt.edu
CR [Anonymous], 1998, INTRO MONTE CARLO ME
   [Anonymous], 2008, 2069 MITCSAILTR
   [Anonymous], TECHNICAL REPORT
   Bakos JD, 2010, COMPUT SCI ENG, V12, P80, DOI 10.1109/MCSE.2010.135
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Birchfield ST, 2005, INT CONF ACOUST SPEE, P1109
   Boykov YY, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P105, DOI 10.1109/ICCV.2001.937505
   Brewer TM, 2010, IEEE MICRO, V30, P70, DOI 10.1109/MM.2010.36
   Campbell D. R., 2005, Computing and Information Systems, V9, P48
   Cardoso JF, 1998, P IEEE, V86, P2009, DOI 10.1109/5.720250
   Charoensak C, 2005, IEEE INT SYMP CIRC S, P5822, DOI 10.1109/ISCAS.2005.1465962
   CHERRY EC, 1953, J ACOUST SOC AM, V25, P975, DOI 10.1121/1.1907229
   CULLER A, 1986, ANNU REV COMPUT SCI, V1, P225
   Das S, 2015, IEEE INT SYMP CIRC S, P2704, DOI 10.1109/ISCAS.2015.7169244
   DEMPSTER AP, 1977, J ROY STAT SOC B MET, V39, P1, DOI 10.1111/j.2517-6161.1977.tb01600.x
   Dennis J. B., 1975, 2nd Annual Symposium on Computer Architecture, P126
   Detrey J, 2007, MICROPROCESS MICROSY, V31, P537, DOI 10.1016/j.micpro.2006.02.008
   Garofolo J. S., 1993, P LING DAT CONSTR
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   GURD JR, 1985, COMMUN ACM, V28, P34, DOI 10.1145/2465.2468
   Gutierrez R, 2011, IEEE T VLSI SYST, V19, P2326, DOI 10.1109/TVLSI.2010.2081387
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton GE, 2006, NEURAL COMPUT, V18, P1527, DOI 10.1162/neco.2006.18.7.1527
   Holma Harri, 2011, LTE UMTS EVOLUTION L
   Hyvarinen A., 2004, INDEPENDENT COMPONEN, V46
   Kappes JH, 2013, PROC CVPR IEEE, P1328, DOI 10.1109/CVPR.2013.175
   Kim CM, 2003, IEEE T NEURAL NETWOR, V14, P1038, DOI 10.1109/TNN.2003.818381
   Kim M., 2012, P 9 INT C EXP EM TEC, P1, DOI DOI 10.1007/S00779-012-0543
   Ko GG, 2017, INT CONF ACOUST SPEE, P2477, DOI 10.1109/ICASSP.2017.7952602
   Koller D., 2009, PROBABILISTIC GRAPHI
   Kolmogorov V, 2006, IEEE T PATTERN ANAL, V28, P1568, DOI 10.1109/TPAMI.2006.200
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Minka T., 1998, EXPECTATION MAXIMIZA
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Neal RM, 1998, NATO ADV SCI I D-BEH, V89, P355
   PEARL J, 1988, PROBABILISTIC REASON
   Roman N, 2003, J ACOUST SOC AM, V114, P2236, DOI 10.1121/1.1610463
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI [10.1109/SMBV.2001.988771, 10.1023/A:1014573219977]
   Shyu KK, 2008, IEEE T NEURAL NETWOR, V19, P958, DOI 10.1109/TNN.2007.915115
   Suyi Li, 2009, 2009 WRI World Congress on Computer Science and Information Engineering, CSIE, P469, DOI 10.1109/CSIE.2009.999
   Szeliski R, 2008, IEEE T PATTERN ANAL, V30, P1068, DOI 10.1109/TPAMI.2007.70844
   Telecommunication Standardization Sector ITU, 2003, INT TEL CONN CIRC GE
   Tkacik Thomas E., 2003, HARDWARE RANDOM NUMB, P450, DOI [10.1007/3-540-36400-5_32, DOI 10.1007/3-540-36400-5_32]
   Vincent E, 2006, IEEE T AUDIO SPEECH, V14, P1462, DOI 10.1109/TSA.2005.858005
   Wang CH, 2013, COMPUT VIS IMAGE UND, V117, P1610, DOI 10.1016/j.cviu.2013.07.004
   Wang SY, 2016, CONF PROC INT SYMP C, P558, DOI 10.1109/ISCA.2016.55
   Yilmaz Ö, 2004, IEEE T SIGNAL PROCES, V52, P1830, DOI 10.1109/TSP.2004.828896
NR 48
TC 4
Z9 4
U1 0
U2 2
PD JUL
PY 2018
VL 14
IS 2
SI SI
AR 17
DI 10.1145/3183351
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Abdelsalam, AM
   Boulet, F
   Demers, G
   Langlois, JMP
   Cheriet, F
AF Abdelsalam, Ahmed M.
   Boulet, Felix
   Demers, Gabriel
   Langlois, J. M. Pierre
   Cheriet, Farida
BE Andrews, D
   Cumplido, R
   Feregrino, C
   Stroobandt, D
TI An Efficient FPGA-based Overlay Inference Architecture for Fully
   Connected DNNs
SO 2018 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY DEC 03-05, 2018
CL Cancun, MEXICO
DE Deep Learning; FPGAs; Hardware Accelerators; Deep Neural Networks;
   Quantization
AB Deep Neural Networks (DNNs) have gained significant popularity in several classification and regression applications. The massive computation and memory requirements of DNNs pose special challenges for FPGA implementation. Moreover, programming FPGAs requires hardware-specific knowledge that many machine-learning researchers do not possess. To make the power and versatility of FPGAs available to a wider DNN user community and to improve DNN design efficiency, we introduce a Single hidden layer Neural Network (SNN) multiplication-free overlay architecture with fully connected DNN-level performance. This FPGA inference overlay can be used for applications that are normally solved with fully connected DNNs. The overlay avoids the time needed to synthesize, place, route and regenerate a new bitstream when the application changes. The SNN overlay inputs and activations are quantized to power-of-two values, which allows utilizing shift units instead of multipliers. Since the overlay is a SNN, we fill the FPGA chip with the maximum possible number of neurons that can work in parallel in the hidden layer. On a ZYNQ-7000 ZC706 FPGA, it is thus possible to implement 2450 neurons in the hidden layer and 30 neurons in the output layer. We evaluate the proposed architecture on typical benchmark datasets and demonstrate higher throughput with respect to the state-of-the-art while achieving the same accuracy.
C1 [Abdelsalam, Ahmed M.; Boulet, Felix; Demers, Gabriel; Langlois, J. M. Pierre; Cheriet, Farida] Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
RP Abdelsalam, AM (corresponding author), Polytech Montreal, Dept Comp & Software Engn, Montreal, PQ, Canada.
EM ahmed.abdelsalam@polymtl.ca; felix.boulet@polymtl.ca;
   gabriel.demers@polymtl.ca; pierre.langlois@polymtl.ca;
   farida.cheriet@polymtl.ca
CR Abdelsalam A. M., 2017, IEEE FCCM
   Alemdar H., 2017, IEEE INT JOINT C NEU
   [Anonymous], 2015, 151000149 ARXIV
   [Anonymous], 1998, P IEEE
   [Anonymous], 1991, NEURAL NETWORKS
   [Anonymous], 2014, ADV NEURAL INFORM PR
   [Anonymous], 2016, ARXIV160702241
   Brant A., 2012, IEEE FCCM
   Courbariaux M., 2016, 160202830 ARXIV
   Gudovskiy D. A., 2017, 170602393 ARXIV
   Gupta S., 2015, INT C MACH LEARN AUG
   Hunter D., 2012, IEEE T IND INFOR MAY
   Kwan H. K., 1993, IEEE MWSCAS
   Lacey G., 2016, 160204283 ARXIV
   Lecun Yann, 2015, NATURE
   Misra J., 2010, NEUROCOMPUTING
   Nurvitadhi E., 2017, ACM SIGDA ISFPGA
   Park J., 2016, IEEE ICASSP
   Rastegari M., 2016, SPRING EUR C COMP VI
   Razlighi M. S., 2017, IEEE DES AUT TEST EU
   Sze V., 2017, 170309039 ARXIV
   Sze V., 2016, 161207625 ARXIV
   Tann H., 2017, ACM ANN DES AUT C JU
   Umuroglu Y., 2017, ACM SIGDA ISFPGA
   Xilinx, AXI REF GUID
NR 25
TC 6
Z9 6
U1 0
U2 3
PY 2018
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Chammas, S
   Wang, Q
   Schneider, T
   Ihme, M
   Chen, YF
   Anderson, J
AF Chammas, Sheide
   Wang, Qing
   Schneider, Tapio
   Ihme, Matthias
   Chen, Yi-fan
   Anderson, John
TI Accelerating Large-Eddy Simulations of Clouds With Tensor Processing
   Units
SO JOURNAL OF ADVANCES IN MODELING EARTH SYSTEMS
DT Article
DE large-eddy simulation; stratocumulus clouds; tensor processing units;
   numerical methods
ID RADIATIVE-CONVECTIVE EQUILIBRIUM; GENERAL-CIRCULATION; HYDROLOGICAL
   CYCLE; ANELASTIC APPROXIMATION; NUMERICAL-SIMULATION; GLOBAL
   CIRCULATIONS; CLIMATE SENSITIVITY; SHALLOW CUMULUS; DYNAMICAL RANGE;
   STRATOCUMULUS
AB Clouds, especially low clouds, are crucial for regulating Earth's energy balance and mediating the response of the climate system to changes in greenhouse gas concentrations. Despite their importance for climate, they remain relatively poorly understood and are inaccurately represented in climate models. A principal reason is that the high computational expense of simulating them with large-eddy simulations (LES) has inhibited broad and systematic numerical experimentation and the generation of large data sets for training parametrization schemes for climate models. Here we demonstrate LES of low clouds on tensor processing units (TPUs), application-specific integrated circuits that were originally developed for machine learning applications. We show that TPUs in conjunction with tailored software implementations can be used to simulate computationally challenging stratocumulus clouds in conditions observed during the Dynamics and Chemistry of Marine Stratocumulus (DYCOMS) field study. The TPU-based LES code successfully reproduces clouds during DYCOMS and opens up the large computational resources available on TPUs to cloud simulations. The code enables unprecedented weak and strong scaling of LES, making it possible, for example, to simulate stratocumulus with 10x speedup over real-time evolution in domains with a 34.7 km x 53.8 km horizontal cross section. The results open up new avenues for computational experiments and for substantially enlarging the sample of LES available to train parameterizations of low clouds.
   The study of clouds has been impeded by, among other factors, limitations in our ability to simulate them rapidly and on sufficiently large domains. In particular, computational limitations in simulating low clouds are among the reasons for the difficulties of representing them accurately in climate models; this is one of the dominant uncertainties in climate predictions. This paper demonstrates how the large computing power available on tensor processing units (TPUs) (integrated circuits originally designed for machine learning applications) can be harnessed for simulating low clouds. We demonstrate the largest simulations of low clouds to date, with hundreds of billions of variables, and we document their fidelity to aircraft observations. The results open up the large computational resources available on TPUs, hitherto primarily used for machine learning, to the study of clouds in the climate system.
   We introduce a large-eddy simulation (LES) framework that runs on tensor processing units (TPUs, accelerators designed for machine learning)The fidelity of the LES is established by reproducing aircraft observations of nocturnal stratocumulus clouds over the PacificThe LES exhibit unprecedented scalability on TPUs, enabling the large-scale generation of training data for cloud parameterizations
C1 [Chammas, Sheide; Wang, Qing; Schneider, Tapio; Ihme, Matthias; Chen, Yi-fan; Anderson, John] Google LLC, Mountain View, CA 94043 USA.
   [Schneider, Tapio] CALTECH, Pasadena, CA USA.
   [Ihme, Matthias] Stanford Univ, Stanford, CA USA.
RP Chammas, S (corresponding author), Google LLC, Mountain View, CA 94043 USA.
EM sheide@google.com
CR Allen MR, 2002, NATURE, V419, P224, DOI 10.1038/nature01092
   Balaji V, 2021, PHILOS T R SOC A, V379, DOI 10.1098/rsta.2020.0085
   Bannon PR, 1996, J ATMOS SCI, V53, P3618, DOI 10.1175/1520-0469(1996)053<3618:OTAAFA>2.0.CO;2
   Belletti F, 2020, Arxiv, DOI arXiv:1906.02818
   Blossey PN, 2016, J ADV MODEL EARTH SY, V8, P1714, DOI 10.1002/2016MS000765
   Blossey PN, 2013, J ADV MODEL EARTH SY, V5, P234, DOI 10.1002/jame.20025
   Bony S, 2005, GEOPHYS RES LETT, V32, DOI 10.1029/2005GL023851
   Bretherton CS, 2015, PHILOS T R SOC A, V373, DOI 10.1098/rsta.2014.0415
   Bretherton CS, 1999, Q J ROY METEOR SOC, V125, P391, DOI 10.1002/qj.49712555402
   Brient F, 2016, J CLIMATE, V29, P5821, DOI 10.1175/JCLI-D-15-0897.1
   Brient F, 2016, CLIM DYNAM, V47, P433, DOI 10.1007/s00382-015-2846-0
   Bryan GH, 2004, MON WEATHER REV, V132, P2421, DOI 10.1175/1520-0493(2004)132<2421:AROIWP>2.0.CO;2
   Caldwell P, 2009, J ATMOS SCI, V66, P432, DOI 10.1175/2008JAS2785.1
   CESS RD, 1990, J GEOPHYS RES-ATMOS, V95, P16601, DOI 10.1029/JD095iD10p16601
   Cess RD, 1996, J GEOPHYS RES-ATMOS, V101, P12791, DOI 10.1029/96JD00822
   Charney JG., 1950, TELLUS, V2, P237, DOI [DOI 10.1111/J.2153-3490.1950.TB00336.X, 10.1111/j.2153-3490.1950.tb00336.x, DOI 10.3402/TELLUSA.V2I4.8607]
   Chou C, 2004, J CLIMATE, V17, P2688, DOI [10.1175/1520-0442(2004)017<2688:MOGWIO>2.0.CO;2, 10.1175/1520-0442(2004)017&lt;2688:MOGWIO&gt;2.0.CO;2]
   Couvreux F, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002217
   Cronin T., 2014, THESIS MIT
   Cronin TW, 2015, Q J ROY METEOR SOC, V141, P1017, DOI 10.1002/qj.2443
   Dufresne JL, 2008, J CLIMATE, V21, P5135, DOI 10.1175/2008JCLI2239.1
   DURRAN DR, 1982, J ATMOS SCI, V39, P2152, DOI 10.1175/1520-0469(1982)039<2152:OTEOMO>2.0.CO;2
   DURRAN DR, 1983, MON WEATHER REV, V111, P2341, DOI 10.1175/1520-0493(1983)111<2341:ACMFTS>2.0.CO;2
   Ham F., 2004, ANN RES BRIEFS, P3
   Held IM, 1999, TELLUS A, V51, P59, DOI 10.1034/j.1600-0870.1999.t01-1-00006.x
   HELD IM, 1993, J ATMOS SCI, V50, P3909, DOI 10.1175/1520-0469(1993)050<3909:RCEWET>2.0.CO;2
   Held IM, 1996, J ATMOS SCI, V53, P946, DOI 10.1175/1520-0469(1996)053<0946:ASTFHH>2.0.CO;2
   Held IM, 2006, J CLIMATE, V19, P5686, DOI 10.1175/JCLI3990.1
   Hourdin F, 2021, J ADV MODEL EARTH SY, V13, DOI 10.1029/2020MS002225
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KLEMP JB, 1978, J ATMOS SCI, V35, P78, DOI 10.1175/1520-0469(1978)035<0078:NSOHMW>2.0.CO;2
   LILLY DK, 1962, TELLUS, V14, P148, DOI 10.3402/tellusa.v14i2.9537
   Lopez-Gomez I, 2022, J ADV MODEL EARTH SY, V14, DOI 10.1029/2022MS003105
   Lu TJ, 2020, Arxiv, DOI arXiv:2002.03260
   MANABE S, 1975, J ATMOS SCI, V32, P3, DOI 10.1175/1520-0469(1975)032<0003:TEODTC>2.0.CO;2
   Manabe S., 1965, MON WEA REV, V93, P769, DOI [DOI 10.1175/1520-0493(1965)093<0769:SCOAGC>2.3.CO;2, 10.1175/1520-0493(1965)0932.3.CO;2]
   Matheou G, 2018, ATMOSPHERE-BASEL, V9, DOI 10.3390/atmos9100392
   Mellado JP, 2018, J ADV MODEL EARTH SY, V10, P1421, DOI 10.1029/2018MS001312
   Mellado JP, 2017, ANNU REV FLUID MECH, V49, P145, DOI 10.1146/annurev-fluid-010816-060231
   Mishra S, 2021, COMMUN COMPUT PHYS, V29, P1299, DOI 10.4208/cicp.OA-2020-0046
   Morinishi Y, 1998, J COMPUT PHYS, V143, P90, DOI 10.1006/jcph.1998.5962
   National Academies of Sciences Engineering and Medicine, 2022, AUT RES WORKFL ACC D
   O'Gorman PA, 2008, J CLIMATE, V21, P3815, DOI 10.1175/2007JCLI2065.1
   Pauluis O, 2008, J ATMOS SCI, V65, P2719, DOI 10.1175/2007JAS2475.1
   Pederson R, 2023, J CHEM THEORY COMPUT, V19, P25, DOI 10.1021/acs.jctc.2c00876
   Phillips N.A., 1954, TELLUS, V6, P273, DOI [10.1111/j.2153-3490.1954.tb01123.x, DOI 10.1111/J.2153-3490.1954.TB01123.X]
   PHILLIPS NA, 1956, Q J ROY METEOR SOC, V82, P123, DOI 10.1002/qj.49708235202
   Pierce C.D., 2001, PROGR VARIABLE APPRO
   Pressel KG, 2017, J ADV MODEL EARTH SY, V9, P1342, DOI 10.1002/2016MS000778
   Pressel KG, 2015, J ADV MODEL EARTH SY, V7, P1425, DOI 10.1002/2015MS000496
   Qingwang John, 2023, Zenodo, DOI 10.5281/ZENODO.7569544
   RANDALL DA, 1984, B AM METEOROL SOC, V65, P1290, DOI 10.1175/1520-0477(1984)065<1290:OFROSM>2.0.CO;2
   Rauber RM, 2007, B AM METEOROL SOC, V88, P1912, DOI 10.1175/BAMS-88-12-1912
   RHINES PB, 1979, ANNU REV FLUID MECH, V11, P401, DOI 10.1146/annurev.fl.11.010179.002153
   RHINES PB, 1975, J FLUID MECH, V69, P417, DOI 10.1017/S0022112075001504
   RIND D, 1992, NATURE, V358, P119, DOI 10.1038/358119a0
   Sandu I, 2011, J ATMOS SCI, V68, P1865, DOI 10.1175/2011JAS3614.1
   Schalkwijk J, 2015, B AM METEOROL SOC, V96, P715, DOI 10.1175/BAMS-D-14-00114.1
   Schneider T, 2006, J ATMOS SCI, V63, P1569, DOI 10.1175/JAS3699.1
   Schneider T, 2006, ANNU REV EARTH PL SC, V34, P655, DOI 10.1146/annurev.earth.34.031405.125144
   Schneider T, 2019, NAT GEOSCI, V12, P163, DOI 10.1038/s41561-019-0310-1
   Schneider T, 2017, NAT CLIM CHANGE, V7, P3, DOI 10.1038/nclimate3190
   Schneider T, 2010, REV GEOPHYS, V48, DOI 10.1029/2009RG000302
   Shen ZY, 2022, J ADV MODEL EARTH SY, V14, DOI 10.1029/2021MS002631
   Siebesma AP, 2003, J ATMOS SCI, V60, P1201, DOI 10.1175/1520-0469(2003)60<1201:ALESIS>2.0.CO;2
   Smagorinsky J., 1965, MON WEATHER REV, V93, P727, DOI DOI 10.1175/1520-0493(1965)093<0727:NRFANL>2.3.CO;2
   Smagorinsky J.S., 1963, MON WEATHER REV, V91, P99, DOI [10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2, DOI 10.1175/1520-0493(1963)091<0099:GCEWTP>2.3.CO;2, 10.1175/1520-0493(1963)091andlt;0099:GCEWTPandgt;2.3.CO;2, DOI 10.1175/1520-0493(1963)0912.3.CO;2]
   Sridhar A, 2022, GEOSCI MODEL DEV, V15, P6259, DOI 10.5194/gmd-15-6259-2022
   Stevens B, 2005, ANNU REV EARTH PL SC, V33, P605, DOI 10.1146/annurev.earth.33.092203.122658
   Stevens B, 2005, MON WEATHER REV, V133, P1443, DOI 10.1175/MWR2930.1
   Stevens B, 2003, Q J ROY METEOR SOC, V129, P3469, DOI 10.1256/qj.02.202
   Stevens DE, 1996, J COMPUT PHYS, V129, P284, DOI 10.1006/jcph.1996.0250
   STRAKA JM, 1993, INT J NUMER METH FL, V17, P1, DOI 10.1002/fld.1650170103
   Tan ZH, 2017, J ADV MODEL EARTH SY, V9, P19, DOI 10.1002/2016MS000804
   Tan ZH, 2016, J ADV MODEL EARTH SY, V8, P1565, DOI 10.1002/2016MS000655
   TAO WK, 1989, MON WEATHER REV, V117, P231, DOI 10.1175/1520-0493(1989)117<0231:AIWSA>2.0.CO;2
   Tompkins AM, 1998, Q J ROY METEOR SOC, V124, P2073, DOI 10.1002/qj.49712455013
   TRIPOLI GJ, 1981, MON WEATHER REV, V109, P1094, DOI 10.1175/1520-0493(1981)109<1094:TUOLLW>2.0.CO;2
   Vial J, 2013, CLIM DYNAM, V41, P3339, DOI 10.1007/s00382-013-1725-9
   Wang Q, 2022, COMPUT PHYS COMMUN, V274, DOI 10.1016/j.cpc.2022.108292
   Webb MJ, 2006, CLIM DYNAM, V27, P17, DOI 10.1007/s00382-006-0111-2
   Webb MJ, 2013, CLIM DYNAM, V40, P677, DOI 10.1007/s00382-012-1336-x
   Williams G. P., 1988, CLIM DYNAM, V3, P45, DOI 10.1007/BF01080901
   Williams G. P., 1988, CLIM DYNAM, V2, P205, DOI 10.1007/bf01371320
   Wing AA, 2018, GEOSCI MODEL DEV, V11, P793, DOI 10.5194/gmd-11-793-2018
   Wood R, 2012, MON WEATHER REV, V140, P2373, DOI 10.1175/MWR-D-11-00121.1
   ZALESAK ST, 1979, J COMPUT PHYS, V31, P335, DOI 10.1016/0021-9991(79)90051-2
   Zelinka MD, 2017, NAT CLIM CHANGE, V7, P674, DOI 10.1038/nclimate3402
   Zhang MH, 2013, J ADV MODEL EARTH SY, V5, P826, DOI 10.1002/2013MS000246
   Zhang MH, 2012, J ADV MODEL EARTH SY, V4, DOI 10.1029/2012MS000182
NR 90
TC 0
Z9 0
U1 0
U2 0
PD OCT
PY 2023
VL 15
IS 10
AR e2023MS003619
DI 10.1029/2023MS003619
WC Meteorology & Atmospheric Sciences
DA 2023-11-11
ER

PT J
AU Kaul, A
   Luo, YD
   Peng, XC
   Manley, M
   Luo, YC
   Yu, SM
   Bakir, MS
AF Kaul, Ankit
   Luo, Yandong
   Peng, Xiaochen
   Manley, Madison
   Luo, Yuan-Chun
   Yu, Shimeng
   Bakir, Muhannad S.
TI 3-D Heterogeneous Integration of RRAM-Based Compute-In-Memory: Impact of
   Integration Parameters on Inference Accuracy
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE Reliability; Common Information Model (electricity); Solid modeling;
   Semiconductor device modeling; Benchmark testing; Performance
   evaluation; Junctions; 3-D heterogeneous integration (3-D-HI);
   compute-in-memory (CIM); emerging nonvolatile memory (eNVM);
   machine-learning accelerator; RRAM reliability; thermal-induced
   retention drift
ID SILICON; DESIGN
AB Three-dimensional heterogeneous integration (3-D-HI) has been proposed as a potential method to stack a large amount of embedded memory required in state-of-the-art compute-in-memory (CIM) artificial intelligence (AI) accelerators. While embedded nonvolatile memory, such as resistive RAM (RRAM), is a promising alternative to static random access memory (SRAM)/dynamic random access memory (DRAM) as a CIM synaptic device owing to high density, low leakage, and nondestructive read, thermal-induced device conductance drift remains a challenge. High-temperature-driven lower retention can be more significant in dense memory-logic 3-D integration due to increased volumetric power, which has not been studied in prior work. The scope of this work is to quantify the thermal impact of different 3-D-HI architectures on the reliability of 3-D-integrated binary RRAM devices for CIM applications. A device-integration-application reliability evaluation methodology is proposed, using which 3-D integration architectures and logic-memory partitioning configurations are benchmarked. Due to higher junction temperatures for memory tier in both five-tier monolithic 3-D (M3D) and five-tier through silicon via (TSV)-based 3-D compared to the 2-D baseline, the drop in inference accuracy at ten years is asymptotic to 80%. For our assumed device, integration, and application parameters, a three-tier configuration provides a balanced design option between thermal and application performance.
C1 [Kaul, Ankit; Luo, Yandong; Peng, Xiaochen; Manley, Madison; Luo, Yuan-Chun; Yu, Shimeng; Bakir, Muhannad S.] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
RP Kaul, A (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM ankit.kaul@gatech.edu; mbakir@ece.gatech.edu
CR [Anonymous], 2016, PROC IEEE INT 3D SYS, DOI DOI 10.1109/3DIC.2016.7969996
   Athikulwongse K, 2010, ICCAD-IEEE ACM INT, P669, DOI 10.1109/ICCAD.2010.5654245
   Brunschwiler T, 2017, INT EL DEVICES MEET, DOI 10.1109/IEDM.2017.8268322
   Chen PY, 2015, IEEE T ELECTRON DEV, V62, P4022, DOI 10.1109/TED.2015.2492421
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Games W, 2020, ISSCC DIG TECH PAP I, P144
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kaul A, 2022, PEDIATR NEPHROL, V37, P735, DOI 10.1007/s00467-021-05113-9
   Kaul A, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371983
   Kaul A, 2020, ELEC COMP C, P1459, DOI 10.1109/ECTC32862.2020.00231
   Kumar SS, 2017, IEEE T VLSI SYST, V25, P1549, DOI 10.1109/TVLSI.2016.2642587
   Lanza M, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800143
   LEE H, 2020, PROC IEEE GLOBECOM W, P1, DOI [DOI 10.1109/GCWkshps50303.2020.9367572, DOI 10.1109/GCWKSHPS50303.2020.9367572]
   Lee JC, 2016, INT SOC DESIGN CONF, P181, DOI 10.1109/ISOCC.2016.7799847
   Mathur R, 2021, IEEE J EXPLOR SOLID-, V7, P70, DOI 10.1109/JXCDC.2021.3092436
   Okoro C, 2007, ELEC COMP C, P249, DOI 10.1109/ECTC.2007.373805
   Peng XC, 2021, IEEE T ELECTRON DEV, V68, P5598, DOI 10.1109/TED.2021.3111857
   Peng XC, 2019, INT EL DEVICES MEET
   Rajan SK, 2021, IEEE T COMP PACK MAN, V11, P974, DOI 10.1109/TCPMT.2021.3082013
   Sarvey TE, 2019, IEEE T COMP PACK MAN, V9, P2393, DOI 10.1109/TCPMT.2019.2930481
   SHIM W, 2021, INT RELIAB PHY SYM
   Shulaker MM, 2017, NATURE, V547, P74, DOI 10.1038/nature22994
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   SINHA S, 2020, INT EL DEVICES MEET
   Sun PX, 2015, SCI REP-UK, V5, DOI [10.1038/srep13504, 10.1038/srep10001]
   Sun X, 2021, IEEE T ELECTRON DEV, V68, P5585, DOI 10.1109/TED.2021.3113300
   TUCKERMAN DB, 1981, ELECTRON DEVIC LETT, V2, P126, DOI 10.1109/EDL.1981.25367
   van Erp R, 2020, NATURE, V585, P211, DOI [10.1038/s41586-020-2666, 10.1038/s41586-020-2666-1]
   Wei TW, 2020, APPL THERM ENG, V164, DOI 10.1016/j.applthermaleng.2019.114535
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Zhang Y, 2014, IEEE T COMP PACK MAN, V4, P1914, DOI 10.1109/TCPMT.2014.2364742
NR 32
TC 2
Z9 2
U1 6
U2 6
PD FEB
PY 2023
VL 70
IS 2
BP 485
EP 492
DI 10.1109/TED.2022.3231570
EA DEC 2022
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Zhang, JL
   Swift, M
   Li, J
AF Zhang, Jialiang
   Swift, Michael
   Li, Jing (Jane)
BE Falsafi, B
   Ferdman, M
   Lu, S
   Weinisch, T
TI Software-Defined Address Mapping: A Case on 3D Memory
SO ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON
   ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS
DT Proceedings Paper
CT 27th ACM International Conference on Architectural Support for
   Programming Languages and Operating Systems (ASPLOS)
CY FEB 28-MAR 04, 2022
CL Lausanne, SWITZERLAND
DE Software defined memory; 3D memory; Address mapping
ID SCHEME
AB 3D-stacking memory such as High-Bandwidth Memory (HBM) and Hybrid Memory Cube (HMC) provides orders of magnitude more bandwidth and significantly increased channel-level parallelism (CLP) due to its new parallel memory architecture. However, it is challenging to fully exploit the abundant CLP for performance as the bandwidth utilization is highly dependent on address mapping in the memory controller. Unfortunately, CLP is very sensitive to a program's data access pattern, which is not made available to OS/hardware by existing mechanisms.
   In this work, we address these challenges with software-defined address mapping (SDAM) that, for the first time, enables user program to obtain a direct control of the low-level memory hardware in a more intelligent and fine-grained manner. In particular, we develop new mechanisms that can effectively communicate a program's data access properties to the OS and hardware and to use it to control data placement in hardware. To guarantee correctness and reduce overhead in storage and performance, we extend Linux kernel and C-language memory allocators to support multiple address mappings. For advanced system optimization, we develop machine learning methods that can automatically identify access patterns of major variables in a program and cluster these with similar access patterns to reduce the overhead for SDAM. We demonstrate the benefits of our design on real system prototype, comprising (1) a RISC-V processor, near memory accelerators and HBM modules using Xilinx FPGA platform, and (2) modified Linux and glibc. Our evaluation on standard CPU benchmarks and data-intensive benchmarks (for both CPU and accelerators) demonstrates 1.41x, 1.84x speedup on CPU and 2.58x on near memory accelerators in our system with SDAM compared to a baseline system that uses a fixed address mapping.
C1 [Zhang, Jialiang; Li, Jing (Jane)] Univ Penn, Philadelphia, PA 19104 USA.
   [Swift, Michael] Univ Wisconsin, Madison, WI USA.
RP Zhang, JL (corresponding author), Univ Penn, Philadelphia, PA 19104 USA.
EM jlzhang@seas.upenn.edu; swift@cs.wisc.edu; janeli@seas.upenn.edu
CR Akin B, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P131, DOI 10.1145/2749469.2750397
   [Anonymous], 2010, PROC IEEE 16 INT S H
   [Anonymous], 2017, ACM IEEE 44 ANN INT, P521
   [Anonymous], 2011, HIGH PERFORMANCE COM
   Ayers G, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P513, DOI 10.1145/3373376.3378498
   Baldi P., 2011, P 2011 INT C UNS TRA, V27, P37
   Balkesen C, 2013, PROC INT CONF DATA, P362, DOI 10.1109/ICDE.2013.6544839
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Brasserl F, 2017, PROCEEDINGS OF THE 26TH USENIX SECURITY SYMPOSIUM (USENIX SECURITY '17), P117
   Bugnion E, 1996, ACM SIGPLAN NOTICES, V31, P244, DOI 10.1145/248209.237195
   Calder B, 1998, ACM SIGPLAN NOTICES, V33, P139, DOI 10.1145/291006.291036
   Celio Christopher, BOOM V2
   Chatterjee N, 2014, INT CONF HIGH PERFOR, P128, DOI 10.1109/SC.2014.16
   ChiachenChou AamerJaleel, 2015, BATMAN MAXIMIZING BA
   Chilimbi TM, 1999, ACM SIGPLAN NOTICES, V34, P1, DOI 10.1145/301631.301633
   Dong Xuan, 2010, P 2010 ACM IEEE INT, P1, DOI DOI 10.1097/MPA.0B013E3181F82F3C
   Evans Jason, 2006, SCALABLE CONCURRENT
   Ghasempour M, 2016, MEMSYS 2016: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P362, DOI 10.1145/2989081.2989102
   Hashemi M., 2018, PR MACH LEARN RES, P1924
   Henning J. L., 2006, SIGARCH COMPUT ARCHI, V34, P1, DOI [10.1145/1186736.1186737, DOI 10.1145/1186736.1186737]
   Hillenbrand M, 2017, PHYS ADDRESS DECODIN
   Intel, 2016, INT XEON PROC E7 V4
   JEDEC, 2012, JEDEC STAND DDR4 SDR
   JEDEC Standard, 2013, JESD235
   Ji X, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126917
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kannan S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P521, DOI 10.1145/3079856.3080245
   Lameter Christoph, 2013, QUEUE, V11, P40, DOI 10.1145/2508834.2513149
   Liu L, 2012, INT CONFER PARA, P367
   Liu YX, 2018, CONF PROC INT SYMP C, P166, DOI 10.1109/ISCA.2018.00024
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Meswani MR, 2015, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2015.7056027
   Min EX, 2018, IEEE ACCESS, V6, P39501, DOI 10.1109/ACCESS.2018.2855437
   Murphy Richard C, 2010, INTRO GRAPH 500, V19, P45
   Narayan A, 2018, INT PARALL DISTRIB P, P326, DOI 10.1109/IPDPS.2018.00042
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Phadke S, 2011, DES AUT TEST EUROPE, P956
   RAU BR, 1991, ACM COMP AR, V19, P74, DOI 10.1145/115953.115961
   Sudan K, 2010, ACM SIGPLAN NOTICES, V45, P219, DOI 10.1145/1735971.1736045
   Sungpack Hong, 2011, Proceedings 2011 International Conference on Parallel Architectures and Compilation Techniques (PACT), P78, DOI 10.1109/PACT.2011.14
   Vijaykumar N, 2018, CONF PROC INT SYMP C, P207, DOI 10.1109/ISCA.2018.00027
   Vijaykumar N, 2018, CONF PROC INT SYMP C, P829, DOI 10.1109/ISCA.2018.00074
   WOLF JL, 1993, IEEE T PARALL DISTR, V4, P70, DOI 10.1109/71.205654
   Wu Q, 2004, INT SYM CODE GENER, P315
   Xilinx, 2019, ULTRASCALE FPGA PROD
   Xilinx, 2019, AXI HIGH BANDW MEM C
   Zhang JL, 2019, ANN IEEE SYM FIELD P, P145, DOI 10.1109/FCCM.2019.00029
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P207, DOI 10.1145/3020078.3021737
   Zhang LX, 2001, IEEE T COMPUT, V50, P1117, DOI 10.1109/12.966490
   Zhang Z, 2000, INT SYMP MICROARCH, P32, DOI 10.1109/MICRO.2000.898056
NR 51
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 70
EP 83
DI 10.1145/3503222.3507774
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ghiglio, P
   Dolinsky, U
   Goli, M
   Narasimhan, K
AF Ghiglio, Pietro
   Dolinsky, Uwe
   Goli, Mehdi
   Narasimhan, Kumudha
GP ACM
TI Improving performance of SYCL applications on CPU architectures using
   LLVM-directed compilation flow
SO PROCEEDINGS OF THE THIRTEENTH INTERNATIONAL WORKSHOP ON PROGRAMMING
   MODELS AND APPLICATIONS FOR MULTICORES AND MANYCORES (PMAM '22)
DT Proceedings Paper
CT 13th International Workshop on Programming Models and Applications for
   Multicores and Manycores (PMAM) part of PPoPP Conference
CY APR 02-06, 2022
CL Seoul, SOUTH KOREA
DE SYCL; parallel programming; multi-cores; software acceleration;
   portability; standards; compiler optimizations
AB The wide adoption of SYCL as an open-standard API for accelerating C++ software in domains such as HPC, Automotive, Artificial Intelligence, Machine Learning, and other areas necessitates efficient compiler and runtime support for a growing number of different platforms. Existing SYCL implementations provide support for various devices like CPUs, GPUs, DSPs, FPGAs, etc, typically via OpenCL or CUDA backends. While accelerators have increased the performance of user applications significantly, employing CPU devices for further performance improvement is beneficial due to the significant presence of CPUs in existing datacenters.
   SYCL applications on CPUs, currently go through an OpenCL backend. Though an OpenCL backend is valuable in supporting accelerators, it may introduce additional overhead for CPUs since the host and device are the same. Overheads like a run-time compilation of the kernel, transferring of input/output memory to/from the OpenCL device, invoking the OpenCL kernel, may not be necessary when running on the CPU. While some of these overheads (such as data transfer) can be avoided by modifying the application, it can introduce disparity in the SYCL application's ability to achieve performance portability on other devices.
   In this paper, we propose an alternate approach to running SYCL applications on CPUs. We bypass OpenCL and use a CPU-directed compilation flow, along with the integration of Whole Function Vectorization to generate optimized host and device code together in the same translation unit. We compare the performance of our approach - the CPU-directed compilation flow, with an OpenCL backend for existing SYCL-based applications, with no code modification. We run experiments across various CPU architectures to attest to the efficacy of our proposed approach.
C1 [Ghiglio, Pietro; Dolinsky, Uwe; Goli, Mehdi; Narasimhan, Kumudha] Codeplay Software Ltd, Edinburgh, Scotland.
RP Ghiglio, P (corresponding author), Codeplay Software Ltd, Edinburgh, Scotland.
EM pietro.ghiglio@codeplay.com; uwe@codeplay.com; mehdi.goli@codeplay.com;
   kumudha.narasimhan@codeplay.com
CR Aliaga JI., 2017, P 5 INT WORKSHOP OPE, DOI [10.1145/3078155.3078189, DOI 10.1145/3078155.3078189]
   Alpay A., 2020, IWOCL 20, DOI DOI 10.1145/3388333.3388658
   [Anonymous], ONEAPI DEEP NEURAL N
   [Anonymous], INTEL ONEAPI MATH KE
   [Anonymous], COMP SDK
   [Anonymous], ONEAPI SPECIFICATION
   [Anonymous], PORTABLE COMPUTING L
   [Anonymous], ONEDPL ONEAPI DPC LI
   [Anonymous], NVIDIA CUDA PROGRAMM
   [Anonymous], SYCL SPECIFICATION C
   [Anonymous], VECTORIZATION SIMD P
   Ashbaugh B., 2020, P INT WORKSHOP OPENC, P1
   Brown G., 2019, P INT WORKSHOP OPENC, P1
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   Computecpp community edition, US
   Copik M., 2017, P 5 INT WORKSH OPENC
   Deakin T., 2016, GPUSTREAM V2 0 BENCH
   Feng W., 2021, INT WORKSHOP OPENCL, P1
   Goli M., 2016, P 4 INT WORKSHOP OPE, P1
   Gozillon A., 2020, 2020 INT C HIGH PERF
   Hecbench, US
   Karrenberg R, 2015, AUTOMATIC SIMD VECTO, P85
   Ke Y., 2021, INT C HIGH PERFORMAN
   Lattner C., 2008, BSD C, P5
   Lawson J, 2021, PARALLEL COMPUT, V107, DOI 10.1016/j.parco.2021.102813
   Murray A., 2020, P INTERNATIONALWORKS
   Pheatt C., 2008, J COMPUT SCI COLL, V23, P298
   Reinders J., 2021, DATA PARALLEL C MAST
   Sato M., 2020, P ISPDC, P1
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Thoman P., 2021, INTERNATIONALWORKSHO, P1
   Yamada Y., 2018, P INTENATIONAL S HIG, VVolume 30, P19
NR 32
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 1
EP 10
DI 10.1145/3528425.3529099
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Long, L
   Bargo, T
   Renambot, L
   Brown, M
   Johnson, AE
AF Long, Lance
   Bargo, Timothy
   Renambot, Luc
   Brown, Maxine
   Johnson, Andrew E.
GP IEEE Comp Soc
TI Composable Infrastructures for an Academic Research Environment: Lessons
   Learned
SO 2022 IEEE 36TH INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING
   SYMPOSIUM WORKSHOPS (IPDPSW 2022)
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 36th IEEE International Parallel and Distributed Processing Symposium
   (IEEE IPDPS)
CY MAY 30-JUN 03, 2022
CL ELECTR NETWORK
DE composable infrastructure; deep learning; visutdization; resource
   management; workload management; user workflow; composable co-location;
   infrastructure as code
AB Composable infrastructure holds the promise of accelerating the pace of academic research and discovery by enabling researchers to tailor the resources of a machine (e.g., GPUs, storage, NICs), on-demand, to address application needs. We were first introduced to composable infrastructure in 2018, and at the same time, there was growing demand among our College of Engineering faculty for GPU systems for data science, artificial intelligence / machine learning / deep learning, and visualization. Many purchased their own individual desktop or deskside systems, a few pursued more costly cloud and IIPC solutions, and others looked to the College or campus computer center for GPU resources which, at the time, were scarce. After surveying the diverse needs of our faculty and studying product offerings by a few nascent startups in the composable infrastructure sector, we applied for and received a grant from the National Science Foundation in November 2019 to purchase a mid-scale system, configured to our specifications, for use by faculty and students for research and research training.
   This paper describes our corn posable infrastructure solution and implementation for our academic community. Given how modern workflows are progressively loosing to containers and cloud frameworks (using Kubernetes) and to programming notebooks (primarily Jupyter), both for ease of use and for ensuring reproducible experiments, we initially adapted these tools for our system. We have since made it simpler to use our system, and now provide our users with a public facing JupyterHub server. We also added an expansion chassis to our system to enable composable co-location, which is a shared central architecture in which our researchers can insert and integrate specialized resources (GPUs, accelerators, networking cards, etc.) needed for their research.
   In February 2020, installation of our system was finalized and made operational and we began providing access to faculty in the College of Engineering. Now, two years later, it is used by over 40 faculty and students plus some external collaborators for research and research training. Their use cases and experiences are briefly described in this paper. Composable infrastructure has proven to be a useful computational system for workload variability, uneven applications, and modern workflows in academic environments.
C1 [Long, Lance; Bargo, Timothy; Renambot, Luc; Brown, Maxine; Johnson, Andrew E.] Univ Illinois, Elect Visualizat Lab, Comp Sci, Chicago, IL 60607 USA.
RP Long, L (corresponding author), Univ Illinois, Elect Visualizat Lab, Comp Sci, Chicago, IL 60607 USA.
EM llong4@uic.edu; tbargo2@uic.edu; renambot@uic.edu; maxine@uic.edu;
   ajohnson@uic.edu
CR Altintas I, 2019, Arxiv, DOI arXiv:1903.06802
   [Anonymous], US
   [Anonymous], 2019, BUSINESS WIRE
   Baldin I, 2019, IEEE INTERNET COMPUT, V23, P38, DOI 10.1109/MIC.2019.2958545
   BROWN M, 2019, MERIT MIDSCALE ED RE, DOI DOI 10.1109/ICNP.2019.8888070
   Chen Zhongyi, 2022, 1 WORKSHOP COMPOSABL
   Davariashtiyani A, 2021, COMMUN MATER, V2, DOI 10.1038/s43246-021-00219-x
   Kane Daniel, 2022, UC SAN DIEGO NE 0120
   Keahey K, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P219
   Liu K., 2020, AS C COMP VIS ACCV K, P89, DOI [10.1007/978-3-030-69525-5_6, DOI 10.1007/978-3-030-69525-5_6]
   Liu MY, 2021, PROC CVPR IEEE, P9721, DOI 10.1109/CVPR46437.2021.00960
   Lowe S. D., 2016, COMPOSABLE INFRASTRU
   Ragone M, 2022, COMP MATER SCI, V201, DOI 10.1016/j.commatsci.2021.110905
   Ragone M, 2021, J POWER SOURCES, V483, DOI 10.1016/j.jpowsour.2020.229108
   Trabucco JT, 2020, IEEE INT C BIOINFORM, P2379, DOI 10.1109/BIBM49941.2020.9313467
NR 15
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 1209
EP 1214
DI 10.1109/IPDPSW55747.2022.00208
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Bae, S
   Kim, H
   Lee, S
   Jung, Y
AF Bae, Seongwoo
   Kim, Haechan
   Lee, Seongjoo
   Jung, Yunho
TI FPGA Implementation of Keyword Spotting System Using Depthwise Separable
   Binarized and Ternarized Neural Networks
SO SENSORS
DT Article
DE binarized neural network; field-programmable gate array; keyword
   spotting; ternarized neural network
ID CHIP; PROCESSOR; MEMORY; CNN
AB Keyword spotting (KWS) systems are used for human-machine communications in various applications. In many cases, KWS involves a combination of wake-up-word (WUW) recognition for device activation and voice command classification tasks. These tasks present a challenge for embedded systems due to the complexity of deep learning algorithms and the need for optimized networks for each application. In this paper, we propose a depthwise separable binarized/ternarized neural network (DS-BTNN) hardware accelerator capable of performing both WUW recognition and command classification on a single device. The design achieves significant area efficiency by redundantly utilizing bitwise operators in the computation of the binarized neural network (BNN) and ternary neural network (TNN). In a complementary metal-oxide semiconductor (CMOS) 40 nm process environment, the DS-BTNN accelerator demonstrated significant efficiency. Compared with a design approach where BNN and TNN were independently developed and subsequently integrated as two separate modules into the system, our method achieved a 49.3% area reduction while yielding an area of 0.558 mm(2). The designed KWS system, which was implemented on a Xilinx UltraScale+ ZCU104 field-programmable gate array (FPGA) board, receives real-time data from the microphone, preprocesses them into a mel spectrogram, and uses this as input to the classifier. Depending on the order, the network operates as a BNN or a TNN for WUW recognition and command classification, respectively. Operating at 170 MHz, our system achieved 97.1% accuracy in BNN-based WUW recognition and 90.5% in TNN-based command classification.
C1 [Bae, Seongwoo; Kim, Haechan; Jung, Yunho] Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang Si 10540, South Korea.
   [Lee, Seongjoo] Sejong Univ, Dept Semicond Syst Engn, Seoul 05006, South Korea.
   [Lee, Seongjoo] Sejong Univ, Inst Semicond & Syst IC, Seoul 05006, South Korea.
   [Lee, Seongjoo] Sejong Univ, Dept Convergence Engn Intelligent Drone, Seoul 05006, South Korea.
   [Jung, Yunho] Korea Aerosp Univ, Dept Smart Air Mobil, Goyang Si 10540, South Korea.
RP Jung, Y (corresponding author), Korea Aerosp Univ, Sch Elect & Informat Engn, Goyang Si 10540, South Korea.; Jung, Y (corresponding author), Korea Aerosp Univ, Dept Smart Air Mobil, Goyang Si 10540, South Korea.
EM tjddn1997@kau.kr; ft0241@kau.kr; seongjoo@sejong.ac.kr; yjung@kau.ac.kr
CR Adjoudani A, 2003, IEEE J SEL AREA COMM, V21, P440, DOI 10.1109/JSAC.2003.809724
   Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   Bankman D, 2019, IEEE J SOLID-ST CIRC, V54, P158, DOI 10.1109/JSSC.2018.2869150
   Blouw P, 2021, Arxiv, DOI arXiv:2009.04465
   Choi S, 2018, ISSCC DIG TECH PAP I, P220, DOI 10.1109/ISSCC.2018.8310263
   Chong YS, 2022, IEEE T CIRCUITS-II, V69, P1662, DOI 10.1109/TCSII.2021.3113259
   Courbariaux M, 2016, Arxiv, DOI [arXiv:1602.02830, DOI 10.48550/ARXIV.1602.02830]
   Giraldo JSP, 2021, IEEE T VLSI SYST, V29, P2220, DOI 10.1109/TVLSI.2021.3120189
   Giraldo JSP, 2019, SYMP VLSI CIRCUITS, pC52, DOI 10.23919/VLSIC.2019.8777994
   Gong Y, 2020, IEEE ACCESS, V8, P205878, DOI 10.1109/ACCESS.2020.3037931
   Gupta H, 2016, 2016 6th International Conference - Cloud System and Big Data Engineering (Confluence), P498, DOI 10.1109/CONFLUENCE.2016.7508171
   HERMANSKY H, 1990, J ACOUST SOC AM, V87, P1738, DOI 10.1121/1.399423
   HERMANSKY H, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P800, DOI 10.1109/ACSSC.1991.186557
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Kepuska V., 2015, J COMPUT COMMUN, V3, P56677, DOI [10.4236/jcc.2015.36001, DOI 10.4236/JCC.2015.36001]
   Liang S, 2018, NEUROCOMPUTING, V275, P1072, DOI 10.1016/j.neucom.2017.09.046
   Liu B, 2020, IEEE T CIRCUITS-I, V67, P4733, DOI 10.1109/TCSI.2020.2997913
   Miyashita D, 2017, IEEE J SOLID-ST CIRC, V52, P2679, DOI 10.1109/JSSC.2017.2712626
   Paszke A., 2019, ADV NEURAL INFORM PR, P8024
   Shan WW, 2021, IEEE J SOLID-ST CIRC, V56, P151, DOI 10.1109/JSSC.2020.3029097
   Song DD, 2018, 2018 5TH INTERNATIONAL CONFERENCE ON INFORMATION SCIENCE AND CONTROL ENGINEERING (ICISCE 2018), P306, DOI 10.1109/ICISCE.2018.00071
   Sorensen PM, 2020, EURASIP J AUDIO SPEE, V2020, DOI 10.1186/s13636-020-00176-2
   Warden P, 2018, Arxiv, DOI arXiv:1804.03209
   Xiang LP, 2019, 2019 IEEE 4TH INTERNATIONAL CONFERENCE ON INTEGRATED CIRCUITS AND MICROSYSTEMS (ICICM 2019), P195, DOI [10.1109/icicm48536.2019.8977176, 10.1109/ICICM48536.2019.8977176]
   Yang L, 2019, PR GR LAK SYMP VLSI, P347, DOI 10.1145/3299874.3318034
   Zhang YD, 2018, Arxiv, DOI [arXiv:1711.07128, DOI 10.48550/ARXIV.1711.07128]
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
   Zhu LX, 2021, PROC EUR SOLID-STATE, P99, DOI 10.1109/ESSCIRC53450.2021.9567770
NR 28
TC 1
Z9 1
U1 1
U2 1
PD JUN
PY 2023
VL 23
IS 12
AR 5701
DI 10.3390/s23125701
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT C
AU Gondimalla, A
   Chesnut, N
   Thottethodi, M
   Vijaykumar, TN
AF Gondimalla, Ashish
   Chesnut, Noah
   Thottethodi, Mithuna
   Vijaykumar, T. N.
GP Assoc Comp Machinery
TI SparTen: A Sparse Tensor Accelerator for Convolutional Neural Networks
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE Convolutional neural networks; Sparse tensors; Accelerators
AB Convolutional neural networks (CNNs) are emerging as powerful tools for image processing. Recent machine learning work has reduced CNNs' compute and data volumes by exploiting the naturally-occurring and actively-transformed zeros in the feature maps and filters. While previous semi-sparse architectures exploit one-sided sparsity either in the feature maps or the filters, but not both, a recent fully-sparse architecture, called Sparse CNN (SCNN), exploits two-sided sparsity to improve performance and energy over dense architectures. However, sparse vector-vector dot product, a key primitive in sparse CNNs, would be inefficient using the representation adopted by SCNN. The dot product requires finding and accessing non-zero elements in matching positions in the two sparse vectors - an inner join using the position as the key with a single value field. SCNN avoids the inner join by performing a Cartesian product capturing the relevant multiplications. However, SCNN's approach incurs several considerable overheads and is not applicable to non-unit-stride convolutions. Further, exploiting reuse in sparse CNNs fundamentally causes systematic load imbalance not addressed by SCNN. We propose SparTen which achieves efficient inner join by providing support for native two-sided sparse execution and memory storage. To tackle load imbalance, SparTen employs a software scheme, called greedy balancing, which groups filters by density via two variants, a software-only one which uses whole-filter density and a software-hardware hybrid which uses finer-grain density. Our simulations show that, on average, SparTen performs 4.7x, 1.8x, and 3x better than a dense architecture, one-sided sparse architecture, and SCNN, respectively. An FPGA implementation shows that SparTen performs 4.3x and 1.9x better than a dense architecture and a one-sided sparse architecture, respectively.
C1 [Gondimalla, Ashish; Thottethodi, Mithuna; Vijaykumar, T. N.] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Gondimalla, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM agondima@purdue.edu; noachesnut11@gmail.com; mithuna@purdue.edu;
   vijay@ecn.purdue.edu
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M, 2016, INT SYMP MICROARCH
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1965, MATH THEORY CONNECTI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2016, ICLR
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   CLOS C, 1953, AT&T TECH J, V32, P406, DOI 10.1002/j.1538-7305.1953.tb01433.x
   Deng CH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P189, DOI 10.1109/MICRO.2018.00024
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Farrell JA, 1998, IEEE J SOLID-ST CIRC, V33, P707, DOI 10.1109/4.668985
   Gibbs N. E., 1976, ACM Transactions on Mathematical Software, V2, P322, DOI 10.1145/355705.355707
   Gokhale V., 2017, 2017 IEEE INT S CIRC, P1, DOI [10.1109/ISCAS.2017.8050809, DOI 10.1109/ISCAS.2017.8050809]
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han Song, 2015, C NEUR INF PROC SYST
   He K., 2016, INDIAN J CHEM B
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Judd  P., 2018, ABS180303688 CORR
   Kim DH, 2016, INT J ADV MANUF TECH, V85, P1825, DOI 10.1007/s00170-015-8014-1
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kung H. T., 2018, ABS181104770 CORR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lin YC, 2005, J PARALLEL DISTR COM, V65, P1585, DOI 10.1016/j.jpdc.2005.05.017
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mahmoud M, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P134, DOI 10.1109/MICRO.2018.00020
   Muralimanohar Naveen, 2009, S Q J MODERN FOREIGN
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Russakovsky O., 2014, IJCV
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sharify S, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P304, DOI 10.1145/3307650.3322255
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Stine JE, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON MICROELECTRONIC SYSTEMS EDUCATION, PROCEEDINGS, P173, DOI 10.1109/MSE.2007.44
   Tao J, 2017, PROCEEDINGS OF 2017 3RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER AND COMMUNICATIONS (ICCC), P23, DOI 10.1109/CompComm.2017.8322508
   Thottethodi M., 2019, WHY GPGPU IS LESS EF
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang SJ, 2016, INT SYMP MICROARCH
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zhuo Ling, 2005, P 2005 ACMSIGDA 13 I, P63
NR 44
TC 107
Z9 110
U1 1
U2 15
PY 2019
BP 151
EP 165
DI 10.1145/3352460.3358291
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Das, SK
   Sudhakaran, G
   Ashok, V
AF Das, Soumen Kumar
   Sudhakaran, G.
   Ashok, V.
BE Jana, D
   Pal, P
TI Learning Based Performance and Power Efficient Cluster Resource Manager
   for CPU-GPU Cluster
SO 2014 FOURTH INTERNATIONAL CONFERENCE OF EMERGING APPLICATIONS OF
   INFORMATION TECHNOLOGY (EAIT)
SE Proceedings International Conference on Emerging Applications of
   Information Technology (EAIT)
DT Proceedings Paper
CT Fourth International Conference on Emerging Applications of Information
   Technology
CY DEC 19-21, 2014
CL Indian Stat Inst, Kolkata, INDIA
HO Indian Stat Inst
DE High performance Cluster; CRM; Moldable Scheduler; Collocation; Resource
   Manager; petascale; green computing
AB The recent success in building petascale High Performance Computing (HPC) systems have produced the demand for efficient and optimized use of resources to increase the performance and reduce the power consumption. Including the above, the heterogeneous architectures of nowadays HPCs comprising a multicore CPU and many-core Accelerator like GPU(s) are facing another concern for using optimum utilization of each of these components. This paper presents the scheduling mechanism of the Cluster Resource Manager (CRM): i. Moldable job Scheduler (MS) which is able to mold the jobs with respect to the number of machines based on an preliminary initialized and auto updated heuristic knowledge-base of problem size, optimum machine count, execution duration to increase the utilization of the full cluster facility. ii) Collocation Aware and Power Efficient Resource Manager (CAPE-RM) manages collocation of CPU only and GPU accelerated jobs by monitoring the CPU load and memory usage. The emerging computation ability is followed by the huge amount of power consumption. Though the use of GPU(s) itself cut down the power to be needed by the only CPU based cluster but to make a green computing facility more power efficiency is desired. The CAPE-RM is designed to support the above by powering off the idle nodes by monitoring the total load to the facility and based on a simple statistic of the frequency of job submission.
C1 [Das, Soumen Kumar; Sudhakaran, G.; Ashok, V.] ISRO, Vikram Sarabhai Space Ctr, Govt India, Dept Space, Trivandrum, Kerala, India.
RP Das, SK (corresponding author), ISRO, Vikram Sarabhai Space Ctr, Govt India, Dept Space, Trivandrum, Kerala, India.
CR [Anonymous], P 18 S OP SYST PRINC
   [Anonymous], 2009, CLUSTER 09, DOI DOI 10.1109/CLUSTR.2009.5289193
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   Cirne W, 2002, J PARALLEL DISTR COM, V62, P1571, DOI 10.1006/jpdc.2002.1869
   Diamos G, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P353, DOI 10.1145/1854273.1854318
   Diamos Gregory F., 2008, P 17 INT S HIGH PERF, P197, DOI DOI 10.1145/1383422.1383447
   Dusseau A. C., 1996, Performance Evaluation Review, V24, P25, DOI 10.1145/233008.233020
   Feitelson DG, 2005, LECT NOTES COMPUT SC, V3277, P1
   Freund R. F. t., 1998, P 7 HET COMP WORKSH, P3
   Furlinger K., 2011, 2011 IEEE International Symposium on Parallel & Distributed Processing, Workshops and Phd Forum, P1377, DOI 10.1109/IPDPS.2011.289
   Hong CT, 2010, PACT 2010: PROCEEDINGS OF THE NINETEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P217, DOI 10.1145/1854273.1854303
   Kerr A., 2010, P 3 WORKSH GEN PURP, P31, DOI DOI 10.1145/1735688.1735696
   Maheswaran M, 1999, PROC HETER COMP WORK, P30, DOI 10.1109/HCW.1999.765094
   Naik V. K., 1993, Proceedings SUPERCOMPUTING '93, P824, DOI 10.1145/169627.169848
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
   Pinheiro E, 2003, COMPILERS AND OPERATING SYSTEMS FOR LOW POWER, P75
   Ravi Vignesh T., 2010, 24th ACM International Conference on Supercomputing 2010, P137
   Sabin G, 2005, 14th IEEE International Symposium on High Performance Distributed Computing, Proceedings, P144
   Sabin G, 2003, LECT NOTES COMPUT SC, V2862, P87
   Srinivasan S, 2002, LECT NOTES COMPUT SC, V2552, P174
   Sudhakaran, 2012, P ATIP A CRC WORKSH, P117
NR 21
TC 1
Z9 2
U1 0
U2 0
PY 2014
BP 161
EP 166
DI 10.1109/EAIT.2014.58
WC Computer Science, Interdisciplinary Applications
DA 2023-11-11
ER

PT J
AU Di Castro, M
   Ferre, M
   Masi, A
AF Di Castro, Mario
   Ferre, Manuel
   Masi, Alessandro
TI CERNTAURO: A Modular Architecture for Robotic Inspection and
   Telemanipulation in Harsh and Semi-Structured Environments
SO IEEE ACCESS
DT Article
DE Mobile robots; robot control; robot learning; robot sensing systems;
   robot vision system; telerobotics; human-robot interaction; intelligent
   systems; Internet of Things
ID BILATERAL TELEOPERATION; MOBILE MANIPULATION; SYSTEMS; TRANSPARENCY;
   STABILITY; OIL
AB Intelligent robotic systems are becoming essential for industries, nuclear plants, and for harsh environments in general, such as the European Organization for Nuclear Research (CERN) particles accelerator complex and experiments. In order to increase safety and machine availability, robots can perform repetitive, unplanned, and dangerous tasks, which humans either prefer to avoid or are unable to carry out due to hazards, size constraints, or the extreme environments in which they take place. Anovel robotic framework for autonomous inspections and supervised teleoperations in harsh environments is presented. The proposed framework covers all aspects of a robotic intervention, from the specification and operator training, the choice of the robot and its material in accordance with possible radiological contamination risks, to the realization of the intervention, including procedures and recovery scenarios. The robotic solution proposed in this paper is able to navigate autonomously, inspecting unknown environments in a safe way. A new real-time control system was implemented in order to guarantee a fast response to environmental changes and adaptation to different type of scenarios the robot may find in a semi-structured and hazardous environment. Components of the presented framework are: a novel bilateral master-slave control, a new robotic platform named CERNbot, and an advanced user-friendly multimodal human-robot interface, also used for the operators' offline training, allowing technicians not expert in robot operation to perform inspection/maintenance tasks. The proposed system has been tested and validated with real robotic interventions in the CERN hazardous particle accelerator complex.
C1 [Di Castro, Mario; Masi, Alessandro] CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.
   [Di Castro, Mario; Ferre, Manuel] Univ Politecn Madrid, CSIC, CAR, E-28006 Madrid, Spain.
RP Di Castro, M (corresponding author), CERN, European Org Nucl Res, CH-1211 Geneva, Switzerland.; Di Castro, M (corresponding author), Univ Politecn Madrid, CSIC, CAR, E-28006 Madrid, Spain.
EM mario.di.castro@cern.ch
CR Abadi M., 2016, P OSDI, V16, P1
   Altarelli M., 2006, TECH REP, P1, DOI DOI 10.1080/08940880601064968
   [Anonymous], 2014, HDB UNMANNED AERIAL
   [Anonymous], 2008, P IEEE INT C OCEAN
   [Anonymous], 2004, 35 INT S ROB PAR FRA
   [Anonymous], 2014, P IEEE NETW OP MAN S
   [Anonymous], 2016, 4 IND REVOLUTION
   [Anonymous], 2008, SPRINGER HDB ROBOTIC, DOI DOI 10.1007/978-3-540-30301-5
   Asaro PM, 2013, SOC SEMIOT, V23, P196, DOI 10.1080/10350330.2013.777591
   Bajracharya M, 2008, COMPUTER, V41, P44, DOI 10.1109/MC.2008.479
   Balta H., 2014, TECH REP
   Bicchi A., 2000, Proceedings 2000 ICRA. Millennium Conference. IEEE International Conference on Robotics and Automation. Symposia Proceedings (Cat. No.00CH37065), P348, DOI 10.1109/ROBOT.2000.844081
   Buckingham R., 2017, NATURE PHYS, V12, P391
   BUTTERWORTH GJ, 1989, FUSION ENG DES, V11, P231, DOI 10.1016/0920-3796(89)90021-5
   Callam A., 2015, INT AFFAIRS REV, V18
   Chao A. W., 2013, HDB ACCELERATOR PHYS
   Chen JYC, 2010, ERGONOMICS, V53, P940, DOI 10.1080/00140139.2010.500404
   Chitta S, 2012, IEEE ROBOT AUTOM MAG, V19, P58, DOI 10.1109/MRA.2012.2191995
   Cho Y, 2017, INT J HUM ROBOT, V14, DOI 10.1142/S0219843617500128
   Claeys C., 2013, RAD EFFECTS ADV SEMI, V57
   Cutkosky M. R., 2012, ROBOTIC GRASPING FIN, V6
   DANIELSSON PE, 1980, COMPUT VISION GRAPH, V14, P227, DOI 10.1016/0146-664X(80)90054-4
   de Cubber Geert, 2014, Applied Mechanics and Materials, V658, P599, DOI 10.4028/www.scientific.net/AMM.658.599
   De Novi G, 2010, IEEE AERO EL SYS MAG, V25, P32, DOI 10.1109/MAES.2010.5638803
   Di Castro M., 2018, P ICALEPCS, P1507
   Di Castro M., 2018, P 16 INT C AC LARG E, P709
   Di Castro M., P 3 INT C MECH ROB E, P6
   Di Castro M., 2014, IMEKO
   di Castro M, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P50, DOI 10.5220/0006426700500055
   Dingus M.L., 1997, U.S. Patent, Patent No. [5 670469, 5670469]
   Dissanayake MWMG, 2001, IEEE T ROBOTIC AUTOM, V17, P229, DOI 10.1109/70.938381
   Drake B. G., 2010, AER C 2010 IEEE, P1, DOI DOI 10.1109/AERO.2010.5446736
   Draper J.V., 1987, P INT TOP M ROB REM
   Ducimetiere L., 1995, Digest of Technical Papers. Tenth IEEE International Pulsed Power Conference (Cat. No.95CH35833), P1406, DOI 10.1109/PPC.1995.599814
   Feron E., 2008, SPRINGER HDB ROBOTIC, P1009
   Ferre M., 2007, ADV TELEROBOTICS, V31
   Friconneau JP, 2017, FUSION ENG DES, V124, P673, DOI 10.1016/j.fusengdes.2017.01.005
   Garage W., 2010, WILLOW GARAGE
   Goertz R.C., 1964, P 12 REM SYST TECHN, V12, P123
   García-Valdovinos LG, 2014, INT J ADV ROBOT SYST, V11, DOI 10.5772/56810
   Guiochet J, 2017, ROBOT AUTON SYST, V94, P43, DOI 10.1016/j.robot.2017.04.004
   Gutierrez-Giles A., 2017, INT J CONTROL, P1
   Haddadi A, 2015, IEEE-ASME T MECH, V20, P2463, DOI 10.1109/TMECH.2014.2385637
   Hainsworth DW, 2001, AUTON ROBOT, V11, P19, DOI 10.1023/A:1011299910904
   Hashtrudi-Zaad K, 2002, IEEE T ROBOTIC AUTOM, V18, P108, DOI 10.1109/70.988981
   Hashtrudi-Zaad K, 2001, INT J ROBOT RES, V20, P419, DOI 10.1177/02783640122067471
   Helms E, 2002, IEEE ROMAN 2002, PROCEEDINGS, P399, DOI 10.1109/ROMAN.2002.1045655
   Henriques JF, 2015, IEEE T PATTERN ANAL, V37, P583, DOI 10.1109/TPAMI.2014.2345390
   Hoddeson L., 2009, AM J PHYS, V77, P671
   Hokayem PF, 2006, AUTOMATICA, V42, P2035, DOI 10.1016/j.automatica.2006.06.027
   HVILSHJ M, 2009, IEEE C EM TECHN FACT, P1
   Hvilshoj M, 2012, IND ROBOT, V39, P120, DOI 10.1108/01439911211201582
   Iida W, 2004, 8TH IEEE INTERNATIONAL WORKSHOP ON ADVANCED MOTION CONTROL, PROCEEDINGS, P217, DOI 10.1109/AMC.2004.1297669
   Irizarry J, 2012, J INF TECHNOL CONSTR, V17, P194
   Jerald Jason, 2014, 2014 IEEE Virtual Reality (VR), P1, DOI 10.1109/VR.2014.6802117
   Joseph L., 2015, MASTERING ROS ROBOTI
   Kellerbauer A, 2008, NUCL INSTRUM METH B, V266, P351, DOI 10.1016/j.nimb.2007.12.010
   Khatib O., 2008, SPRINGER HDB ROBOTIC, P1127, DOI [10.1007/978-3-540-30301-5_50, DOI 10.1007/978-3-540-30301-5_50]
   Kostavelis I., 2017, LECT NOTES BUSINESS, V4, P43
   Langley KF, 2001, NUCL ENERG-J BR NUCL, V40, P189, DOI 10.1680/nuen.40.3.189.40068
   LAWRENCE DA, 1993, IEEE T ROBOTIC AUTOM, V9, P624, DOI 10.1109/70.258054
   Lefevre C., 2008, CERNDI0812015
   Leonard JJ, 2016, SPRINGER HANDBOOK OF OCEAN ENGINEERING, P341
   Lozano-Perez T., 2012, AUTONOMOUS ROBOT VEH
   Lunghi G., 2016, P 13 INT C INF CONTR, P1
   Lunghi G, 2017, ICINCO: PROCEEDINGS OF THE 14TH INTERNATIONAL CONFERENCE ON INFORMATICS IN CONTROL, AUTOMATION AND ROBOTICS - VOL 2, P233, DOI 10.5220/0006395802330238
   Manion W.J., 1980, DOEEV101281 NUCL EN
   Marcastel F., 2013, OPENPHOCHART2013001
   Matolak DW, 2015, IEEE VEH TECHNOL MAG, V10, P79, DOI 10.1109/MVT.2015.2411191
   Meyer J-A., 2003, COGN SYST RES, V4, P283, DOI [10.1016/S1389-0417(03)00007-X, DOI 10.1016/S1389-0417(03)00007-X]
   Murray J.W., 2017, BUILDING VIRTUAL REA
   NIEMEYER G, 1991, IEEE J OCEANIC ENG, V16, P152, DOI 10.1109/48.64895
   Özyesil O, 2017, ACTA NUMER, V26, P305, DOI 10.1017/S096249291700006X
   Pedersen L., 2003, 20030054507 NASA
   Peer A, 2008, 2008 IEEE/RSJ INTERNATIONAL CONFERENCE ON ROBOTS AND INTELLIGENT SYSTEMS, VOLS 1-3, CONFERENCE PROCEEDINGS, P2350, DOI 10.1109/IROS.2008.4650582
   Pryor M., 2017, P 43 WAST MAN C, P4855
   Quigley M, 2009, IEEE INT CONF ROBOT, P3604
   Rombach M.P., 2014, SIAM J APPL MATH, V59, P619
   Rosheim M.E., 1994, ROBOT EVOLUTION DEV
   Rossi Maurizio, 2014, IEEE Sensors 2014. Proceedings, P1431, DOI 10.1109/ICSENS.2014.6985282
   Schuler J., 2013, INTEGRATION FORDER H, V104
   Sharkey N., 2011, LAW INNOVATION TECHN, V3, P229, DOI [10.5235/175799611798204914, DOI 10.5235/175799611798204914]
   Sheridan TB., 1992, TELEROBOTICS AUTOMAT
   Shukla A, 2016, ROBOT AUTON SYST, V75, P508, DOI 10.1016/j.robot.2015.09.013
   Shukla A, 2016, ROBOT AUTON SYST, V75, P490, DOI 10.1016/j.robot.2015.09.012
   Silv e rio J., 2017, LEARNING DEMONSTRATI
   Springer Paul., 2013, MILITARY ROBOTS DRON
   Suzuki A, 2013, IEEE T IND ELECTRON, V60, P177, DOI 10.1109/TIE.2012.2183832
   TAPAS, ROB EN LOG ASS SERV
   Thrun S, 2002, COMMUN ACM, V45, P52, DOI 10.1145/504729.504754
   Tian GS, 2008, IEEE INT C ENG COMP, P69, DOI 10.1109/ICECCS.2008.39
   VALERI, VAL ADV COLL ROB IND
   Wild G, 2016, AEROSPACE, V3, DOI 10.3390/aerospace3030022
   Wu Y., 2017, P IEEE INFOCOM 2017, P1, DOI DOI 10.1007/978-981-10-3066-6_1
   Yim M, 2003, AUTON ROBOT, V14, P225, DOI 10.1023/A:1022287820808
   Yoshida K, 2009, IEEE ROBOT AUTOM MAG, V16, P20, DOI 10.1109/MRA.2009.934818
   Yoshida Tomoaki, 2014, FIELD SERVICE ROBOTI
NR 97
TC 34
Z9 34
U1 2
U2 13
PY 2018
VL 6
BP 37506
EP 37522
DI 10.1109/ACCESS.2018.2849572
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Xing, Y
   Lu, HX
   Gupta, A
   Malik, S
AF Xing, Yue
   Lu, Huaixi
   Gupta, Aarti
   Malik, Sharad
GP IEEE
TI Compositional Verification Using a Formal Component and Interface
   Specification
SO 2022 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED DESIGN, ICCAD
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 41st International Conference on Computer Aided-Design (ICCAD)
CY OCT 29-NOV 03, 2022
CL San Diego, CA
ID REASONING FRAMEWORK
AB Property-based specification such as SystemVerilog Assertions (SVA) uses mathematical logic to specify the temporal behavior of RTL designs which can then be formally verified using model checking algorithms. These properties are specified for a single component (which may contain other components in the design hierarchy). Composing design components that have already been verified r equires a dditional v erification since incorrect communication at their interface may invalidate the properties that have been checked for the individual components. This paper focuses on a specification f or t heir i nterface which can be checked individually for each component, and which guarantees that refinement-based p roperties c hecked f or each component continue to hold after their composition. We do this in the setting of the Instruction-level Abstraction (ILA) specification and verification methodology. The ILA methodology p rovides a uniform specification for processors, accelerators a nd general modules at the instruction-level, and the automatic generation of a complete set of correctness properties for checking that the RTL model is a refinement o f t he ILA s pecification. We add an interface specification to model the inter-ILA communication. Further, we use our interface specification to generate a s et of interface checking properties that check that the communication between the RTL components is correct. This provides the following guarantee: if each RTL component is a refinement of its ILA specification and the interface checks pass, then the RTL composition is a refinement o f t he I LA composition. We have applied the proposed methodology to six case studies including parts of large-scale designs such as parts of the FlexASR and NVDLA machine learning accelerators, demonstrating the practical applicability of our method.
C1 [Xing, Yue; Lu, Huaixi; Gupta, Aarti; Malik, Sharad] Princeton Univ, Princeton, NJ 08544 USA.
RP Xing, Y (corresponding author), Princeton Univ, Princeton, NJ 08544 USA.
EM yuex@princeton.edu; huaixil@princeton.edu; aartig@cs.princeton.edu;
   sharad@princeton.edu
CR [Anonymous], 1985, LOGICS MODELS CONCUR, DOI [DOI 10.1007/978-3-642-82453-1_5, 10.1007/978-3-642-82453-1\5]
   Bourgeat T, 2020, PROCEEDINGS OF THE 41ST ACM SIGPLAN CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '20), P243, DOI 10.1145/3385412.3385965
   Burch J. R., 1994, CAV
   Cadence Design Systems Inc., 2018, JASPERGOLD FORM PROP
   Cerny E., 2015, SVA POWER ASSERTIONS
   Choi J, 2017, P ACM PROGRAM LANG, V1, DOI 10.1145/3110268
   Chou CT, 2004, LECT NOTES COMPUT SC, V3312, P382
   Christensen M, 2021, PROCEEDINGS OF THE 42ND ACM SIGPLAN INTERNATIONAL CONFERENCE ON PROGRAMMING LANGUAGE DESIGN AND IMPLEMENTATION (PLDI '21), P175, DOI 10.1145/3453483.3454037
   Clarke Edmund M., 2018, MODEL CHECKING, V2nd
   de Alfaro L., 2001, Software Engineering Notes, V26, P109, DOI 10.1145/503271.503226
   De Alfaro Luca, 2001, EMSOFT 01, P148
   Giannakopoulou D., 2018, HDB MODEL CHECKING, P345, DOI 10.1007/978-3-319-10575-812
   Huang BY, 2019, LECT NOTES COMPUT SC, V11427, P351, DOI 10.1007/978-3-030-17462-0_21
   Huang BY, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3282444
   IEEE-Commission, 2005, 18502005 IEEE
   Jhala R, 2001, LECT NOTES COMPUT SC, V2102, P396
   Manolios P, 2005, IEEE IC CAD, P863, DOI 10.1109/ICCAD.2005.1560183
   Manolios P, 2008, IEEE T VLSI SYST, V16, P353, DOI 10.1109/TVLSI.2008.918120
   Mattarei C, 2018, PROCEEDINGS OF THE 2018 18TH CONFERENCE ON FORMAL METHODS IN COMPUTER AIDED DESIGN (FMCAD), P7
   McMillan KL, 1997, LECT NOTES COMPUT SC, V1254, P24
   Namjoshi KS, 2016, LECT NOTES COMPUT SC, V9636, P589, DOI 10.1007/978-3-662-49674-9_39
   Nikhil R, 2004, Second ACM and IEEE International Conference on Formal Methods and Models for Co-Design, Proceedings, P69
   NVIDIA, 2018, NVIDIA DEEP LEARN AC
   Olofsson A., 2016, EPIPHANY ELINK AXI
   Panda PR, 2001, ISSS'01: 14TH INTERNATIONAL SYMPOSIUM ON SYSTEM SYNTHESIS, P75, DOI 10.1109/ISSS.2001.957916
   Pnueli A., 1977, 18th Annual Symposium on Foundations of Computer Science, P46, DOI 10.1109/SFCS.1977.32
   Reid A, 2016, LECT NOTES COMPUT SC, V9780, P42, DOI 10.1007/978-3-319-41540-6_3
   Rose A., 2005, OPEN SYSTEMC INITIAT, P297
   Subramanyan P, 2015, PROCEEDINGS OF THE 15TH CONFERENCE ON FORMAL METHODS IN COMPUTER-AIDED DESIGN (FMCAD 2015), P160, DOI 10.1109/FMCAD.2015.7542266
   Talupur M, 2008, 2008 FORMAL METHODS IN COMPUTER-AIDED DESIGN, P69
   Tambe T, 2021, ISSCC DIG TECH PAP I, V64, P158, DOI 10.1109/ISSCC42613.2021.9366062
   Taylor MB, 2018, DES AUT CON, DOI 10.1145/3195970.3199848
   Teran S., 2016, 8051 MICROCONTROLLER
   Wright A. C., 2021, THESIS MIT
   Xilinx, 2019, VIVADO DESIGN SUITE
   Xing Y., 2021, DESIGN AUTOMATION TE
NR 36
TC 0
Z9 0
U1 2
U2 2
PY 2022
DI 10.1145/3508352.3549341
WC Computer Science, Theory & Methods; Engineering, Manufacturing;
   Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Liao, HH
   Elmohr, MA
   Dong, X
   Qian, YJ
   Yang, WZ
   Shang, ZW
   Tan, Y
AF Liao, Haohao
   Elmohr, Mahmoud A.
   Dong, Xuan
   Qian, Yanjun
   Yang, Wenzhe
   Shang, Zhiwei
   Tan, Yin
GP IEEE
TI TurboHE: Accelerating Fully Homomorphic Encryption Using FPGA Clusters
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM,
   IPDPS
SE International Parallel and Distributed Processing Symposium IPDPS
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
DE Fully homomorphic encryption; CKKS; NTT; FPGA Cluster; Hardware
   acceleration
AB With the burgeoning demands for cloud computing in various fields followed by the rising attention to sensitive data exposure, Fully Homomorphic Encryption (FHE) is gaining popularity as a potential solution to privacy protection. By performing computations directly on the ciphertext (encrypted data) without decrypting it, FHE can guarantee the security of data throughout its lifecycle without compromising the privacy. However, the excruciatingly slow speed of FHE scheme makes adopting it impractical in real life applications. Therefore, hardware accelerators come to the rescue to mitigate the problem. Among various hardware platforms, FPGA clusters are particularly promising because of their flexibility and ready availability at many cloud providers such as FPGA-as-a-Service (FaaS). Hence, reusing the existing infrastructure can greatly facilitate the implementation of FHE on the cloud. In this paper, we present TurboHE, the first hardware accelerator for FHE operations based on an FPGA cluster. TurboHE aims to boost the performance of CKKS, one of the fastest FHE schemes which is most suitable to machine learning applications, by accelerating its computationally intensive and frequently used operation: relinearization. The proposed scalable architecture based on hardware partitioning can be easily configured to accommodate high acceleration requirements for relinearization with very large CKKS parameters. As a demonstration, an implementation, which supports 32,768 polynomial coefficients and a coefficient bitwidth of 594 decomposed into 11 Residue Number System (RNS) components, was deployed on a cluster consisting of 9 Xilinx VU13P FPGAs. The cluster operated at 200 MHz and achieved 1096 times throughput compared with a single threaded CPU implementation. Moreover, the low level hardware components implemented in this work such as the NTT module can also be applied to accelerate other lattice-based cryptography schemes.
C1 [Liao, Haohao; Elmohr, Mahmoud A.; Dong, Xuan; Qian, Yanjun; Yang, Wenzhe; Shang, Zhiwei; Tan, Yin] Huawei Technol Canada, Markham, ON, Canada.
RP Liao, HH (corresponding author), Huawei Technol Canada, Markham, ON, Canada.
EM haohao.liao1@huawei.com; mahmoud.elmohr1@huawei.com;
   xuan.dong2@huawei.com; yanjun.qian1@huawei.com; wenzhe.yang@huawei.com;
   zhiwei.shang1@huawei.com; yin.tan@huawei.com
CR Almorsy Mohamed, 2016, ARXIV
   [Anonymous], 2012, IEEE C HIGH PERFORMA, DOI [10.1109/HPEC.2012.6408660, DOI 10.1109/PEAM.2012.6612493]
   Bobda C, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3506713
   Boemer Fabian, 2021, WAHC '21: Proceedings of the 9th on Workshop on Encrypted Computing & Applied Homomorphic Cryptography, P57, DOI 10.1145/3474366.3486926
   Chen H, 2018, BMC MED GENOMICS, V11, DOI 10.1186/s12920-018-0397-z
   Cheon JH, 2017, LECT NOTES COMPUT SC, V10624, P409, DOI 10.1007/978-3-319-70694-8_15
   confidentialcomputing, 2021, TECHN AN CONF COMP
   Gentry C, 2011, LECT NOTES COMPUT SC, V6632, P129, DOI 10.1007/978-3-642-20465-4_9
   Gentry Craig, 2009, FULLY HOMOMORPHIC EN
   github, 2022, MICR SEAL REL 4 0
   Hashizume K, 2013, J INTERNET SERV APPL, V4, DOI 10.1186/1869-0238-4-5
   Jung Hee Cheon, 2019, Selected Areas in Cryptography - SAC 2018. 25th International Conference. Revised Selected Papers: Lecture Notes in Computer Science (LNCS 11349), P347, DOI 10.1007/978-3-030-10970-7_16
   Jung W., 2021, IACR T CRYPTOGRAPH H, V2021, P114, DOI DOI 10.46586/TCHES.V2021.I4.114
   Lauter K, 2011, PROCEEDINGS OF THE 3RD ACM WORKSHOP CLOUD COMPUTING SECURITY WORKSHOP (CCSW'11), P113
   Longa P, 2016, LECT NOTES COMPUT SC, V10052, P124, DOI 10.1007/978-3-319-48965-0_8
   Lynbashevsky V, 2010, LECT NOTES COMPUT SC, V6110, P1, DOI 10.1145/2535925
   Morshed T, 2020, PROCEEDINGS OF THE 2020 IEEE INTERNATIONAL SYMPOSIUM ON HARDWARE ORIENTED SECURITY AND TRUST (HOST), P142, DOI [10.1109/host45689.2020.9300288, 10.1109/HOST45689.2020.9300288]
   Riazi MS, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1295, DOI 10.1145/3373376.3378523
   Samardzic N., 2021, MICRO2021, P238
   Samardzic N, 2022, CONF PROC INT SYMP C, P173, DOI 10.1145/3470496.3527393
   Tarafdar N., 2021, ACM T RECONFIG TECHN, V15, P1
   Turan F, 2020, IEEE T COMPUT, V69, P1185, DOI 10.1109/TC.2020.2988765
   Wang TQ, 2020, IEEE T COMPUT, V69, P1143, DOI 10.1109/TC.2020.3000118
   Zhang C, 2016, I SYMPOS LOW POWER E, P326, DOI 10.1145/2934583.2934644
NR 24
TC 0
Z9 0
U1 3
U2 3
PY 2023
BP 788
EP 797
DI 10.1109/IPDPS54959.2023.00084
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Ravi, J
   Byna, S
   Koziol, Q
AF Ravi, John
   Byna, Suren
   Koziol, Quincey
GP IEEE Comp Soc
TI GPU Direct I/O with HDF5
SO PROCEEDINGS OF 2020 IEEE/ACM FIFTH INTERNATIONAL PARALLEL DATA SYSTEMS
   WORKSHOP (PDSW 2020)
DT Proceedings Paper
CT IEEE/ACM 5th International Parallel Data Systems Workshop (PDSW)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE GPU I/O; NVIDIA GPUDirect Storage (GDS); HDF5 GDS Virtual File Driver
   (VFD)
AB Exascale HPC systems are being designed with accelerators, such as GPUs, to accelerate parts of applications. In machine learning workloads as well as large-scale simulations that use GPUs as accelerators, the CPU (or host) memory is currently used as a buffer for data transfers between GPU (or device) memory and the file system. If the CPU does not need to operate on the data, then this is sub-optimal because it wastes host memory by reserving space for duplicated data. Furthermore, this "bounce buffer" approach wastes CPU cycles spent on transferring data. A new technique, NVIDIA GPUDirect Storage (GDS), can eliminate the need to use the host memory as a bounce buffer. Thereby, it becomes possible to transfer data directly between the device memory and the file system. This direct data path shortens latency by omitting the extra copy and enables higher-bandwidth. To take full advantage of GDS in existing applications, it is necessary to provide support with existing I/O libraries, such as HDF5 and MPI-IO, which are heavily used in applications.
   In this paper, we describe our effort of integrating GDS with HDF5, the top I/O library at NERSC and at DOE leadership computing facilities. We design and implement this integration using a HDF5 Virtual File Driver (VFD). The GDS VFD provides a file system abstraction to the application that allows HDF5 applications to perform I/O without the need to move data between CPUs and GPUs explicitly. We compare performance of the HDF5 GDS VFD with explicit data movement approaches and demonstrate superior performance with the GDS method.
C1 [Ravi, John] North Carolina State Univ, Raleigh, NC 27695 USA.
   [Byna, Suren; Koziol, Quincey] Lawrence Berkeley Natl Lab, Berkeley, CA USA.
RP Ravi, J (corresponding author), North Carolina State Univ, Raleigh, NC 27695 USA.
EM jjravi@ncsu.edu; sbyna@lbl.gov; koziol@lbl.gov
CR Braam P., LUSTRE STORAGE ARCH
   Caswell Hal, 2001, pi
   Folk M., 2011, P EDBT ICDT 2011 WOR, P36, DOI DOI 10.1145/1966895.1966900
   Li J., 2003, SC 03, P39, DOI [DOI 10.1109/SC.2003.10053, 10.1145/1048935.1050189]
   Liu Q, 2014, CONCURR COMP-PRACT E, V26, P1453, DOI 10.1002/cpe.3125
   REW R, 1990, IEEE COMPUT GRAPH, V10, P76, DOI 10.1109/38.56302
   ROMIO team at ANL, ROMIO HIGH PERF PORT
   Tang H., 2019, PDSW 2019 CONJUNCTIO
   The HDF Group, HDF5
   Walli Stephen R., 1995, STANDARDVIEW, V3, P11
   Zhao Z, AUTOMATIC LIB TRACKI
NR 11
TC 2
Z9 2
U1 0
U2 4
PY 2020
BP 28
EP 33
DI 10.1109/PDSW51947.2020.00010
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Software Engineering; Computer Science,
   Theory & Methods
DA 2023-11-11
ER

PT C
AU Clark, G
   Landis, G
   Barnes, E
   LaFuente, B
   Collins, K
AF Clark, Gilbert
   Landis, Geoffrey
   Barnes, Ethan
   LaFuente, Blake
   Collins, Kristina
GP IEEE
TI Testing a Neural Network Accelerator on a High-Altitude Balloon
SO 2019 IEEE COGNITIVE COMMUNICATIONS FOR AEROSPACE APPLICATIONS WORKSHOP
   (CCAAW)
DT Proceedings Paper
CT IEEE Cognitive Communications for Aerospace Applications Workshop
   (CCAAW)
CY JUN 25-26, 2019
CL Cleveland, OH
DE artificial intelligence; embedded systems; system verification
AB The cognitive communications project has been working to refine artificial intelligence and machine learning approaches to support their deployment and sustained use in space environments. It has historically been difficult to implement such techniques on space platforms, however, due to the computational requirements they levy onto general-purpose avionics hardware. While technologies exist to accelerate the computation of aspects of neural networks, such platforms have not historically been deployed in space environments. Given that testing payloads in such environments can be both cost- and time- prohibitive, high-altitude balloons can be used as a way to approximate a space environment at a much lower cost, thus providing a cost-effective way in which to test newer approaches to hardware acceleration for artificial intelligence which may be deployed onto spacecraft more directly.
   This paper describes a successful test of a commercial off-the-shelf neural network accelerator on a high-altitude balloon. It begins by explaining our selection criteria when evaluating different commercial neural network acceleration techniques: primary considerations include size, weight, and power (SWaP) as well as ease of integration. Next, the paper describes the development and implementation of an experimental flight test platform: flight and ground components are discussed. Afterward, the paper discusses the experimental payload itself: this includes the experimental procedure as well as the specific image and method used for testing. Finally, the paper concludes with an evaluation of both the experimental device tested at altitude as well as the flight test framework itself, identifying how the existing platform can be used to continue testing commercial off-the-shelf (COTS) solutions for acceleration.
C1 [Clark, Gilbert] NASA, Glenn Res Ctr, LCN Branch, Cleveland, OH 44135 USA.
   [Landis, Geoffrey] NASA, Glenn Res Ctr, LEX Branch, Cleveland, OH USA.
   [Barnes, Ethan; LaFuente, Blake; Collins, Kristina] NASA, Glenn Res Ctr, Intern, Cleveland, OH USA.
RP Clark, G (corresponding author), NASA, Glenn Res Ctr, LCN Branch, Cleveland, OH 44135 USA.
EM gilbert.j.clark@nasa.gov; geoffrey.landis@nasa.gov;
   ethancbarnes@gmail.com; blakelafuente@gmail.com;
   kristina.collins@case.edu
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   Alawad M, 2018, IEEE T MULTI-SCALE C, V4, P888, DOI 10.1109/TMSCS.2018.2886266
   Amert T, 2017, REAL TIM SYST SYMP P, P104, DOI 10.1109/RTSS.2017.00017
   Ashton K., 2009, RFID J, V22, P97, DOI DOI 10.1145/2967977
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Bonomi F, 2012, P 1 ED MCC WORKSH MO, P13, DOI 10.1145/2342509.2342513
   Cotton NJ, 2011, IEEE T IND ELECTRON, V58, P733, DOI 10.1109/TIE.2010.2098377
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Mankins JC, 2009, ACTA ASTRONAUT, V65, P1216, DOI 10.1016/j.actaastro.2009.03.058
   Moloney D, 2014, IEEE HOT CHIP SYMP
   Nagasubramanian G, 2001, J APPL ELECTROCHEM, V31, P99, DOI 10.1023/A:1004113825283
   Santoni F., 2002, COMMERCIAL LIION BAT, P502
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
NR 14
TC 0
Z9 0
U1 0
U2 0
PY 2019
DI 10.1109/ccaaw.2019.8904886
WC Engineering, Aerospace; Engineering, Electrical & Electronic;
   Telecommunications
DA 2023-11-11
ER

PT J
AU Amirsoleimani, A
   Alibart, F
   Yon, V
   Xu, JX
   Pazhouhandeh, MR
   Ecoffey, S
   Beilliard, Y
   Genov, R
   Drouin, D
AF Amirsoleimani, Amirali
   Alibart, Fabien
   Yon, Victor
   Xu, Jianxiong
   Pazhouhandeh, M. Reza
   Ecoffey, Serge
   Beilliard, Yann
   Genov, Roman
   Drouin, Dominique
TI In-Memory Vector-Matrix Multiplication in Monolithic Complementary
   Metal-Oxide-Semiconductor-Memristor Integrated Circuits: Design Choices,
   Challenges, and Perspectives
SO ADVANCED INTELLIGENT SYSTEMS
DT Review
DE complementary metal-oxide-semiconductor; inference; in-memory computing;
   memristors; redox-based random access memories; resistive switching
   memories; vector-matrix multiplications
ID RESISTIVE RAM; ENERGY; ACCELERATOR; ACCURACY
AB The low communication bandwidth between memory and processing units in conventional von Neumann machines does not support the requirements of emerging applications that rely extensively on large sets of data. More recent computing paradigms, such as high parallelization and near-memory computing, help alleviate the data communication bottleneck to some extent, but paradigm-shifting concepts are required. In-memory computing has emerged as a prime candidate to eliminate this bottleneck by colocating memory and processing. In this context, resistive switching (RS) memory devices is a key promising choice, due to their unique intrinsic device-level properties, enabling both storing and computing with a small, massively-parallel footprint at low power. Theoretically, this directly translates to a major boost in energy efficiency and computational throughput, but various practical challenges remain. A qualitative and quantitative analysis of several key existing challenges in implementing high-capacity, high-volume RS memories for accelerating the most computationally demanding computation in machine learning (ML) inference, that of vector-matrix multiplication (VMM), is presented. The monolithic integration of RS memories with complementary metal-oxide-semiconductor (CMOS) integrated circuits is presented as the core underlying technology. The key existing design choices in terms of device-level physical implementation, circuit-level design, and system-level considerations is reviewed and an outlook for future directions is provided.
C1 [Amirsoleimani, Amirali; Xu, Jianxiong; Pazhouhandeh, M. Reza; Genov, Roman] Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.
   [Alibart, Fabien; Yon, Victor; Ecoffey, Serge; Beilliard, Yann; Drouin, Dominique] Univ Sherbrooke, Inst Interdisciplinaire Innovat Technol 3IT, Sherbrooke, PQ J1K 0A5, Canada.
   [Alibart, Fabien; Yon, Victor; Ecoffey, Serge; Beilliard, Yann; Drouin, Dominique] CNRS UMI 3463 3IT, Lab Nanotechnol Nanosyst LN2, Sherbrooke, PQ J1K 0A5, Canada.
   [Alibart, Fabien] Univ Lille, Inst Elect Microelect & Nanotechnol IEMN, F-59650 Villeneuve Dascq, France.
RP Amirsoleimani, A (corresponding author), Univ Toronto, Dept Elect & Comp Engn, Toronto, ON M5S 2E4, Canada.; Alibart, F (corresponding author), Univ Sherbrooke, Inst Interdisciplinaire Innovat Technol 3IT, Sherbrooke, PQ J1K 0A5, Canada.; Alibart, F (corresponding author), CNRS UMI 3463 3IT, Lab Nanotechnol Nanosyst LN2, Sherbrooke, PQ J1K 0A5, Canada.; Alibart, F (corresponding author), Univ Lille, Inst Elect Microelect & Nanotechnol IEMN, F-59650 Villeneuve Dascq, France.
EM amirali.amirsoleimani@utoronto.ca; fabien.alibart@usherbrooke.ca
CR Adam G.C., 2018, NAT COMMUN, V9, P1
   Adam GC, 2017, IEEE T ELECTRON DEV, V64, P312, DOI 10.1109/TED.2016.2630925
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambrogio S, 2014, IEEE T ELECTRON DEV, V61, P2920, DOI 10.1109/TED.2014.2330202
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 1996, P SUPERCOMPUTING
   [Anonymous], 2018, 2018 IEEE INT EL DEV
   Armasu L., 2018, MOVE GPUS STARTUPS C
   Azghadi MR, 2020, ADV INTELL SYST-GER, V2, DOI 10.1002/aisy.201900189
   Bavandpour M., 2019, ARXIV PREPRINT ARXIV
   Bavandpour M., 2020, IEEE J EXPL SOL STAT
   Bavandpour M., 2019, IEEE T VERY LARGE SC
   Bavandpour M, 2019, IEEE T CIRCUITS-II, V66, P1512, DOI 10.1109/TCSII.2019.2891688
   Bayat FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04482-4
   Bocquet M, 2018, INT EL DEVICES MEET
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai F., 2019, ARXIV PREPRINT ARXIV
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Carusone TC, 2011, ANALOG INTEGR CIRC S
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YY, 2020, IEEE T ELECTRON DEV, V67, P1420, DOI 10.1109/TED.2019.2961505
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choi S, 2017, NANO LETT, V17, P3113, DOI 10.1021/acs.nanolett.7b00552
   Choi S, 2015, SCI REP-UK, V5, DOI 10.1038/srep10492
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Cutress I., 2018, CAMBRICON MAKER HAUW
   Dai YT, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-017-02527-8
   DeBole MV, 2019, COMPUTER, V52, P20, DOI 10.1109/MC.2019.2903009
   Dozortsev A, 2018, INT J CIRC THEOR APP, V46, P122, DOI 10.1002/cta.2399
   Du C, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-02337-y
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Eleftheriou E, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947008
   Eryilmaz SB, 2014, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00205
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Fang Su, 2017, 2017 Symposium on VLSI Technology, pT260, DOI 10.23919/VLSIT.2017.7998149
   Fantini A, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P30, DOI 10.1109/IMW.2013.6582090
   Fantini A., 2015, 2015 IEEE INT EL DEV
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gong YP, 2019, ACM T DES AUTOMAT EL, V24, DOI 10.1145/3290405
   Google, 2019, EDG TPU GOOGL PURP B
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Gupta I, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12805
   Haj-Ali A, 2018, IEEE T CIRCUITS-I, V65, P4258, DOI 10.1109/TCSI.2018.2846699
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Harpe P, 2016, IEEE J SOLID-ST CIRC, V51, P240, DOI 10.1109/JSSC.2015.2487270
   Hashemi S, 2017, DES AUT TEST EUROPE, P1474, DOI 10.23919/DATE.2017.7927224
   Hastings A., 2001, ART ANALOG LAYOUT
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hruska J, 2017, NEW MOVIDIUS MYRIAD
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hu SG, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms8522
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jiang H, 2018, NAT ELECTRON, V1, P548, DOI 10.1038/s41928-018-0146-5
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   KARABUTSA A, 1962, DOKL AKAD NAUK SSSR+, V145, P293
   Kavehei O, 2013, NANOSCALE, V5, P5119, DOI 10.1039/c3nr00535f
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Lee J, 2019, IEEE J SOLID-ST CIRC, V54, P173, DOI 10.1109/JSSC.2018.2865489
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Lim KY, 2010, INT EL DEVICES MEET
   Lin P, 2020, NAT ELECTRON, V3, P225, DOI 10.1038/s41928-020-0397-9
   LIU D, 2015, ACM SIGARCH COMPUT A, V43, P369, DOI DOI 10.1145/2786763.2694358
   Liu Q, 2020, ISSCC DIG TECH PAP I, P500, DOI 10.1109/ISSCC19947.2020.9062953
   Liu SJ, 2018, IEEE CIRC SYST MAG, V18, P29, DOI 10.1109/MCAS.2017.2785421
   Mahmoodi MR, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13103-7
   Mahmoodi MR, 2019, INT EL DEVICES MEET, DOI [10.1109/IBCAST.2019.8667140, 10.1109/iedm19573.2019.8993618]
   Marinella MJ, 2018, IEEE J EM SEL TOP C, V8, P86, DOI 10.1109/JETCAS.2018.2796379
   Merritt R., 2019, STARTUP ACCELERATES
   Midya R, 2019, ADV INTELL SYST-GER, V1, DOI 10.1002/aisy.201900084
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Moon J, 2019, NAT ELECTRON, V2, P480, DOI 10.1038/s41928-019-0313-3
   Moons B, 2017, ISSCC DIG TECH PAP I, P246, DOI 10.1109/ISSCC.2017.7870353
   Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762
   Murmann B., 2020, ADC PERFORMANCE SURV
   Mutlu O, 2019, MICROPROCESS MICROSY, V67, P28, DOI 10.1016/j.micpro.2019.01.009
   Nag A, 2018, IEEE MICRO, V38, P41, DOI 10.1109/MM.2018.053631140
   Nili H, 2018, NAT ELECTRON, V1, P197, DOI 10.1038/s41928-018-0039-7
   Ohnh┬u├▒user, 2015, ANALOG DIGITAL CONVE
   Pan WQ, 2020, IEEE T ELECTRON DEV, V67, P895, DOI 10.1109/TED.2019.2963323
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Prezioso M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21331
   RABUSKE T, 2017, CHARGE SHARING SAR A
   Rahimi A, 2017, IEEE T CIRCUITS-I, V64, P2508, DOI 10.1109/TCSI.2017.2705051
   Rockchip, 2018, ROCKCH REL ITS 1 AL
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Sassine G, 2016, J VAC SCI TECHNOL B, V34, DOI 10.1116/1.4940129
   Schreier R., 2005, UNDERSTANDING DELTA, V74
   Sebastian A., 2019, 2019 Symposium on VLSI Technology, pT168, DOI 10.23919/VLSIT.2019.8776518
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serb A, 2016, NAT COMMUN, V7, DOI 10.1038/ncomms12611
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Strukov, 2019, ARXIV PREPRINT ARXIV
   Strukov D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12521-x
   Strukov DB, 2008, NATURE, V453, P80, DOI 10.1038/nature06932
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sung C, 2018, J APPL PHYS, V124, DOI 10.1063/1.5037835
   Sze V, 2017, 2017 IEEE CUSTOM INT, P1
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   VONNEUMANN J, 1993, IEEE ANN HIST COMPUT, V15, P28
   Walden RH, 1999, IEEE J SEL AREA COMM, V17, P539, DOI 10.1109/49.761034
   Wu TF, 2019, ISSCC DIG TECH PAP I, V62, P226, DOI 10.1109/ISSCC.2019.8662402
   Wu TF, 2018, ISSCC DIG TECH PAP I, P492, DOI 10.1109/ISSCC.2018.8310399
   Xia LX, 2019, IEEE T COMPUT AID D, V38, P1611, DOI 10.1109/TCAD.2018.2855145
   Xia QF, 2019, NAT MATER, V18, P309, DOI 10.1038/s41563-019-0291-x
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
NR 126
TC 63
Z9 63
U1 7
U2 36
PD NOV
PY 2020
VL 2
IS 11
AR 2000115
DI 10.1002/aisy.202000115
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
DA 2023-11-11
ER

PT J
AU Bardhan, A
   Alzo'ubi, AK
   Palanivelu, S
   Hamidian, P
   GuhaRay, A
   Kumar, G
   Tsoukalas, MZ
   Asteris, PG
AF Bardhan, Abidhan
   Alzo'ubi, Abdel Kareem
   Palanivelu, Sangeetha
   Hamidian, Pouria
   GuhaRay, Anasua
   Kumar, Gaurav
   Tsoukalas, Markos Z.
   Asteris, Panagiotis G.
TI A hybrid approach of ANN and improved PSO for estimating soaked CBR of
   subgrade soils of heavy-haul railway corridor
SO INTERNATIONAL JOURNAL OF PAVEMENT ENGINEERING
DT Article
DE Subgrade design; transportation infrastructure; Indian railways;
   artificial neural network; particle swarm optimisation
ID ARTIFICIAL NEURAL-NETWORK; FINE-GRAINED SOILS; BEARING RATIO CBR;
   PREDICTION; PERFORMANCE; REGRESSION; MODELS
AB The determination of subgrade/subsoil strength is one of the most important pavement design factors in transportation engineering, particularly for railways, roadways, and airport runways. The California bearing ratio (CBR) is often used to measure the strength and stiffness modulus of subgrade materials. This study presents a novel machine learning solution as an alternate approach for estimating soil CBR in soaked conditions. The present approach is an integration of an artificial neural network (ANN) and improved particle swarm optimisation (IPSO). According to experimental results during the testing phase, the proposed hybrid model, ANN-IPSO has achieved the highest predictive precision with root mean square error, RMSE = 0.0711 and mean absolute error, MAE = 0.0546. The findings of the proposed model are far superior to those of employed models including the conventional ANN, support vector machine, and group method of data handling. Six additional hybrid models of ANN and standard PSO (SPSO), PSO with time-varying accelerator coefficients, modified PSO, Harris hawks optimisation, slime mould algorithm, and colony predation algorithm were also constructed for a detailed comparison. Based on the outcomes, the newly created ANN-IPSO has the potential to be a new tool to estimate soaked CBR of fine-grained soils in civil engineering projects.
C1 [Bardhan, Abidhan] Natl Inst Technol Patna, Dept Civil Engn, Patna, Bihar, India.
   [Alzo'ubi, Abdel Kareem] Abu Dhabi Univ, Dept Civil Engn, Al Ain, U Arab Emirates.
   [Palanivelu, Sangeetha] Sri Sivasubramaniya Nadar Coll Engn, Dept Civil Engn, Chennai, India.
   [Hamidian, Pouria] Univ Tehran, Coll Engn, Sch Civil Engn, Tehran, Iran.
   [GuhaRay, Anasua] BITS Pilani Hyderabad Campus, Hyderabad, India.
   [Kumar, Gaurav] GLA Univ, Dept Comp Engn & Applicat, Mathura, India.
   [Tsoukalas, Markos Z.; Asteris, Panagiotis G.] Computat Mech Lab, Sch Pedag & Technol Educ, Athens, Heraklion, Greece.
RP Asteris, PG (corresponding author), Computat Mech Lab, Sch Pedag & Technol Educ, Athens, Heraklion, Greece.
EM asteris@aspete.gr
CR Agarwal K., 1970, PROCEEDING 2 S E ASI
   Al-Busultan Shakir, 2020, IOP Conference Series: Materials Science and Engineering, V671, DOI 10.1088/1757-899X/671/1/012106
   Al-Refeai T., 1997, J KING SAUD U ENG SC, V9, P191
   Alam SK, 2020, J GEOL SOC INDIA, V95, P190, DOI 10.1007/s12594-020-1409-0
   Alel MNA, 2018, J PHYS CONF SER, V995, DOI 10.1088/1742-6596/995/1/012046
   Alemdag S, 2016, ENG GEOL, V203, P70, DOI 10.1016/j.enggeo.2015.12.002
   Alzabeebee S, 2022, ROAD MATER PAVEMENT, V23, P2733, DOI 10.1080/14680629.2021.1995471
   Alzo'Ubi AK, 2021, INT J GEOTECH ENG, V15, P810, DOI 10.1080/19386362.2018.1519975
   Alzo'ubi AK, 2019, GEOTECH GEOL ENG, V37, P1311, DOI 10.1007/s10706-018-0687-4
   Alzo'ubi A. K., 2018, MATEC Web of Conferences, V149, DOI 10.1051/matecconf/201814902031
   Alzoubi A.K., 2018, INT C EXHIBITION SUS, P49, DOI [10.1007/978-3-030-01902-0_5, DOI 10.1007/978-3-030-01902-0_5]
   [Anonymous], 1987, 2720 IS
   Armaghani DJ, 2014, ARAB J GEOSCI, V7, P5383, DOI 10.1007/s12517-013-1174-0
   Asteris PG, 2020, NEURAL COMPUT APPL, V32, P11807, DOI 10.1007/s00521-019-04663-2
   Bao GQ, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P2134, DOI 10.1109/ROBIO.2009.5420504
   Bardhan A, 2021, APPL SOFT COMPUT, V110, DOI 10.1016/j.asoc.2021.107595
   Bhatt S., 2014, AM INT J RES SCI TEC, V8, P156
   Black WPM., 1962, GEOTECHNIQUE, V12, P271, DOI [10.1680/geot.1962.12.4.271, DOI 10.1680/GEOT.1962.12.4.271]
   Bui XN, 2020, NAT RESOUR RES, V29, P571, DOI 10.1007/s11053-019-09461-0
   Cabalar AF, 2019, ROAD MATER PAVEMENT, V20, P702, DOI 10.1080/14680629.2017.1407817
   Cabalar AF, 2015, J TEST EVAL, V43, DOI 10.1520/JTE20130070
   Cevik A, 2011, APPL SOFT COMPUT, V11, P2587, DOI 10.1016/j.asoc.2010.10.008
   Chandra S, 2018, ENERGY REP, V4, P252, DOI 10.1016/j.egyr.2017.11.001
   Cui ZH, 2008, ISDA 2008: EIGHTH INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEMS DESIGN AND APPLICATIONS, VOL 2, PROCEEDINGS, P638, DOI 10.1109/ISDA.2008.86
   De Graft-Johnson JWS., 1969, P 7 INT C SOIL MECH, V2, P13
   Dharma Silalahi Divo, 2016, Information Processing in Agriculture, V3, P252, DOI 10.1016/j.inpa.2016.10.001
   Bui DT, 2018, ADV ENG INFORM, V38, P593, DOI 10.1016/j.aei.2018.09.005
   Dorn M, 2012, EXPERT SYST APPL, V39, P12268, DOI 10.1016/j.eswa.2012.04.046
   Trong DK, 2021, MATERIALS, V14, DOI 10.3390/ma14216516
   Ebtehaj I, 2015, ENG SCI TECHNOL, V18, P746, DOI 10.1016/j.jestch.2015.04.012
   Edincliler A, 2013, EUR J ENVIRON CIV EN, V17, P720, DOI 10.1080/19648189.2013.814552
   Erzin Y, 2016, NEURAL COMPUT APPL, V27, P1415, DOI 10.1007/s00521-015-1943-7
   Faridmehr I, 2021, BUILDINGS-BASEL, V11, DOI 10.3390/buildings11060229
   Fukuyama Y, 2001, IEEE C EVOL COMPUTAT, P87, DOI 10.1109/CEC.2001.934375
   Ghorbani A, 2018, SOILS FOUND, V58, P34, DOI 10.1016/j.sandf.2017.11.002
   Golafshani EM, 2020, CONSTR BUILD MATER, V232, DOI 10.1016/j.conbuildmat.2019.117266
   Farias IG, 2018, GEOTECH GEOL ENG, V36, P3485, DOI 10.1007/s10706-018-0548-1
   Ly HB, 2021, NEURAL COMPUT APPL, V33, P3437, DOI 10.1007/s00521-020-05214-w
   Hajihassani M, 2014, APPL ACOUST, V80, P57, DOI 10.1016/j.apacoust.2014.01.005
   Hasanipanah M, 2017, NEURAL COMPUT APPL, V28, pS1043, DOI 10.1007/s00521-016-2434-1
   Hassan J, 2022, TRANSP INFRASTRUCT G, V9, P764, DOI 10.1007/s40515-021-00197-0
   Heidari AA, 2019, FUTURE GENER COMP SY, V97, P849, DOI 10.1016/j.future.2019.02.028
   Ibrahim F, 2023, ARAB J SCI ENG, V48, P4403, DOI 10.1007/s13369-022-06969-1
   IVAKHNENKO AG, 1971, IEEE T SYST MAN CYB, VSMC1, P364, DOI 10.1109/TSMC.1971.4308320
   Katte VY, 2019, GEOTECH GEOL ENG, V37, P217, DOI 10.1007/s10706-018-0604-x
   Kennedy J., 2001, SWARM INTELLIGENCE, DOI DOI 10.1016/B978-155860595-4/50007-3
   Khan MUA, 2022, SOFT COMPUT, V26, P6839, DOI 10.1007/s00500-021-06628-x
   Khan MUA, 2021, NEURAL COMPUT APPL, V33, P14861, DOI 10.1007/s00521-021-06125-0
   Kin MW., 2006, CALIFORNIA BEARING R
   Koopialipoor M, 2019, ENG COMPUT-GERMANY, V35, P243, DOI 10.1007/s00366-018-0596-4
   Kumar S.A., 2013, CBR REMOLDED SOILS, V2, P3019
   Kurnaz TF, 2019, EUR PHYS J PLUS, V134, DOI 10.1140/epjp/i2019-12692-0
   Le LT, 2019, APPL SCI-BASEL, V9, DOI 10.3390/app9132630
   Li SM, 2020, FUTURE GENER COMP SY, V111, P300, DOI 10.1016/j.future.2020.03.055
   Lili Chen, 2020, IOP Conference Series: Earth and Environmental Science, V428, DOI 10.1088/1755-1315/428/1/012089
   Liou SW, 2009, J UNIVERS COMPUT SCI, V15, P742
   Mandal A, 2021, ENERGIES, V14, DOI 10.3390/en14102910
   Min SH, 2006, EXPERT SYST APPL, V31, P652, DOI 10.1016/j.eswa.2005.09.070
   Moayedi H, 2020, ENG COMPUT-GERMANY, V36, P671, DOI 10.1007/s00366-019-00723-2
   Monjezi M, 2012, ARAB J GEOSCI, V5, P441, DOI 10.1007/s12517-010-0185-3
   Murlidhar BR, 2020, NAT RESOUR RES, V29, P4103, DOI 10.1007/s11053-020-09676-6
   NCHRP (National Cooperative Highway Research Program), 2004, 137A NCHRP
   Nefeslioglu HA, 2008, ENG GEOL, V97, P171, DOI 10.1016/j.enggeo.2008.01.004
   Nordin NFC, 2021, GROUNDWATER SUST DEV, V14, DOI 10.1016/j.gsd.2021.100643
   Otchere DA, 2021, J PETROL SCI ENG, V200, DOI 10.1016/j.petrol.2020.108182
   Pandey SK, 2020, ADV INTELL SYST COMP, V1079, P409, DOI 10.1007/978-981-15-1097-7_34
   Patel R. S., 2010, P IND GEOT C MUMB NE, P79
   Pradeep Kumar KJ., 2016, INT J INNOVATIVE RES, V5, P13852
   Quan V., 2022, J SCI TRANSPORT TECH, V1, DOI [10.58845/jstt.utt.2021.en3, DOI 10.58845/JSTT.UTT.2021.EN3]
   Rad HN, 2020, NAT RESOUR RES, V29, P609, DOI 10.1007/s11053-019-09464-x
   Raghurama G., 2018, DEDICATED FREIGHT CO
   Raja MNA, 2021, GEOSYNTH INT, V28, P368, DOI 10.1680/jgein.20.00049
   Raja MNA, 2021, GEOTEXT GEOMEMBRANES, V49, P1280, DOI 10.1016/j.geotexmem.2021.04.007
   Raja MNA, 2022, INT J PAVEMENT ENG, V23, P3505, DOI 10.1080/10298436.2021.1904237
   Ratnaweera A, 2004, IEEE T EVOLUT COMPUT, V8, P240, DOI [10.1109/TEVC.2004.826071, 10.1109/tevc.2004.826071]
   Roy P, 2019, IEEE-CAA J AUTOMATIC, V6, P1365, DOI 10.1109/JAS.2019.1911753
   Roy T.K., 2013, P INT S ENG UNCERTAI, DOI [10.1007/978-81-322-0757-3, DOI 10.1007/978-81-322-0757-3]
   Sabat KA., 2015, ELECTRON J GEOTECH E, V20, P981
   Srivastava P, 2021, MULTIMED TOOLS APPL, V80, P14887, DOI 10.1007/s11042-021-10544-5
   Stephens D.J., 1990, CIV ENG SIVIELE INGE, V1990, P523
   Suthar M, 2018, INT J GEOSYNTH GROUN, V4, DOI 10.1007/s40891-017-0125-3
   Taha S, 2019, ARAB J SCI ENG, V44, P8691, DOI 10.1007/s13369-019-03803-z
   Tang ZY, 2009, 2009 ASIA-PACIFIC CONFERENCE ON INFORMATION PROCESSING (APCIP 2009), VOL 2, PROCEEDINGS, P330, DOI 10.1109/APCIP.2009.217
   Taskiran T, 2010, ADV ENG SOFTW, V41, P886, DOI 10.1016/j.advengsoft.2010.01.003
   TAYLOR CE, 1994, JH HOLLAND Q REV BIO, V69, P88, DOI DOI 10.1086/418447
   Taylor KE, 2001, J GEOPHYS RES-ATMOS, V106, P7183, DOI 10.1029/2000JD900719
   Tenpe AR, 2020, ARAB J SCI ENG, V45, P4301, DOI 10.1007/s13369-020-04441-6
   Tu J, 2021, J BIONIC ENG, V18, P674, DOI 10.1007/s42235-021-0050-y
   van den Bergh F, 2006, INFORM SCIENCES, V176, P937, DOI 10.1016/j.ins.2005.02.003
   Varghese VK, 2013, GEOTECH GEOL ENG, V31, P1187, DOI 10.1007/s10706-013-9643-5
   Wang HL, 2020, ENG GEOL, V276, DOI 10.1016/j.enggeo.2020.105758
   Yildirim B, 2011, EXPERT SYST APPL, V38, P6381, DOI 10.1016/j.eswa.2010.12.054
NR 92
TC 3
Z9 3
U1 20
U2 29
PD DEC 6
PY 2023
VL 24
IS 1
AR 2176494
DI 10.1080/10298436.2023.2176494
WC Construction & Building Technology; Engineering, Civil; Materials
   Science, Characterization & Testing
DA 2023-11-11
ER

PT C
AU Sharma, A
   Bhasi, VM
   Singh, S
   Jain, R
   Gunasekaran, JR
   Mitra, S
   Kandemir, MT
   Kesidis, G
   Das, CR
AF Sharma, Aakash
   Bhasi, Vivek M.
   Singh, Sonali
   Jain, Rishabh
   Gunasekaran, Jashwant Raj
   Mitra, Subrata
   Kandemir, Mahmut Taylan
   Kesidis, George
   Das, Chita R.
GP IEEE
TI Stash: A comprehensive stall-centric characterization of public cloud
   VMs for distributed deep learning
SO 2023 IEEE 43RD INTERNATIONAL CONFERENCE ON DISTRIBUTED COMPUTING
   SYSTEMS, ICDCS
SE IEEE International Conference on Distributed Computing Systems
DT Proceedings Paper
CT 43rd IEEE International Conference on Distributed Computing Systems
   (ICDCS)
CY JUL 18-21, 2023
CL Hong Kong, HONG KONG
ID PYTORCH
AB Deep neural networks (DNNs) are increasingly popular owing to their ability to solve complex problems such as image recognition, autonomous driving, and natural language processing. Their growing complexity coupled with the use of larger volumes of training data (to achieve acceptable accuracy) has warranted the use of GPUs and other accelerators. Such accelerators are typically expensive, with users having to pay a high upfront cost to acquire them. For infrequent use, users can, instead, leverage the public cloud to mitigate the high acquisition cost. However, with the wide diversity of hardware instances (particularly GPU instances) available in public cloud, it becomes challenging for a user to make an appropriate choice from a cost/performance standpoint.
   In this work, we try to address this problem by (i) introducing a comprehensive distributed deep learning (DDL) profiler Stash, which determines the various execution stalls that DDL suffers from, and (ii) using Stash to extensively characterize various public cloud GPU instances by running popular DNN models on them. Specifically, it estimates two types of communication stalls, namely, interconnect and network stalls, that play a dominant role in DDL execution time. Stash is implemented on top of prior work, DS-analyzer, that computes only the CPU and disk stalls. Using our detailed stall characterization, we list the advantages and shortcomings of public cloud GPU instances for users to help them make an informed decision(s). Our characterization results indicate that the more expensive GPU instances may not be the most performant for all DNN models and that AWS can sometimes sub-optimally allocate hardware interconnect resources. Specifically, the intra-machine interconnect can introduce communication overheads of up to 90% of DNN training time and the network-connected instances can suffer from up to 5x slowdown compared to training on a single instance. Furthermore, (iii) we also model the impact of DNN macroscopic features such as the number of layers and the number of gradients on communication stalls, and finally, (iv) we briefly discuss a cost comparison with existing work.
C1 [Sharma, Aakash; Bhasi, Vivek M.; Singh, Sonali; Jain, Rishabh; Kandemir, Mahmut Taylan; Kesidis, George; Das, Chita R.] Penn State Univ, Comp Sci & Engn, University Pk, PA 16802 USA.
   [Gunasekaran, Jashwant Raj; Mitra, Subrata] Adobe Res, San Francisco, CA USA.
RP Sharma, A (corresponding author), Penn State Univ, Comp Sci & Engn, University Pk, PA 16802 USA.
EM abs5688@psu.edu; vmbhasi@psu.edu; sms821@psu.edu; rishabh@psu.edu;
   jgunasekaran@adobe.com; subrata.mitra@adobe.com; mtk2@psu.edu;
   gik2@psu.edu; cxd12@psu.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], AL PAI
   [Anonymous], NVIDIA DEEP LEARN EX
   [Anonymous], NVPROF
   [Anonymous], DAWNBENCH
   [Anonymous], IMAGENET LARGE SCALE
   [Anonymous], AWS NVIDIA GPU INST
   Awan AA, 2019, IEEE ACM INT SYMP, P498, DOI [10.1109/CCGRID.2019.00064, 10.1109/ccgrid.2019.00064]
   Bhasi Vivek M., 2021, P SOCC 21
   Bhasi Vivek M., 2022, P SOCC 22
   Dean Jeffrey, 2012, P ADV NEUR INF PROC, V25
   Devlin Jacob, 2019, P NAACL HLT 19
   Fukuda K., TECHNOLOGIES DISTRIB
   Goyal P, 2018, Arxiv, DOI [arXiv:1706.02677, DOI 10.48550/ARXIV.1706.02677]
   He KM, 2016, LECT NOTES COMPUT SC, V9908, P630, DOI 10.1007/978-3-319-46493-0_38
   Ho Qirong, 2013, P NIPS
   Jain A, 2019, IEEE INT C CL COMP, P58, DOI 10.1109/cluster.2019.8891042
   Kheria Rashika, OPTIMIZING DEEP LEAR
   Ko Y, 2021, INT PARALL DISTRIB P, P994, DOI 10.1109/IPDPS49936.2021.00108
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Leong MC, 2020, APPL SCI-BASEL, V10, DOI 10.3390/app10020557
   Li A, 2020, IEEE T PARALL DISTR, V31, P94, DOI 10.1109/TPDS.2019.2928289
   Li M, 2014, 11 USENIX S OP SYST, P583, DOI DOI 10.1145/2640087.2644155
   Li S, 2020, PROC VLDB ENDOW, V13, P3005, DOI 10.14778/3415478.3415530
   Lian XR, 2018, PR MACH LEARN RES, V80
   Liu J, 2019, INT C PAR DISTRIB SY, P506, DOI 10.1109/ICPADS47876.2019.00077
   Luo Liang, 2022, MLSYS, V4, P833
   Ma NN, 2018, LECT NOTES COMPUT SC, V11218, P122, DOI 10.1007/978-3-030-01264-9_8
   Mattson Peter, 2020, MLSYS, V2, P336
   Mohan J, 2021, Arxiv, DOI arXiv:2007.06775
   Mojumder SA, 2018, I S WORKL CHAR PROC, P122, DOI 10.1109/IISWC.2018.8573521
   Iandola FN, 2016, Arxiv, DOI [arXiv:1602.07360, 10.7717/peerj-cs.528/fig-8]
   Narayanan D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P1, DOI 10.1145/3341301.3359646
   Nsight, US
   Parmar N, 2018, PR MACH LEARN RES, V80
   Rabenseifner R, 2004, LECT NOTES COMPUT SC, V3036, P1
   Rajpurkar P, 2016, P 2016 C EMP METH NA, P2383, DOI [10.18653/v1/d16-1264, DOI 10.18653/V1/D16-1264]
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sharma A, 2022, Arxiv, DOI arXiv:2208.14344
   Sharma Aakash, 2021, P IEEEACM CCGRID
   Keskar NS, 2017, Arxiv, DOI arXiv:1609.04836
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Singh S, 2020, ANN I S COM, P363, DOI 10.1109/ISCA45697.2020.00039
   Singh Sonali, 2022, P 55 IEEEACM MICRO
   Stash, US
   Wang C., 2017, P ACM SIGMETRICS URB
   Wang MD, 2019, I S WORKL CHAR PROC, P189, DOI 10.1109/IISWC47752.2019.9042047
   Weng QZ, 2022, PROCEEDINGS OF THE 19TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '22), P945
   Xia CW, 2018, I S WORKL CHAR PROC, P82, DOI 10.1109/IISWC.2018.8573514
   Yi J, 2020, INT PARALL DISTRIB P, P419, DOI 10.1109/IPDPS47924.2020.00051
   Zhang CL, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P1049
   Zhang Hao, 2017, P USENIX ATC
   Zhang SX, 2015, ADV NEUR IN, V28
   Zhang Tianwei, P SC 21
   Zhu HY, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P337
NR 55
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 875
EP 886
DI 10.1109/ICDCS57875.2023.00023
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Telecommunications
DA 2023-11-11
ER

PT C
AU Sharma, T
   Wang, C
   Agrawal, A
   Roy, K
AF Sharma, Tanvi
   Wang, Cheng
   Agrawal, Amogh
   Roy, Kaushik
GP IEEE
TI Enabling Robust SOT-MTJ Crossbars for Machine Learning using
   Sparsity-Aware Device-Circuit Co-design
SO 2021 IEEE/ACM INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND
   DESIGN (ISLPED)
SE International Symposium on Low Power Electronics and Design
DT Proceedings Paper
CT IEEE/ACM International Symposium on Low Power Electronics and Design
   (ISLPED)
CY JUL 26-28, 2021
CL ELECTR NETWORK
AB Embedded non-volatile memory (eNVM) based crossbars have emerged as energy-efficient building blocks for machine learning accelerators. However, the analog computations in crossbars introduce errors due to several non-idealities. Moreover, since communications between crossbars are usually done in the digital domain, the energy and area costs are dominated by the Analog-to-Digital Converters (ADC). Among the eNVM technologies, Resistive Random-Access-Memory (RRAM) and Phase-Change Memory (PCM) devices suffer from poor endurance, write variability and conductance drift. Whereas magneto-resistive technologies provide superior endurance, write stability and reliability. To that effect, we propose sparsity-aware device/circuit co-design of robust crossbars using Spin-Orbit-Torque Magnetic Tunnel Junctions (SOT-MTJs). Note, standard MTJs have low R-OFF/R-ON and low R-ON, making them unsuitable for crossbars. In this work, we first demonstrate SOT-MTJs as crossbar elements with high R-ON and high R-OFF/R-ON by allowing the read-path to have thicker tunneling-barrier, leaving the write path undisturbed. Second, through extensive simulations, we quantitatively assess the impact of various device-circuit parameters such as R-ON, R-OFF/R-ON ratio, crossbar size, along with input and weight sparsity, on both circuit and application level accuracy and energy consumption. We evaluate system accuracy for Resnet-20 inference on CIFAR-10 dataset and show that leveraging sparsity allows reduced ADC precision, without degrading accuracy. Our results show that an SOT-MTJ (R-ON=200k Omega and E-OFF/R-ON=7) crossbar array of size 32x32 could achieve near-software accuracy. The 64x64 and 128x128 crossbars show an accuracy degradation of 2% and 9.8%, respectively, from the software accuracy and an energy improvement of upto 3.8 x and 6.3x compared to a 32x32array with 4bit-ADC.
C1 [Sharma, Tanvi; Wang, Cheng; Agrawal, Amogh; Roy, Kaushik] Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Sharma, T (corresponding author), Purdue Univ, Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM sharm418@purdue.edu
CR Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   Boniardi M, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3599559
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Chakraborty J, 2020, PROCEEDINGS OF THE 2020 IEEE 10TH INTERNATIONAL CONFERENCE ON NANOMATERIALS: APPLICATIONS & PROPERTIES (NAP-2020)
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Choquette J., 2020, IEEE HOT CHIPS S
   Doevenspeck J., 2020, S VLSI TECH
   Edelstein D, 2020, INT EL DEVICES MEET, DOI 10.1109/IEDM13553.2020.9371922
   Fleischer B., 2020, IBM RES BLOG
   Haensch W, 2019, P IEEE, V107, P108, DOI 10.1109/JPROC.2018.2871057
   He K., 2015, ARXIV
   Ikeda S, 2010, NAT MATER, V9, P721, DOI [10.1038/NMAT2804, 10.1038/nmat2804]
   Ikeda S, 2008, APPL PHYS LETT, V93, DOI 10.1063/1.2976435
   Ikegawa S, 2020, IEEE T ELECTRON DEV, V67, P1407, DOI 10.1109/TED.2020.2965403
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Li HT, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317874
   Lin C. J., 2009, IEDM, P1
   Murmann B., 2018, ADC PERFORMANCE SURV
   Park C, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P185, DOI 10.1109/VLSIT.2018.8510653
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shi YH, 2020, IEEE ELECTR DEVICE L, V41, P1126, DOI 10.1109/LED.2020.2995819
   Xuanyao Fong, 2011, 2011 International Conference on Simulation of Semiconductor Processes and Devices (SISPAD 2011), P51, DOI 10.1109/SISPAD.2011.6035047
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yuasa S, 2004, NAT MATER, V3, P868, DOI 10.1038/nmat1257
NR 24
TC 9
Z9 9
U1 1
U2 3
PY 2021
DI 10.1109/ISLPED52811.2021.9502492
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Gupta, S
   Ullah, S
   Ahuja, K
   Tiwari, A
   Kumar, A
AF Gupta, Siddharth
   Ullah, Salim
   Ahuja, Kapil
   Tiwari, Aruna
   Kumar, Akash
TI ALigN: A Highly Accurate Adaptive Layerwise Log&x005F;2&x005F;Lead
   Quantization of Pre-Trained Neural Networks
SO IEEE ACCESS
DT Article
DE Machine learning; deep neural networks; quantization; multipliers
AB Deep Neural Networks are one of the machine learning techniques which are increasingly used in a variety of applications. However, the significantly high memory and computation demands of deep neural networks often limit their deployment on embedded systems. Many recent works have considered this problem by proposing different types of data quantization schemes. However, most of these techniques either require post-quantization retraining of deep neural networks or bear a significant loss in output accuracy. In this paper, we propose a novel and scalable technique with two different modes for the quantization of the parameters of pre-trained neural networks. In the first mode, referred to as <italic>log & x005F;2 & x005F;lead</italic>, we use a single template for the quantization of all parameters. In the second mode, denoted as <italic>ALigN</italic>, we analyze the trained parameters of each layer and adaptively adjust the quantization template to achieve even higher accuracy. Our technique significantly maintains the accuracy of the parameters and does not require retraining of the networks. Moreover, it supports quantization to an arbitrary bit-size. For example, compared to the single-precision floating-point numbers-based implementation, our proposed 8-bit quantization technique generates only and , loss in the Top-1 and Top-5 accuracies respectively for VGG-16 network using ImageNet dataset. We have observed similar minimal losses in the Top-1 and Top-5 accuracies for AlexNet and Resnet-18 using the proposed quantization scheme for the 8-bit range. Our proposed quantization technique also provides a higher mean intersection over union for semantic segmentation when compared with state-of-the-art quantization techniques. The proposed technique represents parameters in powers of 2, thereby eliminating the need for resource-computationally intensive multiplier units for the hardware accelerators of the neural networks. We also present a design for implementing the multiplication operation using bit-shifts and addition for the proposed quantization technique.
C1 [Gupta, Siddharth; Ahuja, Kapil; Tiwari, Aruna] Indian Inst Technol Indore, Dept Comp Sci & Engn, Indore 453552, India.
   [Ullah, Salim; Kumar, Akash] Tech Univ Dresden, Dept Comp Sci, D-01062 Dresden, Germany.
RP Ullah, S; Kumar, A (corresponding author), Tech Univ Dresden, Dept Comp Sci, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; akash.kumar@tu-dresden.de
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   [Anonymous], 2015, NEURAL NETWORKS FEW
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Dally, 2016, ARXIV161201064
   de Prado M, 2018, 2018 ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS, P36, DOI 10.1145/3203217.3203282
   Deng L, 2013, IEEE INT NEW CIRC
   Everingham M, 2015, INT J COMPUT VISION, V111, P98, DOI 10.1007/s11263-014-0733-5
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hinton G, 2009, LEARNING MULTIPLE LA
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kalamkar D., 2019, ARXIV190512322
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   Lin DD, 2016, PR MACH LEARN RES, V48
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Miyashita D., 2016, ARXIV160301025
   Mordido G., 2019, ARXIV190512253
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tann H, 2017, DES AUT CON, DOI 10.1145/3061639.3062259
   Ullah S, 2020, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE48585.2020.9116373
   Vogel S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240803
   Vogel S, 2019, DES AUT TEST EUROPE, P1094, DOI [10.23919/date.2019.8714901, 10.23919/DATE.2019.8714901]
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou S., 2016, ARXIV160606160
NR 31
TC 7
Z9 7
U1 0
U2 4
PY 2020
VL 8
BP 118899
EP 118911
DI 10.1109/ACCESS.2020.3005286
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Tumeo, A
AF Tumeo, Antonino
GP Assoc Comp Machinery
TI Data and Model Convergence: a Case for Software Defined Architectures
SO CF '19 - PROCEEDINGS OF THE 16TH ACM INTERNATIONAL CONFERENCE ON
   COMPUTING FRONTIERS
DT Proceedings Paper
CT 16th ACM International Conference on Computing Frontiers (CF)
CY APR 30-MAY 02, 2019
CL Alghero, ITALY
DE Data-Model Convergence; reconfigurable architectures
AB High Performance Computing, data analytics, and machine learning are often considered three separate and different approaches. Applications, software and now hardware stacks are typically designed to only address one of the areas at a time. This creates a false distinction across the three different areas. In reality, domain scientists need to exercise all the three approaches in an integrated way. For example, large scale simulations generate enormous amount of data, to which Big Data Analytics techniques can be applied. Or, as scientist seek to use data analytics as well as simulation for discovery, machine learning can play an important role in making sense of the disparate source's information. Pacific Northwest National Laboratory is launching a new Laboratory Directed Research and Development (LDRD) Initiative to investigate the integration of the three techniques at all level of the high-performance computing stack, the Data-Model Convergence (DMC) Initiative. The DMC Initiative aims to increase scientist productivity by enabling purpose-built software and hardware and domain-aware ML techniques.
   In this talk, I will present the objectives of PNNL's DMC Initiative, highlighting the research that will be performed to enable the integration of vastly different programming paradigms and mental models. I will then make the case for how reconfigurable architectures could represent a great opportunity to address the challenges of DMC. In principle, the possibility to dynamically modify the architecture during runtime could provide a way to address the requirement of workloads that have significantly diverse behaviors across phases, without losing too much flexibility or programmer productivity, with respect to highly heterogeneous architectures composed by sea of fixed application specific accelerators. Reconfigurable architectures have been explored since long time ago, and arguably new software breakthroughs are required to make them successful. I will thus present the efforts that the DMC initiative is launching to design a productive toolchain for upcoming novel reconfigurable systems.
C1 [Tumeo, Antonino] Pacific Northwest Natl Lab, High Performance Comp, Richland, WA 99352 USA.
RP Tumeo, A (corresponding author), Pacific Northwest Natl Lab, High Performance Comp, Richland, WA 99352 USA.
EM antonino.tumeo@pnnl.gov
NR 0
TC 0
Z9 0
U1 0
U2 4
PY 2019
BP 343
EP 343
DI 10.1145/3310273.3323438
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Krithivasan, S
   Sen, S
   Raghunathan, A
AF Krithivasan, Sarada
   Sen, Sanchari
   Raghunathan, Anand
TI Sparsity Turns Adversarial: Energy and Latency Attacks on Deep Neural
   Networks
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Adversarial machine learning; deep neural networks; sparsity in DNNs
AB Adversarial attacks have exposed serious vulnerabilities in deep neural networks (DNNs), causing misclassifications through human-imperceptible perturbations to DNN inputs. We explore a new direction in the field of adversarial attacks by suggesting attacks that aim to degrade the energy or latency of DNNs rather than their classification accuracy. As a specific embodiment of this new threat vector, we propose and demonstrate adversarial sparsity attacks, which modify a DNN's inputs so as to reduce sparsity (or the incidence of zeros) in its internal activation values. Exploiting sparsity in hardware and software has emerged as a popular approach to improve DNN efficiency in resource-constrained systems. The proposed attack, therefore, increases the execution time and energy consumption of sparsity-optimized DNN implementations, raising concern over their deployment in latency and energy-critical applications. We propose a systematic methodology to generate adversarial inputs for sparsity attacks by formulating an objective function that quantifies the network's activation sparsity and minimizing this function using iterative gradient-descent techniques. To prevent easy detection of the attack, we further ensure that the perturbation magnitude is within a specified constraint and that the perturbation does not affect classification accuracy. We launch both white-box and black-box versions of adversarial sparsity attacks on image recognition DNNs and demonstrate that they decrease activation sparsity by 1.16x-1.82x. On a sparsity-optimized DNN accelerator, the attack results in degradations of 1.12x-1.59x in latency and 1.18x-1.99x in energy-delay product (EDP). Additionally, we analyze the impact of various hyperparameters and constraints on the attack's efficacy. Finally, we evaluate defense techniques, such as activation thresholding and input quantization and demonstrate that the proposed attack is able to withstand them, highlighting the need for further efforts in this new direction within the field of adversarial machine learning.
C1 [Krithivasan, Sarada; Sen, Sanchari; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Krithivasan, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM skrithiv@purdue.edu; sen9@purdue.edu; raghunathan@purdue.edu
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   [Anonymous], 2016, ADVERSARIAL EXAMPLES
   [Anonymous], 2017, DISCOVERING ADVERSAR
   Brown T.B., 2020, P 34 INT C NEUR INF
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Carlini N, 2017, P IEEE S SECUR PRIV, P39, DOI 10.1109/SP.2017.49
   Chen Pin-Yu, 2017, P 10 ACM WORKSH ART, P15, DOI DOI 10.1145/3128572.3140448
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duddu V., 2018, STEALING NEURAL NETW
   Gondimalla A, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P151, DOI 10.1145/3352460.3358291
   Goodfellow R, 2015, OIL AND GAS PIPELINES: INTEGRITY AND SAFETY HANDBOOK, P3
   Guo C., 2017, COUNTERING ADVERSARI
   Guo Chuan, 2019, SIMPLE BLACK BOX ADV
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hannun Awni, 2014, ABS1412556
   Hegde K, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P319, DOI 10.1145/3352460.3358275
   Hinton G, 2009, LEARNING MULTIPLE LA
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Hwang U, 2019, IEEE ACCESS, V7, P126582, DOI 10.1109/ACCESS.2019.2939352
   Isakov M., 2019, P 2019 IEEE HIGH PER, P1, DOI 10.1109/HPEC.2019.8916519
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Liu Y., 2016, DELVING TRANSFERABLE
   Liu YN, 2017, ICCAD-IEEE ACM INT, P131, DOI 10.1109/ICCAD.2017.8203770
   Madry A., 2018, P 6 INT C LEARN REPR
   Palossi D., 2018, ULTRALOW POWER DEEP
   Pang T., 2019, IMPROVING ADVERSARIA
   Papernot N., 2016, PRACTICAL BLACK BOX
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Rakin Adnan Siraj, 2019, BIT FLIP ATTACK CRUS
   Samangouei P., 2018, INT C LEARNING REPRE
   Sen S, 2020, HERBAL MEDICINE IN INDIA: INDIGENOUS KNOWLEDGE, PRACTICE, INNOVATION AND ITS VALUE, P1, DOI 10.1007/978-981-13-7248-3
   Sen S, 2019, IEEE T COMPUT, V68, P912, DOI 10.1109/TC.2018.2879434
   Shokri Reza, 2016, MEMBERSHIP INFERENCE
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Springenberg J., 2015, 3 INT C LEARN REPR I, P1, DOI DOI 10.1109/TGRS.2018.2833293
   Sutskever I., 2013, INT C MACH LEARN, P1139, DOI DOI 10.1007/S00287-015-0911-Z
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Zhu MH, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P359, DOI 10.1145/3352460.3358269
NR 40
TC 4
Z9 4
U1 1
U2 2
PD NOV
PY 2020
VL 39
IS 11
BP 4129
EP 4141
DI 10.1109/TCAD.2020.3013077
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Nambi, S
   Ullah, S
   Sahoo, SS
   Lohana, A
   Merchant, F
   Kumar, A
AF Nambi, Suresh
   Ullah, Salim
   Sahoo, Siva Satyendra
   Lohana, Aditya
   Merchant, Farhad
   Kumar, Akash
TI <i>ExPAN(N)D</i>: Exploring Posits for Efficient Artificial Neural
   Network Design in FPGA-Based Systems
SO IEEE ACCESS
DT Article
DE Quantization (signal); Hardware; Dynamic range; Field programmable gate
   arrays; Neural networks; Machine learning algorithms; Delays; Computer
   arithmetic; deep neural networks; energy efficient computing; posits;
   FPGA; high-level synthesis
ID ACCURATE
AB The high computational complexity, memory footprints, and energy requirements of machine learning models, such as Artificial Neural Networks (ANNs), hinder their deployment on resource-constrained embedded systems. Most state-of-the-art works have considered this problem by proposing various low bit-width data representation schemes and optimized arithmetic operators' implementations. To further elevate the implementation gains offered by these individual techniques, there is a need to cross-examine and combine these techniques' unique features. This paper presents ExPAN(N)D, a framework to analyze and ingather the efficacy of the Posit number representation scheme and the efficiency of fixed-point arithmetic implementations for ANNs. The Posit scheme offers a better dynamic range and higher precision for various applications than IEEE 754 single-precision floating-point format. However, due to the dynamic nature of the various fields of the Posit scheme, the corresponding arithmetic circuits have higher critical path delay and resource requirements than the single-precision-based arithmetic units. Towards this end, we propose a novel Posit to fixed-point converter for enabling high-performance and energy-efficient hardware implementations for ANNs with minimal drop in the output accuracy. We also propose a modified Posit-based representation to store the trained parameters of a network. With the proposed Posit to fixed-point converter-based designs, we provide multiple design points with varying accuracy-performance trade-offs for an ANN. For instance, compared to the lowest power dissipating Posit-only accelerator design, one of our proposed designs results in 80% and 48% reduction in power dissipation and LUT utilization respectively, with marginal increase in classification error for Imagenet dataset classification using VGG-16.
C1 [Nambi, Suresh; Ullah, Salim; Sahoo, Siva Satyendra; Lohana, Aditya; Kumar, Akash] Tech Univ Dresden, Ctr Adv Elect Dresden Cfaed, Chair Processor Design, D-01062 Dresden, Germany.
   [Merchant, Farhad] Rhein Westfal TH Aachen, Inst Commun Technol & Embedded Syst, D-52056 Aachen, Germany.
RP Ullah, S; Sahoo, SS (corresponding author), Tech Univ Dresden, Ctr Adv Elect Dresden Cfaed, Chair Processor Design, D-01062 Dresden, Germany.
EM salim.ullah@tu-dresden.de; siva_satyendra.sahoo@tu-dresden.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   [Anonymous], 2017, XILINX AXI INTERCONN
   [Anonymous], 2018, 2018 1 WORKSH EN, DOI DOI 10.1109/EMC2.2018.00012
   Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Avnet, 2019, ULTRA96 V2
   Burgess N, 2019, P S COMP ARITHM, P88, DOI 10.1109/ARITH.2019.00022
   Carmichael Z, 2019, DES AUT TEST EUROPE, P1421, DOI [10.23919/DATE.2019.8715262, 10.23919/date.2019.8715262]
   Chaurasiya R, 2018, PR IEEE COMP DESIGN, P334, DOI 10.1109/ICCD.2018.00057
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cococcioni M, 2020, J REAL-TIME IMAGE PR, V17, P759, DOI 10.1007/s11554-020-00984-x
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   De la Parra C, 2020, DES AUT TEST EUROPE, P1193, DOI 10.23919/DATE48585.2020.9116476
   de Prado M., 2018, QUENN QUANTIZATION E, P1
   Deng L, 2013, IEEE INT NEW CIRC
   Ebrahimi Zahra, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P605, DOI 10.1109/ASP-DAC47756.2020.9045171
   Gupta S, 2020, IEEE ACCESS, V8, P118899, DOI 10.1109/ACCESS.2020.3005286
   Gustafson John L., 2017, [Supercomputing Frontiers and Innovations, Supercomputing Frontiers and Innovations], V4, P71
   Gysel P, 2018, IEEE T NEUR NET LEAR, V29, P5784, DOI 10.1109/TNNLS.2018.2808319
   Han S., 2015, ARXIV151000149
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Jain R., 2020, ARXIV200600364
   Jaiswal MK, 2019, IEEE ACCESS, V7, P74586, DOI 10.1109/ACCESS.2019.2920936
   Jaiswal MK, 2018, DES AUT TEST EUROPE, P1159, DOI 10.23919/DATE.2018.8342187
   Langroudi H. F., ARXIV190802386
   Langroudi HF, 2020, IEEE COMPUT SOC CONF, P3123, DOI 10.1109/CVPRW50498.2020.00371
   Langroudi HF, 2019, 2019 IEEE SPACE COMPUTING CONFERENCE (SCC), P53, DOI 10.1109/SpaceComp.2019.00011
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lu HY, 2015, PROC CVPR IEEE, P806, DOI 10.1109/CVPR.2015.7298681
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Murillo R, 2020, DIGIT SIGNAL PROCESS, V102, DOI 10.1016/j.dsp.2020.102762
   Podobas A, 2018, IEEE SYM PARA DISTR, P138, DOI 10.1109/IPDPSW.2018.00029
   Prabakaran BS, 2018, DES AUT TEST EUROPE, P917, DOI 10.23919/DATE.2018.8342140
   Rajagopalan Vidya, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477495
   Rastegari M., 2016, XNOR NET IMAGENET CL, P1
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Ullah S, 2021, IEEE T COMPUT, V70, P384, DOI 10.1109/TC.2020.2988404
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Vogel S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240803
   Wu, 2020, SMALLPOSITHDL
   Xiao FB, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101622
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhang HQ, 2020, IEEE T KNOWL DATA EN, V32, P659, DOI [10.1109/IRMMW-THz.2019.8874163, 10.1109/TKDE.2019.2893266]
   Zhou S., 2016, ARXIV160606160
   Zisserman A., 2014, 14091556 ARXIV
NR 44
TC 5
Z9 5
U1 0
U2 3
PY 2021
VL 9
BP 103691
EP 103708
DI 10.1109/ACCESS.2021.3098730
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Camsari, KY
   Sutton, BM
   Datta, S
AF Camsari, Kerem Y.
   Sutton, Brian M.
   Datta, Supriyo
TI p-bits for probabilistic spin logic
SO APPLIED PHYSICS REVIEWS
DT Review
ID MEMORY; DEVICES
AB We introduce the concept of a probabilistic or p-bit, intermediate between the standard bits of digital electronics and the emerging q-bits of quantum computing. We show that low barrier magnets or LBMs provide a natural physical representation for p-bits and can be built either from perpendicular magnets designed to be close to the in-plane transition or from circular in-plane magnets. Magnetic tunnel junctions (MTJs) built using LBMs as free layers can be combined with standard NMOS transistors to provide three-terminal building blocks for large scale probabilistic circuits that can be designed to perform useful functions. Interestingly, this three-terminal unit looks just like the 1T/MTJ device used in embedded magnetic random access memory technology, with only one difference: the use of an LBM for the MTJ free layer. We hope that the concept of p-bits and p-circuits will help open up new application spaces for this emerging technology. However, a p-bit need not involve an MTJ; any fluctuating resistor could be combined with a transistor to implement it, while completely digital implementations using conventional CMOS technology are also possible. The p-bit also provides a conceptual bridge between two active but disjoint fields of research, namely, stochastic machine learning and quantum computing. First, there are the applications that are based on the similarity of a p-bit to the binary stochastic neuron (BSN), a well-known concept in machine learning. Three-terminal p-bits could provide an efficient hardware accelerator for the BSN. Second, there are the applications that are based on the p-bit being like a poor man's q-bit. Initial demonstrations based on full SPICE simulations show that several optimization problems, including quantum annealing are amenable to p-bit implementations which can be scaled up at room temperature using existing technology. Published under license by AIP Publishing.
C1 [Camsari, Kerem Y.; Sutton, Brian M.; Datta, Supriyo] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Camsari, KY (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
CR ACKLEY DH, 1985, COGNITIVE SCI, V9, P147
   Albash T, 2018, REV MOD PHYS, V90, DOI 10.1103/RevModPhys.90.015002
   Amit D. J., 1992, MODELING BRAIN FUNCT
   [Anonymous], 2014, 2014 IEEE INT EL DEV
   [Anonymous], P 75 ANN DEV RES C D, DOI DOI 10.1109/DRC.2017.7999423
   [Anonymous], 2007, P 24 INT C MACHINE L
   [Anonymous], 2018, SCI REP-UK, DOI DOI 10.1038/s41598-017-17765-5
   [Anonymous], 2018, ARXIV181007144
   [Anonymous], 2017, ARXIV170908102
   [Anonymous], 2002, PREDICTIVE TECHNOLOG
   Ardakani A, 2017, IEEE T VLSI SYST, V25, P2688, DOI 10.1109/TVLSI.2017.2654298
   Atxitia U., 2018, ARXIV180807665
   Bapna M, 2017, APPL PHYS LETT, V111, DOI 10.1063/1.5012091
   Behin-Aein Behtash, 2012, ESSDERC 2012 - 42nd European Solid State Device Research Conference, P36, DOI 10.1109/ESSDERC.2012.6343328
   Behin-Aein B., 2014, U.S. Patent, Patent No. [8 698 517, 8698517]
   Behin-Aein B, 2016, SCI REP-UK, V6, DOI 10.1038/srep29893
   Bhatti S, 2017, MATER TODAY, V20, P530, DOI 10.1016/j.mattod.2017.07.007
   Biswas AK, 2017, NANO LETT, V17, P3478, DOI 10.1021/acs.nanolett.7b00439
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Bucci M, 2003, IEEE T COMPUT, V52, P403, DOI 10.1109/TC.2003.1190581
   Camsari KY, 2018, PHYS REV APPL, V9, DOI 10.1103/PhysRevApplied.9.044020
   Camsari KY, 2017, IEEE ELECTR DEVICE L, V38, P1767, DOI 10.1109/LED.2017.2768321
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Camsari KY, 2016, IEEE MAGN LETT, V7, DOI 10.1109/LMAG.2016.2610942
   Camsari KY, 2015, SCI REP-UK, V5, DOI 10.1038/srep10571
   Chakrapani LN, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255466
   Cheemalavagu Suresh, 2005, P IFIP INT
   Chen E, 2010, IEEE T MAGN, V46, P1873, DOI 10.1109/TMAG.2010.2042041
   Cowburn RP, 1999, PHYS REV LETT, V83, P1042, DOI 10.1103/PhysRevLett.83.1042
   Debashis P., 2016, P 2016 IEEE INT EL D
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Di Ventra M, 2018, J APPL PHYS, V123, DOI 10.1063/1.5026506
   Faria R., ACCELERATING M UNPUB
   Faria R, 2017, IEEE MAGN LETT, V8, DOI 10.1109/LMAG.2017.2685358
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Fukushima A, 2014, APPL PHYS EXPRESS, V7, DOI 10.7567/APEX.7.083001
   GEMAN S, 1984, IEEE T PATTERN ANAL, V6, P721, DOI 10.1109/TPAMI.1984.4767596
   Grollier J, 2016, P IEEE, V104, P2024, DOI 10.1109/JPROC.2016.2597152
   Hassan O., 2018, ARXIV180109026CS
   Henelius P., ARXIV11021296CONDMAT
   Hinton GE, 2002, NEURAL COMPUT, V14, P1771, DOI 10.1162/089976602760128018
   Hinton Geoffrey E., 2012, NEURAL NETWORKS TRIC, P599, DOI [DOI 10.1007/978-3-642-35289-8_32, 10.1007/978-3-642-35289-8_32]
   Holcomb DE, 2009, IEEE T COMPUT, V58, P1198, DOI 10.1109/TC.2008.212
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Johnson MW, 2011, NATURE, V473, P194, DOI 10.1038/nature10012
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Lemieux G, 2004, DESIGN INTERCONNECTI
   LEWIS TG, 1973, J ACM, V20, P456, DOI 10.1145/321765.321777
   Liyanagedera CM, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.064017
   Locatelli N, 2014, PHYS REV APPL, V2, DOI 10.1103/PhysRevApplied.2.034009
   Locatelli N, 2014, NAT MATER, V13, P11, DOI [10.1038/NMAT3823, 10.1038/nmat3823]
   Lopez-Diaz L, 2002, PHYS REV B, V65, DOI 10.1103/PhysRevB.65.224406
   Lucas A, 2014, FRONT PHYS-LAUSANNE, V2, DOI 10.3389/fphy.2014.00005
   Lv Y., 2017, EL DEV M IEDM 2017 I, P36
   Lyle A, 2011, IEEE T MAGN, V47, P2970, DOI 10.1109/TMAG.2011.2158527
   Manipatruni S, 2018, NAT PHYS, V14, P338, DOI 10.1038/s41567-018-0101-4
   Matsunaga S, 2008, APPL PHYS EXPRESS, V1, DOI 10.1143/APEX.1.091301
   McMahon PL, 2016, SCIENCE, V354, P614, DOI 10.1126/science.aah5178
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Mizrahi A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-03963-w
   Mooij JE, 1999, SCIENCE, V285, P1036, DOI 10.1126/science.285.5430.1036
   MURTY KG, 1987, MATH PROGRAM, V39, P117, DOI 10.1007/BF02592948
   NEAL RM, 1992, ARTIF INTELL, V56, P71, DOI 10.1016/0004-3702(92)90065-6
   Nikonov DE, 2015, IEEE J EXPLOR SOLID-, V1, P3, DOI 10.1109/JXCDC.2015.2418033
   Ohno H., 2010, P 2010 IEEE INT EL D, P9
   Parks B, 2018, AIP ADV, V8, DOI 10.1063/1.5006422
   Peng XH, 2008, PHYS REV LETT, V101, DOI 10.1103/PhysRevLett.101.220405
   Pervaiz A. Z., IEEE T NEURAL NETWOR
   Pervaiz AZ, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11011-8
   Querlioz D, 2015, P IEEE, V103, P1398, DOI 10.1109/JPROC.2015.2437616
   Sengupta A, 2016, IEEE T ELECTRON DEV, V63, P2963, DOI 10.1109/TED.2016.2568762
   Sharmin S, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-11732-w
   SHIBATA T, 1992, IEEE T ELECTRON DEV, V39, P1444, DOI 10.1109/16.137325
   Shim Y, 2017, J APPL PHYS, V121, DOI 10.1063/1.4983636
   Shor PW, 1999, SIAM REV, V41, P303, DOI 10.1137/S0036144598347011
   Sutton B, 2017, SCI REP-UK, V7, DOI 10.1038/srep44370
   Traversa FL, 2017, CHAOS, V27, DOI 10.1063/1.4975761
   Tylman W, 2016, COMPUT BIOL MED, V69, P245, DOI 10.1016/j.compbiomed.2015.08.015
   Van Vaerenbergh T., 2018, P SOC PHOTO-OPT INS, V10537
   Vincent AF, 2015, IEEE T BIOMED CIRC S, V9, P166, DOI 10.1109/TBCAS.2015.2414423
   Vodenicarevic D, 2017, PHYS REV APPL, V8, DOI 10.1103/PhysRevApplied.8.054045
   Vodenicarevic D, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351771
   Wang JG, 2005, J APPL PHYS, V97, DOI 10.1063/1.1857655
   Yamaoka M, 2016, IEEE J SOLID-ST CIRC, V51, P303, DOI 10.1109/JSSC.2015.2498601
   Yao XF, 2012, IEEE T NANOTECHNOL, V11, P120, DOI 10.1109/TNANO.2011.2158848
   Zand R, 2018, PR GR LAK SYMP VLSI, P15, DOI 10.1145/3194554.3194558
NR 86
TC 92
Z9 93
U1 6
U2 46
PD MAR
PY 2019
VL 6
IS 1
AR 011305
DI 10.1063/1.5055860
WC Physics, Applied
DA 2023-11-11
ER

PT J
AU Ahmed, H
   Ismail, MA
AF Ahmed, Hameeza
   Ismail, Muhammad Ali
TI Towards a Novel Framework for Automatic Big Data Detection
SO IEEE ACCESS
DT Article
DE Big Data; Feature extraction; Tools; Hardware; Software; Measurement;
   Optimization; Big data (3Vs); detection; LLVM; machine learning
ID BENCHMARK SUITE; INTERNET; COMPILER; CHALLENGES; MAPREDUCE; RUNTIME;
   THINGS; IOT
AB Big data is a relative concept. It is the combination of data, application, and platform properties. Recently, big data specific technologies have emerged, including software frameworks, databases, hardware accelerators, storage technologies, etc. However, the automatic selection of these solutions for big data computations remains a non-trivial task. Presently, the big data tools are selected by analyzing the problem manually, or by using several performance prediction techniques. The manual identification is based on the data properties only, whereas the performance predictors only estimate basic execution metrics without linking them with big data (3Vs) thresholds. Hence, both ways of identification are mostly incorrect, which can lead to inefficient use of 3Vs optimizations, resulting into global inefficiency, reduced system performance, increasing power consumption, requiring greater effort on the part of the programming team, and misallocation of the hardware resources required for the task. In this regard, a novel framework has been proposed for automatic detection of 3Vs (Volume, Velocity, Variety) of big data, using machine learning. The detection is done through static code features, data, and platform properties, leading to relevant tool selection, and code generation, with minimal overheads, lesser programmer interventions, higher usability, and portability. Instead of handling each application with big data specialized solutions, or manually identifying the 3Vs, the framework can automatically detect and link the 3Vs to the relevant optimizations. Several standard applications have been tested using the proposed framework. In the case of volume, the average detection accuracy is up to 97.8% for seen and 95.9% for unseen applications. In the case of velocity, the average detection accuracy is up to 97.3% for seen and 92.6%; for unseen applications. There is no margin of error in variety detection, as it has straightforward computations without any predictions. Furthermore, an airline recommendation system case study strengthens the effectiveness of the proposed approach.
C1 [Ahmed, Hameeza; Ismail, Muhammad Ali] NED Univ Engn & Technol, Dept Comp & Informat Syst Engn, Karachi 75270, Pakistan.
RP Ahmed, H (corresponding author), NED Univ Engn & Technol, Dept Comp & Informat Syst Engn, Karachi 75270, Pakistan.
EM hameeza@neduet.edu.pk
CR Anghel A, 2016, INT J PARALLEL PROG, V44, P924, DOI 10.1007/s10766-016-0410-0
   [Anonymous], 2019, GREP BENCH
   [Anonymous], 2019, C NEURAL NETWORK LIB
   [Anonymous], 2012, LINEAR REGRESSION AN
   Ashouri AH, 2018, SPRINGERBR APPL SCI, P1, DOI 10.1007/978-3-319-71489-9
   Awad M, 2015, EFFICIENT LEARNING M, P67, DOI [DOI 10.1007/978-1-4302-5990-9_4, 10.1007/978-1-4302-5990-9_4]
   Basanta-Val Pablo, 2016, IEEE Transactions on Big Data, V2, P310, DOI 10.1109/TBDATA.2016.2622719
   Belcastro L, 2019, INT J PARALLEL EMERG, V34, P632, DOI 10.1080/17445760.2017.1422501
   Bienia C, 2008, PACT'08: PROCEEDINGS OF THE SEVENTEENTH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES, P72, DOI 10.1145/1454115.1454128
   Chan Y, 2017, IEEE T BIG DATA, V3, P262, DOI 10.1109/TBDATA.2017.2666201
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chen CLP, 2014, INFORM SCIENCES, V275, P314, DOI 10.1016/j.ins.2014.01.015
   Chen C, 2018, IEEE T PARALL DISTR, V29, P1275, DOI 10.1109/TPDS.2018.2794343
   Chen M, 2014, MOBILE NETW APPL, V19, P171, DOI 10.1007/s11036-013-0489-0
   Cherkassky V, 2002, LECT NOTES COMPUT SC, V2415, P687
   Chi MM, 2016, P IEEE, V104, P2207, DOI 10.1109/JPROC.2016.2598228
   Dautov R, 2017, IEEE INT CONF BIG DA, P2843, DOI 10.1109/BigData.2017.8258252
   Dittrich J, 2012, PROC VLDB ENDOW, V5, P2014, DOI 10.14778/2367502.2367562
   Emani CK, 2015, COMPUT SCI REV, V17, P70, DOI 10.1016/j.cosrev.2015.05.002
   Gandomi A, 2015, INT J INFORM MANAGE, V35, P137, DOI 10.1016/j.ijinfomgt.2014.10.007
   Gao WL, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243190
   Ge M, 2018, FUTURE GENER COMP SY, V87, P601, DOI 10.1016/j.future.2018.04.053
   Hashem IAT, 2015, INFORM SYST, V47, P98, DOI 10.1016/j.is.2014.07.006
   Hirzel M, 2013, IBM J RES DEV, V57, DOI 10.1147/JRD.2013.2243535
   Huang W., 2017, BAYESIAN INFERENCE
   Inoubli W, 2018, FUTURE GENER COMP SY, V86, P546, DOI 10.1016/j.future.2018.04.032
   Jagadish HV, 2015, BIG DATA RES, V2, P49, DOI 10.1016/j.bdr.2015.01.005
   Jin XL, 2015, BIG DATA RES, V2, P59, DOI 10.1016/j.bdr.2015.01.006
   Jirkovsky V, 2017, IEEE T IND INFORM, V13, P660, DOI 10.1109/TII.2016.2596101
   Kiriansky V, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P299, DOI 10.1145/2967938.2967948
   Kruse M., 2014, ARXIV14092089
   Kuo S. M., 2006, INTRO REAL TIME DIGI, P1
   Li YY, 2020, NEUROCOMPUTING, V418, P36, DOI 10.1016/j.neucom.2020.07.059
   Mariani G, 2018, FUTURE GENER COMP SY, V87, P618, DOI 10.1016/j.future.2017.10.048
   Mariani G, 2016, INT J PARALLEL PROG, V44, P975, DOI 10.1007/s10766-016-0412-y
   Mayer G, 2018, SLEEP DISORDERS IN NEUROLOGY: A PRACTICAL APPROACH, 2ND EDITION, P47
   Mustafa S, 2018, ALEX ENG J, V57, P3767, DOI 10.1016/j.aej.2018.03.006
   Myung R, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9091340
   Nai LF, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807626
   Nguyen K, 2015, ACM SIGPLAN NOTICES, V50, P675, DOI [10.1145/2694344.2694345, 10.1145/2775054.2694345]
   Rao TR, 2019, KNOWL INF SYST, V60, P1165, DOI 10.1007/s10115-018-1248-0
   Rodríguez-Mazahua L, 2016, J SUPERCOMPUT, V72, P3073, DOI 10.1007/s11227-015-1501-1
   Rubiano T., 2017, THESIS
   Sakr S, 2017, IT PROF, V19, P34, DOI 10.1109/MITP.2017.6
   Schiller Benjamin, 2016, Appl Netw Sci, V1, P9, DOI 10.1007/s41109-016-0011-2
   Sidhanta S, 2021, IEEE T BIG DATA, V7, P115, DOI 10.1109/TBDATA.2019.2908188
   Stevens W. Richard, 2008, ADV PROGRAMMING UNIX
   Strohbach M, 2015, MODEL OPTIM SCI TECH, V4, P257, DOI 10.1007/978-3-319-09177-8_11
   Tetzlaff Dirk, 2013, 2013 Second International Conference on Informatics & Applications (ICIA), P234, DOI 10.1109/ICoIA.2013.6650262
   Thoman P, 2019, J SIGNAL PROCESS SYS, V91, P303, DOI 10.1007/s11265-018-1356-9
   Thomas S, 2014, I S WORKL CHAR PROC, P76, DOI 10.1109/IISWC.2014.6983043
   Triantafyllis S, 2003, INT SYM CODE GENER, P204, DOI 10.1109/CGO.2003.1191546
   Tsai LJ, 2018, IEEE T PARALL DISTR, V29, P1332, DOI 10.1109/TPDS.2018.2800011
   Tumeo A, 2015, COMPUTER, V48, P14, DOI 10.1109/MC.2015.233
   Venkataraman S, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P363
   Wang KW, 2015, IEEE I C EMBED SOFTW, P166, DOI 10.1109/HPCC-CSS-ICESS.2015.246
   Wang L, 2014, INT S HIGH PERF COMP, P488, DOI 10.1109/HPCA.2014.6835958
   Wang Z, 2018, P IEEE, V106, P1879, DOI 10.1109/JPROC.2018.2817118
   Wongthongtham P, 2017, COMPUT COMMUN NETW S, P41, DOI 10.1007/978-3-319-70102-8_3
   Yoo RM, 2009, I S WORKL CHAR PROC, P198, DOI 10.1109/IISWC.2009.5306783
   Zaharia M, 2016, COMMUN ACM, V59, P56, DOI 10.1145/2934664
   Zhang H, 2015, IEEE T KNOWL DATA EN, V27, P1920, DOI 10.1109/TKDE.2015.2427795
   Zhang YQ, 2016, P IEEE, V104, P2114, DOI 10.1109/JPROC.2016.2591592
NR 63
TC 2
Z9 2
U1 0
U2 7
PY 2020
VL 8
BP 186304
EP 186322
DI 10.1109/ACCESS.2020.3030562
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Pal, S
   Feng, SY
   Park, DH
   Kim, S
   Amarnath, A
   Yang, CS
   He, X
   Beaumont, J
   May, K
   Xiong, Y
   Kaszyk, K
   Morton, JM
   Sun, JW
   O'Boyle, M
   Cole, M
   Chakrabarti, C
   Blaauw, D
   Kim, HS
   Mudge, T
   Dreslinski, R
AF Pal, Subhankar
   Feng, Siying
   Park, Dong-hyeon
   Kim, Sung
   Amarnath, Aporva
   Yang, Chi-Sheng
   He, Xin
   Beaumont, Jonathan
   May, Kyle
   Xiong, Yan
   Kaszyk, Kuba
   Morton, John Magnus
   Sun, Jiawen
   O'Boyle, Michael
   Cole, Murray
   Chakrabarti, Chaitali
   Blaauw, David
   Kim, Hun-Seok
   Mudge, Trevor
   Dreslinski, Ronald
GP ASSOC COMP MACHINERY
TI Transmuter: Bridging the Efficiency Gap using Memory and Dataflow
   Reconfiguration
SO PACT '20: PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON PARALLEL
   ARCHITECTURES AND COMPILATION TECHNIQUES
SE International Conference on Parallel Architectures and Compilation
   Techniques
DT Proceedings Paper
CT ACM International Conference on Parallel Architectures and Compilation
   Techniques (PACT)
CY OCT 03-07, 2020
CL ELECTR NETWORK
DE Reconfigurable architectures; memory reconfiguration; dataflow
   reconfiguration; hardware acceleration; general-purpose acceleration
ID ARCHITECTURE; STANDARD; PROCESSORS; CIRCUITS
AB With the end of Dennard scaling and Moore's law, it is becoming increasingly difficult to build hardware for emerging applications that meet power and performance targets, while remaining flexible and programmable for end users. This is particularly true for domains that have frequently changing algorithms and applications involving mixed sparse/dense data structures, such as those in machine learning and graph analytics. To overcome this, we present a flexible accelerator called Transmuter, in a novel effort to bridge the gap between General-Purpose Processors (GPPs) and Application-Specific Integrated Circuits (ASICs). Transmuter adapts to changing kernel characteristics, such as data reuse and control divergence, through the ability to reconfigure the on-chip memory type, resource sharing and dataflow at run-time within a short latency. This is facilitated by a fabric of light-weight cores connected to a network of reconfigurable caches and crossbars. Transmuter addresses a rapidly growing set of algorithms exhibiting dynamic data movement patterns, irregularity, and sparsity, while delivering GPU-like efficiencies for traditional dense applications. Finally, in order to support programmability and ease-of-adoption, we prototype a software stack composed of low-level runtime routines, and a high-level language library called TransPy, that cater to expert programmers and end-users, respectively.
   Our evaluations with Transmut er demonstrate average throughput (energy-efficiency) improvements of 5.0x (18.4x) and 4.2x (4.0x) over a high-end CPU and GPU, respectively, across a diverse set of kernels predominant in graph analytics, scientific computing and machine learning. Transmut er achieves energy-efficiency gains averaging 3.4x and 2.0x over prior FPGA and CGRA implementations of the same kernels, while remaining on average within 9.3x of state-of-the-art ASICs.
C1 [Pal, Subhankar; Feng, Siying; Park, Dong-hyeon; Kim, Sung; Amarnath, Aporva; Yang, Chi-Sheng; He, Xin; Beaumont, Jonathan; May, Kyle; Blaauw, David; Kim, Hun-Seok; Mudge, Trevor; Dreslinski, Ronald] Univ Michigan, Ann Arbor, MI 48109 USA.
   [Xiong, Yan; Chakrabarti, Chaitali] Arizona State Univ, Tempe, AZ 85287 USA.
   [Kaszyk, Kuba; Morton, John Magnus; Sun, Jiawen; O'Boyle, Michael; Cole, Murray] Univ Edinburgh, Edinburgh, Midlothian, Scotland.
RP Pal, S (corresponding author), Univ Michigan, Ann Arbor, MI 48109 USA.
EM subh@umich.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Abeyratne N, 2013, INT S HIGH PERF COMP, P496
   Adelson E. H., 1984, RCA ENG, V29, P33
   Akbari Omid, 2019, IEEE T COMPUTER AIDE
   Anandkumar Anima, 2012, ABS12107559
   [Anonymous], 2013, 2013 IEEE HIGH PERFO
   [Anonymous], 2009, HP LAB
   [Anonymous], 2012, P 26 ACM INT C SUPER
   [Anonymous], 2013, P 27 INT ACM C INT C
   Ayhan T, 2014, EUR SIGNAL PR CONF, P266
   Bacon DF, 2013, COMMUN ACM, V56, P56, DOI 10.1145/2436256.2436271
   Banakar R, 2002, CODES 2002: PROCEEDINGS OF THE TENTH INTERNATIONAL SYMPOSIUM ON HARDWARE/SOFTWARE CODESIGN, P73, DOI 10.1109/CODES.2002.1003604
   Bell N, 2012, SIAM J SCI COMPUT, V34, pC123, DOI 10.1137/110838844
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Binkert NL, 2006, IEEE MICRO, V26, P52, DOI 10.1109/MM.2006.82
   Buck Ian, 2010, P GPU TECHN C 2010, P11
   Burtscher M., 2012, 2012 IEEE International Symposium on Workload Characterization (IISWC 2012), P141, DOI 10.1109/IISWC.2012.6402918
   Caelles S, 2017, PROC CVPR IEEE, P5320, DOI 10.1109/CVPR.2017.565
   Calhoun BH, 2010, P IEEE, V98, P267, DOI 10.1109/JPROC.2009.2037211
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Cuturi Marco, 2013, ADV NEURAL INFORM PR, V26, P2292
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Davidson S, 2018, IEEE MICRO, V38, P30, DOI 10.1109/MM.2018.022071133
   Ding CHQ, 2001, 2001 IEEE INTERNATIONAL CONFERENCE ON DATA MINING, PROCEEDINGS, P107, DOI 10.1109/ICDM.2001.989507
   Dongwook Lee, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P376, DOI 10.1109/FPT.2009.5377609
   Donnat C, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1320, DOI 10.1145/3219819.3220025
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Duff IS, 2002, ACM T MATH SOFTWARE, V28, P239, DOI 10.1145/567806.567810
   Farahini N, 2013, IEEE INT SYMP CIRC S, P1448, DOI 10.1109/ISCAS.2013.6572129
   Fatahalian Kayvon, 2004, P ACM SIGGRAPH EUROG, P133
   Feng SY, 2019, INT SYM PERFORM ANAL, P202, DOI 10.1109/ISPASS.2019.00033
   Filipovic J, 2015, J SUPERCOMPUT, V71, P3934, DOI 10.1007/s11227-015-1483-z
   Fricke Florian, 2018, Applied Reconfigurable Computing. Architectures, Tools, and Applications. 14th International Symposium, ARC 2018. Proceedings: LNCS 10824, P661, DOI 10.1007/978-3-319-78890-6_53
   Fujii Y, 2013, INT C PAR DISTRIB SY, P275, DOI 10.1109/ICPADS.2013.47
   Fujimoto N, 2008, PARALLEL PROCESS LET, V18, P511, DOI 10.1142/S0129626408003545
   Gao MY, 2016, INT S HIGH PERF COMP, P126, DOI 10.1109/HPCA.2016.7446059
   Giefers H, 2016, J SIGNAL PROCESS SYS, V85, P307, DOI 10.1007/s11265-015-1057-6
   Giefers H, 2016, INT SYM PERFORM ANAL, P46, DOI 10.1109/ISPASS.2016.7482073
   Goldstein SC, 2000, COMPUTER, V33, P70, DOI 10.1109/2.839324
   Govindaraju V, 2011, INT S HIGH PERF COMP, P503, DOI 10.1109/HPCA.2011.5749755
   Halfhill Tom R, 2006, MICROPROCESSOR REPOR, V20, P19
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   HUGHES RA, 1986, P IEEE, V74, P1775, DOI 10.1109/PROC.1986.13691
   Ipek E, 2007, CONF PROC INT SYMP C, P186, DOI 10.1145/1273440.1250686
   ITOH S, 1995, COMPUT PHYS COMMUN, V88, P173, DOI 10.1016/0010-4655(95)00031-A
   Jackson Preston A., 2004, HIGH PERFORMANCE EMB
   Jakob W., 2017, PYBIND11 SEAMLESS OP
   Jeloka S, 2014, INT SYMP MICROARCH, P471, DOI 10.1109/MICRO.2014.45
   JOHNSON KT, 1993, COMPUTER, V26, P20, DOI 10.1109/2.241423
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Karunaratne M, 2017, DES AUT CON, DOI 10.1145/3061639.3062262
   Kelm JH, 2009, CONF PROC INT SYMP C, P140, DOI 10.1145/1555815.1555774
   Kepner J., 2016, 2016 IEEE HIGH PERF, P1, DOI DOI 10.1109/HPEC.2016.7761646
   Khubaib, 2012, INT SYMP MICROARCH, P305, DOI 10.1109/MICRO.2012.36
   Kim MM, 2008, CONF PROC INT SYMP C, P101, DOI 10.1109/ISCA.2008.25
   Koeplinger D, 2018, ACM SIGPLAN NOTICES, V53, P296, DOI [10.1145/3296979.3192379, 10.1145/3192366.3192379]
   Komuravelli R, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P707, DOI 10.1145/2749469.2750374
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kuon I, 2007, IEEE T COMPUT AID D, V26, P203, DOI 10.1109/TCAD.2006.884574
   Kuon Ian, 2008, FPGA ARCHITECTURE SU
   Kusner MJ, 2015, PR MACH LEARN RES, V37, P957
   Kuzmanov Georgi, 2009, Proceedings of the 2009 International Conference on Field-Programmable Technology (FPT 2009), P483, DOI 10.1109/FPT.2009.5377625
   Lee BC, 2004, PROC INT CONF PARAL, P169
   Lee CC, 2016, ELEC COMP C, P1439, DOI 10.1109/ECTC.2016.348
   Lee CH, 2015, KNOWL-BASED SYST, V85, P71, DOI 10.1016/j.knosys.2015.04.020
   Liang C, 2008, IEEE WRK SIG PRO SYS, P257, DOI 10.1109/SIPS.2008.4671772
   Liu LB, 2020, ACM COMPUT SURV, V52, DOI 10.1145/3357375
   Liu LB, 2015, IEEE T MULTIMEDIA, V17, P1706, DOI 10.1109/TMM.2015.2463735
   Logan Beth, 2000, ISMIR, V270, P1
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Magaki I, 2016, CONF PROC INT SYMP C, P178, DOI 10.1109/ISCA.2016.25
   Mai K, 2000, PROCEEDING OF THE 27TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P161, DOI [10.1145/342001.339673, 10.1109/ISCA.2000.854387]
   Marcin J., 2018, P ACL 2018 SYST DEM, P116, DOI DOI 10.18653/V1/P18-4020
   Mattson T, 2013, IEEE HIGH PERF EXTR
   Merity S., 2018, ANAL NEURAL LANGUAGE
   Mohapatra BN, 2017, INT CONF WIREL OPT
   Mueller Frank, 1993, PTHREADS LIB INTERFA
   Nicol Chris, 2017, CISC VIS NETW IND GL
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   O'Connor M, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P41, DOI 10.1145/3123939.3124545
   O'Neil MA, 2014, I S WORKL CHAR PROC, P130, DOI 10.1109/IISWC.2014.6983052
   Ovtcharov K., 2015, ACCELERATING DEEP CO, V2, P1
   Pal S, 2019, SYMP VLSI CIRCUITS, pC150
   Pal S, 2018, INT S HIGH PERF COMP, P724, DOI 10.1109/HPCA.2018.00067
   Parashar A, 2019, INT SYM PERFORM ANAL, P304, DOI 10.1109/ISPASS.2019.00042
   Park DH, 2020, IEEE J SOLID-ST CIRC, V55, P933, DOI 10.1109/JSSC.2019.2960480
   Pedram A, 2014, J SIGNAL PROCESS SYS, V77, P169, DOI 10.1007/s11265-014-0896-x
   Pedram A, 2011, IEEE INT CONF ASAP, P35, DOI 10.1109/ASAP.2011.6043234
   Penn G, 2006, THEOR COMPUT SCI, V354, P72, DOI 10.1016/j.tcs.2005.11.008
   Poon KKW, 2005, ACM T DES AUTOMAT EL, V10, P279, DOI 10.1145/1059876.1059881
   Prabhakar R, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P389, DOI 10.1145/3079856.3080256
   Putnam A, 2014, CONF PROC INT SYMP C, P13, DOI 10.1109/ISCA.2014.6853195
   Salimans T., 2018, INT C LEARN REPR
   Schuiki F, 2019, DES AUT TEST EUROPE, P662, DOI [10.23919/DATE.2019.8715007, 10.23919/date.2019.8715007]
   Sewell K, 2012, IEEE J EM SEL TOP C, V2, P278, DOI 10.1109/JETCAS.2012.2193936
   Shafique M, 2017, IEEE DES TEST, V34, P8, DOI 10.1109/MDAT.2016.2633408
   Soorishetty A, 2020, INT CONF ACOUST SPEE, P1558, DOI [10.1109/ICASSP40776.2020.9054126, 10.1109/icassp40776.2020.9054126]
   Steffl S, 2017, PR IEEE COMP DESIGN, P137, DOI 10.1109/ICCD.2017.29
   Steuwer M, 2017, INT SYM CODE GENER, P74, DOI 10.1109/CGO.2017.7863730
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Swartzlander EE, 2006, IEEE INT CONF ASAP, P153
   Tan C, 2018, CONF PROC INT SYMP C, P575, DOI 10.1109/ISCA.2018.00054
   Tanomoto M, 2015, 2015 IEEE 9TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANYCORE SYSTEMS-ON-CHIP (MCSOC), P73, DOI 10.1109/MCSoC.2015.41
   Taylor MB, 2002, IEEE MICRO, V22, P25, DOI 10.1109/MM.2002.997877
   Tehre Vaishali, IMPLEMENTATION FAST
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Verma M, 2004, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, VOLS 1 AND 2, PROCEEDINGS, P1264, DOI 10.1109/DATE.2004.1269069
   Vipin K, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3193827
   Wang DL, 2016, INT S HIGH PERF COMP, P457, DOI 10.1109/HPCA.2016.7446086
   Web Chang, 2001, US Patent., Patent No. [6,260,087, 6260087]
   Weerasinghe J, 2015, IEEE 12TH INT CONF UBIQUITOUS INTELLIGENCE & COMP/IEEE 12TH INT CONF ADV & TRUSTED COMP/IEEE 15TH INT CONF SCALABLE COMP & COMMUN/IEEE INT CONF CLOUD & BIG DATA COMP/IEEE INT CONF INTERNET PEOPLE AND ASSOCIATED SYMPOSIA/WORKSHOPS, P1078, DOI 10.1109/UIC-ATC-ScalCom-CBDCom-IoP.2015.199
   Wijtvliet M, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING AND SIMULATION (SAMOS), P235, DOI 10.1109/SAMOS.2016.7818353
   Xilinx, PART REC US GUID UG7
   Xin He, 2020, ICS '20: Proceedings of the 34th ACM International Conference on Supercomputing, DOI 10.1145/3392717.3392751
   Yamazaki I, 2011, LECT NOTES COMPUT SC, V6449, P421, DOI 10.1007/978-3-642-19328-6_38
   Ye FH, 2018, CIKM'18: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P1393, DOI 10.1145/3269206.3271697
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
NR 119
TC 10
Z9 10
U1 2
U2 2
PY 2020
BP 175
EP 190
DI 10.1145/3410463.3414627
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Jia, DL
   Yuan, G
   Lin, X
   Mi, NF
AF Jia, Danlin
   Yuan, Geng
   Lin, Xue
   Mi, Ningfang
BE Ardagna, CA
   Atukorala, N
   Buyya, R
   Chang, CK
   Chang, RN
   Damiani, E
   Dasgupta, GB
   Gagliardi, F
   Hagleitner, C
   Milojicic, D
   Trong, TMH
   Ward, R
   Xhafa, F
   Zhang, J
TI A Data-Loader Tunable Knob to Shorten GPU Idleness for Distributed Deep
   Learning
SO 2022 IEEE 15TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (IEEE CLOUD
   2022)
SE IEEE International Conference on Cloud Computing
DT Proceedings Paper
CT 15th IEEE International Conference on Cloud Computing (IEEE CLOUD) /
   IEEE World Congress on Services (IEEE SERVICES)
CY JUL 11-15, 2022
CL Barcelona, SPAIN
AB Deep Neural Network (DNN) has been applied as an effective machine learning algorithm to tackle problems in different domains. However, training a sophisticated DNN model takes days to weeks and becomes a challenge in constructing research on large-scale DNN models. Distributed Deep Learning (DDL) contributes to accelerating DNN training by distributing training workloads across multiple computation accelerators (e.g., GPUs). Although a surge of research works has been devoted to optimizing DDL training, the impact of data-loading on GPU usage and training performance has been relatively under-explored. It is non-trivial to optimize data-loading in DDL applications that need intensive CPU and I/O resources to process enormous training data. When multiple DDL applications are deployed on a system (e.g., Cloud and HPC), the lack of a practical and efficient technique for data-loader allocation incurs GPU idleness and degrades the training throughput. Therefore, our work first focuses on investigating the impact of data-loading on the global training throughput. We then propose a throughput prediction model to predict the maximum throughput for an individual DDL training application. By leveraging the predicted results, A-Dloader is designed to dynamically allocate CPU and I/O resources to concurrently running DDL applications and use the data-loader allocation as a knob to reduce GPU idle intervals and thus improve the overall training throughput. We implement and evaluate A-Dloader in a DDL framework for a series of DDL applications arriving and completing across the runtime. Our experimental results show that A-Dloader can achieve a 23.5% throughput improvement and a 10% makespan improvement, compared to allocating resources evenly across applications.
C1 [Jia, Danlin; Yuan, Geng; Lin, Xue; Mi, Ningfang] Northeastern Univ, Boston, MA 02115 USA.
RP Jia, DL (corresponding author), Northeastern Univ, Boston, MA 02115 USA.
EM jia.da@northeastern.edu; yuan.geng@northeastern.edu;
   xue.lin@northeastern.edu; ningfang@ece.neu.edu
CR Ben-Nun T, 2019, ACM COMPUT SURV, V52, DOI 10.1145/3320060
   Evci Utku, 2020, INT C MACHINE LEARNI
   Hashemi S. H., 2019, P MACH LEARN SYST
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hindman B, 2011, 8 USENIX S NETWORKED, P295
   Jain A, 2018, CONF PROC INT SYMP C, P776, DOI 10.1109/ISCA.2018.00070
   LeCun Y, 1989, NEURAL COMPUT, V1, P541, DOI 10.1162/neco.1989.1.4.541
   Li S, 2020, Arxiv, DOI arXiv:2006.15704
   Mohan J, 2021, Arxiv, DOI arXiv:2007.06775
   pypi, THOP PYTORCH OPCOUNT
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Vavilapalli V.K., P 4 ANN S
   Yang C.-C., 2019, 2019 IEEE 26 INT C H
   Yang CC, 2019, 2019 IEEE 26TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING, DATA, AND ANALYTICS (HIPC), P235, DOI 10.1109/HiPC.2019.00037
   Zhu HY, 2018, I S WORKL CHAR PROC, P88, DOI 10.1109/IISWC.2018.8573476
   Zhu Y, 2018, I S MOD ANAL SIM COM, P145, DOI 10.1109/MASCOTS.2018.00023
   Zolnouri M, 2020, Arxiv, DOI arXiv:2005.02130
NR 18
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 449
EP 458
DI 10.1109/CLOUD55607.2022.00068
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems
DA 2023-11-11
ER

PT J
AU Kontaxis, C
   Bol, GH
   Lagendijk, JJW
   Raaymakers, BW
AF Kontaxis, C.
   Bol, G. H.
   Lagendijk, J. J. W.
   Raaymakers, B. W.
TI DeepDose: Towards a fast dose calculation engine for radiation therapy
   using deep learning
SO PHYSICS IN MEDICINE AND BIOLOGY
DT Article
DE dose engine; IMRT; deep learning; AI; treatment planning; plan
   adaptation; MR-linac
ID PLATFORM; IMPACT
AB We present DeepDose, a deep learning framework for fast dose calculations in radiation therapy. Given a patient anatomy and linear-accelerator IMRT multi-leaf-collimator shape or segment, a novel set of physics-based inputs is calculated that encode the linac machine parameters into the underlying anatomy. These inputs are then used to train a deep convolutional network to derive the dose distribution of individual MLC shapes on a given patient anatomy.
   In this work we demonstrate the proof-of-concept application of DeepDose on 101 prostate patients treated in our clinic with fixed-beam IMRT. The ground-truth data used for training, validation and testing of the prediction were calculated with a state-of-the-art Monte Carlo dose engine at 1% statistical uncertainty per segment. A deep convolution network was trained using the data of 80 patients at the clinically used 3 mm(3) grid spacing while 10 patients were used for validation.
   For another 11 independent test patients, the network was able to accurately estimate the segment doses from the clinical plans of each patient passing the clinical QA when compared with the Monte Carlo calculations, yielding on average 99.9%+/- 0.3% for the forward calculated patient plans at 3%/3 mm gamma tests. Dose prediction using the trained network was very fast at approximately 0.9 seconds for the input generation and 0.6 seconds for single GPU inference per segment and 1 minute per patient in total.
   The overall performance of this dose calculation framework in terms of both accuracy and inference speed, makes it compelling for online adaptive workflows where fast segment dose calculations are needed.
C1 [Kontaxis, C.; Bol, G. H.; Lagendijk, J. J. W.; Raaymakers, B. W.] Univ Med Ctr Utrecht, Dept Radiotherapy, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
RP Kontaxis, C (corresponding author), Univ Med Ctr Utrecht, Dept Radiotherapy, Heidelberglaan 100, NL-3584 CX Utrecht, Netherlands.
EM c.kontaxis@umcutrecht.nl
CR AHNESJO A, 1989, MED PHYS, V16, P577, DOI 10.1118/1.596360
   Arnfield MR, 2000, MED PHYS, V27, P1266, DOI 10.1118/1.599004
   Barragan-Montero AM, 2019, MED PHYS, V46, P3679, DOI 10.1002/mp.13597
   BORTFELD TR, 1994, INT J RADIAT ONCOL, V28, P723, DOI 10.1016/0360-3016(94)90200-3
   Cicek Ozgun, 2016, Medical Image Computing and Computer-Assisted Intervention - MICCAI 2016. 19th International Conference. Proceedings: LNCS 9901, P424, DOI 10.1007/978-3-319-46723-8_49
   Nguyen D, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37741-x
   Gibson E, 2018, COMPUT METH PROG BIO, V158, P113, DOI 10.1016/j.cmpb.2018.01.025
   Henke LE, 2018, CLIN ONCOL-UK, V30, P720, DOI 10.1016/j.clon.2018.08.010
   Hissoiny S, 2011, PHYS MED BIOL, V56, P5119, DOI 10.1088/0031-9155/56/16/003
   Kontaxis C, 2017, PHYS MED BIOL, V62, P7233, DOI 10.1088/1361-6560/aa82ae
   Kontaxis C, 2015, PHYS MED BIOL, V60, P2493, DOI 10.1088/0031-9155/60/6/2493
   Krieger T, 2005, PHYS MED BIOL, V50, P859, DOI 10.1088/0031-9155/50/5/010
   Mahmood R., 2018, MACH LEARN HEALTHC C, P484
   MOHAN R, 1986, MED PHYS, V13, P64, DOI 10.1118/1.595924
   Raaijmakers AJE, 2007, PHYS MED BIOL, V52, P929, DOI 10.1088/0031-9155/52/4/005
   Rogers DWO, 2006, PHYS MED BIOL, V51, pR287, DOI 10.1088/0031-9155/51/13/R17
   Shepard DM, 2002, MED PHYS, V29, P1007, DOI 10.1118/1.1477415
   Tian Z, 2015, PHYS MED BIOL, V60, P7419, DOI 10.1088/0031-9155/60/19/7419
   Werensteijn-Honingh AM, 2019, RADIOTHER ONCOL, V134, P50, DOI 10.1016/j.radonc.2019.01.024
NR 19
TC 56
Z9 57
U1 2
U2 18
PD APR 7
PY 2020
VL 65
IS 7
AR 075013
DI 10.1088/1361-6560/ab7630
WC Engineering, Biomedical; Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT C
AU Zhang, XY
   Song, SL
   Xie, CH
   Wang, J
   Zhang, WG
   Fu, X
AF Zhang, Xingyao
   Song, Shuaiwen Leon
   Xie, Chenhao
   Wang, Jing
   Zhang, Weigong
   Fu, Xin
GP IEEE
TI Enabling Highly Efficient Capsule Networks Processing Through A
   PIM-Based Architecture Design
SO 2020 IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2020)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 26th IEEE International Symposium on High Performance Computer
   Architecture (HPCA)
CY FEB 22-26, 2020
CL San Diego, CA
DE Accelerators; domain-specific architectures Architecture applications of
   Machine Learning; Emerging technologies
AB In recent years, the CNNs have achieved great successes in the image processing tasks, e.g., image recognition and object detection. Unfortunately, traditional CNN's classification is found to be easily misled by increasingly complex image features due to the usage of pooling operations, hence unable to preserve accurate position and pose information of the objects. To address this challenge, a novel neural network structure called Capsule Network has been proposed, which introduces equivariance through capsules to significantly enhance the learning ability for image segmentation and object detection. Due to its requirement of performing a high volume of matrix operations, CapsNets have been generally accelerated on modern GPU platforms that provide highly optimized software library for common deep learning tasks. However, based on our performance characterization on modern GPUs, CapsNets exhibit low efficiency due to the special program and execution features of their routing procedure, including massive unshareable intermediate variables and intensive synchronizations, which are very difficult to optimize at software level. To address these challenges, we propose a hybrid computing architecture design named PIM-CapsNet. It preserves GPU's on-chip computing capability for accelerating CNN types of layers in CapsNet, while pipelining with an off-chip in-memory acceleration solution that effectively tackles routing procedure's inefficiency by leveraging the processingin -memory capability of today's 31) stacked memory. Using routing procedure's inherent parallellization feature, our design enables hierarchical improvements on CapsNet inference efficiency through minimizing data movement and maximizing parallel processing in memory. Evaluation results demonstrate that our proposed design can achieve substantial improvement on both performance and energy savings for CapsNet inference, with almost zero accuracy loss. The results also suggest good performance scalability in optimizing the routing procedure with increasing network size.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, ECE Dept, ECOMS Lab, Houston, TX 77004 USA.
   [Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture FSA Lab, Sydney, NSW, Australia.
   [Xie, Chenhao] Pacific Northwest Natl Lab PNNL, Richland, WA USA.
   [Wang, Jing] Capital Normal Univ, Coll Informat Engn, Beijing, Peoples R China.
   [Zhang, Weigong] Beijing Adv Innovanon Ctr Imaging Theory & Techno, Beijing, Peoples R China.
RP Zhang, XY (corresponding author), Univ Houston, ECE Dept, ECOMS Lab, Houston, TX 77004 USA.
EM xzhang55@uh.edu; shuaiwen.song@sydney.edu.au; chenhao.xie@pnnl.gov;
   jwang@cnu.edu.cn; 5591@cnu.edu.cn; xfu8@central.uh.edu
CR Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P105, DOI 10.1145/2749469.2750386
   Ahn J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P336, DOI 10.1145/2749469.2750385
   [Anonymous], 2017, 22 INT C ARCHITECTUR, DOI DOI 10.1145/3037697.3037702
   [Anonymous], SCCAPSNET DEEP LEARN
   [Anonymous], P HIPEAC WAPCO AMST
   [Anonymous], CANADIAN J REMOTE SE
   [Anonymous], THESIS
   [Anonymous], ARXIV190209839
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Buczak AL, 2016, IEEE COMMUN SURV TUT, V18, P1153, DOI 10.1109/COMST.2015.2494502
   Carrillo J., 2018, ARXIV PREPRINT ARXIV, P1
   Chen F, 2018, ASIA S PACIF DES AUT, P178, DOI 10.1109/ASPDAC.2018.8297302
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen ZY, 2018, IEEE 20TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING AND COMMUNICATIONS / IEEE 16TH INTERNATIONAL CONFERENCE ON SMART CITY / IEEE 4TH INTERNATIONAL CONFERENCE ON DATA SCIENCE AND SYSTEMS (HPCC/SMARTCITY/DSS), P578, DOI 10.1109/HPCC/SmartCity/DSS.2018.00107
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   De Caro D, 2009, IEEE T CIRCUITS-I, V56, P1968, DOI 10.1109/TCSI.2008.2010150
   Erickson BJ, 2017, RADIOGRAPHICS, V37, P505, DOI 10.1148/rg.2017160130
   Falahati H., 2018, ARXIV181211473
   Grimmer J, 2015, PS-POLIT SCI POLIT, V48, P80, DOI 10.1017/S1049096514001784
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton GE, 2018, 6 INT C LEARN REPR I, P1
   Hinton G, 2014, COGNITIVE SCI, V38, P1078, DOI 10.1111/cogs.12049
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Iandola F. N., 2016, ARXIV
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   Jeon DI, 2018, IEEE COMPUT ARCHIT L, V17, P5, DOI 10.1109/LCA.2017.2700298
   Jiménez-Sánchez A, 2018, LECT NOTES COMPUT SC, V11043, P150, DOI 10.1007/978-3-030-01364-6_17
   Joardar BK, 2019, DES AUT TEST EUROPE, P522, DOI [10.23919/date.2019.8714802, 10.23919/DATE.2019.8714802]
   Kahan W., 1996, LECT NOTES STATUS IE, V754, P11
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Kober J, 2013, INT J ROBOT RES, V32, P1238, DOI 10.1177/0278364913495721
   KOISTINEN P, 1992, ADV NEUR IN, V4, P1033
   Kononenko I, 2001, ARTIF INTELL MED, V23, P89, DOI 10.1016/S0933-3657(01)00077-X
   Kumar A. D., 2018, ABS180504424 CORR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leidel JD, 2014, PARALLEL PROCESS LET, V24, DOI 10.1142/S012962641442002X
   Li C, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P633, DOI 10.1109/SC.2016.53
   Li YJ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P175, DOI 10.1109/MICRO.2018.00023
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lomont C, 2003, FAST INVERSE SQUARE, V32
   Mao HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P669, DOI [10.1109/MICRO.2018.00060, 10.1109/MICR0.2018.00060]
   Middendorf L, 2013, COMPUT GRAPH FORUM, V32, P325, DOI 10.1111/cgf.12240
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071, P741, DOI 10.1007/978-3-030-00934-2_82
   Netzer Y., 2011, NIPS WORKSH DEEP LEA, DOI DOI 10.2118/18761-MS
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Perini F, 2018, COMBUST FLAME, V194, P37, DOI 10.1016/j.combustflame.2018.04.013
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Robertson Matthew, 2012, BRIEF HIST INVSQRT
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song MC, 2017, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2017.52
   Stoutchinin Arthur, 2019, ARXIV190201492
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Xi E, 2017, CAPSULE NETWORK PERF
   Yitbarek SF, 2016, DES AUT TEST EUROPE, P1449
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang XQ, 2019, J MED IMAG HEALTH IN, V9, P159, DOI 10.1166/jmihi.2019.2555
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
   Zoglauer A, 2011, NUCL INSTRUM METH A, V652, P568, DOI 10.1016/j.nima.2010.08.043
NR 61
TC 12
Z9 12
U1 1
U2 5
PY 2020
BP 542
EP 555
DI 10.1109/HPCA47549.2020.00051
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Zhang, XY
   Fu, X
   Zhuang, DL
   Xie, CH
   Song, SL
AF Zhang, Xingyao
   Fu, Xin
   Zhuang, Donglin
   Xie, Chenhao
   Song, Shuaiwen Leon
TI Enabling Highly Efficient Capsule Networks Processing Through
   Software-Hardware Co-Design
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Accelerators; domain-specific architectures; machine learning; emerging
   technologies
ID IMAGE CLASSIFICATION
AB As the demand for the image processing increases, the image features become increasingly complicated. Although the Convolutional Neural Network (CNN) have been widely adopted for the imaging processing tasks, it has been found easily misled due to the massive usage of pooling operations. A novel neural network structure called Capsule Networks (CapsNet) is proposed to address the CNN challenge and essentially enhance the learning ability for the image segmentation and object detection. Since the CapsNet contains the high volume of the matrix execution, it has been generally accelerated on modern GPU platforms with the highly optimized deep-learning library. However, the routing procedure of CapsNet introduces the special program and execution features,including massive unshareable intermediate variables and intensive synchronizations, causing inefficient CapsNet execution on modern GPU. To address these challenges, we propose the software-hardware co-designed optimizations, SH-CapsNet, which includes the software-level optimizations named S-CapsNet and a hybrid computing architecture design named PIM-CapsNet. In software-level, S-CapsNet reduces the computation and memory accesses by exploiting the computational redundancy and data similarity of the routing procedure. In hardware-level, the PIM-CapsNet leverages the processing-in-memory capability of today's 3D stacked memory to conduct the off-chip in-memory acceleration solution for the routing procedure, while pipelining with the GPU's on-chip computing capability for accelerating CNN types of layers in CapsNet. Evaluation results demonstrate that either our software or hardware optimizations can significantly improve the CapsNet execution efficiency. Together, our co-design can achieve greatly improvement on both performance ($3.41\times$3.41x) and energy savings (68.72 percent) for CapsNet inference, with negligible accuracy loss.
C1 [Zhang, Xingyao; Fu, Xin] Univ Houston, Dept Elect & Comp Engn, Houston, TX 77004 USA.
   [Zhuang, Donglin; Song, Shuaiwen Leon] Univ Sydney, Future Syst Architecture FSA Lab, Sydney, NSW 2006, Australia.
   [Xie, Chenhao] Pacific Northwest Natl Lab PNNL, Richland, WA 99354 USA.
RP Zhang, XY (corresponding author), Univ Houston, Dept Elect & Comp Engn, Houston, TX 77004 USA.
EM zhangxyleo2013@gmail.com; xfu8@central.uh.edu; dzhu9887@sydney.edu.au;
   chenhao.xie@pnnl.gov; shuaiwen.song@sydney.edu.au
CR [Anonymous], NVIDIA TESLA P100 WH
   [Anonymous], OPTIMIZATIONS ACCELE
   [Anonymous], 2018, DENSE DIVERSE CAPSUL
   [Anonymous], GATE LEVEL SIMULATIO
   [Anonymous], HBM3 CHEAPER 64GB ON
   [Anonymous], 2018, P INT C LEARN REPR
   [Anonymous], HMC SPECIFICATION 21
   [Anonymous], NVIDIA PROFILER
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chacón MI, 2005, NAFIPS 2005 - 2005 Annual Meeting of the North American Fuzzy Information Processing Society, P241, DOI 10.1109/NAFIPS.2005.1548541
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Coates A., P ADV C NEUR INF PRO, V2011, P5
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Falahati H., 2018, ARXIV181211473
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Hinton G, 2014, COGNITIVE SCI, V38, P1078, DOI 10.1111/cogs.12049
   Hinton GE, 2011, LECT NOTES COMPUT SC, V6791, P44, DOI 10.1007/978-3-642-21735-7_6
   Hu X, 2018, IEEE MICRO, V38, P22, DOI 10.1109/MM.2018.011441561
   Jeddeloh J., 2012, 2012 IEEE Symposium on VLSI Technology, P87, DOI 10.1109/VLSIT.2012.6242474
   Kahan W., 1996, LECT NOTES STATUS IE, V754, P11
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Kronenberger J, 2018, LECT NOTES COMPUT SC, V11141, P33, DOI 10.1007/978-3-030-01424-7_4
   Kumar A. D., 2018, ABS180504424 CORR
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Leidel JD, 2014, PARALLEL PROCESS LET, V24, DOI 10.1142/S012962641442002X
   Liu JQ, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P655, DOI [10.1109/MICR0.2018.00059, 10.1109/MICRO.2018.00059]
   Lomont C, 2003, FAST INVERSE SQUARE, V32
   Lopez D. A, 2018, THESIS U NEVADA RENO
   Marchisio A, 2019, DES AUT TEST EUROPE, P964, DOI [10.23919/DATE.2019.8714922, 10.23919/date.2019.8714922]
   Middendorf L, 2013, COMPUT GRAPH FORUM, V32, P325, DOI 10.1111/cgf.12240
   Mobiny A, 2018, LECT NOTES COMPUT SC, V11071, P741, DOI 10.1007/978-3-030-00934-2_82
   Robertson M, 2012, THESIS U NEW BRUNSWI
   Sabour S., 2017, P 31 INT C NEUR INF, P3856
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Xie CH, 2019, INT S HIGH PERF COMP, P609, DOI 10.1109/HPCA.2019.00013
   Xie CH, 2017, INT S HIGH PERF COMP, P637, DOI 10.1109/HPCA.2017.37
   Yusuf A, 2018, CAN J REMOTE SENS, V44, P532, DOI 10.1080/07038992.2018.1559725
   Zhang Dong Ping, 2014, P 23 INT S HIGH PERF, P85
   Zhang XQ, 2019, J MED IMAG HEALTH IN, V9, P159, DOI 10.1166/jmihi.2019.2555
   Zhang XY, 2020, INT S HIGH PERF COMP, P542, DOI 10.1109/HPCA47549.2020.00051
   Zhang XY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P162, DOI 10.1109/MICRO.2018.00022
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 44
TC 4
Z9 4
U1 4
U2 28
PD APR 1
PY 2021
VL 70
IS 4
BP 495
EP 510
DI 10.1109/TC.2021.3056929
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Tsuji, S
   Yamada, F
   Kawaguchi, H
   Inoue, A
   Sakai, Y
AF Tsuji, Satoki
   Yamada, Fuyuka
   Kawaguchi, Hiroshi
   Inoue, Atsuki
   Sakai, Yasufumi
TI Greedy search algorithm for partial quantization of convolutional neural
   networks inspired by submodular optimization
SO NEURAL COMPUTING & APPLICATIONS
DT Article; Early Access
DE Machine learning; Deep neural networks; Quantization; Neural
   architecture search; Submodular optimization
AB Recent results of studies have indicated that neural network quantization effects on inference accuracy vary among layers. Therefore, partial quantization and mixed precision quantization have been studied for neural network accelerators with multi-precision designs. However, these quantization methods typically require network training, which entails a high computational cost because of the exponentially increasing search space with respect to the number of layers N. However, an insufficient search leads to a significant degradation of inference accuracy. For partial quantization, this paper presents a greedy search algorithm that can derive practical combinations of quantization layers without re-training; notably, the proposed method exhibits particularly low computational complexity O(N-2). The proposed greedy search algorithm achieved 4.2x model size compression with only 0.03% accuracy degradation in ResNet50 and 2.5x compression with +0.015% accuracy gain in Xception. The computational cost of the greedy search algorithm was only 2.6 hours for a single V100 GPU in the case of MobileNetV2 quantization for ImageNet classification. Furthermore, we accelerated the proposed algorithm to computational complexity O(N) and achieved 4.15x model size compression with only 0.072% accuracy degradation in ResNet50.
C1 [Tsuji, Satoki; Yamada, Fuyuka] Kobe Univ, Grad Sch Syst Informat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.
   [Kawaguchi, Hiroshi; Inoue, Atsuki] Kobe Univ, Grad Sch Sci Technol & Innovat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.
   [Tsuji, Satoki; Yamada, Fuyuka; Sakai, Yasufumi] Fujitsu Ltd, Fujitsu Res, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
RP Tsuji, S (corresponding author), Kobe Univ, Grad Sch Syst Informat, 1-1 Rokkoudai, Kobe, Hyogo 6578501, Japan.; Tsuji, S (corresponding author), Fujitsu Ltd, Fujitsu Res, 4-1-1 Kamikodanaka, Kawasaki, Kanagawa 2118588, Japan.
EM tsuji.satoki@fujitsu.com; yamada.fuyuka@fujitsu.com;
   kawapy@godzilla.kobe-u.ac.jp; ainoue@godzilla.kobe-u.ac.jp;
   sakaiyasufumi@fujitsu.com
CR Banner Ron, 2018, POSTTRAINING 4 BIT Q
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   Choukroun Y, 2019, IEEE INT CONF COMP V, P3009, DOI 10.1109/ICCVW.2019.00363
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong Z, 2019, IEEE I CONF COMP VIS, P293, DOI 10.1109/ICCV.2019.00038
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Krishnamoorthi R., 2018, ARXIV180608342, V8, P667
   Le Q. V., 2016, ARXIV161101578
   Lin H, 2010, PROC ANN C N AM CHAP, P912
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Molchanov P., 2016, 5 INT C LEARNING REP
   Nagel M, 2019, IEEE I CONF COMP VIS, P1325, DOI 10.1109/ICCV.2019.00141
   Nagel Markus, 2020, INT C MACH LEARN, P7197
   Nahshan Y., 2019, ARXIV PREPRINT ARXIV
   Nemhauser G. L., 1981, Studies on graphs and discrete programming, P279
   Paszke A, 2019, ADV NEUR IN, V32
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Uhlich Stefan, 2019, ARXIV190511452
   Vanhoucke V., 2011, IMPROVING SPEED NEUR
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang TZ, 2020, PROC CVPR IEEE, P2075, DOI 10.1109/CVPR42600.2020.00215
   Wu BC, 2019, PROC CVPR IEEE, P10726, DOI 10.1109/CVPR.2019.01099
   Wu Hao, 2020, ARXIV200409602
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xie Q., 2020, P IEEE CVF C COMP VI
   Zhang Peizhao, 2018, ARXIV181200090
   Zhou S., 2016, ARXIV160606160
   Zhou YR, 2018, AAAI CONF ARTIF INTE, P4596
   Zichao Guo, 2020, Computer Vision - ECCV 2020 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12361), P544, DOI 10.1007/978-3-030-58517-4_32
NR 38
TC 0
Z9 0
U1 0
U2 1
PD 2022 JAN 13
PY 2022
DI 10.1007/s00521-021-06752-7
EA JAN 2022
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Juste, B
   Barrachina, T
   Miró, R
   Verdú, G
AF Juste, Belen
   Barrachina, Teresa
   Miro, Rafael
   Verdu, Gumersindo
BE GomezChova, L
   LopezMartinez, A
   CandelTorres, I
TI USE OF SIMULATION CODES IN NUCLEAR ENGINEERING TO INCREASE THE KNOWLEDGE
   OF RADIATION TRANSPORT THROUGH MATTER
SO EDULEARN15: 7TH INTERNATIONAL CONFERENCE ON EDUCATION AND NEW LEARNING
   TECHNOLOGIES
SE EDULEARN Proceedings
DT Proceedings Paper
CT 7th International Conference on Education and New Learning Technologies
   (EDULEARN)
CY JUL 06-08, 2015
CL Barcelona, SPAIN
DE simulation; radiation transport; radiological protection; medical
   physics
AB Radiation transport through matter is a complex phenomenon whose physics can be described by the Boltzmann equation, involving the interactions of different subatomic particles, like photons, electrons and/or neutrons.
   The use of simulation become complex for undergraduate students since fields as Radiation Protection need good knowledge of several subjects as computing, a high level of mathematical skills in modeling and numerical methods or a good knowledge of the physical problem to be simulated.
   We have introduced the use of Monte Carlo radiation transport codes in the master programs taught at the Chemical and Nuclear Engineering Department at the UPV. Radiological Protection and Radiation Technology computer-aided learning courses are designed to be supported with the use of simulation techniques to analyze, design and understand the behavior of industrial of medical devices making use of ionizing radiation. These devices include radiotherapy linear accelerators, mammographic and diagnostic X-ray machines, industrial X-ray equipment, radiation detectors, etc. Then, the goal of the courses is that students develop the capabilities necessaries to face complex problems, using computer codes as a tool.
C1 [Juste, Belen; Barrachina, Teresa; Miro, Rafael; Verdu, Gumersindo] Univ Politecn Valencia, DIQN, E-46022 Valencia, Spain.
   [Barrachina, Teresa] Univ Politecn Valencia, DEIOAC, E-46022 Valencia, Spain.
RP Juste, B (corresponding author), Univ Politecn Valencia, DIQN, E-46022 Valencia, Spain.
CR Barrows H.S., 1980, PROBLEM BASED LEARNI
   James M. R., 2014, LACP1400745 LOS AL N
   Martz Roger L., LAUR1105668 TN GEN D
NR 3
TC 0
Z9 0
U1 0
U2 3
PY 2015
BP 6655
EP 6659
WC Education & Educational Research
DA 2023-11-11
ER

PT C
AU Romero, P
   Idler, C
AF Romero, Phil
   Idler, Craig
GP IEEE
TI Methodologies and Application of Machine Learning Algorithms to Classify
   the Performance of High Performance Cluster Components
SO 2014 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT 16th IEEE International Conference on Cluster Computing (CLUSTER)
CY SEP 22-26, 2014
CL Madrid, SPAIN
AB High Performance Computing Clusters are designed to host highly parallelized applications, often in excess of thousands of nodes allocated to a job. These jobs, especially those that require a high level of synchronous communication, can be greatly affected by a single poor, or even sub-standard performing component. These components, often referred to as a node, are typically comprised of CPUs, accelerator processors, memory, a communication bus, and so on. Consequently it is important to identify and eliminate these sub-standard performing nodes before a job is scheduled onto them.
   In this paper we will describe the process used to measure and the methodology used to quantify poor performing nodes or classify suspect performing nodes into groups, or clusters, that can be later used to identify future performance issues. This process is more involved than simply running a scientific calculation across all the nodes, finding one that was "slow", and labeling it as a bad node. At Los Alamos, this methodology has been used successfully to find problem nodes and has helped characterize the components of other clusters to aid in the proactive elimination of potential problems.
C1 [Romero, Phil] Los Alamos Natl Lab, High Performance Comp 1, Los Alamos, NM 87545 USA.
   [Idler, Craig] Los Alamos Natl Lab, High Performance Comp 5, Los Alamos, NM USA.
RP Romero, P (corresponding author), Los Alamos Natl Lab, High Performance Comp 1, Los Alamos, NM 87545 USA.
EM prr@lanl.gov; cwi@lanl.gov
CR Abdi Herve, 2010, WILEY INTERDISCIPLIN
   Antoine, 2001, LINPACK BENCHMARK PR
   Coates A., 2012, NEURAL NETWORKS TRIC
   Danalis A, 2010, SCALABLE HETEROGENEO
   Ketchen Jr David J., 1996, STRATEGIC MANAGEMENT, V17
   Madhulatha T. Soni, 2011, INT J ADV COMPUT APR
   Tibshirani R., 2001, J ROYAL STAT SOC B
   van der Maaten L., 2013, P INT C LEARN REPR
NR 8
TC 0
Z9 0
U1 0
U2 0
PY 2014
BP 400
EP 407
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Selmi, R
   Hammoudeh, S
   Errami, Y
   Wohar, ME
AF Selmi, Refk
   Hammoudeh, Shawkat
   Errami, Youssef
   Wohar, Mark E.
TI Is COVID-19 Related Anxiety an Accelerator for Responsible and
   Sustainable Investing ? A Sentiment Analysis
SO APPLIED ECONOMICS
DT Article
DE COVID-19; anxiety; environmental and social responsibilities; Sentiment
   analysis
ID LONG-RUN CAUSALITY; TIME-SERIES
AB The excessive volatility generated by the COVID-19 pandemic highlights that environmental and social issues are potential elements that businesses and governments must manage effectively and swiftly. This study seeks to test whether the rising anxiety over this pandemic has affected the attitudes and choices towards environmentally and socially responsible investing. To this end, we first use machine learning tools to examine tweets related to this unprecedented and wild shock. Second, we compare the impact of these sentiments on the stock performance of companies from the S&P500 that meet environmental and social sustainability criteria for three COVID-19 phases with varying levels of anxiety, which we label incubation, fever and the increasing risk of second wave pandemic (in the absence of vaccine). Our findings reveal that the increasing uncertainty and worries over COVID-19 and its consequences has not distracted investors' attention away from environmental and social issues, but companies with responsible strategies on environmental issues that specifically address climate responsibility are likely to be more responsive to sentiments at the current situation of emergency.
C1 [Selmi, Refk; Errami, Youssef] ESC Pau Business Sch, Pau, France.
   [Hammoudeh, Shawkat] Drexel Univ, Lebow Coll Business, Philadelphia, PA USA.
   [Wohar, Mark E.] Univ Econ, Inst Business Res, Ho Chi Minh, Vietnam.
   Univ Nebraska, Coll Business Adm, Sch Business & Econ, Omaha, NE 68182 USA.
RP Wohar, ME (corresponding author), Univ Nebraska, Coll Business Adm, Omaha, NE 68182 USA.
EM mwohar@mail.unomaha.edu
CR Breitung J, 2006, J ECONOMETRICS, V132, P363, DOI 10.1016/j.jeconom.2005.02.004
   Broock WA., 1996, ECONOMET REV, V15, P197, DOI [DOI 10.1080/07474939608800353, DOI 10.1080/2F07474939608800353.NUME]
   Dufour JM, 2006, J ECONOMETRICS, V132, P337, DOI 10.1016/j.jeconom.2005.02.003
   Dufour JM, 1998, ECONOMETRICA, V66, P1099, DOI 10.2307/2999631
   Fernandez M, 2016, PROCEEDINGS OF THE 2016 ACM WEB SCIENCE CONFERENCE (WEBSCI'16), P85, DOI 10.1145/2908131.2908167
   Garel A, 2020, INVESTOR REWARDS ENV
   Hodson J., 2018, INTERDISCIPLINARY EN, V12, P17
   Jost F., ENV SCI POLICY
   O'Brien K, 2015, SCIENCE, V350, P1170, DOI 10.1126/science.aad0267
   Porshnev A., SSRN ELECT J
   Scharl A, 2017, IEEE SYST J, V11, P762, DOI 10.1109/JSYST.2015.2466439
   Sluban B., 2015, COMPUTATIONAL SOCIAL, V2, P1, DOI [DOI 10.1186/S40649-015-0016-5, 10.1186/s40649-015-0016-5]
   Sluban B, 2014, 10TH INTERNATIONAL CONFERENCE ON SIGNAL-IMAGE TECHNOLOGY AND INTERNET-BASED SYSTEMS SITIS 2014, P376, DOI 10.1109/SITIS.2014.27
   Stulz, 2020, W27106 NAT BUR EC RE
   Weichselbraun A, 2016, P ANN HICSS, P1040, DOI 10.1109/HICSS.2016.133
NR 15
TC 8
Z9 8
U1 2
U2 33
PD MAR 16
PY 2021
VL 53
IS 13
BP 1528
EP 1539
DI 10.1080/00036846.2020.1834501
EA OCT 2020
WC Economics
DA 2023-11-11
ER

PT J
AU Mazumdar, S
   Scionti, A
AF Mazumdar, Somnath
   Scionti, Alberto
TI Ring-mesh: a scalable and high-performance approach for manycore
   accelerators
SO JOURNAL OF SUPERCOMPUTING
DT Article
DE Interconnect; Network-on-chip; Manycores; Performance; Energy; Latency;
   Throughput
ID NETWORK; TOPOLOGY; INTERCONNECT; GENERATION; DESIGN; TOOL; NOC
AB There is increasing number of works addressing the design challenges of fast, scalable solutions for the growing number of new type of applications. Recently, many of the solutions aimed at improving processing element capabilities to speed up the execution of machine learning application domain. However, only a few works focused on the interconnection subsystem as a potential source of performance improvement. Wrapping many cores together offer excellent parallelism, but it brings other challenges (e.g. adequate interconnections). Scalable, power-aware interconnects are required to support such a growing number of processing elements, as well as modern applications. In this paper, we propose a scalable and energy-efficient network-on-chip architecture fusing the advantages of rings as well as the 2D mesh without using any bridge router to provide high performance. A dynamic adaptation mechanism allows to better adapt to the application requirements. Simulation results show efficient power consumption (up to141.3%saving for connecting 1024 cores),2x (on average) throughput growth with better scalability (up to 1024 processing elements) compared to popular 2D mesh while tested in multiple statistical traffic pattern scenarios.
C1 [Mazumdar, Somnath] Univ Siena, Dept Informat Engn & Math, Siena, Italy.
   [Scionti, Alberto] LINKS Fdn, Turin, Italy.
RP Mazumdar, S (corresponding author), Univ Siena, Dept Informat Engn & Math, Siena, Italy.
EM mazumdar@dii.unisi.it; alberto.scionti@linksfoundation.com
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2016, VLSI CIRCUITS 2016 I
   [Anonymous], 2011, P 5 ACMIEEE INT S
   Ausavarungnirun R, 2016, PARALLEL COMPUT, V54, P29, DOI 10.1016/j.parco.2016.01.009
   Balfour J., 2006, P 20 ANN INT C SUP I, P187, DOI DOI 10.1145/1183401.1183430
   BARAN P, 1964, IEEE T COMMUN SYST, VCS12, P1, DOI 10.1109/TCOM.1964.1088883
   Barrow-Williams N, 2009, I S WORKL CHAR PROC, P86, DOI 10.1109/IISWC.2009.5306792
   Besta M, 2018, ACM SIGPLAN NOTICES, V53, P43, DOI [10.1145/3173162.3177158, 10.1145/3296957.3177158]
   Bolotin E, 2004, INTEGRATION, V38, P19, DOI 10.1016/j.vlsi.2004.03.006
   Bourduas S, 2007, NOCS 2007: FIRST INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP, PROCEEDINGS, P195
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen XN, 2003, ISLPED'03: PROCEEDINGS OF THE 2003 INTERNATIONAL SYMPOSIUM ON LOW POWER ELECTRONICS AND DESIGN, P90
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Choi W, 2018, IEEE T COMPUT, V67, P672, DOI 10.1109/TC.2017.2777863
   Dally W. J., 2004, PRINCIPLES PRACTICES
   Das R, 2009, INT S HIGH PERF COMP, P175, DOI 10.1109/HPCA.2009.4798252
   Ding L, 2012, PROCEEDINGS OF ISCRAM ASIA 2012 CONFERENCE ON INFORMATION SYSTEMS FOR CRISIS RESPONSE AND MANAGEMENT, P201
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Grot B, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P401, DOI 10.1145/2024723.2000112
   Hamacher VC, 2001, IEEE T COMPUT, V50, P1, DOI 10.1109/12.902749
   Harting RC, 2012, TECHNICAL REPORT, V131
   Horro M, 2019, IEEE ACCESS, V7, P81195, DOI 10.1109/ACCESS.2019.2923855
   Hoskote Y, 2007, IEEE MICRO, V27, P51, DOI 10.1109/MM.2007.4378783
   Jeffers J, 2016, INTEL XEON PHI PROCE
   Junghee Lee, 2013, 2013 IEEE Computer Society Annual Symposium on VLSI. Emerging VLSI Technologies and Architectures (ISVLSI), P2, DOI 10.1109/ISVLSI.2013.6654614
   Kandula S, 2009, IMC'09: PROCEEDINGS OF THE 2009 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P202
   Kim H, 2014, INT S HIGH PERF COMP, P332, DOI 10.1109/HPCA.2014.6835943
   Kim J, 2007, INT SYMP MICROARCH, P172, DOI 10.1109/MICRO.2007.29
   Kim J, 2008, CONF PROC INT SYMP C, P77, DOI 10.1109/ISCA.2008.19
   Kumar A, 2007, CONF PROC INT SYMP C, P150, DOI 10.1145/1273440.1250681
   Kurth T, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126916
   Kwon H, 2017, NEW J PHYS, V19, DOI 10.1088/1367-2630/aa68f5
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Liu SL, 2016, IEEE T PARALL DISTR, V27, P1700, DOI 10.1109/TPDS.2015.2465905
   Liu XX, 2018, ASIA S PACIF DES AUT, P141, DOI 10.1109/ASPDAC.2018.8297296
   Liu Y, 2016, APPL DEEP CONVOLUTIO, P81
   Ma S, 2012, INT S HIGH PERF COMP, P467
   Maltz, 2010, P 10 ACM SIGCOMM C I, P267, DOI DOI 10.1145/1879141.1879175
   Moraes F, 2004, INTEGRATION, V38, P69, DOI 10.1016/j.vlsi.2004.03.003
   Murali S, 2004, DES AUT CON, P914, DOI 10.1145/996566.996809
   Papamichael MK, 2012, FPGA 12: PROCEEDINGS OF THE 2012 ACM-SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P37
   Parikh R, 2014, DES AUT CON
   Puttmann C, 2007, DSD 2007: 10TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN ARCHITECTURES, METHODS AND TOOLS, PROCEEDINGS, P495, DOI 10.1109/DSD.2007.4341514
   Ravindran G, 1997, THIRD INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER ARCHITECTURE - PROCEEDINGS, P58, DOI 10.1109/HPCA.1997.569606
   Scionti A, 2018, IEEE COMPUT ARCHIT L, V17, P1, DOI 10.1109/LCA.2017.2697863
   Scionti A, 2016, 2016 INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING & SIMULATION (HPCS 2016), P112, DOI 10.1109/HPCSim.2016.7568323
   Suettlerlein J, 2013, LECT NOTES COMPUT SC, V8097, P633, DOI 10.1007/978-3-642-40047-6_63
   Tam SM, 2018, ISSCC DIG TECH PAP I, P34, DOI 10.1109/ISSCC.2018.8310170
   Vangal SR, 2008, IEEE J SOLID-ST CIRC, V43, P29, DOI 10.1109/JSSC.2007.910957
   Vranesic ZG, 1995, NUMACHINE MULTIPROCE
   Wang H, 2003, 36TH INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, PROCEEDINGS, P105
   Wentzlaff D, 2007, IEEE MICRO, V27, P15, DOI 10.1109/MM.2007.4378780
   Xianglun Leng, 2005, International Symposium on Communications and Information Technologies 2005 (IEEE Cat. No.05EX1224), P1203
   Zheng NJ, 2015, MICROPROCESS MICROSY, V39, P313, DOI 10.1016/j.micpro.2015.03.008
NR 55
TC 2
Z9 2
U1 0
U2 1
PD SEP
PY 2020
VL 76
IS 9
BP 6720
EP 6752
DI 10.1007/s11227-019-03072-5
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Hassan, O
   Paul, T
   Thakker, R
   Parvin, D
   Shuvo, MMH
   Mosa, AM
   Islam, SK
AF Hassan, Omiya
   Paul, Tanmoy
   Thakker, Rushil
   Parvin, Dilruba
   Shuvo, Md Maruf Hossain
   Mosa, Abu Saleh Mohammad
   Islam, Syed Kamrul
GP IEEE
TI A Multi-Sensor Based Automatic Sleep Apnea Detection System for Adults
   Using Neural Network Inference on FPGA
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON MEDICAL MEASUREMENTS AND
   APPLICATIONS (MEMEA 2022)
SE IEEE International Symposium on Medical Measurements and Applications
   Proceedings-MeMeA
DT Proceedings Paper
CT 17th IEEE International Symposium on Medical Measurements and
   Applications (IEEE MeMeA)
CY JUN 22-24, 2022
CL Messina, ITALY
DE Sleep Apnea; ECG Sensor; Biomedical; Feedforward Neural Network;
   Shifter; FPGA; Digital Hardware; Deep Learning
ID ELECTROCARDIOGRAM; VARIABILITY; OXIMETRY
AB This paper proposes an automatic sleep apnea monitoring device for adults employing of single ECG patch and a pulse oximeter. The device is designed to automatically detect sleep apneic (SA) events with the inference of feedforward neural network (FNN) model embedded in digital hardware. The three-layer (8-6-4) FNN model was trained over several epochs with a 5-fold cross validation technique where the training set had a mini-batch size of 10. Open-source Apnea ECG dataset collected from the PhysioNET bank was used in training, validating, and testing the model. Rectified Linear Unit (ReLU) activation function was used in the input and hidden layers of the network and sigmoid function was used as the output classifier. ADAM optimizer was used for optimization of the model while mean-squared-error (MSE) was used for calculating model loss. The final trained and validated model was implemented onto re-programmable digital hardware called Field Programmable Gate Array (FPGA). The hardware implementation of the model yielded an accuracy of over 87 percent with a power consumption rate of around 52 W, which is 5x times lower than that of commercially available machine learning hardware accelerators. The proposed system design will be realized in integrated circuits on CMOS platform for developing energy-efficient, smart, wearable, and automated sleep apnea detection and screening device for adults.
C1 [Hassan, Omiya; Paul, Tanmoy; Thakker, Rushil; Parvin, Dilruba; Shuvo, Md Maruf Hossain; Islam, Syed Kamrul] Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
   [Mosa, Abu Saleh Mohammad] Univ Missouri, Dept Hlth Management & Informat, Columbia, MO 65211 USA.
RP Hassan, O (corresponding author), Univ Missouri, Dept Elect Engn & Comp Sci, Columbia, MO 65211 USA.
EM omiya.hassan@mail.missouri.edu
CR Alvarez D, 2020, SCI REP-UK, V10, DOI 10.1038/s41598-020-62223-4
   Amaral L., 2020, CIRCULATION, V101, P215
   Azimi H, 2020, IEEE INT SYM MED MEA, DOI 10.1109/memea49120.2020.9137203
   de Chazal P, 2009, PHILOS T R SOC A, V367, P369, DOI 10.1098/rsta.2008.0156
   Han S, 2015, ADV NEUR IN, V28
   Hassan O, 2020, MIDWEST SYMP CIRCUIT, P607, DOI [10.1109/mwscas48704.2020.9184554, 10.1109/MWSCAS48704.2020.9184554]
   Hassan T., 2022, J SIGNAL PROCESS SYS
   Hillman DR, 2006, SLEEP, V29, P299, DOI 10.1093/sleep/29.3.299
   Hossain M. M., 2021, IEEE INT INSTRUMENTA
   Jin JY, 2015, IEEE T BIOMED CIRC S, V9, P96, DOI 10.1109/TBCAS.2014.2314301
   Khincha Rishab, 2020, Image and Signal Processing. 9th International Conference, ICISP 2020. Proceedings. Lecture Notes in Computer Science (LNCS 12119), P377, DOI 10.1007/978-3-030-51935-3_40
   Kwon S, 2021, SENSORS-BASEL, V21, DOI 10.3390/s21093122
   Leung RST, 2001, AM J RESP CRIT CARE, V164, P2147, DOI 10.1164/ajrccm.164.12.2107045
   Li HY, 2019, FUTURE GENER COMP SY, V98, P69, DOI 10.1016/j.future.2018.12.001
   Li KY, 2018, NEUROCOMPUTING, V294, P94, DOI 10.1016/j.neucom.2018.03.011
   Mostafa SS, 2017, 2017 XXVI INTERNATIONAL CONFERENCE ON INFORMATION, COMMUNICATION AND AUTOMATION TECHNOLOGIES (ICAT)
   Narkiewicz K, 1998, CIRCULATION, V98, P1071, DOI 10.1161/01.CIR.98.11.1071
   Penzel T, 2000, COMPUT CARDIOL, V27, P255, DOI 10.1109/CIC.2000.898505
   PhysioNet, US
   Ravelo-García AG, 2015, ENTROPY-SWITZ, V17, P914, DOI 10.3390/e17030914
   Schmittendorf E, 2011, BIOMED TECH, V56, P215, DOI 10.1515/BMT.2011.101
   Song CY, 2016, IEEE T BIO-MED ENG, V63, P1532, DOI 10.1109/TBME.2015.2498199
   Tsmots I, 2019, EXP DES APPL CAD SYS, DOI 10.1109/cadsm.2019.8779253
   Varon C, 2015, IEEE T BIO-MED ENG, V62, P2269, DOI 10.1109/TBME.2015.2422378
   Wang T, 2019, BIOMED RES INT, V2019, DOI 10.1155/2019/9768072
NR 25
TC 2
Z9 2
U1 0
U2 2
PY 2022
DI 10.1109/MEMEA54994.2022.9856509
WC Engineering, Biomedical
DA 2023-11-11
ER

PT C
AU Belabed, T
   Coutinho, MGF
   Fernandes, MAC
   Carlos, V
   Souani, C
AF Belabed, Tarek
   Coutinho, Maria Gracielly F.
   Fernandes, Marcelo A. C.
   Carlos, Valderrama
   Souani, Chokri
GP IEEE
TI Low Cost and Low Power Stacked Sparse Autoencoder Hardware Acceleration
   for Deep Learning Edge Computing Applications
SO 2020 5TH INTERNATIONAL CONFERENCE ON ADVANCED TECHNOLOGIES FOR SIGNAL
   AND IMAGE PROCESSING (ATSIP'2020)
DT Proceedings Paper
CT 5th International Conference on Advanced Technologies for Signal and
   Image Processing (ATSIP)
CY SEP 02-05, 2020
CL Sfax, TUNISIA
DE Autoencoder; FPGA; Low energy consumption; low cost
AB Nowadays, Deep Learning DL becoming more and more interesting in many areas, such as genomics, security, data analysis, image, and video processing. However, DL requires more and more powerful and parallel computing. The calculation performed by super-machines equipped with powerful processors, such as the latest GPUs. Despite their power, these computing units consume a lot of energy, which makes their use very difficult in small embedded systems and edge computing. To overcome the problem for which we must keep the maximum performance and satisfy the power constraint, it is necessary to use a heterogeneous strategy. Some solutions are promising when using less energy-consuming electronic circuits, such as FPGAs associated with less expensive topologies such as Stacked Sparse Autoencoders. Our target architecture is the Xilinx ZYNQ 7020 SoC, which combines a dual-core ARM processor and an FPGA in the same chip. In the interest of flexibility, we decided to leverage the performance of Xilinx's high-level synthesis tools, evaluate and choose the best solution in terms of size and performance of the data exchange, synchronization and pipeline processing. The results show that our implementation gives high performance at very low energy consumption. Indeed, the evaluation of our accelerator shows that it can classify 1160 MNIST images per second, consuming only 0.443 W; 2.4 W for the entire system. More than the low energy consumption and the high performance, the platform used only costs $ 125.
C1 [Belabed, Tarek; Carlos, Valderrama] iUniv Mons, Fac Polytech, SEMi, 31 Bd Dolez, B-7000 Mons, Belgium.
   [Belabed, Tarek] Univ Sousse, Ecole Natl Ingn Sousse, Sousse 4000, Tunisia.
   [Belabed, Tarek; Souani, Chokri] Univ Monastir, Fac Sci Monastir, Lab Microelect & Instrumentat, Monastir 5019, Tunisia.
   [Souani, Chokri] Univ Sousse, Inst Super Sci Appl & Technol Sousse, Sousse 4003, Tunisia.
   [Coutinho, Maria Gracielly F.; Fernandes, Marcelo A. C.] Univ Fed Rio Grande do Norte, Dept Comp & Automat Engn, BR-59078970 Natal, RN, Brazil.
RP Belabed, T (corresponding author), iUniv Mons, Fac Polytech, SEMi, 31 Bd Dolez, B-7000 Mons, Belgium.; Belabed, T (corresponding author), Univ Sousse, Ecole Natl Ingn Sousse, Sousse 4000, Tunisia.; Belabed, T (corresponding author), Univ Monastir, Fac Sci Monastir, Lab Microelect & Instrumentat, Monastir 5019, Tunisia.
EM belabed.tarek@gmail.com; gracielly@dca.ufrn.br; mfernandes@dca.ufrn.br;
   sakuyama@umons.ac.be; chokri.souani@gmail.com
CR Coutinho MGF, 2019, IEEE ACCESS, V7, P40674, DOI 10.1109/ACCESS.2019.2907261
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   LeCun Y., MNIST DATABASE HANDW
   Maria J, 2016, NEURAL PROCESS LETT, V43, P445, DOI 10.1007/s11063-015-9430-9
   Moss DJM, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350890
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou YM, 2015, PROCEEDINGS OF 2015 4TH INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND NETWORK TECHNOLOGY (ICCSNT 2015), P829, DOI 10.1109/ICCSNT.2015.7490869
NR 8
TC 3
Z9 3
U1 0
U2 0
PY 2020
DI 10.1109/atsip49331.2020.9231748
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic; Imaging Science & Photographic Technology
DA 2023-11-11
ER

PT C
AU Akin, B
   Chishti, ZA
   Alameldeen, AR
AF Akin, Berkin
   Chishti, Zeshan A.
   Alameldeen, Alaa R.
GP Assoc Comp Machinery
TI ZCOMP: Reducing DNN Cross-Layer Memory Footprint Using Vector Extensions
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE Deep learning; memory system; sparsity; compression; ISA; CPU
ID CACHE COMPRESSION
AB Deep Neural Networks (DNNs) are becoming the prevalent approach in computer vision, machine learning, natural language processing, and speech recognition applications. Although DNNs are perceived as compute-intensive tasks, they also apply intense pressure on the capacity and bandwidth of the memory hierarchy, primarily due to the large intermediate data communicated across network layers. Prior work on hardware DNN accelerators leverages the cross-layer data sparsity via fully-customized datapaths. However, dynamically compressing/expanding such data is a challenging task for general-purpose multi-processors with virtual memory and hardware-managed coherent cache hierarchies.
   In this paper, we observe that the DNN intermediate data is either sequentially streamed or reshaped with a regular transformation between layers. Hence, accesses to this data can tolerate a sequential or block sequential compression/expansion without requiring random element retrieval. Based on this insight, we propose ZCOMP, a CPU vector ISA extension tailored for DNN cross-layer communication. ZCOMP compactly represents zero value compression/expansion and fully automates the metadata generation, storage and retrieval which eliminates the need for several extra instruction executions and register usage. ZCOMP can be targeted both for inference and training to dynamically compress/expand cross-layer data before being written to memory. Our evaluations for individual layers and end-to-end DNN networks demonstrate that ZCOMP offers substantial data traffic reduction, both on-chip across cache-hierarchy and off-chip to DRAM, and performance improvements over no compression and existing AVX512 compression approaches.
C1 [Akin, Berkin; Chishti, Zeshan A.; Alameldeen, Alaa R.] Intel Labs, Hillsboro, OR 97124 USA.
RP Akin, B (corresponding author), Intel Labs, Hillsboro, OR 97124 USA.
EM berkin.akin@intel.com; zeshan.a.chishti@intel.com;
   alaa.r.alameldeen@intel.com
CR Abadi M, TENSORFLOW SYSTEM LA
   Aklaghi Vahideh, 2018, ACM IEEE INT S COMP
   Alameldeen AR, 2018, PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS (MEMSYS 2018), P129, DOI 10.1145/3240302.3240429
   Alameldeen Alaa R, 2004, 1500 U WISC DEP COMP
   Alameldeen AR, 2004, CONF PROC INT SYMP C, P212
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M., 2016, MICROPAGE, P1
   [Anonymous], 2016, ACM SIGARCH COMPUTER, DOI DOI 10.1109/ISCA.2016.32
   [Anonymous], 2016, MICRO
   Arelakis A, 2014, CONF PROC INT SYMP C, P145, DOI 10.1109/ISCA.2014.6853231
   Carlson TE, 2014, ACM T ARCHIT CODE OP, V11, P127, DOI 10.1145/2629677
   Chen Tianqi, 2016, ARXIV160406174
   Chen X, 2010, IEEE T VLSI SYST, V18, P1196, DOI 10.1109/TVLSI.2009.2020989
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Dusser J, 2009, ICS'09: PROCEEDINGS OF THE 2009 ACM SIGARCH INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P46, DOI 10.1145/1542275.1542288
   Fog Agner, 2018, LISTS INSTRUCTION LA
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gao M, 2017, OPER SYST REV, V51, P751, DOI 10.1145/3037697.3037702
   Gaur J, 2016, CONF PROC INT SYMP C, P317, DOI 10.1109/ISCA.2016.36
   Georganas Evangelos, 2018, ARXIV180805567
   Hallnor EG, 2005, INT S HIGH PERF COMP, P201, DOI 10.1109/HPCA.2005.4
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Hill P, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P786, DOI 10.1145/3123939.3123970
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon Y, 2018, IEEE COMPUT ARCHIT L, V17, P134, DOI 10.1109/LCA.2018.2823302
   Liu Y., 2018, ARXIV180902697
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Park Ji Ho, 2018, BAM BOTTLENECK ATTEN
   Pekhimenko Gennady, 2012, P INT C PAR ARCH COM, P51
   Rhu M, 2016, 2016 49 ANN IEEEACM, P1, DOI [DOI 10.1109/MICRO.2016.7783721, 10.1109/MICRO.2016.7783721]
   Rhu M, 2018, INT S HIGH PERF COMP, P78, DOI 10.1109/HPCA.2018.00017
   Sardashti S, 2014, INT SYMP MICROARCH, P331, DOI 10.1109/MICRO.2014.41
   Sardashti Somayeh, 2013, P 46 ANN INT S MICR
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Tang L., 2018, SCHEDULING COMPUTATI
   Vanhoucke Vincent, 2011, DEEP LEARN UNS FEAT
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
NR 48
TC 13
Z9 13
U1 0
U2 2
PY 2019
BP 126
EP 138
DI 10.1145/3352460.3358305
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Selg, H
   Jenihhin, M
   Ellervee, P
   Raik, J
AF Selg, Hardi
   Jenihhin, Maksim
   Ellervee, Peeter
   Raik, Jaan
BE Savino, A
   Maniatakos, M
   DiCarlo, S
   Gizopoulos, D
TI ML-Based Online Design Error Localization for RISC-V Implementations
SO 2023 IEEE 29TH INTERNATIONAL SYMPOSIUM ON ON-LINE TESTING AND ROBUST
   SYSTEM DESIGN, IOLTS
SE IEEE International On-Line Testing Symposium
DT Proceedings Paper
CT 29th IEEE International Symposium on On-Line Testing and Robust System
   Design (IOLTS)
CY JUL 03-05, 2023
CL Platanias, GREECE
DE Online design error debug; microprocessor architecture; machine
   learning; neural architecture search
ID TRACE; BUGS
AB The accelerated growth of computing systems' complexity makes comprehensive design verification challenging and time-consuming. In practice, hard-to-model complex environments are unfeasible to be simulated exhaustively within a reasonable time frame. Therefore, some corner-case conditions can be overlooked and design errors might escape to the final product. This means that it is imperative for the system to be able to detect and locate bugs to enable self-repair. This is particularly crucial during long-term remote missions in order to apply graceful degradation. This paper proposes a novel online design error localization methodology for microprocessors by immediate analysis of traced and buffered signals upon a failure detection event, using a pre-trained Neural Network (NN) and existing processor components, i.e. trace buffers and AI accelerators. An in-house Neural Architecture Search (NAS) framework is used to train a tailored Multi-Layer Perceptron (MLP) NN for error localization at the microprocessor module-level resolution. The proposed approach is validated by simulating a RISC-V implementation with different workload programs. It is demonstrated to be capable of localizing the microprocessor module of bug origin with 92.81% accuracy, on average.
C1 [Selg, Hardi; Jenihhin, Maksim; Ellervee, Peeter; Raik, Jaan] Tallinn Univ Technol, Comp Syst, Tallinn, Estonia.
RP Selg, H (corresponding author), Tallinn Univ Technol, Comp Syst, Tallinn, Estonia.
EM hardi.selg@taltech.ee
CR Abramovici M, 2006, DES AUT CON, P7, DOI 10.1109/DAC.2006.238683
   Azambuja JR, 2013, IEEE T NUCL SCI, V60, P2805, DOI 10.1109/TNS.2013.2246798
   Azambuja JR, 2012, IEEE T NUCL SCI, V59, P1117, DOI 10.1109/TNS.2012.2201750
   Bailey B., WHAT MAKES RISC V VE
   Benso A, 2001, IEEE MICRO, V21, P16, DOI 10.1109/40.958696
   Dutta A, 2021, J COMPUT LANG, V66, DOI 10.1016/j.cola.2021.101064
   Dutto S, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1456, DOI 10.23919/DATE51398.2021.9474120
   Goh M., 2006, MSP430 COMPETITIVE B
   Grosso M., 2010, 2010 IEEE 16th International On-Line Testing Symposium (IOLTS 2010), P167, DOI 10.1109/IOLTS.2010.5560215
   Jenihhin M, 2014, IEEE DES TEST, V31, P83, DOI 10.1109/MDAT.2013.2271420
   Jin HF, 2019, KDD'19: PROCEEDINGS OF THE 25TH ACM SIGKDD INTERNATIONAL CONFERENCCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P1946, DOI 10.1145/3292500.3330648
   Jones J. A., 2005, P 20 IEEE ACM INT C, P273
   Jutman A, 2017, DES AUT TEST EUROPE, P115, DOI 10.23919/DATE.2017.7926968
   Kumar B, 2020, IEEE T COMPUT AID D, V39, P248, DOI 10.1109/TCAD.2018.2883899
   Li M, 2013, DES AUT TEST EUROPE, P485
   Li X, 2019, PROCEEDINGS OF THE 28TH ACM SIGSOFT INTERNATIONAL SYMPOSIUM ON SOFTWARE TESTING AND ANALYSIS (ISSTA '19), P169, DOI 10.1145/3293882.3330574
   McCann E., SYSTEM VALIDATION AR
   Nakamura Y, 2002, 2002 PACIFIC RIM INTERNATIONAL SYMPOSIUM ON DEPENDABLE COMPUTING, PROCEEDINGS, P75, DOI 10.1109/PRDC.2002.1185621
   Rahmani K, 2016, IEEE T VLSI SYST, V24, P313, DOI 10.1109/TVLSI.2015.2396083
   Schiavone PD, 2018, IEEE SOI3DSUB MICRO
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Selg H, 2021, INT SYM DEFEC FAU TO, DOI 10.1109/DFT52944.2021.9568321
   Veira N, 2020, IEEE T COMPUT AID D, V39, P5267, DOI 10.1109/TCAD.2020.2966448
   VESSEY I, 1986, IEEE T SYST MAN CYB, V16, P621, DOI 10.1109/TSMC.1986.289308
   WEICKER RP, 1984, COMMUN ACM, V27, P1013, DOI 10.1145/358274.358283
   Xiao Y, 2018, ASIA PAC SOFWR ENG, P703, DOI 10.1109/APSEC.2018.00097
   Xiao Y, 2017, ASIA PAC SOFWR ENG, P338, DOI 10.1109/APSEC.2017.40
   Zhou J, 2012, PROC INT CONF SOFTW, P14, DOI 10.1109/ICSE.2012.6227210
NR 28
TC 0
Z9 0
U1 0
U2 0
PY 2023
DI 10.1109/IOLTS59296.2023.10224864
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Ansari, S
   Du, HP
   Naghdy, F
AF Ansari, Shahzeb
   Du, Haiping
   Naghdy, Fazel
GP IEEE
TI Driver's Foot Trajectory Tracking for Safe Maneuverability Using New
   Modified reLU-BiLSTM Deep Neural Network
SO 2020 IEEE INTERNATIONAL CONFERENCE ON SYSTEMS, MAN, AND CYBERNETICS
   (SMC)
SE IEEE International Conference on Systems Man and Cybernetics Conference
   Proceedings
DT Proceedings Paper
CT IEEE International Conference on Systems, Man, and Cybernetics (SMC)
CY OCT 11-14, 2020
CL ELECTR NETWORK
DE Driver foot behaviour; foot trajectory; foot posture; classification;
   deep learning model; reLU-BiLSTM
ID PEDAL APPLICATIONS; RISK
AB Driver's foot behaviour is unpredictable and can suddenly change the nature of driving and dynamics under the influence of different factors that stimulates the driving style. Such effects result in sudden variations in foot dynamics and trajectory between accelerator and brake pedals inducing vagueness in smart active control system. This paper is an extension to the intrusive approach where driver's foot trajectory and shifting between pedals are monitored using XSENS motion capture system. The main objective is to predict the foot patterns associated with acceleration and braking. The experiments were conducted on 10 young subjects on MATHWORKS driver-in-loop (DIL) simulator, interfaced with Unreal Engine 4 studio. A new modified bidirectional long short-term memory (Bi-LSTM) deep neural network based on a rectified linear unit layer was designed, trained, tested and compared with traditional machine learning algorithms on 3D time-series foot orientation data for the sequence-to-sequence classification. The results show that the proposed classifier performs well and successfully recognizes the driver's foot behaviour with overall accuracy of 99.8%. Such identified patterns will help in determining the foot posture and the degree of intention in pressing the particular pedal. Moreover, the patterns will be useful for early intervention by smart systems to cope with the longitudinal mistakes made during driving. The limitations of the current work and directions for future work are explored.
C1 [Ansari, Shahzeb; Du, Haiping; Naghdy, Fazel] Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2500, Australia.
RP Ansari, S (corresponding author), Univ Wollongong, Sch Elect Comp & Telecommun Engn, Wollongong, NSW 2500, Australia.
EM sa345@uowmail.edu.au
CR Ameli S, 2017, PATTERN RECOGN, V63, P246, DOI 10.1016/j.patcog.2016.08.002
   Atwood J, 2018, ACCIDENT ANAL PREV, V119, P149, DOI 10.1016/j.aap.2018.07.007
   Bin Y, 2019, IEEE T CYBERNETICS, V49, P2631, DOI 10.1109/TCYB.2018.2831447
   Blanco JL., 2010, U MALAGA TECH REP, V3, P6
   Cui ZY, 2020, TRANSPORT RES C-EMER, V118, DOI 10.1016/j.trc.2020.102674
   Tran C, 2012, COMPUT VIS IMAGE UND, V116, P435, DOI 10.1016/j.cviu.2011.09.008
   Frank S, 2019, J AMB INTEL SMART EN, V11, P221, DOI 10.3233/AIS-190522
   Hatfield J, 2014, ACCIDENT ANAL PREV, V62, P223, DOI 10.1016/j.aap.2013.09.028
   Jagvaral B, 2020, EXPERT SYST APPL, V142, DOI 10.1016/j.eswa.2019.112960
   Kim J, 2020, J NUCL CARDIOL, V27, P2154, DOI 10.1007/s12350-019-01617-y
   Kuipers J. B., 1999, QUATERNIONS ROTATION
   Liu G, 2019, NEUROCOMPUTING, V337, P325, DOI 10.1016/j.neucom.2019.01.078
   Mathworks, 2019, VEH DYN BLOCKS
   Murad A, 2017, SENSORS-BASEL, V17, DOI 10.3390/s17112556
   Ohn-Bar E, 2014, IEEE INT VEH SYM, P719, DOI 10.1109/IVS.2014.6856612
   Panhwar YN, 2018, IEEE INT C BIOINF BI, P269, DOI 10.1109/BIBE.2018.00059
   Podusenko A, 2017, 2017 56TH ANNUAL CONFERENCE OF THE SOCIETY OF INSTRUMENT AND CONTROL ENGINEERS OF JAPAN (SICE), P1622, DOI 10.23919/SICE.2017.8105641
   Suzuki K., 2018, 01487191 SAE
   Tran C, 2012, IEEE INT C INTELL TR, P1137, DOI 10.1109/ITSC.2012.6338908
   Tran C, 2011, IEEE INT VEH SYM, P577, DOI 10.1109/IVS.2011.5940548
   Wu YQ, 2018, ACCIDENT ANAL PREV, V118, P146, DOI 10.1016/j.aap.2018.02.011
   Wu YQ, 2017, ACCIDENT ANAL PREV, V99, P102, DOI 10.1016/j.aap.2016.10.019
   Wu YQ, 2015, HUM FACTORS, V57, P1276, DOI 10.1177/0018720815589665
   Xi Y., 2018, SAE TECHNICAL PAPER, P01
   Zeng H, 2018, COGN NEURODYNAMICS, V12, P597, DOI 10.1007/s11571-018-9496-y
   Zhang ZJ, 2018, 2018 IEEE/ACM 26TH INTERNATIONAL SYMPOSIUM ON QUALITY OF SERVICE (IWQOS), DOI 10.1109/IWQoS.2018.8624183
NR 26
TC 5
Z9 5
U1 0
U2 2
PY 2020
BP 4392
EP 4397
WC Computer Science, Cybernetics; Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Xu, XY
   Ren, GH
   Feleppa, T
   Liu, XM
   Boes, A
   Mitchell, A
   Lowery, AJ
AF Xu, Xingyuan
   Ren, Guanghui
   Feleppa, Tim
   Liu, Xumeng
   Boes, Andreas
   Mitchell, Arnan
   Lowery, Arthur J.
TI Self-calibrating programmable photonic integrated circuits
SO NATURE PHOTONICS
DT Article
ID PHASE; TRIPLEX; CHIP
AB Researchers demonstrate a self-calibrating programmable photonic integrated circuit. The findings may be useful for the accurate control of large-scale photonic integrated circuits in applications such as light-based machine learning.
   Programmable photonic integrated circuits (PICs) are dense assemblies of tunable elements that provide flexible reconfigurability to enable different functions to be selected; however, due to manufacturing variations and thermal gradients that affect the optical phases of the elements, it is difficult to guarantee a stable correspondence between the electrical commands to the chip, and the function that it provides. Here we demonstrate a self-calibrating programmable PIC with full control over its complex impulse response, in the presence of thermal cross-talk between phase-tuning elements. Self-calibration is achieved by: (1) incorporating an optical reference path into the PIC; (2) using the Kramers-Kronig relationship to recover the phase response from amplitude measurements; and (3) applying a fast-converging self-calibration algorithm. We demonstrate dial-up signal processing functions with complex impulse responses using only 25 training iterations. This approach offers stable and accurate control of large-scale PICs, for demanding applications such as communications network reconfiguration, neuromorphic hardware accelerators and quantum computers.
C1 [Xu, Xingyuan; Feleppa, Tim; Liu, Xumeng; Lowery, Arthur J.] Monash Univ, Dept Elect & Comp Syst Engn, Electrophoton Lab, Clayton, Vic, Australia.
   [Xu, Xingyuan] Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
   [Ren, Guanghui; Boes, Andreas; Mitchell, Arnan] RMIT Univ, Sch Engn, Integrated Photon & Applicat Ctr, Melbourne, Vic, Australia.
   [Boes, Andreas] Univ Adelaide, Inst Photon & Adv Sensing IPAS, Adelaide, SA, Australia.
   [Boes, Andreas] Univ Adelaide, Sch Elect & Elect Engn, Adelaide, SA, Australia.
RP Xu, XY (corresponding author), Monash Univ, Dept Elect & Comp Syst Engn, Electrophoton Lab, Clayton, Vic, Australia.; Xu, XY (corresponding author), Beijing Univ Posts & Telecommun, State Key Lab Informat Photon & Opt Commun, Beijing, Peoples R China.
EM xingyuanxu@bupt.edu.cn
CR Annoni A, 2017, LIGHT-SCI APPL, V6, DOI 10.1038/lsa.2017.110
   Bogaerts W., 2013, P SPIE, V8781
   Bogaerts W, 2020, NATURE, V586, P207, DOI 10.1038/s41586-020-2764-0
   Capmany J., 2019, PROGRAMMABLE INTEGRA
   Capmany J, 2016, NAT PHOTONICS, V10, P6, DOI 10.1038/nphoton.2015.254
   Carolan J, 2019, OPTICA, V6, P335, DOI 10.1364/OPTICA.6.000335
   Carolan J, 2015, SCIENCE, V349, P711, DOI 10.1126/science.aab3642
   Carroll L, 2016, APPL SCI-BASEL, V6, DOI 10.3390/app6120426
   Cheng Q, 2015, J OPT COMMUN NETW, V7, pA388, DOI 10.1364/JOCN.7.00A388
   Choo G, 2018, J LIGHTWAVE TECHNOL, V36, P5263, DOI 10.1109/JLT.2018.2873199
   Choo G, 2018, J LIGHTWAVE TECHNOL, V36, P1899, DOI 10.1109/JLT.2018.2795582
   Chrostowski L, 2015, SILICON PHOTONICS DESIGN, P1
   Gazman A, 2018, OPT EXPRESS, V26, P32662, DOI 10.1364/OE.26.032662
   Guan BV, 2014, IEEE J SEL TOP QUANT, V20, DOI 10.1109/JSTQE.2013.2296233
   Guo YH, 2016, OPT LETT, V41, P4939, DOI 10.1364/OL.41.004939
   Halir R, 2009, OPT EXPRESS, V17, P8349, DOI 10.1364/OE.17.008349
   HAYES MH, 1980, IEEE T ACOUST SPEECH, V28, P672, DOI 10.1109/TASSP.1980.1163463
   Inniss D., 2016, SILICON PHOTONICS FU
   Jayatilleka H, 2018, J LIGHTWAVE TECHNOL, V36, P210, DOI 10.1109/JLT.2017.2769962
   Jiang HY, 2018, OPT LETT, V43, P415, DOI 10.1364/OL.43.000415
   Li Z, 2017, J LIGHTWAVE TECHNOL, V35, P1887, DOI 10.1109/JLT.2017.2684298
   Lin Y, 2018, IEEE PHOTONICS J, V10, DOI 10.1109/JPHOT.2018.2842026
   Lyke JC, 2015, P IEEE, V103, P291, DOI 10.1109/JPROC.2015.2397832
   Mauthe S, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-18374-z
   Mecozzi A, 2016, OPTICA, V3, P1220, DOI 10.1364/OPTICA.3.001220
   Milanizadeh M, 2019, J LIGHTWAVE TECHNOL, V37, P1325, DOI 10.1109/JLT.2019.2892512
   Miller DAB, 2015, OPTICA, V2, P747, DOI 10.1364/OPTICA.2.000747
   Ozcan A, 2006, J LIGHTWAVE TECHNOL, V24, P1739, DOI 10.1109/JLT.2006.871111
   Ozcan A, 2006, J OPT SOC AM A, V23, P1669, DOI 10.1364/JOSAA.23.001669
   Pérez D, 2019, OPTICA, V6, P19, DOI 10.1364/OPTICA.6.000019
   Pérez D, 2018, OPT EXPRESS, V26, P27265, DOI 10.1364/OE.26.027265
   Pérez D, 2017, NAT COMMUN, V8, DOI 10.1038/s41467-017-00714-1
   Pérez-López D, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-19608-w
   Qiao PF, 2017, IEEE J SEL TOP QUANT, V23, DOI 10.1109/JSTQE.2017.2707181
   Ribeiro A, 2016, OPTICA, V3, P1348, DOI 10.1364/OPTICA.3.001348
   Roeloffzen CGH, 2013, OPT EXPRESS, V21, P22937, DOI 10.1364/OE.21.022937
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Streshinsky M, 2013, OPT PHOTONICS NEWS, V24, P32, DOI 10.1364/OPN.24.9.000032
   Tait AN, 2016, OPT EXPRESS, V24, P8895, DOI 10.1364/OE.24.008895
   Tait AN, 2016, IEEE PHOTONIC TECH L, V28, P887, DOI 10.1109/LPT.2016.2516440
   Wörhoff K, 2015, ADV OPT TECHNOL, V4, P189, DOI 10.1515/aot-2015-0016
   Xie YW, 2018, NANOPHOTONICS-BERLIN, V7, P837, DOI 10.1515/nanoph-2017-0113
   Yegnanarayanan S., 2018, C LASERS ELECTRO OPT
   Zhang H, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-020-20719-7
   Zhang WF, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-14249-0
   Zheng D, 2019, OPT LETT, V44, P2629, DOI 10.1364/OL.44.002629
   Zhuang LM, 2015, OPTICA, V2, P854, DOI 10.1364/OPTICA.2.000854
   Zhuang LM, 2012, OPT EXPRESS, V20, P26499, DOI 10.1364/OE.20.026499
NR 48
TC 28
Z9 29
U1 20
U2 80
PD AUG
PY 2022
VL 16
IS 8
BP 595
EP +
DI 10.1038/s41566-022-01020-z
EA JUL 2022
WC Optics; Physics, Applied
DA 2023-11-11
ER

PT J
AU Kim, MS
   Del Barrio, AA
   Kim, H
   Bagherzadeh, N
AF Kim, Min Soo
   Del Barrio, Alberto A.
   Kim, Hyunjin
   Bagherzadeh, Nader
TI The Effects of Approximate Multiplication on Convolutional Neural
   Networks
SO IEEE TRANSACTIONS ON EMERGING TOPICS IN COMPUTING
DT Article
DE Machine learning; computer vision; object recognition; arithmetic and
   logic units; low-power design
AB This article analyzes the effects of approximate multiplication when performing inferences on deep convolutional neural networks (CNNs). The approximate multiplication can reduce the cost of the underlying circuits so that CNN inferences can be performed more efficiently in hardware accelerators. The study identifies the critical factors in the convolution, fully-connected, and batch normalization layers that allow more accurate CNN predictions despite the errors from approximate multiplication. The same factors also provide an arithmetic explanation of why bfloat16 multiplication performs well on CNNs. The experiments are performed with recognized network architectures to show that the approximate multipliers can produce predictions that are nearly as accurate as the FP32 references, without additional training. For example, the ResNet and Inception-v4 models with Mitch-w6 multiplication produces Top-5 errors that are within 0.2 percent compared to the FP32 references. A brief cost comparison of Mitch-w6 against bfloat16 is presented where a MAC operation saves up to 80 percent of energy compared to the bfloat16 arithmetic. The most far-reaching contribution of this article is the analytical justification that multiplications can be approximated while additions need to be exact in CNN MAC operations.
C1 [Kim, Min Soo] NGD Syst, Irvine, CA 92618 USA.
   [Del Barrio, Alberto A.] Univ Complutense Madrid, Dept Comp Architecture & Automat, Madrid 28040, Spain.
   [Kim, Hyunjin] Dankook Univ, Sch Elect & Elect Engn, Yongin 16890, Gyeonggi Do, South Korea.
   [Bagherzadeh, Nader] Univ Calif Irvine, Dept Elect Engn & Comp Sci, Irvine, CA 92697 USA.
RP Kim, MS (corresponding author), NGD Syst, Irvine, CA 92618 USA.
EM minsk1@uci.edu
CR Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Ansari MS, 2020, IEEE T VLSI SYST, V28, P317, DOI 10.1109/TVLSI.2019.2940943
   Chippa VK, 2010, DES AUT CON, P555
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   De S, 2018, 2018 21ST EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN (DSD 2018), P288, DOI 10.1109/DSD.2018.00059
   Del Barrio A, 2019, LOGARITHMETIC
   Del Barrio AA, 2014, ACM T EMBED COMPUT S, V13, DOI 10.1145/2567932
   Du ZD, 2014, ASIA S PACIF DES AUT, P201, DOI 10.1109/ASPDAC.2014.6742890
   Guadarrama S., 2016, TENSORFLOW SLIM LIGH
   Hammad I, 2018, IEEE ACCESS, V6, P60438, DOI 10.1109/ACCESS.2018.2875376
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Henry G, 2019, P S COMP ARITHM, P69, DOI 10.1109/ARITH.2019.00019
   Imani M, 2018, ASIA S PACIF DES AUT, P682, DOI 10.1109/ASPDAC.2018.8297401
   Ioffe S., 2015, ARXIV150203167, P448, DOI DOI 10.48550/ARXIV.1502.03167
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Judd P, 2016, INT SYMP MICROARCH
   Kim D, 2017, IEEE T EMERG TOP COM, V5, P164, DOI 10.1109/TETC.2017.2673548
   Kim H, 2019, P S COMP ARITHM, P108, DOI 10.1109/ARITH.2019.00029
   Kim MS, 2019, IEEE T COMPUT, V68, P660, DOI 10.1109/TC.2018.2880742
   Kim MS, 2018, ASIA S PACIF DES AUT, P617, DOI 10.1109/ASPDAC.2018.8297391
   Kung J, 2015, I SYMPOS LOW POWER E, P85, DOI 10.1109/ISLPED.2015.7273495
   Lai L, 2017, ARXIV 170303073
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lin DD, 2016, PR MACH LEARN RES, V48
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Liu Y, 2020, PROCEEDINGS OF THE 28TH ACM JOINT MEETING ON EUROPEAN SOFTWARE ENGINEERING CONFERENCE AND SYMPOSIUM ON THE FOUNDATIONS OF SOFTWARE ENGINEERING (ESEC/FSE '20), P1320, DOI 10.1145/3368089.3417051
   Lotric U, 2012, NEUROCOMPUTING, V96, P57, DOI 10.1016/j.neucom.2011.09.039
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Miyashita D., 2016, ARXIV160301025
   Mrazek V, 2019, ICCAD-IEEE ACM INT, DOI 10.1109/iccad45719.2019.8942068
   Mrazek V, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967021
   Oliveira L.T., 2019, EUROPEAN S ARTIFICIA, P203
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Salamat S, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON REBOOTING COMPUTING (ICRC), P219
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Sarwar SS, 2016, DES AUT TEST EUROPE, P145
   Shim Y., 2016, PATAIS CHEM FUNCTION, P1
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Wang S., 2019, GOOGLE CLOUD BLO AUG
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
NR 45
TC 20
Z9 20
U1 1
U2 17
PD APR-JUN
PY 2022
VL 10
IS 2
BP 904
EP 916
DI 10.1109/TETC.2021.3050989
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT C
AU Bhattacharjee, D
   Devadoss, R
   Chattopadhyay, A
AF Bhattacharjee, Debjyoti
   Devadoss, Rajeswari
   Chattopadhyay, Anupam
GP IEEE
TI ReVAMP : ReRAM based VLIW Architecture for in-Memory comPuting
SO PROCEEDINGS OF THE 2017 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE &
   EXHIBITION (DATE)
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT 20th Conference and Exhibition on Design, Automation and Test in Europe
   (DATE)
CY MAR 27-31, 2017
CL EPFL Campus, Lausanne, SWITZERLAND
HO EPFL Campus
AB With diverse types of emerging devices offering simultaneous capability of storage and logic operations, researchers have proposed novel platforms that promise gains in energy-efficiency. Such platforms can be classified into two domainsapplication- specific and general-purpose. The application-specific in-memory computing platforms include machine learning accelerators, arithmetic units, and Content Addressable Memory (CAM)-based structures. On the other hand, the general-purpose computing platforms stem from the idea that several in-memory computing logic devices do support a universal set of Boolean logic operation and therefore, can be used for mapping arbitrary Boolean functions efficiently. In this direction, so far, researchers have concentrated on challenges in logic synthesis (e.g. depth optimization), and technology mapping (e.g. device count reduction). The important problem of efficient technology mapping of arbitrary logic network onto a crossbar array structure has been overlooked so far. In this paper, we propose, ReVAMP, a generalpurpose computing platform based on Resistive RAM crossbar array, which exploits the parallelism in computing multiple logic operations in the same word. Further, we study the problem of instruction generation and scheduling for such a platform. We benchmark the performance of ReVAMP with respect to the state of the art architecture.
C1 [Bhattacharjee, Debjyoti; Devadoss, Rajeswari; Chattopadhyay, Anupam] Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
RP Bhattacharjee, D (corresponding author), Nanyang Technol Univ, Sch Comp Sci & Engn, Singapore 639798, Singapore.
EM debjyoti001@ntu.edu.sg; rajeswari@ntu.edu.sg; anupam@ntu.edu.sg
CR Amaru L. G., 2014, P 51 ANN DES AUT C, P1
   Bhattacharjee D., 2016, VER LARG SCAL INT VL, P1, DOI DOI 10.1109/VLSISOC.2016.7753568
   Bhattacharjee D., 2016, P 35 INT C COMP AID, P119
   Easwaran Arvind, 2017, 22 AS S PAC DES AUT
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Hamdioui S, 2015, DES AUT TEST EUROPE, P1718
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Lehtonen E, 2009, 2009 IEEE/ACM INTERNATIONAL SYMPOSIUM ON NANOSCALE ARCHITECTURES, P33, DOI 10.1109/NANOARCH.2009.5226356
   Linn E, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/30/305205
   Poikonen JH, 2012, IEEE T COMPUT AID D, V31, P1129, DOI 10.1109/TCAD.2012.2187524
   Raghuvanshi A, 2014, ICCAD-IEEE ACM INT, P470, DOI 10.1109/ICCAD.2014.7001393
   Shirinzadeh S., 2016, DATE
   Shulaker MM, 2013, NATURE, V501, P526, DOI 10.1038/nature12502
   Siemon A, 2014, IEEE INT SYMP CIRC S, P1420, DOI 10.1109/ISCAS.2014.6865411
   Siemon A, 2015, IEEE J EM SEL TOP C, V5, P64, DOI 10.1109/JETCAS.2015.2398217
   Soeken M., 2016, DAC
   Strukov DB, 2010, IEEE INT SYMP CIRC S, P1967, DOI 10.1109/ISCAS.2010.5537020
NR 17
TC 38
Z9 38
U1 0
U2 1
PY 2017
BP 782
EP 787
WC Automation & Control Systems; Engineering, Industrial; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Arnaudov, P
   Ogunfunmi, T
AF Arnaudov, Pavel
   Ogunfunmi, Tokunbo
TI Artificially Intelligent Adaptive Search Fast Motion Estimation
   Algorithm for HD Video
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Motion estimation; H; 264; HEVC; AI; ML; ASIC; VLSI; HMDS; Adaptive;
   Video coding; Video compression; Video; multidimensional signal
   processing
ID DIAMOND SEARCH
AB This paper presents a new Machine Learning based approach to video Fast Motion Estimation, which improves quality, minimizes power consumption and provides control over the performance vs power balance, rendering it very suitable for hardware implementation into a motion co-processor. Many mobile and hand-held devices today deploy such hardware accelerators. The main goal of the presented algorithm is to achieve maximum quality Motion Estimation per unit of consumed power by minimizing the number of search points and also providing an optional mechanism for finding an optimal early termination point. The paper presents the creation of a dictionary of adaptively pre-learned fixed search patterns along with a pre-trained neural network to adaptively help select the most adequate search pattern from a dictionary according to the dynamics of the motion within a specific region of the video frame, not the frame or scene as a whole. There are often motions in various directions within the same scene or frame and the ability to focus on a local region within the frame improves quality significantly. Full Search represents the quality goal and upper boundary for any integer Fast Motion Estimation. The presented algorithm adds about 1 dB of PSNR to state-of-the-art fixed search patterns. There is only about 0.5 dB of PSNR remaining between our algorithm and Full Search.
C1 [Arnaudov, Pavel; Ogunfunmi, Tokunbo] Santa Clara Univ, Santa Clara, CA 95053 USA.
RP Ogunfunmi, T (corresponding author), Santa Clara Univ, Santa Clara, CA 95053 USA.
EM togunfunmi@scu.edu
CR Al-Najdawi N, 2014, INFORM SCIENCES, V268, P425, DOI 10.1016/j.ins.2013.08.009
   Arnaudov P., ICCE 17, P221
   Arnaudov P., 2017, 10 INT C UB MED COMP, P1
   Arnaudov P., 2017, ISCAS C, P1
   Arnaudov P, 2017, CONF REC ASILOMAR C, P173, DOI 10.1109/ACSSC.2017.8335161
   Arnaudov P, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P11, DOI 10.1109/SiPS.2016.10
   Cheng YS, 2009, IEEE INT SYMP CIRC S, P880, DOI 10.1109/ISCAS.2009.5117897
   Cheung CH, 2005, IEEE T MULTIMEDIA, V7, P16, DOI 10.1109/TMM.2004.840609
   Hosur P.I., 2 INT C INF COMM SIG
   Jeong JH, 2015, INT SOC DESIGN CONF, P275, DOI 10.1109/ISOCC.2015.7401754
   Jing X, 2004, IEEE T MULTIMEDIA, V6, P435, DOI 10.1109/TMM.2004.827517
   LI RX, 1994, IEEE T CIRC SYST VID, V4, P438, DOI 10.1109/76.313138
   NAM KM, 1995, IEEE T CIRC SYST VID, V5, P344, DOI 10.1109/76.465087
   Ndili O, 2011, IEEE T CIRC SYST VID, V21, P1214, DOI 10.1109/TCSVT.2011.2133990
   Ndili O, 2010, IEEE IMAGE PROC, P749, DOI 10.1109/ICIP.2010.5652065
   Parmar N, 2014, INT SOC DESIGN CONF, P260, DOI 10.1109/ISOCC.2014.7087637
   Po LM, 1996, IEEE T CIRC SYST VID, V6, P313, DOI 10.1109/76.499840
   Song X., 1998, ISCAS 98 P 1998 IEEE, V4, P126
   Sullivan GJ, 2012, IEEE T CIRC SYST VID, V22, P1649, DOI 10.1109/TCSVT.2012.2221191
   Tham JY, 1998, IEEE T CIRC SYST VID, V8, P369, DOI 10.1109/76.709403
   Tourapis AM, 2002, IEEE T CIRC SYST VID, V12, P934, DOI 10.1109/TCSVT.2002.804894
   Tourapis HYC, 2003, 2003 INTERNATIONAL CONFERENCE ON MULTIMEDIA AND EXPO, VOL III, PROCEEDINGS, P517
   Wiegand T, 2003, IEEE T CIRC SYST VID, V13, P560, DOI 10.1109/TCSVT.2003.815165
   Zhu S, 2000, IEEE T IMAGE PROCESS, V9, P287, DOI 10.1109/83.821744
NR 24
TC 3
Z9 3
U1 0
U2 4
PD APR
PY 2020
VL 92
IS 4
BP 389
EP 408
DI 10.1007/s11265-019-01466-5
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Schade, R
   Kenter, T
   Elgabarty, H
   Lass, M
   Schütt, O
   Lazzaro, A
   Pabst, H
   Mohr, S
   Hutter, J
   Kühne, TD
   Plessl, C
AF Schade, Robert
   Kenter, Tobias
   Elgabarty, Hossam
   Lass, Michael
   Schuett, Ole
   Lazzaro, Alfio
   Pabst, Hans
   Mohr, Stephan
   Hutter, Juerg
   Kuehne, Thomas D.
   Plessl, Christian
TI Towards electronic structure-based <i>ab-initio</i> molecular dynamics
   simulations with hundreds of millions of atoms
SO PARALLEL COMPUTING
DT Article
DE Supercomputing; High-performance computing; Massively-parallel
   algorithms; Large-scale linear algebra; Ab-initio molecular dynamics;
   Approximate computing
ID LINEAR-SCALING DFT; 1ST PRINCIPLES; DENSITY; CODE; PARALLELISM;
   PERFORMANCE; FIELD
AB We push the boundaries of electronic structure-based ab-initio molecular dynamics (AIMD) beyond 100 million atoms. This scale is otherwise barely reachable with classical force-field methods or novel neural network and machine learning potentials. We achieve this breakthrough by combining innovations in linear-scaling AIMD, efficient and approximate sparse linear algebra, low and mixed-precision floating-point computation on GPUs, and a compensation scheme for the errors introduced by numerical approximations.
   The core of our work is the non-orthogonalized local submatrix method (NOLSM), which scales very favorably to massively parallel computing systems and translates large sparse matrix operations into highly parallel, dense matrix operations that are ideally suited to hardware accelerators. We demonstrate that the NOLSM method, which is at the center point of each AIMD step, is able to achieve a sustained performance of 324 PFLOP/s in mixed FP16/FP32 precision corresponding to an efficiency of 67.7% when running on 1536 NVIDIA A100 GPUs.
C1 [Schade, Robert; Kenter, Tobias; Lass, Michael; Kuehne, Thomas D.; Plessl, Christian] Paderborn Univ, Paderborn Ctr Parallel Comp, Warburger Str 100, D-33098 Paderborn, Germany.
   [Kenter, Tobias; Lass, Michael; Plessl, Christian] Paderborn Univ, Dept Comp Sci, Warburger Str 100, D-33098 Paderborn, Germany.
   [Elgabarty, Hossam; Kuehne, Thomas D.] Paderborn Univ, Dept Chem, Warburger Str 100, D-33098 Paderborn, Germany.
   [Schuett, Ole] Swiss Fed Inst Technol, Dept Mat, CH-8092 Zurich, Switzerland.
   [Lazzaro, Alfio] HPE Switzerland GmbH, Basel, Switzerland.
   [Pabst, Hans] Intel Extreme Comp Software & Syst, Zurich, Switzerland.
   [Mohr, Stephan] Nextmol Bytelab Solut SL, Barcelona, Spain.
   [Mohr, Stephan] Barcelona Supercomp Ctr BSC, Barcelona, Spain.
   [Hutter, Juerg] Univ Zurich, Dept Chem, Zurich, Switzerland.
RP Kühne, TD (corresponding author), Paderborn Univ, Paderborn Ctr Parallel Comp, Warburger Str 100, D-33098 Paderborn, Germany.; Kühne, TD (corresponding author), Paderborn Univ, Dept Chem, Warburger Str 100, D-33098 Paderborn, Germany.
EM thomas.kuehne@uni-paderborn.de
CR Andermatt S, 2016, J CHEM THEORY COMPUT, V12, P3214, DOI 10.1021/acs.jctc.6b00398
   [Anonymous], HARDWARE CONFIGURATI
   [Anonymous], JUWELS BOOSTER TOP 5
   Arita M, 2014, J ADV SIMUL SCI ENG, V1, P87, DOI 10.15748/jasse.1.87
   Bartók AP, 2017, SCI ADV, V3, DOI 10.1126/sciadv.1701816
   Borstnik U, 2014, PARALLEL COMPUT, V40, P47, DOI 10.1016/j.parco.2014.03.012
   Bowler DR, 2010, J PHYS-CONDENS MAT, V22, DOI 10.1088/0953-8984/22/7/074207
   CAR R, 1985, PHYS REV LETT, V55, P2471, DOI 10.1103/PhysRevLett.55.2471
   Das S, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3357157
   ESSMANN U, 1995, J CHEM PHYS, V103, P8577, DOI 10.1063/1.470117
   Fattebert JL, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P12, DOI 10.1109/SC.2016.88
   GALLI G, 1992, PHYS REV LETT, V69, P3547, DOI 10.1103/PhysRevLett.69.3547
   github, US
   Goedecker S, 1999, REV MOD PHYS, V71, P1085, DOI 10.1103/RevModPhys.71.1085
   Grimme S, 2017, J CHEM THEORY COMPUT, V13, P1989, DOI 10.1021/acs.jctc.7b00118
   Grimme S, 2011, J COMPUT CHEM, V32, P1456, DOI 10.1002/jcc.21759
   Gygi, 2006, P 2006 ACM IEEE C SU, P45
   Gygi F, 2008, IBM J RES DEV, V52, P137, DOI 10.1147/rd.521.0137
   Hasegawa Y, 2014, INT J HIGH PERFORM C, V28, P335, DOI 10.1177/1094342013508163
   Higham NJ, 1997, NUMER ALGORITHMS, V15, P227, DOI 10.1023/A:1019150005407
   Hutter J, 2005, CHEMPHYSCHEM, V6, P1788, DOI 10.1002/cphc.200500059
   Hutter J, 2005, PARALLEL COMPUT, V31, P1, DOI 10.1016/j.parco.2004.12.004
   Jain N, 2016, LECT NOTES COMPUT SC, V9697, P139, DOI 10.1007/978-3-319-41321-1_8
   Johnson SG, 2001, OPT EXPRESS, V8, P173, DOI 10.1364/OE.8.000173
   Karhan K, 2014, J CHEM PHYS, V141, DOI 10.1063/1.4902537
   Keith J.A, ARXIV
   KENNEY C, 1991, SIAM J MATRIX ANAL A, V12, P273, DOI 10.1137/0612020
   Klavík P, 2014, PHILOS T R SOC A, V372, DOI 10.1098/rsta.2013.0278
   Kühne TD, 2020, ANN PHYS-NEW YORK, V421, DOI 10.1016/j.aop.2020.168290
   Kühne TD, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0007045
   Kühne TD, 2018, ANN PHYS-NEW YORK, V391, P120, DOI 10.1016/j.aop.2018.01.016
   Kühne TD, 2014, WIRES COMPUT MOL SCI, V4, P391, DOI 10.1002/wcms.1176
   Kühne TD, 2009, J CHEM THEORY COMPUT, V5, P235, DOI 10.1021/ct800417q
   Kühne TD, 2007, PHYS REV LETT, V98, DOI 10.1103/PhysRevLett.98.066401
   Lass, 2020, PROC INT C HIGH PERF, P1127
   Lass M, 2017, PROCEEDINGS OF THE PLATFORM FOR ADVANCED SCIENTIFIC COMPUTING CONFERENCE (PASC '18), DOI 10.1145/3218176.3218231
   MacKerell AD, 1998, J PHYS CHEM B, V102, P3586, DOI 10.1021/jp973084f
   MCWEENY R, 1960, REV MOD PHYS, V32, P335, DOI 10.1103/RevModPhys.32.335
   METROPOLIS N, 1953, J CHEM PHYS, V21, P1087, DOI 10.1063/1.1699114
   Motamarri P, 2020, COMPUT PHYS COMMUN, V246, DOI 10.1016/j.cpc.2019.07.016
   Nakata A, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0005074
   Németh K, 2000, J CHEM PHYS, V113, P6035, DOI 10.1063/1.1308546
   Nomura K, 2014, INT CONF HIGH PERFOR, P661, DOI 10.1109/SC.2014.59
   nvidia, US
   NVIDIA Corp, 2021, CUDA C PROGRAMMING G
   PAYNE MC, 1992, REV MOD PHYS, V64, P1045, DOI 10.1103/RevModPhys.64.1045
   Plessl C., 2015, INFORM SPEKTRUM, V38, P396, DOI [10.1007/s00287-015-0911-z, DOI 10.1007/S00287-015-0911-Z]
   Prentice JCA, 2020, J CHEM PHYS, V152, DOI 10.1063/5.0004445
   Prodan E, 2005, P NATL ACAD SCI USA, V102, P11635, DOI 10.1073/pnas.0505436102
   PULAY P, 1969, MOL PHYS, V17, P197, DOI 10.1080/00268976900100941
   RAHMAN A, 1964, PHYS REV, V136, pA405, DOI 10.1103/PhysRev.136.A405
   RAPPE AK, 1992, J AM CHEM SOC, V114, P10024, DOI 10.1021/ja00051a040
   Rengaraj V, 2020, COMPUTATION, V8, DOI 10.3390/computation8020039
   Ricci A, 2003, MOL PHYS, V101, P1927, DOI 10.1080/0026897031000108113
   Richters D, 2019, COMMUN COMPUT PHYS, V25, P564, DOI 10.4208/cicp.OA-2018-0053
   Richters D, 2014, J CHEM PHYS, V140, DOI 10.1063/1.4869865
   Schade Robert, 2021, Zenodo, DOI 10.5281/ZENODO.4692508
   Schulz G., 1933, Z ANGEW MATH MECH, V13, P57, DOI DOI 10.1002/ZAMM.19330130111
   VandeVondele J, 2012, J CHEM THEORY COMPUT, V8, P3565, DOI 10.1021/ct200897x
   Wilkinson KA, 2014, J CHEM THEORY COMPUT, V10, P4782, DOI 10.1021/ct500686r
   YANG WT, 1991, PHYS REV LETT, V66, P1438, DOI 10.1103/PhysRevLett.66.1438
   Zhao GP, 2013, NATURE, V497, P643, DOI 10.1038/nature12162
   Zhao ZJ, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012079
NR 63
TC 8
Z9 8
U1 1
U2 3
PD JUL
PY 2022
VL 111
AR 102920
DI 10.1016/j.parco.2022.102920
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Vandebon, J
   Coutinho, JGF
   Luk, W
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
TI Scheduling Hardware-Accelerated Cloud Functions
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Cloud computing; Heterogeneous computing; FaaS; FPGA
AB This paper presents a Function-as-a-Service (FaaS) approach for deploying managed cloud functions onto heterogeneous cloud infrastructures. Current FaaS systems, such as AWS Lambda, allow domain-specific functionality, such as AI, HPC and image processing, to be deployed in the cloud while abstracting users from infrastructure and platform concerns. Existing approaches, however, use a single type of resource configuration to execute all function requests. In this paper, we present a novel FaaS approach that allows cloud functions to be effectively executed across heterogeneous compute resources, including hardware accelerators such as GPUs and FPGAs. We implement heterogeneous scheduling to tailor resource selection to each request, taking into account performance and cost concerns. In this way, our approach makes use of different processor types and quantities (e.g. 2 CPU cores), uniquely suited to handle different types of workload, potentially providing improved performance at a reduced cost. We validate our approach in three application domains: machine learning, bio-informatics, and physics, and target a hardware platform with a combined computational capacity of 24 FPGAs and 12 CPU cores. Compared to traditional FaaS, our approach achieves a cost improvement for non-uniform traffic of up to 8.9 times, while maintaining performance objectives.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk
CR Amazon Web Services, AM EC2
   Amazon Web Services, AWS LAMBD SERV COMP
   Apache Software Foundation, OP SOURC SERV CLOUD
   Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Bleuse R, 2017, IEEE T PARALL DISTR, V28, P2689, DOI 10.1109/TPDS.2017.2675891
   Google Cloud Platform, CLOUD FUNCT
   Graepel Thore, 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Kubeless, KUB NAT SERV FRAM
   Maxeler, 2015, N BOD PART SIM
   Microsoft Azure, AZ FUNCT SERV COMP
   Peilun Du, 2019, 2019 IEEE 21st International Conference on High Performance Computing and Communications; IEEE 17th International Conference on Smart City; IEEE 5th International Conference on Data Science and Systems (HPCC/SmartCity/DSS). Proceedings, P534, DOI 10.1109/HPCC/SmartCity/DSS.2019.00084
   SciPy.org, SCIPY OPT
   Vandebon J, 2020, IEEE INT CONF ASAP, P141, DOI 10.1109/ASAP49362.2020.00032
   Vandebon J, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P162, DOI 10.1109/ICFPT47387.2019.00027
   Wen Y, 2014, INT C HIGH PERFORM
   Yasudo R, 2018, 2018 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT 2018), P317, DOI 10.1109/FPT.2018.00062
NR 16
TC 1
Z9 1
U1 1
U2 1
PD DEC
PY 2021
VL 93
IS 12
BP 1419
EP 1431
DI 10.1007/s11265-021-01695-7
EA OCT 2021
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU León, EA
   D'Hooge, T
   Hanford, N
   Karlin, I
   Pankajakshan, R
   Foraker, J
   Chambreau, C
   Leininger, ML
AF Leon, Edgar A.
   D'Hooge, Trent
   Hanford, Nathan
   Karlin, Ian
   Pankajakshan, Ramesh
   Foraker, Jim
   Chambreau, Chris
   Leininger, Matthew L.
GP IEEE
TI TOSS-2020: A Commodity Software Stack for HPC
SO PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE
   COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20)
DT Proceedings Paper
CT International Conference on High Performance Computing, Networking,
   Storage and Analysis (SC)
CY NOV 09-19, 2020
CL ELECTR NETWORK
DE Scientific computing; Accelerator architectures; Parallel architectures;
   Multicore processing; Multiprocessor interconnection networks; Parallel
   machines; Supercomputers; Processor scheduling; Cluster computing; High
   performance computing; Software performance; Software reusability;
   System software; Operating systems; Utility programs; Programming
   environments; Runtime; Runtime environment; Software libraries
AB The simulation environment of any HPC platform is key to the performance, portability, and productivity of scientific applications. This environment has traditionally been provided by platform vendors, presenting challenges for HPC centers and users including platform-specific software that tend to stagnate over the lifetime of the system. In this paper, we present the Tri-Laboratory Operating System Stack (TOSS), a production simulation environment based on Linux and open source software, with proprietary software components integrated as needed. TOSS, focused on mid-to-large scale commodity HPC systems, provides a common simulation environment across system architectures, reduces the learning curve on new systems, and benefits from a lineage of past experience and bug fixes. To further the scope and applicability of TOSS, we demonstrate its feasibility and effectiveness on a leadership-class supercomputer architecture. Our evaluation, relative to the vendor stack, includes an analysis of resource manager complexity, system noise, networking, and application performance.
C1 [Leon, Edgar A.; D'Hooge, Trent; Hanford, Nathan; Karlin, Ian; Pankajakshan, Ramesh; Foraker, Jim; Chambreau, Chris; Leininger, Matthew L.] Lawrence Livermore Natl Lab, Livermore Comp, Livermore, CA 94550 USA.
RP León, EA (corresponding author), Lawrence Livermore Natl Lab, Livermore Comp, Livermore, CA 94550 USA.
EM leon@llnl.gov; dhooge1@llnl.gov; nhanford@llnl.gov; karlin1@llnl.gov;
   pankajakshan1@llnl.gov; foraker1@llnl.gov; chambreau1@llnl.gov;
   leininger4@llnl.gov
CR Agelastos A., 2014, SC 14
   Ahn Dong H., 2014, 2014 43rd International Conference on Parallel Processing Workshops (ICCPW). Proceedings, P9, DOI 10.1109/ICPPW.2014.15
   [Anonymous], 2018, ALGEBRAIC MULTIGRID
   [Anonymous], 2013, CORAL BENCHMARK CODE
   Balaji P, 2009, LECT NOTES COMPUT SC, V5759, P20, DOI 10.1007/978-3-642-03770-2_9
   Beckman P., 2006, CLUSTER 06
   Capit N, 2005, 2005 IEEE INTERNATIONAL SYMPOSIUM ON CLUSTER COMPUTING AND THE GRID, VOLS 1 AND 2, P776
   CORAL: Collaboration of Oak Ridge Argonne and Livermore National Laboratories, 2013, B604142 CORAL RFP AS
   Cray, CRAY LIN ENV
   De P., 2009, IPDPS 09
   De P, 2007, 2007 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING, P331, DOI 10.1109/CLUSTR.2007.4629247
   De Sensi D, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356196
   Doerfler D., 2010, INT J DISTRIBUTED SY, V1
   Exascale Computing Project, ECP PROX APPS SUIT R
   Fermilab, SCI LIN
   Ferreira K. B., 2008, SC 08
   Ferreira K. B., 2010, CLUSTER 10
   Gamblin T, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807623
   Giampapa M., 2010, INT C HIGH PERF COMP
   Groves T, 2017, IEEE INT C CL COMP, P809, DOI 10.1109/CLUSTER.2017.76
   Haring RA, 2012, IEEE MICRO, V32, P48, DOI 10.1109/MM.2011.108
   Hoefler T., 2010, SC 10
   IBM Corporation, 2018, IBM CSM CLUST SYST M
   Jones T., 2003, SC 03
   Jones T, 2011, ROSS 11
   Kato Takeharu, 2019, K COMPUTER, P183, DOI [10.1007/978-981-13-6624-6_11, DOI 10.1007/978-981-13-6624-6_11]
   Kumar S, 2012, INT PARALL DISTRIB P, P763, DOI 10.1109/IPDPS.2012.73
   Lawrence Livermore National Laboratory, TOSS SPEED COMM CLUS
   Lawrence Livermore National Laboratory, PDSH
   Lawrence Livermore National Laboratory, ZFS LIN
   Lawrence Livermore National Laboratory, CONMAN CONS MAN
   Lawrence Livermore National Laboratory, MUNGE MUNGE UID N GI
   Lawrence Livermore National Laboratory, POW
   Leon E. A., 2016, IPDPS 16
   Leon E.A., 2018, GTC 18
   Leon E. A., 2018, MEMSYS 18
   Leon E. A., 2017, MEMSYS 17
   León EA, 2016, SC '16: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, P909, DOI 10.1109/SC.2016.77
   Linux Foundation, 2018, OPENHPC COMM BUILD H
   Mellanox Technologies, LIN INF DRIV
   Morari A., 2011, IPDPS 11
   Panda D., 2019, OSU MICROBENCHMARKS
   Pankajakshan R., 2019, IBM J RES DEV
   Papadopoulou N, 2017, IEEE ACM INT SYMP, P345, DOI 10.1109/CCGRID.2017.149
   Petersson NA, 2015, J COMPUT PHYS, V299, P820, DOI 10.1016/j.jcp.2015.07.023
   Petersson NA, 2014, COMMUN COMPUT PHYS, V16, P913, DOI 10.4208/cicp.290113.220514a
   PETRINI F, 2003, SC 03
   Priedhorsky R, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126925
   Pritchard H., 2012, CUG 12
   Red Hat, RED HAT ENT LIN
   Riesen R, 2009, CONCURR COMP-PRACT E, V21, P793, DOI 10.1002/cpe.1361
   Rosenthal E., 2013, SC 13
   Seagate Technology LLC, LUSTR
   Seelam S., 2010, IPDPS 10
   Sjögreen B, 2012, J SCI COMPUT, V52, P17, DOI 10.1007/s10915-011-9531-1
   SUSE Group, SUSE LIN ENT SERV
   SyLabs.io, SINGULARITY
   Tabe T. B., 1995, Computing Science and Statistics. Vol.27. Proceedings of the 27th Symposium on the Interface. Statistics and Manufacturing with Subthemes in Environmental Statistics, Graphics and Imaging, P347
   Yoo AB, 2003, LECT NOTES COMPUT SC, V2862, P44
   Zimmer C., 2019, SC 19
   TORQUE RESOURCE MANA
NR 61
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1109/SC41405.2020.00044
WC Computer Science, Information Systems; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Elbtity, ME
   Chandarana, PS
   Reidy, B
   Eshraghian, JK
   Zand, R
AF Elbtity, Mohammed E.
   Chandarana, Peyton S.
   Reidy, Brendan
   Eshraghian, Jason K.
   Zand, Ramtin
TI APTPU: Approximate Computing Based Tensor Processing Unit
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE Approximate computing; tensor processing units; machine learning
   hardware accelerator; systolic array
ID POWER
AB We propose an approximate tensor processing unit (APTPU), which includes two main components: (1) approximate processing elements (APEs) consisting of a low-precision multiplier and an approximate adder, and (2) pre-approximate units (PAUs) which are shared among the APEs in the APTPU's systolic array, functioning as the steering logic to pre-process the operands and feed them to the APEs. We conduct extensive experiments to evaluate the performance of the APTPU across various configurations and various workloads. The results show that the APTPU's systolic array achieves up to 5.2 x TOPSmm(2) and 4.4 x TOPS/W improvements compared to that of a conventional systolic array design. The comparison between the proposed APTPU and in-house TPU designs shows that we can achieve approximately 2.5 x and 1.2 x area and power reduction, respectively, while realizing comparable accuracy. Finally, a comparison with the state-of-the-art approximate systolic arrays shows that the APTPU can realize up to 1.58x , 2x , and 1.78x , reduction in delay, power, and area, respectively, while using similar design specifications and synthesis constraints.
C1 [Elbtity, Mohammed E.; Chandarana, Peyton S.; Reidy, Brendan; Zand, Ramtin] Univ South Carolina, Dept Comp Sci & Comp Engn, Columbia, SC 29201 USA.
   [Eshraghian, Jason K.] Univ Calif Santa Cruz, Dept Elect & Comp Engn, Santa Cruz, CA 95064 USA.
RP Elbtity, ME (corresponding author), Univ South Carolina, Dept Comp Sci & Comp Engn, Columbia, SC 29201 USA.
EM elbtity@ieee.org
CR Adarsh P, 2020, INT CONF ADVAN COMPU, P687, DOI [10.1109/ICACCS48705.2020.9074315, 10.1109/icaccs48705.2020.9074315]
   Amudha M., 2012, INT J ELECT COMPUT S, V1, P522
   [Anonymous], 2017, ARXIV, Patent No. 171009829Cs
   [Anonymous], 2020, ARXIV
   Ansari MS, 2021, IEEE T COMPUT, V70, P614, DOI 10.1109/TC.2020.2992113
   Balasubramanian P, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8111212
   Bhardwaj K, 2015, INT SYM QUAL ELECT, P263
   Boro B, 2020, MICROELECTRON J, V101, DOI 10.1016/j.mejo.2020.104816
   Chen K, 2015, IEEE INT SYMP NANO, P151, DOI 10.1109/NANOARCH.2015.7180604
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cohen G, 2017, IEEE IJCNN, P2921, DOI 10.1109/IJCNN.2017.7966217
   Dalloo A, 2018, IEEE T VLSI SYST, V26, P1595, DOI 10.1109/TVLSI.2018.2822278
   Elbtity ME, 2020, INT SOC DESIGN CONF, P71, DOI 10.1109/ISOCC50952.2020.9333013
   Guo SS, 2019, PR GR LAK SYMP VLSI, P63, DOI 10.1145/3299874.3317966
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hashemi S, 2015, ICCAD-IEEE ACM INT, P418, DOI 10.1109/ICCAD.2015.7372600
   Jiang HL, 2020, P IEEE, V108, P2108, DOI 10.1109/JPROC.2020.3006451
   Jing Shen, 2019, 2019 IEEE 19th International Conference on Communication Technology (ICCT), P1200, DOI 10.1109/ICCT46805.2019.8947127
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kumar Vinay, 2019, Proceedings of 2nd International Conference on Communication, Computing and Networking. ICCCN 2018. Lecture Notes in Networks and Systems (LNNS 46), P607, DOI 10.1007/978-981-13-1217-5_59
   Lahari P. L., 2020, 2020 4th International Conference on Trends in Electronics and Informatics (ICOEI). Proceedings, P1039, DOI 10.1109/ICOEI48184.2020.9142930
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee Jaeheum, 2021, J Nanosci Nanotechnol, V21, P1854, DOI 10.1166/jnn.2021.18925
   Liang TL, 2021, NEUROCOMPUTING, V461, P370, DOI 10.1016/j.neucom.2021.07.045
   Lim H, 2000, IEEE T COMPUT, V49, P1297, DOI 10.1109/12.895848
   Lin IC, 2015, IEEE T VLSI SYST, V23, P1591, DOI 10.1109/TVLSI.2014.2355217
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Liu WQ, 2017, IEEE T COMPUT, V66, P1435, DOI 10.1109/TC.2017.2672976
   Mitchell J. N., 1962, IRE T ELECT COMPUT, VEC-11, P512, DOI DOI 10.1109/TEC.1962.5219391
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mo H., 2019, PROC 56 ACMIEEE DESI, P1
   Nam BG, 2008, IEEE T COMPUT, V57, P490, DOI 10.1109/TC.2008.12
   Nayar R, 2020, IEEE COMP SOC ANN, P84, DOI 10.1109/ISVLSI49217.2020.00025
   Qin E, 2020, INT S HIGH PERF COMP, P58, DOI 10.1109/HPCA47549.2020.00015
   Samajdar Ananda, 2018, ARXIV
   Sullivan MB, 2012, CONF REC ASILOMAR C, P355, DOI 10.1109/ACSSC.2012.6489023
   Venkataramani Swagath, 2013, 2013 46th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). Proceedings, P1, DOI 10.1145/2540708.2540710
   Wang JP, 2011, IEEE T VLSI SYST, V19, P52, DOI 10.1109/TVLSI.2009.2032289
   Waris H, 2021, J SIGNAL PROCESS SYS, V93, P605, DOI 10.1007/s11265-020-01582-7
   Waris H, 2019, IEEE WRK SIG PRO SYS, P13, DOI [10.1109/sips47522.2019.9020404, 10.1109/SiPS47522.2019.9020404]
   Xiao H, 2017, ARXIV PREPRINT ARXIV
   Xu XW, 2018, PROC CVPR IEEE, P8300, DOI 10.1109/CVPR.2018.00866
   Yin PP, 2021, IEEE T SUST COMPUT, V6, P612, DOI 10.1109/TSUSC.2020.3004980
   Younes H, 2019, IEEE I C ELECT CIRC, P113, DOI [10.1109/icecs46596.2019.8964974, 10.1109/ICECS46596.2019.8964974]
   Zhou  A., 2017, ARXIV170203044
NR 46
TC 3
Z9 3
U1 1
U2 5
PD DEC
PY 2022
VL 69
IS 12
BP 5135
EP 5146
DI 10.1109/TCSI.2022.3206262
EA SEP 2022
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Sunkavilli, S
   Zhang, ZM
   Yu, QY
AF Sunkavilli, Sandeep
   Zhang, Zhiming
   Yu, Qiaoyan
GP IEEE Comp Soc
TI New Security Threats on FPGAs: From FPGA Design Tools Perspective
SO 2021 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI 2021)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 20th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 07-09, 2017-2021
CL ELECTR NETWORK
DE FPGA security; hardware security; covert channel; hardware Trojan;
   multi-tenant FPGA; cloud computing
AB The growing market share of FPGAs motivates the increasing number of attackers to tamper with FPGA systems. The majority of existing research efforts on FPGA security focus on counterfeiting devices, hardware Trojans, reverse engineering hardware designs via decomposing or decrypting bitstream files, and side-channel analysis attacks. Those attacks are typically limited to the FPGA systems implemented in standalone FPGA devices. As more cloud-based FPGA providers, third-party accelerator suppliers, and open-source FPGA design tools are available for prototyping, hardware acceleration, and high-performance computing, new FPGA utilization models are gradually formed. The increasing number of entities involved in the new FPGA use model leads to the emergence of new security threats and attack surfaces. Although the security issues on FPGA systems design and piracy have been widely investigated, there is limited investigation available disclosing the security threats from the FPGA design tools perspective. This work conducts a comprehensive survey on the FPGA tool security and proposes a thorough security threat landscape for the new FPGA utilization model in the era of machine learning and cloud computing.
C1 [Sunkavilli, Sandeep; Zhang, Zhiming; Yu, Qiaoyan] Univ New Hampshire, Dept Elect & Comp Engn, Durham, NH 03824 USA.
RP Sunkavilli, S (corresponding author), Univ New Hampshire, Dept Elect & Comp Engn, Durham, NH 03824 USA.
CR Alam Md Mahbub, 2019, 2019 Workshop on Fault Diagnosis and Tolerance in Cryptography (FDTC). Proceedings, P48, DOI 10.1109/FDTC.2019.00015
   [Anonymous], 2015, ISO IEC, P1, DOI [DOI 10.1016/B978-0-7020-2920-2.50020-0, DOI 10.1109/IEEESTD.2015.7118618, DOI 10.1109/IEEESTD.2015.7106435]
   [Anonymous], 2018, IACR T CRYPTOGRAPHIC
   Benhani EM, 2019, IEEE T COMPUT, V68, P1238, DOI 10.1109/TC.2019.2900235
   Chakraborty RS, 2013, IEEE DES TEST, V30, P45, DOI 10.1109/MDT.2013.2247460
   Chhotaray A., 2017, P CCS 17, P1533
   Dogan H, 2014, INT SYM DEFEC FAU TO, P171, DOI 10.1109/DFT.2014.6962099
   Giechaskil I, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3322483
   Gundabolu S, 2018, IEEE COMP SOC ANN, P644, DOI 10.1109/ISVLSI.2018.00122
   Hoque T, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3361147
   Intel, 2019, AN 556 US DES SEC F, V11
   Jin C., 2020, ARXIV PREPRINT ARXIV
   Krautter J, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3328222
   Krieg C, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967054
   Luo YK, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P331, DOI 10.1109/ICFPT47387.2019.00060
   Mal-Sarkar S, 2014, PR GR LAK SYMP VLSI, P287, DOI 10.1145/2591513.2591520
   Moradi A, 2016, LECT NOTES COMPUT SC, V9689, P71, DOI 10.1007/978-3-319-43283-0_5
   Murray KE, 2020, ACM T RECONFIG TECHN, V13, DOI 10.1145/3388617
   Murray KE, 2020, IEEE MICRO, V40, P49, DOI 10.1109/MM.2020.2998435
   Narula S, 2015, INT C ADV COMPUT COM, P501, DOI 10.1109/ACCT.2015.20
   Olney B, 2020, ACM T DES AUTOMAT EL, V25, DOI 10.1145/3373638
   Pham KD, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2018), P36, DOI 10.1109/MCSoC2018.2018.00018
   Pitaka S., 2020, XILINX XAPP1222
   Provelengios G, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P292, DOI 10.1145/3289602.3293923
   Schellenberg F, 2018, DES AUT TEST EUROPE, P1111, DOI 10.23919/DATE.2018.8342177
   Seifoori Z, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P197, DOI 10.1145/3373087.3375319
   Sunkavilli S, 2021, INT SYM QUAL ELECT, P504, DOI 10.1109/ISQED51717.2021.9424291
   Thoonen M., 2019, THESIS U TWENTE
   Tian SQ, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P298, DOI 10.1145/3289602.3293920
   Trimberger SM, 2014, P IEEE, V102, P1248, DOI 10.1109/JPROC.2014.2331672
   Turan F., 2020, CSUR, V53, P1
   Wei LX, 2018, 34TH ANNUAL COMPUTER SECURITY APPLICATIONS CONFERENCE (ACSAC 2018), P393, DOI 10.1145/3274694.3274696
   Xilinx, US ENCR SEC 7 SER FP, V2, P2021
   Zhang JL, 2019, ACM T RECONFIG TECHN, V12, DOI 10.1145/3340557
   Zhang T, 2019, IEEE ACCESS, V7, P38379, DOI 10.1109/ACCESS.2019.2901949
   Zhang ZM, 2019, IEEE T VLSI SYST, V27, P665, DOI 10.1109/TVLSI.2018.2879878
NR 36
TC 5
Z9 5
U1 5
U2 31
PY 2021
BP 278
EP 283
DI 10.1109/ISVLSI51109.2021.00058
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Sankaralingam, K
   Nowatzki, T
   Gangadhar, V
   Shah, P
   Davies, M
   Galliher, W
   Guo, ZL
   Khare, J
   Vijay, D
   Palamuttam, P
   Punde, M
   Tan, A
   Thiruvengadam, V
   Wang, RY
   Xu, SM
AF Sankaralingam, Karthikeyan
   Nowatzki, Tony
   Gangadhar, Vinay
   Shah, Preyas
   Davies, Michael
   Galliher, William
   Guo, Ziliang
   Khare, Jitu
   Vijay, Deepak
   Palamuttam, Poly
   Punde, Maghawan
   Tan, Alex
   Thiruvengadam, Vijay
   Wang, Rongyi
   Xu, Shunmiao
GP ACM
TI The Mozart Reuse Exposed Dataflow Processor for AI and Beyond
SO PROCEEDINGS OF THE 2022 THE 49TH ANNUAL INTERNATIONAL SYMPOSIUM ON
   COMPUTER ARCHITECTURE (ISCA '22)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 49th IEEE/ACM Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2022
CL New York, NY
DE dataflow; reuse; accelerator; multicasting; chips; machine learning
ID FLEXIBILITY; COMPILER
AB In this paper we introduce the Mozart Processor, which implements a new processing paradigm called Reuse Exposed Dataflow (RED). RED is a counterpart to existing execution models of Von-Neumann, SIMT, Dataflow, and FPGA. Dataflow and data reuse are the fundamental architecture primitives in RED, implemented with mechanisms for inter-worker communication and synchronization. The paper defines the processor architecture, the details of the microarchitecture, chip implementation, software stack development, and performance results. The architecture's goal is to achieve near-CPU like flexibility while having ASIC-like efficiency for a large-class of data-intensive workloads. An additional goal was software maturity - have large coverage of applications immediately, avoiding the need for a long-drawn hand-tuning software development phase. The architecture was defined with this software-maturity/compiler friendliness in mind. In short, the goal was to do to GPUs, what GPUs did to CPUs - i.e. be a better solution for a large range of workloads, while preserving flexibility and programmability. The chip was implemented with HBM and PCIe interfaces and taken to production on a 16nm TSMC FFC process. For ML inference tasks with batch-size=4, Mozart is integer factors better than state-of-the-art GPUs even while being nearly 2 technology nodes behind. We conclude with a set of lessons learned, the unique challenges of a clean-slate architecture in a commercial setting, and pointers for uncovered research problems.
C1 [Sankaralingam, Karthikeyan; Nowatzki, Tony; Gangadhar, Vinay; Shah, Preyas; Davies, Michael; Galliher, William; Guo, Ziliang; Khare, Jitu; Vijay, Deepak; Palamuttam, Poly; Punde, Maghawan; Tan, Alex; Thiruvengadam, Vijay; Wang, Rongyi; Xu, Shunmiao] SimpleMachines Inc, San Jose, CA 95134 USA.
   [Nowatzki, Tony] UCLA, Los Angeles, CA USA.
RP Sankaralingam, K (corresponding author), SimpleMachines Inc, San Jose, CA 95134 USA.
CR Abts D, 2020, ANN I S COM, P145, DOI 10.1109/ISCA45697.2020.00023
   Asanovic K., 2016, ROCKET CHIP GENERATO
   Balasubramonian R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3085572
   Bhaskaracharya S.G., 2020, ARXIV
   Cao Y, 2022, J COMPUT ASSIST LEAR, V38, P845, DOI 10.1111/jcal.12652
   Chen TQ, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P785, DOI 10.1145/2939672.2939785
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Cho Sung-Gun, 2021, 2021 S VLSI CIRCUITS, P1, DOI [10.23919/VLSICircuits52068.2021.9492517, DOI 10.23919/VLSICIRCUITS52068.2021.9492517]
   Clark Don, 2017, NEW YORK TIMES
   Cook H, 2017, 1 WORKSHOP COMPUTER
   CYTRON R, 1991, ACM T PROGR LANG SYS, V13, P451, DOI 10.1145/115372.115320
   Dadu V, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P1, DOI 10.1145/3503222.3507706
   Dadu V, 2021, CONF PROC INT SYMP C, P595, DOI 10.1109/ISCA52012.2021.00053
   Dadu V, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P924, DOI 10.1145/3352460.3358276
   Darvish Rouhani B., 2020, ADV NEURAL INFORM PR, V33, P10271
   Dave S, 2021, P IEEE, V109, P1706, DOI 10.1109/JPROC.2021.3098483
   DFI Group, 2021, DFI SPEC
   Domke Jens, 2021, IEEE INT PARALLEL DI
   Dong Junfeng, 2019, ACCELERATING COMPUTE
   Ehsan Ardestani K., 2021, ARXIV
   Georganas Evangelos, 2018, SC18: International Conference for High Performance Computing, Networking, Storage and Analysis. Proceedings, P830, DOI 10.1109/SC.2018.00069
   Han RC, 2019, INT SYM PERFORM ANAL, P22, DOI 10.1109/ISPASS.2019.00011
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He YZ, 2019, INT CONF ACOUST SPEE, P6381, DOI 10.1109/ICASSP.2019.8682336
   Hooker S, 2021, COMMUN ACM, V64, P58
   Hower DR, 2014, ACM SIGPLAN NOTICES, V49, P427, DOI 10.1145/2541940.2541981
   Huang QJ, 2021, CONF PROC INT SYMP C, P554, DOI 10.1109/ISCA52012.2021.00050
   Intel, 2022, INT 64 IA 32 ARCH OP
   Johnson J, 2018, Arxiv, DOI arXiv:1811.01721
   Jouppi NP, 2021, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA52012.2021.00010
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Kal H, 2021, CONF PROC INT SYMP C, P679, DOI 10.1109/ISCA52012.2021.00059
   Lee Y, 2016, IEEE MICRO, V36, P8, DOI 10.1109/MM.2016.11
   Li MZ, 2021, IEEE T PARALL DISTR, V32, P708, DOI 10.1109/TPDS.2020.3030548
   Liu SL, 2016, CONF PROC INT SYMP C, P393, DOI 10.1109/ISCA.2016.42
   Mittal S, 2022, IEEE T NEUR NET LEAR, V33, P5095, DOI 10.1109/TNNLS.2021.3071762
   Nowatzki T, 2018, 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION TECHNIQUES (PACT 2018), DOI 10.1145/3243176.3243212
   Nowatzki T, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P416, DOI [10.1145/3079856.3080255, 10.1145/3140659.3080255]
   Nowatzki T, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P298, DOI 10.1145/2749469.2750380
   Nowatzki Tony, 2013, P 34 INT C PROGRAMMI
   NVIDIA, 2021, CUTLASS 2 8
   Pradeep Vijay, 2017, ETHEREUM MEMORY HARD
   Qadeer W, 2015, COMMUN ACM, V58, P85, DOI 10.1145/2735841
   Ragan-Kelley J, 2013, ACM SIGPLAN NOTICES, V48, P519, DOI 10.1145/2499370.2462176
   Reuther A, 2020, IEEE HIGH PERF EXTR, DOI 10.1109/hpec43674.2020.9286149
   Ries E., 2011, LEAN STARTUP TODAYS, DOI DOI 10.1111/J.1540-5885.2012.00920_2.X
   Sankaralingam Karthikeyan, 2021, SYSTEMS METHODS STRE
   Sankaralingam Karthikeyan, 2021, METHOD COMPUTER PROG
   Sankaralingam Karthikeyan, 2020, ACCELERATING PARALLE
   Shallue CJ, 2019, J MACH LEARN RES, V20
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   TESLA, 2021, TESL DOJ TECHN GUID
   Vaswani A, 2017, ADV NEUR IN, V30
   Vijayaraghavan T, 2018, IEEE COMPUT ARCHIT L, V17, P179, DOI 10.1109/LCA.2018.2849064
   Wang ZR, 2021, INT S HIGH PERF COMP, P640, DOI 10.1109/HPCA51647.2021.00060
   Wang ZR, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P736, DOI 10.1145/3307650.3322229
   Weng J, 2020, INT S HIGH PERF COMP, P703, DOI 10.1109/HPCA47549.2020.00063
   Wheeler Bob, 2021, SAMBANOVA TAKES NVID
   Zhaoying Li, 2022, 2022 IEEE INT S HIGH
NR 61
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 978
EP 992
DI 10.1145/3470496.3533040
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Chen, YR
   Wang, TF
   Chen, SH
   Kao, YC
AF Chen, Yean Ru
   Wang, Tzu Fan
   Chen, Si-Han
   Kao, Yi-Chun
TI Empirical study on security verification and assessment of neural
   network accelerator
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE Neural network; Formal verification; Hardware Trojan; Risk assessment;
   Trojan detection
AB With the significant success of machine learning, there are plenty of innovative neural network designs nowadays. The related applications become more and more pervasive in our daily life, even in life-critical domains such as autopilot and medical diagnosis, etc. In these domains, whether the AI-based system is "secure"or not is a critical issue. In this work, we first present six Hardware Trojan attacks with demonstrations of their impacts on the hardware design of neural networks. When data leakage occurs, we encode the leakage data to the output and make it more difficult to be detected. Most of our attacks can either achieve more than 98% attack success rate or leak out confidential data without causing any functional violation, with less than 1.5% overhead. We also discuss how to effectively and efficiently detect these Hardware Trojans with formal verification methods and further propose a risk assessment process to constitute a priority guidance to suggest security verification tasks of neuron network hardware. Based on our results, we strongly suggest that security specification and total verification are essential to neuron network designs.
C1 [Chen, Yean Ru; Wang, Tzu Fan; Chen, Si-Han; Kao, Yi-Chun] Natl Cheng Kung Univ, 1 Univ Rd, Tainan 70101, Taiwan.
RP Chen, YR (corresponding author), Natl Cheng Kung Univ, 1 Univ Rd, Tainan 70101, Taiwan.
EM chenyr@mail.ncku.edu.tw
CR Abbink David A., 2022, Road Vehicle Automation 8. Lecture Notes in Mobility, P60, DOI 10.1007/978-3-030-80063-5_6
   [Anonymous], 2006, 2006 IEEE INT TEST C, DOI DOI 10.1109/TEST.2006.297720
   Baier C, 2008, PRINCIPLES OF MODEL CHECKING, P1
   Berezin S, 1998, LECT NOTES COMPUT SC, V1536, P81, DOI 10.1007/3-540-49213-5_4
   Cadence Design Systems Inc., JASPERGOLD FORM VER
   Chakraborty RS, 2009, INT HIGH LEVEL DESIG, P166, DOI 10.1109/HLDVT.2009.5340158
   Clements J, 2018, Arxiv, DOI arXiv:1806.05768
   Clements J, 2019, IEEE INT SYMP CIRC S
   Corin Ricardo, 2012, Information and Communication Security. 14th International Conference (ICICS 2012). Proceedings, P264, DOI 10.1007/978-3-642-34129-8_23
   Cruz J, 2018, I CONF VLSI DESIGN, P91, DOI 10.1109/VLSID.2018.43
   DeepMind I., ALPHAGO PROJ
   Fagot C., 1999, European Test Workshop 1999 (Cat. No.PR00390), P7, DOI 10.1109/ETW.1999.803819
   Gehr T, 2018, P IEEE S SECUR PRIV, P3, DOI 10.1109/SP.2018.00058
   Hetherington G., 1999, International Test Conference 1999. Proceedings (IEEE Cat. No.99CH37034), P358, DOI 10.1109/TEST.1999.805650
   Hoque T, 2018, INT TEST CONF P
   Hu X, 2021, IEEE T COMPUT AID D, V40, P1230, DOI 10.1109/TCAD.2020.2995347
   Jacob N, 2014, IET COMPUT DIGIT TEC, V8, P264, DOI 10.1049/iet-cdt.2014.0039
   Jin Y, 2009, 2009 IEEE INTERNATIONAL WORKSHOP ON HARDWARE-ORIENTED SECURITY AND TRUST, P50, DOI 10.1109/HST.2009.5224971
   Kuo MH, 2019, 2019 IEEE INTERNATIONAL TEST CONFERENCE IN ASIA (ITC-ASIA 2019), P43, DOI 10.1109/ITC-Asia.2019.00021
   LeCun Y., MNIST DATABASE HANDW
   Li H., 2016, 5 INT C LEARNING REP, P1
   Li WS, 2018, IEEE COMP SOC ANN, P482, DOI 10.1109/ISVLSI.2018.00093
   Liu ZZ, 2020, IEEE VLSI TEST SYMP, DOI 10.1109/vts48691.2020.9107582
   Madry A, 2019, Arxiv, DOI [arXiv:1706.06083, DOI 10.48550/ARXIV.1706.06083]
   Nahiyan A, 2017, INT TEST CONF P
   Pierce J, 2019, CHI 2019: PROCEEDINGS OF THE 2019 CHI CONFERENCE ON HUMAN FACTORS IN COMPUTING SYSTEMS, DOI 10.1145/3290605.3300275
   Piscitelli R., 2015, P INT C DES TECHN IN, P1, DOI DOI 10.1109/DTIS.2015.7127352
   Rajendran J, 2016, I CONF VLSI DESIGN, P547, DOI 10.1109/VLSID.2016.143
   Rajendran J, 2015, DES AUT CON, DOI 10.1145/2744769.2744823
   Salmani H, 2017, IEEE T INF FOREN SEC, V12, P338, DOI 10.1109/TIFS.2016.2613842
   Tehranipoor M, 2010, IEEE DES TEST COMPUT, V27, P10, DOI 10.1109/MDT.2010.7
   Yasaei R., 2022, HARDWARE TROJAN DETE
   Yasaei R, 2021, PROCEEDINGS OF THE 2021 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION (DATE 2021), P1504, DOI 10.23919/DATE51398.2021.9474174
   Ye J, 2018, ASIAN TEST SYMPOSIUM, P68, DOI 10.1109/ATS.2018.00024
   Yean-Ru Chen, 2014, 2014 International Conference on Trustworthy Systems and their Applications, P22, DOI 10.1109/TSA.2014.13
   Yin J, 2019, BIOMED CIRC SYST C, DOI 10.1109/biocas.2019.8919127
   Yu XY, 2019, IEEE T NEUR NET LEAR, V30, P2805, DOI 10.1109/TNNLS.2018.2886017
   Zhang BY, 2019, IEEE T CIRCUITS-II, V66, P2052, DOI 10.1109/TCSII.2019.2899829
   Zhang JL, 2020, IEEE T NEUR NET LEAR, V31, P2578, DOI 10.1109/TNNLS.2019.2933524
   Zhao Y, 2019, DES AUT TEST EUROPE, P1415, DOI [10.23919/date.2019.8715027, 10.23919/DATE.2019.8715027]
NR 40
TC 0
Z9 0
U1 0
U2 0
PD JUN
PY 2023
VL 99
AR 104845
DI 10.1016/j.micpro.2023.104845
EA MAY 2023
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Zaruba, F
   Schuiki, F
   Mach, S
   Benini, L
AF Zaruba, Florian
   Schuiki, Fabian
   Mach, Stefan
   Benini, Luca
GP IEEE
TI The Floating Point Trinity: A Multi-modal Approach to Extreme
   Energy-Efficiency and Performance
SO 2019 26TH IEEE INTERNATIONAL CONFERENCE ON ELECTRONICS, CIRCUITS AND
   SYSTEMS (ICECS)
SE IEEE International Conference on Electronics Circuits and Systems
DT Proceedings Paper
CT 26th IEEE International Conference on Electronics, Circuits and Systems
   (ICECS)
CY NOV 27-29, 2019
CL Genoa, ITALY
AB The demand for floating-point compute power is ever growing. The domains of big-data, machine learning, and scientific computing require a wide precision range and high operational intensity. The sheer number of operations paired with increased power density implied by technology scaling makes it more important than ever to achieve maximum energy-efficiency for floating point operations. In this work, we present Kosmodrom, our novel silicon solution in Globalfoundries 22 nm Fully-Depleted Silicon on Insulator (FD-SOI) which offers a multi-dimensional approach to trade-off performance, energy-efficiency and power consumption. A variable-precision, dual-core RISC-V system together with a specialized floating point accelerator form the architectural basis. Different implementation strategies and standard cell flavors provide optimal solutions for different operating conditions while supply voltage and forward body bias (FBB) enable for a dynamic trade-off during operation. In this work, we provide a unique insight into the impact of a multitude of tuning parameters to achieve the optimal operating point on the power-performance surface. Kosmodrom achieves a peak energy-efficiency of 260Gflop/s/W and up to 28Gflop/s peak performance within a 6.2-400mW power envelope.
C1 [Zaruba, Florian; Schuiki, Fabian; Mach, Stefan; Benini, Luca] Swiss Fed Inst Technol, Integrated Syst Lab IIS, Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Dept Elect Elect & Informat Engn DEI, Bologna, Italy.
RP Zaruba, F (corresponding author), Swiss Fed Inst Technol, Integrated Syst Lab IIS, Zurich, Switzerland.
EM zarubaf@iis.ee.ethz.ch; fschuiki@iis.ee.ethz.ch; smach@iis.ee.ethz.ch;
   lbenini@iis.ee.ethz.ch
CR Abadi M., 2016, P OSDI 16 12 USENIX, V16, P265, DOI DOI 10.1038/NN.3331
   Dongarra JJ, 1997, SUPERCOMPUTER, V13, P89
   Feng WC, 2007, COMPUTER, V40, P50, DOI 10.1109/MC.2007.445
   Hall C., 2018, KEEPING COOL CUTTING
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kogge P., 2008, TECH REP, P15
   Mach S., 2019, 080 PJ FLOP 1 24 TFL
   Malossi ACI, 2018, DES AUT TEST EUROPE, P1105, DOI 10.23919/DATE.2018.8342176
   Markidis S, 2018, IEEE SYM PARA DISTR, P522, DOI 10.1109/IPDPSW.2018.00091
   Reed DA, 2015, COMMUN ACM, V58, P56, DOI 10.1145/2699414
   Schuiki F, 2019, IEEE T COMPUT, V68, P484, DOI 10.1109/TC.2018.2876312
   Shibahara S, 2017, IEEE J SOLID-ST CIRC, V52, P77, DOI 10.1109/JSSC.2016.2623682
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Youn Kyu Lee, 2014, 2014 21st Asia-Pacific Software Engineering Conference (APSEC), P199, DOI 10.1109/APSEC.2014.39
   Zaruba F., 2019, IEEE T VERY LARGE SC, P1
NR 15
TC 4
Z9 4
U1 0
U2 5
PY 2019
BP 767
EP 770
DI 10.1109/icecs46596.2019.8964820
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ali, MS
   Bin Iqbal, MT
   Lee, KH
   Muqeet, A
   Lee, SH
   Kim, L
   Bae, SH
AF Ali, Muhammad Salman
   Iqbal, Md Tauhid Bin
   Lee, Kang-Ho
   Muqeet, Abdul
   Lee, Seunghyun
   Kim, Lokwon
   Bae, Sung-Ho
TI ERDNN: Error-Resilient Deep Neural Networks With a New Error Correction
   Layer and Piece-Wise Rectified Linear Unit
SO IEEE ACCESS
DT Article
DE Hardware; Error correction; Convolution; Machine learning; Computational
   complexity; Neural networks; Standards; Deep learning; soft error;
   reliability; error correction layer; piece-wise ReLU; PwReLU; bit error
   rate
ID CLASSIFICATION
AB Deep Learning techniques have been successfully used to solve a wide range of computer vision problems. Due to their high computation complexity, specialized hardware accelerators are being proposed to achieve high performance and efficiency for deep learning-based algorithms. However, soft errors, i.e., bit flipping errors in the layer output, are often caused due to process variation and high energy particles in these hardware systems. These can significantly reduce model accuracy. To remedy this problem, we propose new algorithms that effectively reduce the impact of errors, thus keeping high accuracy. We firstly propose to incorporate an Error Correction Layer (ECL) into neural networks where convolution is performed multiple times in each layer and majority reporting is conducted for the outputs at bit level. We found that ECL can eliminate most errors while bypassing the bit-error when the bits at the same position are corrupted multiple times under the simulated condition. In order to solve this problem, we analyze the impact of errors depending on the position of bits, thus observing that errors in most significant bit (MSB) positions tend to severely corrupt the output of the network compared to the errors in the least significant bit (LSB) positions. According to this observation, we propose a new specialized activation function, called Piece-wise Rectified Linear Unit (PwReLU), which selectively suppresses errors depending on the bit positions, resulting in an increased model resistance against the errors. Compared to existing activation functions, the proposed PwReLU outperforms with large accuracy margins of up-to 20% even with very high bit error rates (BERs). Our extensive experiments show that the proposed ECL and PwReLU work in a complementary manner, achieving comparable accuracy to the error-free networks even at a severe BER of 0.1% on CIFAR10, CIFAR100, and ImageNet.
C1 [Ali, Muhammad Salman; Iqbal, Md Tauhid Bin; Lee, Kang-Ho; Muqeet, Abdul; Kim, Lokwon; Bae, Sung-Ho] Kyung Hee Univ, Dept Comp Sci & Engn, Yongin 17104, South Korea.
   [Lee, Seunghyun] Kyung Hee Univ, Dept Elect Engn, Yongin 17104, South Korea.
RP Bae, SH (corresponding author), Kyung Hee Univ, Dept Comp Sci & Engn, Yongin 17104, South Korea.
EM shbae@khu.ac.kr
CR [Anonymous], 2014, THE CIFAR 10 DATASET
   [Anonymous], 2010, TECH REP
   [Anonymous], 2018, IEEE T NEUR NET LEAR, DOI DOI 10.1109/TNNLS.2018.2815085
   Barron J.T., 2017, ARXIV170407483
   BENGIO Y, 1994, IEEE T NEURAL NETWOR, V5, P157, DOI 10.1109/72.279181
   Boski M, 2017, 2017 10TH INTERNATIONAL WORKSHOP ON MULTIDIMENSIONAL (ND) SYSTEMS (NDS)
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chen Z, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON RADIO-FREQUENCY INTEGRATION TECHNOLOGY (RFIT2019), DOI 10.1109/rfit.2019.8929159
   Choi Y, 2018, IEEE T INTELL TRANSP, V19, P934, DOI 10.1109/TITS.2018.2791533
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CLEVERT D.-A., 2015, P 4 INT C LEARNING R
   Czerny B. J., 2002, ORIGINS, V9, P2003
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Feinberg B, 2018, INT S HIGH PERF COMP, P52, DOI 10.1109/HPCA.2018.00015
   Glorot X., 2010, P 13 INT C ARTIFICIA, V13, P249, DOI DOI 10.1.1/207.2059
   Guan H., 2019, NIPS, P5735
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hareland S, 2001, 2001 SYMPOSIUM ON VLSI TECHNOLOGY, DIGEST OF TECHNICAL PAPERS, P73, DOI 10.1109/VLSIT.2001.934953
   Hasan R, 2017, IEEE IJCNN, P3527, DOI 10.1109/IJCNN.2017.7966300
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Hubara I, 2018, J MACH LEARN RES, V18
   Ishizaka M, 2018, ASIAN TEST SYMPOSIUM, P167, DOI 10.1109/ATS.2018.00040
   Jin XJ, 2016, AAAI CONF ARTIF INTE, P1737
   Kim JS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317805
   Kim LW, 2018, IEEE T NEUR NET LEAR, V29, P1441, DOI 10.1109/TNNLS.2017.2665555
   Kong SM, 2017, IEEE IJCNN, P2562, DOI 10.1109/IJCNN.2017.7966168
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2010, CONVOLUTIONAL DEEP B, V40, P1, DOI DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA, DOI DOI 10.1145/3233231
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Maas A. L., 2013, PROC ICML WORKSHOP D, P3
   Nicolae A., 2018, ARXIV180909534
   Park J, 1991, NEURAL COMPUT, V3, P246, DOI 10.1162/neco.1991.3.2.246
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schorn C, 2019, DES AUT TEST EUROPE, P1507, DOI [10.23919/date.2019.8714885, 10.23919/DATE.2019.8714885]
   Schorn C, 2018, LECT NOTES COMPUT SC, V11093, P205, DOI 10.1007/978-3-319-99130-6_14
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sun J.(, 2015, IEEE I CONF COMP VIS, P1026, DOI DOI 10.1109/ICCV.2015.123
   Sun XH, 2019, IEEE ELECTR DEVICE L, V40, P1080, DOI 10.1109/LED.2019.2917944
   Tithi JJ, 2014, INT SYM PERFORM ANAL, P23, DOI 10.1109/ISPASS.2014.6844458
   Wang JF, 2016, WATER-SUI, V8, DOI 10.3390/w8010011
   WERBOS PJ, 1990, P IEEE, V78, P1550, DOI 10.1109/5.58337
   Xu B., 2015, ARXIV PREPRINT ARXIV, V1505, P853
   Zhang X, 2018, PROC CVPR IEEE, P6848, DOI 10.1109/CVPR.2018.00716
   Zhang ZY, 2019, INNOV SMART GRID TEC, DOI 10.1109/isgt.2019.8791651
NR 52
TC 1
Z9 1
U1 0
U2 4
PY 2020
VL 8
BP 158702
EP 158711
DI 10.1109/ACCESS.2020.3017211
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Crafton, B
   Spetalnick, S
   Murali, G
   Krishna, T
   Lim, SK
   Raychowdhury, A
AF Crafton, Brian
   Spetalnick, Samuel
   Murali, Gauthaman
   Krishna, Tushar
   Lim, Sung-Kyu
   Raychowdhury, Arijit
BE Calimera, A
   Gaillardon, PE
   Korgaonkar, K
   Kvatinsky, S
   Reis, R
TI Statistical Array Allocation and Partitioning for Compute In-Memory
   Fabrics
SO VLSI-SOC: DESIGN TRENDS, VLSI-SOC 2020
SE IFIP Advances in Information and Communication Technology
DT Proceedings Paper
CT 28th IFIP WG 10.5/IEEE International Conference on Very Large Scale
   Integration (VLSI-SoC)
CY OCT 06-09, 2020
CL ELECTR NETWORK
DE Compute In-Memory; RRAM; PCRAM
AB Compute in-memory (CIM) is a promising technique that minimizes data transport, the primary performance bottleneck and energy cost of most data intensive applications. This has found widespread adoption in accelerating neural networks for machine learning applications. Utilizing a crossbar architecture with emerging nonvolatile memories (eNVM) such as dense resistive random access memory (RRAM) or phase change random access memory (PCRAM), various forms of neural networks can be implemented to greatly reduce power and increase on chip memory capacity. However, compute in-memory faces its own limitations at both the circuit and the device levels. Although compute in-memory using the crossbar architecture can greatly reduce data transport, the rigid nature of these large fixed weight matrices forfeits the flexibility of traditional CMOS and SRAM based designs. In this work, we explore the different synchronization barriers that occur from the CIM constraints. Furthermore, we propose a new allocation algorithm and data flow based on input data distributions to maximize utilization and performance for compute-in memory based designs. We demonstrate a 7.47x performance improvement over a naive allocation method for CIM accelerators on ResNet18.
C1 [Crafton, Brian; Spetalnick, Samuel; Murali, Gauthaman; Krishna, Tushar; Lim, Sung-Kyu; Raychowdhury, Arijit] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Crafton, B (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM brian.crafton@gatech.edu; arijit.raychowdhury@ece.gatech.edu
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Crafton B., 2020, ARXIV PREPRINT ARXIV
   Crafton B, 2020, IEEE INT CONF VLSI, P123, DOI 10.1109/VLSI-SOC46417.2020.9344086
   Davies M, 2018, IEEE MICRO, V38, P82, DOI 10.1109/MM.2018.112130359
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Peng X., 2019, IEEE T CIRCUITS SYST
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Wilton SJE, 1996, IEEE J SOLID-ST CIRC, V31, P677, DOI 10.1109/4.509850
   Wu JY, 2018, INT EL DEVICES MEET
   Yang TH, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P236, DOI 10.1145/3307650.3322271
   Yoon J.-H., 2021 IEEE INT SOLID, V64
   Yoon JH, 2021, IEEE CUST INTEGR CIR, DOI 10.1109/CICC51472.2021.9431412
NR 19
TC 0
Z9 0
U1 0
U2 7
PY 2021
VL 621
BP 323
EP 341
DI 10.1007/978-3-030-81641-4_15
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Manufacturing; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Xu, LN
   Butt, AR
   Lim, SH
   Kannan, R
AF Xu, Luna
   Butt, Ali R.
   Lim, Seung-Hwan
   Kannan, Ramakrishnan
GP IEEE
TI A Heterogeneity-Aware Task Scheduler for Spark
SO 2018 IEEE INTERNATIONAL CONFERENCE ON CLUSTER COMPUTING (CLUSTER)
SE IEEE International Conference on Cluster Computing
DT Proceedings Paper
CT IEEE International Conference on Cluster Computing (CLUSTER)
CY SEP 10-13, 2018
CL Belfast, NORTH IRELAND
AB Big data processing systems such as Spark are employed in an increasing number of diverse applications- such as machine learning, graph computation, and scientific computing-each with dynamic and different resource needs. These applications increasingly run on heterogeneous hardware, e.g., with out-of-core accelerators. However, big data platforms do not factor in the multi-dimensional heterogeneity of applications and hardware. This leads to a fundamental mismatch between the application and hardware characteristics, and the resource scheduling adopted in big data platforms. For example, Hadoop and Spark consider only data locality when assigning tasks to nodes, and typically disregard the hardware capabilities and suitability to specific application requirements.
   In this paper, we present RUPAM, a heterogeneity-aware task scheduling system for big data platforms, which considers both task-level resource characteristics and underlying hardware characteristics, as well as preserves data locality. RUPAM adopts a simple yet effective heuristic to decide the dominant scheduling factor (e.g., CPU, memory, or DO), given a task in a particular stage. Our experiments show that RUPAM is able to improve the performance of representative applications by up to 62.3% compared to the standard Spark scheduler.
C1 [Xu, Luna; Butt, Ali R.] Virginia Tech, Blacksburg, VA 24061 USA.
   [Lim, Seung-Hwan; Kannan, Ramakrishnan] Oak Ridge Natl Lab, Oak Ridge, TN USA.
RP Xu, LN (corresponding author), Virginia Tech, Blacksburg, VA 24061 USA.
EM xuluna@cs.vt.edu; butta@cs.vt.edu; lims1@ornl.gov; kannanr@ornl.gov
CR Ahmad F., 2012, ACM SIGARCH COMPUTER
   Ahsan M. K., 2003, Journal of Systems Science and Systems Engineering, V12, P190, DOI 10.1007/s11518-006-0129-3
   [Anonymous], 2013, P 8 ACM EUROPEAN C C
   [Anonymous], 2017, ARXIV171107440
   [Anonymous], 2011, P 8 ACM INT C AUTONO, DOI DOI 10.1145/1998582.1998637
   [Anonymous], 2011, P 2 ACM S CLOUD COMP
   Bo Wang, 2015, 2015 IEEE Conference on Computer Communications (INFOCOM). Proceedings, P1328, DOI 10.1109/INFOCOM.2015.7218509
   Bobroff N, 2007, 2007 10TH IFIP/IEEE INTERNATIONAL SYMPOSIUM ON INTEGRATED NETWORK MANAGEMENT (IM 2009), VOLS 1 AND 2, P119, DOI 10.1109/inm.2007.374776
   Cheng DZ, 2017, IEEE T PARALL DISTR, V28, P774, DOI 10.1109/TPDS.2016.2594765
   Chowdhury Mosharaf, 2016, NSDI
   Das T., 2012, P 9 USENIX C NETWORK, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Delimitrou C, 2014, ACM SIGPLAN NOTICES, V49, P127, DOI 10.1145/2541940.2541941
   Fadika Z., 2012, Proceedings of the 2012 12th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid 2012), P49, DOI 10.1109/CCGrid.2012.135
   Ferguson A. D., 2012, P 7 ACM EUR C COMP S, P99
   Gandhi Rohan, 2013, PRESENTED PART 2013, P61
   Ghodsi An, 2011, Computer Communication Review, V41, P507, DOI 10.1145/2018584.2018586
   Graham R. L., 1979, Discrete Optimisation, P287
   Grandl R, 2014, ACM SIGCOMM COMP COM, V44, P455, DOI 10.1145/2740070.2626334
   Hindman Benjamin, 2011, NSDI
   Jyothi SA, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P117
   Konwinski A. D, 2008, USENIX OSDI, P7
   Kopytov A., SYSBENCH
   Lee G., 2012, RESOURCE ALLOCATION
   Li MH, 2017, ASIA PAC J MANAG, V34, P19, DOI 10.1007/s10490-015-9436-x
   Ousterhout K., 2017, P SOSP
   Ousterhout K, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P69, DOI 10.1145/2517349.2522716
   Polo J., 2011, RESOURCE AWARE ADAPT, P187
   Seung-Hwan Lim, 2012, Performance Evaluation Review, V40, P271, DOI 10.1145/2318857.2254790
   Sharma B, 2013, INT CON DISTR COMP S, P102, DOI 10.1109/ICDCS.2013.31
   SHMOYS DB, 1995, SIAM J COMPUT, V24, P1313, DOI 10.1137/S0097539793248317
   Tan ZL, 2016, PROC VLDB ENDOW, V9, P720, DOI 10.14778/2977797.2977799
   Thinakaran Prashanth, 2017, 37 IEEE INT C DISTR
   Thusoo A., 2010, P 2010 ACM SIGMOD IN, P1013, DOI 10.1145/1807167.1807278
   Tian C, 2009, 2009 EIGHTH INTERNATIONAL CONFERENCE ON GRID AND COOPERATIVE COMPUTING, PROCEEDINGS, P218, DOI 10.1109/GCC.2009.19
   Vavilapalli V.K., 2013, P 4 ANN S CLOUD COMP, P5
   Verma A, 2014, PERFORM EVALUATION, V79, P328, DOI 10.1016/j.peva.2014.07.020
   Xu L., 2017, P 2017 IEEE INT C BI
   Yang H., 2013, ACM SIGARCH COMPUTER
   Yang HB, 2016, PROCEEDINGS OF 2016 INTERNATIONAL CONFERENCE ON AUDIO, LANGUAGE AND IMAGE PROCESSING (ICALIP), P28, DOI 10.1109/ICALIP.2016.7846627
   Zhang XC, 2017, CIKM'17: PROCEEDINGS OF THE 2017 ACM CONFERENCE ON INFORMATION AND KNOWLEDGE MANAGEMENT, P507, DOI 10.1145/3132847.3132996
   Zhang XC, 2017, IEEE INT CONF BIG DA, P1688, DOI 10.1109/BigData.2017.8258107
   Zhang XC, 2017, IEEE INT CONF BIG DA, P1590, DOI 10.1109/BigData.2017.8258093
NR 42
TC 9
Z9 9
U1 1
U2 2
PY 2018
BP 245
EP 256
DI 10.1109/CLUSTER.2018.00042
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Markidis, S
AF Markidis, Stefano
TI On physics-informed neural networks for quantum computers
SO FRONTIERS IN APPLIED MATHEMATICS AND STATISTICS
DT Article
DE quantum physics-informed neural network; Poisson equation; quantum
   neural networks; continuous variable quantum computing; heterogeneous
   QPU CPU computing
ID COMPUTATION; INFORMATION
AB Physics-Informed Neural Networks (PINN) emerged as a powerful tool for solving scientific computing problems, ranging from the solution of Partial Differential Equations to data assimilation tasks. One of the advantages of using PINN is to leverage the usage of Machine Learning computational frameworks relying on the combined usage of CPUs and co-processors, such as accelerators, to achieve maximum performance. This work investigates the design, implementation, and performance of PINNs, using the Quantum Processing Unit (QPU) co-processor. We design a simple Quantum PINN to solve the one-dimensional Poisson problem using a Continuous Variable (CV) quantum computing framework. We discuss the impact of different optimizers, PINN residual formulation, and quantum neural network depth on the quantum PINN accuracy. We show that the optimizer exploration of the training landscape in the case of quantum PINN is not as effective as in classical PINN, and basic Stochastic Gradient Descent (SGD) optimizers outperform adaptive and high-order optimizers. Finally, we highlight the difference in methods and algorithms between quantum and classical PINNs and outline future research challenges for quantum PINN development.
C1 [Markidis, Stefano] KTH Royal Inst Technol, Dept Comp Sci, Stockholm, Sweden.
RP Markidis, S (corresponding author), KTH Royal Inst Technol, Dept Comp Sci, Stockholm, Sweden.
EM markidis@kth.se
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   AMARI S, 1993, NEUROCOMPUTING, V5, P185, DOI 10.1016/0925-2312(93)90006-O
   Arrasmith A, 2021, QUANTUM-AUSTRIA, V5, DOI 10.22331/q-2021-10-05-558
   Arute F, 2019, NATURE, V574, P505, DOI 10.1038/s41586-019-1666-5
   Baydin AG, 2018, J MACH LEARN RES, V18
   Bengio Y., 2006, ADV NEURAL INF PROCE, V19
   Braunstein SL, 2005, REV MOD PHYS, V77, P513, DOI 10.1103/RevModPhys.77.513
   Bromley TR, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab8504
   Broughton M., 2020, PREPRINT
   Cai SZ, 2021, ACTA MECH SINICA-PRC, V37, P1727, DOI 10.1007/s10409-021-01148-1
   Cerezo M, 2021, NAT REV PHYS, V3, P625, DOI 10.1038/s42254-021-00348-9
   Chen CG, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-018-37354-4
   Chen YY, 2020, OPT EXPRESS, V28, P11618, DOI 10.1364/OE.384875
   Chien Steven W. D., 2019, 2019 IEEE International Parallel and Distributed Processing Symposium Workshops (IPDPSW). Proceedings, P509, DOI 10.1109/IPDPSW.2019.00092
   Chow Jerry, 2021, IBM QUANTUM BREAKS 1
   Fukui K, 2022, J PHYS B-AT MOL OPT, V55, DOI 10.1088/1361-6455/ac489c
   Gidney C, 2021, QUANTUM-AUSTRIA, V5, DOI 10.22331/q-2021-04-15-433
   Grover L. K., 1996, Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, P212, DOI 10.1145/237814.237866
   Haghighat E, 2021, COMPUT METHOD APPL M, V373, DOI 10.1016/j.cma.2020.113552
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   Heim N., 2021, PREPRINT
   Horowitz M, 2005, INT EL DEVICES MEET, P11
   Killoran N, 2019, PHYS REV RES, V1, DOI 10.1103/PhysRevResearch.1.033063
   Killoran N, 2019, QUANTUM-AUSTRIA, V3, DOI 10.22331/q-2019-03-11-129
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Knudsen M., 2020, PREPRINT
   Kumar N., 2022, PREPRINT, DOI DOI 10.48550/ARXIV.2206.14184
   Kyriienko O., 2022, PREPRINT
   Kyriienko O, 2021, PHYS REV A, V103, DOI 10.1103/PhysRevA.103.052416
   LaRose Ryan, 2019, PREPRINT
   Lattner C., 2020, PREPRINT
   Li H, 2018, ADV NEUR IN, V31
   LIU DC, 1989, MATH PROGRAM, V45, P503, DOI 10.1007/BF01589116
   Lloyd S., 1999, Physical Review Letters, V82, P1784, DOI 10.1103/PhysRevLett.82.1784
   Lu L, 2021, SIAM REV, V63, P208, DOI 10.1137/19M1274067
   Madsen LS, 2022, NATURE, V606, P75, DOI 10.1038/s41586-022-04725-x
   Markidis S, 2021, FRONT BIG DATA, V4, DOI 10.3389/fdata.2021.669097
   McClean JR, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07090-4
   McClean JR, 2016, NEW J PHYS, V18, DOI 10.1088/1367-2630/18/2/023023
   McKay DC., 2018, PREPRINT
   Mishra S, 2022, IMA J NUMER ANAL, V42, P981, DOI 10.1093/imanum/drab032
   Moore GE, 1998, P IEEE, V86, P82, DOI 10.1109/JPROC.1998.658762
   O'Malley PJJ, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.031007
   Ortiz-Gutiérrez L, 2017, OPT COMMUN, V397, P166, DOI 10.1016/j.optcom.2017.04.011
   Paine AE., 2022, PREPRINT
   Paine AE., 2021, PREPRINT
   Pang GF, 2019, SIAM J SCI COMPUT, V41, pA2603, DOI 10.1137/18M1229845
   Paszke A, 2019, ADV NEUR IN, V32
   Peruzzo A, 2014, NAT COMMUN, V5, DOI 10.1038/ncomms5213
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Raissi M, 2019, J COMPUT PHYS, V378, P686, DOI 10.1016/j.jcp.2018.10.045
   Ruder, 2017, OVERVIEW MULTI TASK
   Shin Y., 2020, PREPRINT
   Slussarenko S, 2019, APPL PHYS REV, V6, DOI 10.1063/1.5115814
   Spall JC, 1998, J HOPKINS APL TECH D, V19, P482
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Watabe M, 2021, QUANTUM REPORTS, V3, P333
   Weedbrook C, 2012, REV MOD PHYS, V84, P621, DOI 10.1103/RevModPhys.84.621
   Zeiler M.D., 2012, PREPRINT
NR 60
TC 0
Z9 0
U1 4
U2 6
PD OCT 28
PY 2022
VL 8
AR 1036711
DI 10.3389/fams.2022.1036711
WC Mathematics, Interdisciplinary Applications
DA 2023-11-11
ER

PT J
AU Dong, BW
   Aggarwal, S
   Zhou, W
   Ali, UE
   Farmakidis, N
   Lee, JS
   He, YH
   Li, X
   Kwong, DL
   Wright, CD
   Pernice, WHP
   Bhaskaran, H
AF Dong, Bowei
   Aggarwal, Samarth
   Zhou, Wen
   Ali, Utku Emre
   Farmakidis, Nikolaos
   Lee, June Sang
   He, Yuhan
   Li, Xuan
   Kwong, Dim-Lee
   Wright, C. D.
   Pernice, Wolfram H. P.
   Bhaskaran, H.
TI Higher-dimensional processing using a photonic tensor core with
   continuous-time data
SO NATURE PHOTONICS
DT Article; Early Access
ID ARTIFICIAL-INTELLIGENCE
AB New developments in hardware-based 'accelerators' range from electronic tensor cores and memristor-based arrays to photonic implementations. The goal of these approaches is to handle the exponentially growing computational load of machine learning, which currently requires the doubling of hardware capability approximately every 3.5 months. One solution is increasing the data dimensionality that is processable by such hardware. Although two-dimensional data processing by multiplexing space and wavelength has been previously reported, the use of three-dimensional processing has not yet been implemented in hardware. In this paper, we introduce the radio-frequency modulation of photonic signals to increase parallelization, adding an additional dimension to the data alongside spatially distributed non-volatile memories and wavelength multiplexing. We leverage higher-dimensional processing to configure such a system to an architecture compatible with edge computing frameworks. Our system achieves a parallelism of 100, two orders higher than implementations using only the spatial and wavelength degrees of freedom. We demonstrate this by performing a synchronous convolution of 100 clinical electrocardiogram signals from patients with cardiovascular diseases, and constructing a convolutional neural network capable of identifying patients at sudden death risk with 93.5% accuracy.
C1 [Dong, Bowei; Aggarwal, Samarth; Zhou, Wen; Ali, Utku Emre; Farmakidis, Nikolaos; Lee, June Sang; He, Yuhan; Li, Xuan; Bhaskaran, H.] Univ Oxford, Dept Mat, Oxford, England.
   [Dong, Bowei; Kwong, Dim-Lee] ASTAR, Inst Microelect, Singapore, Singapore.
   [Wright, C. D.] Univ Exeter, Dept Engn, Exeter, England.
   [Pernice, Wolfram H. P.] Univ Munster, Inst Phys, Munster, Germany.
   [Pernice, Wolfram H. P.] Heidelberg Univ, Kirchhoff Inst Phys, Heidelberg, Germany.
RP Bhaskaran, H (corresponding author), Univ Oxford, Dept Mat, Oxford, England.
EM harish.bhaskaran@materials.ox.ac.uk
CR Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Assael Y, 2022, NATURE, V603, P280, DOI 10.1038/s41586-022-04448-z
   Baig MT, 2013, REV SCI INSTRUM, V84, DOI 10.1063/1.4832042
   Dauparas J, 2022, SCIENCE, V378, P49, DOI 10.1126/science.add2187
   Dong BW, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abl9874
   Wang YE, 2019, Arxiv, DOI arXiv:1907.10701
   Fawzi A, 2022, NATURE, V610, P47, DOI 10.1038/s41586-022-05172-4
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Greenwald S. D., 1986, DEV ANAL VENTRICULAR
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Han C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aav6134
   Iigaya K, 2021, NAT HUM BEHAV, V5, P743, DOI 10.1038/s41562-021-01124-6
   Ji H, 2010, IEEE PHOTONIC TECH L, V22, P1762, DOI 10.1109/LPT.2010.2084566
   Jung S, 2022, NATURE, V601, P211, DOI 10.1038/s41586-021-04196-6
   Kim MK, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm8537
   Lanza M, 2022, SCIENCE, V376, P1066, DOI 10.1126/science.abj9979
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee JS, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn9459
   Li XQ, 2016, PROC INT CONF PARAL, P67, DOI 10.1109/ICPP.2016.15
   Liu WL, 2016, NAT PHOTONICS, V10, P190, DOI [10.1038/nphoton.2015.281, 10.1038/NPHOTON.2015.281]
   Liu Y, 2022, SCIENCE, V376, P1309, DOI 10.1126/science.abo2631
   Magaki I, 2016, CONF PROC INT SYMP C, P178, DOI 10.1109/ISCA.2016.25
   Markov IL, 2014, NATURE, V512, P147, DOI 10.1038/nature13570
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Rao ZY, 2022, SCIENCE, V378, P78, DOI 10.1126/science.abo4940
   Reuther A, 2021, IEEE HIGH PERF EXTR, DOI 10.1109/HPEC49654.2021.9622867
   Ríos C, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau5759
   Ríos C, 2015, NAT PHOTONICS, V9, P725, DOI [10.1038/NPHOTON.2015.182, 10.1038/nphoton.2015.182]
   Sanz M., 2022, CREATETFW INPUTSIGNA
   Sarwat SG, 2022, NAT NANOTECHNOL, V17, P507, DOI 10.1038/s41565-022-01095-3
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Shastri BJ, 2021, NAT PHOTONICS, V15, P102, DOI 10.1038/s41566-020-00754-y
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shi WS, 2016, IEEE INTERNET THINGS, V3, P637, DOI 10.1109/JIOT.2016.2579198
   Shu HW, 2022, NATURE, V605, P457, DOI 10.1038/s41586-022-04579-3
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Statista Research Department, 2022, AM DAT CREAT CONS ST
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Trail MA, 2022, NATURE, V610, P54, DOI 10.1038/s41586-022-05119-9
   Wan WE, 2022, NATURE, V608, P504, DOI 10.1038/s41586-022-04992-8
   Wang C, 2021, NAT NANOTECHNOL, V16, P1079, DOI 10.1038/s41565-021-00943-y
   Wang LN, 2018, ACM SIGPLAN NOTICES, V53, P41, DOI 10.1145/3200691.3178491
   Wang N., 2020, NIPS 20
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   White AD, 2023, NAT PHOTONICS, V17, P143, DOI 10.1038/s41566-022-01110-y
   World Health Organization, CARDIOVASC DIS
   Wu CM, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abm2956
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yan T, 2022, SCI ADV, V8, DOI 10.1126/sciadv.abn7630
   Yang KY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-35446-4
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yuan LQ, 2018, OPTICA, V5, P1396, DOI 10.1364/OPTICA.5.001396
   Zhao H, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-022-33132-z
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou LN, 2017, NEUROCOMPUTING, V237, P350, DOI 10.1016/j.neucom.2017.01.026
NR 57
TC 0
Z9 0
U1 1
U2 1
PD 2023 OCT 19
PY 2023
DI 10.1038/s41566-023-01313-x
EA OCT 2023
WC Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Kahng, AB
   Varadarajan, R
   Wang, ZA
AF Kahng, Andrew B.
   Varadarajan, Ravi
   Wang, Zhiang
GP ACM
TI RTL-MP: Toward Practical, Human-Quality Chip Planning and Macro
   Placement
SO ISPD'22: PROCEEDINGS OF THE 2022 INTERNATIONAL SYMPOSIUM ON PHYSICAL
   DESIGN
DT Proceedings Paper
CT 31st edition of the ACM International Symposium on Physical Design
   (ISPD)
CY MAR 27-30, 2022
CL ELECTR NETWORK
DE Macro placement; RTL-driven; dataflow
ID ALGORITHM; PACKING; TREES
AB In a typical RTL-to-GDSII flow, floorplanning plays an essential role in achieving decent quality of results (QoR). A good floorplan typically requires interaction between the frontend designer, who is responsible for the functionality of the RTL, and the backend physical design engineer. The increasing complexity of macro-dominated designs (especially machine learning accelerators with autogenerated RTL) has made the floorplanning task even more challenging and time-consuming. In this paper, we propose RTL-MP, a novel macro placer which utilizes RTL information and tries to "mimic" the interaction between the frontend RTL designer and the backend physical design engineer to produce human-quality floorplans. By exploiting the logical hierarchy and processing logical modules based on connection signatures, RTL-MP can capture the dataflow inherent in the RTL and use the dataflow information to guide macro placement. We also apply autotuning [37] to optimize hyperparameter settings based on input designs. We have built RTL-MP based on OpenROAD infrastructure [25, 49] and applied RTL-MP to a set of industrial designs. RTL-MP outperforms state-of-the-art commercial macro placers and achieves QoR similar to that of handcrafted floorplans.
C1 [Kahng, Andrew B.; Varadarajan, Ravi; Wang, Zhiang] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Kahng, AB (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM abk@ucsd.edu; rvaradarajan@ucsd.edu; zhwO33@ucsd.edu
CR Adya SN, 2003, IEEE T VLSI SYST, V11, P1120, DOI 10.1109/TVLSI.2003.817546
   ALDOUS D, 1994, AN S FDN CO, P492, DOI 10.1109/SFCS.1994.365742
   [Anonymous], COYOTE RISC V ROCKET
   [Anonymous], TUNE
   [Anonymous], OPENROAD PROJECT
   [Anonymous], SWERV CORETM VERSION
   [Anonymous], CVA6 RISC V CPU
   [Anonymous], BLACKPARROT
   Bruck R., 1988, Proceedings of the International Workshop on Artificial Intelligence for Industrial Applications: IEEE AI '88 (Cat. No.88CH2529-6), P194, DOI 10.1109/AIIA.1988.13292
   Caldwell A., 2006, MLPART HIGH PERFORMA
   Chan TB, 2020, INT WORKS SYST LEVEL, DOI 10.1145/3414622.3431907
   Chang CH, 2017, ICCAD-IEEE ACM INT, P504, DOI 10.1109/ICCAD.2017.8203819
   Chang YC, 2000, DES AUT CON, P458
   Chen GL, 2008, 2008 3RD INTERNATIONAL CONFERENCE ON INTELLIGENT SYSTEM AND KNOWLEDGE ENGINEERING, VOLS 1 AND 2, P1020, DOI 10.1109/ISKE.2008.4731079
   Chen TC, 2006, IEEE T COMPUT AID D, V25, P637, DOI 10.1109/TCAD.2006.870076
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P1621, DOI 10.1109/TCAD.2008.927760
   Chen TC, 2008, IEEE T COMPUT AID D, V27, P286, DOI 10.1109/TCAD.2007.907065
   Chen YF, 2014, DES AUT CON, DOI 10.1145/2593069.2593206
   Chiou CH, 2016, ASIA S PACIF DES AUT, P172, DOI 10.1109/ASPDAC.2016.7428007
   Choi WJ, 2003, DESIGN, AUTOMATION AND TEST IN EUROPE CONFERENCE AND EXHIBITION, PROCEEDINGS, P1104
   Chuang YL, 2010, ICCAD-IEEE ACM INT, P663, DOI 10.1109/ICCAD.2010.5654234
   Cong J, 2006, IEEE T COMPUT AID D, V25, P1719, DOI 10.1109/TCAD.2005.859519
   Cortadella J., 2020, IEEE T CAD, V40, P2542
   Dae Hyun Kim, 2008, 13th Asia and South Pacific Design Automation Conference ASP-DAC 2008, P204
   Ekpanyapong M, 2006, IEEE T COMPUT AID D, V25, P1289, DOI 10.1109/TCAD.2005.855971
   Fogaça M, 2020, INTEGRATION, V74, P32, DOI 10.1016/j.vlsi.2020.03.007
   Gwee BH, 1999, INTEGRATION, V28, P157, DOI 10.1016/S0167-9260(99)00015-2
   He ZL, 2020, PR IEEE COMP DESIGN, P324, DOI 10.1109/ICCD50377.2020.00061
   Hsu MK, 2013, DES AUT CON
   Hsu MK, 2014, IEEE T COMPUT AID D, V33, P1914, DOI 10.1109/TCAD.2014.2360453
   Hu CC, 2004, 2004 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL 5, PROCEEDINGS, P205
   Kahng A. B., 2000, Proceedings International Symposium on Physical Design, 2000. ISPD-2000, P207, DOI 10.1145/332357.332401
   Kahng A. B., 2021, PROC GOMACTECH
   Kim MC, 2012, ISPD 12: PROCEEDINGS OF THE 2012 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN, P193
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Liaw R, 2018, Arxiv, DOI [arXiv:1807.05118, DOI 10.48550/ARXIV.1807.05118]
   Lin JM, 2021, IEEE T VLSI SYST, V29, P973, DOI 10.1109/TVLSI.2021.3057921
   Lin JM, 2019, ICCAD-IEEE ACM INT, DOI [10.1109/iccad45719.2019.8942168, 10.1145/3316781.3317901]
   Lin JM, 2019, IEEE T VLSI SYST, V27, P57, DOI 10.1109/TVLSI.2018.2867833
   Liu Y.-C., 2019, PROC ASP DAC
   Lu JW, 2015, IEEE T COMPUT AID D, V34, P685, DOI 10.1109/TCAD.2015.2391263
   Mirhoseini A, 2020, Arxiv, DOI arXiv:2004.10746
   Mirhoseini A, 2021, NATURE, V594, P207, DOI 10.1038/s41586-021-03544-w
   Murata H, 1996, IEEE T COMPUT AID D, V15, P1518, DOI 10.1109/43.552084
   Nookala V, 2005, DES AUT CON, P579
   OUSTERHOUT JK, 1984, IEEE T COMPUT AID D, V3, P87, DOI 10.1109/TCAD.1984.1270061
   Tang XP, 2001, PROCEEDINGS OF THE ASP-DAC 2001: ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE 2001, P521, DOI 10.1109/ASPDAC.2001.913361
   Team VLSI, 2014, FLOORPL STRAT MACR D
   Temme K. -H., 1998, PROC INT WORKSHOP AR, P188
   Vidal-Obiols A, 2019, DES AUT TEST EUROPE, P186, DOI [10.23919/date.2019.8714812, 10.23919/DATE.2019.8714812]
   Yan JZ, 2008, DES AUT CON, P161
   Yan JZ, 2014, ACM T DES AUTOMAT EL, V19, DOI 10.1145/2611761
   Zhan Y, 2006, ASIA S PACIF DES AUT, P771
NR 53
TC 2
Z9 2
U1 2
U2 3
PY 2022
BP 3
EP 11
DI 10.1145/3505170.3506731
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Li, Y
   Li, JY
   Jiang, XL
   Gao, CL
   Zhang, T
AF Li, Ya
   Li, Jiying
   Jiang, Xinlong
   Gao, Chenlong
   Zhang, Teng
GP IEEE Comp Soc
TI A Driving Attention Detection Method Based on Head Pose
SO 2019 IEEE SMARTWORLD, UBIQUITOUS INTELLIGENCE & COMPUTING, ADVANCED &
   TRUSTED COMPUTING, SCALABLE COMPUTING & COMMUNICATIONS, CLOUD & BIG DATA
   COMPUTING, INTERNET OF PEOPLE AND SMART CITY INNOVATION
   (SMARTWORLD/SCALCOM/UIC/ATC/CBDCOM/IOP/SCI 2019)
DT Proceedings Paper
CT IEEE Conference on SmartWorld, Ubiquitous Intelligence and Computing,
   Advanced and Trusted Computing, Scalable Computing and Communications,
   Cloud and Big Data Computing, Internet of People and Smart City
   Innovation
CY AUG 19-23, 2019
CL Leicester, ENGLAND
DE Driving Attention Detection; Wearable Sensor; Machine Learning; Head
   Pose
ID SYSTEM; DISTRACTION; INATTENTION; BEHAVIOR
AB Head pose is an important indicator of driving attention detection. During driving, head pose, including head position and head movement, can infer the driver's attention. This paper presents a novel method for collecting driver's head pose information using a built-in accelerometer and gyroscope head-mounted inertial sensor. In our experimental study, we designed 10 scenes that are easy to distract from driving. And five subjects were asked to wear a head-mounted inertial sensor to drive the driving simulator. This driving simulator is equipped with real driving conditions such as brakes, steering wheels, accelerators and so on. While driving, subjects need to complete the designed driving scene in order. Subsequently,We perform pre-processing such as Savitzky-Golay filtering and windowing on data collected by inertial sensors with built-in accelerometers and gyroscopes. The time domain and frequency domain features of the data are then extracted in the corresponding window. Finally, we designed a random forest model to detect driving attention. Our simulation experiments show that our proposed method of collecting data using the built-in accelerometer and gyroscope's head-mounted sensor can achieve higher precision, recall and F1(score).
C1 [Li, Ya; Li, Jiying] Lanzhou Jiaotong Univ, Lanzhou, Peoples R China.
   [Li, Ya; Jiang, Xinlong; Gao, Chenlong; Zhang, Teng] Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
   [Jiang, Xinlong; Gao, Chenlong; Zhang, Teng] Beijing Key Lab Mobile Comp & Pervas Device, Beijing, Peoples R China.
   [Jiang, Xinlong; Gao, Chenlong] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Li, Y (corresponding author), Lanzhou Jiaotong Univ, Lanzhou, Peoples R China.; Li, Y (corresponding author), Chinese Acad Sci, Inst Comp Technol, Beijing, Peoples R China.
EM liyash66@163.com; ljy7609@mail.lzjtu.cn; jiangxinlong@ict.ac.cn;
   gaochenlong@ict.ac.cn; ztech@outlook.com
CR ALMUALLIM H, 1991, PROCEEDINGS : NINTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, VOLS 1 AND 2, P547
   Angell L.S., 2006, DRIVER WORKLOAD METR
   [Anonymous], 2010, P CHI, DOI DOI 10.1145/1753846.1754138
   Arun S, 2012, IEEE CONF SUSTAIN UT, P1, DOI 10.1109/STUDENT.2012.6408351
   Banos O, 2014, SENSORS-BASEL, V14, P6474, DOI 10.3390/s140406474
   Batista JP, 2005, LECT NOTES COMPUT SC, V3522, P200
   Bergasa LM, 2006, IEEE T INTELL TRANSP, V7, P63, DOI 10.1109/TITS.2006.869598
   Ersal T, 2010, IEEE T INTELL TRANSP, V11, P692, DOI 10.1109/TITS.2010.2049741
   Harbluk JL, 2007, ACCIDENT ANAL PREV, V39, P372, DOI 10.1016/j.aap.2006.08.013
   Itoh M, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON MECHATRONICS AND AUTOMATION, VOLS 1-7, CONFERENCE PROCEEDINGS, P7, DOI 10.1109/ICMA.2009.5246188
   Jiménez F, 2015, IET INTELL TRANSP SY, V9, P105, DOI 10.1049/iet-its.2013.0118
   Kawakita E., 2010, 2010 13th International IEEE Conference on Intelligent Transportation Systems (ITSC 2010), P765, DOI 10.1109/ITSC.2010.5625079
   Li XP, 2018, T I MEAS CONTROL, V40, P885, DOI 10.1177/0142331216670451
   Mead R, 2013, INT J SOC ROBOT, V5, P367, DOI 10.1007/s12369-013-0189-8
   Rumar K., 1999, NORDIC ROAD TRANSPOR, V11
   Sahayadhas A, 2015, BIOCYBERN BIOMED ENG, V35, P198, DOI 10.1016/j.bbe.2014.12.002
   Smith P, 2003, IEEE T INTELL TRANSP, V4, P205, DOI 10.1109/TITS.2003.821342
   Spasova V., 2014, INT J ADV COMPUT RES, V4, P94
   Tango F, 2013, IEEE T INTELL TRANSP, V14, P894, DOI 10.1109/TITS.2013.2247760
   W. H. Organization, 2018, GLOBAL STATUS REPORT
   Wu BF, 2014, IET INTELL TRANSP SY, V8, P361, DOI 10.1049/iet-its.2013.0009
   Xing Y, 2018, IEEE T COMPUT SOC SY, V5, P95, DOI 10.1109/TCSS.2017.2766884
   Yan C, 2015, 2015 8TH INTERNATIONAL CONGRESS ON IMAGE AND SIGNAL PROCESSING (CISP), P680, DOI 10.1109/CISP.2015.7407964
NR 23
TC 0
Z9 0
U1 2
U2 2
PY 2019
BP 483
EP 490
DI 10.1109/SmartWorld-UIC-ATC-SCALCOM-IOP-SCI.2019.00124
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Min, D
   Ko, Y
   Walker, R
   Lee, J
   Kim, Y
AF Min, Donghyun
   Ko, Yungwoo
   Walker, Ryan
   Lee, Junghee
   Kim, Youngjae
TI A Content-Based Ransomware Detection and Backup Solid-State Drive for
   Ransomware Defense
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Ransomware; Performance evaluation; Entropy; Encryption; Machine
   learning; Libraries; Engines; Ransomware attack; solid-state drive
   (SSD); storage security; storage system
AB Ransomware is a growing concern in business and government because it causes immediate financial damages or loss of important data. There is a way to detect and block ransomware in advance, but evolved ransomware can still attack while avoiding detection. Another alternative is to back up the original data. However, existing backup solutions can be under the control of ransomware and backup copies can be destroyed by ransomware. Moreover, backup methods incur storage and performance overhead. In this article, we propose AMOEBA, a device-level backup solution that does not require additional storage for backup. AMOEBA is armed with: 1) a hardware accelerator to run content-based detection algorithms for ransomware detection at high speed and 2) a fine-grained backup control mechanism to minimize space overhead for data backup. For evaluations, we not only implemented AMOEBA using the Microsoft solid-state drive (SSD) simulator but also prototyped it on the OpenSSD-platform. Our extensive evaluations with real ransomware workloads show that AMOEBA has high ransomware detection accuracy with negligible performance overhead.
C1 [Min, Donghyun; Kim, Youngjae] Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.
   [Ko, Yungwoo] TmaxSoft, Seoul, South Korea.
   [Walker, Ryan] Booz Allen Hamilton, Global Def Grp, Mclean, VA 22102 USA.
   [Lee, Junghee] Korea Univ, Sch Cybersecur, Seoul 02841, South Korea.
RP Kim, Y (corresponding author), Sogang Univ, Dept Comp Sci & Engn, Seoul 04107, South Korea.; Lee, J (corresponding author), Korea Univ, Sch Cybersecur, Seoul 02841, South Korea.
EM mdh38112@sogang.ac.kr; ryan.walker@my.utsa.edu; j_lee@korea.ac.kr;
   youkim@sogang.ac.kr
CR Aggarwal Charu C., 2018, NEURAL NETWORKS DEEP, V10, P3, DOI [10.1007/978-3-319-94463-0, DOI 10.1007/978-3-319-94463-0]
   Agrawal N., 2008, PROC USENIX ANN TECH, P57, DOI DOI 10.1109/ISSCC.2012.6177101
   Ahmadian MM, 2016, 2016 13TH INTERNATIONAL IRANIAN SOCIETY OF CRYPTOLOGY CONFERENCE ON INFORMATION SECURITY AND CRYPTOLOGY (ISCISC), P79, DOI 10.1109/ISCISC.2016.7736455
   [Anonymous], 2019, CYEMPTIVE LAUNCHES P
   [Anonymous], VIRTUAL GANGSTER
   [Anonymous], 2019, MCAFEE LABS THREATS
   [Anonymous], COSMOS OPENSSD PLATF
   [Anonymous], 2012, P 10 USENIX C FIL ST
   [Anonymous], 2020, WILL I RECOVER RANSO
   [Anonymous], 2018, DATA SHEET DS188 V1
   Aydonat U, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P55, DOI 10.1145/3020078.3021738
   Back S, 2018, INT CON DISTR COMP S, P875, DOI 10.1109/ICDCS.2018.00089
   Biggio B, 2018, PATTERN RECOGN, V84, P317, DOI 10.1016/j.patcog.2018.07.023
   Bucy John S., 2008, CMUPDL08101
   Cabaj K, 2016, IEEE NETWORK, V30, P14, DOI 10.1109/MNET.2016.1600110NM
   Chen X, 2008, I C DEPEND SYS NETWO, P177, DOI 10.1109/DSN.2008.4630086
   Continella A, 2016, ANN COMPUT SECURITY, P336, DOI 10.1145/2991079.2991110
   Maimo LF, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19051114
   Huang J, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P2231, DOI 10.1145/3133956.3134035
   Kangara M. G. M., 2016, Proceedings - International Fertiliser Society, P1
   Kim S., 2011, PROC INT WORKSHOP AC, P1
   Kim S, 2018, DES AUT CON, DOI 10.1145/3195970.3196085
   Kleinbaum D. G., 2002, LOGISTIC REGRESSION
   Knudsen Jesper, 2008, NANGATE 45NM OPEN CE
   Kolodenker E, 2017, PROCEEDINGS OF THE 2017 ACM ASIA CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY (ASIA CCS'17), P599, DOI 10.1145/3052973.3053035
   Lv H, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON NETWORKING, ARCHITECTURE AND STORAGE (NAS)
   Lyda R, 2007, IEEE SECUR PRIV, V5, P40, DOI 10.1109/MSP.2007.48
   Maiorca D., 2017, P S APPL COMP ACM, P1718
   Miladinovic N., 2012, FLASH MEM SUMM
   Min D, 2018, IEEE COMPUT ARCHIT L, V17, P243, DOI 10.1109/LCA.2018.2883431
   Moore C, 2016, 2016 CYBERSECURITY AND CYBERFORENSICS CONFERENCE (CCC), P77, DOI 10.1109/CCC.2016.14
   OCZ Technology, 2012, PCI EXPR OCZ TECHN
   Park D., 2018, PROC USENIX C FILE S
   Park J, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317889
   Rho E, 2018, PROCEEDINGS OF THE 16TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES, P257
   ROSENBLUM M, 1992, ACM T COMPUT SYST, V10, P26, DOI 10.1145/146941.146943
   Scaife N, 2016, INT CON DISTR COMP S, P303, DOI 10.1109/ICDCS.2016.46
   Trend Micro, 2017, ER LIN RANS IMP SERV
   Wei XC, 2017, DES AUT CON, DOI 10.1145/306l639.3062207
   Wilson V., 2019, 24 RECENT RANSOMWARE
   Xilinx, 2019, ZCU102 EV BOARD US M
   Xilinx, ISE SIM ISIM
NR 42
TC 3
Z9 3
U1 6
U2 11
PD JUL
PY 2022
VL 41
IS 7
BP 2038
EP 2051
DI 10.1109/TCAD.2021.3099084
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Nguyen, S
   Salcic, Z
   Trivedi, U
   Zhang, XY
AF Nguyen, Sang
   Salcic, Zoran
   Trivedi, Utsav
   Zhang, Xuyun
GP IEEE
TI Predicting Parking Occupancy by FPGA-Accelerated DNN Models at Fog Layer
SO 2021 IEEE INTERNATIONAL CONFERENCE ON SMART COMPUTING (SMARTCOMP 2021)
DT Proceedings Paper
CT 7th IEEE International Conference on Smart Computing (SMARTCOMP)
CY AUG 23-27, 2021
CL ELECTR NETWORK
DE Fog computing; Deep Neural Network; FPGA accelerator; parking inferences
ID SYSTEM
AB Model inference is the final stage in machine/deep learning application deployments in practical applications. Hardware-implemented or accelerated model inferences find significant attractions as they offer faster inference than those implemented as programs. This is especially attractive for real-time applications. In this paper, we address models that serve for parking occupancy prediction based on historical time-series parking records. We use the Keras library to build and train software DNN and LSTM models, then compare their prediction performances in terms of accuracy. While the software-implemented inference models indicate advantages of LSTM, we still opted to select only DNN-based models for additional hardware acceleration as the current advanced tool-chains leveraged for automatic software-to-hardware model converting do not allow the creation of LSTM hardware-implemented models. We create, explore and compare the inference performances of hardware (FPGA)-implemented models on relatively low-cost FPGAs. For this, we create an FPGA-accelerated Fog-layer cluster by adding two additional Xilinx FPGA boards of different performances into our existing cluster of four Raspberry Pi (RPi) computers.
C1 [Nguyen, Sang; Salcic, Zoran; Trivedi, Utsav] Univ Auckland, Dept Elect Comp & Software Engn, Auckland, New Zealand.
   [Zhang, Xuyun] Macquarie Univ, Dept Comp, Sydney, NSW, Australia.
RP Nguyen, S (corresponding author), Univ Auckland, Dept Elect Comp & Software Engn, Auckland, New Zealand.
EM sugn565@aucklanduni.ac.nz; z.salcic@auckland.ac.nz;
   utri092@aucklanduni.ac.nz; xuyun.zhang@mq.edu.au
CR A Camero, 2018, INT C LEARN INT OPT
   Abe M, 2018, LECT NOTES ARTIF INT, V10937, P273, DOI 10.1007/978-3-319-93034-3_22
   Ali G, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9101696
   [Anonymous], 2021, HLS4ML STATUS FEATUR
   Awan FM, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20010322
   DH Stolfi, 2017, INT C SMART CIT
   Duarte J, 2018, J INSTRUM, V13, DOI 10.1088/1748-0221/13/07/P07027
   Gómez-Carmona O, 2020, FUTURE GENER COMP SY, V112, P670, DOI 10.1016/j.future.2020.06.013
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   J Du, 2020, IEEE T PARALLEL DIST
   Mohammed T, 2020, IEEE INFOCOM SER, P854, DOI [10.1109/INFOCOM41043.2020.9155237, 10.1109/infocom41043.2020.9155237]
   Ngadiuba J, 2021, MACH LEARN-SCI TECHN, V2, DOI 10.1088/2632-2153/aba042
   Nguyen S., 2020, IEEE INTERNET THINGS
   S Jiang, 2019, IEEE ACCESS
   Saharan S, 2020, FUTURE GENER COMP SY, V106, P622, DOI 10.1016/j.future.2020.01.031
   T Aarrestad, 2021, ARXIV210105108
   Vlahogianni EI, 2016, J INTELL TRANSPORT S, V20, P192, DOI 10.1080/15472450.2015.1037955
   XU ZCA, 2020, P 28 ACM INT C MULT, P3265, DOI DOI 10.1145/3394171.3414048
   Yi SH, 2015, 2015 THIRD IEEE WORKSHOP ON HOT TOPICS IN WEB SYSTEMS AND TECHNOLOGIES (HOTWEB), P73, DOI 10.1109/HotWeb.2015.22
   Zhang W, 2020, MEASUREMENT, V164, DOI 10.1016/j.measurement.2020.108052
NR 20
TC 0
Z9 0
U1 0
U2 1
PY 2021
BP 83
EP 88
DI 10.1109/SMARTCOMP52413.2021.00032
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Crilly, AJ
   Garin-Fernandez, I
   Appelbe, BD
   Chittenden, JP
AF Crilly, A. J.
   Garin-Fernandez, I.
   Appelbe, B. D.
   Chittenden, J. P.
TI Efficacy of inertial confinement fusion experiments in light ion fusion
   cross section measurement at nucleosynthesis relevant energies
SO FRONTIERS IN PHYSICS
DT Article
DE inertial confinement fusion (ICF); nuclear astrophysics; Bayesian
   inference; S factor; bare nuclear cross section; thermal reactivity; ion
   kinetic effects
ID DATA LIBRARY; CHAIN
AB Inertial confinement fusion (ICF) experiments create a unique laboratory environment in which thermonuclear fusion reactions occur within a plasma, with conditions comparable to stellar cores and the early universe. In contrast, accelerator-based measurements must compete with bound electron screening effects and beam stopping when measuring fusion cross sections at nucleosynthesis-relevant energies. Therefore, ICF experiments are a natural place to study nuclear reactions relevant to nuclear astrophysics. However, analysis of ICF-based measurements must address its own set of complicating factors. These include: the inherent range of reaction energies, spatial and temporal thermal temperature variation, and kinetic effects such as species separation. In this work we examine these phenomena and develop an analysis to quantify and, when possible, compensate for their effects on our inference. Error propagation in the analyses are studied using synthetic data combined with Markov Chain Monte Carlo (MCMC) machine learning. The novel inference techniques will aid in the extraction of valuable and accurate data from ICF-based nuclear astrophysics experiments.
C1 [Crilly, A. J.; Garin-Fernandez, I.; Appelbe, B. D.; Chittenden, J. P.] Imperial Coll, Ctr Inertial Fus Studies, Blackett Lab, London, England.
RP Crilly, AJ (corresponding author), Imperial Coll, Ctr Inertial Fus Studies, Blackett Lab, London, England.
EM ac116@ic.ac.uk
CR Adelberger EG, 2011, REV MOD PHYS, V83, P195, DOI 10.1103/RevModPhys.83.195
   [Anonymous], 1989, NEUTRINO ASTROPHYSIC
   Appelbe B, 2011, PLASMA PHYS CONTR F, V53, DOI 10.1088/0741-3335/53/4/045002
   Appelbe BD., 2022, PRIMARY NEUTRO UNPUB
   BAHCALL JN, 1966, ASTROPHYS J, V143, P259, DOI 10.1086/148497
   Ballabio L, 1998, NUCL FUSION, V38, P1723, DOI 10.1088/0029-5515/38/11/310
   Bellei C, 2014, PHYS PLASMAS, V21, DOI 10.1063/1.4876614
   BOSCH HS, 1992, NUCL FUSION, V32, P611, DOI 10.1088/0029-5515/32/4/I07
   BRYSK H, 1973, PLASMA PHYS CONTR F, V15, P611, DOI 10.1088/0032-1028/15/7/001
   Casella C, 2002, NUCL PHYS A, V706, P203, DOI 10.1016/S0375-9474(02)00749-2
   Casey DT, 2017, NAT PHYS, V13, P1227, DOI [10.1038/NPHYS4220, 10.1038/nphys4220]
   Chadwick MB, 2006, NUCL DATA SHEETS, V107, P2931, DOI 10.1016/j.nds.2006.11.001
   Clayton D. D., 1983, PRINCIPLES STELLAR E
   Foreman-Mackey D, 2013, PUBL ASTRON SOC PAC, V125, P306, DOI 10.1086/670067
   Goodman J, 2010, COMM APP MATH COM SC, V5, P65, DOI 10.2140/camcos.2010.5.65
   Hatarik R, 2018, REV SCI INSTRUM, V89, DOI 10.1063/1.5039372
   Higginson DP, 2019, PHYS PLASMAS, V26, DOI 10.1063/1.5048386
   Inglebert A, 2014, EPL-EUROPHYS LETT, V107, DOI 10.1209/0295-5075/107/65003
   Kabadi NV, 2021, PHYS PLASMAS, V28, DOI 10.1063/5.0032139
   Kagan G, 2014, PHYS LETT A, V378, P1531, DOI 10.1016/j.physleta.2014.04.005
   Leonard DS, 2006, PHYS REV C, V73, DOI 10.1103/PhysRevC.73.045801
   Mannion OM, 2020, NUCL INSTRUM METH A, V964, DOI 10.1016/j.nima.2020.163774
   Mannion OM., 2022, EVIDENCE NONMA UNPUB
   Mossa V, 2020, NATURE, V587, P210, DOI 10.1038/s41586-020-2878-4
   Munro DH, 2016, NUCL FUSION, V56, DOI 10.1088/0029-5515/56/3/036001
   Murphy TJ, 2014, PHYS PLASMAS, V21, DOI 10.1063/1.4885342
   Otuka N, 2014, NUCL DATA SHEETS, V120, P272, DOI 10.1016/j.nds.2014.07.065
   Rinderknecht HG, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.025001
   Spitaleri C, 2019, EUR PHYS J A, V55, DOI 10.1140/epja/i2019-12833-0
   Turkat S, 2021, PHYS REV C, V103, DOI 10.1103/PhysRevC.103.045805
   Kabadi NV, 2021, PHYS REV E, V104, DOI 10.1103/PhysRevE.104.L013201
   van Ravenzwaaij D, 2018, PSYCHON B REV, V25, P143, DOI 10.3758/s13423-016-1015-8
   WILLIAMS MM, 1971, J NUCL ENERGY, V25, P489, DOI 10.1016/0022-3107(71)90029-3
   Zylstra AB, 2020, PHYS REV C, V101, DOI 10.1103/PhysRevC.101.042802
   Zylstra AB, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.035002
NR 35
TC 0
Z9 0
U1 2
U2 3
PD SEP 20
PY 2022
VL 10
AR 937972
DI 10.3389/fphy.2022.937972
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Lu, AN
   Luo, YD
   Yu, SM
AF Lu, Anni
   Luo, Yandong
   Yu, Shimeng
TI An Algorithm-Hardware Co-Design for Bayesian Neural Network Utilizing
   SOT-MRAM's Inherent Stochasticity
SO IEEE JOURNAL ON EXPLORATORY SOLID-STATE COMPUTATIONAL DEVICES AND
   CIRCUITS
DT Article
DE Bayesian neural network (BayesNN); magnetic tunnel junction (MTJ);
   neural network hardware accelerator; probabilistic computing; random
   number generation
AB Probabilistic machine learning plays a central role in the domains such as decision-making and autonomous control benefitting from its ability of representing and manipulating uncertainty about models and predictions. Until now, there are few hardware considerations to address the intensive computation and true random number generation for Bayesian neural network (BayesNN), whose weights are represented by probability distributions. In this article, we propose to apply the local reparameterization trick to alleviate the burden of random number generators (RNGs), which could be implemented by utilizing the inherent random noise of spin-orbit torque magnetic random access memory (SOT-MRAM). Sampling strategies are discussed to significantly reduce the number of operations and parameters of BayesNN. A device-circuit-system benchmark framework is then developed to evaluate the effects of device nonidealities such as the bias and variation of switching probability. The evaluation on the CIFAR-10 dataset suggests that BayesNN could achieve comparable accuracy as conventional deep neural network (DNN) with acceptable hardware overhead but provide much better uncertainty calibration with respect to out-of-distribution (OOD) inputs (rotated images as the example).
C1 [Lu, Anni; Luo, Yandong; Yu, Shimeng] Georgia Inst Technol, Atlanta, GA 30332 USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR Blundell C, 2015, PR MACH LEARN RES, V37, P1613
   Cai RZ, 2018, ACM SIGPLAN NOTICES, V53, P476, DOI [10.1145/3173162.3173212, 10.1145/3296957.3173212]
   Camsari KY, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.031014
   Debashis P, 2018, IEEE MAGN LETT, V9, DOI 10.1109/LMAG.2018.2860547
   Doevenspeck J., 2021, 2021 Symposium on VLSI Technology
   Doevenspeck J, 2020, S VLSI TECH, DOI 10.1109/vlsitechnology18217.2020.9265099
   Fan HX, 2021, DES AUT CON, P1063, DOI 10.1109/DAC18074.2021.9586137
   Garello K, 2019, S VLSI TECH, pT194
   Garello K, 2018, SYMP VLSI CIRCUITS, P81, DOI 10.1109/VLSIC.2018.8502269
   Jia XT, 2021, IEEE T NEUR NET LEAR, V32, P1703, DOI 10.1109/TNNLS.2020.2987760
   Lin Y., 2019, IEDM, P14
   Lu AN, 2020, IEEE T VLSI SYST, V28, P1945, DOI 10.1109/TVLSI.2020.3001526
   Malhotra A, 2020, IEEE T NANOTECHNOL, V19, P328, DOI 10.1109/TNANO.2020.2982819
   Mulaosmanovic H, 2018, IEEE ELECTR DEVICE L, V39, P135, DOI 10.1109/LED.2017.2771818
   Ostwal V, 2019, IEEE MAGN LETT, V10, DOI 10.1109/LMAG.2019.2912971
   Peng XC, 2019, INT EL DEVICES MEET
   Wang H, 2016, IEEE T KNOWL DATA EN, V28, P3395, DOI 10.1109/TKDE.2016.2606428
   Welling M., 2015, ADV NEURAL INFORM PR, P2575
   Yamaoka M, 2016, IEEE J SOLID-ST CIRC, V51, P303, DOI 10.1109/JSSC.2015.2498601
   Yang KZ, 2020, IEEE T ELECTRON DEV, V67, P1340, DOI 10.1109/TED.2020.2968223
   Yu SM, 2021, IEEE CIRC SYST MAG, V21, P31, DOI 10.1109/MCAS.2021.3092533
NR 21
TC 4
Z9 4
U1 4
U2 10
PD JUN
PY 2022
VL 8
IS 1
BP 27
EP 34
DI 10.1109/JXCDC.2022.3177588
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Chiu, PF
   Choi, WH
   Ma, W
   Qin, MH
   Lueker-Boden, M
AF Chiu, Pi-Feng
   Choi, Won Ho
   Ma, Wen
   Qin, Minghai
   Lueker-Boden, Martin
GP IEEE
TI A Binarized Neural Network Accelerator with Differential Crosspoint
   Memristor Array for Energy-Efficient MAC Operations
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE Crosspoint memristor array; Binarized Neural Network (BNN); In-Memory
   Computing; Machine Learning
AB Binarized Neural Networks (BNN) significantly reduce computational complexity and relax memory requirements with binarized weights and activations. We propose a differential crosspoint (DX) memristor array for enabling parallel multiply-and-accumulate (MAC) operations in BNN to further improve the efficiency. Two differential memristors compose one synapse. The synapses on the same column form a voltage divider in which the output voltage corresponds linearly to the digital summation. The analog output voltage is then quantized to 4-bit output by a voltage sense amplifier. A small 64x64 DX array in every DX unit (DXU) minimizes parasitic resistance and capacitance for quicker MAC operations. A system architecture using DXUs for BNN acceleration is introduced. A wide range of BNN models can be mapped to an array of DXUs. To further reduce the energy spent on data movement, a neighbor shifting scheme increases the input data reusability. The effects of quantization and bit errors are investigated by running MNIST and CFAR-10 datasets. A DXU is able to achieve an estimated energy efficiency of 160 TMAC/s/W.
C1 [Chiu, Pi-Feng; Choi, Won Ho; Ma, Wen; Qin, Minghai; Lueker-Boden, Martin] Western Digital, San Jose, CA 95119 USA.
RP Chiu, PF (corresponding author), Western Digital, San Jose, CA 95119 USA.
EM pi-feng.chiu@wdc.com
CR Bankman D, 2018, ISSCC DIG TECH PAP I, P222, DOI 10.1109/ISSCC.2018.8310264
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chiu PF, 2016, IEEE ASIAN SOLID STA, P181, DOI 10.1109/ASSCC.2016.7844165
   Chiu PF, 2015, IEEE T CIRCUITS-II, V62, P461, DOI 10.1109/TCSII.2014.2385431
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Liu R, 2014, 2014 INTERNATIONAL SYMPOSIUM ON ANTENNAS AND PROPAGATION (ISAP), P1, DOI 10.1109/ISANP.2014.7026480
   Pogue BW, 2004, TECHNOL CANCER RES T, V3, P15, DOI 10.1177/153303460400300102
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Sun XY, 2018, ASIA S PACIF DES AUT, P574, DOI 10.1109/ASPDAC.2018.8297384
   Zisserman A., 2014, 14091556 ARXIV
NR 12
TC 6
Z9 6
U1 1
U2 3
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Chen, XH
   Zhao, Y
   Wang, Y
   Xu, PF
   You, HR
   Li, CJ
   Fu, YG
   Lin, YY
   Wang, ZY
AF Chen, Xiaohan
   Zhao, Yang
   Wang, Yue
   Xu, Pengfei
   You, Haoran
   Li, Chaojian
   Fu, Yonggan
   Lin, Yingyan
   Wang, Zhangyang
TI SmartDeal: Remodeling Deep Network Weights for Efficient Inference and
   Training
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Training; Matrix decomposition; Costs; Quantization (signal); Inference
   algorithms; Random access memory; Hardware acceleration; Data movement;
   deep network training; efficient machine learning; hardware accelerator
ID NEURAL-NETWORKS; ACCELERATOR
AB The record-breaking performance of deep neural networks (DNNs) comes with heavy parameter budgets, which leads to external dynamic random access memory (DRAM) for storage. The prohibitive energy of DRAM accesses makes it nontrivial for DNN deployment on resource-constrained devices, calling for minimizing the movements of weights and data in order to improve the energy efficiency. Driven by this critical bottleneck, we present SmartDeal, a hardware-friendly algorithm framework to trade higher-cost memory storage/access for lower-cost computation, in order to aggressively boost the storage and energy efficiency, for both DNN inference and training. The core technique of SmartDeal is a novel DNN weight matrix decomposition framework with respective structural constraints on each matrix factor, carefully crafted to unleash the hardware-aware efficiency potential. Specifically, we decompose each weight tensor as the product of a small basis matrix and a large structurally sparse coefficient matrix whose nonzero elements are readily quantized to the power-of-2. The resulting sparse and readily quantized DNNs enjoy greatly reduced energy consumption in data movement as well as weight storage, while incurring minimal overhead to recover the original weights thanks to the required sparse bit-operations and cost-favorable computations. Beyond inference, we take another leap to embrace energy-efficient training, by introducing several customized techniques to address the unique roadblocks arising in training while preserving the SmartDeal structures. We also design a dedicated hardware accelerator to fully utilize the new weight structure to improve the real energy efficiency and latency performance. We conduct experiments on both vision and language tasks, with nine models, four datasets, and three settings (inference-only, adaptation, and fine-tuning). Our extensive results show that 1) being applied to inference, SmartDeal achieves up to 2.44x improvement in energy efficiency as evaluated using real hardware implementations and 2) being applied to training, SmartDeal can lead to 10.56x and 4.48x reduction in the storage and the training energy cost, respectively, with usually negligible accuracy loss, compared to state-of-the-art training baselines. Our source codes are available at: https://github.com/VITA-Group/SmartDeal.
C1 [Chen, Xiaohan; Wang, Zhangyang] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
   [Zhao, Yang; Wang, Yue; Xu, Pengfei; You, Haoran; Li, Chaojian; Fu, Yonggan; Lin, Yingyan] Rice Univ, Dept Elect & Comp Engn, Houston, TX 77005 USA.
RP Chen, XH (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM xiaohan.chen@utexas.edu; zy34@rice.edu; atlaswang@utexas.edu;
   px5@rice.edu; hy34@rice.edu; cl114@rice.edu; yf22@rice.edu;
   yingyan.lin@rice.edu
CR Albericio J, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P382, DOI 10.1145/3123939.3123982
   Ba LJ, 2014, ADV NEURAL INFORM PR, V3, P2654, DOI DOI 10.5555/2969033.2969123
   Banner R., 2018, ADV NEURAL INFORM PR, P5151, DOI DOI 10.5555/3327345.3327421
   Bernstein J., 2018, ARXIV180204434, V80, P560
   Brostow GJ, 2008, LECT NOTES COMPUT SC, V5302, P44, DOI 10.1007/978-3-540-88682-2_5
   Brown T., 2020, PROC ADV NEUR INF PR, P1877
   Chaojian Li, 2020, Computer Vision - ECCV 2020. 16th European Conference. Proceedings. Lecture Notes in Computer Science (LNCS 12354), P500, DOI 10.1007/978-3-030-58545-7_29
   Chen, 2020, ARXIV200712223
   Chen, 2020, ARXIV201206908
   Chen LC, 2018, IEEE T PATTERN ANAL, V40, P834, DOI 10.1109/TPAMI.2017.2699184
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Esser Steven K, 2019, ARXIV190208153
   Fu Y.`, 2020, ADV NEURAL INFORM PR, P12127
   Gong RH, 2019, IEEE I CONF COMP VIS, P4851, DOI 10.1109/ICCV.2019.00495
   Gong Y., 2014, ARXIV14126115
   Gui S., 2019, ADVERSARIALLY TRAINE
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Han S, 2015, ADV NEUR IN, V28
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Helwegen K., 2019, ADV NEURAL INFORM PR, P7531
   Hinton G., 2015, ARXIV150302531, DOI DOI 10.4140/TCP.N.2015.249
   Howard A. G., 2017, ARXIV
   Hu T.-K., 2020, ARXIV200210025
   Huang HT, 2018, IEEE T NANOTECHNOL, V17, P645, DOI 10.1109/TNANO.2017.2732698
   Izmailov P, 2018, UNCERTAINTY IN ARTIFICIAL INTELLIGENCE, P876
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim C, 2019, ISSCC DIG TECH PAP I, V62, P136, DOI [10.1109/isscc.2019.8662447, 10.1109/ISSCC.2019.8662447]
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lascorz AD, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P749, DOI 10.1145/3297858.3304041
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Liu Z, 2017, IEEE I CONF COMP VIS, P2755, DOI 10.1109/ICCV.2017.298
   Luo JH, 2017, IEEE I CONF COMP VIS, P5068, DOI 10.1109/ICCV.2017.541
   Mao HZ, 2017, IEEE COMPUT SOC CONF, P1927, DOI 10.1109/CVPRW.2017.241
   Marcus Mitchell P., 1993, COMPUT LINGUIST, V19, P313, DOI DOI 10.21236/ADA273556
   Micikevicius P., 2018, P 6 INT C LEARN REPR, P1, DOI DOI 10.1109/CAMAD.2018.8514963
   Mishra A., 2018, P INT C LEARN REPR I
   Novikov A., 2015, ADV NEURAL INFORM PR, P442, DOI DOI 10.5555/2969239.2969289
   NVIDIA, NVIDIA JETSON TX2 DE
   NVIDIA, NVIDIA TESL V100 TEN
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Polino A., 2018, ARXIV180205668
   Qin ZD, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8010078
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Shen JH, 2020, AAAI CONF ARTIF INTE, V34, P5700
   Synopsys, PRIMETIME PX SIGN PO
   Tailor S. A., 2021, P INT C LEARN REPR
   Tan MX, 2019, PR MACH LEARN RES, V97
   Tung F, 2018, PROC CVPR IEEE, P7873, DOI 10.1109/CVPR.2018.00821
   Wang, 2019, ADV NEURAL INFORM PR, P5139
   Wang H., 2020, ECCV, P54, DOI DOI 10.1007/978
   Wang K, 2019, PROC CVPR IEEE, P8604, DOI [10.1109/CVPR.2019.01218, 10.1109/CVPR.2019.00881]
   Wang M., 2018, ARXIV181108589
   Wang N., 2018, ADV NEURAL INFORM PR, P7675, DOI DOI 10.1109/THERMINIC.2018.8593303
   Wang X, 2018, LECT NOTES COMPUT SC, V11217, P420, DOI 10.1007/978-3-030-01261-8_25
   Wang Y, 2020, IEEE J-STSP, V14, P623, DOI 10.1109/JSTSP.2020.2979669
   Wen W, 2016, ADV NEUR IN, V29
   Wu JR, 2018, PR MACH LEARN RES, V80
   Xilinx Inc, AVNET ULTRA96
   YANG G, 2019, ARXIV190411943
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P369, DOI 10.1145/3373376.3378514
   Yang YK, 2020, NEURAL NETWORKS, V125, P70, DOI 10.1016/j.neunet.2019.12.027
   You, 2020, ARXIV201012785
   You Haoran, 2019, ARXIV190911957
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Yu XY, 2017, PROC CVPR IEEE, P67, DOI 10.1109/CVPR.2017.15
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang Peizhao, 2018, ARXIV181200090
   Zhao Y, 2020, ANN I S COM, P954, DOI 10.1109/ISCA45697.2020.00082
   Zhou S., 2016, ARXIV160606160
   Zhou XD, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P15, DOI 10.1109/MICRO.2018.00011
NR 75
TC 0
Z9 0
U1 0
U2 3
PD OCT
PY 2023
VL 34
IS 10
BP 7099
EP 7113
DI 10.1109/TNNLS.2021.3138056
EA MAR 2022
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Puyati, W
   Khawne, A
   Barnes, M
   Zwan, B
   Greer, P
   Fuangrod, T
AF Puyati, Wayo
   Khawne, Amnach
   Barnes, Michael
   Zwan, Benjamin
   Greer, Peter
   Fuangrod, Todsaporn
TI Predictive quality assurance of a linear accelerator based on the
   machine performance check application using statistical process control
   and ARIMA forecast modeling
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE autoregressive integrated moving average forecast modeling; machine
   performance check; predictive quality assurance; statistical process
   control
ID VERIFICATION; STABILITY; SYMMETRY
AB Purpose A predictive linac quality assurance system based on the output of the Machine Performance Check (MPC) application was developed using statistical process control and autoregressive integrated moving average forecast modeling. The aim of this study is to demonstrate the feasibility of predictive quality assurance based on MPC tests that allow proactive preventative maintenance procedures to be carried out to better ensure optimal linac performance and minimize downtime. Method and Materials Daily MPC data were acquired for a total of 490 measurements. The initial 85% of data were used in prediction model learning with the autoregressive integrated moving average technique and in calculating upper and lower control limits for statistical process control analysis. The remaining 15% of data were used in testing the accuracy of the predictions of the proposed system. Two types of prediction were studied, namely, one-step-ahead values for predicting the next day's quality assurance results and six-step-ahead values for predicting up to a week ahead. Results that fall within the upper and lower control limits indicate a normal stage of machine performance, while the tolerance, determined from AAPM TG-142, is the clinically required performance. The gap between the control limits and the clinical tolerances (as the warning stage) provides a window of opportunity for rectifying linac performance issues before they become clinically significant. The accuracy of the predictive model was tested using the root-mean-square error, absolute error, and average accuracy rate for all MPC test parameters. Results The accuracy of the predictive model is considered high (average root-mean-square error and absolute error for all parameters of less than 0.05). The average accuracy rate for indicating the normal/warning stages was higher than 85.00%. Conclusion Predictive quality assurance with the MPC will allow preventative maintenance, which could lead to improved linac performance and a reduction in unscheduled linac downtime.
C1 [Puyati, Wayo; Khawne, Amnach] King Mongkuts Inst Technol Ladkrabang, Fac Engn, Dept Comp Engn, Bangkok 10520, Thailand.
   [Puyati, Wayo] Ubon Ratchathani Univ, Fac Sci, Dept Math Stat & Comp, Ubon Ratchathani 34190, Thailand.
   [Barnes, Michael; Greer, Peter] Calvary Mater Hosp Newcastle, Dept Radiat Oncol, Newcastle, NSW 2298, Australia.
   [Barnes, Michael; Zwan, Benjamin; Greer, Peter] Univ Newcastle, Sch Math & Phys Sci, Newcastle, NSW 2308, Australia.
   [Zwan, Benjamin] Gosford Hosp, Cent Coast Canc Ctr, Gosford, NSW 2250, Australia.
   [Fuangrod, Todsaporn] Chulabhorn Royal Acad, HRH Princess Chulabhorn Coll Med Sci, Fac Med & Publ Hlth, Bangkok 10210, Thailand.
RP Fuangrod, T (corresponding author), Chulabhorn Royal Acad, HRH Princess Chulabhorn Coll Med Sci, Fac Med & Publ Hlth, Bangkok 10210, Thailand.
EM Todsaporn.fua@pccms.ac.th
CR Able C, 2012, MED PHYS, V39, P3750, DOI 10.1118/1.4735265
   Able C, 2012, MED PHYS, V39, P3751, DOI 10.1118/1.4735268
   Able CM, 2011, RADIAT ONCOL, V6, DOI 10.1186/1748-717X-6-180
   Barnes MP, 2018, J APPL CLIN MED PHYS, V19, P68, DOI 10.1002/acm2.12445
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P56, DOI 10.1002/acm2.12072
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P200, DOI 10.1002/acm2.12064
   Barnes MP, 2017, J APPL CLIN MED PHYS, V18, P139, DOI 10.1002/acm2.12016
   Binny D, 2019, J APPL CLIN MED PHYS, V20, P71, DOI 10.1002/acm2.12547
   Binny D, 2017, PHYS MEDICA, V38, P105, DOI 10.1016/j.ejmp.2017.05.052
   Bissonnette JP, 2012, MED PHYS, V39, P1946, DOI 10.1118/1.3690466
   Burnham KP., 2002, MODEL SELECTION MULT, DOI 10.1007/978-0-387-22456-5_2
   Clivio A, 2015, RADIAT ONCOL, V10, DOI 10.1186/s13014-015-0381-0
   Fuangrod T, 2016, RADIAT ONCOL, V11, DOI 10.1186/s13014-016-0682-y
   GEURTS M, 1977, J MARKETING RES, V14, P269, DOI 10.2307/3150485
   Greer PB, 2003, MED PHYS, V30, P1618, DOI 10.1118/1.1582469
   Hampton CJ, 2010, INT J RADIAT ONCOL, V78, pS71, DOI 10.1016/j.ijrobp.2010.07.198
   King BW, 2011, AUSTRALAS PHYS ENG S, V34, P459, DOI 10.1007/s13246-011-0106-0
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Li QG, 2017, ANN NY ACAD SCI, V1387, P84, DOI 10.1111/nyas.13215
   Li YT, 2018, J APPL CLIN MED PHYS, V19, P375, DOI 10.1002/acm2.12391
   López-Tarjuelo J, 2015, PHYS MEDICA, V31, P493, DOI 10.1016/j.ejmp.2015.05.006
   Louwe RJW, 2004, MED PHYS, V31, P2989, DOI 10.1118/1.1803751
   Nijsten SMJJG, 2007, MED PHYS, V34, P3872, DOI 10.1118/1.2776244
   Qin Y, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P2627
   Shewhart W.A, 1939, STAT METHOD VIEWPOIN
   Smith K, 2017, J APPL CLIN MED PHYS, V18, P23, DOI 10.1002/acm2.12080
   Van Esch A, 2004, RADIOTHER ONCOL, V71, P223, DOI 10.1016/j.radonc.2004.02.018
   Wheeler DJ, 1995, ADV TOPICS STAT PROC, V470
   Winkler P, 2005, MED PHYS, V32, P3095, DOI 10.1118/1.2040711
NR 29
TC 6
Z9 8
U1 0
U2 6
PD AUG
PY 2020
VL 21
IS 8
BP 73
EP 82
DI 10.1002/acm2.12917
EA JUN 2020
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Lu, XY
   Jordan, KE
   Wheeler, MF
   Pyzer-Knapp, EO
   Benatan, M
AF Lu, Xueying
   Jordan, Kirk E.
   Wheeler, Mary F.
   Pyzer-Knapp, Edward O.
   Benatan, Matthew
TI Bayesian Optimization for Field-Scale Geological Carbon Storage
SO ENGINEERING
DT Article
DE Compositional flow; Bayesian optimization; Geological carbon storage;
   CCUS; Machine learning; AI for science
ID CO2 STORAGE; FLOW; PERMEABILITY; HYSTERESIS; ALGORITHMS
AB We present a framework that couples a high-fidelity compositional reservoir simulator with Bayesian optimization (BO) for injection well scheduling optimization in geological carbon sequestration. This work represents one of the first at tempts to apply BO and high-fidelity physics models to geological carbon storage. The implicit parallel accurate reservoir simulator (IPARS) is utilized to accurately capture the underlying physical processes during CO2 sequestration. IPARS provides a framework for several flow and mechanics models and thus supports both stand-alone and coupled simulations. In this work, we use the compositional flow module to simulate the geological carbon storage process. The compositional flow model, which includes a hysteretic three-phase relative permeability model, accounts for three major CO2 trapping mechanisms: structural trapping, residual gas trapping, and solubility trapping. Furthermore, IPARS is coupled to the International Business Machines (IBM) Corporation Bayesian Optimization Accelerator (BOA) for parallel optimizations of CO2 injection strategies during field-scale CO2 sequestration. BO builds a probabilistic surrogate for the objective function using a Bayesian machine learning algorithm-the Gaussian process regression, and then uses an acquisition function that leverages the uncertainty in the surrogate to decide where to sample. The IBM BOA addresses the three weaknesses of standard BO that limits its scalability in that IBM BOA supports parallel (batch) executions, scales better for high-dimensional problems, and is more robust to initializations. We demonstrate these merits by applying the algorithm in the optimization of the CO2 injection schedule in the Cranfield site in Mississippi, USA, using field data. The optimized injec-tion schedule achieves 16% more gas storage volume and 56% less water/surfactant usage compared with the baseline. The performance of BO is compared with that of a genetic algorithm (GA) and a covariance matrix adaptation (CMA)-evolution strategy (ES). The results demonstrate the superior performance of BO, in that it achieves a competitive objective function value with over 60% fewer forward model evaluations.(c) 2022 THE AUTHORS. Published by Elsevier LTD on behalf of Chinese Academy of Engineering and Higher Education Press Limited Company. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/).
C1 [Lu, Xueying; Wheeler, Mary F.] Univ Texas Austin, Oden Inst Computat Engn & Sci, Ctr Subsurface Modeling, Austin, TX 78712 USA.
   [Jordan, Kirk E.; Pyzer-Knapp, Edward O.; Benatan, Matthew] IBM Res United Kingdom, Warrington WA4 4AD, England.
RP Lu, XY (corresponding author), Univ Texas Austin, Oden Inst Computat Engn & Sci, Ctr Subsurface Modeling, Austin, TX 78712 USA.
EM xylu@utexas.edu
CR Abdollahzadeh A, 2012, SPE J, V17, P865, DOI 10.2118/143290-PA
   [Anonymous], 2012, NEURIPS, DOI DOI 10.5555/2999325.2999464
   Bangerth W, 2006, COMPUTAT GEOSCI, V10, P303, DOI 10.1007/s10596-006-9025-7
   Beygi MR, 2015, SPE J, V20, P21, DOI 10.2118/165324-PA
   Brochu E, 2010, Arxiv, DOI [arXiv:1012.2599, DOI 10.48550/ARXIV.1012.2599]
   Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Calandra R, 2016, ANN MATH ARTIF INTEL, V76, P5, DOI 10.1007/s10472-015-9463-9
   Cappa F, 2011, GEOPHYS RES LETT, V38, DOI 10.1029/2011GL048487
   [陈至立 CHEN Zhili], 2006, [中国软科学, China Soft Science], P1
   Class H, 2009, COMPUTAT GEOSCI, V13, P409, DOI 10.1007/s10596-009-9146-x
   Delshad M, 2011, P SPE RES SIM S 2011
   Delshad M, 2013, INT J GREENH GAS CON, V18, P463, DOI 10.1016/j.ijggc.2013.03.019
   Fonseca RRM, 2017, INT J NUMER METH ENG, V109, P1756, DOI 10.1002/nme.5342
   Fortin FA, 2012, J MACH LEARN RES, V13, P2171
   Ganis B, 2017, COMPUTAT GEOSCI, V21, P1189, DOI 10.1007/s10596-017-9683-7
   Frazier PI, 2018, Arxiv, DOI [arXiv:1807.02811, DOI 10.48550/ARXIV.1807.02811]
   iea, 2021, US
   Jasrasaria D, 2019, ADV INTELL SYST COMP, V858, P1, DOI 10.1007/978-3-030-01174-1_1
   Kulkarni MM, 2005, J PETROL SCI ENG, V48, P1, DOI 10.1016/j.petrol.2005.05.001
   Kumar A, 2005, SPE J, V10, P336, DOI 10.2118/89343-PA
   Kumar A, 2004, DISSERTATION
   Li HY, 2020, J COMPUT PHYS, V403, DOI [10.1016/j.jcp.2019.10.9074, 10.1016/j.jcp.2019.109074]
   Liu Y, ENGINEERING
   Lizotte DJ, 2008, DISSERTATION
   Lotfollahi M, 2017, TRANSPORT POROUS MED, V116, P687, DOI 10.1007/s11242-016-0796-6
   Lu X, 2019, P SPE RESERVOIR SIMU
   Lu X, 2018, P SPE IMPR OIL REC C
   Lu XY, 2020, J COMPUT PHYS, V401, DOI 10.1016/j.jcp.2019.109053
   Ma K, 2015, SPE J, V20, P453, DOI 10.2118/169104-PA
   Marchant R, 2012, IEEE INT C INT ROBOT, P2242, DOI 10.1109/IROS.2012.6385653
   Matern B., 1986, SPATIAL VARIATION
   Hernández-Lobato JM, 2017, PR MACH LEARN RES, V70
   Mikelic A, 2014, COMPUTAT GEOSCI, V18, P325, DOI 10.1007/s10596-013-9393-8
   Min B, 2018, J PETROL SCI ENG, V170, P244, DOI 10.1016/j.petrol.2018.06.035
   Mockus J., 1978, Towards global optimisation. II, P117
   Navarre-Sitchler AK, 2013, ADV WATER RESOUR, V53, P45, DOI 10.1016/j.advwatres.2012.10.005
   Nwachukwu A., 2018, SPE IMPR OIL REC C
   Onwunalu JE, 2010, COMPUTAT GEOSCI, V14, P183, DOI 10.1007/s10596-009-9142-1
   PENG D, 1976, IND ENG CHEM FUND, V15, P59, DOI 10.1021/i160057a011
   Shahriari B, 2016, P IEEE, V104, P148, DOI 10.1109/JPROC.2015.2494218
   Singh G, 2016, COMPUTAT GEOSCI, V20, P421, DOI 10.1007/s10596-015-9535-2
   Stein ML., 1999, INTERPOLATION SPATIA, DOI 10.1007/978-1-4612-1494-6
   Tang M, 2020, J COMPUT PHYS, V413, DOI 10.1016/j.jcp.2020.109456
   Thomas SG, 2009, DISSERTATION
   Wheeler MF, 2010, PROCEEDINGS OF THE INTERNATIONAL CONGRESS OF MATHEMATICIANS, VOL IV: INVITED LECTURES, P2864
   White D, 2017, SPE RESERVOIR SIMULA, P1
   Zandvliet MJ, 2008, SPE J, V13, P392, DOI 10.2118/105797-PA
   Zhang K, 2010, J PETROL SCI ENG, V73, P220, DOI 10.1016/j.petrol.2010.07.002
   Zhao XL, 2016, J NAT GAS SCI ENG, V29, P275, DOI 10.1016/j.jngse.2015.12.044
   Zhao XL, 2014, J ENERGY INST, V87, P297, DOI 10.1016/j.joei.2014.03.032
   Zhu YH, 2018, J COMPUT PHYS, V366, P415, DOI 10.1016/j.jcp.2018.04.018
   Zoback MD, 2012, P NATL ACAD SCI USA, V109, P10164, DOI 10.1073/pnas.1202473109
NR 52
TC 1
Z9 1
U1 4
U2 14
PD NOV
PY 2022
VL 18
BP 96
EP 104
DI 10.1016/j.eng.2022.06.011
WC Engineering, Multidisciplinary
DA 2023-11-11
ER

PT C
AU Rybalkin, V
   Bukhari, SS
   Ghaffar, MM
   Ghafoor, A
   Wehn, N
   Dengel, A
AF Rybalkin, Vladimir
   Bukhari, Syed Saqib
   Ghaffar, Muhammad Mohsin
   Ghafoor, Aqib
   Wehn, Norbert
   Dengel, Andreas
GP ACM
TI <i>i</i>DocChip - A Configurable Hardware Architecture for Historical
   Document Image Processing: Percentile Based Binarization
SO PROCEEDINGS OF THE ACM SYMPOSIUM ON DOCUMENT ENGINEERING (DOCENG 2018)
DT Proceedings Paper
CT 18th ACM Symposium on Document Engineering (DocEng)
CY AUG 28-31, 2018
CL Halifax, CANADA
DE Optical Character Recognition; FPGA; Binarization; Hardware-Software
   Co-Design; Zynq; Hardware Architecture; Machine Learning
AB End-to-end Optical Character Recognition (OCR) systems are heavily used to convert document images into machine-readable text. Commercial and open-source OCR systems (like Abbyy, OCRopus, Tesseract etc.) have traditionally been optimized for contemporary documents like books, letters, memos, and other end-user documents. However, these systems are difficult to use equally well for digitizing historical document images, which contain degradations like non-uniform shading, bleed-through, and irregular layout; such degradations usually do not exist in contemporary document images.
   The open-source anyOCR is an end-to-end OCR pipeline, which contains state-of-the-art techniques that are required for digitizing degraded historical archives with high accuracy. However, high accuracy comes at a cost of high computational complexity that results in 1) long runtime that limits digitization of big collection of historical archives and 2) high energy consumption that is the most critical limiting factor for portable devices with constrained energy budget. Therefore, we are targeting energy efficient and high throughput acceleration of the anyOCR pipeline. General-purpose computing platforms fail to meet these requirements that makes custom hardware design mandatory. In this paper, we are presenting a new concept named iDocChip. It is a portable hybrid hardware-software FPGA-based accelerator that is characterized by low footprint meaning small size, high power efficiency that will allow using it in portable devices, and high throughput that will make it possible to process big collection of historical archives in real time without effecting the accuracy.
   In this paper, we focus on binarization, which is the second most critical step in the anyOCR pipeline after text-line recognizer that we have already presented in our previous publication [21]. The anyOCR system makes use of a Percentile Based Binarization method that is suitable for overcoming degradations like non-uniform shading and bleed-through. To the best of our knowledge, we propose the first hardware architecture of the PBB technique. Based on the new architecture, we present a hybrid hardware-software FPGA-based accelerator that outperforms the existing anyOCR software implementation running on i7-4790T in terms of runtime by factor of 21, while achieving energy efficiency of 10 Images/J that is higher than that achieved by low power embedded processors with negligible loss of recognition accuracy.
C1 [Rybalkin, Vladimir; Ghaffar, Muhammad Mohsin; Wehn, Norbert] Univ Kaiserslautern, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
   [Bukhari, Syed Saqib; Dengel, Andreas] Univ Kaiserslautern, German Res Ctr Artificial Intelligence DFKI, Kaiserslautern, Germany.
   [Ghafoor, Aqib] Univ Kaiserslautern, Kaiserslautern, Germany.
RP Rybalkin, V (corresponding author), Univ Kaiserslautern, Microelect Syst Design Res Grp, Kaiserslautern, Germany.
EM rybalkin@eit.uni-kl.de; saqib.bukhari@dfki.de; ghaffar@eit.uni-kl.de;
   aaqibghafoor@gmail.com; wehn@eit.uni-kl.de; andreas.dengel@dfki.de
CR Afzal MZ, 2014, LECT NOTES COMPUT SC, V8357, P139, DOI 10.1007/978-3-319-05167-3_11
   ALVAREZ L, 1994, SIAM J NUMER ANAL, V31, P590, DOI 10.1137/0731032
   [Anonymous], 2011, INT J COMPUT APPL
   [Anonymous], 2011, INT J COMPUT APPL
   Breuel TM, 2013, PROC INT CONF DOC, P683, DOI 10.1109/ICDAR.2013.140
   Bukhari Syed Saqib, 2017, 14 IAPR INT C DOC AN
   Faure Claudie, 2009, COMP NIBLACK INSPIRE, DOI [10.1117/12.805827, DOI 10.1117/12.805827]
   Garg Naresh, 2013, INT J COMPUTER APPL, V71, P8, DOI 10.5120/12320-8533
   Graves Alex, 2006, P 23 INT C MACH LEAR, P369, DOI DOI 10.1145/1143844.1143891
   He J, 2005, PROC INT CONF DOC, P538, DOI 10.1109/ICDAR.2005.3
   Kavallieratou E, 2006, INT C PATT RECOG, P742
   Kawakami K., 2008, SUPERVISED SEQUENCE
   Kheiri F., 2017, ARXIVCSCV171005749
   Najafi MH, 2016, IEEE T VLSI SYST, V24, P808, DOI 10.1109/TVLSI.2015.2415932
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rybalkin V, 2017, DES AUT TEST EUROPE, P1390, DOI 10.23919/DATE.2017.7927210
   Sauvola J, 1997, PROC INT CONF DOC, P147, DOI 10.1109/ICDAR.1997.619831
   WAGNER RA, 1974, J ACM, V21, P168, DOI 10.1145/321796.321811
   YANG JD, 1994, PATTERN RECOGN LETT, V15, P141, DOI 10.1016/0167-8655(94)90043-4
   Yousefi MR, 2015, PROC INT CONF DOC, P1121, DOI 10.1109/ICDAR.2015.7333935
   Yousefi MR, 2015, PROC SPIE, V9402, DOI 10.1117/12.2075930
NR 21
TC 0
Z9 0
U1 0
U2 1
PY 2018
DI 10.1145/3209280.3209538
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Shao, RL
   He, HY
   Chen, ZW
   Liu, H
   Liu, DB
AF Shao, Rulin
   He, Hongyu
   Chen, Ziwei
   Liu, Hui
   Liu, Dianbo
TI Stochastic Channel-Based Federated Learning With Neural Network Pruning
   for Medical Data Privacy Preservation: Model Development and
   Experimental Validation
SO JMIR FORMATIVE RESEARCH
DT Article
DE federated learning; differential privacy preserving; neural network
   pruning; health care; privacy; medical data; machine learning; neural
   network
AB Background: Artificial neural networks have achieved unprecedented success in the medical domain. This success depends on the availability of massive and representative datasets. However, data collection is often prevented by privacy concerns, and people want to take control over their sensitive information during both the training and using processes.
   Objective: To address security and privacy issues, we propose a privacy-preserving method for the analysis of distributed medical data. The proposed method, termed stochastic channel-based federated learning (SCBFL), enables participants to train a high-performance model cooperatively and in a distributed manner without sharing their inputs.
   Methods: We designed, implemented, and evaluated a channel-based update algorithm for a central server in a distributed system. The update algorithm will select the channels with regard to the most active features in a training loop, and then upload them as learned information from local datasets. A pruning process, which serves as a model accelerator, was further applied to the algorithm based on the validation set.
   Results: We constructed a distributed system consisting of 5 clients and 1 server. Our trials showed that the SCBFL method can achieve an area under the receiver operating characteristic curve (AUC-ROC) of 0.9776 and an area under the precision-recall curve (AUC-PR) of 0.9695 with only 10% of channels shared with the server. Compared with the federated averaging algorithm, the proposed SCBFL method achieved a 0.05388 higher AUC-ROC and 0.09695 higher AUC-PR. In addition, our experiment showed that 57% of the time is saved by the pruning process with only a reduction of 0.0047 in AUC-ROC performance and a reduction of 0.0068 in AUC-PR performance.
   Conclusions: In this experiment, our model demonstrated better performance and a higher saturating speed than the federated averaging method, which reveals all of the parameters of local models to the server. The saturation rate of performance could be promoted by introducing a pruning process and further improvement could be achieved by tuning the pruning rate.
C1 [Shao, Rulin] Xi An Jiao Tong Univ, Dept Math & Stat, Xian, Peoples R China.
   [He, Hongyu] Xi An Jiao Tong Univ, Dept Elect Engn, Xian, Peoples R China.
   [Chen, Ziwei] Beijing Jiaotong Univ, Beijing, Peoples R China.
   [Liu, Hui] Mianyang Vocat Coll, Dept Math, Mianyang, Sichuan, Peoples R China.
   [Liu, Dianbo] MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
RP Liu, DB (corresponding author), MIT, Comp Sci & Artificial Intelligence Lab, 77 Massachusetts Ave, Cambridge, MA 02139 USA.
EM dianbo@mit.edu
CR Abadi M, 2016, CCS'16: PROCEEDINGS OF THE 2016 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P308, DOI 10.1145/2976749.2978318
   Abouelmehdi K, 2018, J BIG DATA-GER, V5, DOI 10.1186/s40537-017-0110-7
   Adam Nabil, 2007, AMIA Annu Symp Proc, P1
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2006, L DIVERSITY PRIVACY, DOI DOI 10.1109/ICDE.2006.1
   Bagdasaryan E, 2020, PR MACH LEARN RES, V108, P2938
   Bassily R, 2014, ANN IEEE SYMP FOUND, P464, DOI 10.1109/FOCS.2014.56
   Bertino E, 2005, PROC INT CONF DATA, P521
   Bonawitz K., 2019, MLSYS
   Bonawitz K, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1175, DOI 10.1145/3133956.3133982
   Chilimbi T., 2014, 11 USENIX S OPERATIN, P571, DOI DOI 10.1108/01439911111122716
   Craig Terence, 2011, PRIVACY BIG DATA PLA
   Dwork C, 2006, LECT NOTES COMPUT SC, V3876, P265, DOI 10.1007/11681878_14
   Dwork C, 2013, FOUND TRENDS THEOR C, V9, P211, DOI 10.1561/0400000042
   Dwork C, 2010, ACM S THEORY COMPUT, P715
   Dwork C, 2010, ANN IEEE SYMP FOUND, P51, DOI 10.1109/FOCS.2010.12
   Fredrikson M, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1322, DOI 10.1145/2810103.2813677
   Geyer R. C., 2017, ARXIV
   Han HG, 2010, IEEE T FUZZY SYST, V18, P1129, DOI 10.1109/TFUZZ.2010.2070841
   Hard A, 2019, Arxiv, DOI arXiv:1811.03604
   He YH, 2017, IEEE I CONF COMP VIS, P1398, DOI 10.1109/ICCV.2017.155
   Hu HY, 2016, Arxiv, DOI [arXiv:1607.03250, 10.48550/arXiv.1607.03250]
   Hundepool A, 1997, RECORD LINKAGE TECHN
   Jain Priyank, 2016, Journal of Big Data, V3, DOI 10.1186/s40537-016-0059-y
   Jensen M, 2013, IEEE INT CONGR BIG, P235, DOI 10.1109/BigData.Congress.2013.39
   Konečny J, 2015, Arxiv, DOI arXiv:1511.03575
   Konečny J, 2016, Arxiv, DOI [arXiv:1610.02527, DOI 10.48550/ARXIV.1610.02527]
   Konečny J, 2017, Arxiv, DOI [arXiv:1610.05492, DOI 10.48550/ARXIV.1610.05492]
   Li Ninghui, 2006, ICDE, P106, DOI DOI 10.1109/ICDE.2007.367856
   Ma C, 2017, OPTIM METHOD SOFTW, V32, P813, DOI 10.1080/10556788.2016.1278445
   McMahan H.B., 2016, ARXIV, DOI DOI 10.48550/ARXIV.1602.05629
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mohassel P, 2017, P IEEE S SECUR PRIV, P19, DOI [10.1109/SP.2017.12, 10.1145/3132747.3132768]
   Peterson ED, 2019, JAMA-J AM MED ASSOC, V322, P2283, DOI 10.1001/jama.2019.17831
   Raghupathi W, 2014, HEALTH INF SCI SYST, V2, DOI 10.1186/2047-2501-2-3
   Rajkomar A, 2019, NEW ENGL J MED, V380, P1347, DOI 10.1056/NEJMra1814259
   Samarati P, 2001, IEEE T KNOWL DATA EN, V13, P1010, DOI 10.1109/69.971193
   Sarwate AD, 2013, IEEE SIGNAL PROC MAG, V30, P86, DOI 10.1109/MSP.2013.2259911
   Sedayao Jeff, 2014, 2014 IEEE International Congress on Big Data (BigData Congress), P601, DOI 10.1109/BigData.Congress.2014.92
   Shamir O, 2014, PR MACH LEARN RES, V32, P1000
   Shokri R, 2015, CCS'15: PROCEEDINGS OF THE 22ND ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1310, DOI 10.1145/2810103.2813687
   Song S, 2013, IEEE GLOB CONF SIG, P245, DOI 10.1109/GlobalSIP.2013.6736861
   Srinivas S, 2015, Arxiv, DOI arXiv:1507.06149
   Sweeney L., 1998, Database Security XI. Status and Prospects. IFIP TC11 WG11.3 Eleventh International Conference on Database Security, P356
   Wang YC, 2018, TECHNOL FORECAST SOC, V126, P3, DOI 10.1016/j.techfore.2015.12.019
   Watson HJ, 2014, COMMUN ASSOC INF SYS, V34, P1247
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yang TMY, 2018, Arxiv, DOI [arXiv:1812.02903, DOI 10.48550/ARXIV.1812.02903]
   Zhang YC, 2015, PR MACH LEARN RES, V37, P362
NR 49
TC 2
Z9 2
U1 0
U2 8
PD DEC
PY 2020
VL 4
IS 12
AR e17265
DI 10.2196/17265
WC Health Care Sciences & Services; Medical Informatics
DA 2023-11-11
ER

PT C
AU Sailer, J
   Frey, C
   Kühnert, C
AF Sailer, Johannes
   Frey, Christian
   Kuehnert, Christian
BE Beyerer, J
   Kuhnert, C
   Niggemann, O
TI GPU GEMM-Kernel Autotuning for scalable machine learners
SO MACHINE LEARNING FOR CYBER PHYSICAL SYSTEMS, ML4CPS 2018
SE Technologien fur die intelligente Automation
DT Proceedings Paper
CT 4th Conference on Machine Learning for Cyber-Physical-Systems and
   Industry 4.0 (ML4CPS)
CY OCT 23-24, 2018
CL Fraunhofer IOSB, Karlsruhe, GERMANY
HO Fraunhofer IOSB
DE GPU; Matrix Multiplication; Autotuning; automatic gerneration;
   acceleration; CUDA; BLAS
AB Deep learning (DL) is one of the key technologies in the artificial intelligence (AI) domain Deep learning neural networks (DLNN) profit a lot from the overall exponential data growth while on the other hand the computational effort for training and inference strongly increase. Most of the computational time in DLNN is consumed by the convolution step, which is based on a general matrix multiplication (GEMM). In order to accelerate the computational time for DLNN different highly optimized GEMM implementations for Graphic Processing Units (GPUs) have been presented in the last years [1] most of these approaches are GPU hardware specific implementations of the GEMM software kernel and do not incorporate the performance dependency of the training data layout. In order to achieve a maximum performance the parameters of the GEMM algorithm have to be tuned for the different GPU hardware and specific data layout of the training task. In this paper we present a two step autotuning approach for GPU based GEMM algorithms. In the first step the kernel parameter search space is pruned by several performance criteria and afterwards further processed by a modified Simulated Annealing in order to find the best kernel parameter combinations with respect to the GPU hardware and the task specific data layout. Our results were carried out on 160 different input problems with the proposed approach an average speedup against the state of the art implementation from NVIDIA (cuBLAS) from around 12 on a NVIDIA GTX 1080 Ti accelerator card can be achieved.
C1 [Sailer, Johannes; Frey, Christian; Kuehnert, Christian] Fraunhofer Inst Optron Syst Technol & Image Explo, Karlsruhe, Germany.
RP Sailer, J (corresponding author), Fraunhofer Inst Optron Syst Technol & Image Explo, Karlsruhe, Germany.
CR Aarts E., 1988, SIMULATED ANNEALING
   [Anonymous], 2017, PERFORMANCE PREDICTI
   [Anonymous], 2015, BRUTE FORCE K NEARES
   [Anonymous], 2013, SCRIPT BASED AUTOTUN
   [Anonymous], 2015, EXPERIENCES AUTOTUNI
   [Anonymous], 2016, PERFORMANCE DESIGN A
   [Anonymous], 2013, APPL INDEPENDENT AUT
   [Anonymous], 2009, NOTE AUTOTUNING GEMM
   [Anonymous], 2009, AUTOTUNING 3 D FFT L
   [Anonymous], 2017, NOVEL HPC TECHNIQUES
   [Anonymous], FAST K NEAREST NEIGH
   [Anonymous], 2011, AUTOTUNING GEMMS FER
   [Anonymous], 2001, AUTOMATED EMPIRICAL
   [Anonymous], 2008, BENCHMARKING GPUS TU
   [Anonymous], 2010, MODEL DRIVEN AUTOTUN
   Baskaran M. M., 2010, AUTOMATIC C TO CUDA
   Nath R., 2010, IMPROVED MAGMA GEMM
   python Bergstra James, NIPS 2011 BIGLEARNIN
   Volkov V., 2016, UNDERSTANDING LATENC
   Vuduc R., 2005, OSKI LIB AUTOMATICAL
NR 20
TC 1
Z9 1
U1 0
U2 1
PY 2019
VL 9
BP 66
EP 76
DI 10.1007/978-3-662-58485-9_8
WC Computer Science, Artificial Intelligence; Engineering,
   Multidisciplinary
DA 2023-11-11
ER

PT J
AU Lopez, JM
   Hirtz, T
   Dampfhoffer, M
   Grenouillee, L
   Reganaz, L
   Navarro, G
   Carabasse, C
   Vianello, E
   Magis, T
   Deleruyelle, D
   Bocquet, M
   Portal, JM
   Andrieu, F
   Molas, G
AF Lopez, J. Minguet
   Hirtz, T.
   Dampfhoffer, M.
   Grenouillee, L.
   Reganaz, L.
   Navarro, G.
   Carabasse, C.
   Vianello, E.
   Magis, T.
   Deleruyelle, D.
   Bocquet, M.
   Portal, J. M.
   Andrieu, F.
   Molas, G.
TI OxRAM plus OTS optimization for binarized neural network hardware
   implementation
SO SEMICONDUCTOR SCIENCE AND TECHNOLOGY
DT Article
DE BNN; resistive RAM; OTS; chalcogenide; crossbar
AB Low-power memristive devices embedded on graphics or central processing units logic core are a very promising non-von-Neumann approach to improve significantly the speed and power consumption of deep learning accelerators, enhancing their deployment on embedded systems. Among various non-ideal emerging neuromorphic memory devices, synaptic weight hardware implementation using resistive random-access memories (RRAMs) within 1T1R architectures promises high performance on low precision binarized neural networks (BNN). Taking advantage of the RRAM capabilities and allowing to substantially improve the density thanks to the ovonic threshold selector (OTS) selector, this work proposes to replace the standard 1T1R architecture with a denser 1S1R crossbar system, where an HfO2-based resistive oxide memory (OxRAM) is co-integrated with a Ge-Se-Sb-N-based OTS. In this context, an extensive experimental study is performed to optimize the 1S1R stack and programming conditions for extended read window margin and endurance characteristics. Focusing on the standard machine learning MNIST image recognition task, we perform offline training simulations in order to define the constraints on the devices during the training process. A very promising bit error rate of similar to 10(-3) is demonstrated together with 1S1R 10(4) error-free programming endurance characteristics, fulfilling the requirements for the application of interest. Based on this simulation and experimental study, BNN figures of merit (system footprint, number of weight updates, accuracy, inference speed, electrical consumption per image classification and tolerance to errors) are optimized by engineering the number of learnable parameters of the system. Altogether, an inherent BNN resilience to 1S1R parasitic bit errors is demonstrated.
C1 [Lopez, J. Minguet; Hirtz, T.; Grenouillee, L.; Reganaz, L.; Navarro, G.; Carabasse, C.; Vianello, E.; Magis, T.; Andrieu, F.; Molas, G.] Univ Grenoble Alpes, LETI, CEA, F-38000 Grenoble, France.
   [Dampfhoffer, M.] Univ Grenoble Alpes, CEA, CNRS, Grenoble INP,INAC Spintec, F-38000 Grenoble, France.
   [Bocquet, M.; Portal, J. M.] Aix Marseille Univ, Univ Toulon, CNRS, IM2NP, F-13009 Marseille, France.
   [Deleruyelle, D.] INL CNRS, INSA Lyon, F-69621 Villeurbanne, France.
RP Lopez, JM; Molas, G (corresponding author), Univ Grenoble Alpes, LETI, CEA, F-38000 Grenoble, France.
EM joel.minguetlopez@cea.fr; gabriel.molas@cea.fr
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Bocquet M, 2018, INT EL DEVICES MEET
   Cai FX, 2020, NAT ELECTRON, V3, P409, DOI 10.1038/s41928-020-0436-6
   Chou, 2020, IEEE S VLSI CIRCUITS, V1, P1
   Garbin D, 2015, IEEE T ELECTRON DEV, V62, P2494, DOI 10.1109/TED.2015.2440102
   Grenouillet L., 2021, P IMW
   Helwegen K., 2019, ADV NEURAL INFORM PR, P7531
   Hirtzlin T, 2020, FRONT NEUROSCI-SWITZ, V13, DOI 10.3389/fnins.2019.01383
   Hubara Itay, 2016, P 30 INT C NEUR INF
   Ielmini D, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/ab554b
   Jain P, 2019, ISSCC DIG TECH PAP I, V62, P212, DOI 10.1109/ISSCC.2019.8662393
   Joshi V, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-16108-9
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lopez JM, 2021, INT RELIAB PHY SYM, DOI 10.1109/IRPS46558.2021.9405195
   Villanueva JAL, 2020, CON DES CIRC INTEGR, DOI 10.1109/dcis51330.2020.9268676
   Martí D, 2016, NEURAL COMPUT, V28, P2011, DOI 10.1162/NECO_a_00882
   Molas, P IMW2020, V1, P1
   Nail C, 2016, INT EL DEVICES MEET
   Pedram A, 2017, IEEE DES TEST, V34, P39, DOI 10.1109/MDAT.2016.2573586
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Regev A, 2020, 2020 2ND IEEE INTERNATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE CIRCUITS AND SYSTEMS (AICAS 2020), P145, DOI [10.1109/aicas48895.2020.9073840, 10.1109/AICAS48895.2020.9073840]
   ROBAYO DA, 2019, IEDM2019 TECH DIG 35
   Sassine G, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800658
   Sheng X, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201800876
   Truong SN, 2020, IEEE ACCESS, V8, P69327, DOI 10.1109/ACCESS.2020.2986513
   Strukov D, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12521-x
   Sze V., 2019, NEURIPS
   Tsai H, 2018, J PHYS D APPL PHYS, V51, DOI 10.1088/1361-6463/aac8a5
   Valentian A, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993431
   Verdy A, 2018, INT EL DEVICES MEET
   Yu S., 2015, IEDM2015 TECH DIG
NR 32
TC 4
Z9 4
U1 2
U2 15
PD JAN
PY 2022
VL 37
IS 1
AR 014001
DI 10.1088/1361-6641/ac31e2
WC Engineering, Electrical & Electronic; Materials Science,
   Multidisciplinary; Physics, Condensed Matter
DA 2023-11-11
ER

PT C
AU Abdelfattah, A
   Tomov, S
   Dongarra, J
AF Abdelfattah, Ahmad
   Tomov, Stanimire
   Dongarra, Jack
GP IEEE
TI Towards Half-Precision Computation for Complex Matrices: A Case Study
   for Mixed-Precision Solvers on GPUs
SO PROCEEDINGS OF SCALA 2019: 2019 IEEE/ACM 10TH WORKSHOP ON LATEST
   ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA)
DT Proceedings Paper
CT 10th IEEE/ACM Workshop on Latest Advances in Scalable Algorithms for
   Large-Scale Systems (ScalA)
CY NOV 18, 2019
CL Denver, CO
DE Half precision; Tensor cores FP16 arithmetic; mixed-precision solvers
ID GMRES
AB The use of low-precision computations is popular in accelerating machine learning and artificial intelligence (AI) applications. Hardware architectures, such as high-end graphics processing units (GPUs), now support native 16-bit floating-point arithmetic (i.e., half-precision). While half precision provides a natural 2x/4x speedup against the performance of single/double precisions, respectively, modern GPUs are equipped with hardware accelerators that further boost the FP16 performance. These accelerators, known as tensor cores (TCs), have a theoretical peak performance that is 8x/16x faster than FP32/FP64 performance, respectively. Such a high level of performance has encouraged researchers to harness the compute power of TCs outside AI applications.
   This paper presents a mixed-precision dense linear solver (Ax = b) for complex matrices using the GPU's TC units. Unlike similar efforts that have discussed accelerating Ax = b in real FP16 arithmetic, this paper focuses on complex FP16 precisions. The developed solution uses a "half-complex" precision to accelerate the solution of Ax = b while maintaining complex FP32 precision accuracy. The proposed solver requires the development of a high-performance mixed-precision matrix multiplication (CGEMM-FP16) that accepts half-complex inputs, and uses the TCs' full-precision products and FP32 accumulations for the computation. We discuss two designs and their performance. Similar to the way fast GEMMs power the performance of LAPACK, the mixed-precision CGEMM-FP16 can enable the development of mixed-precision LAPACK algorithms. We illustrate this by integrating both CGEMM-FP16s into the development of mixed-precision LU factorizations of complex matrices. Finally, an iterative refinement solver is used to deliver complex FP32 accuracy using a preconditioned GMRES solver. Our experiments, conducted on V100 GPUs, show that the mixed-precision solver can be up to 2.5x faster than a full single-complex precision solver.
C1 [Abdelfattah, Ahmad; Tomov, Stanimire; Dongarra, Jack] Univ Tennessee, Innovat Comp Lab, Knoxville, TN 37996 USA.
RP Abdelfattah, A (corresponding author), Univ Tennessee, Innovat Comp Lab, Knoxville, TN 37996 USA.
EM ahmad@icl.utk.edu; tomov@icl.utk.edu; dongarra@icl.utk.edu
CR Abdelfattah A, 2019, INT PARALL DISTRIB P, P111, DOI 10.1109/IPDPS.2019.00022
   Abdelfattah A, 2018, IEEE T PARALL DISTR, V29, P2700, DOI 10.1109/TPDS.2018.2842785
   Agullo E, 2009, J PHYS CONF SER, V180, DOI 10.1088/1742-6596/180/1/012037
   [Anonymous], 2006, SC 06 P 2006 ACM IEE
   [Anonymous], 2015, FULL WALK SGEMM IMPL
   [Anonymous], 2016, LECT NOTES COMPUT SC, DOI DOI 10.1007/978-3-319-41321-1_2
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2018, P INT C HIGH PERF CO, DOI DOI 10.1109/SC.2018.00050
   Baboulin M, 2009, COMPUT PHYS COMMUN, V180, P2526, DOI 10.1016/j.cpc.2008.11.005
   Carson E, 2018, SIAM J SCI COMPUT, V40, pA817, DOI 10.1137/17M1140819
   Carson E, 2017, SIAM J SCI COMPUT, V39, pA2834, DOI 10.1137/17M1122918
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA2536, DOI 10.1137/18M1229511
   Lai JJ, 2013, INT SYM CODE GENER, P89
   Nath R, 2010, INT J HIGH PERFORM C, V24, P511, DOI 10.1177/1094342010385729
   SAAD Y, 1986, SIAM J SCI STAT COMP, V7, P856, DOI 10.1137/0907058
   SAAD Y, 1993, SIAM J SCI COMPUT, V14, P461, DOI 10.1137/0914028
   Simoncini V, 2003, SIAM J NUMER ANAL, V40, P2219
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
NR 18
TC 8
Z9 8
U1 1
U2 2
PY 2019
BP 17
EP 24
DI 10.1109/ScalA49573.2019.00008
WC Computer Science, Theory & Methods; Mathematics, Applied
DA 2023-11-11
ER

PT J
AU Chen, ZJ
   Sludds, A
   Davis, R
   Christen, I
   Bernstein, L
   Ateshian, L
   Heuser, T
   Heermeier, N
   Lott, JA
   Reitzenstein, S
   Hamerly, R
   Englund, D
AF Chen, Zaijun
   Sludds, Alexander
   Davis III, Ronald
   Christen, Ian
   Bernstein, Liane
   Ateshian, Lamia
   Heuser, Tobias
   Heermeier, Niels
   Lott, James A.
   Reitzenstein, Stephan
   Hamerly, Ryan
   Englund, Dirk
TI Deep learning with coherent VCSEL neural networks
SO NATURE PHOTONICS
DT Article
ID ACCELERATOR; PHOTONICS; INFERENCE
AB Energy consumption and compute density are challenges for computing systems. Here researchers show an optical computing architecture using micrometre-scale VCSEL transmitter arrays enabling 7 fJ energy per operation and a potential compute density of 6 tera-operations mm(-2) s(-1).
   Deep neural networks (DNNs) are reshaping the field of information processing. With the exponential growth of these DNNs challenging existing computing hardware, optical neural networks (ONNs) have recently emerged to process DNN tasks with high clock rates, parallelism and low-loss data transmission. However, existing challenges for ONNs are high energy consumption due to their low electro-optic conversion efficiency, low compute density due to large device footprints and channel crosstalk, and long latency due to the lack of inline nonlinearity. Here we experimentally demonstrate a spatial-temporal-multiplexed ONN system that simultaneously overcomes all these challenges. We exploit neuron encoding with volume-manufactured micrometre-scale vertical-cavity surface-emitting laser (VCSEL) arrays that exhibit efficient electro-optic conversion (V-& pi; = 4 mV) and compact footprint (<0.01 mm(2) per device). Homodyne photoelectric multiplication allows matrix operations at the quantum-noise limit and detection-based optical nonlinearity with instantaneous response. With three-dimensional neural connectivity, our system can reach an energy efficiency of 7 femtojoules per operation (OP) with a compute density of 6 teraOP mm(-)(2) s(-1), representing 100-fold and 20-fold improvements, respectively, over state-of-the-art digital processors. Near-term development could improve these metrics by two more orders of magnitude. Our optoelectronic processor opens new avenues to accelerate machine learning tasks from data centres to decentralized devices.
C1 [Chen, Zaijun; Sludds, Alexander; Davis III, Ronald; Christen, Ian; Bernstein, Liane; Ateshian, Lamia; Hamerly, Ryan; Englund, Dirk] MIT, Res Lab Elect, Cambridge, MA 02139 USA.
   [Chen, Zaijun] Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.
   [Heuser, Tobias; Heermeier, Niels; Lott, James A.; Reitzenstein, Stephan] Tech Univ Berlin, Fak Inst Festkorperphys 2, Berlin, Germany.
   [Hamerly, Ryan] NTT Res Inc, PHI Labs, Sunnyvale, CA 94085 USA.
RP Chen, ZJ; Hamerly, R; Englund, D (corresponding author), MIT, Res Lab Elect, Cambridge, MA 02139 USA.; Chen, ZJ (corresponding author), Univ Southern Calif, Ming Hsieh Dept Elect & Comp Engn, Los Angeles, CA 90007 USA.; Hamerly, R (corresponding author), NTT Res Inc, PHI Labs, Sunnyvale, CA 94085 USA.
EM zaijunch@usc.edu; rhamerly@mit.edu; englund@mit.edu
CR [Anonymous], 2022, US VCSELS 3D SENS AP
   Ashtiani F, 2022, NATURE, V606, P501, DOI 10.1038/s41586-022-04714-0
   Atabaki AH, 2018, NATURE, V556, P349, DOI 10.1038/s41586-018-0028-z
   Bhooplapur S, 2011, OPT LETT, V36, P1887, DOI 10.1364/OL.36.001887
   Brown T., 2020, ADV NEURAL INFORM PR, V33, P1877, DOI DOI 10.48550/ARXIV.2005.14165
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Feldmann J, 2021, NATURE, V589, P52, DOI 10.1038/s41586-020-03070-1
   Feldmann J, 2019, NATURE, V569, P208, DOI 10.1038/s41586-019-1157-8
   Hadibrata W, 2021, NANO LETT, V21, P2422, DOI 10.1021/acs.nanolett.0c04463
   Hamerly R, 2019, PHYS REV X, V9, DOI 10.1103/PhysRevX.9.021032
   Heidari E, 2020, NANOPHOTONICS-BERLIN, V9, P4743, DOI 10.1515/nanoph-2020-0437
   Heuser T, 2020, J PHYS-PHOTONICS, V2, DOI 10.1088/2515-7647/aba671
   Hoghooghi N, 2010, OPT LETT, V35, P1218, DOI 10.1364/OL.35.001218
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hubara I, 2018, J MACH LEARN RES, V18
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jager R, 1997, ELECTRON LETT, V33, P330, DOI 10.1049/el:19970193
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim I, 2021, NAT NANOTECHNOL, V16, P508, DOI 10.1038/s41565-021-00895-3
   Koyama F, 2006, J LIGHTWAVE TECHNOL, V24, P4502, DOI 10.1109/JLT.2006.886064
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kumari S, 2018, LASER PHOTONICS REV, V12, DOI 10.1002/lpor.201700206
   Li GHY, 2023, NANOPHOTONICS-BERLIN, V12, P847, DOI 10.1515/nanoph-2022-0137
   Lin X, 2018, SCIENCE, V361, P1004, DOI 10.1126/science.aat8084
   Liu AJ, 2019, PHOTONICS RES, V7, P121, DOI 10.1364/PRJ.7.000121
   Miller DAB, 2017, J LIGHTWAVE TECHNOL, V35, P346, DOI 10.1109/JLT.2017.2647779
   Mishkin D., 2016, INT C LEARNING REPRE
   Mnih V, 2015, NATURE, V518, P529, DOI 10.1038/nature14236
   Nahmias MA, 2020, IEEE J SEL TOP QUANT, V26, DOI 10.1109/JSTQE.2019.2941485
   Noé F, 2020, ANNU REV PHYS CHEM, V71, P361, DOI 10.1146/annurev-physchem-042018-052331
   Ossiander M, 2018, NATURE, V561, P374, DOI 10.1038/s41586-018-0503-6
   Paszke A, 2019, ADV NEUR IN, V32
   Rowland J, 2021, OPT LETT, V46, P412, DOI 10.1364/OL.416166
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Serre T, 2007, IEEE T PATTERN ANAL, V29, P411, DOI 10.1109/TPAMI.2007.56
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Sludds Alexander, 2022, Science, V378, P270, DOI 10.1126/science.abq8271
   Sun C, 2015, NATURE, V528, P534, DOI 10.1038/nature16454
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tait AN, 2019, PHYS REV APPL, V11, DOI 10.1103/PhysRevApplied.11.064043
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Vamathevan J, 2019, NAT REV DRUG DISCOV, V18, P463, DOI 10.1038/s41573-019-0024-5
   Wang C, 2018, NATURE, V562, P101, DOI 10.1038/s41586-018-0551-y
   Wang TY, 2022, NAT COMMUN, V13, DOI 10.1038/s41467-021-27774-8
   Wetzstein G, 2020, NATURE, V588, P39, DOI 10.1038/s41586-020-2973-6
   Xu XW, 2018, NAT ELECTRON, V1, P216, DOI 10.1038/s41928-018-0059-3
   Xu XY, 2021, NATURE, V589, P44, DOI 10.1038/s41586-020-03063-0
   Yang YS, 2017, OPT EXPRESS, V25, P5758, DOI 10.1364/OE.25.005758
   Yeap G, 2019, INT EL DEVICES MEET, DOI 10.1109/IEDM19573.2019.8993577
   Young T, 2018, IEEE COMPUT INTELL M, V13, P55, DOI 10.1109/MCI.2018.2840738
   Zhou HL, 2022, LIGHT-SCI APPL, V11, DOI 10.1038/s41377-022-00717-8
   Zhou TK, 2021, NAT PHOTONICS, V15, P367, DOI 10.1038/s41566-021-00796-w
   Zuo Y, 2019, OPTICA, V6, P1132, DOI 10.1364/OPTICA.6.001132
NR 55
TC 0
Z9 0
U1 24
U2 24
PD AUG
PY 2023
VL 17
IS 8
BP 723
EP +
DI 10.1038/s41566-023-01233-w
EA JUL 2023
WC Optics; Physics, Applied
DA 2023-11-11
ER

PT C
AU Ahn, J
   Hong, S
   Yoo, S
   Mutlu, O
   Choi, K
AF Ahn, Junwhan
   Hong, Sungpack
   Yoo, Sungjoo
   Mutlu, Onur
   Choi, Kiyoung
GP IEEE
TI A Scalable Processing-in-Memory Accelerator for Parallel Graph
   Processing
SO 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
DT Proceedings Paper
CT ACM/IEEE 42nd Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 13-17, 2015
CL Portland, OR
AB The explosion of digital data and the ever-growing need for fast data analysis have made in-memory big-data processing in computer systems increasingly important. In particular, large-scale graph processing is gaining attention due to its broad applicability from social science to machine learning. However, scalable hardware design that can efficiently process large graphs in main memory is still an open problem. Ideally, cost-effective and scalable graph processing systems can be realized by building a system whose performance increases proportionally with the sizes of graphs that can be stored in the system, which is extremely challenging in conventional systems due to severe memory bandwidth limitations.
   In this work, we argue that the conventional concept of processing-in-memory (PIM) can be a viable solution to achieve such an objective. The key modern enabler for PIM is the recent advancement of the 3D integration technology that facilitates stacking logic and memory dies in a single package, which was not available when the PIM concept was originally examined. In order to take advantage of such a new technology to enable memory-capacity-proportional performance, we design a programmable PIM accelerator for large-scale graph processing called Tesseract. Tesseract is composed of (1) a new hardware architecture that fully utilizes the available memory bandwidth, (2) an efficient method of communication between different memory partitions, and (3) a programming interface that reflects and exploits the unique hardware design. It also includes two hardware prefetchers specialized for memory access patterns of graph processing, which operate based on the hints provided by our programming model. Our comprehensive evaluations using five state-of-the-art graph processing workloads with large real-world graphs show that the proposed architecture improves average system performance by a factor of ten and achieves 87% average energy reduction over conventional systems.
C1 [Ahn, Junwhan; Yoo, Sungjoo; Choi, Kiyoung] Seoul Natl Univ, Seoul 151, South Korea.
   [Hong, Sungpack] Oracle Labs, Palo Alto, CA USA.
   [Mutlu, Onur] Carnegie Mellon Univ, Pittsburgh, PA 15213 USA.
RP Ahn, J (corresponding author), Seoul Natl Univ, Seoul 151, South Korea.
EM junwhan@snu.ac.kr; sungpack.hong@oracle.com; sungjoo.yoo@gmail.com;
   onur@cmu.edu; kchoi@snu.ac.kr
CR [Anonymous], 2013, TECH REP
   [Anonymous], P WWW
   [Anonymous], P ASPLOS
   [Anonymous], 2006, P ASPLOS
   [Anonymous], P ISCA
   [Anonymous], 2014, P HPDC
   [Anonymous], 2013, P ISCA
   [Anonymous], 2013, P SSDBM
   [Anonymous], 2006, 2GB X4 X8 X16 DDR3 S
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Basu A., 2013, P ISCA
   Basu A., 2014, IEEE MICRO, V34, P36
   BIRRELL AD, 1984, ACM T COMPUT SYST, V2, P39, DOI 10.1145/2080.357392
   CHEN TF, 1995, IEEE T COMPUT, V44, P609, DOI 10.1109/12.381947
   Chung E. S., 2013, P ISCA
   Dagum L, 1998, IEEE COMPUT SCI ENG, V5, P46, DOI 10.1109/99.660313
   Eckert Y., 2014, WONDP
   GOKHALE M, 1995, IEEE COMPUT, V28, P23
   Gonzalez JE, 2012, 10 USENIX S OP SYST
   Gutierrez A., 2014, P ASPLOS
   Hall M., 1999, P SC
   Harish P., 2007, P HIPC
   Harshvardhan, 2014, P PACT
   Hong S., 2011, P PPOPP
   Hong S., 2012, P ASPLOS
   Hong S., 2011, P PACT
   Hong S., 2014, P CGO
   Hughes CJ, 2005, J PARALLEL DISTR COM, V65, P448, DOI 10.1016/j.jpdc.2004.11.004
   Hybrid Memory Cube Consortium, 2014, TECH REP
   Jeddeloh J., 2012, P VLSIT
   JOUPPI N, 1990, P ISCA
   Kang Y., 1999, P ICCD
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Kim G., 2013, P PACT
   Kocberber O., 2013, P ICPP
   Kocberber Onur, 2013, P MICRO
   Lim K., 2013, P ISCA
   Loh G., 2008, P ISCA
   Loh G. H., 2013, WONDP
   Low Y, 2012, PROC VLDB ENDOW, V5, P716, DOI 10.14778/2212351.2212354
   Luk Chi-Keung, 2005, P PLDI
   Malewicz G., 2010, P SIGMOD
   Merrill D. G., 2012, P PPOPP
   MISLOVE A, 2007, P IMC
   Mutlu O., 2003, P HPCA
   Oskin M., 1998, P ISCA
   Ousterhout J., 2010, ACM SIGOPS OPERAT SY, V43, P92, DOI DOI 10.1145/1713254.1713276
   Patterson D., 1997, ISSCC
   Pugsley Seth H., 2014, P ISPASS
   Qadeer W., 2013, P ISCA
   Ranganathan P, 2011, COMPUTER, V44, P39, DOI 10.1109/MC.2011.18
   Seshadri V., 2013, P MICRO
   Shevgoor M., 2013, P MICRO
   Solihin Y., 2002, P ISCA
   Srinath S., 2007, P HPCA
   Suleman M. A., 2009, P ASPLOS
   Tian Y, 2013, PROC VLDB ENDOW, V7, P193, DOI 10.14778/2732232.2732238
   Wu L., 2013, P ICS
   Zhang D. P., 2014, P 3DIC
   Zhu Q., 2013, P HPEC
NR 60
TC 260
Z9 269
U1 2
U2 15
PY 2015
BP 105
EP 117
DI 10.1145/2749469.2750386
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Huang, Y
   Chen, ZY
   Li, D
   Yang, KY
AF Huang, Yi
   Chen, Zhiyu
   Li, Dai
   Yang, Kaiyuan
GP IEEE Comp Soc
TI CAMA: Energy and Memory Efficient Automata Processing in
   Content-Addressable Memories
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
AB Accelerating finite automata processing is critical for advancing real-time analytic in pattern matching, data mining, bioinformatics, intrusion detection, and machine learning. Recent in-memory automata accelerators leveraging SRAMs and DRAMs have shown exciting improvements over conventional digital designs. However, the bit-vector representation of state transitions used by all state-of-the-art (SOTA) designs is only optimal in processing worst-case completely random patterns, while a significant amount of memory and energy is wasted in running most real-world benchmarks.
   We present CAMA, a Content-Addressable Memory (CAM) enabled Automata accelerator for processing homogeneous non-deterministic finite automata (NFA). A radically different state representation scheme, along with co-designed novel circuits and data encoding schemes, greatly reduces energy, memory, and chip area for most realistic NFAs. CAMA is holistically optimized with the following major contributions: (1) a 16x256 8-transistor (8T) CAM array for state matching, replacing the 256x256 6T SRAM array or two 16x256 6T SRAM banks in state-of-the-art (SOTA) designs; (2) a novel encoding scheme that enables content searching within 8T SRAMs and adapts to different applications; (3) a reconfigurable and scalable architecture that improves efficiency on all tested benchmarks, without losing support for any NFA that's compatible with SOTA designs; (4) an optimization framework that automates the choice of encoding schemes and maps a given NFA to the proposed hardware. Two versions of CAMA, one optimized for energy (CAMA-E) and the other for throughput (CAMA-T), are comprehensively evaluated in a 28nm CMOS process, and across 21 real-world and synthetic benchmarks. CAMA-E achieves 2.1x, 2.8x, and 2.04x lower energy than CA, 2-stride Impala, and eAP. CAMA-T shows 2.68x, 3.87x and 2.62x higher average compute density than 2-stride Impala, CA, and eAP. Both versions reduce the chip area required for the largest tested benchmark by 2.48x over CA, 1.91x over 2-stride Impala, and 1.78x over eAP.
C1 [Huang, Yi; Chen, Zhiyu; Li, Dai; Yang, Kaiyuan] Rice Univ, Dept Elect & Comp Engn, POB 1892, Houston, TX 77251 USA.
RP Huang, Y (corresponding author), Rice Univ, Dept Elect & Comp Engn, POB 1892, Houston, TX 77251 USA.
EM yihuang@ustc.edu; zc37@rice.edu; d137@rice.edu; kyang@rice.edu
CR AHO AV, 1975, COMMUN ACM, V18, P333, DOI 10.1145/360825.360855
   Alicherry M, 2006, PROCEEDINGS OF THE 2006 IEEE INTERNATIONAL CONFERENCE ON NETWORK PROTOCOLS, P183
   Alur R, 2001, ACM T PROGR LANG SYS, V23, P273, DOI 10.1145/503502.503503
   Becchi M, 2007, P 3 ACM IEEE S ARCH
   Becchi M., 2008, PROC 4 ACMIEEE S ARC, P50, DOI 10.1145/1477942.1477950
   Becchi M, 2008, I S WORKL CHAR PROC, P73
   Bo C, 2018, INT S HIGH PERF COMP, P737, DOI 10.1109/HPCA.2018.00068
   Bo CK, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA), P311, DOI 10.1109/BigData.2016.7840617
   Bremler-Barr A, 2014, IEEE ACM T NETWORK, V22, P415, DOI 10.1109/TNET.2013.2253119
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang Yu, 2006, ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS 2006), P93, DOI 10.1109/ANCS.2006.4579527
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Glushkov V. M, ABSTRACT THEORY AUTO, V16, P1, DOI [10.1070/rm1961v016n05abeh004112, DOI 10.1070/RM1961V016N05ABEH004112]
   Gogte V, 2016, INT SYMP MICROARCH
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Kunyang Peng, 2011, 2011 ACM/IEEE Symposium on Architectures for Networking and Communications Systems (ANCS), P24, DOI 10.1109/ANCS.2011.13
   Lenjani M, 2014, IET COMPUT DIGIT TEC, V8, P30, DOI 10.1049/iet-cdt.2011.0066
   Li D, 2020, IEEE SOLID-ST CIRC L, V3, P358, DOI 10.1109/LSSC.2020.3022006
   Liu TW, 2011, IEEE INFOCOM SER, P2129, DOI 10.1109/INFCOM.2011.5935024
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pao D, 2011, IEEE T COMPUT, V60, P1596, DOI 10.1109/TC.2010.250
   Rahimi R, 2020, ANN IEEE SYM FIELD P, P138, DOI 10.1109/FCCM48280.2020.00027
   Roy I, 2016, IEEE ACM T COMPUT BI, V13, P99, DOI 10.1109/TCBB.2015.2430313
   Sadredini E., 2017, P INT C SUPERCOMPUTI, DOI [10.1145/3079079.3079084, DOI 10.1145/3079079.3079084]
   Sadredini E, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P219, DOI 10.1145/3373376.3378459
   Sadredini E, 2020, INT S HIGH PERF COMP, P86, DOI 10.1109/HPCA47549.2020.00017
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Sadredini E, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P665, DOI 10.1145/3219819.3219889
   Subramaniyan A, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P259, DOI 10.1145/3123939.3123986
   Tandon P, 2016, PROC INT CONF DATA, P469, DOI 10.1109/ICDE.2016.7498263
   Hieu TT, 2013, INT CONF UBIQ FUTUR, P252, DOI 10.1109/ICUFN.2013.6614821
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Wadden J, 2018, I S WORKL CHAR PROC, P13, DOI 10.1109/IISWC.2018.8573482
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wadden J, 2016, I S WORKL CHAR PROC, P105, DOI 10.1109/IISWC.2016.7581271
   Wang K, 2016, PROCEEDINGS OF THE ACM INTERNATIONAL CONFERENCE ON COMPUTING FRONTIERS (CF'16), P135, DOI 10.1145/2903150.2903172
   Wang K, 2016, 2016 INTERNATIONAL CONFERENCE ON HARDWARE/SOFTWARE CODESIGN AND SYSTEM SYNTHESIS (CODES+ISSS), DOI 10.1145/2968456.2976763
   Xie T, 2017, I C FIELD PROG LOGIC
   Yabuuchi M, 2018, SYMP VLSI CIRCUITS, P19, DOI 10.1109/VLSIC.2018.8502345
   Yun S, 2012, IEEE T COMPUT, V61, P213, DOI 10.1109/TC.2010.273
NR 40
TC 3
Z9 3
U1 0
U2 1
PY 2022
BP 25
EP 37
DI 10.1109/HPCA53966.2022.00011
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Rotaru, MD
   Tang, W
   Rahul, D
   Zhang, ZY
AF Rotaru, Mihai D.
   Tang, Wei
   Rahul, Dutta
   Zhang, Zhengya
GP IEEE Comp Soc
TI Design and Development of High Density Fan-Out Wafer Level Package
   (HD-FOWLP) for Deep Neural Network (DNN) Chiplet Accelerators using
   Advanced Interface Bus (AIB)
SO IEEE 71ST ELECTRONIC COMPONENTS AND TECHNOLOGY CONFERENCE (ECTC 2021)
SE Electronic Components and Technology Conference
DT Proceedings Paper
CT IEEE 71st Electronic Components and Technology Conference (ECTC)
CY JUN 01-JUL 04, 2021
CL ELECTR NETWORK
DE High Density Fan-out Wafer Level Package; chiplet; heterogeneous
   integration; signal and power integrity
AB Emerging applications such as machine learning (ML) and artificial intelligence (AI) require more computing capabilities that ought to be distributed and have access to large memory and storage, while the systems need to be energy efficient and low-cost. The increase in cost of advanced nodes and the difficulties of shrinking analog circuits such as input and output (I/O) to address the computation and communication needs of ML/AI applications have created the opportunity to bring into the mainstream chiplet-based systems. The chiplet based systems enable modularity, scalability and technology partitioning providing a cost and energy efficient solution. The chiplet integration has been enabled by the development of a raft of advanced packaging technologies such as silicon interposer, EMIB, COWoS, high density fan-out wafer level packaging (HDFOWLP) to name a few. In this work the design, development and electrical characterization of a four-chiplet system integrated using in 2.5D HD-FOWLP platform is discussed. The chiplet accelerators are fabricated in 22 nm CMOS technology, while the package uses a five metal layer HD-FOWLP with dielectric polymer and 2 um width and space as minimum design rules. The Advanced Bus Interface (AIB) die-to-die PHY-level standard is used to interconnect the four chiplets in a ring topology. The AIB bus requires 192 lines between each two chiplets, and a total of 768 2umx2um lines are routed on the top three layers of the HDFOLWP. The bottom two metal layers of the package are used to distribute the ground and power necessary for all four chiplets. Each chiplet requires seven distinct voltage islands that are separately routed on the bottom metal layer.
C1 [Rotaru, Mihai D.; Rahul, Dutta] ASTAR, Inst Microelect, Singapore, Singapore.
   [Tang, Wei; Zhang, Zhengya] Univ Michigan, EECS Dept, Ann Arbor, MI USA.
RP Rotaru, MD (corresponding author), ASTAR, Inst Microelect, Singapore, Singapore.
EM mihaidr@ime.a-star.edu.sg; weitang@umich.edu; duttar@ime.a-star.edu.sg;
   zhengya@umich.edu
CR [Anonymous], ADS USER MANUAL
   Beck N, 2018, ISSCC DIG TECH PAP I, P40, DOI 10.1109/ISSCC.2018.8310173
   Chen M.-F., 2019, P IEEE 69 EL COMP TE, P1
   Coughlin T., 2020, IEEE CONSUM ELECTR M, V9
   Coughlin T, 2019, IEEE CONSUM ELECTR M, V8, P97, DOI 10.1109/MCE.2018.2880855
   DARPA Microsystems Technology Office, 2016, BROAD AG ANN COMM HE
   Hancock T. M., 2019, 2019 INT 3D SYST INT
   Lin M.-S., 2019, P S VLSI CIRC JUN, P28
   Pantano N, 2016, 2016 6TH ELECTRONIC SYSTEM-INTEGRATION TECHNOLOGY CONFERENCE (ESTC)
   Rotaru MD, 2020, EL PACKAG TECH CONF, P430, DOI 10.1109/EPTC50525.2020.9315178
   Vivet P, 2021, IEEE J SOLID-ST CIRC, V56, P79, DOI 10.1109/JSSC.2020.3036341
   Wade M, 2020, IEEE MICRO, V40, P63, DOI 10.1109/MM.2020.2976067
NR 12
TC 7
Z9 6
U1 2
U2 13
PY 2021
BP 1258
EP 1263
DI 10.1109/ECTC32696.2021.00204
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Walter, I
   Ney, J
   Hotfilter, T
   Rybalkin, V
   Hoefer, J
   Wehn, N
   Becker, J
AF Walter, Iris
   Ney, Jonas
   Hotfilter, Tim
   Rybalkin, Vladimir
   Hoefer, Julian
   Wehn, Norbert
   Becker, Juergen
BE Kamp, M
   Koprinska, I
   Bibal, A
   Bouadi, T
   Frenay, B
   Galarraga, L
   Oramas, J
   Adilova, L
TI Embedded Face Recognition for Personalized Services in the Assistive
   Robotics
SO MACHINE LEARNING AND PRINCIPLES AND PRACTICE OF KNOWLEDGE DISCOVERY IN
   DATABASES, ECML PKDD 2021, PT I
SE Communications in Computer and Information Science
DT Proceedings Paper
CT 21st Joint European Conference on Machine Learning and Principles and
   Practice of Knowledge Discovery in Databases (ECML PKDD)
CY SEP 13-17, 2021
CL ELECTR NETWORK
DE Ambient assisted living; Assistive robotics; Convolutional neural
   networks; Face recognition; Field programmable gate array; Quantization
AB Recently, the field of assistive robotics has drawn much attention in the health care sector. In combination with modern machine learning-supported person recognition systems, they can deliver highly personalized services. However, common algorithms for person recognition such as convolutional neural networks (CNNs) consume high amounts of power and show low energy efficiency when executed on general-purpose computing platforms.
   In this paper, we present our hardware architecture and field programmable gate array (FPGA) accelerator to enable on-device person recognition in the context of assistive robotics. Therefore, we optimize a neural network based on the SqueezeNet topology and implement it on an FPGA for a high degree of flexibility and reconfigurability. By pruning redundant filters and quantization of weights and activations, we are able to find a well-fitting neural network that achieves a high identification accuracy of 84%. On a Xilinx Zynq Ultra96v2, we achieve a power consumption of 4.8 W, a latency of 31 ms and an efficiency of 6.738 FPS/W. Our results outperform the latency by 1.6x compared to recent person recognition systems in assistive robots and energy efficiency by 1.7x for embedded face recognition, respectively.
C1 [Walter, Iris; Hotfilter, Tim; Hoefer, Julian; Becker, Juergen] Karlsruhe Inst Technol, Karlsruhe, Germany.
   [Ney, Jonas; Rybalkin, Vladimir; Wehn, Norbert] Tech Univ Kaiserslautern, Kaiserslautern, Germany.
RP Walter, I (corresponding author), Karlsruhe Inst Technol, Karlsruhe, Germany.
EM iris.walter@kit.edu; ney@eit.uni-kl.de; hotfilter@kit.edu;
   rybalkin@eit.uni-kl.de; julian.hoefer@kit.edu; wehn@eit.uni-kl.de;
   becker@kit.edu
CR Asfour T, 2019, IEEE ROBOT AUTOM MAG, V26, P108, DOI 10.1109/MRA.2019.2941246
   Baehr S., 2019, LOW LATENCY NEURAL N
   Brinker TJ, 2019, EUR J CANCER, V113, P47, DOI 10.1016/j.ejca.2019.04.001
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Duque-Domingo J, 2020, FRONT NEUROROBOTICS, V14, DOI 10.3389/fnbot.2020.00034
   Esler T., FACE RECOGNITION USI
   Ghita Stefania Alexandra, 2018, Towards Autonomous Robotic Systems. 19th Annual Conference, TAROS 2018 Proceedings: Lecture Notes in Artificial Intelligence (LNAI 10965), P271, DOI 10.1007/978-3-319-96728-8_23
   Hotfilter T., 2020, 2020 IEEE 6 WORLD FO, P1, DOI [10.1109/WF-IoT48130.2020.9221396, DOI 10.1109/WF-IOT48130.2020.9221396]
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Hubara I, 2018, J MACH LEARN RES, V18
   Iandola F.N., 2016, GITHUB FORRESTI SQUE
   Iandola F. N., 2016, ARXIV
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Labs X.R, FINN HLS LIB
   Liu X, 2022, IEEE T COMPUT SOC SY, V9, P252, DOI 10.1109/TCSS.2021.3059318
   Liu Y., 2017, ABS171000870 CORR
   Liu Z., 2018, ARXIV181005270
   Ranjan R., 2017, ABS170309507 CORR
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Siciliano B, 2016, SPRINGER HANDBOOK OF ROBOTICS, P1, DOI 10.1007/978-3-319-32552-1
   SIROVICH L, 1987, J OPT SOC AM A, V4, P519, DOI 10.1364/JOSAA.4.000519
   Sun Y, 2014, PROC CVPR IEEE, P1891, DOI 10.1109/CVPR.2014.244
   Taigman Y, 2014, PROC CVPR IEEE, P1701, DOI 10.1109/CVPR.2014.220
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Wang M., 2018, ARXIV180406655
   Yi D., 2014, ARXIV14117923
   Zhang HY, 2018, PROCEEDINGS OF THE 2ND INTERNATIONAL CONFERENCE ON COMPUTER SCIENCE AND APPLICATION ENGINEERING (CSAE2018), DOI 10.1145/3207677.3277958
   Zhang KP, 2016, IEEE SIGNAL PROC LET, V23, P1499, DOI 10.1109/LSP.2016.2603342
   Zhou HL, 2014, IEEE T HUM-MACH SYST, V44, P701, DOI 10.1109/THMS.2014.2340578
   Zhuge C., 2018, ABS180309004 CORR
NR 32
TC 6
Z9 6
U1 1
U2 2
PY 2021
VL 1524
BP 339
EP 350
DI 10.1007/978-3-030-93736-2_26
WC Computer Science, Artificial Intelligence; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Sun, Z
   Pedretti, G
   Mannocci, P
   Ambrosi, E
   Bricalli, A
   Ielmini, D
AF Sun, Zhong
   Pedretti, Giacomo
   Mannocci, Piergiulio
   Ambrosi, Elia
   Bricalli, Alessandro
   Ielmini, Daniele
TI Time Complexity of In-Memory Solution of Linear Systems
SO IEEE TRANSACTIONS ON ELECTRON DEVICES
DT Article
DE In-memory computing (IMC); linear system; resistive memory; time
   complexity
ID NEURAL NETWORKS
AB In-memory computing (IMC) with cross-point resistive memory arrays has been shown to accelerate data-centric computations, such as the training and inference of deep neural networks, due to the high parallelism endowed by physical rules in the electrical circuits. By connecting cross-point arrays with negative feedback amplifiers, it is possible to solve linear algebraic problems, such as linear systems and matrix eigenvectors in just one step. Based on the theory of feedback circuits, we study the dynamics of the solution of linear systems within a memory array, showing that the time complexity of the solution is free of any direct dependence on the problem size N, rather it is governed by theminimal eigenvalue of an associatedmatrix of the coefficient matrix. We show that when the linear system is modeled by a covariancematrix, the time complexity is O(logN) or O(1). In the case of sparse positive-definite linear systems, the time complexity is solely determined by the minimal eigenvalue of the coefficient matrix. These results demonstrate the high speed of the circuit for solving linear systems in a wide range of applications, thus supporting IMC as a strong candidate for future big data and machine learning accelerators.
C1 [Sun, Zhong; Pedretti, Giacomo; Mannocci, Piergiulio; Ambrosi, Elia; Bricalli, Alessandro; Ielmini, Daniele] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
RP Sun, Z; Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, I-20133 Milan, Italy.
EM zhong.sun@polimi.it; daniele.ielmini@polimi.it
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], 2015, RESISTIVE SWITCHING
   [Anonymous], 1989, DENSITY FUNCTIONAL T
   [Anonymous], 2018, IEEE INT EL DEV M IE
   [Anonymous], 2000, MATRIX ANAL APPL LIN
   Bekas C., 2009, P 2 WORKSH HIGH PERF, P1
   Bhatia R, 2007, PRINC SER APPL MATH, P1
   Bhatia R., 1997, MATRIX ANAL
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Bourzac K, 2017, NATURE, V551, P554, DOI 10.1038/d41586-017-07523-y
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Chang TC, 2016, MATER TODAY, V19, P254, DOI 10.1016/j.mattod.2015.11.009
   CICHOCKI A, 1992, IEEE T CIRCUITS-I, V39, P124, DOI 10.1109/81.167018
   Csanky L., 1976, SIAM Journal on Computing, V5, P618, DOI 10.1137/0205040
   Elango V, 2015, ACM SIGPLAN NOTICES, V50, P567, DOI [10.1145/2676726.2677010, 10.1145/2775051.2677010]
   Golub G. H., 2013, MATRIX COMPUTATIONS
   Harrow AW, 2009, PHYS REV LETT, V103, DOI 10.1103/PhysRevLett.103.150502
   HELLER D, 1978, SIAM REV, V20, P740, DOI 10.1137/1020096
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Ielmini D, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/6/063002
   Kent AD, 2015, NAT NANOTECHNOL, V10, P187, DOI 10.1038/nnano.2015.24
   Ladd TD, 2010, NATURE, V464, P45, DOI 10.1038/nature08812
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Mehonic A, 2018, ADV MATER, V30, DOI 10.1002/adma.201801187
   Moler C, 2003, SIAM REV, V45, P3, DOI 10.1137/S00361445024180
   Park J, 2016, IEEE ELECTR DEVICE L, V37, P1559, DOI 10.1109/LED.2016.2622716
   Raoux S, 2010, CHEM REV, V110, P240, DOI 10.1021/cr900040x
   Razavi B., 2005, DESIGN ANALOG CMOS I
   Robertson J, 2004, EUR PHYS J-APPL PHYS, V28, P265, DOI 10.1051/epjap:2004206
   Rojas R., 1996, NEURAL NETWORKS, P149, DOI 10.1007/978-3-642-61068-4_7
   Saad Y., 2003, ITERATIVE METHODS SP
   Seo K, 2011, NANOTECHNOLOGY, V22, DOI 10.1088/0957-4484/22/25/254023
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shewchuk J.R., 1994, CMUCS94125
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Tang JM, 2012, NUMER LINEAR ALGEBR, V19, P485, DOI 10.1002/nla.779
   Waldrop MM, 2016, NATURE, V530, P144, DOI 10.1038/530144a
   Waser R, 2009, ADV MATER, V21, P2632, DOI 10.1002/adma.200900375
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yu S, 2015, 2015 IEEE 5TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS - BERLIN (ICCE-BERLIN), P170, DOI 10.1109/ICCE-Berlin.2015.7391225
   Zheng YR, 2017, PHYS REV LETT, V118, DOI 10.1103/PhysRevLett.118.210504
NR 44
TC 17
Z9 19
U1 2
U2 4
PD JUL
PY 2020
VL 67
IS 7
BP 2945
EP 2951
DI 10.1109/TED.2020.2992435
WC Engineering, Electrical & Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Kim, Y
   Venkataramani, S
   Roy, K
   Raghunathan, A
AF Kim, Younghoon
   Venkataramani, Swagath
   Roy, Kaushik
   Raghunathan, Anand
GP ACM
TI Designing Approximate Circuits using Clock Overgating
SO 2016 ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 53rd ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 05-09, 2016
CL Austin, TX
DE Approximate Computing; Clock Gating; Energy Efficiency
AB Approximate computing is an emerging paradigm to improve the efficiency of computing systems by leveraging the intrinsic resilience of applications to their computations being executed in an approximate manner. Prior efforts on approximate hardware design have largely focused on circuit-level techniques. We propose a new approach, clock overgating, for the design of approximate circuits at the Register Transfer Level (RTL). The key idea is to gate the clock signal to selected Flip-Flops (FFs) in the circuit, even during execution cycles in which the circuit functionality is sensitive to their state. This saves power in the clock tree, the FF itself and in its downstream logic, while a quality loss ensues if the erroneous FF state propagates to the circuit output. We develop a systematic methodology to identify an energy-efficient overgating configuration for any given circuit and quality constraint. Towards this end, we develop 3 key strategies - significance-based overgating, grouping FFs into overgating islands, and utilizing internal signals of the circuit as triggers for overgating - that efficiently prune the large space of possible overgating configurations. We evaluate clock overgating by designing approximate versions of 6 machine learning accelerators, and demonstrate energy benefits of 1.36x on average (and upto 1.80x) for negligible (< 0.5%) loss in application quality (classification accuracy).
C1 [Kim, Younghoon; Venkataramani, Swagath; Roy, Kaushik; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Kim, Y (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM kim1606@purdue.edu; venkata0@purdue.edu; kaushik@purdue.edu;
   raghunathan@purdue.edu
CR [Anonymous], 2014, PROC DESIGN AUTOM TE
   [Anonymous], 2011, DESIGN AUTOMATION TE
   Breuer MA, 2005, DSD 2005: 8TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN, PROCEEDINGS, P2
   Chakradhar ST, 2010, DES AUT CON, P865
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Hegde R., 1999, Proceedings. 1999 International Symposium on Low Power Electronics and Design (Cat. No.99TH8477), P30, DOI 10.1109/LPE.1999.799405
   Huang JW, 2012, DES AUT CON, P504
   Kahng AB, 2012, DES AUT CON, P820
   Krause P. K., 2011, P DATE, P1
   Kulkarni P., 2011, Proceedings of the 24th International Conference on VLSI Design: concurrently with the 10th International Conference on Embedded Systems Design, P346, DOI 10.1109/VLSID.2011.51
   Li CR, 2015, J APPL REMOTE SENS, V8, DOI 10.1117/1.JRS.8.083498
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Misailovic S, 2014, ACM SIGPLAN NOTICES, V49, P309, DOI [10.1145/10.1145/2660193.2660231, 10.1145/2714064.2660231]
   Ranjan A., 2014, P DATE, P1, DOI DOI 10.7873/DATE.2014.377
   Shin D., 2011, P DATE, P1
   Shin D, 2010, DES AUT TEST EUROPE, P957
   Thwaites B, 2014, INT CONFER PARA, P493, DOI 10.1145/2628071.2628110
   Venkataramani S, 2012, DES AUT CON, P796
   Yazdanbakhsh A, 2015, DES AUT TEST EUROPE, P812
   Zhai B, 2009, IEEE T VLSI SYST, V17, P1127, DOI 10.1109/TVLSI.2008.2007564
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
NR 21
TC 5
Z9 5
U1 0
U2 1
PY 2016
DI 10.1145/2897937.2898005
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Chaikittisilp, W
   Yamauchi, Y
   Ariga, K
AF Chaikittisilp, Watcharop
   Yamauchi, Yusuke
   Ariga, Katsuhiko
TI Material Evolution with Nanotechnology, Nanoarchitectonics, and
   Materials Informatics: What will be the Next Paradigm Shift in
   Nanoporous Materials?
SO ADVANCED MATERIALS
DT Review
DE data science; machine learning; mesoporous materials; metal-organic
   frameworks; self-assembly; zeolites
ID METAL-ORGANIC FRAMEWORKS; TRANSMISSION ELECTRON-MICROSCOPY;
   DENSITY-FUNCTIONAL THEORY; CRYSTALLINE SPONGE METHOD; X-RAY
   SPECTROSCOPY; ZEOLITE SYNTHESIS; OXYGEN REDUCTION; CARBON-DIOXIDE;
   COMBINING EXPERIMENTS; COMPUTATION-READY
AB Materials science and chemistry have played a central and significant role in advancing society. With the shift toward sustainable living, it is anticipated that the development of functional materials will continue to be vital for sustaining life on our planet. In the recent decades, rapid progress has been made in materials science and chemistry owing to the advances in experimental, analytical, and computational methods, thereby producing several novel and useful materials. However, most problems in material development are highly complex. Here, the best strategy for the development of functional materials via the implementation of three key concepts is discussed: nanotechnology as a game changer, nanoarchitectonics as an integrator, and materials informatics as a super-accelerator. Discussions from conceptual viewpoints and example recent developments, chiefly focused on nanoporous materials, are presented. It is anticipated that coupling these three strategies together will open advanced routes for the swift design and exploratory search of functional materials truly useful for solving real-world problems. These novel strategies will result in the evolution of nanoporous functional materials.
C1 [Chaikittisilp, Watcharop; Yamauchi, Yusuke; Ariga, Katsuhiko] Natl Inst Mat Sci NIMS, JST ERATO Yamauchi Mat Space Tecton Project, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Chaikittisilp, Watcharop] Natl Inst Mat Sci NIMS, Res & Serv Div Mat Data & Integrated Syst Ma DIS, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Yamauchi, Yusuke; Ariga, Katsuhiko] Natl Inst Mat Sci NIMS, Int Ctr Mat Nanoarchitecton WPI MANA, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.
   [Yamauchi, Yusuke] Univ Queensland, Australian Inst Bioengn & Nanotechnol AIBN, Brisbane, Qld 4072, Australia.
   [Yamauchi, Yusuke] Univ Queensland, Sch Chem Engn, Brisbane, Qld 4072, Australia.
   [Ariga, Katsuhiko] Univ Tokyo, Grad Sch Frontier Sci, 5-1-5 Kashiwanoha, Kashiwa, Chiba 2778561, Japan.
RP Chaikittisilp, W; Yamauchi, Y; Ariga, K (corresponding author), Natl Inst Mat Sci NIMS, JST ERATO Yamauchi Mat Space Tecton Project, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Chaikittisilp, W (corresponding author), Natl Inst Mat Sci NIMS, Res & Serv Div Mat Data & Integrated Syst Ma DIS, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Yamauchi, Y; Ariga, K (corresponding author), Natl Inst Mat Sci NIMS, Int Ctr Mat Nanoarchitecton WPI MANA, 1-1 Namiki, Tsukuba, Ibaraki 3050044, Japan.; Yamauchi, Y (corresponding author), Univ Queensland, Australian Inst Bioengn & Nanotechnol AIBN, Brisbane, Qld 4072, Australia.; Yamauchi, Y (corresponding author), Univ Queensland, Sch Chem Engn, Brisbane, Qld 4072, Australia.; Ariga, K (corresponding author), Univ Tokyo, Grad Sch Frontier Sci, 5-1-5 Kashiwanoha, Kashiwa, Chiba 2778561, Japan.
EM CHAIKITTISILP.Watcharop@nims.go.jp; y.yamauchi@uq.edu.au;
   ARIGA.Katsuhiko@nims.go.jp
CR Aarva A, 2019, CHEM MATER, V31, P9256, DOI 10.1021/acs.chemmater.9b02050
   Aarva A, 2019, CHEM MATER, V31, P9243, DOI 10.1021/acs.chemmater.9b02049
   Allen FH, 2002, ACTA CRYSTALLOGR B, V58, P380, DOI 10.1107/S0108768102003890
   Altintas C, 2019, J MATER CHEM A, V7, P9593, DOI 10.1039/c9ta01378d
   Amrute AP, 2021, CHEM-EUR J, V27, P6819, DOI 10.1002/chem.202004583
   Anantharaj S, 2021, NANO ENERGY, V80, DOI 10.1016/j.nanoen.2020.105514
   [Anonymous], 2017, RES FRONTS
   Aono M, 2016, ADV MATER, V28, P989, DOI 10.1002/adma.201502868
   Ariga K., 2021, CHEM WORLD-UK, V18, P5
   Ariga K, 2008, SCI TECHNOL ADV MAT, V9, DOI 10.1088/1468-6996/9/1/014109
   Ariga K, 2021, SMALL STRUCT, V2, DOI 10.1002/sstr.202100006
   Ariga K, 2021, NANOSCALE HORIZ, V6, P364, DOI 10.1039/d0nh00680g
   Ariga K, 2021, B CHEM SOC JPN, V94, P839, DOI 10.1246/bcsj.20200362
   Ariga K, 2019, SCI TECHNOL ADV MAT, V20, P51, DOI 10.1080/14686996.2018.1553108
   Ariga K, 2020, ANGEW CHEM INT EDIT, V59, P15424, DOI 10.1002/anie.202000802
   Ariga K, 2020, ADV MATER, V32, DOI 10.1002/adma.201905657
   Ariga K, 2020, CHEM-ASIAN J, V15, P718, DOI 10.1002/asia.202000106
   Ariga K, 2019, BEILSTEIN J NANOTECH, V10, P1559, DOI 10.3762/bjnano.10.153
   Ariga K, 2018, CHEM-ASIAN J, V13, P1266, DOI 10.1002/asia.201800225
   Ariga K, 2017, MATER CHEM FRONT, V1, P208, DOI 10.1039/c6qm00240d
   Ariga K, 2016, COORDIN CHEM REV, V320, P139, DOI 10.1016/j.ccr.2016.01.015
   Ariga K, 2016, POLYM J, V48, P371, DOI 10.1038/pj.2016.8
   Ariga K, 2016, ADV MATER, V28, P1251, DOI 10.1002/adma.201502545
   Ariga K, 2015, MATER HORIZ, V2, P406, DOI 10.1039/c5mh00012b
   Ariga K, 2012, NPG ASIA MATER, V4, DOI 10.1038/am.2012.30
   Ariga K, 2012, B CHEM SOC JPN, V85, P1, DOI 10.1246/bcsj.20110162
   Avizienis AV, 2012, PLOS ONE, V7, DOI 10.1371/journal.pone.0042772
   Aykol M, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-10030-5
   Aykol M, 2018, SCI ADV, V4, DOI 10.1126/sciadv.aaq0148
   Azhar A, 2019, B CHEM SOC JPN, V92, P875, DOI 10.1246/bcsj.20180368
   Bacilla ACC, 2021, B CHEM SOC JPN, V94, P34, DOI 10.1246/bcsj.20200188
   Bairi P, 2016, ACS NANO, V10, P6631, DOI 10.1021/acsnano.6b01544
   Baskar AV, 2021, B CHEM SOC JPN, V94, P133, DOI 10.1246/bcsj.20200265
   Bastakoti BP, 2021, J HAZARD MATER, V401, DOI 10.1016/j.jhazmat.2020.123348
   Belgibayeva A, 2021, J POWER SOURCES, V484, DOI 10.1016/j.jpowsour.2020.229308
   Biener J, 2008, ADV MATER, V20, P1211, DOI 10.1002/adma.200701899
   BINNING G, 1982, PHYS REV LETT, V49, P57, DOI 10.1103/PhysRevLett.49.57
   Briggs K, 2018, NANO LETT, V18, P660, DOI 10.1021/acs.nanolett.7b03987
   Burger B, 2020, NATURE, V583, P237, DOI 10.1038/s41586-020-2442-2
   Burner J, 2020, J PHYS CHEM C, V124, P27996, DOI 10.1021/acs.jpcc.0c06334
   Butler KT, 2018, NATURE, V559, P547, DOI 10.1038/s41586-018-0337-2
   Cai XQ, 2021, IND ENG CHEM RES, V60, P639, DOI 10.1021/acs.iecr.0c05398
   Cai ZY, 2018, CHEM REV, V118, P6091, DOI 10.1021/acs.chemrev.7b00536
   Carné-Sánchez A, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04834-0
   Castro Neto AH, 2009, REV MOD PHYS, V81, P109, DOI 10.1103/RevModPhys.81.109
   Chaikittisilp W., 2017, HDB SOLID STATE CHEM, P97, DOI DOI 10.1002/9783527691036.HSSCVOL4013
   Chen KK, 2021, ACS NANO, V15, P2679, DOI 10.1021/acsnano.0c07947
   Chen PC, 2020, MATTER-US, V2, P1651, DOI 10.1016/j.matt.2020.04.021
   Chiorescu I, 2003, SCIENCE, V299, P1869, DOI 10.1126/science.1081045
   Chiu YH, 2019, CATALYSTS, V9, DOI 10.3390/catal9050430
   Cho EH, 2020, J PHYS CHEM C, V124, P27580, DOI 10.1021/acs.jpcc.0c09073
   Cho HS, 2021, ANGEW CHEM INT EDIT, V60, P20504, DOI 10.1002/anie.202107897
   Cho HS, 2019, NAT CHEM, V11, P562, DOI 10.1038/s41557-019-0257-2
   Choi M, 2009, NATURE, V461, P246, DOI 10.1038/nature08288
   Chung YG, 2019, J CHEM ENG DATA, V64, P5985, DOI 10.1021/acs.jced.9b00835
   Chung YG, 2014, CHEM MATER, V26, P6185, DOI 10.1021/cm502594j
   Clayson IG, 2020, ADV MATER, V32, DOI 10.1002/adma.202002780
   Correa-Baena JP, 2018, JOULE, V2, P1410, DOI 10.1016/j.joule.2018.05.009
   Daglar H, 2021, ANGEW CHEM INT EDIT, V60, P7828, DOI 10.1002/anie.202015250
   Datta S, 2020, NATURE, V583, P400, DOI 10.1038/s41586-020-2445-z
   DAVIS ME, 1992, CHEM MATER, V4, P756, DOI 10.1021/cm00022a005
   Davis ME, 2002, NATURE, V417, P813, DOI 10.1038/nature00785
   de Pablo JJ, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0173-4
   de Pablo JJ, 2014, CURR OPIN SOLID ST M, V18, P99, DOI 10.1016/j.cossms.2014.02.003
   Dekker C, 2007, NAT NANOTECHNOL, V2, P209, DOI 10.1038/nnano.2007.27
   Deng HX, 2012, SCIENCE, V336, P1018, DOI 10.1126/science.1220131
   Du QZ, 2018, TRAC-TREND ANAL CHEM, V102, P290, DOI 10.1016/j.trac.2018.02.014
   Durá G, 2016, ANGEW CHEM INT EDIT, V55, P9173, DOI 10.1002/anie.201602226
   Dureckova H, 2019, J PHYS CHEM C, V123, P4133, DOI 10.1021/acs.jpcc.8b10644
   Epps RW, 2020, ADV MATER, V32, DOI 10.1002/adma.202001626
   Evans JD, 2017, CHEM MATER, V29, P7833, DOI 10.1021/acs.chemmater.7b02532
   Falyouna O, 2020, J COLLOID INTERF SCI, V571, P66, DOI 10.1016/j.jcis.2020.03.028
   Fan YX, 2021, ADV MATER, V33, DOI [10.1002/adma.202003956, 10.1002/adma.202004243]
   Feng XY, 2016, ACS NANO, V10, P556, DOI 10.1021/acsnano.5b05579
   Fernandez M, 2013, J PHYS CHEM C, V117, P14095, DOI 10.1021/jp404287t
   Ferreira KN, 2004, SCIENCE, V303, P1831, DOI 10.1126/science.1093087
   Feynman RP, 1960, ENG SCI, V23, P22, DOI [DOI 10.1108/IJCST-06-2013-0067, 10.1201/9781420040623-8]
   Freeze JG, 2019, CHEM REV, V119, P6595, DOI 10.1021/acs.chemrev.8b00759
   Gao P, 2020, J PHYS CHEM LETT, V11, P9812, DOI 10.1021/acs.jpclett.0c02654
   Garcia R, 2014, NAT NANOTECHNOL, V9, P577, DOI [10.1038/NNANO.2014.157, 10.1038/nnano.2014.157]
   Gawande MB, 2021, SMALL, V17, DOI 10.1002/smll.202101584
   Glotov A, 2019, B CHEM SOC JPN, V92, P61, DOI 10.1246/bcsj.20180207
   Greenaway RL, 2021, ADV MATER, V33, DOI 10.1002/adma.202004831
   Gu YM, 2020, J PHYS CHEM C, V124, P9314, DOI 10.1021/acs.jpcc.0c00130
   Guo DH, 2016, SCIENCE, V351, P361, DOI 10.1126/science.aad0832
   Guo YN, 2019, ADV MATER, V31, DOI 10.1002/adma.201807134
   Harada M, 2020, J MATER CHEM A, V8, P15103, DOI 10.1039/d0ta04441e
   Harano K, 2021, B CHEM SOC JPN, V94, P463, DOI 10.1246/bcsj.20200333
   Hasegawa T, 2012, ADV MATER, V24, P252, DOI 10.1002/adma.201102597
   He TJ, 2020, CHEM MATER, V32, P7861, DOI 10.1021/acs.chemmater.0c02553
   Hecht S, 2003, ANGEW CHEM INT EDIT, V42, P24, DOI 10.1002/anie.200390045
   Hetz C, 2020, NAT REV MOL CELL BIO, V21, P421, DOI 10.1038/s41580-020-0250-z
   Hoshino M, 2016, IUCRJ, V3, P139, DOI 10.1107/S2052252515024379
   Hosono N, 2021, B CHEM SOC JPN, V94, P60, DOI 10.1246/bcsj.20200242
   Huang HH, 2019, J MEMBRANE SCI, V572, P12, DOI 10.1016/j.memsci.2018.10.085
   Huff T, 2018, NAT ELECTRON, V1, P636, DOI 10.1038/s41928-018-0180-3
   Huo HY, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0204-1
   Iacomi P, 2020, CHEM MATER, V32, P982, DOI 10.1021/acs.chemmater.9b03376
   Imaoka T, 2019, B CHEM SOC JPN, V92, P941, DOI 10.1246/bcsj.20190008
   Inokuma Y, 2014, B CHEM SOC JPN, V87, P1161, DOI 10.1246/bcsj.20140217
   Inokuma Y, 2013, NATURE, V495, P461, DOI 10.1038/nature11990
   Inokuma Y, 2010, NAT CHEM, V2, P780, DOI [10.1038/NCHEM.742, 10.1038/nchem.742]
   Ishida T, 2020, CHEM REV, V120, P464, DOI 10.1021/acs.chemrev.9b00551
   Jablonka KM, 2020, CHEM REV, V120, P8066, DOI 10.1021/acs.chemrev.0c00004
   Jang J, 2020, J AM CHEM SOC, V142, P18836, DOI 10.1021/jacs.0c07384
   Jena AK, 2019, CHEM REV, V119, P3036, DOI 10.1021/acs.chemrev.8b00539
   Jensen Z, 2021, ACS CENTRAL SCI, V7, P858, DOI 10.1021/acscentsci.1c00024
   Jensen Z, 2019, ACS CENTRAL SCI, V5, P892, DOI 10.1021/acscentsci.9b00193
   Jeong B, 2020, ADV MATER, V32, DOI 10.1002/adma.202000597
   Ji DX, 2019, ADV MATER, V31, DOI 10.1002/adma.201808267
   Ji Q, 2008, J AM CHEM SOC, V130, P2376, DOI 10.1021/ja076139s
   Ji QM, 2009, ADV FUNCT MATER, V19, P1792, DOI 10.1002/adfm.200801762
   Jia Y, 2019, NAT REV CHEM, V3, P361, DOI 10.1038/s41570-019-0100-8
   Jia Y, 2019, ACCOUNTS CHEM RES, V52, P1623, DOI 10.1021/acs.accounts.9b00015
   Jiang JZ, 2019, CHEM SOC REV, V48, P4639, DOI 10.1039/c9cs00348g
   Jordá JL, 2013, ANGEW CHEM INT EDIT, V52, P10458, DOI 10.1002/anie.201305230
   Jung EH, 2019, NATURE, V567, P511, DOI 10.1038/s41586-019-1036-3
   Jung WB, 2020, ADV MATER, V32, DOI 10.1002/adma.201907101
   Kamei K, 2020, B CHEM SOC JPN, V93, P1603, DOI 10.1246/bcsj.20200232
   Kankala RK, 2020, ADV MATER, V32, DOI 10.1002/adma.201907035
   Kato T, 2021, B CHEM SOC JPN, V94, P357, DOI 10.1246/bcsj.20200304
   Kawai S, 2020, ANGEW CHEM INT EDIT, V59, P10842, DOI 10.1002/anie.202001268
   Kawai S, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay8913
   Kazuma E, 2020, B CHEM SOC JPN, V93, P1552, DOI 10.1246/bcsj.20200204
   Kim C, 2018, J PHYS CHEM C, V122, P17575, DOI 10.1021/acs.jpcc.8b02913
   Kimmig J, 2021, ADV MATER, V33, DOI 10.1002/adma.202004940
   Kimura K, 2019, NATURE, V570, P210, DOI 10.1038/s41586-019-1284-2
   Kitagawa S, 2004, ANGEW CHEM INT EDIT, V43, P2334, DOI 10.1002/anie.200300610
   Kobayashi J, 2019, B CHEM SOC JPN, V92, P817, DOI 10.1246/bcsj.20180378
   Konnerth H, 2020, COORDIN CHEM REV, V416, DOI 10.1016/j.ccr.2020.213319
   Kramer D, 2004, NANO LETT, V4, P793, DOI 10.1021/nl049927d
   KRESGE CT, 1992, NATURE, V359, P710, DOI 10.1038/359710a0
   Krishnapriyan AS, 2020, J PHYS CHEM C, V124, P9360, DOI 10.1021/acs.jpcc.0c01167
   Kudo A, 2009, CHEM SOC REV, V38, P253, DOI 10.1039/b800489g
   Lan YS, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-07720-x
   Lee JW, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-019-13749-3
   Lee Y, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15396
   Li BL, 2017, ACS APPL MATER INTER, V9, P15286, DOI 10.1021/acsami.7b02529
   Li CL, 2018, ACCOUNTS CHEM RES, V51, P1764, DOI 10.1021/acs.accounts.8b00119
   Li JG, 2020, ADV SCI, V7, DOI 10.1002/advs.201901957
   Li Y, 2020, B CHEM SOC JPN, V93, P176, DOI 10.1246/bcsj.20190298
   Li Y, 2015, NAT COMMUN, V6, DOI 10.1038/ncomms9328
   Li Y, 2018, ACS NANO, V12, P1455, DOI 10.1021/acsnano.7b07841
   Liang XG, 2020, B CHEM SOC JPN, V93, P581, DOI 10.1246/bcsj.20200012
   Liao W, 2019, ACTA BIOMATER, V86, P1, DOI 10.1016/j.actbio.2018.12.045
   Lim HR, 2020, ADV MATER, V32, DOI 10.1002/adma.201901924
   Liu GQ, 2020, CHEM REV, V120, P6009, DOI 10.1021/acs.chemrev.9b00725
   Liu XM, 2021, J ENERGY CHEM, V53, P290, DOI 10.1016/j.jechem.2020.04.012
   Liu XH, 2020, ADV MATER, V32, DOI 10.1002/adma.202000866
   Liu YZ, 2016, SCIENCE, V351, P365, DOI 10.1126/science.aad4011
   Liu Z, 2013, MICROSCOPY-JPN, V62, P109, DOI 10.1093/jmicro/dfs098
   Cortez ML, 2018, SOFT MATTER, V14, P1939, DOI 10.1039/c8sm00052b
   Lu XF, 2019, ADV MATER, V31, DOI 10.1002/adma.201902339
   Ma RM, 2020, ACS APPL MATER INTER, V12, P34041, DOI 10.1021/acsami.0c06858
   MacLeod BP, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aaz8867
   Maeda K, 2019, B CHEM SOC JPN, V92, P38, DOI 10.1246/bcsj.20180258
   Mahyuddin MH, 2020, B CHEM SOC JPN, V93, P345, DOI 10.1246/bcsj.20190282
   Maji S, 2021, B CHEM SOC JPN, V94, P1502, DOI 10.1246/bcsj.20210059
   Markovich G, 1999, ACCOUNTS CHEM RES, V32, P415, DOI 10.1021/ar980039x
   Martin RL, 2014, J AM CHEM SOC, V136, P5006, DOI 10.1021/ja4123939
   Mi P, 2020, ADV MATER, V32, DOI 10.1002/adma.201902604
   Mishima K, 2020, B CHEM SOC JPN, V93, P1509, DOI 10.1246/bcsj.20200187
   Moghadam PZ, 2019, MATTER-US, V1, P219, DOI 10.1016/j.matt.2019.03.002
   Moghadam PZ, 2017, CHEM MATER, V29, P2618, DOI 10.1021/acs.chemmater.7b00441
   Moliner M, 2013, ANGEW CHEM INT EDIT, V52, P13880, DOI 10.1002/anie.201304713
   Moosavi SM, 2020, J AM CHEM SOC, V142, P20273, DOI 10.1021/jacs.0c09105
   Moosavi SM, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-08483-9
   Muraoka K, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-12394-0
   Nakamura E, 2018, P JPN ACAD B-PHYS, V94, P428, DOI 10.2183/pjab.94.028
   Nishijima H, 1999, APPL PHYS LETT, V74, P4061, DOI 10.1063/1.123261
   NISHIZUKA Y, 1984, NATURE, V308, P693, DOI 10.1038/308693a0
   Noh J, 2020, CHEM SCI, V11, P4871, DOI 10.1039/d0sc00594k
   Nugraha AS, 2020, J MATER CHEM A, V8, P13532, DOI 10.1039/d0ta04096g
   Ohata Y, 2019, B CHEM SOC JPN, V92, P655, DOI 10.1246/bcsj.20180376
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   Ongari D, 2019, ACS CENTRAL SCI, V5, P1663, DOI 10.1021/acscentsci.9b00619
   Otake K, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-14627-z
   Oviedo F, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0196-x
   Pang PF, 2020, B CHEM SOC JPN, V93, P637, DOI 10.1246/bcsj.20190365
   Pardakhti M, 2020, J PHYS CHEM C, V124, P4534, DOI 10.1021/acs.jpcc.9b09319
   Park J, 2017, CHEM MATER, V29, P10487, DOI 10.1021/acs.chemmater.7b04287
   Paruzzo FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06972-x
   Pavlicek N, 2017, NAT NANOTECHNOL, V12, P308, DOI [10.1038/nnano.2016.305, 10.1038/NNANO.2016.305]
   Pavlicek N, 2015, NAT CHEM, V7, P623, DOI [10.1038/NCHEM.2300, 10.1038/nchem.2300]
   Percec V, 2021, B CHEM SOC JPN, V94, P900, DOI 10.1246/bcsj.20210015
   Pophale R, 2011, PHYS CHEM CHEM PHYS, V13, P12407, DOI 10.1039/c0cp02255a
   Qiao JL, 2014, CHEM SOC REV, V43, P631, DOI 10.1039/c3cs60323g
   Qu XB, 2020, ANGEW CHEM INT EDIT, V59, P10297, DOI 10.1002/anie.201908162
   Quo ZW, 2021, J PHYS CHEM C, V125, P7839, DOI 10.1021/acs.jpcc.0c10773
   Raccuglia P, 2016, NATURE, V533, P73, DOI 10.1038/nature17439
   Rainer DN, 2021, DALTON T, V50, P8995, DOI 10.1039/d1dt01440d
   Rajan AC, 2018, CHEM MATER, V30, P4031, DOI 10.1021/acs.chemmater.8b00686
   Rajan K, 2015, ANNU REV MATER RES, V45, P153, DOI 10.1146/annurev-matsci-070214-021132
   Rao CNR, 2019, B CHEM SOC JPN, V92, P441, DOI 10.1246/bcsj.20180335
   Rapenne G, 2017, NAT REV MATER, V2, DOI 10.1038/natrevmats.2017.40
   Rosen AS, 2021, MATTER-US, V4, P1578, DOI 10.1016/j.matt.2021.02.015
   Roukes M, 2001, SCI AM, V285, P48, DOI 10.1038/scientificamerican0901-48
   Roy N, 2019, B CHEM SOC JPN, V92, P178, DOI 10.1246/bcsj.20180250
   Saito Y, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0262-4
   Salinas-Torres D, 2020, B CHEM SOC JPN, V93, P438, DOI 10.1246/bcsj.20190371
   Sang YT, 2019, MOL SYST DES ENG, V4, P11, DOI 10.1039/c8me00068a
   Sasaki Y, 2021, COORDIN CHEM REV, V429, DOI 10.1016/j.ccr.2020.213607
   Schmidt J, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0221-0
   Shi Y, 2021, ACCOUNTS CHEM RES, V54, P546, DOI 10.1021/acs.accounts.0c00736
   Shi YF, 2021, CHEM REV, V121, P649, DOI 10.1021/acs.chemrev.0c00454
   Shimizu T, 2020, B CHEM SOC JPN, V93, P1079, DOI 10.1246/bcsj.20200134
   Sillin HO, 2013, NANOTECHNOLOGY, V24, DOI 10.1088/0957-4484/24/38/384004
   Simpson GJ, 2017, NAT NANOTECHNOL, V12, P604, DOI 10.1038/nnano.2017.137
   Singh B, 2020, B CHEM SOC JPN, V93, P1459, DOI 10.1246/bcsj.20200136
   Singh G, 2021, B CHEM SOC JPN, V94, P1232, DOI 10.1246/bcsj.20200379
   Suga M, 2015, NATURE, V517, P99, DOI 10.1038/nature13991
   Sugimoto Y, 2007, NATURE, V446, P64, DOI 10.1038/nature05530
   Sun HM, 2020, ADV MATER, V32, DOI 10.1002/adma.201806326
   Sun QM, 2020, ADV MATER, V32, DOI 10.1002/adma.202001818
   Sun WB, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aay4275
   Tamura T, 2006, JPN J APPL PHYS 2, V45, pL364, DOI 10.1143/JJAP.45.L364
   Tan C, 2020, CHEM COMMUN, V56, P2811, DOI 10.1039/c9cc09966b
   Tang J, 2015, J AM CHEM SOC, V137, P1572, DOI 10.1021/ja511539a
   Tao QL, 2021, NPJ COMPUT MATER, V7, DOI 10.1038/s41524-021-00495-8
   Tayfuroglu O, 2020, LANGMUIR, V36, P119, DOI 10.1021/acs.langmuir.9b03618
   Wada N, 2018, ANGEW CHEM INT EDIT, V57, P3671, DOI 10.1002/anie.201713219
   Wan HR, 2021, B CHEM SOC JPN, V94, P961, DOI 10.1246/bcsj.20200380
   Wang CH, 2020, CHEM-US, V6, P19, DOI 10.1016/j.chempr.2019.09.005
   Wang HF, 2020, CHEM SOC REV, V49, P1414, DOI 10.1039/c9cs00906j
   Wang HJ, 2012, J AM CHEM SOC, V134, P10819, DOI 10.1021/ja303773z
   Wang J, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15717
   Wang Q, 2020, CHEM REV, V120, P919, DOI 10.1021/acs.chemrev.9b00201
   Wang S, 2020, ANGEW CHEM INT EDIT, V59, P19645, DOI 10.1002/anie.202005931
   Wang S, 2019, ACS MATER LETT, V1, P558, DOI 10.1021/acsmaterialslett.9b00374
   Wang Y, 2020, MATER TODAY, V32, P178, DOI 10.1016/j.mattod.2019.06.005
   Wang Z, 2019, CHEM SOC REV, V48, P2109, DOI 10.1039/c8cs00542g
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wei LF, 2019, CHEM MATER, V31, P7340, DOI 10.1021/acs.chemmater.9b01953
   Wei YS, 2020, CHEM REV, V120, P12089, DOI 10.1021/acs.chemrev.9b00757
   Wiktor C, 2017, J MATER CHEM A, V5, P14969, DOI 10.1039/c7ta00194k
   Willhammar T, 2014, ADV FUNCT MATER, V24, P182, DOI 10.1002/adfm.201301949
   Wilmer CE, 2012, NAT CHEM, V4, P83, DOI [10.1038/nchem.1192, 10.1038/NCHEM.1192]
   Wu YJ, 2019, NPJ COMPUT MATER, V5, DOI 10.1038/s41524-019-0193-0
   Wu Y, 2020, CHEM MATER, V32, P2986, DOI 10.1021/acs.chemmater.9b05322
   Xiao X, 2020, CHEM SOC REV, V49, P301, DOI 10.1039/c7cs00614d
   Xie YC, 2020, J AM CHEM SOC, V142, P1475, DOI 10.1021/jacs.9b11569
   Xing JF, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-11564-4
   Xiong MY, 2020, ACS NANO, V14, P16131, DOI 10.1021/acsnano.0c08382
   Xu GR, 2021, COORDIN CHEM REV, V427, DOI 10.1016/j.ccr.2020.213554
   Yabuuchi N, 2014, CHEM REV, V114, P11636, DOI 10.1021/cr500192f
   Yamada H, 2019, ACS CENTRAL SCI, V5, P1717, DOI 10.1021/acscentsci.9b00804
   Yamada Y, 2020, B CHEM SOC JPN, V93, P109, DOI 10.1246/bcsj.20190314
   Yamashita M, 2021, B CHEM SOC JPN, V94, P209, DOI 10.1246/bcsj.20200257
   YANAGISAWA T, 1990, B CHEM SOC JPN, V63, P988, DOI 10.1246/bcsj.63.988
   Yang JC, 2019, ADV MATER, V31, DOI 10.1002/adma.201904765
   Yang LJ, 2019, ADV MATER, V31, DOI 10.1002/adma.201804799
   Ye WK, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-06322-x
   Yonamine Y, 2016, PHYS CHEM CHEM PHYS, V18, P12576, DOI 10.1039/c6cp01586g
   Yonamine Y, 2015, PHYS CHEM CHEM PHYS, V17, P32122, DOI 10.1039/c5cp05765e
   Zeng YX, 2019, ADV MATER, V31, DOI 10.1002/adma.201903675
   Zhang DL, 2018, SCIENCE, V359, P675, DOI 10.1126/science.aao0865
   Zhang NN, 2021, ANGEW CHEM INT EDIT, V60, P2861, DOI 10.1002/anie.202012322
   Zhang Q, 2020, ANGEW CHEM INT EDIT, V59, P19403, DOI 10.1002/anie.202007490
   Zhang XY, 2020, CHEM SCI, V11, P10844, DOI 10.1039/d0sc02048f
   Zhang ZH, 2019, ANGEW CHEM INT EDIT, V58, P259, DOI 10.1002/anie.201812363
   Zhao YC, 2021, NAT COMMUN, V12, DOI 10.1038/s41467-021-22472-x
   Zhao YX, 2019, ADV MATER, V31, DOI 10.1002/adma.201806482
   Zheng C, 2018, NPJ COMPUT MATER, V4, DOI 10.1038/s41524-018-0067-x
   Zhu QL, 2016, CHEM-US, V1, P220, DOI 10.1016/j.chempr.2016.07.005
   Zhu YH, 2017, NAT MATER, V16, P532, DOI [10.1038/NMAT4852, 10.1038/nmat4852]
NR 265
TC 58
Z9 58
U1 54
U2 326
PD FEB
PY 2022
VL 34
IS 7
AR 2107212
DI 10.1002/adma.202107212
EA JAN 2022
WC Chemistry, Multidisciplinary; Chemistry, Physical; Nanoscience &
   Nanotechnology; Materials Science, Multidisciplinary; Physics, Applied;
   Physics, Condensed Matter
HC Y
HP N
DA 2023-11-11
ER

PT C
AU Arora, A
   Wei, ZG
   John, LK
AF Arora, Aman
   Wei, Zhigang
   John, Lizy K.
BE Hannig, F
   Navaridas, J
   Koch, D
   Abdelhadi, A
TI Hamamu: Specializing FPGAs for ML Applications by Adding Hard Matrix
   Multiplier Blocks
SO 2020 IEEE 31ST INTERNATIONAL CONFERENCE ON APPLICATION-SPECIFIC SYSTEMS,
   ARCHITECTURES AND PROCESSORS (ASAP 2020)
SE IEEE International Conference on Application-Specific Systems
   Architectures and Processors
DT Proceedings Paper
CT 31st IEEE International Conference on Application-Specific Systems,
   Architectures and Processors (ASAP)
CY JUL 06-08, 2020
CL Univ Manchester, Dept Comp Sci, Manchester, ENGLAND
HO Univ Manchester, Dept Comp Sci
ID ARCHITECTURE
AB Designing efficient hardware for accelerating artificial intelligence (AI) and machine learning (ML) applications is a major challenge. Rapidly changing algorithms and neural network architectures make FPGA based designs an attractive solution. But the generic building blocks available in current FPGAs (Logic Blocks (LBs), multipliers, DSP blocks) limit the acceleration that can be achieved. We propose Hamamu, a modification to the current FPGA architecture that makes FPGAs specialized for ML applications. Specifically, we propose adding hard matrix multiplier blocks (matmuls) into the FPGA fabric. These matmuls are implemented using systolic arrays of MACs (Multiply-And-Accumulate) and can be connected using programmable direct interconnect between neighboring matmuls to make larger systolic matrix multipliers. We explore various matmul sizes (2x2x2, 4x4x4, 8x8x8, 16x16x16) and various strategies to place these blocks on the FPGA (Columnar, Surround, Hybrid). We find that providing 4x4x4 hard matrix multiplier blocks in an FPGA speeds up neural networks from MLPerf benchmarks by up to (similar to)3.9x, compared to a Stratix-10 like FPGA with equal number of MACs, same MAC architecture and high DSP:LB ratio. Although the flexibility of the FPGA will reduce for non-ML applications, an FPGA with hard matrix multipliers is a faster, and more area efficient hardware accelerator for ML applications, compared to current FPGAs.
C1 [Arora, Aman; Wei, Zhigang; John, Lizy K.] Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
RP Arora, A (corresponding author), Univ Texas Austin, Dept Elect & Comp Engn, Austin, TX 78712 USA.
EM aman.kbm@utexas.edu; zw5259@utexas.edu; ljohn@ece.utexas.edu
CR Abdelfattah M. S., 2018, CORR
   Achronix, 2019, SPEEDSTER7T FPGAS
   [Anonymous], 2017, NVID TESL V100 GPU A, P1
   Boutros A, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P94, DOI 10.1145/3289602.3293912
   Boutros A, 2018, I C FIELD PROG LOGIC, P35, DOI 10.1109/FPL.2018.00014
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Flex-Logix, 2019, FLEX LOG EFLX EFPGA
   Flex-Logix, 2019, FLEX LOG NNMAX INF A
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Ho CH, 2007, I C FIELD PROG LOGIC, P196, DOI 10.1109/FPL.2007.4380647
   Jamieson PA, 2010, IEEE T VLSI SYST, V18, P1696, DOI 10.1109/TVLSI.2009.2026651
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Keller R. M., 2011, SYSTOLIC ARRAYS ALGO
   KUNG HT, 1982, COMPUTER, V15, P37, DOI 10.1109/MC.1982.1653825
   Kuon I, 2007, FOUND TRENDS ELECTRO, V2, P135, DOI 10.1561/1000000005
   Lacey G., 2016, CORR
   Luu J, 2014, ACM T RECONFIG TECHN, V7, DOI 10.1145/2617593
   Nurvitadhi E., 2018, IN PACKAGE DOMAIN SP, P287
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Rasoulinezhad S, 2019, ANN IEEE SYM FIELD P, P35, DOI 10.1109/FCCM.2019.00015
   Stillmaker A, 2017, INTEGRATION, V58, P74, DOI 10.1016/j.vlsi.2017.02.002
   Synopsys, 2018, SYN DES COMP
   Synopsys, 2018, SYNOPS VCS
   Xilinx, 2018, XIL AI ENG THEIR APP
   Xilinx, 2018, ACC DNNS XIL ALV ACC
   Yu C., 2010, ROUTING OPTIMIZATION, P419
   Yu CW, 2008, 2008 4TH SOUTHERN CONFERENCE ON PROGRAMMABLE LOGIC, PROCEEDINGS, P63, DOI 10.1109/SPL.2008.4547733
NR 27
TC 6
Z9 6
U1 0
U2 0
PY 2020
BP 53
EP 60
DI 10.1109/ASAP49362.2020.00018
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Luo, AW
   An, FW
   Zhang, XY
   Mattausch, HJ
AF Luo, Aiwen
   An, Fengwei
   Zhang, Xiangyu
   Mattausch, Hans Juergen
TI A Hardware-Efficient Recognition Accelerator Using Haar-Like Feature and
   SVM Classifier
SO IEEE ACCESS
DT Article
DE Hardware architecture; Haar-like feature extraction; support vector
   machine (SVM); object recognition; high-speed processing; flexible
   memory allocation; high resolution image
ID ORIENTED GRADIENTS; COMPUTER VISION; ALGORITHM; MODELS; SPARSE
AB Significantly improved performance of the various learning algorithms has revived the interest in computer vision for recognition applications during the current decade. This paper reports a vision-based hardware recognition architecture combining the Haar-like feature extraction with the support vector machine (SVM) classification. To support an optimal tradeoff between resource requirements, processing speed, and recognition accuracy, a 12-bit fixed-point computation for block-based feature normalization and a recycling allocation of minimalized memory resources are proposed in this paper. Furthermore, an efficient scale generation of target objects for recognition is enabled by configurable windows with high size flexibility. Additionally, a parallel-partial SVM-classification architecture is developed for improving the recognition speed, by accumulating the partially completed SVM results for multiple windows in parallel. The proposed hardware architecture is verified with an Altera DE4 platform to achieve a high throughput rate of 216 and 70 f/s for XGA (1024 x 768) and HD (1920 x 1080) video resolutions, respectively. A recycled memory space of only 193 KB is sufficient for processing high-resolution images up to 2048 x 2048 pixels during online testing. Using the INRIA person dataset, 89.81% average precision and maximum accuracy of 96.93% for pedestrian recognition are realized. Furthermore, about 99.08% accuracy is achieved for two car recognition tasks using the UIUC dataset (side view of cars) and a frontal car dataset collected by ourselves at Hiroshima University with the proposed hardware-architecture framework.
C1 [Luo, Aiwen; Mattausch, Hans Juergen] Hiroshima Univ, HiSIM Res Ctr, Higashihiroshima 7398530, Japan.
   [Luo, Aiwen] Hiroshima Univ, Global Career Design Ctr, Higashihiroshima 7398514, Japan.
   [An, Fengwei; Zhang, Xiangyu] Hiroshima Univ, Grad Sch Engn, Higashihiroshima 7398527, Japan.
RP Luo, AW (corresponding author), Hiroshima Univ, HiSIM Res Ctr, Higashihiroshima 7398530, Japan.; Luo, AW (corresponding author), Hiroshima Univ, Global Career Design Ctr, Higashihiroshima 7398514, Japan.
EM luoaiwen@hiroshima-u.ac.jp
CR Agarwal S, 2004, IEEE T PATTERN ANAL, V26, P1475, DOI 10.1109/TPAMI.2004.108
   [Anonymous], 2005, INRIA PERSON DATASET
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Bengler K, 2014, IEEE INTEL TRANSP SY, V6, P6, DOI 10.1109/MITS.2014.2336271
   Bhatia N., 2010, INT J COMPUT SCI INF, V8, P302, DOI DOI 10.1016/J.PMCJ.2015.02.001
   CISCO, 2018, CISCO GLOBAL CLOUD I
   Cristianini N., 2000, INTRO SUPPORT VECTOR, DOI DOI 10.1017/CBO9780511801389
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   David  P., PYTHON RESOURCES
   Dollár P, 2012, IEEE T PATTERN ANAL, V34, P743, DOI 10.1109/TPAMI.2011.155
   Dürre J, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P163, DOI 10.1145/3174243.3174249
   Nguyen-Tuong D, 2011, COGN PROCESS, V12, P319, DOI 10.1007/s10339-011-0404-1
   Greenhalgh J, 2012, IEEE T INTELL TRANSP, V13, P1498, DOI 10.1109/TITS.2012.2208909
   Hahnle M, 2013, IEEE COMPUT SOC CONF, P629, DOI 10.1109/CVPRW.2013.95
   Hassan A, 2018, IEEE ACCESS, V6, P13949, DOI 10.1109/ACCESS.2018.2814818
   Hu WM, 2008, IEEE T SYST MAN CY B, V38, P577, DOI 10.1109/TSMCB.2007.914695
   Huang J, 2017, IEEE INT C INT ROBOT, P3296, DOI 10.1109/IROS.2017.8206166
   ITAKURA F, 1975, IEEE T ACOUST SPEECH, VAS23, P67, DOI 10.1109/TASSP.1975.1162641
   Klikauer T, 2016, TRIPLEC-COMMUN CAPIT, V14, P260
   Li ZS, 2017, IEEE INT SYMP PARAL, P143, DOI 10.1109/ISPA/IUCC.2017.00030
   Liu ZY, 2018, IEEE ACCESS, V6, P57006, DOI 10.1109/ACCESS.2018.2872939
   Lopez-Martin M, 2017, IEEE ACCESS, V5, P18042, DOI 10.1109/ACCESS.2017.2747560
   Lowe DG, 2004, INT J COMPUT VISION, V60, P91, DOI 10.1023/B:VISI.0000029664.99615.94
   Luo AW, 2018, IEEE T VLSI SYST, V26, P431, DOI 10.1109/TVLSI.2017.2774813
   Luo AW, 2017, JPN J APPL PHYS, V56, DOI 10.7567/JJAP.56.04CF06
   Mizuno K, 2012, IEEE WORKSHOP SIG, P197, DOI 10.1109/SiPS.2012.57
   Och FJ, 2003, 41ST ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P160
   Oliver NM, 2000, IEEE T PATTERN ANAL, V22, P831, DOI 10.1109/34.868684
   Papineni K, 2002, 40TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS, PROCEEDINGS OF THE CONFERENCE, P311, DOI 10.3115/1073083.1073135
   RABINER LR, 1989, P IEEE, V77, P257, DOI 10.1109/5.18626
   Redmon J, 2018, Arxiv, DOI [arXiv:1804.02767, 10.48550/arXiv.1804.02767]
   Ren SQ, 2017, IEEE T PATTERN ANAL, V39, P1137, DOI 10.1109/TPAMI.2016.2577031
   Rister B, 2013, INT CONF ACOUST SPEE, P2674, DOI 10.1109/ICASSP.2013.6638141
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Schroff F, 2015, PROC CVPR IEEE, P815, DOI 10.1109/CVPR.2015.7298682
   Sivaraman S, 2010, IEEE T INTELL TRANSP, V11, P267, DOI 10.1109/TITS.2010.2040177
   Su YC, 2012, IEEE J SOLID-ST CIRC, V47, P797, DOI 10.1109/JSSC.2012.2185349
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szeliski R, 2011, TEXTS COMPUT SCI, P1, DOI 10.1007/978-1-84882-935-0
   Tang YX, 2018, IEEE T PATTERN ANAL, V40, P3045, DOI 10.1109/TPAMI.2017.2771779
   Tang YX, 2014, IEEE IMAGE PROC, P4072, DOI 10.1109/ICIP.2014.7025827
   Vapnik VN., 1998, STAT LEARNING THEORY
   Viola P, 2004, INT J COMPUT VISION, V57, P137, DOI 10.1023/B:VISI.0000013087.49260.fb
   Wright J, 2010, P IEEE, V98, P1031, DOI 10.1109/JPROC.2010.2044470
   Xu Y, 2015, IEEE IMAGE PROC, P3452, DOI 10.1109/ICIP.2015.7351445
   Yin SY, 2017, IEEE SYST J, V11, P260, DOI 10.1109/JSYST.2015.2418680
   Zeng HQ, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P117, DOI 10.1145/3174243.3174265
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P25, DOI 10.1145/3020078.3021698
   Zhang XY, 2017, JPN J APPL PHYS, V56, DOI 10.7567/JJAP.56.04CF01
NR 49
TC 15
Z9 15
U1 1
U2 13
PY 2019
VL 7
BP 14472
EP 14487
DI 10.1109/ACCESS.2019.2894169
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Kim, J
   Kang, M
   Han, Y
   Kim, YG
   Kim, LS
AF Kim, Junkyum
   Kang, Myeonggu
   Han, Yunki
   Kim, Yang-gon
   Kim, Lee-sup
GP IEEE
TI OptimStore: In-Storage Optimization of Large Scale DNNs with On-Die
   Processing
SO 2023 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE, HPCA
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 29th IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY FEB 25-MAR 01, 2023
CL Montreal, CANADA
AB Training deep neural network (DNN) models is a resource-intensive, iterative process. For this reason, nowadays, complex optimizers like Adam are widely adopted as it increases the speed and efficiency of training. These optimizers, however, employ additional variables and raise the memory demand 2x to 3x of model parameters, worsening the memory capacity bottleneck. Moreover, as the size of DNN models is projected to grow even further, it is not practical to assume that the future models will fit in accelerator memory. This has triggered various efforts to offload models to flash-based storage. However, when the model, especially the optimizer, is offloaded to flash, the limited I/O bandwidth severely slows down the overall training process. To this end, we present OptimStore, a solid-state drive (SSD) system with on-die processing (ODP) architectures for gradient descent-based machine learning models. OptimStore accelerates the training process of such large-scale models by processing model optimization in the storage device, specifically inside the flash dies. ODP capability of OptimStore eliminates the heavy data movement over external interconnect and internal flash channels. Overall, OptimStore achieves, on average, a 2.8x speedup and a 3.6x improved energy efficiency in the weight update stage over baseline SSD offloading.
C1 [Kim, Junkyum] Samsung Elect, SAIT, Seoul, South Korea.
   [Kim, Junkyum; Kang, Myeonggu; Han, Yunki; Kim, Yang-gon; Kim, Lee-sup] Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
   [Kim, Yang-gon] Samsung Elect, Syst LSI, Seoul, South Korea.
RP Kim, J (corresponding author), Samsung Elect, SAIT, Seoul, South Korea.; Kim, J (corresponding author), Korea Adv Inst Sci & Technol, Sch Elect Engn, Daejeon, South Korea.
CR Agrawal A, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126918
   Brown TB, 2020, Arxiv, DOI [arXiv:2005.14165, DOI 10.48550/ARXIV.2005.14165]
   Bae J, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P387
   Cai Y, 2012, DES AUT TEST EUROPE, P521
   Chandrasekar K., DRAMPOWER OPEN SOURC
   Choe H, 2017, Arxiv, DOI arXiv:1610.02273
   Choi C., 2016, FLASH MEM SUMM
   Das D, 2018, Arxiv, DOI arXiv:1802.00930
   Do Jaeyoung, 2013, P 2013 ACM SIGMOD IN, P1221
   Duchi J, 2011, J MACH LEARN RES, V12, P2121
   Ge LL, 2020, IEEE CIRC SYST MAG, V20, P30, DOI 10.1109/MCAS.2020.2988388
   Ghiasi NM, 2022, ASPLOS '22: PROCEEDINGS OF THE 27TH ACM INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P635, DOI 10.1145/3503222.3507702
   Gouk D, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P469, DOI 10.1109/MICRO.2018.00045
   Gupta S, 2020, ICCAD-IEEE ACM INT, DOI 10.1145/3400302.3415723
   Hildebrand M, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P875, DOI 10.1145/3373376.3378465
   Huang CC, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P1341, DOI 10.1145/3373376.3378530
   Jeong WS, 2020, IEEE T PARALL DISTR, V31, P1137, DOI 10.1109/TPDS.2019.2953646
   Jia XY, 2018, Arxiv, DOI arXiv:1807.11205
   Jun SW, 2016, IEEE HIGH PERF EXTR
   K. Corporation, KIOX TECHN BRIEF
   Kang D, 2019, ISSCC DIG TECH PAP I, V62, P216, DOI 10.1109/ISSCC.2019.8662493
   Kim H, 2021, INT S HIGH PERF COMP, P249, DOI 10.1109/HPCA51647.2021.00030
   Kim S, 2021, PROCEEDINGS OF THE 19TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '21), P371
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Koo G, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P219, DOI 10.1145/3123939.3124553
   Kuchaiev O, 2018, Arxiv, DOI arXiv:1805.10387
   Kwon M, 2022, Arxiv, DOI arXiv:2201.09189
   Kwon Y, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P148, DOI 10.1109/MICRO.2018.00021
   Li CY, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P225
   Liang SW, 2019, I C FIELD PROG LOGIC, P173, DOI 10.1109/FPL.2019.00035
   Liang SW, 2019, PROCEEDINGS OF THE 2019 USENIX ANNUAL TECHNICAL CONFERENCE, P395
   Liu Re., 2012, TARGET-NETH
   Luo YX, 2015, IEEE S MASS STOR SYS
   Luo YX, 2018, P ACM MEAS ANAL COMP, V2, DOI [10.1145/3224432, 10.1145/3292040.3219659]
   Mailthody VS, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P224, DOI 10.1145/3352460.3358320
   Michael O., 2016, U.S. Patent, Patent No. 9367392
   Micikevicius P., 2017, ARXIV171003740
   Microsoft, DEEPSPEED
   Minsub Kim, 2020, APSys 20. Proceedings of the 2020 SIGOPS Asia-Pacific Workshop on Systems, P90, DOI 10.1145/3409963.3410501
   Dauphin YN, 2015, Arxiv, DOI arXiv:1502.04390
   O. N. F. Interface, ONF 50 SPEC
   Park J, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P702, DOI 10.1145/3445814.3446719
   Pati S, 2021, Arxiv, DOI arXiv:2104.08335
   Peng X, 2020, TWENTY-FIFTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXV), P891, DOI 10.1145/3373376.3378505
   Radford A., 2018, IMPROVING LANGUAGE U
   Radford A., 2019, OPENAI BLOG
   Raffel C, 2020, Arxiv, DOI [arXiv:1910.10683, DOI 10.48550/ARXIV.1910.10683]
   Rajbhandari S, 2021, Arxiv, DOI arXiv:2104.07857
   Rajbhandari S, 2020, PROCEEDINGS OF SC20: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS (SC20), DOI 10.1109/SC41405.2020.00024
   Ren J, 2021, INT S HIGH PERF COMP, P598, DOI 10.1109/HPCA51647.2021.00057
   Seagate, FIRECUDA530 PCIE 40
   Seshadri S., 2014, 11 USENIX S OPERATIN
   Sheng Li, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P469
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Stoica R, 2019, I S MOD ANAL SIM COM, P152, DOI 10.1109/MASCOTS.2019.00025
   Synopsys I, DESIGN COMPILER
   Szegedy C, 2015, PROC CVPR IEEE, P1, DOI 10.1109/CVPR.2015.7298594
   Tiwari D., 2012, 2012 WORKSH POW AW C
   Tiwari Devesh, 2013, P 11 USENIX C FILE S, P119
   Vaswani A, 2017, ADV NEUR IN, V30
   Walczyk C. J., 2018, IMPROVING ACCURACY F
   Wilkening M, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P717, DOI 10.1145/3445814.3446763
   Yoon J, 2020, ANN I S COM, P693, DOI 10.1109/ISCA45697.2020.00063
NR 63
TC 1
Z9 1
U1 0
U2 0
PY 2023
BP 611
EP 623
DI 10.1109/HPCA56546.2023.10071024
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Aweisi, A
   Arora, D
   Emby, R
   Rehman, M
   Tanev, G
   Tanev, S
AF Aweisi, Abdulla
   Arora, Daman
   Emby, Renee
   Rehman, Madiha
   Tanev, George
   Tanev, Stoyan
TI Using Web Text Analytics to Categorize the Business Focus of Innovative
   Digital Health Companies
SO TECHNOLOGY INNOVATION MANAGEMENT REVIEW
DT Article
DE Digital health sector; topic modeling algorithm; market offer; value
   proposition; machine learning; web analytics
AB Categorizing the market focus of larger samples of companies can be a tedious and time-consuming process for both researchers and business analysts interested in developing insights about emerging business sectors. The objective of this article is to suggest a text analytics approach to categorizing the application areas of companies operating in the digital health sector based on the information provided on their websites. More specifically, we apply topic modeling on a collection of text documents, including information collected from the websites of a sample of 100 innovative digital health companies. The topic model helps in grouping the companies offering similar types of market offers. It enables identifying the companies that are most highly associated with each of the topics. In addition, it allows identifying some of the emerging themes that are discussed online by the companies, as well as their specific market offers. The results will be of interest to aspiring technology entrepreneurs, organizations supporting new ventures, and business accelerators interested to enhance their services to new venture clients. The development, operationalization, and automation of the company categorization process based on publicly available information is a methodological contribution that opens the opportunity for future applications in research and business practice.
C1 [Aweisi, Abdulla] TechBrew Robot, Salmon Arm, BC, Canada.
   [Arora, Daman] Carleton Univ, TIM Program, Appl Business Analyt Degree, Ottawa, ON, Canada.
   [Emby, Renee] Shared Serv Canada, Ottawa, ON, Canada.
   [Tanev, George] Export Dev Canada, Ottawa, ON, Canada.
   [Tanev, Stoyan] Carleton Univ, Sprott Sch Business, Technol Innovat Management TIM Program, Ottawa, ON, Canada.
   [Tanev, Stoyan] Univ Southern Denmark SDU, Fac Engn, Innovat & Design Engn Sect, Odense, Denmark.
RP Aweisi, A (corresponding author), TechBrew Robot, Salmon Arm, BC, Canada.
CR Blei DM, 2012, COMMUN ACM, V55, P77, DOI 10.1145/2133806.2133826
   Hannigan TR, 2019, ACAD MANAG ANN, V13, P586, DOI 10.5465/annals.2017.0099
   Hecking T., 2018, TOPIC MODELLING EMPI
   Johnson MW, 2008, HARVARD BUS REV, V86, P50
   Mamosian H., 2018, P ISPIM CONN FUK C
   Taney S, 2015, EXPERT SYST APPL, V42, P7582, DOI 10.1016/j.eswa.2015.06.006
   Tang JT, 2012, J BUS VENTURING, V27, P77, DOI 10.1016/j.jbusvent.2010.07.001
   Wulfovich S., 2020, DIGITAL HLTH ENTREPR
NR 8
TC 2
Z9 2
U1 0
U2 5
PY 2021
VL 11
IS 7-8
BP 65
EP 78
DI 10.22215/timreview/1457
WC Management
DA 2023-11-11
ER

PT J
AU Tang, YQ
   Zhang, JT
   Verma, N
AF Tang, Yinqi
   Zhang, Jintao
   Verma, Naveen
TI Scaling Up In-Memory-Computing Classifiers via Boosted Feature Subsets
   in Banked Architectures
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS II-EXPRESS BRIEFS
DT Article
DE Boosting; feature segmentation; in-memory computing; machine learning;
   multi-armed bandits
AB In-memory computing is an emerging approach for overcoming memory-accessing bottlenecks, by eliminating the costs of explicitly moving data from point of storage to point of computation outside the array. However, computation increases the dynamic range of signals, such that performing it via the existing structure of dense memory substantially squeezes the signal-to-noise ratio (SNR). In this brief, we explore how computations can be scaled up, to jointly optimize energy/latency/bandwidth gains with SNR requirements. We employ algorithmic techniques to decompose computations so that they can be mapped to multiple parallel memory banks operating at chosen optimal points. Specifically focusing on in-memory classification, we consider a custom IC in 130-nm CMOS IC and demonstrate an algorithm combining error-adaptive classifier boosting and multi-armed bandits, to enable segmentation of a feature vector into multiple subsets. The measured performance of 10-way MNIST digit classification, using images downsampled to 16x16 pixels (mapped across four separate banks), is 91%, close to that simulated using full unsegmented feature vectors. The energy per classification is 879.7 pJ, 14.3x lower than that of a system based on separated memory and digital accelerator.
C1 [Tang, Yinqi; Zhang, Jintao; Verma, Naveen] Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
RP Tang, YQ (corresponding author), Princeton Univ, Dept Elect Engn, Princeton, NJ 08544 USA.
EM yinqit@princeton.edu; jintao@princeton.edu; nverma@princeton.edu
CR Aly M. A., 2006, INT J ARTIF INTELL M, V6, P1
   [Anonymous], 2009, JMLR WORKSHOP C P KD
   [Anonymous], 2016, MICRO
   Auer P, 2003, SIAM J COMPUT, V32, P48, DOI 10.1137/S0097539701398375
   Busa-Fekete R., 2010, INT C MACH LEARN, V27, P143
   Freund Y, 1997, J COMPUT SYST SCI, V55, P119, DOI 10.1006/jcss.1997.1504
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Schapire RE, 1999, MACH LEARN, V37, P297, DOI 10.1023/A:1007614523901
   Wang Z, 2015, IEEE T CIRCUITS-I, V62, P1136, DOI 10.1109/TCSI.2015.2395591
   Zhang JT, 2017, IEEE J SOLID-ST CIRC, V52, P915, DOI 10.1109/JSSC.2016.2642198
NR 14
TC 7
Z9 9
U1 1
U2 7
PD MAR
PY 2019
VL 66
IS 3
BP 477
EP 481
DI 10.1109/TCSII.2018.2854759
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Li, J
   Wang, Y
   Zi, YY
   Sun, XJ
   Yang, Y
AF Li, Jie
   Wang, Yu
   Zi, Yanyang
   Sun, Xiaojie
   Yang, Ying
TI A Current Signal-Based Adaptive Semisupervised Framework for Bearing
   Faults Diagnosis in Drivetrains
SO IEEE TRANSACTIONS ON INSTRUMENTATION AND MEASUREMENT
DT Article
DE Bearing faults; current signals; generative adversarial network;
   semisupervised learning; signal processing
ID INDUCTION MACHINES; FEATURE-EXTRACTION; NETWORK
AB In most practical applications of fault diagnosis methods, two problems will inevitably arise. First, limited by the monitored object itself and its environment, accelerators are difficult to install. Second, industrial applications lack data with fault labels, which limits the use of data-driven-based methods. To solve these problems, a current signal-based adaptive semisupervised framework (C-ASSF) is proposed. In C-ASSF, the Wasserstein generative adversarial network with gradient penalty (WGAN-CP) is adopted to extract recognizable features from only normal current signals. Subsequently, since WGAN-GP pays too much attention to body signals and ignores the changes caused by faults, the line spectrum feature extraction (LSFE) technique is utilized to remove the main frequency component of the current signal specifically. Finally, an index indicating the degree of deviation from the normal distribution is introduced to identify external bearing faults in drivetrains. Two groups of different experimental data sets are applied to verify the performance of C-ASSF. The results show that C-ASSF is superior to existing methods, such as self-organizing map (SOM) and stack autoencoder (SAE), and can not only identify faults in drivetrains but also identify different fault classes.
C1 [Li, Jie; Wang, Yu; Zi, Yanyang; Sun, Xiaojie] Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China.
   [Yang, Ying] Peking Univ, Dept Mech & Engn Sci, Coll Engn, Beijing 100871, Peoples R China.
RP Wang, Y (corresponding author), Xi An Jiao Tong Univ, State Key Lab Mfg Syst Engn, Xian 710049, Peoples R China.
EM lijie1@stu.xjtu.edu.cn; ywang95@xjtu.edu.cn; ziyy@xjtu.edu.cn;
   banjamin555@stu.xjtu.edu.cn; yy@mech.pku.edu.cn
CR Akcay S, 2019, LECT NOTES COMPUT SC, V11363, P622, DOI 10.1007/978-3-030-20893-6_39
   [Anonymous], 2017, BEGAN BOUNDARY EQUIL
   [Anonymous], 2016, P 30 C NEUR INF PROC
   Arjovsky M, 2017, PR MACH LEARN RES, V70
   Beggel L., 2019, P JOINT EUR C MACH L, P206
   Ben Abid F, 2018, IEEE T ENERGY CONVER, V33, P1692, DOI 10.1109/TEC.2018.2839083
   Bloedt M, 2008, IEEE T IND ELECTRON, V55, P1813, DOI 10.1109/TIE.2008.917108
   Hoang DT, 2020, IEEE T INSTRUM MEAS, V69, P3325, DOI 10.1109/TIM.2019.2933119
   Goodfellow I, 2020, COMMUN ACM, V63, P139, DOI 10.1145/3422622
   Gulrajani Ishaan, 2017, ADV NEURAL INFORM PR, P5767
   Han T, 2019, MECH SYST SIGNAL PR, V117, P170, DOI 10.1016/j.ymssp.2018.07.048
   Immovilli F, 2010, IEEE T IND APPL, V46, P1350, DOI 10.1109/TIA.2010.2049623
   Ince T, 2016, IEEE T IND ELECTRON, V63, P7067, DOI 10.1109/TIE.2016.2582729
   Jung JH, 2006, IEEE T IND ELECTRON, V53, P1842, DOI 10.1109/TIE.2006.885131
   Kuncan M, 2020, ISA T, V100, P346, DOI 10.1016/j.isatra.2019.11.006
   Leite VCMN, 2015, IEEE T IND ELECTRON, V62, P1855, DOI 10.1109/TIE.2014.2345330
   Lessmeier C., 2016, P EUR C PROGN HLTH M, P152
   Li HF, 2019, PROCEDIA COMPUT SCI, V162, P438, DOI 10.1016/j.procs.2019.12.008
   Li JX, 2018, I C CONT AUTOMAT ROB, P1327, DOI 10.1109/ICARCV.2018.8581331
   Li J, 2020, IEEE T INSTRUM MEAS, V69, P8580, DOI 10.1109/TIM.2020.2986853
   Mao WT, 2020, IEEE T INSTRUM MEAS, V69, P443, DOI 10.1109/TIM.2019.2903699
   Mao XD, 2017, IEEE I CONF COMP VIS, P2813, DOI 10.1109/ICCV.2017.304
   Paderborn University Paderborn Germany, KAT DATACENTER WEBSI
   Pan TY, 2019, IEEE T IND INFORM, V15, P5119, DOI 10.1109/TII.2019.2896665
   Plakias S, 2019, NEUROCOMPUTING, V332, P396, DOI 10.1016/j.neucom.2018.12.041
   Ramanathan S, 2020, INT C TRANS OPT NETW, DOI 10.1109/icton51198.2020.9328898
   SCHOEN RR, 1995, IEEE T IND APPL, V31, P900, DOI 10.1109/28.395302
   Shahriar MR, 2018, IEEE T IND ELECTRON, V65, P5941, DOI 10.1109/TIE.2017.2782240
   Singh S, 2017, IEEE T IND INFORM, V13, P1341, DOI 10.1109/TII.2016.2641470
   Wagner T, 2020, P INT C INNOVATIONS, P1
   Wang XX, 2020, IEEE T INSTRUM MEAS, V69, P5556, DOI 10.1109/TIM.2019.2963582
   Xiao YC, 2016, CHEMOMETR INTELL LAB, V151, P15, DOI 10.1016/j.chemolab.2015.11.010
   Yan K, 2017, NEUROCOMPUTING, V228, P205, DOI 10.1016/j.neucom.2016.09.076
   Zhang DC, 2020, IEEE T INSTRUM MEAS, V69, P2996, DOI 10.1109/TIM.2019.2929669
   Zhang KY, 2020, J MANUF SYST, V55, P273, DOI 10.1016/j.jmsy.2020.04.016
NR 35
TC 5
Z9 6
U1 4
U2 59
PY 2021
VL 70
AR 3508012
DI 10.1109/TIM.2020.3046051
WC Engineering, Electrical & Electronic; Instruments & Instrumentation
DA 2023-11-11
ER

PT C
AU Kulkarni, A
   Jafari, A
   Sagedy, C
   Mohsenin, T
AF Kulkarni, Amey
   Jafari, Ali
   Sagedy, Chris
   Mohsenin, Tinoosh
GP IEEE
TI Sketching-based High-Performance Biomedical Big Data Processing
   Accelerator
SO 2016 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (ISCAS)
CY MAY 22-25, 2016
CL Montreal, CANADA
DE Big Data Processing; Sketching Technique; Many-Core; Seizure Detection
ID ARCHITECTURE
AB Multi-Sensor health monitoring systems are used to predict near future events of our health system. Each sensor generates humongous amount of data per second and needs to be processed in real-time. At the same time health monitoring systems are battery operated, thus they have rigid constraints on power and area of processing platform. Additionally, health monitoring systems should be accurate, thus we adapt machine learning techniques to improve detection accuracy. We propose a programmable Big Data Processing framework to reduce on-chip communications and computations, thus reducing energy of the processing. We integrate a low-overhead sketching framework with a low-power programmable PENC many-core platform. The sketching technique reduces the data communications and computations, additionally processing time is scaled down by parallel processing on the many-core platform. For demonstration we show seizure detection application with 22-channel of electroencephalograph (EEG), each channel generates 256 samples per second requiring total of 88 Kbps data rate. The computations are reduced by 16x while energy consumption of processing is reduced up to 68%. For compression rates of 2-16x, the seizure detection performance for sensitivity and specificity is degraded by 2.07% and 2.97%, respectively for Logistic Regression classifier.
C1 [Kulkarni, Amey; Jafari, Ali; Sagedy, Chris; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
RP Kulkarni, A (corresponding author), Univ Maryland Baltimore Cty, Dept Comp Sci & Elect Engn, Baltimore, MD 21228 USA.
CR [Anonymous], IEEE BIOM CIRC SYST
   [Anonymous], IEEE BIOM CIRC SYST
   [Anonymous], MATHWORKS NEWS NOTES
   Chen F, 2012, IEEE J SOLID-ST CIRC, V47, P744, DOI 10.1109/JSSC.2011.2179451
   Donoho DL, 2006, IEEE T INFORM THEORY, V52, P1289, DOI 10.1109/TIT.2006.871582
   Goldberger AL, 2000, CIRCULATION, V101, pE215, DOI 10.1161/01.CIR.101.23.e215
   Kulkarni A., 2016, P 26 ED GREAT LAK S
   Kulkarni A., 2016, J EMERGING TECHNOLOG
   Kulkarni A, 2014, PR GR LAK SYMP VLSI, P299, DOI 10.1145/2591513.2591598
   Kulkarni A, 2015, IEEE INT SYMP CIRC S, P970, DOI 10.1109/ISCAS.2015.7168797
   Page A, 2015, IEEE T CIRCUITS-II, V62, P109, DOI 10.1109/TCSII.2014.2385211
   Septimus A., 2010, CIRC SYST ISCAS P 20, P3316
   Shoaib M, 2012, CUSTOM INTEGRATED CI, P1
   Shoeb A., 2010, P 27 INT C MACH LEAR, P975, DOI [10.5555/3104322.3104446, DOI 10.5555/3104322.3104446]
   Tavana MK, 2014, I SYMPOS LOW POWER E, P275, DOI 10.1145/2627369.2627654
   Wulsin DF, 2011, J NEURAL ENG, V8, DOI 10.1088/1741-2560/8/3/036015
NR 16
TC 7
Z9 7
U1 0
U2 0
PY 2016
BP 1138
EP 1141
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Tang, LX
   Ning, CF
   Adaimi, G
   Ijspeert, A
   Alahi, A
   Bolotnikova, A
AF Tang, Lixuan
   Ning, Chuanfang
   Adaimi, George
   Ijspeert, Auke
   Alahi, Alexandre
   Bolotnikova, Anastasia
TI Real-Time Localization for Closed-Loop Control of Assistive Furniture
SO IEEE ROBOTICS AND AUTOMATION LETTERS
DT Article
DE Vision-based navigation; localization; object detection; segmentation
   and categorization
AB For people with limited mobility, navigating in cluttered indoor environment is challenging. In this work, we propose a mobile assistive furniture suite that is designed to ease the life of people with special needs in indoor movement. To enable intelligent coordination of this system, a key component is the localization of each mobile furniture. The challenge is to assess the state of an arbitrary living scenario so that the estimation can be used as a real-time feedback signal for autonomous closed-loop control of mobile furniture. We propose a perception pipeline that addresses these challenges. A machine learning model is designed and trained to jointly achieve multi-object semantic keypoint detection and classification in camera images. The synthetic data generation is employed to augment the training set and boost the model performance. A robust point cloud registration uses the detected semantic keypoints and depth information to estimate poses of the furniture. Tracking is applied to achieve smooth estimation. A high-performance accelerator that optimizes the efficiency of using heterogeneous devices is applied to achieve real-time performance. This visual perception pipeline is used in closed-loop control to steer the mobile furniture from initial to a desired location demonstrated in experiments on real hardware.
C1 [Tang, Lixuan; Ning, Chuanfang; Ijspeert, Auke; Bolotnikova, Anastasia] Swiss Fed Inst Technol Lausanne EPFL, Biorobot Lab, CH-1015 Lausanne, Switzerland.
   [Adaimi, George; Alahi, Alexandre] Swiss Fed Inst Technol Lausanne EPFL, Visual Intelligence Transportat Lab, CH-1015 Lausanne, Switzerland.
RP Tang, LX (corresponding author), Swiss Fed Inst Technol Lausanne EPFL, Biorobot Lab, CH-1015 Lausanne, Switzerland.
EM lixuan.tang@epfl.ch; chuanfang.ning@epfl.ch; george.adaimi@epfl.ch;
   auke.ijspeert@epfl.ch; alexandre.alahi@epfl.ch;
   anastasia.bolotnikova@epfl.ch
CR Amodei D., 2016, P INT C MACH LEARN, P173
   Bell S, 2015, PROC CVPR IEEE, P3479, DOI 10.1109/CVPR.2015.7298970
   Cimpoi M, 2014, PROC CVPR IEEE, P3606, DOI 10.1109/CVPR.2014.461
   Conzelmann FM, 2022, IEEE INT C INT ROBOT, P7259, DOI 10.1109/IROS47612.2022.9981583
   Fallatah A., 2021, P IEEE INT C ROB HUM, P1066
   Günther M, 2017, ARTIF INTELL, V247, P336, DOI 10.1016/j.artint.2014.12.007
   Hauser S, 2020, ROBOT AUTON SYST, V127, DOI 10.1016/j.robot.2020.103467
   Knight H, 2017, IEEE ROMAN, P443, DOI 10.1109/ROMAN.2017.8172340
   Kreiss S, 2022, IEEE T INTELL TRANSP, V23, P13498, DOI 10.1109/TITS.2021.3124981
   Kreiss S, 2019, PROC CVPR IEEE, P11969, DOI 10.1109/CVPR.2019.01225
   Li JF, 2019, PROC CVPR IEEE, P10855, DOI 10.1109/CVPR.2019.01112
   Lugaresi Camillo, 2019, 3 WORKSHOP COMPUTER
   Moon I, 2003, IROS 2003: PROCEEDINGS OF THE 2003 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, VOLS 1-4, P3453
   RUS D, 1995, IROS '95 - 1995 IEEE/RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS: HUMAN ROBOT INTERACTION AND COOPERATIVE ROBOTS, PROCEEDINGS, VOL 1, P235, DOI 10.1109/IROS.1995.525802
   Weng XS, 2020, IEEE INT C INT ROBOT, P10359, DOI 10.1109/IROS45743.2020.9341164
   Wu JJ, 2018, INT J COMPUT VISION, V126, P1009, DOI 10.1007/s11263-018-1074-6
   Xiang Y, 2014, IEEE WINT CONF APPL, P75, DOI 10.1109/WACV.2014.6836101
   Yang H, 2021, IEEE T ROBOT, V37, P314, DOI 10.1109/TRO.2020.3033695
   Yixiao Guo, 2021, MM '21: Proceedings of the 29th ACM International Conference on Multimedia, P3763, DOI 10.1145/3474085.3478325
   Zhou XY, 2018, LECT NOTES COMPUT SC, V11205, P328, DOI 10.1007/978-3-030-01246-5_20
NR 20
TC 0
Z9 0
U1 5
U2 5
PD AUG
PY 2023
VL 8
IS 8
BP 4799
EP 4806
DI 10.1109/LRA.2023.3287365
WC Robotics
DA 2023-11-11
ER

PT C
AU Liu, SY
   Bavikadi, S
   Sen, T
   Shen, HY
   Sutradhar, PR
   Ganguly, A
   Dinakarrao, SMP
   Smith, BL
AF Liu, Shiyi
   Bavikadi, Sathwika
   Sen, Tanmoy
   Shen, Haiying
   Sutradhar, Purab Ranjan
   Ganguly, Amlan
   Dinakarrao, Sai Manoj Pudukotai
   Smith, Brian L.
GP IEEE
TI Accelerating Adversarial Attack using Process-in-Memory Architecture
SO 2022 18TH INTERNATIONAL CONFERENCE ON MOBILITY, SENSING AND NETWORKING,
   MSN
DT Proceedings Paper
CT 18th IEEE International Conference on Mobility, Sensing and Networking
   (MSN)
CY DEC 14-16, 2022
CL ELECTR NETWORK
DE Black-box adversarial attack; Deep neural network; Processing in memory
   (PIM)
AB Recent research has demonstrated that machine learning algorithms are vulnerable to adversarial attacks, in which small but carefully crafted input perturbations can lead to algorithm failure. It has been demonstrated that certain adversarial attack algorithms are capable of producing these types of perturbations. These attack methods are inapplicable when the attack must be generated in near real time. The use of a hardware accelerator, such as a Process-in-Memory (PIM) architecture, is a potential method for addressing this issue. The PIM architecture is regarded as a superior option for data-intensive applications such as solving optimization problems and Deep Neural Networks (DNN) due to its capacity for ultra-low-latency parallel processing. However, implementing an adversarial attack algorithm directly on the PIM platform is inefficient due to the PIM architecture's complexity and overhead costs. To address this issue, we utilize a novel adversarial attack scheme based on the PIM that leverages Look-up-Table (LUT)-based processing. The proposed LUT-based PIM architecture is capable of being dynamically programmed to execute the operations necessary for an adversarial attack algorithm. Our simulations reveal that the proposed method is capable of achieving an ultra-low operating delay and energy-efficiency performance.
C1 [Liu, Shiyi; Smith, Brian L.] Univ Virginia, Dept Engn Syst & Environm, Charlottesville, VA 22903 USA.
   [Bavikadi, Sathwika; Dinakarrao, Sai Manoj Pudukotai] George Mason Univ, Dept Elect & Comp Engn, Fairfax, VA USA.
   [Sen, Tanmoy; Shen, Haiying] Univ Virginia, Dept Comp Sci, Charlottesville, VA USA.
   [Sutradhar, Purab Ranjan; Ganguly, Amlan] Rochester Inst Technol, Rochester, NY USA.
RP Liu, SY (corresponding author), Univ Virginia, Dept Engn Syst & Environm, Charlottesville, VA 22903 USA.
EM sl9hm@virginia.edu; sbavikad@gmu.edu; ts5xm@virginia.edu;
   hs6ms@virginia.edu; ps9525@rit.edu; axgeec@rit.edu; spudukot@gmu.edu;
   bls2z@virginia.edu
CR Ajmi H., 2022, ARXIV
   [Anonymous], 2020, IEEE J SOLID-ST CIRC
   [Anonymous], 2019, IEEE INT S CIRCUITS
   [Anonymous], 2019, ACMIEEE DESIGN AUTOM
   Bavikadi S., 2021, 2021 IEEE 3 INT C AR, P1
   Bavikadi S., 2020, GLSVLSI 20
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Cai F., 2019, ARXIV
   Carboni R, 2019, ADV ELECTRON MATER, V5, DOI 10.1002/aelm.201900198
   Chakraborty A, 2021, CAAI T INTELL TECHNO, V6, P25, DOI 10.1049/cit2.12028
   Chen P.-Y., 2017, PROC AISW
   Chen X, 2019, ARXIV
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chollet F., 2015, KERAS
   Esteva A, 2019, NAT MED, V25, P24, DOI 10.1038/s41591-018-0316-z
   Eykholt K, 2018, PROC CVPR IEEE, P1625, DOI 10.1109/CVPR.2018.00175
   Feinberg B, 2018, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2018.00039
   Fridman L., 2017, ARXIV
   Gong Y., 2019, ARXIV
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Goodfellow I. J., 2014, INT C LEARNING REPRE, DOI DOI 10.1109/CVPR.2016.90
   Guesmi A., 2022, ARXIV
   Hu G, 2015, 2015 IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION WORKSHOP (ICCVW), P384, DOI 10.1109/ICCVW.2015.58
   Karim F, 2019, NEURAL NETWORKS, V116, P237, DOI 10.1016/j.neunet.2019.04.014
   Kim Y, 2017, ICCAD-IEEE ACM INT, P25, DOI 10.1109/ICCAD.2017.8203756
   Kingma D. P., 2014, ARXIV, DOI DOI 10.48550/ARXIV.1412.6980
   Kong Z., 2021, WIRELESS COMPUTING C, V2021
   Kuutti S, 2021, IEEE T INTELL TRANSP, V22, P712, DOI 10.1109/TITS.2019.2962338
   Li C, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8351877
   Li S, 2018, ARXIV
   Madry A., 2018, INT C LEARNING REPRE
   McAllister R, 2017, PROCEEDINGS OF THE TWENTY-SIXTH INTERNATIONAL JOINT CONFERENCE ON ARTIFICIAL INTELLIGENCE, P4745
   Mladenovic A., 2021, ARXIV
   Modas A, 2020, IEEE SIGNAL PROC MAG, V37, P14, DOI 10.1109/MSP.2020.2985363
   Moosavi-Dezfooli SM, 2016, PROC CVPR IEEE, P2574, DOI 10.1109/CVPR.2016.282
   Papernot N., 2018, ARXIV
   Sarker A., 2021, PROC MASS
   Sarker A., 2021, PROC SECON
   Sarker A, 2020, IEEE INT CONF MOB, P184, DOI 10.1109/MASS50613.2020.00032
   Sebastian A, 2020, NAT NANOTECHNOL, V15, P529, DOI 10.1038/s41565-020-0655-z
   Seo JS, 2015, IEEE T NANOTECHNOL, V14, P969, DOI 10.1109/TNANO.2015.2478861
   Serrano CR, 2020, 2020 IEEE SYMPOSIUM ON SECURITY AND PRIVACY WORKSHOPS (SPW 2020), P27, DOI 10.1109/SPW50608.2020.00022
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shen H., 2022, 2022 IFIP NETWORKING, P1
   Sutradhar PR, 2021, PR IEEE COMP DESIGN, P252, DOI 10.1109/ICCD53106.2021.00049
   Sutradhar PR, 2022, IEEE T PARALL DISTR, V33, P263, DOI 10.1109/TPDS.2021.3066909
   Sutradhar PR, 2020, IEEE COMPUT ARCHIT L, V19, P118, DOI 10.1109/LCA.2020.3011643
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Tandel NH, 2020, INT CONF ADVAN COMPU, P459, DOI [10.1109/ICACCS48705.2020.9074184, 10.1109/icaccs48705.2020.9074184]
   Tramer Florian, 2017, ARXIV
   Tu CC, 2019, AAAI CONF ARTIF INTE, P742
   Wang F, 2021, PROC INT CONF DATA, P1859, DOI 10.1109/ICDE51399.2021.00167
   Wang J, 2018, INT CON DISTR COMP S, P1385, DOI 10.1109/ICDCS.2018.00139
   Wang JJ, 2018, J MANUF SYST, V48, P144, DOI 10.1016/j.jmsy.2018.01.003
   Wang Y, 2019, TRANSPORT RES C-EMER, V99, P144, DOI 10.1016/j.trc.2018.12.004
   Zhang C., 2021, ARXIV
NR 57
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 325
EP 330
DI 10.1109/MSN57253.2022.00061
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Yadav, N
   Kim, Y
   Li, S
   Choi, KK
AF Yadav, Nandakishor
   Kim, Youngbae
   Li, Shuai
   Choi, Kyuwon Ken
TI Stable, Low Power and Bit-Interleaving Aware SRAM Memory for Multi-Core
   Processing Elements
SO ELECTRONICS
DT Article
DE SRAM; stability; reliability; CNN; read time; write time
ID SUBTHRESHOLD SRAM; SENSE-AMPLIFIER; VOLTAGE; CELL
AB The machine learning and convolutional neural network (CNN)-based intelligent artificial accelerator needs significant parallel data processing from the cache memory. The separate read port is mostly used to design built-in computational memory (CRAM) to reduce the data processing bottleneck. This memory uses multi-port reading and writing operations, which reduces stability and reliability. In this paper, we proposed a self-adaptive 12T SRAM cell to increase the read stability for multi-port operation. The self-adaptive technique increases stability and reliability. We increased the read stability by refreshing the storing node in the read mode of operation. The proposed technique also prevents the bit-interleaving problem. Further, we offered a butterfly-inspired SRAM bank to increase the performance and reduce the power dissipation. The proposed SRAM saves 12% more total power than the state-of-the-art 12T SRAM cell-based SRAM. We improve the write performance by 28.15% compared with the state-of-the-art 12T SRAM design. The total area overhead of the proposed architecture compared to the conventional 6T SRAM cell-based SRAM is only 1.9 times larger than the 6T SRAM cell.
C1 [Yadav, Nandakishor] Fraunhofer Inst Photon Microsyst IPMS, D-01109 Dresden, Germany.
   [Kim, Youngbae; Li, Shuai; Choi, Kyuwon Ken] IIT, Chicago, IL 60616 USA.
RP Yadav, N (corresponding author), Fraunhofer Inst Photon Microsyst IPMS, D-01109 Dresden, Germany.
EM nkyadav.vlsi@gmail.com; ykim102@hawk.iit.edu; sli97@hawk.iit.edu;
   kchoi12@iit.edu
CR Ahmad S, 2016, IEEE T VLSI SYST, V24, P2634, DOI 10.1109/TVLSI.2016.2520490
   Almeida RB, 2018, MICROELECTRON RELIAB, V88-90, P196, DOI 10.1016/j.microrel.2018.07.134
   [Anonymous], 2012, COMPUTER BRAIN
   Ataei S, 2016, PR IEEE COMP DESIGN, P499, DOI 10.1109/ICCD.2016.7753333
   Chhabra A, 2016, IEEE INT SYMP CIRC S, P1018, DOI 10.1109/ISCAS.2016.7527416
   Chiu YW, 2014, IEEE T CIRCUITS-I, V61, P2578, DOI 10.1109/TCSI.2014.2332267
   Dong Q, 2018, IEEE J SOLID-ST CIRC, V53, P1006, DOI 10.1109/JSSC.2017.2776309
   Gupta P, 2019, 2019 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE), P11
   Hodges D., 2005, DEEP SUBMICRON TECHN
   Jaiswal A, 2019, IEEE T VLSI SYST, V27, P2556, DOI 10.1109/TVLSI.2019.2929245
   Jia HY, 2020, IEEE J SOLID-ST CIRC, V55, P2609, DOI 10.1109/JSSC.2020.2987714
   Jiang JW, 2019, IEEE T CIRCUITS-I, V66, P967, DOI 10.1109/TCSI.2018.2872507
   Jiang WX, 2020, J SEMICOND, V41, DOI 10.1088/1674-4926/41/2/022406
   Kang M, 2011, IEEE T ELECTRON DEV, V58, P2959, DOI 10.1109/TED.2011.2160180
   Kim TH, 2008, IEEE J SOLID-ST CIRC, V43, P518, DOI 10.1109/JSSC.2007.914328
   Moon S, 2020, ELECTRONICS-SWITZ, V9, DOI 10.3390/electronics9050704
   Moradi F, 2008, IEEE INT SOC CONF, P113, DOI 10.1109/SOCC.2008.4641491
   Pal S, 2016, IEEE T COMPUT AID D, V35, P549, DOI 10.1109/TCAD.2015.2474408
   Patel PK, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2019.102956
   Pedretti G, 2021, ELECTRONICS-SWITZ, V10, DOI 10.3390/electronics10091063
   Ranganathan K, 2002, 11TH IEEE INTERNATIONAL SYMPOSIUM ON HIGH PERFORMANCE DISTRIBUTED COMPUTING, PROCEEDINGS, P352, DOI 10.1109/HPDC.2002.1029935
   Reniwal BS, 2019, CIRC SYST SIGNAL PR, V38, P1482, DOI 10.1007/s00034-018-0934-1
   Sheu YM, 2006, IEEE T ELECTRON DEV, V53, P2792, DOI 10.1109/TED.2006.884070
   Verma N, 2008, IEEE J SOLID-ST CIRC, V43, P141, DOI 10.1109/JSSC.2007.908005
   Yadav N, 2017, IEEE T SEMICONDUCT M, V30, P276, DOI 10.1109/TSM.2017.2718029
   Yang Y, 2015, IEEE T VLSI SYST, V23, P2748, DOI 10.1109/TVLSI.2014.2367234
   Zhao Q, 2020, IEEE T VLSI SYST, V28, P848, DOI 10.1109/TVLSI.2019.2955865
NR 27
TC 1
Z9 1
U1 0
U2 6
PD NOV
PY 2021
VL 10
IS 21
AR 2724
DI 10.3390/electronics10212724
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Akyildiz, TA
   Aljundi, AA
   Kaya, K
AF Akyildiz, Taha Atahan
   Aljundi, Amro Alabsi
   Kaya, Kamer
BE Wu, XT
   Jermaine, C
   Xiong, L
   Hu, XH
   Kotevska, O
   Lu, SY
   Xu, WJ
   Aluru, S
   Zhai, CX
   Al-Masri, E
   Chen, ZY
   Saltz, J
TI Understanding Coarsening for Embedding Large-Scale Graphs
SO 2020 IEEE INTERNATIONAL CONFERENCE ON BIG DATA (BIG DATA)
SE IEEE International Conference on Big Data
DT Proceedings Paper
CT 8th IEEE International Conference on Big Data (Big Data)
CY DEC 10-13, 2020
CL ELECTR NETWORK
DE Graph coarsening; graph embedding; multi-level approach
ID SCHEME
AB A significant portion of the data today, e.g, social networks, web connections, etc., can be modeled by graphs. A proper analysis of graphs with Machine Learning (ML) algorithms has the potential to yield far-reaching insights into many areas of research and industry. However, the irregular structure of graph data constitutes an obstacle for running ML tasks on graphs such as link prediction, node classification, and anomaly detection. Graph embedding is a compute-intensive process of representing graphs as a set of vectors in a d-dimensional space, which in turn makes it amenable to ML tasks. Many approaches have been proposed in the literature to improve the performance of graph embedding, e.g., using distributed algorithms, accelerators, and pre-processing techniques. Graph coarsening, which can be considered a pre-processing step, is a structural approximation of a given, large graph with a smaller one. As the literature suggests, the cost of embedding significantly decreases when coarsening is employed. In this work, we thoroughly analyze the impact of the coarsening quality on the embedding performance both in terms of speed and accuracy. Our experiments with a state-of-the-art, fast graph embedding tool show that there is an interplay between the coarsening decisions taken and the embedding quality.
C1 [Akyildiz, Taha Atahan; Aljundi, Amro Alabsi; Kaya, Kamer] Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
RP Akyildiz, TA (corresponding author), Sabanci Univ, Fac Engn & Nat Sci, Istanbul, Turkey.
EM aakyildiz@sabanciuniv.edu; amroa@sabanciuniv.edu; kaya@sabanciuniv.edu
CR Akyildiz T., 2020, ICPP 20
   Blondel VD, 2008, J STAT MECH-THEORY E, DOI 10.1088/1742-5468/2008/10/P10008
   Çatalyürek ÜV, 2012, INT PARALL DISTRIB P, P848, DOI 10.1109/IPDPS.2012.81
   Chen HC, 2018, AAAI CONF ARTIF INTE, P2127
   Deveci M, 2015, J PARALLEL DISTR COM, V77, P69, DOI 10.1016/j.jpdc.2014.12.002
   Fawcett T, 2006, PATTERN RECOGN LETT, V27, P861, DOI 10.1016/j.patrec.2005.10.010
   Grover A, 2016, KDD'16: PROCEEDINGS OF THE 22ND ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING, P855, DOI 10.1145/2939672.2939754
   Halappanavar M., 2017, IEEE HIGH PERF EXTR, P1
   Hendrickson B, 1995, SUPERCOMP PROC, P626
   Hu RJ, 2016, PROC INT CONF DATA, P385, DOI 10.1109/ICDE.2016.7498256
   Hu Y., 2005, MATH J, V10, P37, DOI DOI 10.3402/QHW.V6I2.5918
   Karypis G, 1998, SIAM J SCI COMPUT, V20, P359, DOI 10.1137/S1064827595287997
   Karypis G, 1998, J PARALLEL DISTR COM, V48, P96, DOI 10.1006/jpdc.1997.1404
   Kipf Thomas N., 2017, ICLR 2017 A BROWN IN
   Lerer A., 2019, P MACH LEARN SYST 20
   Leskovec J., 2014, SNAP DATASETS STANFO
   Liang J., 2018, CORR
   Liben-Nowell D, 2007, J AM SOC INF SCI TEC, V58, P1019, DOI 10.1002/asi.20591
   Meusel R, 2015, J WEB SCI, DOI DOI 10.1561/106.00000003
   Mislove A, 2007, IMC'07: PROCEEDINGS OF THE 2007 ACM SIGCOMM INTERNET MEASUREMENT CONFERENCE, P29
   Newman M.E.J., 2004, PHYS REV E, V69, DOI 10.1103/PhysRevE.69.026113
   Pellegrini F., 1996, High-Performance Computing and Networking. International Conference and Exhibition HPCN EUROPE 1996. Proceedings, P493, DOI 10.1007/3-540-61142-8_588
   Perozzi B, 2014, PROCEEDINGS OF THE 20TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY AND DATA MINING (KDD'14), P701, DOI 10.1145/2623330.2623732
   Rossi RA, 2015, AAAI CONF ARTIF INTE, P4292
   Tang J, 2015, PROCEEDINGS OF THE 24TH INTERNATIONAL CONFERENCE ON WORLD WIDE WEB (WWW 2015), P1067, DOI 10.1145/2736277.2741093
   Tithi JJ, 2020, PROC INT CONF PARAL, DOI 10.1145/3404397.3404455
   Tsitsulin A, 2018, WEB CONFERENCE 2018: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW2018), P539, DOI 10.1145/3178876.3186120
   Zhu ZC, 2019, WEB CONFERENCE 2019: PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE (WWW 2019), P2494, DOI 10.1145/3308558.3313508
NR 28
TC 2
Z9 2
U1 0
U2 0
PY 2020
BP 2937
EP 2946
DI 10.1109/BigData50022.2020.9377898
WC Computer Science, Artificial Intelligence; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Wang, WJ
   Lin, B
AF Wang, Weijia
   Lin, Bill
TI Trained Biased Number Representation for ReRAM-Based Neural Network
   Accelerators
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article; Proceedings Paper
CT 3rd Workshop on Hardware Algorithms for Learning On-a-Chip (HALO)
CY NOV 16, 2017
CL Irvine, CA
DE Resistive Memory; convolutional neural networks; quantization; machine
   learning; processing-in-memory
AB Recent works have demonstrated the promise of using resistive random access memory (ReRAM) to perform neural network computations in memory. In particular, ReRAM-based crossbar structures can perform matrix-vector multiplication directly in the analog domain, but the resolutions of ReRAM cells and digital/analog converters limit the precisions of inputs and weights that can be directly supported. Although convolutional neural networks (CNNs) can be trained with low-precision weights and activations, previous quantization approaches are either not amenable to ReRAM-based crossbar implementations or have poor accuracies when applied to deep CNNs on complex datasets. In this article, we propose a new CNN training and implementation approach that implements weights using a trained biased number representation, which can achieve near full-precision model accuracy with as little as 2-bit weights and 2-bit activations on the CIFAR datasets. The proposed approach is compatible with a ReRAM-based crossbar implementation. We also propose an activation-side coalescing technique that combines the steps of batch normalization, nonlinear activation, and quantization into a single stage that simply performs a clipped-rounding operation. Experiments demonstrate that our approach outperforms previous low-precision number representations for VGG-11, VGG-13, and VGG-19 models on both the CIFAR-10 and CIFAR-100 datasets.
C1 [Wang, Weijia; Lin, Bill] Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
RP Wang, WJ (corresponding author), Univ Calif San Diego, Dept Elect & Comp Engn, La Jolla, CA 92093 USA.
EM wweijia@eng.ucsd.edu; billlin@eng.ucsd.edu
CR Burr GW, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM), DOI 10.1109/iedm.2015.7409625
   Cai Z, 2017, WOODH PUBL SER BIOM, P171, DOI 10.1016/B978-0-08-100383-1.00010-2
   Chen ZJ, 2015, COMPUT INTEL NEUROSC, V2015, DOI 10.1155/2015/919805
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Courbariaux Matthieu, 2014, ARXIV14127024
   Han S., 2015, ARXIV151000149
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Hu M, 2012, DES AUT CON, P498
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Kim Y, 2015, ACM J EMERG TECH COM, V11, DOI 10.1145/2700234
   Li BX, 2013, I SYMPOS LOW POWER E, P242, DOI 10.1109/ISLPED.2013.6629302
   Liu XD, 2015, 4TH INTERNATIONAL CONFERENCE ON NEXT GENERATION COMPUTER AND INFORMATION TECHNOLOGY NGCIT 2015, P15, DOI 10.1109/NGCIT.2015.8
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Miyashita D., 2016, ARXIV160301025
   Paszke Adam, 2017, P 2017 NIPS WORKSH
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Taha T., 2013, P 2013 INT JOINT C N
   Wang P, 2018, PROC CVPR IEEE, P5860, DOI 10.1109/CVPR.2018.00614
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Yakopcic C., 2013, P 2013 INT JOINT C N
   Yu Ji, 2018, ACM SIGPLAN Notices, V53, P448, DOI 10.1145/3296957.3173205
   Zhou S., 2016, ARXIV160606160
   Zhuang B., 2017, ARXIV171100205
NR 28
TC 4
Z9 4
U1 1
U2 4
PD JUN
PY 2019
VL 15
IS 2
SI SI
AR 15
DI 10.1145/3304107
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT C
AU Huang, NS
   Braun, JM
   Larsen, JC
   Manoonpong, P
AF Huang, Nan-Sheng
   Braun, Jan-Matthias
   Larsen, Jorgen Christian
   Manoonpong, Poramate
BE Jozwiak, L
   Stojanovic, R
   Lutovac, B
   Jurisic, D
TI A scalable Echo State Networks hardware generator for embedded systems
   using high-level synthesis
SO 2019 8TH MEDITERRANEAN CONFERENCE ON EMBEDDED COMPUTING (MECO)
SE Mediterranean Conference on Embedded Computing
DT Proceedings Paper
CT 8th Mediterranean Conference on Embedded Computing (MECO)
CY JUN 10-14, 2019
CL Budva, MONTENEGRO
DE Neural Networks; Reservoir Computing; Echo State Networks; Hardware
   Accelerator; Embedded Systems; High-Level Synthesis
ID RESERVOIR
AB Reservoir computing (RC) features with the rich computational dynamics is a kind of powerful machine learning paradigm that is well suited for non-linear time-series prediction and classification problems. However, this impressive performance comes with a cost of complex arithmetic operations and high memory usage that make it significantly challenging to deploy on embedded systems. Solutions based on CPU and/or GPU-based designs, provides flexibility but suffers from a lack of efficiency in terms of power, performance, and area (PPA). Although hardware-accelerated solutions can improve efficiency, it takes longer design cycles and is time-consuming. Furthermore, it may happen that design spec requires run change due to the fact that the network is retrained with the new data set to improve the performance. It leads to extra effort in the redesign of the hardware-accelerated solution. This preliminary work presents the design and implementation of a hardware generator for RC-ESNs (echo state networks) to tackle the problem. The proposed methodology is demonstrated by various offline-trained network parameters and topologies. Compared to existing solutions, the proposed framework provides scalability with the support of DSE in agile hardware design.
C1 [Huang, Nan-Sheng; Braun, Jan-Matthias; Larsen, Jorgen Christian; Manoonpong, Poramate] Univ Southern Denmark, Maersk Mckinney Moller Inst, Embodied AI & Neurorobot Lab, Odense M, Denmark.
RP Huang, NS (corresponding author), Univ Southern Denmark, Maersk Mckinney Moller Inst, Embodied AI & Neurorobot Lab, Odense M, Denmark.
EM nan@mmmi.sdu.dk; j-mb@mmmi.sdu.dk; jcla@mmmi.sdu.dk; poma@mmmi.sdu.dk
CR Alomar M, 2017, NEURAL COMPUT APPL, V32, P1
   Alomar ML, 2016, COMPUT INTEL NEUROSC, V2016, DOI 10.1155/2016/3917892
   Buchanan S., 2016, DESIGN FPGA IMPLEMEN
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dasgupta S, 2013, EVOL SYST-GER, V4, P235, DOI 10.1007/s12530-013-9080-y
   DeHon A, 2004, ANN IEEE SYM FIELD P, P13
   Gamma E, 1995, DESIGN PATTERNS ELEM
   Lukosevicius M, 2009, COMPUT SCI REV, V3, P127, DOI 10.1016/j.cosrev.2009.03.005
   Nane R, 2016, IEEE T COMPUT AID D, V35, P1591, DOI 10.1109/TCAD.2015.2513673
   Schuman C.D., 2017, SURVEY NEUROMORPHIC, Vabs/1705.06963
   Soures N, 2017, IEEE CONSUM ELECTR M, V6, P67, DOI 10.1109/MCE.2017.2685159
   Xilinx, 2017, VIVADO DESIGN SUITE
   Yi Y, 2016, MICROPROCESS MICROSY, V46, P175, DOI 10.1016/j.micpro.2016.03.009
NR 14
TC 3
Z9 3
U1 0
U2 1
PY 2019
BP 128
EP 133
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Amin, R
   George, JK
   Wang, H
   Maiti, R
   Ma, ZZ
   Dalir, H
   Khurgin, JB
   Sorger, VJ
AF Amin, Rubab
   George, Jonathan K.
   Wang, Hao
   Maiti, Rishi
   Ma, Zhizhen
   Dalir, Hamed
   Khurgin, Jacob B.
   Sorger, Volker J.
TI An ITO-graphene heterojunction integrated absorption modulator on
   Si-photonics for neuromorphic nonlinear activation
SO APL PHOTONICS
DT Article
ID MACH-ZEHNDER MODULATOR; ELECTROABSORPTION MODULATOR; DIRAC FERMIONS
AB The high demand for machine intelligence of doubling every three months is driving novel hardware solutions beyond charging of electrical wires, given a resurrection to application specific integrated circuit (ASIC)-based accelerators. These innovations include photonic-based ASICs (P-ASICs) due to prospects of performing optical linear (and also nonlinear) operations, such as multiply-accumulate for vector matrix multiplications or convolutions, without iterative architectures. Such photonic linear algebra enables picosecond delay when photonic integrated circuits are utilized via "on-the-fly" mathematics. However, the neuron's full function includes providing a nonlinear activation function, known as thresholding, to enable decision making on inferred data. Many P-ASIC solutions perform this nonlinearity in the electronic domain, which brings challenges in terms of data throughput and delay, thus breaking the optical link and introducing increased system complexity via domain crossings. This work follows the notion of utilizing enhanced light-matter interactions to provide efficient, compact, and engineerable electro-optic neuron nonlinearity. Here, we introduce and demonstrate a novel electro-optic device to engineer the shape of this optical nonlinearity to resemble a leaky rectifying linear unit-the most commonly used nonlinear activation function in neural networks. We combine the counter-directional transfer functions from heterostructures made out of two electro-optic materials to design a diode-like nonlinear response of the device. Integrating this nonlinearity into a photonic neural network, we show how the electrostatics of this thresholder's gating junction improves machine learning inference accuracy and the energy efficiency of the neural network. (c) 2021 Author(s). All article content, except where otherwise noted, is licensed under a Creative Commons Attribution (CC BY) license (http://creativecommons.org/licenses/by/4.0/).
C1 [Amin, Rubab; George, Jonathan K.; Wang, Hao; Maiti, Rishi; Ma, Zhizhen; Dalir, Hamed; Sorger, Volker J.] George Washington Univ, Dept Elect & Comp Engn, 800 22nd St NW, Washington, DC 20052 USA.
   [Khurgin, Jacob B.] Johns Hopkins Univ, Dept Elect & Comp Engn, Baltimore, MD 21218 USA.
RP Sorger, VJ (corresponding author), George Washington Univ, Dept Elect & Comp Engn, 800 22nd St NW, Washington, DC 20052 USA.
EM sorger@gwu.edu
CR Amin R, 2019, APL MATER, V7, DOI 10.1063/1.5109039
   Amin R, 2021, IEEE J SEL TOP QUANT, V27, DOI 10.1109/JSTQE.2020.3041835
   Amin R, 2021, SCI REP-UK, V11, DOI 10.1038/s41598-020-80381-3
   Amin R, 2020, OPTICA, V7, P333, DOI 10.1364/OPTICA.389437
   Amin R, 2020, J LIGHTWAVE TECHNOL, V38, P282, DOI 10.1109/JLT.2019.2956719
   Amin R, 2018, APL PHOTONICS, V3, DOI 10.1063/1.5052635
   Amin R, 2018, OPT EXPRESS, V26, P15445, DOI 10.1364/OE.26.015445
   Amin R, 2018, NANOPHOTONICS-BERLIN, V7, P455, DOI 10.1515/nanoph-2017-0072
   Blumenthal DJ, 2018, NAT PHOTONICS, V12, P447, DOI 10.1038/s41566-018-0222-4
   Brunner D, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms2368
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Cheng Z, 2020, NANOPHOTONICS-BERLIN, V9, P2377, DOI 10.1515/nanoph-2019-0381
   Chiu Y., 2015, 2015 14 INT C OPT CO, P1
   de Lima TF, 2017, NANOPHOTONICS-BERLIN, V6, P577, DOI 10.1515/nanoph-2016-0139
   Dejonckheere A, 2014, OPT EXPRESS, V22, P10868, DOI 10.1364/OE.22.010868
   Dionne JA, 2009, NANO LETT, V9, P897, DOI 10.1021/nl803868k
   Esmaeilzadeh H, 2012, IEEE MICRO, V32, P122, DOI 10.1109/MM.2012.17
   George J., 2018, ADV PHOT 2018 BGPP I
   George S., 2021, ARXIV210210398
   Giambra MA, 2019, OPT EXPRESS, V27, P20145, DOI 10.1364/OE.27.020145
   Koh SK, 2006, THIN SOLID FILMS, V496, P81, DOI 10.1016/j.tsf.2005.08.251
   Lee KB, 2017, POWER SYST, P179, DOI 10.1007/978-981-10-4992-7_5
   Lee SH, 2012, MOL CRYST LIQ CRYST, V564, P185, DOI 10.1080/15421406.2012.691772
   Li W, 2014, NANO LETT, V14, P955, DOI 10.1021/nl404356t
   Liu JH, 2016, NANOSCALE RES LETT, V11, DOI 10.1186/s11671-016-1323-y
   Liu M, 2011, NATURE, V474, P64, DOI 10.1038/nature10067
   Liu XG, 2018, ACS PHOTONICS, V5, P4484, DOI 10.1021/acsphotonics.8b00945
   Ma PY, 2017, OPT EXPRESS, V25, P33504, DOI 10.1364/OE.25.033504
   Ma ZZ, 2020, ACS PHOTONICS, V7, P932, DOI 10.1021/acsphotonics.9b01452
   Ma ZZ, 2017, IEEE J SEL TOP QUANT, V23, DOI 10.1109/JSTQE.2016.2574306
   Mesaritakis C, 2016, SCI REP-UK, V6, DOI 10.1038/srep39317
   Miscuglio M, 2018, OPT MATER EXPRESS, V8, P3851, DOI 10.1364/OME.8.003851
   Moscoso-Mártir A, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-12023-0
   Nagamine T, 2016, INTERSPEECH, P803, DOI 10.21437/Interspeech.2016-1406
   Novoselov KS, 2005, NATURE, V438, P197, DOI 10.1038/nature04233
   Nozaki K, 2017, APL PHOTONICS, V2, DOI 10.1063/1.4980036
   Peng HT, 2018, IEEE J SEL TOP QUANT, V24, DOI 10.1109/JSTQE.2018.2840448
   Rajput S, 2020, J LIGHTWAVE TECHNOL, V38, P1365, DOI 10.1109/JLT.2019.2953690
   Reed GT, 2014, NANOPHOTONICS-BERLIN, V3, P229, DOI 10.1515/nanoph-2013-0016
   Shastri BJ, 2016, SCI REP-UK, V6, DOI 10.1038/srep19126
   Shen YC, 2017, NAT PHOTONICS, V11, P441, DOI [10.1038/NPHOTON.2017.93, 10.1038/nphoton.2017.93]
   Shu HW, 2018, SCI REP-UK, V8, DOI 10.1038/s41598-018-19171-x
   Sorger VJ, 2012, NANOPHOTONICS-BERLIN, V1, P17, DOI 10.1515/nanoph-2012-0009
   Tahersima MH, 2019, NANOPHOTONICS-BERLIN, V8, P1559, DOI 10.1515/nanoph-2019-0153
   Tait AN, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-07754-z
   Tait AN, 2014, J LIGHTWAVE TECHNOL, V32, P4029, DOI 10.1109/JLT.2014.2345652
   Tu XG, 2011, OPT EXPRESS, V19, P18029, DOI 10.1364/OE.19.018029
   Yoo S, 2016, ACS NANO, V10, P4274, DOI 10.1021/acsnano.5b07747
   Zhou SY, 2006, NAT PHYS, V2, P595, DOI 10.1038/nphys393
   Zhu SY, 2013, OPT EXPRESS, V21, P8320, DOI 10.1364/OE.21.008320
NR 50
TC 18
Z9 18
U1 3
U2 17
PD DEC 1
PY 2021
VL 6
IS 12
AR 120801
DI 10.1063/5.0062830
WC Optics; Physics, Applied
DA 2023-11-11
ER

PT J
AU Inoue, A
   Miyoshi, T
   Ishihara, T
   Honda, Y
AF Inoue, Atsuki
   Miyoshi, Takashi
   Ishihara, Teruo
   Honda, Yasufumi
TI Innovative Computing for Solving Social Issues
SO FUJITSU SCIENTIFIC & TECHNICAL JOURNAL
DT Article
ID ACCELERATOR
AB Since the development of practical stored-program computers in the late 1940s, performance has risen amazingly by about 10(12) times over a period of 70 years. However, it is generally recognized that semiconductor transistor scaling is reaching its limits and that Moore's law is coming to an end. Regardless of these technical issues, the explosive increase in the amount of data generated in today's loT era is expected to continue, and it is highly anticipated that this data will be used to create new value and novel services. Meeting these expectations will therefore require improvements in performance independent of Moore's law. To address these issues, Fujitsu Laboratories proposes domain-specific computing as a new computing paradigm. The aim of domain-specific computing is to break through Moore's law by adopting 'architecture specific to the type of processing needed in fields such as knowledge processing whose objective is not to obtain rigorous numerical results. For example, in application to deep learning engines, high-speed image search engines, and machines dedicated to combinatorial optimization problems, domain-specific computing has demonstrated that it showed 50-12,000 times higher performance than that of conventional approaches. In this paper, we describe the direction of domain-specific computing as a new computing paradigm and present specific application examples.
C1 [Inoue, Atsuki; Miyoshi, Takashi; Ishihara, Teruo] Fujitsu Labs Ltd, Tokyo, Japan.
   [Honda, Yasufumi] Fujitsu Ltd, Tokyo, Japan.
RP Inoue, A (corresponding author), Fujitsu Labs Ltd, Tokyo, Japan.
CR Ike A, 2017, FUJITSU SCI TECH J, V53, P14
   Koomey JG, 2011, IEEE ANN HIST COMPUT, V33, P46, DOI 10.1109/MAHC.2010.28
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Maruyama T., ISC 2017
   Micikevicius P., 2017, ARXIV171003740
   MOORE GE, 1965, ELECTRONICS, V38
   Nihei M., 2016, IEICE TECHNICAL REPO, V116, P9
   Theis TN, 2017, COMPUT SCI ENG, V19, P41, DOI 10.1109/MCSE.2017.29
   Tsukamoto S, 2017, FUJITSU SCI TECH J, V53, P8
   Watanabe Y, 2017, FUJITSU SCI TECH J, V53, P20
NR 10
TC 0
Z9 0
U1 0
U2 2
PD OCT
PY 2018
VL 54
IS 5
BP 15
EP 21
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU O'Neal, K
   Brisk, P
AF O'Neal, Kenneth
   Brisk, Philip
GP IEEE
TI Predictive Modeling for CPU, GPU, and FPGA Performance and Power
   Consumption: A Survey
SO 2018 IEEE COMPUTER SOCIETY ANNUAL SYMPOSIUM ON VLSI (ISVLSI)
SE IEEE Computer Society Annual Symposium on VLSI
DT Proceedings Paper
CT 17th IEEE-Computer-Society Annual Symposium on VLSI (ISVLSI)
CY JUL 09-11, 2018
CL Hong Kong Polytechn Univ, Hong Kong, HONG KONG
HO Hong Kong Polytechn Univ
DE CPU; GPU; FPGA; Predictive Model; Machine Learning; Accuracy; Error;
   Survey
AB CPUs and dedicated accelerators (namely GPUs and FPGAs) continue to grow increasingly large and complex to support todays demanding performance and power requirements. Designers are tasked with evaluating the performance and power of similarly increasingly large design spaces during pre-silicon design for CPUs and GPUs to reduce time-to-market and limit manufacturing costs, or to figure out how to best map applications onto FPGAs using high-level synthesis tools. Typically, cycle accurate simulators are used to evaluate workloads for pre-silicon CPUs and GPUs and to avoid the overhead of synthesis and place and-route when targeting FPGAs; however, simulators exhibit prohibitively long run times that limit the number of design points and workloads that can be evaluated in a reasonable timeframe.
   This survey focuses on predictive modeling as an alternative to cycle-accurate simulation, which enables rapid evaluation of workloads and design points. When applied properly, predictive modeling can improve time to market, and can facilitate more comprehensive design space explorations with far less overhead than simulation. The survey focuses on predictive models applied to CPUs, GPUs, and FPGAs, noting that the general approach has been applied to many other computing platforms as well.
C1 [O'Neal, Kenneth; Brisk, Philip] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
RP O'Neal, K (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
EM konea001@ucr.edu; philip@cs.ucr.edu
CR [Anonymous], 2010, HPCA 16 2010 16 INT, DOI DOI 10.1109/HPCA.2010.5416635
   [Anonymous], 2014, TUTORIAL PRINCIPAL C
   Ardalani N, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P725, DOI 10.1145/2830772.2830780
   Breiman L, 1996, MACH LEARN, V24, P123, DOI 10.1007/bf00058655
   Canis A, 2011, FPGA 11: PROCEEDINGS OF THE 2011 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD PROGRAMMABLE GATE ARRAYS, P33
   Carlson T. E., 2011, HIGH PERFORMANCE COM, P1, DOI [10.1145/2063384.2063454, DOI 10.1145/2063384.2063454]
   Choi YK, 2017, ICCAD-IEEE ACM INT, P691
   Guo Q, 2016, IEEE T COMPUT AID D, V35, P433, DOI 10.1109/TCAD.2015.2481796
   Hoste K, 2006, I S WORKL CHAR PROC, P83
   Ipek E, 2006, ACM SIGPLAN NOTICES, V41, P195, DOI 10.1145/1168918.1168882
   Koeplinger D, 2016, CONF PROC INT SYMP C, P115, DOI 10.1109/ISCA.2016.20
   Lee BC, 2006, ACM SIGPLAN NOTICES, V41, P185, DOI [10.1145/1168919.1168881, 10.1145/1168917.1168881]
   Liu HY, 2013, 2013 15TH IEEE INTERNATIONAL CONFERENCE ON COMMUNICATION TECHNOLOGY (ICCT), P1, DOI 10.1109/ICCT.2013.6820340
   Luk CK, 2005, ACM SIGPLAN NOTICES, V40, P190, DOI 10.1145/1064978.1065034
   Nath R, 2013, IEEE SYMP COMP COMMU
   O'Neal K., 2017, 2017 54 ACMEDACIEEE, P1
   O'Neal K, 2017, ACM T EMBED COMPUT S, V16, DOI 10.1145/3126557
   Palermo G, 2009, IEEE T COMPUT AID D, V28, P1816, DOI 10.1109/TCAD.2009.2028681
   Pellauer M, 2011, INT S HIGH PERF COMP, P406, DOI 10.1109/HPCA.2011.5749747
   Perelman E., 2003, Performance Evaluation Review, V31, P318, DOI 10.1145/885651.781076
   Sanchez Daniel, 2013, INT S COMPUTER ARCHI, P475, DOI DOI 10.1145/2485922.2485963
   Skadron K., 2004, ACM T ARCHIT CODE OP, V1, P94
   Sujeeth A.K., 2011, ICML 11
   Tibshirani R, 1996, J ROY STAT SOC B, V58, P267, DOI 10.1111/j.2517-6161.1996.tb02080.x
   Wang S., 2017, MOLECULES, V22, P1, DOI DOI 10.1007/s00784-017-2197-9
   Wu G, 2015, INT S HIGH PERF COMP, P564, DOI 10.1109/HPCA.2015.7056063
   Wunderlich RE, 2003, CONF PROC INT SYMP C, P84, DOI 10.1109/ISCA.2003.1206991
   Yu K., 2006, P 23 INT C MACH LEAR, P1081
   Zheng XN, 2015, PROCEEDINGS INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTER SYSTEMS - ARCHITECTURES, MODELING AND SIMULATION (SAMOS XV), P52, DOI 10.1109/SAMOS.2015.7363659
   Zheng XF, 2016, ACSR ADV COMPUT, V66, P1
   Zhong GW, 2017, DES AUT TEST EUROPE, P1141, DOI 10.23919/DATE.2017.7927161
   Zhong Guanwen, 2016, DAC, P1
NR 32
TC 23
Z9 23
U1 0
U2 5
PY 2018
BP 763
EP 768
DI 10.1109/ISVLSI.2018.00143
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ahmadi, F
   Semati, MR
   Daryanavard, H
AF Ahmadi, Farshid
   Semati, Mohammad R.
   Daryanavard, Hassan
TI A Low-Power Improved-Accuracy Approximate Error-Report-Propagate Adder
   for DSP Applications
SO CIRCUITS SYSTEMS AND SIGNAL PROCESSING
DT Article; Early Access
DE Approximate computing; Approximate adder; High-speed integrated
   circuits; Low-power design; Digital signal processing (DSP);
   Error-report-propagate adder (ERPA)
ID DESIGN; VIDEO
AB Approximate computing is widely used as an efficient method in areas such as digital signal processing (DSP) and machine learning which are inherently error tolerant. This technique can increase the speed and reduce the energy consumption of the hardware at the expense of lower accuracy. As the performance of the adder used in a digital signal processor has a significant impact on its speed and power dissipation, this paper presents an approximate error-report-propagate adder (ERPA) in which error compensation occurs from the higher-value to the lower-value bits without any delay overhead. Furthermore, in microarchitectural level, a novel design methodology for implementing and synthesizing hardware accelerators is proposed. In this design, the approximate adders compensate for each other's error without any additional cost. Simulation results show that the proposed adders offer 17% reduction in the mean error distance compared to the other state-of-the-art approximate adders. Furthermore, a dense computational DSP task using the proposed approximate adders is presented. Compared to other conventional approximate adders, our approximation methodologies achieve 9.47%, 42%, and 26% improvements in quality, energy and area, respectively.
C1 [Ahmadi, Farshid; Semati, Mohammad R.; Daryanavard, Hassan] Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
RP Semati, MR (corresponding author), Univ Hormozgan, Dept Elect & Comp Engn, Bandar Abbas, Iran.
EM farshidahmadi.stu@hormozgan.ac.ir; semati@hormozgan.ac.ir;
   h_daryanavard@hormozgan.ac.ir
CR Asadi MA, 2021, J AMB INTEL HUM COMP, V12, P7745, DOI 10.1007/s12652-020-02499-6
   Banerjee N, 2007, DES AUT TEST EUROPE, P630
   Bhaskaran V., 1997, IMAGE VIDEO COMPRESS
   Celia D, 2018, DES AUT TEST EUROPE, P1488, DOI 10.23919/DATE.2018.8342248
   Chen JJ, 2015, IEEE T CIRCUITS-I, V62, P224, DOI 10.1109/TCSI.2014.2348072
   Eshraghian K., 1993, PRINCIPLES CMOS VLSI
   Garg B, 2019, 2019 IEEE INTERNATIONAL SYMPOSIUM ON SMART ELECTRONIC SYSTEMS (ISES 2019), P296, DOI 10.1109/iSES47678.2019.00073
   Goel S, 2006, IEEE T VLSI SYST, V14, P1309, DOI 10.1109/TVLSI.2006.887807
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Jiang H., 2017, ACM J EMERG TECH COM, V13, P1, DOI DOI 10.1145/3094124
   Jothin R, 2020, MICROPROCESS MICROSY, V78, DOI 10.1016/j.micpro.2020.103237
   Kahng AB, 2012, DES AUT CON, P820
   Kheirandish D, 2021, QUANTUM INF PROCESS, V20, DOI 10.1007/s11128-021-03292-w
   Kumm M, 2018, IEEE T CIRCUITS-II, V65, P567, DOI 10.1109/TCSII.2018.2823780
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Madanayake A, 2015, IEEE CIRC SYST MAG, V15, P25, DOI 10.1109/MCAS.2014.2385553
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Ning Zhu, 2010, Proceedings 2010 International SoC Design Conference (ISOCC 2010), P323, DOI 10.1109/SOCDC.2010.5682905
   Ning Zhu, 2009, 2009 12th International Symposium on Integrated Circuits (ISIC 2009), P69
   Oppenheim AV., 2001, DISCRETE TIME SIGNAL
   Pan Y, 2014, IEEE T CIRCUITS-I, V61, P455, DOI 10.1109/TCSI.2013.2278331
   Pashaeifar M, 2018, IEEE T VLSI SYST, V26, P2530, DOI 10.1109/TVLSI.2018.2859939
   Predictive Technology Model (PTM), AS ED
   Roy AS, 2020, IEEE T VLSI SYST, V28, P876, DOI 10.1109/TVLSI.2020.2967149
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Xu WB, 2018, IEEE T VLSI SYST, V26, P1112, DOI 10.1109/TVLSI.2018.2803081
   Yang ZX, 2015, IEEE INT SYMP NANO, P145, DOI 10.1109/NANOARCH.2015.7180603
   Ye R, 2013, ICCAD-IEEE ACM INT, P48, DOI 10.1109/ICCAD.2013.6691096
   Zhang MY, 2003, PROCEEDINGS OF THE 2003 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL V, P317
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
NR 32
TC 3
Z9 3
U1 2
U2 3
PD 2023 JAN 24
PY 2023
DI 10.1007/s00034-023-02291-9
EA JAN 2023
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Inggs, G
   Thomas, DB
   Luk, W
AF Inggs, Gordon
   Thomas, David B.
   Luk, Wayne
TI A Domain Specific Approach to High Performance Heterogeneous Computing
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Distributed computing; programming environments; accelerator
   architectures; high performance computing; application software
ID INDEPENDENT TASKS; ALLOCATION
AB Users of heterogeneous computing systems face two problems: first, in understanding the trade-off relationships between the observable characteristics of their applications, such as latency and quality of the result, and second, how to exploit knowledge of these characteristics to allocate work to distributed computing platforms efficiently. A domain specific approach addresses both of these problems. By considering a subset of operations or functions, models of the observable characteristics or domain metrics may be formulated in advance, and populated at run-time for task instances. These metric models can then be used to express the allocation of work as a constrained integer program. These claims are illustrated using the domain of derivatives pricing in computational finance, with the domain metrics of workload latency and pricing accuracy. For a large, varied workload of 128 Black-Scholes and Heston model-based option pricing tasks, running upon a diverse array of 16 Multicore CPUs, GPUs and FPGAs platforms, predictions made by models of both the makespan and accuracy are generally within 10 percent of the run-time performance. When these models are used as inputs to machine learning and MILP-based workload allocation approaches, a latency improvement of up to 24 and 270 times over the heuristic approach is seen.
C1 [Inggs, Gordon; Thomas, David B.] Imperial Coll London, Dept Elect & Elect Engn, Circuits & Syst Grp, London SW7 2AZ, England.
   [Luk, Wayne] Imperial Coll London, Dept Comp, Custom Comp Grp, London SW7 2AZ, England.
RP Inggs, G (corresponding author), Imperial Coll London, Dept Elect & Elect Engn, Circuits & Syst Grp, London SW7 2AZ, England.
EM gordon.e.inggs@ieee.org; d.thomas1@imperial.ac.uk; w.luk@imperial.ac.uk
CR Achterberg T, 2009, MATH PROGRAM COMPUT, V1, P1, DOI 10.1007/s12532-008-0001-1
   [Anonymous], 2006, TECH REP
   Berman F., 1996, SUPERCOMPUTING, P39
   Bixby R, 2007, ANN OPER RES, V149, P37, DOI 10.1007/s10479-006-0091-y
   Braun T. D., 2001, High Performance Computing - HiPC 2001. 8th International Conference. Proceedings (Lecture Notes in Computer Science Vol.2238), P307
   Braun TD, 2001, J PARALLEL DISTR COM, V61, P810, DOI 10.1006/jpdc.2000.1714
   Chafi H, 2011, ACM SIGPLAN NOTICES, V46, P35, DOI 10.1145/2038037.1941561
   Che SA, 2009, I S WORKL CHAR PROC, P44, DOI 10.1109/IISWC.2009.5306797
   Chi-Keung Luk, 2009, Proceedings of the 2009 42nd Annual IEEE/ACM International Symposium on Microarchitecture (MICRO 2009), P45
   CHU WW, 1980, COMPUTER, V13, P57, DOI 10.1109/MC.1980.1653419
   de Schryver Christian, 2011, Knowledge-Based and Intelligent Information and Engineering Systems. Proceedings 15th International Conference, KES 2011, P177, DOI 10.1007/978-3-642-23866-6_19
   Fisher N, 2005, 11TH IEEE INTERNATIONAL CONFERENCE ON EMBEDDED AND REAL-TIME COMPUTING SYSTEMS AND APPLICATIONS, PROCEEDINGS, P416, DOI 10.1109/RTCSA.2005.97
   Fowler M., 2010, DOMAIN SPECIFIC LANG
   Grewe D, 2011, LECT NOTES COMPUT SC, V6601, P286, DOI 10.1007/978-3-642-19861-8_16
   Hull JC, 2011, OPTIONS FUTURES OTHE
   IBARRA OH, 1977, J ACM, V24, P280, DOI 10.1145/322003.322011
   Inggs G., 2015, P INT WORKSH FPGAS S, Vabs/1506.06684
   Inggs G, 2013, PROC INT CONF PARAL, P688, DOI 10.1109/ICPP.2013.82
   Kang QM, 2011, J SYST SOFTWARE, V84, P985, DOI 10.1016/j.jss.2011.01.051
   Karp R.M., 2010, REDUCIBILITY COMBINA
   KHOKHAR AA, 1993, COMPUTER, V26, P18, DOI 10.1109/2.214439
   Kidd T, 1996, SECOND INTERNATIONAL SYMPOSIUM ON PARALLEL ARCHITECTURES, ALGORITHMS, AND NETWORKS (I-SPAN '96), PROCEEDINGS, P514, DOI 10.1109/ISPAN.1996.509034
   Kirlik G, 2014, EUR J OPER RES, V232, P479, DOI 10.1016/j.ejor.2013.08.001
   Koch T., 2004, THESIS
   Kuang SR, 2005, 11TH INTERNATIONAL CONFERENCE ON PARALLEL AND DISTRIBUTED SYSTEMS WORKSHOPS, VOL II, PROCEEDINGS,, P37
   Nardi B.A., 1993, SMALL MATTER PROGRAM
   Peterson P, 2001, SCIPY OPEN SOURCE SC
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Tarplee KM, 2015, J PARALLEL DISTR COM, V84, P76, DOI 10.1016/j.jpdc.2015.07.002
   Thomas DB, 2007, ICFPT 2007: INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY, PROCEEDINGS, P97
   van Deursen A, 2000, ACM SIGPLAN NOTICES, V35, P26, DOI 10.1145/352029.352035
NR 31
TC 6
Z9 6
U1 0
U2 12
PD JAN 1
PY 2017
VL 28
IS 1
BP 2
EP 15
DI 10.1109/TPDS.2016.2563427
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Dix, J
   Holleman, J
   Blalock, BJ
AF Dix, Jeff
   Holleman, Jeremy
   Blalock, Benjamin J.
TI Programmable Energy-Efficient Analog Multilayer Perceptron Architecture
   Suitable for Future Expansion to Hardware Accelerators
SO JOURNAL OF LOW POWER ELECTRONICS AND APPLICATIONS
DT Article
DE neural network; multilayer perceptron; energy efficient; analog; weak
   inversion; programmable
ID TRANSLINEAR CIRCUITS
AB A programmable, energy-efficient analog hardware implementation of a multilayer perceptron (MLP) is presented featuring a highly programmable system that offers the user the capability to create an MLP neural network hardware design within the available framework. In addition to programmability, this implementation provides energy-efficient operation via analog/mixed-signal design. The configurable system is made up of 12 neurons and is fabricated in a standard 130 nm CMOS process occupying approximately 1 mm2 of on-chip area. The system architecture is analyzed in several different configurations with each achieving a power efficiency of greater than 1 tera-operations per watt. This work offers an energy-efficient and scalable alternative to digital configurable neural networks that can be built upon to create larger networks capable of standard machine learning applications, such as image and text classification. This research details a programmable hardware implementation of an MLP that achieves a peak power efficiency of 5.23 tera-operations per watt while consuming considerably less power than comparable digital and analog designs. This paper describes circuit elements that can readily be scaled up at the system level to create a larger neural network architecture capable of improved energy efficiency.
C1 [Dix, Jeff] Univ Arkansas, Elect Engn Dept, Fayetteville, AR 72701 USA.
   [Holleman, Jeremy] Univ North Carolina Charlotte, Elect & Comp Engn Dept, Charlotte, NC 28262 USA.
   [Blalock, Benjamin J.] Univ Tennessee Knoxville, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
RP Blalock, BJ (corresponding author), Univ Tennessee Knoxville, Dept Elect Engn & Comp Sci, Knoxville, TN 37996 USA.
EM dix@uark.edu; jhollem3@uncc.edu; bblalock@utk.edu
CR Al-Absi M. A., 2012, 2012 International Conference on Computer and Communication Engineering (ICCCE), P13, DOI 10.1109/ICCCE.2012.6271143
   Binas J, 2020, Arxiv, DOI arXiv:1606.07786
   Duc-Thinh Nguyen-hoang, 2022, 2022 IEEE Ninth International Conference on Communications and Electronics (ICCE), P219, DOI 10.1109/ICCE55644.2022.9852060
   Gales M., 2015, MODULE 4F10 STAT PAT
   Gilbert B, 1996, ANALOG INTEGR CIRC S, V9, P95, DOI 10.1007/BF00166408
   GILBERT B, 1975, ELECTRON LETT, V11, P14, DOI 10.1049/el:19750011
   Gravati M, 2005, PROC EUR SOLID-STATE, P495, DOI 10.1109/ESSCIR.2005.1541668
   Harrison R., 2010, MOSFET OPERATION WEA
   Hasler P, 2005, FIFTH INTERNATIONAL WORKSHOP ON SYSTEM-ON-CHIP FOR REAL-TIME APPLICATIONS, PROCEEDINGS, P413, DOI 10.1109/IWSOC.2005.83
   LONT JB, 1992, IEEE T NEURAL NETWOR, V3, P457, DOI 10.1109/72.129418
   Lopez-Martin AJ, 2000, VLSI DES, V11, P321, DOI 10.1155/2000/21852
   MacKay D.J., 2003, INFORM THEORY INFERE
   MEAD CA, 1989, ADVANCED RESEARCH IN VLSI : PROCEEDINGS OF THE DECENNIAL CALTECH CONFERENCE ON VLSI, P1
   Minch BA, 2002, 2002 45TH MIDWEST SYMPOSIUM ON CIRCUITS AND SYSTEMS, VOL II, CONFERENCE PROCEEDINGS, P53
   Park SW, 2015, IEEE T BIOMED CIRC S, V9, P838, DOI 10.1109/TBCAS.2015.2504563
   Riedmiller M., 2009, MACHINE LEARNING MUL
   Sedra A.S., 1998, MICROELECTRONIC CIRC, VVolume 1
   Talaska T, 2016, IEEE T NEUR NET LEAR, V27, P661, DOI 10.1109/TNNLS.2015.2434847
   Tsai CH, 2017, IEEE J SOLID-ST CIRC, V52, P2601, DOI 10.1109/JSSC.2017.2715171
   Venkataramanaiah SK, 2020, INT SOC DESIGN CONF, P21, DOI 10.1109/ISOCC50952.2020.9333063
   Wunderlich RB, 2013, IEEE T VLSI SYST, V21, P1496, DOI 10.1109/TVLSI.2012.2211049
   Yüzügüler AC, 2019, IEEE MICRO, V39, P55, DOI 10.1109/MM.2019.2931182
   Zhang H., 2021, P 2021 IEEE 14 INT C, P1, DOI DOI 10.1109/ASICON52560.2021.9620305
NR 23
TC 0
Z9 0
U1 0
U2 0
PD SEP
PY 2023
VL 13
IS 3
AR 47
DI 10.3390/jlpea13030047
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Feng, HY
   Chen, PY
   Hou, JP
AF Feng, Hsin-Yu
   Chen, Po-Ying
   Hou, Janpu
GP IEEE
TI SR-ScatNet Algorithm for On-device ECG Time Series Anomaly Detection
SO SOUTHEASTCON 2021
SE IEEE SoutheastCon-Proceedings
DT Proceedings Paper
CT IEEEE Southeast Conference (SoutheastCon)
CY MAR 10-13, 2021
CL Atlanta, GA
DE Spectral Residual; Arrhythmia ECG; Smart Cloth
AB Anomaly detection of real-time ECG time series is of particular interest for early detection of cardiovascular disease for aging population. To use convolutional neural networks (CNN) for any on-device training or inference, you need GPU-accelerated hardware which will not only increase the hardware cost but also consume higher battery power. We proposed a SR-ScatNet algorithm for on-device application such as smart cloth with ECG monitoring sensors. Two improvements were made. First on spectral residual, we use Fourier Transform of autocorrelation of ECG signals instead of original time series to increase the sensitivity. Second on feature extraction, we use shallow wavelet scattering network (ScatNet) instead of deep CNN network so the on-device training can be performed on a simple Arm Cortex-A53 processor without any GPU-accelerator. These improvements are made to create a compact machine learning model according to the nature of different waves constituting the ECG signals. To verify the proposed method, we use the MIT-BIH Arrhythmia Database. The spectral residual of autocorrelation ECG signals can detect the abnormal ECG signals with over 98% accuracy. The wavelet scattering network can further classify the type of abnormality with over 90% accuracy. We believe the design of ECG monitoring smart cloth can benefit from such SR-ScatNet algorithm.
C1 [Feng, Hsin-Yu; Chen, Po-Ying] Natl Tsing Hua Univ, Dept Math, Hsinchu, Taiwan.
   [Hou, Janpu] Inst Data Learning, Appl Data Res, Las Vegas, NV USA.
RP Feng, HY (corresponding author), Natl Tsing Hua Univ, Dept Math, Hsinchu, Taiwan.
EM sabrina900118@gmail.com; bchenturkey@gmail.com; janpu@ieee.org
CR Feng Hsin-Yu, 2020, THESIS NATL TSING HU
   Hou D., 2020, 2020 IEEE INT C CONS, P1
   Kumar A, 2019, BIOMED ENG LETT, V9, P145, DOI 10.1007/s13534-018-0087-y
   Lu ZY, 2020, IEEE J-STARS, V13, P4311, DOI 10.1109/JSTARS.2020.3011992
   Moody GA, 2001, IEEE ENG MED BIOL, V20, P45, DOI 10.1109/51.932724
   Prerau MJ, 2017, PHYSIOLOGY, V32, P60, DOI 10.1152/physiol.00062.2015
   Quiroz-Juárez MA, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-55448-5
   Xing Tony, 2019, STRAT DAT C NEW YORK STRAT DAT C NEW YORK
   Zhou HJ, 2019, IEEE ACCESS, V7, P175889, DOI 10.1109/ACCESS.2019.2957519
NR 9
TC 4
Z9 4
U1 0
U2 4
PY 2021
BP 736
EP 740
DI 10.1109/SOUTHEASTCON45413.2021.9401872
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Ngo, DM
   Lightbody, D
   Temko, A
   Pham-Quoc, C
   Tran, NT
   Murphy, CC
   Popovici, E
AF Ngo, Duc-Minh
   Lightbody, Dominic
   Temko, Andriy
   Pham-Quoc, Cuong
   Tran, Ngoc-Thinh
   Murphy, Colin C. C.
   Popovici, Emanuel
TI HH-NIDS: Heterogeneous Hardware-Based Network Intrusion Detection
   Framework for IoT Security
SO FUTURE INTERNET
DT Article
DE network security; artificial neural Networks; hardware accelerators; low
   power; high-performance; microcontrollers; CPU; GPU; FPGA
AB This study proposes a heterogeneous hardware-based framework for network intrusion detection using lightweight artificial neural network models. With the increase in the volume of exchanged data, IoT networks' security has become a crucial issue. Anomaly-based intrusion detection systems (IDS) using machine learning have recently gained increased popularity due to their generation's ability to detect unseen attacks. However, the deployment of anomaly-based AI-assisted IDS for IoT devices is computationally expensive. A high-performance and ultra-low power consumption anomaly-based IDS framework is proposed and evaluated in this paper. The framework has achieved the highest accuracy of 98.57% and 99.66% on the UNSW-NB15 and IoT-23 datasets, respectively. The inference engine on the MAX78000EVKIT AI-microcontroller is 11.3 times faster than the Intel Core i7-9750H 2.6 GHz and 21.3 times faster than NVIDIA GeForce GTX 1650 graphics cards, when the power drawn was 18mW. In addition, the pipelined design on the PYNQ-Z2 SoC FPGA board with the Xilinx Zynq xc7z020-1clg400c device is optimised to run at the on-chip frequency (100 MHz), which shows a speedup of 53.5 times compared to the MAX78000EVKIT.
C1 [Ngo, Duc-Minh; Lightbody, Dominic; Temko, Andriy; Murphy, Colin C. C.; Popovici, Emanuel] Univ Coll Cork, Elect & Elect Engn, Cork T12 K8AF, Ireland.
   [Pham-Quoc, Cuong; Tran, Ngoc-Thinh] Ho Chi Minh City Univ Technol HCMUT, Comp Sci & Engn, VNU HCM, 268 Ly Thuong Kiet St,Dist 10, Ho Chi Minh City 740050, Vietnam.
RP Ngo, DM; Murphy, CC (corresponding author), Univ Coll Cork, Elect & Elect Engn, Cork T12 K8AF, Ireland.; Pham-Quoc, C (corresponding author), Ho Chi Minh City Univ Technol HCMUT, Comp Sci & Engn, VNU HCM, 268 Ly Thuong Kiet St,Dist 10, Ho Chi Minh City 740050, Vietnam.
EM 120220051@umail.ucc.ie; cuongpham@hcmut.edu.vn; colinmurphy@ucc.ie
CR Ahmed M, 2016, J NETW COMPUT APPL, V60, P19, DOI 10.1016/j.jnca.2015.11.016
   Alani MM, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22155690
   Alsoufi MA, 2021, APPL SCI-BASEL, V11, DOI 10.3390/app11188383
   [Anonymous], XUP PYNQ Z2
   Antonopoulos CP, 2017, ELECTRONICS-SWITZ, V6, DOI 10.3390/electronics6030054
   Bovenzi G, 2020, IEEE GLOB COMM CONF, DOI 10.1109/GLOBECOM42002.2020.9348167
   Cheour R., 2020, P IEEE 6 WORLD FORUM, P1
   d'Orazio L., 2018, OPEN J INTERNET THIN, V4, P150
   Douiba M, 2023, J SUPERCOMPUT, V79, P3392, DOI 10.1007/s11227-022-04783-y
   Ngo DM, 2021, I C FIELD PROG LOGIC, P69, DOI 10.1109/FPL53798.2021.00020
   Dutta V, 2020, J UNIVERS COMPUT SCI, V26, P1422
   Dutta V, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20164583
   Expertsystem, WHAT IS MACH LEARN D
   Gao CY, 2019, PALG STUD GLOB HIGHE, P1, DOI 10.1007/978-3-030-21465-4_1
   Garcia S., 2020, IOT 23 LABELED DATAS
   García-Teodoro P, 2009, COMPUT SECUR, V28, P18, DOI 10.1016/j.cose.2008.08.003
   Hasan M, 2019, INTERNET THINGS-NETH, V7, DOI 10.1016/j.iot.2019.100059
   Hegde Mandira, 2020, 2020 International Conference on Intelligent Data Science Technologies and Applications (IDSTA), P21, DOI 10.1109/IDSTA50958.2020.9264143
   Heidari A, 2023, CLUSTER COMPUT, V26, P3753, DOI 10.1007/s10586-022-03776-z
   Hossin M., 2015, INT J DATA MIN KNOWL, V5, P1, DOI [DOI 10.5121/IJDKP.2015.5201, 10.5121/ijdkp.2015.5201]
   Hubballi N, 2014, COMPUT COMMUN, V49, P1, DOI 10.1016/j.comcom.2014.04.012
   Hussain FB, 2020, ARXIV
   Idhammad M, 2017, INT J ADV COMPUT SC, V8, P465
   Integrated M., MAX78000 ART INT MIC
   Integrated M., MAX78000EVKIT EV KIT
   Ioannou L, 2019, I C FIELD PROG LOGIC, P232, DOI 10.1109/FPL.2019.00043
   Kalantar A, 2021, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM51124.2021.00013
   Kumar P, 2021, AUTOM CONTROL COMPUT, V55, P137, DOI 10.3103/S0146411621020085
   Kumar KS, 2017, 2017 3RD IEEE INTERNATIONAL SYMPOSIUM ON NANOELECTRONIC AND INFORMATION SYSTEMS (INIS), P151, DOI 10.1109/iNIS.2017.39
   Maitra S, 2019, 2019 IEEE SENSORS APPLICATIONS SYMPOSIUM (SAS)
   Manimurugan S, 2020, IEEE ACCESS, V8, P77396, DOI 10.1109/ACCESS.2020.2986013
   Mishra A., 2020, P 2 INT C DAT ENG AP, P1, DOI 10.1109/IDEA49133.2020.9170674
   Mothukuri V, 2022, IEEE INTERNET THINGS, V9, P2545, DOI 10.1109/JIOT.2021.3077803
   Moustafa N, 2015, 2015 MILITARY COMMUNICATIONS AND INFORMATION SYSTEMS CONFERENCE (MILCIS)
   Nobakht M, 2022, EVOL SYST-GER, DOI 10.1007/s12530-022-09471-z
   Protogerou A, 2021, EVOL SYST-GER, V12, P19, DOI 10.1007/s12530-020-09347-0
   Sidana M., TYPES CLASSIFICATION
   Stoian N.-A., 2020, THESIS U TWENTE ENSC
   Storcheus D., 2015, JMLR WORKSHOP C P, P1
   Thamaraiselvi D., 2020, INT J COMPUT SCI MOB, V9, P95, DOI [10.47760/ijcsmc.2020.v09i10.012, DOI 10.47760/IJCSMC.2020.V09I10.012]
   Nguyen TD, 2019, INT CON DISTR COMP S, P756, DOI 10.1109/ICDCS.2019.00080
   Ullah I, 2022, IEEE ACCESS, V10, P62722, DOI 10.1109/ACCESS.2022.3176317
   Vaccari I, 2020, SENSORS-BASEL, V20, DOI 10.3390/s20226578
   Vailshery L., NUMBER INTERNET THIN
   van Long N.H., 2020, P INT WORKSHOP VERY
   Vinayakumar R, 2019, IEEE ACCESS, V7, P41525, DOI 10.1109/ACCESS.2019.2895334
   Wielgosz M, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19132981
   Xu CY, 2018, IEEE ACCESS, V6, P48697, DOI 10.1109/ACCESS.2018.2867564
   Yang Z, 2022, COMPUT SECUR, V116, DOI 10.1016/j.cose.2022.102675
   Yin CY, 2022, IEEE T SYST MAN CY-S, V52, P112, DOI 10.1109/TSMC.2020.2968516
NR 50
TC 3
Z9 3
U1 0
U2 3
PD JAN
PY 2023
VL 15
IS 1
AR 9
DI 10.3390/fi15010009
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Mills, AP
AF Mills, Allen P., Jr.
GP AIP
TI Proposal for a slow positron facility at Jefferson National Laboratory
SO INTERNATIONAL WORKSHOP ON PHYSICS WITH POSITRONS AT JEFFERSON LAB
SE AIP Conference Proceedings
DT Proceedings Paper
CT International Workshop on Positron Physics at Jefferson Lab (JPos)
CY SEP 12-17, 2017
CL Newport News, VA
ID BRIGHTNESS ENHANCEMENT; ANNIHILATION; DIFFRACTION; CRYSTAL; REEMISSION
AB One goal of the JPos-17 International Workshop on Physics with Positrons was to ascertain whether it would be a good idea to expand the mission of the Thomas Jefferson National Accelerator Facility (JLab) to include science with low energy (i.e. "slow") spin polarized positrons. It is probably true that experimentation with slow positrons would potentially have wide-ranging benefits comparable to those obtained with neutron and x-ray scattering, but it is certain that the full range of these benefits will never be fully available without an infrastructure comparable to that of existing neutron and x-ray facilities. The role for Jefferson Laboratory would therefore be to provide and maintain (1) a dedicated set of machines for making and manipulating high intensity, high brightness beams of polarized slow positrons; (2) a suite of unique and easily used instruments of wide utility that will make efficient use of the positrons; and (3) a group of on-site positron scientists to provide scientific leadership, instrument development, and user support. In this note some examples will be given of the science that might make a serious investment in a positron facility worthwhile. At the same time, the lessons learned from various proposed and successful positron facilities will be presented for consideration.
C1 [Mills, Allen P., Jr.] Univ Calif Riverside, Riverside, CA 92521 USA.
RP Mills, AP (corresponding author), Univ Calif Riverside, Riverside, CA 92521 USA.
EM allen.mills@ucr.edu
CR Abbott D, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.214801
   Barbiellini B, 2006, NEW J PHYS, V8, DOI 10.1088/1367-2630/8/2/020
   BERKO S, 1980, SCRIPTA METALL MATER, V14, P23, DOI 10.1016/0036-9748(80)90118-0
   Berko S., 1981, POSITRON SOLID STATE, P64
   Biasini M, 2006, J PHYS-CONDENS MAT, V18, pL289, DOI 10.1088/0953-8984/18/22/L03
   BRANDES GR, 1988, REV SCI INSTRUM, V59, P228, DOI 10.1063/1.1140231
   BRANDES GR, 1988, PHYS REV LETT, V61, P492, DOI 10.1103/PhysRevLett.61.492
   CANTER KF, 1982, CAN J PHYS, V60, P551, DOI 10.1139/p82-071
   CANTER KF, 1972, J PHYS PT B ATOM M P, V5, pL167, DOI 10.1088/0022-3700/5/8/007
   Cassidy DB, 2010, PHYS REV LETT, V104, DOI 10.1103/PhysRevLett.104.173401
   Cassidy DB, 2001, PHYS REV C, V64, DOI 10.1103/PhysRevC.64.054603
   Chen Y., 1993, CONF9209221 DOE
   Cherry W. H., 1958, THESIS
   Davisson C, 1927, PHYS REV, V30, P705, DOI 10.1103/PhysRev.30.705
   Dil JH, 2009, J PHYS-CONDENS MAT, V21, DOI 10.1088/0953-8984/21/40/403001
   Eberle C., 1994, CONF9405170
   FRIEZE WE, 1985, PHYS REV B, V31, P5628, DOI 10.1103/PhysRevB.31.5628
   Fukaya Y, 2014, APPL PHYS EXPRESS, V7, DOI 10.7567/APEX.7.056601
   Gidley DW, 1999, PHYS REV B, V60, pR5157, DOI 10.1103/PhysRevB.60.R5157
   Golge S, 2014, J APPL PHYS, V115, DOI 10.1063/1.4884781
   HORSKY TN, 1989, PHYS REV LETT, V62, P1876, DOI 10.1103/PhysRevLett.62.1876
   Howell R. H., 1997, AIP C P, V392, P451, DOI [10.1063/1.52486, DOI 10.1063/1.52486]
   Hugenschmidt C, 2016, SURF SCI REP, V71, P547, DOI 10.1016/j.surfrep.2016.09.002
   Hulett LD, 1997, ACCELERATOR-BASED ATOMIC PHYSICS TECHNIQUES AND APPLICATIONS, P637
   JACKSON JD, 1957, PHYS REV, V106, P517, DOI 10.1103/PhysRev.106.517
   Jones ACL, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.216402
   Jones ACL, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.153201
   KOSSLER WJ, 1994, AIP CONF PROC, P296, DOI 10.1063/1.45513
   LEE KH, 1994, PHYS REV LETT, V72, P1866, DOI 10.1103/PhysRevLett.72.1866
   LEE TD, 1956, PHYS REV, V104, P254, DOI 10.1103/PhysRev.104.254
   LOCK DG, 1973, J PHYS F MET PHYS, V3, P561, DOI 10.1088/0305-4608/3/3/014
   LYNN KG, 1994, HYPERFINE INTERACT, V89, P19, DOI 10.1007/BF02064493
   MACKENZIE IK, 1967, PHYS REV LETT, V19, P946, DOI 10.1103/PhysRevLett.19.946
   MADANSKY L, 1950, PHYS REV, V79, P397, DOI 10.1103/PhysRev.79.397
   Mills AP, 2011, RIV NUOVO CIMENTO, V34, P151, DOI 10.1393/ncr/i2011-10064-5
   Mills AP, 2001, NEW DIRECTIONS IN ANTIMATTER CHEMISTRY AND PHYSICS, P115
   MILLS AP, 1980, APPL PHYS, V23, P189, DOI 10.1007/BF00899716
   MILLS AP, 1986, APPL PHYS LETT, V49, P1121, DOI 10.1063/1.97441
   Mills Jr A. P., 1994, AIP C P, V303, P335
   Mukherjee S, 2016, REV SCI INSTRUM, V87, DOI 10.1063/1.4943858
   Peng P. J., 1996, PHYS REV LETT, V76, P2157
   ROSENBERG IJ, 1980, PHYS REV LETT, V44, P1139, DOI 10.1103/PhysRevLett.44.1139
   SCHULTZ PJ, 1986, PHYS REV B, V34, P442, DOI 10.1103/PhysRevB.34.442
   Stoeffl W, 1999, APPL SURF SCI, V149, P1, DOI 10.1016/S0169-4332(99)00162-2
   VEHANEN A, 1983, APPL PHYS A-MATER, V32, P163, DOI 10.1007/BF00616613
   Wagner A, 2017, J PHYS CONF SER, V791, DOI 10.1088/1742-6596/791/1/012004
   Xu J, 1997, APPL SURF SCI, V116, P34, DOI 10.1016/S0169-4332(96)00970-1
   ZITZEWITZ PW, 1979, PHYS REV LETT, V43, P1281, DOI 10.1103/PhysRevLett.43.1281
NR 48
TC 2
Z9 2
U1 0
U2 5
PY 2018
VL 1970
AR 040002
DI 10.1063/1.5040214
WC Physics, Particles & Fields
DA 2023-11-11
ER

PT C
AU Dupuis, E
   Novo, D
   O'Connor, I
   Bosio, A
AF Dupuis, Etienne
   Novo, David
   O'Connor, Ian
   Bosio, Alberto
GP IEEE
TI Sensitivity Analysis and Compression Opportunities in DNNs Using Weight
   Sharing
SO 2020 23RD INTERNATIONAL SYMPOSIUM ON DESIGN AND DIAGNOSTICS OF
   ELECTRONIC CIRCUITS & SYSTEMS (DDECS 2020)
SE IEEE International Symposium on Design and Diagnostics of Electronic
   Circuits & Systems
DT Proceedings Paper
CT 23rd IEEE International Symposium on Design and Diagnostics of
   Electronic Circuits and Systems (DDECS)
CY APR 22-24, 2020
CL Univ Novi Sad, Novi Sad, SERBIA
HO Univ Novi Sad
DE Deep Neural Networks; Approximate Computing; Model Compression; Weight
   Sharing; Design Space Exploration; Embedded System; Hardware Accelerator
AB Deep artificial Neural Networks (DNNs) are currently one of the most intensively and widely used predictive models in the field of machine learning. However, the computational workload involved in DNNs is typically out of reach for lowpower embedded devices. The approximate computing paradigm can be exploited to reduce the DNN complexity. It improves performance and energy-efficiency by relaxing the need for fully accurate operations. There are a large number of implementation options leveraging many approximation techniques (e.g., pruning, quantization, weight-sharing, low-rank factorization, knowledge distillation, etc.). However, to the best of our knowledge, a few or no automated approach exists to explore, select and generate the best approximate version of a given DNN according to design objectives. The goal of this paper is to demonstrate that the design space exploration phase can enable significant network compression without noticeable accuracy loss. We demonstrate this via an example based on weight sharing and show that our direct conversion method can obtain a 4.85x compression rate with 0.14% accuracy loss in ResNetl8 and 4.91x compression rate with 0.44% accuracy loss in SqueezeNet without involving retraining steps.
C1 [Dupuis, Etienne; O'Connor, Ian; Bosio, Alberto] Ecole Cent Lyon, Inst Nanotechnol Lyon, Lyon, France.
   [Novo, David] Univ Montpellier, CNRS, LIRMM, Montpellier, France.
RP Dupuis, E (corresponding author), Ecole Cent Lyon, Inst Nanotechnol Lyon, Lyon, France.
EM etienne.dupuis@ec-lyon.fr; david.novo@lirmm.fr; ian.oconnor@ec-lyon.fr;
   alberto.bosio@ec-lyon.fr
CR Acharya A., 2018, ONLINE EMBEDDING COM
   Alom MZ, 2019, ELECTRONICS-SWITZ, V8, DOI 10.3390/electronics8030292
   [Anonymous], 2015, CORR
   [Anonymous], 2014, COMPRESSING DEEP CON
   Arvin AM, 2009, LIVE VARIOLA VIRUS: CONSIDERATIONS FOR CONTINUING RESEARCH, P9
   Bai Junjie, 2019, ONNX OPEN NEURAL NET
   Baskin C., 2018, UNIQ UNIFORM NOISE I
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cheng T, 2016, AIDS BEHAV, V20, P377, DOI 10.1007/s10461-015-1101-3
   Dupuis E., 2020, P DATE2020
   Han SY, 2016, IEEE ICC, DOI 10.1109/ICC.2016.7511104
   Hartigan J. A., 1979, Applied Statistics, V28, P100, DOI 10.2307/2346830
   Hinton G., 2015, P NIPS DEEP LEARNING, V14, P38, DOI DOI 10.48550/ARXIV.1503.02531
   Kaiming He, 2016, 2016 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), P770, DOI 10.1109/CVPR.2016.90
   Razlighi MS, 2017, DES AUT TEST EUROPE, P1775, DOI 10.23919/DATE.2017.7927280
   Redmon J., 2016, ARXIV160207360, P779
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Ullrich K., 2017, ABS170204008 ARXIV
   Wu J., 2018, DEEP K MEANS RETRAIN
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
NR 20
TC 7
Z9 7
U1 0
U2 0
PY 2020
DI 10.1109/ddecs50862.2020.9095658
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Peng, XC
   Liu, R
   Yu, SM
AF Peng, Xiaochen
   Liu, Rui
   Yu, Shimeng
GP IEEE
TI Optimizing Weight Mapping and Data Flow for Convolutional Neural
   Networks on RRAM based Processing-In-Memory Architecture
SO 2019 IEEE INTERNATIONAL SYMPOSIUM ON CIRCUITS AND SYSTEMS (ISCAS)
SE IEEE International Symposium on Circuits and Systems
DT Proceedings Paper
CT IEEE International Symposium on Circuits and Systems (IEEE ISCAS)
CY MAY 26-29, 2019
CL Sapporo, JAPAN
DE non-volatile memory; processing-in-memory; machine learning; deep neural
   network; hardware accelerator
AB Resistive random access memory (RRAM) based array architecture has been proposed for on-chip acceleration of convolutional neural networks (CNNs), where the array could be configured for dot-product computation in a parallel fashion by summing up the column currents. Prior processing-in-memory (PIM) designs unroll each 3D kernel of the convolutional layers into a vertical column of a large weight matrix, where the input data will be accessed multiple times. As a result, significant latency and energy are consumed in interconnect and buffer. In this paper, in order to maximize both weight and input data reuse for RRAM based PIM architecture, we propose a novel weight mapping method and the corresponding data flow which divides the kernels and assign the input data into different processing-elements (PEs) according to their spatial locations. The proposed design achieves similar to 65% save in latency and energy for interconnect and buffer, and yields overall 2.1x speed up and similar to 17% improvement in the energy efficiency in terms of TOPS/W for VGG-16 CNN, compared with the prior design based on the conventional mapping method.
C1 [Peng, Xiaochen; Yu, Shimeng] Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
   [Liu, Rui] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ USA.
RP Yu, SM (corresponding author), Georgia Inst Technol, Sch Elect & Comp Engn, Atlanta, GA 30332 USA.
EM shimeng.yu@ece.gatech.edu
CR [Anonymous], 2018, IEEE T COMPUTER AIDE
   Chen PY, 2016, IEEE INT SYMP CIRC S, P2310, DOI 10.1109/ISCAS.2016.7539046
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Simonyan K., 2015, P 3 INT C LEARN REPR, P1
   Sun XY, 2018, DES AUT TEST EUROPE, P1423, DOI 10.23919/DATE.2018.8342235
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
NR 11
TC 39
Z9 39
U1 0
U2 3
PY 2019
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Truong, MSQ
   Shen, LT
   Glass, A
   Hoffmann, A
   Carley, LR
   Bain, JA
   Ghose, S
AF Truong, Minh S. Q.
   Shen, Liting
   Glass, Alexander
   Hoffmann, Alison
   Carley, L. Richard
   Bain, James A.
   Ghose, Saugata
TI Adapting the RACER Architecture to Integrate Improved In-ReRAM Logic
   Primitives
SO IEEE JOURNAL ON EMERGING AND SELECTED TOPICS IN CIRCUITS AND SYSTEMS
DT Article
DE Computer architecture; Microprocessors; Resistance; Logic arrays; Random
   access memory; Topology; Voltage; Accelerator architectures; memory
   architecture; resistive RAM
ID MEMORY; OPERATIONS; MEMRISTOR; CHALLENGES
AB Modern computing applications based upon machine learning can incur significant data movement overheads in state-of-the-art computers. Resistive-memory-based processing-using-memory (PUM) can mitigate this data movement by instead performing computation in situ (i.e., directly within memory cells), but device-level limitations restrict the practicality and/or performance of many PUM architecture proposals. The RACER architecture overcomes these limitations, by proposing efficient peripheral circuitry and the concept of bit-pipelining to enable high-performance, high-efficiency computation using small memory tiles. In this work, we extend RACER to adapt easily to different PUM logic families, by (1) modifying the device access circuitry to support a wide range of logic families, (2) evaluating three logic families proposed by prior work, and (3) proposing and evaluating a new logic family called OSCAR that significantly relaxes the switching voltage constraints required to perform logic with resistive memory devices. We show that the modified RACER architecture, using the OSCAR logic family, can enable practical PUM on real ReRAM devices while improving performance and energy savings by 30% and 37%, respectively, over the original RACER work.
C1 [Truong, Minh S. Q.; Shen, Liting; Glass, Alexander; Hoffmann, Alison; Carley, L. Richard; Bain, James A.] Carnegie Mellon Univ, Dept Elect & Comp Engn, Pittsburgh, PA 15213 USA.
   [Ghose, Saugata] Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
RP Ghose, S (corresponding author), Univ Illinois, Dept Comp Sci, Urbana, IL 61801 USA.
EM minhsyqt@andrew.cmu.edu; ghose@illinois.edu
CR Aga S, 2017, INT S HIGH PERF COMP, P481, DOI 10.1109/HPCA.2017.21
   Angizi S, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317764
   Angizi S, 2018, DES AUT CON, DOI 10.1145/3195970.3196009
   Ankit A, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P715, DOI 10.1145/3297858.3304049
   [Anonymous], 2018, PROC 55 ACMESDAIEEE
   ARCANA Research Group, 2021, RACER Artifacts-Zenodo Repository, DOI 10.5281/zenodo.5495803
   BATCHER KE, 1982, IEEE T COMPUT, V31, P377, DOI 10.1109/TC.1982.1676015
   Bhanushali K., 2015, P 2015 S INT S PHYS, P165
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3173162.3173177, 10.1145/3296957.3173177]
   Chen A, 2016, SOLID STATE ELECTRON, V125, P25, DOI 10.1016/j.sse.2016.07.006
   Chen YY, 2012, 2012 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chou T, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P114, DOI 10.1145/3352460.3358328
   Chung-Wei Hsu, 2013, 2013 Symposium on VLSI Technology, pT166
   Dally W. J., 2015, HIPEAC KEYN, P1
   Dong XY, 2008, DES AUT CON, P554
   Eckert C, 2018, CONF PROC INT SYMP C, P383, DOI 10.1109/ISCA.2018.00040
   El-Kady M. A., 1983, IEEE POWER ENG REV, P46
   Fantini A, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P30, DOI 10.1109/IMW.2013.6582090
   Fujiki D, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P397, DOI 10.1145/3307650.3322257
   Gaillardon PE, 2016, DES AUT TEST EUROPE, P427
   Gao F, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P100, DOI 10.1145/3352460.3358260
   Ghose S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2934048
   Gupta S, 2018, ICCAD-IEEE ACM INT, DOI 10.1145/3240765.3240811
   Hajinazar N, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P329, DOI 10.1145/3445814.3446749
   Hamdioui S, 2017, DES AUT TEST EUROPE, P722, DOI 10.23919/DATE.2017.7927083
   Hamdioui S, 2015, DES AUT TEST EUROPE, P1718
   Imani M, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P802, DOI 10.1145/3307650.3322237
   Intel Corp, INT XEON PLAT 8253
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Kang U, 2014, PROC MEMORY FORUM
   Kestor G, 2013, I S WORKL CHAR PROC, P56, DOI 10.1109/IISWC.2013.6704670
   Kvatinsky S, 2014, IEEE T CIRCUITS-II, V61, P895, DOI 10.1109/TCSII.2014.2357292
   Kvatinsky S, 2014, IEEE T VLSI SYST, V22, P2054, DOI 10.1109/TVLSI.2013.2282132
   Kvatinsky S, 2011, 2011 IEEE 29TH INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P142, DOI 10.1109/ICCD.2011.6081389
   Levy Y, 2014, MICROELECTRON J, V45, P1429, DOI 10.1016/j.mejo.2014.06.006
   Li BX, 2015, DES AUT CON, DOI 10.1145/2744769.2744870
   Li SC, 2016, DES AUT CON, DOI [10.1145/2897937.2898064, 10.1109/ICAUMS.2016.8479697]
   Liu R, 2015, IEEE ELECTR DEVICE L, V36, P1380, DOI 10.1109/LED.2015.2496257
   Louis J, 2019, IEEE I C ELECT CIRC, P787, DOI [10.1109/icecs46596.2019.8965179, 10.1109/ICECS46596.2019.8965179]
   Maiti DK, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-13754-w
   Makarov A, 2012, MICROELECTRON RELIAB, V52, P628, DOI 10.1016/j.microrel.2011.10.020
   Mandelman JA, 2002, IBM J RES DEV, V46, P187, DOI 10.1147/rd.462.0187
   Minh SQ, 2021, ANN INT S MICROARCHI, P100
   Mutlu O, 2013, 2013 5TH IEEE INTERNATIONAL MEMORY WORKSHOP (IMW), P21, DOI 10.1109/IMW.2013.6582088
   NVIDIA Corp, GEF RTX 2070
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Seshadri V, 2017, ADV COMPUT, V106, P107, DOI 10.1016/bs.adcom.2017.04.004
   Seung Ryul Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P71, DOI 10.1109/VLSIT.2012.6242466
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shimeng Yu, 2016, IEEE Solid-State Circuits Magazine, V8, P43, DOI 10.1109/MSSC.2016.2546199
   Shuangchen Li, 2017, 2017 50th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO), P288, DOI 10.1145/3123939.3123977
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Wang J, 2014, I SYMPOS LOW POWER E, P339, DOI 10.1145/2627369.2627610
   Weste N., 2011, CIRCUITS SYSTEMS PER, V4th
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Woo J, 2016, IEEE ELECTR DEVICE L, V37, P994, DOI 10.1109/LED.2016.2582859
   Xie L, 2015, 2015 33RD IEEE INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P335, DOI 10.1109/ICCD.2015.7357122
   Ye C, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/10/105005
   Yu JT, 2018, DES AUT TEST EUROPE, P1646, DOI 10.23919/DATE.2018.8342278
   Yu SM, 2016, INT EL DEVICES MEET
   Zha Y, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P51, DOI 10.1145/31742433174244
NR 62
TC 0
Z9 0
U1 2
U2 5
PD JUN
PY 2022
VL 12
IS 2
BP 393
EP 407
DI 10.1109/JETCAS.2022.3171765
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chang, YN
   Chen, GJ
AF Chang, Yun-Nan
   Chen, Guan-Jhen
GP IEEE
TI Design of A Bit-Serial Artificial Neuron VLSI Architecture with Early
   Termination
SO 2019 INTERNATIONAL CONFERENCE ON ELECTRONICS, INFORMATION, AND
   COMMUNICATION (ICEIC)
DT Proceedings Paper
CT 18th Annual International Conference on Electronics, Information, and
   Communication (ICEIC)
CY JAN 22-25, 2019
CL Inst Elect & Informat Engineers, Auckland, NEW ZEALAND
HO Inst Elect & Informat Engineers
DE Neuron; nerual network; CNN; most significant bit; bit-serial
AB In this paper, a VLSI design of a bit-serial artificial neuron circuit is proposed. Different from the ordinary bit-serial architectures which usually start from the least significant bit (LSB), the proposed design will start from processing the most significant bit (MSB). For the MSB-first approach, the more significant part of results will be generated earlier, and the intermediate results will be progressively refined by processing the less significant bits. An artificial neuron is equipped with an activation function at the output, and many common used activation functions such as sigmoid, a rectified linear unit (ReLU) etc will saturate to 0 for large negative inputs. Some will saturate to 1 for large positive inputs. Therefore, when the intermediate results are positive or negative enough, the remaining processing of less significant bits can be neglected. Our preliminary results shows that the approximation results due to the proposed early termination can still lead to the same classification accuracy as the full precision, but the processing cycles can be reduced by more than 25%. The proposed methodology can be applied to the design of hardware accelerators for those machine learning networks based on neurons such as neural network (NN) and convolution NN (CNN).
C1 [Chang, Yun-Nan; Chen, Guan-Jhen] Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
RP Chang, YN (corresponding author), Natl Sun Yat Sen Univ, Dept Comp Sci & Engn, Kaohsiung, Taiwan.
CR Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Choi Y, 2017, IEEE T CIRCUITS-II, V64, P1332, DOI 10.1109/TCSII.2017.2691771
   Guo KY, 2018, IEEE T COMPUT AID D, V37, P35, DOI 10.1109/TCAD.2017.2705069
   Judd P, 2017, IEEE COMPUT ARCHIT L, V16, P80, DOI 10.1109/LCA.2016.2597140
   Lee J, 2018, ISSCC DIG TECH PAP I, P218, DOI 10.1109/ISSCC.2018.8310262
   Moons B, 2017, IEEE J SOLID-ST CIRC, V52, P903, DOI 10.1109/JSSC.2016.2636225
   PARHI KK, 1989, IEEE T ACOUST SPEECH, V37, P1099, DOI 10.1109/29.32286
   Sharma H, 2018, CONF PROC INT SYMP C, P764, DOI 10.1109/ISCA.2018.00069
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
NR 11
TC 0
Z9 0
U1 1
U2 1
PY 2019
BP 503
EP 505
DI 10.23919/elinfocom.2019.8706444
WC Computer Science, Information Systems; Telecommunications
DA 2023-11-11
ER

PT C
AU Yik, J
   Kuppannagari, SR
   Zeng, HQ
   Prasanna, VK
AF Yik, Jason
   Kuppannagari, Sanmukh R.
   Zeng, Hanqing
   Prasanna, Viktor K.
GP IEEE
TI Input Feature Pruning for Accelerating GNN Inference on Heterogeneous
   Platforms
SO 2022 IEEE 29TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS, HIPC
SE International Conference on High Performance Computing
DT Proceedings Paper
CT 29th Annual IEEE International Conference on High Performance Computing,
   Data, and Analytics (HiPC)
CY DEC 18-21, 2022
CL Bangalore, INDIA
DE data science algorithms; graph neural network; accuracy/performance
   trade-off; input feature pruning
AB Graph Neural Networks (GNNs) are an emerging class of machine learning models which utilize structured graph information and node features to reduce high-dimensional input data to low-dimensional embeddings, from which predictions can be made. Due to the compounding effect of aggregating neighbor information, GNN inferences require raw data from many times more nodes than are targeted for prediction. Thus, on heterogeneous compute platforms, inference latency can be largely subject to the inter-device communication cost of transferring input feature data to the GPU/accelerator before computation has even begun. In this paper, we analyze the trade-off effect of pruning input features from GNN models, reducing the volume of raw data that the model works with to lower communication latency at the expense of an expected decrease in the overall model accuracy. We develop greedy and regression-based algorithms to determine which features to retain for optimal prediction accuracy. We evaluate pruned model variants and find that they can reduce inference latency by up to 80% with an accuracy loss of less than 5% compared to non-pruned models. Furthermore, we show that the latency reductions from input feature pruning can be extended under different system variables such as batch size and floating point precision.
C1 [Yik, Jason] Harvard Univ, Cambridge, MA 02138 USA.
   [Kuppannagari, Sanmukh R.] Case Western Reserve Univ, Cleveland, OH 44106 USA.
   [Zeng, Hanqing] Meta AI, New York, NY USA.
   [Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90007 USA.
RP Yik, J (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM jyik@g.harvard.edu; sanmukh.kuppannagari@case.edu; zengh@meta.com;
   prasanna@usc.edu
CR Bahri M., 2021, BINARY GRAPH NEURAL
   Blalock D, 2020, ARXIV200303033, DOI DOI 10.1109/CVPR.2019.01152
   Brennan J., 2020, NOT HALF BAD EXPLORI, P2725
   Derrow-pinion Austin, 2021, CIKM '21: Proceedings of the 30th ACM International Conference on Information & Knowledge Management, P3767, DOI 10.1145/3459637.3481916
   Fey M., ARXIV190302428, V2019
   Halpern M, 2019, INT SYM PERFORM ANAL, P34, DOI 10.1109/ISPASS.2019.00012
   Hamilton WL, 2017, ADV NEUR IN, V30
   Hennessy J. L., 2011, COMPUTER ARCHITECTUR
   Hu WH, 2021, Arxiv, DOI arXiv:2005.00687
   Liu X., 2022, ARXIV
   Liu Z., 2020, HETEROGENEOUS GRAPH
   Nagel M, 2019, Arxiv, DOI arXiv:1906.04721
   Pal A, 2020, KDD '20: PROCEEDINGS OF THE 26TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P2311, DOI 10.1145/3394486.3403280
   Romero F, 2021, PROCEEDINGS OF THE 2021 USENIX ANNUAL TECHNICAL CONFERENCE, P397
   Tailor S. A., 2021, DEGREE QUANT QUANTIZ
   Velickovi P., 2018, GRAPH ATTENTION NETW
   Welling M., 2016, INT C LEARNING REPRE, DOI DOI 10.48550/ARXIV.1609.02907
   Wu F, 2019, PR MACH LEARN RES, V97
   Xu K., 2018, INT C LEARN REPR ICL, DOI DOI 10.48550/ARXIV.1810.00826
   Yan MY, 2020, INT S HIGH PERF COMP, P15, DOI 10.1109/HPCA47549.2020.00012
   Zeng H., 2021, 35 C NEURAL INFORM P
   Zeng HQ, 2020, Arxiv, DOI arXiv:1907.04931
   Zhang BY, 2020, ANN IEEE SYM FIELD P, P241, DOI 10.1109/FCCM48280.2020.00074
   Zhang Jeff, 2020, 12 USENIX WORKSH HOT
   Zhou HK, 2021, PROC VLDB ENDOW, V14, P1597, DOI 10.14778/3461535.3461547
   Zhu R, 2019, PROC VLDB ENDOW, V12, P2094, DOI 10.14778/3352063.3352127
NR 26
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 282
EP 291
DI 10.1109/HiPC56025.2022.00045
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Agrawal, A
   Jaiswal, A
   Roy, D
   Han, B
   Srinivasan, G
   Ankit, A
   Roy, K
AF Agrawal, Amogh
   Jaiswal, Akhilesh
   Roy, Deboleena
   Han, Bing
   Srinivasan, Gopalakrishnan
   Ankit, Aayush
   Roy, Kaushik
TI Xcel-RAM: Accelerating Binary Neural Networks in High-Throughput SRAM
   Compute Arrays
SO IEEE TRANSACTIONS ON CIRCUITS AND SYSTEMS I-REGULAR PAPERS
DT Article
DE In-memory computing; SRAM; binary convolution; binary neural networks;
   deep-CNNs
ID MEMORY
AB Deep neural networks are biologically inspired class of algorithms that have recently demonstrated the state-of-the-art accuracy in large-scale classification and recognition tasks. Hardware acceleration of deep networks is of paramount importance to ensure their ubiquitous presence in future computing platforms. Indeed, a major landmark that enables efficient hardware accelerators for deep networks is the recent advances from the machine learning community that have demonstrated the viability of aggressively scaled deep binary networks. In this paper, we demonstrate how deep binary networks can be accelerated in modified von Neumann machines by enabling binary convolutions within the static random access memory (SRAM) arrays. In general, binary convolutions consist of bit-wise exclusive-NOR (XNOR) operations followed by a population count (popcount). We present two proposals: one based on charge sharing approach to perform vector XNOR and approximate popcount and another based on bit-wise XNOR followed by a digital bit-tree adder for accurate popcount. We highlight the various tradeoffs in terms of circuit complexity, speed-up, and classification accuracy for both the approaches. Few key techniques presented as a part of the manuscript are the use of low-precision, low-overhead analog-todigital converter (ADC), to achieve a fairly accurate popcount for the charge-sharing scheme and proposal for sectioning of the SRAM array by adding switches onto the read-bitlines, thereby achieving improved parallelism. Our results on benchmark image classification datasets for CIFAR-10 and SVHN on a binarized neural network architecture show energy improvements of up to 6.1x and 2.3x for the two proposals, compared to conventional SRAM banks. In terms of latency, improvements of up to 15.8x and 8.1x were achieved for the two respective proposals.
C1 [Agrawal, Amogh; Jaiswal, Akhilesh; Roy, Deboleena; Han, Bing; Srinivasan, Gopalakrishnan; Ankit, Aayush; Roy, Kaushik] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
RP Agrawal, A (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47907 USA.
EM agrawa64@purdue.edu
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   Ankit A., 2017, PROC 54 ACMEDACIEEE, P1
   [Anonymous], 2016, BINARIZED NEURAL NET
   [Anonymous], IEEE T COMPUT
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2016, PREDICTIVE TECHNOLOG
   [Anonymous], 2017, 2017 S VLSI CIRC
   [Anonymous], BINARYNET PYTORCH
   [Anonymous], NEURAL CACHE BIT SER
   [Anonymous], IEEE T CIRCUITS SY 1
   [Anonymous], ADV NEURAL INFORM PR
   [Anonymous], P NIPS AUT WORKSH OC
   [Anonymous], 2011, VARIABILITY RESISTIV, DOI DOI 10.1109/IRPS.2011.5784590
   [Anonymous], ANALOGTODIGITAL CONV
   BACKUS J, 1978, COMMUN ACM, V21, P613, DOI 10.1145/359576.359579
   Bengio Y, 2009, FOUND TRENDS MACH LE, V2, P1, DOI 10.1561/2200000006
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chatterjee N, 2017, INT S HIGH PERF COMP, P73, DOI 10.1109/HPCA.2017.58
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chu P. P., 2011, EMBEDDED SOPC DESIGN, P179
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Jain S, 2018, IEEE T VLSI SYST, V26, P470, DOI 10.1109/TVLSI.2017.2776954
   Jaiswal A., 2018, 8T SRAM CELL MULTIBI
   Jeloka S, 2016, IEEE J SOLID-ST CIRC, V51, P1009, DOI 10.1109/JSSC.2016.2515510
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Jones N, 2014, NATURE, V505, P146, DOI 10.1038/505146a
   Krizhevsky Alex, 2022, LEARNING MULTIPLE LA
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Schneider ML, 2018, SCI ADV, V4, DOI 10.1126/sciadv.1701329
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Srinivasan G, 2017, DES AUT TEST EUROPE, P530, DOI 10.23919/DATE.2017.7927045
   Srinivasan G, 2016, SCI REP-UK, V6, DOI 10.1038/srep29545
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Yuval N., 2011, NIPS WORKSH DEEP LEA
NR 37
TC 61
Z9 62
U1 1
U2 14
PD AUG
PY 2019
VL 66
IS 8
BP 3064
EP 3076
DI 10.1109/TCSI.2019.2907488
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU de Oliveira, LA
   Barros, E
AF de Oliveira Junior, Luiz Antonio
   Barros, Edna
GP IEEE
TI An FPGA-based Hardware Accelerator for Scene Text Character Recognition
SO PROCEEDINGS OF THE 2018 26TH IFIP/IEEE INTERNATIONAL CONFERENCE ON VERY
   LARGE SCALE INTEGRATION (VLSI-SOC)
SE IEEE-IFIP International Conference on VLSI and System-on-Chip
DT Proceedings Paper
CT 26th IFIP/IEEE International Conference on Very Large Scale Integration
   (VLSI-SoC)
CY OCT 08-10, 2018
CL Verona, ITALY
DE Character Recognition; FPGA; HOG; ELM; Computer Vision
AB Scene text character recognition is a challenging task in Computer Vision since natural scene images usually have cluttered background and the character's size, font, orientation, texture, brightness, and alignment in the picture are variable and non-predictable. Furthermore, most systems including scene text character recognition are usually embedded in a system on a chip (SoC), which has critical requirements, such as low latency, low area, mobility, and flexibility, at the same time that they require high accuracy. In this context, in this work we propose a heterogeneous system for embedded applications with time, area and power constraints, that combines hardware and software to accelerate a technique for scene text character recognition, based on Histogram of Oriented Gradients (HOG) for feature extraction and a neural network Extreme Learning Machine (ELM) as a classifier. The system was prototyped and experimented in the Terasic embedded platform DE2i-150 and the results showed that the system has accuracy of 65.5% in the Chars74k-15 dataset and is able to process up to 11 frames per second, having a good trade-off between processing time and accuracy in embedded environments. Moreover, it occupies only 11% logic elements of the Altera Cyclone IV FPGA, enabling its use in embedded systems.
C1 [de Oliveira Junior, Luiz Antonio; Barros, Edna] Univ Fed Pernambuco, Ctr Informat, Recife, PE, Brazil.
RP de Oliveira, LA (corresponding author), Univ Fed Pernambuco, Ctr Informat, Recife, PE, Brazil.
EM laoj2@cin.ufpe.br; ensb@cin.ufpe.br
CR Aggravi M, 2015, AMBIENT ASSISTED LIVING: ITALIAN FORUM 2014, P487, DOI 10.1007/978-3-319-18374-9_45
   Ali Muhammad, 2015, 10th International Conference on Computer Vision Theory and Applications (VISAPP 2015). Proceedings, P368
   [Anonymous], 2005, PROC CVPR IEEE
   Chongmu Chen, 2015, Image and Graphics. 8th International Conference, ICIG 2015. Proceedings: LNCS 9219, P310, DOI 10.1007/978-3-319-21969-1_27
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Graham S. L., 1982, SIGPLAN Notices, V17, P120, DOI 10.1145/872726.806987
   Huang GB, 2006, NEUROCOMPUTING, V70, P489, DOI 10.1016/j.neucom.2005.12.126
   Jacobsen M, 2015, ACM T RECONFIG TECHN, V8, DOI 10.1145/2815631
   KEYS RG, 1981, IEEE T ACOUST SPEECH, V29, P1153, DOI 10.1109/TASSP.1981.1163711
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Rong X., 2016, EUR C COMP VIS, P1
   Sanni Kayode, 2015, 2015 49 ANN C INF SC, P1, DOI [DOI 10.1109/CISS.2015.7086904, 10.1109/CISS.2015.7086904]
   Shi CZ, 2017, PATTERN RECOGN, V72, P1, DOI 10.1016/j.patcog.2017.06.022
   Shi CZ, 2014, PATTERN RECOGN, V47, P2853, DOI 10.1016/j.patcog.2014.03.023
   Yi CC, 2014, IEEE T IMAGE PROCESS, V23, P2972, DOI 10.1109/TIP.2014.2317980
   Zhang C, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P35, DOI 10.1145/3020078.3021727
   Zhang Z, 2018, IEEE ACCESS, V6, P16454, DOI 10.1109/ACCESS.2018.2817342
   Zho H, 2016, 2016 IEEE INTERNATIONAL CONFERENCE ON SIGNAL AND IMAGE PROCESSING (ICSIP), P539, DOI 10.1109/SIPROCESS.2016.7888320
NR 19
TC 0
Z9 0
U1 0
U2 2
PY 2018
BP 125
EP 130
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Largent, A
   Nunes, JC
   Saint-Jalmes, H
   Simon, A
   Perichon, N
   Barateau, A
   Hervé, C
   Lafond, C
   Greer, PB
   Dowling, JA
   de Crevoisier, R
   Acosta, O
AF Largent, Axel
   Nunes, Jean-Claude
   Saint-Jalmes, Herve
   Simon, Antoine
   Perichon, Nicolas
   Barateau, Anais
   Herve, Chloe
   Lafond, Caroline
   Greer, Peter B.
   Dowling, Jason A.
   de Crevoisier, Renaud
   Acosta, Oscar
GP IEEE
TI Pseudo-CT Generation by Conditional Inference Random Forest for
   MRI-based Radiotherapy Treatment Planning
SO 2017 25TH EUROPEAN SIGNAL PROCESSING CONFERENCE (EUSIPCO)
SE European Signal Processing Conference
DT Proceedings Paper
CT 25th European Signal Processing Conference (EUSIPCO)
CY AUG 28-SEP 02, 2017
CL GREECE
DE Pseudo-CT; Radiotherapy; Magnetic Resonance Imaging; Treatment planning;
   Random Forest
ID PROSTATE RADIATION-THERAPY; REGISTRATION; TOMOGRAPHY; SEQUENCES
AB Dose calculation from MRI is a topical issue. New treatment systems combining a linear accelerator with a MRI have been recently being developed. MRI has good soft tissue contrast without ionizing radiation exposure. However, unlike CT, MRI does not provide electron density information necessary for dose calculation. We propose in this paper a machine learning method to simulate a CT from a target MRI and co-registered CT-MRI training set. Ten prostate MR and CT images have been considered. Firstly, a reference image was randomly selected in the training set. A common space has been built thanks to affine registrations between the training set and the reference image. Multiscale image descriptors such as spatial information, gradients and texture features were extracted from MRI patches at different levels of a Gaussian pyramid and used as voxel-wise characteristics in the learning scheme. A Conditional Inference Random Forest (CIRF) modelled the relation between MRI descriptors and CT patches. For validation, test images were spatially normalized and the same descriptors were computed to generate a new pCT. Leave-one out experiments were performed. We obtained a MAE = 45.79 (pCT vs CT). Dose volume histograms inside PTV and organs at risk are in close agreement. The D98% was 0.45 % (inside PTV) and the 3D gamma pass rate (1mm, 1%) was 99,2%. Our method has better results than direct bulk assignment. And the results suggest that the method may be used for dose calculations in an MR based planning system.
C1 [Largent, Axel; Nunes, Jean-Claude; Saint-Jalmes, Herve; Simon, Antoine; Barateau, Anais; Lafond, Caroline; de Crevoisier, Renaud; Acosta, Oscar] Lab Signal & Image Proc LTSI, Rennes, France.
   [Largent, Axel; Nunes, Jean-Claude; Saint-Jalmes, Herve; Simon, Antoine; Barateau, Anais; Lafond, Caroline; de Crevoisier, Renaud; Acosta, Oscar] INSERM, UMR 1099, Rennes, France.
   [Perichon, Nicolas; Herve, Chloe; Lafond, Caroline; de Crevoisier, Renaud] Ctr Eugene Marquis, Dept Radiotherapy, Rennes, France.
   [Saint-Jalmes, Herve] Ctr Eugene Marquis, Imagery Dept, Rennes, France.
   [Greer, Peter B.] Univ Newcastle, Sch Math & Phys Sci, Newcastle, NSW, Australia.
   [Dowling, Jason A.] CSIRO Australian E Hlth Res Ctr, Herston, Qld, Australia.
RP Nunes, JC (corresponding author), Lab Signal & Image Proc LTSI, Rennes, France.; Nunes, JC (corresponding author), INSERM, UMR 1099, Rennes, France.
EM jean-claude.nunes@univ-rennes1.fr
CR Burgos N, 2015, LECT NOTES COMPUT SC, V9350, P476, DOI 10.1007/978-3-319-24571-3_57
   Demol B, 2016, MED PHYS, V43, P6557, DOI 10.1118/1.4967480
   Demol B, 2015, J APPL CLIN MED PHYS, V16, P117, DOI 10.1120/jacmp.v16i5.5586
   Dowling JA, 2015, INT J RADIAT ONCOL, V93, P1144, DOI 10.1016/j.ijrobp.2015.08.045
   Dowling JA, 2012, INT J RADIAT ONCOL, V83, pE5, DOI 10.1016/j.ijrobp.2011.11.056
   Hoogcarspel SJ, 2014, PHYS MED BIOL, V59, P7383, DOI 10.1088/0031-9155/59/23/7383
   Johanson A, 2013, ACTA ONCOL, V52, P1369, DOI 10.3109/0284186X.2013.819119
   Johansson A, 2011, MED PHYS, V38, P2708, DOI 10.1118/1.3578928
   Kapanen M, 2013, ACTA ONCOL, V52, P612, DOI 10.3109/0284186X.2012.692883
   Korhonen J, 2014, MED PHYS, V41, DOI 10.1118/1.4842575
   Lagendijk JJW, 2008, RADIOTHER ONCOL, V86, P25, DOI 10.1016/j.radonc.2007.10.034
   Lambert J, 2011, RADIOTHER ONCOL, V98, P330, DOI 10.1016/j.radonc.2011.01.012
   Lee YK, 2003, RADIOTHER ONCOL, V66, P203, DOI 10.1016/S0167-8140(02)00440-1
   Low DA, 1998, MED PHYS, V25, P656, DOI 10.1118/1.598248
   Rivest-Henault D., 2013, CLIN IMAGE BASED PRO, P65
   Rivest-Henault D, 2015, MED IMAGE ANAL, V23, P56, DOI 10.1016/j.media.2015.04.014
   Huynh T, 2016, IEEE T MED IMAGING, V35, P174, DOI 10.1109/TMI.2015.2461533
   Wang ZH, 2013, LECT NOTES COMPUT SC, V8184, P98, DOI 10.1007/978-3-319-02267-3_13
   Wendling M, 2007, MED PHYS, V34, P1647, DOI 10.1118/1.2721657
NR 19
TC 9
Z9 10
U1 0
U2 1
PY 2017
BP 46
EP 50
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT J
AU Sze, V
   Chen, YH
   Yang, TJ
   Emer, JS
AF Sze, Vivienne
   Chen, Yu-Hsin
   Yang, Tien-Ju
   Emer, Joel S.
TI Efficient Processing of Deep Neural Networks: A Tutorial and Survey
SO PROCEEDINGS OF THE IEEE
DT Article
DE ASIC; computer architecture; convolutional neural networks; dataflow
   processing; deep learning; deep neural networks; energy-efficient
   accelerators; low power; machine learning; spatial architectures; VLSI
ID COPROCESSOR; OBJECT
AB Deep neural networks (DNNs) are currently widely used for many artificial intelligence (AI) applications including computer vision, speech recognition, and robotics. While DNNs deliver state-of-the-art accuracy on many AI tasks, it comes at the cost of high computational complexity. Accordingly, techniques that enable efficient processing of DNNs to improve energy efficiency and throughput without sacrificing application accuracy or increasing hardware cost are critical to the wide deployment of DNNs in AI systems. This article aims to provide a comprehensive tutorial and survey about the recent advances toward the goal of enabling efficient processing of DNNs. Specifically, it will provide an overview of DNNs, discuss various hardware platforms and architectures that support DNNs, and highlight key trends in reducing the computation cost of DNNs either solely via hardware design changes or via joint hardware design and DNN algorithm changes. It will also summarize various development resources that enable researchers and practitioners to quickly get started in this field, and highlight important benchmarking metrics and design considerations that should be used for evaluating the rapidly growing number of DNN hardware designs, optionally including algorithmic codesigns, being proposed in academia and industry. The reader will take away the following concepts from this article: understand the key design considerations for DNNs; be able to evaluate different DNN hardware implementations with benchmarks and comparison metrics; understand the tradeoffs between various hardware architectures and platforms; be able to evaluate the utility of various DNN design techniques for efficient processing; and understand recent implementation trends and opportunities.
C1 [Sze, Vivienne; Chen, Yu-Hsin; Yang, Tien-Ju; Emer, Joel S.] MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
   [Emer, Joel S.] Nvidia Corp, Westford, MA 01886 USA.
RP Sze, V (corresponding author), MIT, Dept Elect Engn & Comp Sci, Cambridge, MA 02139 USA.
EM sze@mit.edu; yhchen@mit.edu; tjy@mit.edu; jsemer@mit.edu
CR Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alipanahi B, 2015, NAT BIOTECHNOL, V33, P831, DOI 10.1038/nbt.3300
   Alwani M., 2016, MICROPAGE, P1
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2016, COMPLETE VISUAL NETW
   [Anonymous], 2015, BIOMED RES INT, DOI DOI 10.1111/PPL.12281
   [Anonymous], 2016, P ICLR
   [Anonymous], 2017, P 22 INT C ARCHITECT
   [Anonymous], 2012, P 2012 7 INT FOR STR, DOI [10.1109/IFOST.2012.6357669, DOI 10.1109/IFOST.2012.6357669]
   [Anonymous], 2017, INTEL ARCHITECTURE I
   [Anonymous], 2016, TUTORIAL EMERGING ME
   [Anonymous], 2017, P CVPR
   [Anonymous], 2015, P ICLR
   [Anonymous], 2017, P ICLR
   Anwar S, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005348
   Ba LJ, 2014, ADV NEURAL INFORM PR, V3, P2654, DOI DOI 10.5555/2969033.2969123
   BAILEY DH, 1991, J SUPERCOMPUT, V4, P357, DOI 10.1007/BF00129836
   Benini L., 2015, P 25 EDITION GREAT L, P199, DOI DOI 10.1145/2742060.2743766
   Bucila C., 2006, P 12 ACM SIGKDD INT, DOI [DOI 10.1145/1150402.1150464, 10.1145/1150402.1150464]
   Cai ZW, 2017, PROC CVPR IEEE, P5406, DOI 10.1109/CVPR.2017.574
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   Chen CY, 2015, IEEE I CONF COMP VIS, P2722, DOI 10.1109/ICCV.2015.312
   Chen HG, 2016, PROC CVPR IEEE, P903, DOI 10.1109/CVPR.2016.104
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen WL, 2015, PR MACH LEARN RES, V37, P2285
   Chen YH, 2017, IEEE MICRO, V37, P12, DOI 10.1109/MM.2017.54
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chollet F, 2017, PROC CVPR IEEE, P1800, DOI 10.1109/CVPR.2017.195
   CHUA LO, 1971, IEEE T CIRCUITS SYST, VCT18, P507, DOI 10.1109/TCT.1971.1083337
   Clevert D.-A., 2016, PROC INT C LEARN REP, P1
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Condon S., 2017, P ZDNET MAR
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Courbariaux M., 2015, ADV NEURAL INFORM PR, V28, P3123, DOI [DOI 10.5555/2969442.2969588, DOI 10.1109/TWC.2016.2633262]
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Dally W.J., 2015, ADV NEURAL INFORM PR, P1135
   Deng L, 2013, INT CONF ACOUST SPEE, P8604, DOI 10.1109/ICASSP.2013.6639345
   Denton Emily L, 2014, ADV NEURAL INFORM PR, DOI DOI 10.5555/2968826.2968968
   Dorrance Richard, 2014, PROC ISFPGA, P161
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Dubout C, 2012, LECT NOTES COMPUT SC, V7574, P301, DOI 10.1007/978-3-642-33712-3_22
   Eryilmaz SB, 2016, INT SYM QUAL ELECT, P118
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Esteva A, 2017, NATURE, V542, P115, DOI 10.1038/nature21056
   Girshick R., 2014, P 2014 IEEE C COMP V, P580, DOI DOI 10.1109/CVPR.2014.81
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Graham B., 2014, CORR
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Gysel P., 2016, P ICLR
   Han S., 2016, INT C LEARN REPR ICL
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He KM, 2015, IEEE I CONF COMP VIS, P1026, DOI 10.1109/ICCV.2015.123
   Hemsoth N., 2016, TECH REP
   Higginbotham S., 2016, GOOGLE TAKES UNCONVE
   Hinton G., 2015, NIPS WORKSH, P1
   Hinton G, 2012, IEEE SIGNAL PROC MAG, V29, P82, DOI 10.1109/MSP.2012.2205597
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Howard AG., 2017, MOBILENETS EFFICIENT
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107
   Ioffe S., 2015, ICML, DOI DOI 10.1007/S13398-014-0173-7.2
   Jeddeloh J., 2012, 2012 S VLSI TECHN VL, P87
   Jermyn M, 2016, J BIOMED OPT, V21, DOI 10.1117/1.JBO.21.9.094002
   Jia YQ, 2014, PROCEEDINGS OF THE 2014 ACM CONFERENCE ON MULTIMEDIA (MM'14), P675, DOI 10.1145/2647868.2654889
   Kaelbling LP, 1996, J ARTIF INTELL RES, V4, P237, DOI 10.1613/jair.301
   Keitel-Schulz D, 2001, IEEE DES TEST COMPUT, V18, P7, DOI 10.1109/54.922799
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2010, CONVOLUTIONAL DEEP B, V40, P1, DOI DOI 10.1145/3065386
   Krizhevsky A., THE CIFAR 10 DATASET
   Lavin A, 2016, PROC CVPR IEEE, P4013, DOI 10.1109/CVPR.2016.435
   LECUN Y, 1989, IEEE COMMUN MAG, V27, P41, DOI 10.1109/35.41400
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   Lee EH, 2017, INT CONF ACOUST SPEE, P5900, DOI 10.1109/ICASSP.2017.7953288
   Lee EH, 2016, ISSCC DIG TECH PAP I, V59, P418, DOI 10.1109/ISSCC.2016.7418085
   Levine S, 2016, J MACH LEARN RES, V17
   Li F.-F., STANFORD CS CLASS CS
   [李凡杰 Li Fanjie], 2016, [低温工程, Cryogenics], P1
   LikamWa R, 2016, CONF PROC INT SYMP C, P255, DOI 10.1109/ISCA.2016.31
   Lim J.S., 1990, 2 DIMENSIONAL SIGNAL, P710
   Lin M, 2014, 2014 INTERNATIONAL CONFERENCE ON MEDICAL BIOMETRICS (ICMB 2014), P1, DOI 10.1109/ICMB.2014.8
   Long J, 2015, PROC CVPR IEEE, P3431, DOI 10.1109/CVPR.2015.7298965
   Ma YF, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577356
   Maas AL, 2013, RECTIFIER NONLINEARI, DOI DOI 10.1016/0010-0277(84)90022-2
   Mao Huizi, 2017, IEEE C COMP VIS PATT
   Mathieu M., 2014, P ICLR
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Miyashita D., 2016, ARXIV160301025
   Mnih V., 2013, ARXIV, DOI DOI 10.1038/NATURE14236
   Moons B, 2016, SYMP VLSI CIRCUITS
   Morgan T.P, 2016, NVIDIA PUSHES DEEP L
   Nair V., 2010, ICML, P807
   Oord A. V. D., 2016, ARXIV
   Parashar Angshuman, 2017, ACM SIGARCH Computer Architecture News, V45, P27, DOI 10.1145/3140659.3080254
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Pfeiffer Mark, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P1527, DOI 10.1109/ICRA.2017.7989182
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Romero A., 2015, ICLR, P1
   Rusk N, 2016, NAT METHODS, V13, P35, DOI 10.1038/nmeth.3707
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Sainath TN, 2013, INT CONF ACOUST SPEE, P8614, DOI 10.1109/ICASSP.2013.6639347
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Sermanet P., 2014, INT C LEARN REPR ICL, DOI DOI 10.1016/J.NEUNET.2012.02.016
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shalev-Shwartz S., 2016, P NIPS WORKSH LEARN
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K., 2014, ADV NEURAL INFORM PR, P568, DOI DOI 10.1002/14651858.CD001941.PUB3
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Sriram V., 2010, Proceedings 2010 International Conference on Field-Programmable Technology (FPT 2010), P273, DOI 10.1109/FPT.2010.5681487
   Standard J., 2013, P JESD
   Suleiman A, 2014, IEEE WRK SIG PRO SYS, P256
   Sze V., 2014, INTEGRATED CIRCUIT S, V39, P49, DOI DOI 10.1007/978-3-319-06895-4
   Szegedy C., 2017, P 31 AAAI C ART INT, DOI DOI 10.1609/AAAI.V31I1.11231
   SZEGEDY C, 2016, PROC CVPR IEEE, P2818, DOI DOI 10.1109/CVPR.2016.308
   Szegedy C, 2014, Arxiv, DOI [arXiv:1312.6199, DOI 10.1109/CVPR.2015.7298594]
   Torralba A, 2008, IEEE T PATTERN ANAL, V30, P1958, DOI 10.1109/TPAMI.2008.128
   Urban G., 2017, INT C LEARN REPR ICL
   Wan L., 2013, P 30 INT C MACH LEAR, V28, P1058
   Wang D, 2016, ARXIV160605718, P1
   Wen W., 2016, ADV NEURAL INFORM PR, P2082, DOI DOI 10.1016/J.CCR.2008.06.009
   Widrow B, 2005, IEEE SIGNAL PROC MAG, V22, P100, DOI 10.1109/MSP.2005.1407720
   Widrow B., 1960, P IRE WESCON CONV RE
   Wilson L., 2013, P SEM IND ASS
   Woodhouse J., 2016, BIG BIG BIG DATA HIG
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xiaohui Zhang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P215, DOI 10.1109/ICASSP.2014.6853589
   Xiong HY, 2015, SCIENCE, V347, DOI 10.1126/science.1254806
   Yang T.-J., 2017, P CVPR
   Yann C.J.B., MNIST DATABASE HANDW
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zeng HY, 2016, BIOINFORMATICS, V32, P121, DOI 10.1093/bioinformatics/btw255
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang J., 2015, IEEE ISSCC, P27
   Zhang JX, 2016, OXID MED CELL LONGEV, V2016, DOI 10.1155/2016/4350965
   Zhang TH, 2016, IEEE INT CONF ROBOT, P528, DOI 10.1109/ICRA.2016.7487175
   Zhang Y, 2016, INTERSPEECH, P410, DOI 10.21437/Interspeech.2016-1446
   Zhou A., 2017, P ICLR
   Zhou J, 2015, NAT METHODS, V12, P931, DOI [10.1038/NMETH.3547, 10.1038/nmeth.3547]
   Zhou S., 2016, ARXIV160606160
   Zhu C., 2017, 5 INT C LEARN REPR I
   Zhuo Wang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P3884, DOI 10.1109/ICASSP.2014.6854329
NR 150
TC 1773
Z9 1884
U1 59
U2 548
PD DEC
PY 2017
VL 105
IS 12
BP 2295
EP 2329
DI 10.1109/JPROC.2017.2761740
WC Engineering, Electrical & Electronic
HC Y
HP N
DA 2023-11-11
ER

PT C
AU James, M
   Tom, M
   Groeneveld, P
   Kibardin, V
AF James, Michael
   Tom, Marvin
   Groeneveld, Patrick
   Kibardin, Vladimir
GP ACM
TI ISPD 2020 Physical Mapping of Neural Networks on a Wafer-Scale Deep
   Learning Accelerator
SO PROCEEDINGS OF THE 2020 INTERNATIONAL SYMPOSIUM ON PHYSICAL DESIGN
   (ISPD'20)
DT Proceedings Paper
CT ACM International Symposium on Physical Design (ISPD)
CY MAR 29-APR 01, 2020
CL Taipei, TAIWAN
DE Machine Learning; Physical Design; Floorplanning; Training of Neural
   Networks; Wafer-Scale Circuits
AB This paper introduces a special case of the floorplanning problem for optimizing neural networks to run on a wafer-scale computing engine. From a compute perspective, neural networks can be represented by a deeply layered structure of compute kernels. During the training of a neural network, gradient descent is used to determine the weight factors. Each layer then uses a local weight tensor to transform "activations" and "gradients" that are shared among connected kernels according to the topology of the network. This process is computationally intensive and requires high memory and communication bandwidth. Cerebras has developed a novel computer system designed for this work that is powered by a 21.5cm by 21.5cm wafer-scale processor with 400,000 programmable compute cores. It is structured as a regular array of 633 by 633 processing elements, each with its own local high bandwidth SRAM memory and direct high bandwidth connection to its neighboring cores. In addition to supporting traditional execution models for neural network training and inference, this engine has a unique capability to compile and compute every layer of a complete neural network simultaneously. Mapping a neural network in this fashion onto Cerebras' Wafer-Scale Engine (WSE) is reminiscent of the traditional floorplanning problem in physical design. A kernel ends up as a rectangle of x by y compute elements. These are the flexible blocks that need to be placed to optimize performance. This paper describes an ISPD 2020 challenge to develop algorithms and heuristics that produce compiled neural networks that achieve the highest possible performance on the Cerebras WSE.
C1 [James, Michael; Tom, Marvin; Groeneveld, Patrick; Kibardin, Vladimir] Cerebras Syst, Los Altos, CA 94022 USA.
RP James, M (corresponding author), Cerebras Syst, Los Altos, CA 94022 USA.
EM michael@cerebras.net; marvin@cerebras.net; patrick@cerebras.net;
   vladimir@cerebras.net
CR Amodei Dario, 2018, AI AND COMPUTE
   [Anonymous], 1988, SIMULATED ANNEALING
   Fricker J. P., 2019, BUILDING WAFER SCALE
   He J K., 2015, DEEP RESIDUAL LEARNI
   James M., 2020, ISPD 20202 CONTEST W
   KIRKPATRICK S, 1983, SCIENCE, V220, P671, DOI 10.1126/science.220.4598.671
   Otten R. H. J. M., 1982, ACM IEEE Nineteenth Design Automation Conference Proceedings, P261
   Silver D., 2017, MASTERING CHESS SHOG
   Strubell E, 2019, 57TH ANNUAL MEETING OF THE ASSOCIATION FOR COMPUTATIONAL LINGUISTICS (ACL 2019), P3645
NR 9
TC 13
Z9 14
U1 0
U2 0
PY 2020
BP 145
EP 149
DI 10.1145/3372780.3380846
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Shah, N
   Chaudhari, P
   Varghese, K
AF Shah, Nimish
   Chaudhari, Paragkumar
   Varghese, Kuruvilla
TI Runtime Programmable and Memory Bandwidth Optimized FPGA-Based
   Coprocessor for Deep Convolutional Neural Network
SO IEEE TRANSACTIONS ON NEURAL NETWORKS AND LEARNING SYSTEMS
DT Article
DE Accelerator; coprocessor; deep convolutional neural network (DCNN); deep
   learning; field-programmable gate array (FPGA); runtime programmable
AB The deep convolutional neural network (DCNN) is a class of machine learning algorithms based on feed-forward artificial neural network and is widely used for image processing applications. Implementation of DCNN in real-world problems needs high computational power and high memory bandwidth, in a power-constrained environment. A general purpose CPU cannot exploit different parallelisms offered by these algorithms and hence is slow and energy inefficient for practical use. We propose a field-programmable gate array (FPGA)-based runtime programmable coprocessor to accelerate feed-forward computation of DCNNs. The coprocessor can be programmed for a new network architecture at runtime without resynthesizing the FPGA hardware. Hence, it acts as a plug-and-use peripheral for the host computer. Caching is implemented for input features and filter weights using on-chip memory to reduce the external memory bandwidth requirement. Data are prefetched at several stages to avoid stalling of computational units and different optimization techniques are used to efficiently reuse the fetched data. Dataflow is dynamically adjusted in runtime for each DCNN layer to achieve consistent computational throughput across a wide range of input feature sizes and filter sizes. The coprocessor is prototyped using Xilinx Virtex-7 XC7VX485T FPGA-based VC707 board and operates at 150 MHz. Experimental results show that our implementation is 15x energy efficient than highly optimized CPU implementation and achieves consistent computational throughput of more than 140 G operations/s for a wide range of input feature sizes and filter sizes. Off-chip memory transactions decrease by 111x due to the use of the on-chip cache.
C1 [Shah, Nimish; Chaudhari, Paragkumar; Varghese, Kuruvilla] Indian Inst Sci, Dept Elect Syst Engn, Bangalore, Karnataka, India.
RP Varghese, K (corresponding author), Indian Inst Sci, Dept Elect Syst Engn, Bangalore, Karnataka, India.
EM snimish@dese.iisc.ernet.in; parag@dese.iisc.ernet.in; kuru@iisc.ac.in
CR Alain G., 2016, THEANO PYTHON FRAMEW
   Ayer J., 2009, XAPP1022 XIL
   Chakradhar S, 2010, CONF PROC INT SYMP C, P247, DOI 10.1145/1816038.1815993
   CHEN T, 2014, P 19 INT C ARCH SUPP, P269, DOI DOI 10.1145/2541940.2541967
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cong Jason, 2014, Artificial Neural Networks and Machine Learning - ICANN 2014. 24th International Conference on Artificial Neural Networks. Proceedings: LNCS 8681, P281, DOI 10.1007/978-3-319-11179-7_36
   Conti F, 2015, DES AUT TEST EUROPE, P683
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Dundar A, 2017, IEEE T NEUR NET LEAR, V28, P1572, DOI 10.1109/TNNLS.2016.2545298
   Farabet C, 2010, IEEE INT SYMP CIRC S, P257, DOI 10.1109/ISCAS.2010.5537908
   Gokhale V, 2014, IEEE COMPUT SOC CONF, P696, DOI 10.1109/CVPRW.2014.106
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Han XS, 2016, PR IEEE COMP DESIGN, P320, DOI 10.1109/ICCD.2016.7753296
   Jia Yangqing, 2014, ARXIV14085093, P675, DOI [DOI 10.1145/2647868.2654889, 10.1145/2647868.2654889]
   Jin JH, 2014, MIDWEST SYMP CIRCUIT, P133, DOI 10.1109/MWSCAS.2014.6908370
   Kim L.-W., IEEE T NEUR IN PRESS
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Lavin A., 2015, MAXDNN EFFICIENT CON
   Li HM, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577308
   Park J, 2017, IEEE T NEUR NET LEAR, V28, P2408, DOI 10.1109/TNNLS.2016.2572164
   Peemen M, 2013, 2013 IEEE 31ST INTERNATIONAL CONFERENCE ON COMPUTER DESIGN (ICCD), P13, DOI 10.1109/ICCD.2013.6657019
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Sankaradas M, 2009, IEEE INT CONF ASAP, P53, DOI 10.1109/ASAP.2009.25
   Scherer D, 2010, LECT NOTES COMPUT SC, V6354, P82, DOI 10.1007/978-3-642-15825-4_9
   Sim J, 2016, ISSCC DIG TECH PAP I, V59, P264, DOI 10.1109/ISSCC.2016.7418008
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Suda N, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P16, DOI 10.1145/2847263.2847276
   Vasilache Nicolas, 2014, ARXIV14127580
   Xilinx Inc, 2016, 7 SER DSP48E1 SLIC U
   Yadan O., 2013, MULTI GPU TRAINING C
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhou X., IEEE T NEUR IN PRESS
NR 35
TC 99
Z9 100
U1 3
U2 5
PD DEC
PY 2018
VL 29
IS 12
BP 5922
EP 5934
DI 10.1109/TNNLS.2018.2815085
WC Computer Science, Artificial Intelligence; Computer Science, Hardware &
   Architecture; Computer Science, Theory & Methods; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Loni, M
   Zoljodi, A
   Majd, A
   Ahn, BH
   Daneshtalab, M
   Sjödin, M
   Esmaeilzadeh, H
AF Loni, Mohammad
   Zoljodi, Ali
   Majd, Amin
   Ahn, Byung Hoon
   Daneshtalab, Masoud
   Sjodin, Mikael
   Esmaeilzadeh, Hadi
TI FastStereoNet: A Fast Neural Architecture Search for Improving the
   Inference of Disparity Estimation on Resource-Limited Platforms
SO IEEE TRANSACTIONS ON SYSTEMS MAN CYBERNETICS-SYSTEMS
DT Article
DE Disparity estimation; machine vision; neural architecture search;
   optimization; transfer learning
ID STEREO; VISION
AB Convolutional neural networks (CNNs) provide the best accuracy for disparity estimation. However, CNNs are computationally expensive, making them unfavorable for resource-limited devices with real-time constraints. Recent advances in neural architectures search (NAS) promise opportunities in automated optimization for disparity estimation. However, the main challenge of the NAS methods is the significant amount of computing time to explore a vast search space [e.g., 1.6x10(29)] and costly training candidates. To reduce the NAS computational demand, many proxy-based NAS methods have been proposed. Despite their success, most of them are designed for comparatively small-scale learning tasks. In this article, we propose a fast NAS method, called FastStereoNet, to enable resource-aware NAS within an intractably large search space. FastStereoNet automatically searches for hardware-friendly CNN architectures based on late acceptance hill climbing (LAHC), followed by simulated annealing (SA). FastStereoNet also employs a fine-tuning with a transferred weights mechanism to improve the convergence of the search process. The collection of these ideas provides competitive results in terms of search time and strikes a balance between accuracy and efficiency. Compared to the state of the art, FastStereoNet provides 5.25x reduction in search time and 44.4x reduction in model size. These benefits are attained while yielding a comparable accuracy that enables seamless deployment of disparity estimation on resource-limited devices. Finally, FastStereoNet significantly improves the perception quality of disparity estimation deployed on field-programmable gate array and Intel Neural Compute Stick 2 accelerator in a significantly less onerous manner.
C1 [Loni, Mohammad; Zoljodi, Ali; Daneshtalab, Masoud; Sjodin, Mikael] Malardalen Univ, Sch Innovat Design & Engn, S-72218 Vasteras, Sweden.
   [Majd, Amin] Arcada Univ Appl Sci, Dept Econ & Business Anal, Helsinki 00560, Finland.
   [Ahn, Byung Hoon; Esmaeilzadeh, Hadi] Univ Calif San Diego, Dept Comp Sci & Engn, Alternat Comp Technol Lab, La Jolla, CA 92093 USA.
   [Daneshtalab, Masoud] TalTech Univ, Dept Comp Syst, EE-19086 Tallinn, Estonia.
RP Loni, M (corresponding author), Malardalen Univ, Sch Innovat Design & Engn, S-72218 Vasteras, Sweden.
EM mohammad.loni@mdh.se; ali.zoljodi@mdh.se; amin.majd@arcada.fi;
   bhahn@eng.ucsd.edu; masoud.daneshtalab@mdh.se; mikael.sjodin@mdh.se;
   hadi@eng.ucsd.edu
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Ahlberg C, 2019, IEEE WINT CONF APPL, P1616, DOI 10.1109/WACV.2019.00177
   Ahn B. H., 2020, P MACHINE LEARNING S, V2, P44
   [Anonymous], 2018, IEEE ROBOT AUTOM LET
   Atienza R, 2018, IEEE INT CONF ROBOT, P3207
   Brock Andrew, 2018, P INT C LEARN REPR
   Burke EK, 2017, EUR J OPER RES, V258, P70, DOI 10.1016/j.ejor.2016.07.012
   Cai H., 2019, 7 INT C LEARN REPR I
   Cai H., 2019, ONCE FOR ALL TRAIN N
   Cai H., 2018, INT C MACH LEARN, P678
   Cai H, 2018, AAAI CONF ARTIF INTE, P2787
   Chang JR, 2018, PROC CVPR IEEE, P5410, DOI 10.1109/CVPR.2018.00567
   Chen Tianqi, 2016, P ICLR
   Collobert R., 2002, TECHNICAL REPORT
   Dong XY, 2022, IEEE T PATTERN ANAL, V44, P3634, DOI 10.1109/TPAMI.2021.3054824
   Dong XY, 2019, PROC CVPR IEEE, P1761, DOI 10.1109/CVPR.2019.00186
   Elsken T., 2017, ARXIV171104528
   Elsken T, 2019, J MACH LEARN RES, V20
   Geiger A, 2013, INT J ROBOT RES, V32, P1231, DOI 10.1177/0278364913491297
   Geiger A, 2011, LECT NOTES COMPUT SC, V6492, P25, DOI 10.1007/978-3-642-19315-6_3
   GRANVILLE V, 1994, IEEE T PATTERN ANAL, V16, P652, DOI 10.1109/34.295910
   Hsu C.-H, 2018, CORR
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jin S, 2010, IEEE T CIRC SYST VID, V20, P15, DOI 10.1109/TCSVT.2009.2026831
   Kendall A, 2017, IEEE I CONF COMP VIS, P66, DOI 10.1109/ICCV.2017.17
   Li J, 2015, IEEE T CYBERNETICS, V45, P2390, DOI 10.1109/TCYB.2014.2371918
   Li X, 2019, PROC CVPR IEEE, P9137, DOI 10.1109/CVPR.2019.00936
   Libutti L. A., 2020, PROC 2NDWORKSHOP ACC
   Liu C, 2019, IEEE T CYBERNETICS, V49, P3665, DOI 10.1109/TCYB.2018.2846361
   Liu CX, 2018, LECT NOTES COMPUT SC, V11205, P19, DOI 10.1007/978-3-030-01246-5_2
   Liu H, 2019, PROCEEDINGS OF THE THIRD INTERNATIONAL SYMPOSIUM - EDUCATIONAL RESEARCH AND EDUCATIONAL TECHNOLOGY, 2019, P3
   Liu Ying, 2012, Optics and Precision Engineering, V20, P213, DOI 10.3788/OPE.20122002.0213
   Logothetis F, 2019, IEEE I CONF COMP VIS, P1052, DOI 10.1109/ICCV.2019.00114
   Loni M, 2020, IEEE C EVOL COMPUTAT
   Loni M, 2020, MICROPROCESS MICROSY, V73, DOI 10.1016/j.micpro.2020.102989
   Loni M, 2019, LECT NOTES COMPUT SC, V11727, P208, DOI 10.1007/978-3-030-30487-4_17
   Loni M, 2018, 2018 IEEE 12TH INTERNATIONAL SYMPOSIUM ON EMBEDDED MULTICORE/MANY-CORE SYSTEMS-ON-CHIP (MCSOC 2018), P244, DOI 10.1109/MCSoC2018.2018.00049
   Luo WJ, 2016, PROC CVPR IEEE, P5695, DOI 10.1109/CVPR.2016.614
   Mahjourian R, 2018, PROC CVPR IEEE, P5667, DOI 10.1109/CVPR.2018.00594
   Mayer N, 2016, PROC CVPR IEEE, P4040, DOI 10.1109/CVPR.2016.438
   Menze M, 2015, PROC CVPR IEEE, P3061, DOI 10.1109/CVPR.2015.7298925
   Miikkulainen R, 2019, ARTIFICIAL INTELLIGENCE IN THE AGE OF NEURAL NETWORKS AND BRAIN COMPUTING, P293, DOI 10.1016/B978-0-12-815480-9.00015-3
   Niu LC, 2018, IOP CONF SER-MAT SCI, V320, DOI 10.1088/1757-899X/320/1/012007
   Pang JH, 2017, IEEE INT CONF COMP V, P878, DOI 10.1109/ICCVW.2017.108
   Pham H, 2018, PR MACH LEARN RES, V80
   Poggi M., 2020, ARXIV200408566
   Rahnama O, 2019, IEEE T CIRCUITS-II, V66, P773, DOI 10.1109/TCSII.2019.2909169
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Russell S, 2009, ARTIFICIAL INTELLIGE
   Saikia T, 2019, IEEE I CONF COMP VIS, P1812, DOI 10.1109/ICCV.2019.00190
   Scharstein D, 2014, LECT NOTES COMPUT SC, V8753, P31, DOI 10.1007/978-3-319-11752-2_3
   Smith N, 2019, TRANSITIONING INTEL
   Suganuma M, 2020, EVOL COMPUT, V28, P141, DOI 10.1162/evco_a_00253
   Sun YN, 2020, IEEE T CYBERNETICS, V50, P3840, DOI 10.1109/TCYB.2020.2983860
   SZU H, 1987, PHYS LETT A, V122, P157, DOI 10.1016/0375-9601(87)90796-1
   Tan MX, 2019, PROC CVPR IEEE, P2815, DOI [arXiv:1807.11626, 10.1109/CVPR.2019.00293]
   Tonioni A., 2019, CODE REAL TIME SELF
   Tonioni A, 2019, PROC CVPR IEEE, P195, DOI 10.1109/CVPR.2019.00028
   Vinyals O., 2018, PROC 6 INT C LEARN R
   Zbontar J, 2015, PROC CVPR IEEE, P1592, DOI 10.1109/CVPR.2015.7298767
   Zha D., 2016, PROC ACMSIGDA INT S, P274
   Zhang FH, 2019, PROC CVPR IEEE, P185, DOI 10.1109/CVPR.2019.00027
   Zhang HY, 2021, IEEE T EVOLUT COMPUT, V25, P371, DOI 10.1109/TEVC.2020.3040272
   Zhou C, 2017, IEEE I CONF COMP VIS, P1576, DOI 10.1109/ICCV.2017.174
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
   Zoph Barret, 2017, INT C LEARNING REPRE
NR 66
TC 8
Z9 8
U1 0
U2 8
PD AUG
PY 2022
VL 52
IS 8
BP 5222
EP 5234
DI 10.1109/TSMC.2021.3123136
EA NOV 2021
WC Automation & Control Systems; Computer Science, Cybernetics
DA 2023-11-11
ER

PT J
AU Morningstar, A
   Hauru, M
   Beall, J
   Ganahl, M
   Lewis, AGM
   Khemani, V
   Vidal, G
AF Morningstar, Alan
   Hauru, Markus
   Beall, Jackson
   Ganahl, Martin
   Lewis, Adam G. M.
   Khemani, Vedika
   Vidal, Guifre
TI Simulation of Quantum Many-Body Dynamics with Tensor Processing Units:
   Floquet Prethermalization
SO PRX QUANTUM
DT Article
ID PERIODICALLY DRIVEN; THERMALIZATION
AB Tensor processing units (TPUs) are specialized hardware accelerators developed by Google to support large-scale machine-learning tasks but they can also be leveraged to accelerate and scale other linear-algebra-intensive computations. In this paper, we demonstrate the usage of TPUs for massively parallel classical simulations of quantum many-body dynamics on long time scales. We apply our methods to study the phenomenon of Floquet prethermalization, i.e., exponentially slow heating in quantum spin chains subject to high-frequency periodic driving. We simulate the dynamics of L = 34 qubits for over 10(5) Floquet periods, corresponding to circuits with 4 x 10(6) nearest-neighbor two-qubit gates. The circuits simulated have no additional symmetries and represent a pure-state evolution in the full 2(L)-dimensional Hilbert space. This is achieved by distributing the computation over 128 TPU cores. On that size TPU cluster, we find speed-ups in wall-clock run time of 230 times and 15 times when compared to reference CPU and single-graphics-processing-unit (GPU) simulations, respectively, for shorter-time 30-qubit simulations that can be handled by all three platforms. We study the computational cost of the simulations, as a function of both the number of qubits and the number of TPU cores used, up to our maximum capacity of L = 40 qubits, which requires a "full pod" of 2048 TPU cores with tens of terabytes of memory in total. For these simulations, an eight-TPU-core machine is comparable to a single A100 GPU and thus the full TPU pod is comparable to a machine with hundreds of top-of-the-line GPUs. However, the TPU pod is more energy and cost efficient and readily accessible (via Google Cloud), unlike such large many-GPU configurations. We also study the accumulation of numerical error as a function of circuit depth in very deep circuits. Our work demonstrates that TPUs can offer significant advantages for state-of-the-art simulations of quantum many-body dynamics.
C1 [Morningstar, Alan] Princeton Univ, Dept Phys, Princeton, NJ 08544 USA.
   [Morningstar, Alan; Hauru, Markus; Beall, Jackson; Ganahl, Martin; Lewis, Adam G. M.; Vidal, Guifre] Sandbox Alphabet, Mountain View, CA 94043 USA.
   [Khemani, Vedika] Stanford Univ, Dept Phys, Stanford, CA 94305 USA.
RP Morningstar, A (corresponding author), Princeton Univ, Dept Phys, Princeton, NJ 08544 USA.; Morningstar, A (corresponding author), Sandbox Alphabet, Mountain View, CA 94043 USA.
EM alanmorningstar@princeton.edu
CR Abadi Martin, 2016, arXiv
   Abanin DA, 2021, ANN PHYS-NEW YORK, V427, DOI 10.1016/j.aop.2021.168415
   Abanin D, 2017, COMMUN MATH PHYS, V354, P809, DOI 10.1007/s00220-017-2930-x
   Abanin DA, 2019, REV MOD PHYS, V91, DOI 10.1103/RevModPhys.91.021001
   Abanin DA, 2017, PHYS REV B, V95, DOI 10.1103/PhysRevB.95.014112
   Abanin DA, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.256803
   Alet F, 2018, CR PHYS, V19, P498, DOI 10.1016/j.crhy.2018.03.003
   Alexeev Y, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017001
   Altman E, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017003
   [Anonymous], JAX DOCUMENTATION
   Aspuru-Guzik A, 2012, NAT PHYS, V8, P285, DOI [10.1038/NPHYS2253, 10.1038/nphys2253]
   Awschalom D, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.017002
   Belletti F., 2020, ARXIV190602818
   Blatt R, 2012, NAT PHYS, V8, P277, DOI [10.1038/nphys2252, 10.1038/NPHYS2252]
   Bloch I, 2012, NAT PHYS, V8, P267, DOI [10.1038/nphys2259, 10.1038/NPHYS2259]
   Bradbury J., 2018, JAX COMPOSABLE TRANS
   Bukov M, 2015, ADV PHYS, V64, P139, DOI 10.1080/00018732.2015.1055918
   Chan A, 2018, PHYS REV X, V8, DOI 10.1103/PhysRevX.8.041019
   Cirq developers, 2021, CIRQ
   D'Alessio L, 2016, ADV PHYS, V65, P239, DOI 10.1080/00018732.2016.1198134
   D'Alessio L, 2014, PHYS REV X, V4, DOI 10.1103/PhysRevX.4.041048
   Efthymiou S, 2022, QUANTUM SCI TECHNOL, V7, DOI 10.1088/2058-9565/ac39f5
   Else DV, 2017, PHYS REV X, V7, DOI 10.1103/PhysRevX.7.011026
   Else DV, 2016, PHYS REV LETT, V117, DOI 10.1103/PhysRevLett.117.090402
   FEYNMAN RP, 1982, INT J THEOR PHYS, V21, P467, DOI 10.1007/BF02650179
   Fleckenstein C, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.144307
   Frostig R., 2018, SYSTEMS MACHINE LEAR, P23
   Ganahl M., IN PRESS
   Georgescu IM, 2014, REV MOD PHYS, V86, P153, DOI 10.1103/RevModPhys.86.153
   Gray J, 2018, J OPEN SOURCE SOFTW, V3, P819, DOI [DOI 10.21105/JOSS.00819, 10.21105/joss.00819]
   Gustafson E., ARXIV211007482 2021
   Harper F, 2020, ANNU REV CONDEN MA P, V11, P345, DOI 10.1146/annurev-conmatphys-031218-013721
   Hauru M., 2021, ARXIV211110466
   Heyl M, 2019, SCI ADV, V5, DOI 10.1126/sciadv.aau8342
   Houck AA, 2012, NAT PHYS, V8, P292, DOI [10.1038/nphys2251, 10.1038/NPHYS2251]
   Huang C., 2020, ARXIV200506787
   Huot F., 2019, ARXIV191208063
   Ippoliti M, 2021, PRX QUANTUM, V2, DOI 10.1103/PRXQuantum.2.030346
   Isakov S. V., ARXIV211102396 2021
   Jones T, 2019, SCI REP-UK, V9, DOI 10.1038/s41598-019-47174-9
   Jouppi NP, 2020, COMMUN ACM, V63, P67, DOI 10.1145/3360307
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kelly A., 2018, ARXIV180500988
   Khemani V, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.250401
   Kiefer-Emmanouilidis M, 2021, PHYS REV B, V103, DOI 10.1103/PhysRevB.103.024203
   Kuwahara T, 2016, ANN PHYS-NEW YORK, V367, P96, DOI 10.1016/j.aop.2016.01.012
   Ladd TD, 2010, NATURE, V464, P45, DOI 10.1038/nature08812
   Lazarides A, 2015, PHYS REV LETT, V115, DOI 10.1103/PhysRevLett.115.030402
   Lazarides A, 2014, PHYS REV E, V90, DOI 10.1103/PhysRevE.90.012110
   Lewis A. G. M., 2021, ARXIV211209017
   Lezama TLM, 2019, PHYS REV B, V99, DOI 10.1103/PhysRevB.99.161106
   Li A., 2020, STRATEG ORGAN, P1
   Lloyd S, 1996, SCIENCE, V273, P1073, DOI 10.1126/science.273.5278.1073
   Lu T., 2020, ARXIV
   Lu TJ, 2021, I S BIOMED IMAGING, P783, DOI 10.1109/ISBI48211.2021.9434068
   Luitz DJ, 2020, PHYS REV B, V102, DOI 10.1103/PhysRevB.102.100202
   Luitz DJ, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.021046
   Luo XZ, 2020, QUANTUM-AUSTRIA, V4, DOI 10.22331/q-2020-10-11-341
   Ma C., 2021, NONUNIFORM FAST FOUR
   Machado F, 2019, PHYS REV RES, V1, DOI 10.1103/PhysRevResearch.1.033202
   Mandra S, 2021, PROCEEDINGS OF SECOND INTERNATIONAL WORKSHOP ON QUANTUM COMPUTING SOFTWARE (QCS 2021), P99, DOI 10.1109/QCS54837.2021.00015
   Mi X., 2021, ARXIV210713571
   Monroe C, 2021, REV MOD PHYS, V93, DOI 10.1103/RevModPhys.93.025001
   Mori T, 2016, PHYS REV LETT, V116, DOI 10.1103/PhysRevLett.116.120401
   Morningstar A., 2021, ARXIV210705642
   Moudgalya S., 2022, ARXIV210900548, V85
   Nandkishore R, 2015, ANNU REV CONDEN MA P, V6, P15, DOI 10.1146/annurev-conmatphys-031214-014726
   Oka T, 2019, ANNU REV CONDEN MA P, V10, P387, DOI 10.1146/annurev-conmatphys-031218-013423
   Oka T, 2009, PHYS REV B, V79, DOI 10.1103/PhysRevB.79.081406
   Pan F., 2021, ARXIV210303074
   Pan Z., 2021, ARXIV210311927
   Panda RK, 2019, EPL-EUROPHYS LETT, V128, DOI 10.1209/0295-5075/128/67003
   Pederson R., IN PRESS
   Peng P, 2021, NAT PHYS, V17, P444, DOI 10.1038/s41567-020-01120-z
   Po HC, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.041070
   Polkovnikov A, 2011, REV MOD PHYS, V83, P863, DOI 10.1103/RevModPhys.83.863
   Ponte P, 2015, PHYS REV LETT, V114, DOI 10.1103/PhysRevLett.114.140401
   Preskill J, 2018, QUANTUM-AUSTRIA, V2, DOI 10.22331/q-2018-08-06-79
   Quantum AI team and collaborators, 2020, QSIM
   Rubio-Abadal A, 2020, PHYS REV X, V10, DOI 10.1103/PhysRevX.10.021044
   Rudner MS, 2013, PHYS REV X, V3, DOI 10.1103/PhysRevX.3.031005
   Sels D., 2020, ARXIV200904501
   Serbyn M, 2021, NAT PHYS, V17, P675, DOI 10.1038/s41567-021-01230-2
   Shillito R, IN PRESS
   Sierant P., 2021, ARXIV210913608
   Sierant P, 2020, PHYS REV LETT, V124, DOI 10.1103/PhysRevLett.124.186601
   Song R., IN PRESS
   Sünderhauf C, 2018, PHYS REV B, V98, DOI 10.1103/PhysRevB.98.134204
   Suntajs J, 2020, PHYS REV E, V102, DOI 10.1103/PhysRevE.102.062144
   SUZUKI M, 1991, J MATH PHYS, V32, P400, DOI 10.1063/1.529425
   Suzuki Y, 2021, QUANTUM-AUSTRIA, V5, P1, DOI 10.22331/q-2021-10-06-559
   Titum P, 2016, PHYS REV X, V6, DOI 10.1103/PhysRevX.6.021013
   Vidal G, 2004, PHYS REV LETT, V93, DOI 10.1103/PhysRevLett.93.040502
   Villalonga B, 2020, QUANTUM SCI TECHNOL, V5, DOI 10.1088/2058-9565/ab7eeb
   Vincent T., 2021, ARXIV210709793
   Wang Q., 2022, COMPUT PHYS COMMUN, V274, DOI [10.1016/j.cpc.2022.108292, DOI 10.1016/J.CPC.2022.108292]
   Weinberg P, 2017, SCIPOST PHYS, V2, DOI 10.21468/SciPostPhys.2.1.003
NR 97
TC 10
Z9 10
U1 0
U2 1
PD MAY 11
PY 2022
VL 3
IS 2
AR 020331
DI 10.1103/PRXQuantum.3.020331
WC Quantum Science & Technology; Physics, Applied; Physics,
   Multidisciplinary
DA 2023-11-11
ER

PT C
AU Khandelwal, S
   Shreejith, S
AF Khandelwal, Shashwat
   Shreejith, Shanker
GP IEEE
TI A Lightweight FPGA-based IDS-ECU Architecture for Automotive CAN
SO 2022 21ST INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY
   (ICFPT 2022)
DT Proceedings Paper
CT 21st International Conference on Field-Programmable Technology (ICFPT)
CY DEC 05-09, 2022
CL Hong Kong Univ Sci & Technol, Hong Kong, HONG KONG
HO Hong Kong Univ Sci & Technol
DE Controller Area Network; Intrusion Detection System; Machine Learning;
   Field Programmable Gate Arrays
ID INTRUSION DETECTION
AB Recent years have seen an exponential rise in complex software-driven functionality in vehicles, leading to a rising number of electronic control units (ECUs), network capabilities, and interfaces. These expanded capabilities also bring-in new planes of vulnerabilities making intrusion detection and management a critical capability; however, this can often result in more ECUs and network elements due to the high computational overheads. In this paper, we present a consolidated ECU architecture incorporating an Intrusion Detection System (IDS) for Automotive Controller Area Network (CAN) along with traditional ECU functionality on an off-the-shelf hybrid FPGA device, with near-zero overhead for the ECU functionality. We propose two quantised multi-layer perceptrons (QMLP's) as isolated IDSs for detecting a range of attack vectors including Denial-of-Service, Fuzzing and Spoofing, which are accelerated using off-the-shelf deep-learning processing unit (DPU) IP block from Xilinx, operating fully transparently to the software on the ECU. The proposed models achieve the state-of-the-art classification accuracy for all the attacks, while we observed a 15x reduction in power consumption when compared against the GPU-based implementation of the same models quantised using Nvidia libraries. We also achieved a 2.3x speed up in permessage processing latency (at 0.24 ms from the arrival of a CAN message) to meet the strict end-to-end latency on critical CAN nodes and a 2.6x reduction in power consumption for inference when compared to the state-of-the-art IDS models on embedded IDS and loosely coupled IDS accelerators (GPUs) discussed in the literature.
C1 [Khandelwal, Shashwat; Shreejith, Shanker] Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
RP Khandelwal, S (corresponding author), Trinity Coll Dublin, Dept Elect & Elect Engn, Dublin, Ireland.
EM khandels@tcd.ie; shankers@tcd.ie
CR Agrawal K, 2022, IEEE T INTELL TRANSP, V23, P22596, DOI 10.1109/TITS.2022.3146024
   Al-Jarrah OY, 2019, IEEE ACCESS, V7, P21266, DOI 10.1109/ACCESS.2019.2894183
   Alshammari A., 2018, WIRELESS ENG TECHNOL, V9, P79, DOI [10.4236/wet.2018.94007, DOI 10.4236/WET.2018.94007]
   [Anonymous], 2018, ZYNQ ULTRASCALE PLUS
   [Anonymous], 2013, DEF CON
   Blaiech AG, 2019, J SYST ARCHITECT, V98, P331, DOI 10.1016/j.sysarc.2019.01.007
   Bozdal M, 2018, 2018 INTERNATIONAL CONFERENCE ON COMPUTING, ELECTRONICS & COMMUNICATIONS ENGINEERING (ICCECE), P201, DOI 10.1109/iCCECOME.2018.8658720
   Cai Zhiqiang, 2019, BLACK HAT US, V2019, P39
   CAR Hacking Dataset, 2020, CAR HACKING DATASET
   Casino M, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON SYSTEM RELIABILITY AND SAFETY (ICSRS 2019), P136, DOI [10.1109/icsrs48664.2019.8987605, 10.1109/ICSRS48664.2019.8987605]
   Cheng PZ, 2022, SYMMETRY-BASEL, V14, DOI 10.3390/sym14020310
   Cho KN, 2021, MICROMACHINES-BASEL, V12, DOI 10.3390/mi12111309
   Cho KT, 2017, CCS'17: PROCEEDINGS OF THE 2017 ACM SIGSAC CONFERENCE ON COMPUTER AND COMMUNICATIONS SECURITY, P1109, DOI 10.1145/3133956.3134001
   Cho KT, 2016, PROCEEDINGS OF THE 25TH USENIX SECURITY SYMPOSIUM, P911
   De Araujo PF, 2021, IEEE ACCESS, V9, P166855, DOI 10.1109/ACCESS.2021.3136147
   Desta Araya Kibrom, 2020, PROC INT TELECOMMUNI, P1
   Enev M., 2016, P PRIVACY ENHANCING, V2016, P34, DOI DOI 10.1515/POPETS-2015-0029
   Fons F., 2012, XCELL J, p[20, 31]
   GmbH R.B., 2015, ENGINE CONTROL UNIT
   GmbH R.B., 1991, CAN SPEC VERS 2 0
   Greenberg A., 2015, WIRED, V7, P21
   Hartwich F., 2012, P ICC, P1
   Iehira K, 2018, CONSUM COMM NETWORK
   Khandelwal S, 2022, I C FIELD PROG LOGIC, P425, DOI 10.1109/FPL57034.2022.00070
   Khandelwal S, 2022, IEEE INT CONF ASAP, P88, DOI 10.1109/ASAP54787.2022.00023
   Koscher K, 2010, P IEEE S SECUR PRIV, P447, DOI 10.1109/SP.2010.34
   Larson Ulf E., 2008, 2008 IEEE Intelligent Vehicles Symposium (IV), P220, DOI 10.1109/IVS.2008.4621263
   Lee H, 2017, ANN CONF PRIV SECUR, P57, DOI 10.1109/PST.2017.00017
   Ma H., 2022, SECUR COMMUN NETW, V2022
   Mukherjee S, 2016, LECT NOTES COMPUT SC, V10063, P23, DOI 10.1007/978-3-319-49806-5_2
   Narayanan SN, 2015, Arxiv, DOI arXiv:1512.08048
   Nie S., 2017, BLACK HAT US
   Ohira S, 2022, VEH COMMUN, V35, DOI 10.1016/j.vehcom.2022.100470
   Palanca Andrea, 2017, Detection of Intrusions and Malware, and Vulnerability Assessment. 14th International Conference, DIMVA 2017. Proceedings: LNCS 10327, P185, DOI 10.1007/978-3-319-60876-1_9
   Seo E, 2018, ANN CONF PRIV SECUR, P286
   Sharma H., 2016, WORKSH COGN ARCH
   Shreejith S, 2018, IEEE MICRO, V38, P72, DOI 10.1109/MM.2018.022071137
   Shreejith S, 2013, IEEE EMBED SYST LETT, V5, P12, DOI 10.1109/LES.2013.2243698
   Song HM, 2020, VEH COMMUN, V21, DOI 10.1016/j.vehcom.2019.100198
   Studnia I, 2018, INT J EMBED SYST, V10, P1
   Tuan Phan Vuong, 2015, 2015 IEEE International Conferences on Computer and Information Technology; Ubiquitous Computing and Communications; Dependable, Autonomic and Secure Computing; and Pervasive Intelligence and Computing (CIT/IUCC/DASC/PICOM). Proceedings, P2106, DOI 10.1109/CIT/IUCC/DASC/PICOM.2015.313
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Vasistha D. K., 2017, THESIS
   Vipin Kizheppatt, 2014, 2014 IEEE International Conference on Cyber-Physical Systems, Networks, and Applications, P31, DOI 10.1109/CPSNA.2014.14
   Wang C, 2017, IEEE T COMPUT AID D, V36, P513, DOI 10.1109/TCAD.2016.2587683
   Wang EW, 2019, ANN IEEE SYM FIELD P, P26, DOI 10.1109/FCCM.2019.00014
   Weber M., 2018, 9 EUR C EMB REAL TIM
   Wu S, 2018, Arxiv, DOI arXiv:1802.04680
   Wu WF, 2018, IEEE ACCESS, V6, P45233, DOI 10.1109/ACCESS.2018.2865169
   Xiao QC, 2017, DES AUT CON, DOI 10.1145/3061639.3062244
   Xilinx, 2020, ZYNQ DPU V3 2
   Xilinx, 2021, VIT US GUID
   Yang L, 2022, IEEE INTERNET THINGS, V9, P616, DOI 10.1109/JIOT.2021.3084796
   Yang L, 2019, IEEE GLOB COMM CONF, DOI 10.1109/globecom38437.2019.9013892
   Yang Y, 2020, SMART CITIES-BASEL, V3, P17, DOI 10.3390/smartcities3010002
   Zhou J, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362034
NR 56
TC 0
Z9 0
U1 1
U2 1
PY 2022
BP 113
EP 121
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering, Electrical
   & Electronic
DA 2023-11-11
ER

PT J
AU Qu, Z
   Deng, L
   Wang, BY
   Chen, HN
   Lin, JL
   Liang, L
   Li, GQ
   Zhang, Z
   Xie, Y
AF Qu, Zheng
   Deng, Lei
   Wang, Bangyan
   Chen, Hengnu
   Lin, Jilan
   Liang, Ling
   Li, Guoqi
   Zhang, Zheng
   Xie, Yuan
TI Hardware-Enabled Efficient Data Processing With Tensor-Train
   Decomposition
SO IEEE TRANSACTIONS ON COMPUTER-AIDED DESIGN OF INTEGRATED CIRCUITS AND
   SYSTEMS
DT Article
DE Algorithm hardware co-design; tensor-train decomposition (TTD);
   TT-format data processing
ID SINGULAR VALUE DECOMPOSITION; ALGORITHM
AB In recent years, tensor computation has become a promising tool for solving big data analysis, machine learning, medical image, and EDA problems. To ease the memory and computation intensity of tensor processing, decomposition techniques, especially tensor-train decomposition (TTD), are widely adopted to compress the extremely high-dimensional tensor data. Despite TTD's potential to break the curse of dimensionality, researchers have not yet leveraged its full computational potential, mainly because of two reasons: 1) executing TTD itself is time- and energy-consuming due to the singular value decomposition (SVD) operation inside each of TTD's iteration and 2) additional software/hardware optimizations are often required to process the obtained TT-format data in certain applications such as deep learning inference. In this article, we address these challenges with two approaches. First, we propose an algorithm-hardware co-design with customized architecture, namely, TTD Engine to accelerate TTD. We use MRI image compression as a demo application to illustrate the efficacy of the proposed accelerator. Second, we present a case study demonstrating the benefit of TT-format data processing and the efficacy of using TTD Engine. In the case study, we use the TT approach to realize convolution operation, which is difficult and nontrivial for TT-format data. Experimental results show that, TTD Engine achieves, on average, 14.9 x-36.9 x speedup over CPU implementations and 4.1 x-9.9 x speedup compared to the GPU baseline. The energy efficiency is also improved by at least 14.4 x and 5.4 x over CPU and GPU, respectively. Moreover, our hardware-enabled TT-format data processing further leads to more efficient implementations of complicated operations and applications.
C1 [Qu, Zheng; Deng, Lei; Wang, Bangyan; Lin, Jilan; Liang, Ling; Zhang, Zheng; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Chen, Hengnu; Li, Guoqi] Tsinghua Univ, Ctr Brain Inspired Comp Res, Dept Precis Instrument, Beijing 100084, Peoples R China.
RP Deng, L (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM zhengqu@ucsb.edu; leideng@ucsb.edu; bangyan@ucsb.edu;
   chn18@mails.tsinghua.edu.cn; jilan@ucsb.edu; linglinag@ucsb.edu;
   liguoqi@mail.tsinghua.edu.cn; zhengzhang@ucsb.edu; yuanxie@ucsb.edu
CR [Anonymous], 2019, ARXIV190701522
   [Anonymous], 2009, HP LAB
   [Anonymous], 2014, ARXIV14073124
   ARNOLDI WE, 1951, Q APPL MATH, V9, P17, DOI 10.1090/qam/42792
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   Ballester R., TNTORCH TENSOR NETWO
   BRENT RP, 1985, J VLSI COMPUT SYST, V1, P242
   CARROLL JD, 1970, PSYCHOMETRIKA, V35, P283, DOI 10.1007/BF02310791
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Cichocki A., 2009, NONNEGATIVE MATRIX T, DOI DOI 10.1002/9780470747278
   Cichocki A., 2014, ERA BIG DATA PROCESS, Vabs/1403.2048
   Cichocki A, 2015, IEEE SIGNAL PROC MAG, V32, P145, DOI 10.1109/MSP.2013.2297439
   Comon P, 2010, HANDBOOK OF BLIND SOURCE SEPARATION: INDEPENDENT COMPONENT ANALYSIS AND APPLICATIONS, P1
   De Lathauwer L, 2008, SIAM J MATRIX ANAL A, V30, pVII, DOI 10.1137/SJMAEL000030000003000vii000001
   DERIJK PPM, 1989, SIAM J SCI STAT COMP, V10, P359, DOI 10.1137/0910023
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Garipov Timur, 2016, ABS161103214 CORR
   Gupta U., 2019, ARXIV190808976
   Harshman R. A., 1970, WORKING PAPERS PHONE
   Hwang R., 2020, ARXIV200505968
   Klus S, 2018, NONLINEARITY, V31, P3359, DOI 10.1088/1361-6544/aabc8f
   Kolda TG, 2009, SIAM REV, V51, P455, DOI 10.1137/07070111X
   Krizhevsky A., 2009, LEARNING MULTIPLE LA
   Ledesma-Carrillo Luis M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P345, DOI 10.1109/ReConFig.2011.77
   Novikov A., 2015, ADV NEURAL INFORM PR, P442, DOI DOI 10.5555/2969239.2969289
   Novikov A., 2015, P NIPS, P442
   Oseledets I., 2021, OSELEDETS TT TOOLBOX
   Oseledets IV, 2012, SIAM J SCI COMPUT, V34, pA2718, DOI 10.1137/110833142
   Oseledets IV, 2011, SIAM J SCI COMPUT, V33, P2295, DOI 10.1137/090752286
   Oseledets I, 2010, LINEAR ALGEBRA APPL, V432, P70, DOI 10.1016/j.laa.2009.07.024
   Sorber L, 2013, SIAM J OPTIMIZ, V23, P695, DOI 10.1137/120868323
   Srivastava N, 2020, INT S HIGH PERF COMP, P689, DOI 10.1109/HPCA47549.2020.00062
   Srivastava N, 2019, ANN IEEE SYM FIELD P, P181, DOI 10.1109/FCCM.2019.00033
   Tucker L. R., 1963, PROBLEMS MEASURING C, V15, P122
   Tucker L. R., 1964, CONTRIBUTIONS MATH P, P110
   TUCKER LR, 1966, PSYCHOMETRIKA, V31, P279, DOI 10.1007/BF02289464
   Wang XY, 2014, PROCEEDINGS OF 2014 IEEE INTERNATIONAL PARALLEL & DISTRIBUTED PROCESSING SYMPOSIUM WORKSHOPS (IPDPSW), P220, DOI 10.1109/IPDPSW.2014.29
   Zhang Y., 2019, ARXIV190913654
   Zhang Z, 2017, IEEE T COMPUT AID D, V36, P521, DOI 10.1109/TCAD.2016.2618879
   Zhang Z, 2015, IEEE T COMPUT AID D, V34, P63, DOI 10.1109/TCAD.2014.2369505
NR 41
TC 3
Z9 3
U1 2
U2 10
PD FEB
PY 2022
VL 41
IS 2
BP 372
EP 385
DI 10.1109/TCAD.2021.3058317
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Hosseini, M
   Mohsenin, T
AF Hosseini, Morteza
   Mohsenin, Tinoosh
TI Binary Precision Neural Network Manycore Accelerator
SO ACM JOURNAL ON EMERGING TECHNOLOGIES IN COMPUTING SYSTEMS
DT Article
DE BiNMAC; low-power manycore accelerator; binarized neural network;
   CPU-GPU; deep learning; ASIC
ID DESIGN; MEMORY
AB This article presents a low-power, programmable, domain-specific manycore accelerator, Binarized neural Network Manycore Accelerator (BiNMAC), which adopts and efficiently executes binary precision weight/activation neural network models. Such networks have compact models in which weights are constrained to only 1 bit and can be packed several in one memory entry that minimizes memory footprint to its finest. Packing weights also facilitates executing single instruction, multiple data with simple circuitry that allows maximizing performance and efficiency. The proposed BiNMAC has light-weight cores that support domain-specific instructions, and a router-based memory access architecture that helps with efficient implementation of layers in binary precision weight/activation neural networks of proper size. With only 3.73% and 1.98% area and average power overhead, respectively, novel instructions such as Combined Population-Count-XNOR, Patch-Select, and Bit-based Accumulation are added to the instruction set architecture of the BiNMAC, each of which replaces execution cycles of frequently used functions with 1 clock cycle that otherwise would have taken 54, 4, and 3 clock cycles, respectively. Additionally, customized logic is added to every core to transpose 16x16-bit blocks of memory on a bit-level basis, that expedites reshaping intermediate data to be well-aligned for bitwise operations. A 64-cluster architecture of the BiNMAC is fully placed and routed in 65-nm TSMC CMOS technology, where a single cluster occupies an area of 0.53 mm(2) with an average power of 232 mW at 1-GHz clock frequency and 1.1 V. The 64-cluster architecture takes 36.5 mm(2) area and, if fully exploited, consumes a total power of 16.4 W and can perform 1,360 Giga Operations Per Second (GOPS) while providing full programmability. To demonstrate its scalability, four binarized case studies including ResNet-20 and LeNet-5 for high-performance image classification, as well as a ConvNet and a multilayer perceptron for low-power physiological applications were implemented on BiNMAC. The implementation results indicate that the population-count instruction alone can expedite the performance by approximately 5x. When other new instructions are added to a RISC machine with existing population-count instruction, the performance is increased by 58% on average. To compare the performance of the BiNMAC with other commercial-off-the-shelf platforms, the case studies with their double-precision floating-point models are also implemented on the NVIDIA Jetson TX2 SoC (CPU+GPU). The results indicate that, within a margin of similar to 2.1%-9.5% accuracy loss, BiNMAC on average outperforms the TX2 GPU by approximately 1.9x (or 7.5x with fabrication technology scaled) in energy consumption for image classification applications. On low power settings and within a margin of similar to 3.7%-5.5% accuracy loss compared to ARM Cortex-A57 CPU implementation, BiNMAC is roughly similar to 9.7x-17.2x (or 38.8x-68.8x with fabrication technology scaled) more energy efficient for physiological applications while meeting the application deadline.
C1 [Hosseini, Morteza; Mohsenin, Tinoosh] Univ Maryland Baltimore Cty, 1000 Hilltop Cir, Catonsville, MD 21250 USA.
RP Hosseini, M (corresponding author), Univ Maryland Baltimore Cty, 1000 Hilltop Cir, Catonsville, MD 21250 USA.
EM hs10@umbc.edu; tinoosh@umbc.edu
CR Abtahi T, 2018, IEEE T VLSI SYST, V26, P1737, DOI 10.1109/TVLSI.2018.2825145
   AMDAHL GM, 1967, P APR 18 20 1967 SPR, P483, DOI DOI 10.1145/1465482.1465560
   Ando K, 2017, SYMP VLSI CIRCUITS, pC24, DOI 10.23919/VLSIC.2017.8008533
   Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   Birjandtalab J, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P110, DOI 10.1109/SiPS.2016.27
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Colangelo P, 2017, ANN IEEE SYM FIELD P, P135, DOI 10.1109/FCCM.2017.46
   Courbariaux M, 2015, ADV NEUR IN, V28
   Dauphin Yann N., 2013, P ICLR WORKSH
   Deng L, 2018, FRONT NEUROSCI-SWITZ, V12, DOI 10.3389/fnins.2018.00841
   DENNARD RH, 1974, IEEE J SOLID-ST CIRC, VSC 9, P256, DOI 10.1109/JSSC.1974.1050511
   Franklin D., 2017, NVIDIA ACCELERATED C
   Gong Y., 2014, ARXIV14126115
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   He K., 2015, ARXIV
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   Hossain MJ, 2020, PROCEEDINGS OF 2020 11TH INTERNATIONAL CONFERENCE ON ELECTRICAL AND COMPUTER ENGINEERING (ICECE), P1, DOI 10.1109/ICECE51571.2020.9393122
   Howard A. G., 2017, ARXIV170404861, DOI DOI 10.48550/ARXIV.1704.04861
   Huang G, 2017, PROC CVPR IEEE, P2261, DOI 10.1109/CVPR.2017.243
   Hubara I, 2018, J MACH LEARN RES, V18
   Ioffe S, 2015, Arxiv, DOI [arXiv:1502.03167, DOI 10.48550/ARXIV.1502.03167]
   Javaheripi M, 2020, IEEE J-STSP, V14, P750, DOI 10.1109/JSTSP.2020.2992384
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kwon Y, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P740, DOI 10.1145/3352460.3358284
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Mirzaeian Ali, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P530, DOI 10.1109/ASP-DAC47756.2020.9045135
   Mirzaeian A, 2019, 2019 INT C RECONFIGU, P1
   Nurvitadhi E, 2016, 2016 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (FPT), P77, DOI 10.1109/FPT.2016.7929192
   Page A, 2017, ACM J EMERG TECH COM, V13, DOI 10.1145/3005448
   Page A, 2016, 2016 INTERNATIONAL GREAT LAKES SYMPOSIUM ON VLSI (GLSVLSI), P63, DOI 10.1145/2902961.2902986
   Park J, 2016, INT CONF ACOUST SPEE, P1011, DOI 10.1109/ICASSP.2016.7471828
   Peng XC, 2019, MEMSYS 2019: PROCEEDINGS OF THE INTERNATIONAL SYMPOSIUM ON MEMORY SYSTEMS, P471, DOI 10.1145/3357526.3357566
   Prakash B., 2020, SAFEAI WORKSH 34 AAA
   Rastegari M, 2016, LECT NOTES COMPUT SC, V9908, P525, DOI 10.1007/978-3-319-46493-0_32
   Reiss A, 2012, IEEE INT SYM WRBL CO, P108, DOI 10.1109/ISWC.2012.13
   Ren H., 2020, P 2020 IEEE 33 INT S
   Samragh M, 2020, ACM T EMBED COMPUT S, V19, DOI 10.1145/3391901
   Shea C, 2019, ACM J EMERG TECH COM, V15, DOI 10.1145/3358699
   Shiri Aidin, 2020, GLSVLSI '20. Proceedings of the 2020 Great Lakes Symposium on VLSI, P131, DOI 10.1145/3386263.3407652
   Song LH, 2019, CCF T HIGH PERFORM C, V1, P196, DOI 10.1007/s42514-019-00014-8
   Sumbul Huseyin Ekin, 2020, US Patent App, Patent No. [16/697,616, 16697616]
   Thulasiraman K., 1992, GRAPHS THEORY ALGORI
   Umuroglu Y, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P65, DOI 10.1145/3020078.3021744
   Venieris SI, 2016, ANN IEEE SYM FIELD P, P40, DOI 10.1109/FCCM.2016.22
   Venkatesh G, 2017, INT CONF ACOUST SPEE, P2861, DOI 10.1109/ICASSP.2017.7952679
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Yin SH, 2020, IEEE J SOLID-ST CIRC, V55, P1733, DOI 10.1109/JSSC.2019.2963616
   Yonekawa H, 2017, IEEE SYM PARA DISTR, P98, DOI 10.1109/IPDPSW.2017.95
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Y, 2017, HELLO EDGE KEYWORD S
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zhu ZH, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317739
NR 52
TC 2
Z9 2
U1 1
U2 1
PD FEB
PY 2021
VL 17
IS 2
AR 19
DI 10.1145/3423136
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Almagro, CV
   Orrego, RAM
   González, AG
   Matheson, E
   Prades, RM
   Di Castro, M
   PéTrez, MF
AF Veiga Almagro, Carlos
   Munoz Orrego, Renato Andres
   Gonzalez, Alvaro Garcia
   Matheson, Eloise
   Marin Prades, Raul
   Di Castro, Mario
   Ferre Perez, Manuel
TI (MARGOT) Monocular Camera-Based Robot Grasping Strategy for Metallic
   Objects
SO SENSORS
DT Article
DE computer vision; telerobotics; grasping determination
ID VISION
AB Robotic handling of objects is not always a trivial assignment, even in teleoperation where, in most cases, this might lead to stressful labor for operators. To reduce the task difficulty, supervised motions could be performed in safe scenarios to reduce the workload in these non-critical steps by using machine learning and computer vision techniques. This paper describes a novel grasping strategy based on a groundbreaking geometrical analysis which extracts diametrically opposite points taking into account surface smoothing (even those target objects that might conform highly complex shapes) to guarantee the uniformity of the grasping. It uses a monocular camera, as we are often facing space restrictions that generate the need to use laparoscopic cameras integrated in the tools, to recognize and isolate targets from the background, estimating their spatial coordinates and providing the best possible stable grasping points for both feature and featureless objects. It copes with reflections and shadows produced by light sources (which require extra effort to extract their geometrical properties) in unstructured facilities such as nuclear power plants or particle accelerators on scientific equipment. Based on the experimental results, utilizing a specialized dataset improved the detection of metallic objects in low-contrast environments, resulting in the successful application of the algorithm with error rates in the scale of millimeters in the majority of repeatability and accuracy tests.
C1 [Veiga Almagro, Carlos; Munoz Orrego, Renato Andres; Gonzalez, Alvaro Garcia; Matheson, Eloise; Di Castro, Mario] European Org Nucl Res CERN, BE CEM Beams Dept, Elect & Mechatron Grp, CH-1217 Geneva, Switzerland.
   [Veiga Almagro, Carlos; Marin Prades, Raul] Jaume I Univ Castellon, Interact Robot Syst Lab, Castellon De La Plana 12006, Spain.
   [Munoz Orrego, Renato Andres; Ferre Perez, Manuel] Univ Politecn Madrid, Ctr Automat & Robot CAR UPM CSIC, Madrid 28006, Spain.
RP Almagro, CV; Orrego, RAM (corresponding author), European Org Nucl Res CERN, BE CEM Beams Dept, Elect & Mechatron Grp, CH-1217 Geneva, Switzerland.; Almagro, CV (corresponding author), Jaume I Univ Castellon, Interact Robot Syst Lab, Castellon De La Plana 12006, Spain.; Orrego, RAM (corresponding author), Univ Politecn Madrid, Ctr Automat & Robot CAR UPM CSIC, Madrid 28006, Spain.
EM carlos.veiga.almagro@cern.ch; rena.munozo@gmail.com
CR [Anonymous], 2014, SCIPY V1 9 3 MAN
   Balasubramanian R, 2012, IEEE T ROBOT, V28, P899, DOI 10.1109/TRO.2012.2189498
   Bay H, 2008, COMPUT VIS IMAGE UND, V110, P346, DOI 10.1016/j.cviu.2007.09.014
   Brown MZ, 2003, IEEE T PATTERN ANAL, V25, P993, DOI 10.1109/TPAMI.2003.1217603
   Calandra R, 2018, IEEE ROBOT AUTOM LET, V3, P3300, DOI 10.1109/LRA.2018.2852779
   Calonder M, 2010, LECT NOTES COMPUT SC, V6314, P778, DOI 10.1007/978-3-642-15561-1_56
   Chen LC, 2017, Arxiv, DOI [arXiv:1706.05587, DOI 10.48550/ARXIV.1706.05587]
   Chiou M, 2022, Arxiv, DOI arXiv:2207.00648
   COVER TM, 1967, IEEE T INFORM THEORY, V13, P21, DOI 10.1109/TIT.1967.1053964
   CUTKOSKY MR, 1989, IEEE T ROBOTIC AUTOM, V5, P269, DOI 10.1109/70.34763
   Dalal N, 2005, PROC CVPR IEEE, P886, DOI 10.1109/cvpr.2005.177
   Di Castro M, 2018, IEEE ACCESS, V6, P37506, DOI 10.1109/ACCESS.2018.2849572
   Duan SL, 2010, 2010 8TH WORLD CONGRESS ON INTELLIGENT CONTROL AND AUTOMATION (WCICA), P1000, DOI 10.1109/WCICA.2010.5554595
   Elaraby AF, 2018, 2018 IEEE 9TH ANNUAL INFORMATION TECHNOLOGY, ELECTRONICS AND MOBILE COMMUNICATION CONFERENCE (IEMCON), P247, DOI 10.1109/IEMCON.2018.8615020
   Fan Q, 2020, PROC CVPR IEEE, P4012, DOI 10.1109/CVPR42600.2020.00407
   Graeter J, 2018, IEEE INT C INT ROBOT, P7872, DOI 10.1109/IROS.2018.8594394
   Grech L, 2018, IEEE INT CON AUTO SC, P817, DOI 10.1109/COASE.2018.8560485
   Hambarde P, 2019, IEEE IMAGE PROC, P989, DOI [10.1109/icip.2019.8803027, 10.1109/ICIP.2019.8803027]
   Hartley R., 2003, MULTIPLE VIEW GEOMET, DOI [DOI 10.1017/CBO9780511811685, 10.1016/S0143-8166(01)00145-2]
   He KM, 2017, IEEE I CONF COMP VIS, P2980, DOI [10.1109/ICCV.2017.322, 10.1109/TPAMI.2018.2844175]
   Held D, 2016, LECT NOTES COMPUT SC, V9905, P749, DOI 10.1007/978-3-319-46448-0_45
   Hirschmüller H, 2008, IEEE T PATTERN ANAL, V30, P328, DOI [10.1109/TPAMI.2007.1166, 10.1109/TPAMl.2007.1166]
   Hsu GS, 2012, INT C PATT RECOG, P3500
   Hu XY, 2012, IEEE T PATTERN ANAL, V34, P2121, DOI 10.1109/TPAMI.2012.46
   Kao I, 1997, IEEE T ROBOTIC AUTOM, V13, P557, DOI 10.1109/70.611319
   Kok-Meng Lee, 1999, 1999 IEEE/ASME International Conference on Advanced Intelligent Mechatronics (Cat. No.99TH8399), P354, DOI 10.1109/AIM.1999.803192
   Kumra S, 2017, IEEE INT C INT ROBOT, P769, DOI 10.1109/IROS.2017.8202237
   LANGLEY P, 1992, AAAI-92 PROCEEDINGS : TENTH NATIONAL CONFERENCE ON ARTIFICIAL INTELLIGENCE, P223
   Lars W.L., 2000, EXTENDED ARM MAN HIS
   Lee MA, 2020, IEEE T ROBOT, V36, P582, DOI 10.1109/TRO.2019.2959445
   Li FF, 2006, IEEE T PATTERN ANAL, V28, P594, DOI 10.1109/TPAMI.2006.79
   Lin TY, 2018, Arxiv, DOI [arXiv:1708.02002, DOI 10.48550/ARXIV.1708.02002]
   Lin TY, 2017, PROC CVPR IEEE, P936, DOI 10.1109/CVPR.2017.106
   Liu W, 2016, Arxiv, DOI [arXiv:1512.02325, DOI 10.48550/ARXIV.1512.02325]
   Lowe D. G., 1999, P INT C COMP VIS, P1150
   Lunchi G, 2019, IEEE ACCESS, V7, P127290, DOI 10.1109/ACCESS.2019.2939493
   May S, 2009, 2009 IEEE-RSJ INTERNATIONAL CONFERENCE ON INTELLIGENT ROBOTS AND SYSTEMS, P1673, DOI 10.1109/IROS.2009.5354684
   Moghari M D., 2019, 2019 IEEE NUCL SCI S
   Mohammed MQ, 2020, IEEE ACCESS, V8, P178450, DOI 10.1109/ACCESS.2020.3027923
   Nakajima C, 2000, INT C PATT RECOG, P787, DOI 10.1109/ICPR.2000.903035
   Nalpantidis L, 2008, INT J OPTOMECHATRONI, V2, P435, DOI 10.1080/15599610802438680
   Noraky J, 2020, IEEE T CIRC SYST VID, V30, P1524, DOI 10.1109/TCSVT.2019.2907904
   OTSU N, 1979, IEEE T SYST MAN CYB, V9, P62, DOI 10.1109/TSMC.1979.4310076
   Park H.J., 2020, INDONES J ELECT ENG, V19, P1021, DOI [10.11591/ijeecs.v19.i2.pp1021-1027, DOI 10.11591/IJEECS.V19.I2.PP1021-1027]
   Qin XB, 2020, PATTERN RECOGN, V106, DOI 10.1016/j.patcog.2020.107404
   Ranftl R, 2022, IEEE T PATTERN ANAL, V44, P1623, DOI 10.1109/TPAMI.2020.3019967
   Redmon J, 2016, PROC CVPR IEEE, P779, DOI 10.1109/CVPR.2016.91
   Ren SQ, 2016, Arxiv, DOI [arXiv:1506.01497, 10.48550/ARXIV.1506.01497, DOI 10.1109/TPAMI.2016.2577031]
   Reza AM, 2004, J VLSI SIG PROC SYST, V38, P35, DOI 10.1023/B:VLSI.0000028532.53893.82
   Ronneberger O, 2015, Arxiv, DOI [arXiv:1505.04597, 10.48550/arXiv.1505.04597, DOI 10.48550/ARXIV.1505.04597]
   Rublee E, 2011, IEEE I CONF COMP VIS, P2564, DOI 10.1109/ICCV.2011.6126544
   Sanz P., 2008, THESIS U JAUME I CAS
   Saravanakumar S., 2010, 2010 International Conference on Signal and Image Processing (ICSIP 2010), P79, DOI 10.1109/ICSIP.2010.5697446
   Scharstein D, 2001, IEEE WORKSHOP ON STEREO AND MULTI-BASELINE VISION, PROCEEDINGS, P131, DOI [10.1109/SMBV.2001.988771, 10.1023/A:1014573219977]
   Schneider & Company, COEFF FRICT REF CHAR
   Seitz SM., 2006, 2006 IEEE COMP SOC C, V1, P519, DOI DOI 10.1109/CVPR.2006.19
   Shi CQ, 2022, SENSORS-BASEL, V22, DOI 10.3390/s22114283
   Shin YS, 2018, IEEE INT CONF ROBOT, P5144, DOI 10.1109/ICRA.2018.8461102
   Tongphu S., 2012, P 2012 9 INT C ELECT, P1, DOI [10.1109/ECTICon.2012.6254268, DOI 10.1109/ECTICON.2012.6254268]
   Almagro CV, 2019, SENSORS-BASEL, V19, DOI 10.3390/s19143220
   Velasco E, 2020, REV IBEROAM AUTOM IN, V17, P44, DOI 10.4995/riai.2019.10923
   Wang LM, 2017, PROC CVPR IEEE, P6402, DOI 10.1109/CVPR.2017.678
   Wu Y, 2001, EIGHTH IEEE INTERNATIONAL CONFERENCE ON COMPUTER VISION, VOL I, PROCEEDINGS, P275, DOI 10.1109/ICCV.2001.937529
   Yamaguchi T., 2007, P 2007 14 INT WORKSH, P426, DOI [10.1109/IWSSIP.2007.4381132, DOI 10.1109/IWSSIP.2007.4381132]
   Yan Q, 2013, PROC CVPR IEEE, P1155, DOI 10.1109/CVPR.2013.153
   Yang Y, 2012, COMPUT MATH APPL, V64, P1235, DOI 10.1016/j.camwa.2012.03.067
   Yoon K, 2020, IEEE ACCESS, V8, P38060, DOI 10.1109/ACCESS.2020.2975912
   Yoshida T, 2014, FIELD SERVICE ROBOTI, P19
   Zeng A, 2018, IEEE INT C INT ROBOT, P4238, DOI 10.1109/IROS.2018.8593986
   Zhang ZB, 2013, IEEE T CIRC SYST VID, V23, P1795, DOI 10.1109/TCSVT.2013.2269023
   Zhang ZY, 2000, IEEE T PATTERN ANAL, V22, P1330, DOI 10.1109/34.888718
   Zhou MH, 2020, PROC CVPR IEEE, P11771, DOI 10.1109/CVPR42600.2020.01179
NR 72
TC 0
Z9 0
U1 3
U2 3
PD JUN 5
PY 2023
VL 23
IS 11
AR 5344
DI 10.3390/s23115344
WC Chemistry, Analytical; Engineering, Electrical & Electronic; Instruments
   & Instrumentation
DA 2023-11-11
ER

PT J
AU Ielmini, D
   Pedretti, G
AF Ielmini, Daniele
   Pedretti, Giacomo
TI Device and Circuit Architectures for In-Memory Computing
SO ADVANCED INTELLIGENT SYSTEMS
DT Review
DE artificial intelligence; in-memory computing; machine learning;
   memories; neural networks
ID PHASE-CHANGE MATERIALS; RANDOM-ACCESS MEMORY; CONTENT-ADDRESSABLE
   MEMORY; RESISTIVE SWITCHES; LOGIC OPERATIONS; NEURAL-NETWORKS; CROSSBAR
   ARRAY; PART I; OXIDE; RESISTANCE
AB With the rise in artificial intelligence (AI), computing systems are facing new challenges related to the large amount of data and the increasing burden of communication between the memory and the processing unit. In-memory computing (IMC) appears as a promising approach to suppress the memory bottleneck and enable higher parallelism of data processing, thanks to the memory array architecture. As a result, IMC shows a better throughput and lower energy consumption with respect to the conventional digital approach, not only for typical AI tasks, but also for general-purpose problems such as constraint satisfaction problems (CSPs) and linear algebra. Herein, an overview of IMC is provided in terms of memory devices and circuit architectures. First, the memory device technologies adopted for IMC are summarized, focusing on both charge-based memories and emerging devices relying on electrically induced material modification at the chemical or physical level. Then, the computational memory programming and the corresponding device nonidealities are described with reference to offline and online training of IMC circuits. Finally, array architectures for computing are reviewed, including typical architectures for neural network accelerators, content addressable memory (CAM), and novel circuit topologies for general-purpose computing with low complexity.
C1 [Ielmini, Daniele; Pedretti, Giacomo] Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza L da Vinci 32, I-20133 Milan, Italy.
   [Ielmini, Daniele; Pedretti, Giacomo] Italian Univ Nanoelect Team IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
RP Ielmini, D (corresponding author), Politecn Milan, Dipartimento Elettron Informaz & Bioingn, Piazza L da Vinci 32, I-20133 Milan, Italy.; Ielmini, D (corresponding author), Italian Univ Nanoelect Team IUNET, Piazza L da Vinci 32, I-20133 Milan, Italy.
EM daniele.ielmini@polimi.it
CR Ambrogio S, 2018, NATURE, V558, P60, DOI 10.1038/s41586-018-0180-5
   Ambrogio S, 2016, IEEE T ELECTRON DEV, V63, P1508, DOI 10.1109/TED.2016.2526647
   Ambrogio S, 2015, IEEE T ELECTRON DEV, V62, P3812, DOI 10.1109/TED.2015.2477135
   Ambrogio S, 2014, IEEE T ELECTRON DEV, V61, P2912, DOI 10.1109/TED.2014.2330200
   [Anonymous], 2019, ARXIV190907514
   [Anonymous], 2019, ARXIV190311194CS
   Athmanathan A, 2016, IEEE J EM SEL TOP C, V6, P87, DOI 10.1109/JETCAS.2016.2528598
   Baek IG, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Baek IG, 2005, INT EL DEVICES MEET, P769
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P3365, DOI 10.1109/TED.2015.2463104
   Balatti S, 2015, IEEE J EM SEL TOP C, V5, P214, DOI 10.1109/JETCAS.2015.2426492
   Balatti S, 2015, IEEE T ELECTRON DEV, V62, P1831, DOI 10.1109/TED.2015.2422999
   Balatti S, 2013, IEEE ELECTR DEVICE L, V34, P861, DOI 10.1109/LED.2013.2261451
   Bez R, 2003, P IEEE, V91, P489, DOI 10.1109/JPROC.2003.811702
   Bi GQ, 1998, J NEUROSCI, V18, P10464, DOI 10.1523/jneurosci.18-24-10464.1998
   BIENENSTOCK EL, 1982, J NEUROSCI, V2, P32, DOI 10.1523/jneurosci.02-01-00032.1982
   Bojnordi MN, 2016, INT S HIGH PERF COMP, P1, DOI 10.1109/HPCA.2016.7446049
   Borghetti J, 2010, NATURE, V464, P873, DOI 10.1038/nature08940
   Boscke T. S., 2011, IEDM
   Boybat I, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04933-y
   Bricalli A, 2018, IEEE T ELECTRON DEV, V65, P122, DOI 10.1109/TED.2017.2776085
   Bryan K, 2006, SIAM REV, V48, P569, DOI 10.1137/050623280
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Cai FX, 2019, NAT ELECTRON, V2, P290, DOI 10.1038/s41928-019-0270-x
   Carboni R, 2019, IEEE T ELECTRON DEV, V66, P4176, DOI 10.1109/TED.2019.2933315
   Carboni R, 2018, IEEE T ELECTRON DEV, V65, P2470, DOI 10.1109/TED.2018.2822343
   Cassinerio M, 2013, ADV MATER, V25, P5975, DOI 10.1002/adma.201301940
   Chang CC, 2018, IEEE J EM SEL TOP C, V8, P116, DOI 10.1109/JETCAS.2017.2771529
   Chanthbouala A, 2012, NAT NANOTECHNOL, V7, P101, DOI [10.1038/nnano.2011.213, 10.1038/NNANO.2011.213]
   Chappert C, 2007, NAT MATER, V6, P813, DOI 10.1038/nmat2024
   Chen B, 2015, 2015 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Chen WH, 2019, NAT ELECTRON, V2, P420, DOI 10.1038/s41928-019-0288-0
   Chen YC, 2003, 2003 IEEE INTERNATIONAL ELECTRON DEVICES MEETING, TECHNICAL DIGEST, P905
   Cheng HY, 2018, INT EL DEVICES MEET
   Chi P, 2016, CONF PROC INT SYMP C, P27, DOI 10.1109/ISCA.2016.13
   Chicca E, 2014, P IEEE, V102, P1367, DOI 10.1109/JPROC.2014.2313954
   Ciocchini N, 2012, IEEE T ELECTRON DEV, V59, P3084, DOI 10.1109/TED.2012.2214784
   Cosemans S, 2019, INT EL DEVICES MEET
   Cubukcu M, 2014, APPL PHYS LETT, V104, DOI 10.1063/1.4863407
   Engel BN, 2005, IEEE T MAGN, V41, P132, DOI 10.1109/TMAG.2004.840847
   Fantini P, 2012, APPL PHYS LETT, V100, DOI 10.1063/1.3674311
   Florent K., 2018, 2018 IEEE INT EL DEV
   Fuller EJ, 2019, SCIENCE, V364, P570, DOI 10.1126/science.aaw5581
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Furber SB, 2014, P IEEE, V102, P652, DOI 10.1109/JPROC.2014.2304638
   Gabardi S, 2015, PHYS REV B, V92, DOI 10.1103/PhysRevB.92.054201
   Gao LG, 2016, IEEE T ELECTRON DEV, V63, P3109, DOI 10.1109/TED.2016.2578720
   Garbin D, 2015, IEEE T ELECTRON DEV, V62, P2494, DOI 10.1109/TED.2015.2440102
   Garello K, 2014, APPL PHYS LETT, V105, DOI 10.1063/1.4902443
   Garey M. R., 1979, COMPUTERS INTRACTABI
   Giannopoulos I, 2018, INT EL DEVICES MEET
   Gokmen T, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993573
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Gopalakrishnan K, 2010, S VLSI TECH, P205, DOI 10.1109/VLSIT.2010.5556229
   Govoreanu B, 2011, 2011 IEEE INTERNATIONAL ELECTRON DEVICES MEETING (IEDM)
   Graves CE, 2019, IEEE T NANOTECHNOL, V18, P963, DOI 10.1109/TNANO.2019.2936239
   Grollier J, 2016, P IEEE, V104, P2024, DOI 10.1109/JPROC.2016.2597152
   Gu Y, 2014, 2014 IEEE 12TH INTERNATIONAL CONFERENCE ON DEPENDABLE, AUTONOMIC AND SECURE COMPUTING (DASC)/2014 IEEE 12TH INTERNATIONAL CONFERENCE ON EMBEDDED COMPUTING (EMBEDDEDCOM)/2014 IEEE 12TH INTERNATIONAL CONF ON PERVASIVE INTELLIGENCE AND COMPUTING (PICOM), P1, DOI 10.1109/DASC.2014.10
   Guo Q., 2013, 2013 ACM IEEE 43 ANN, P189
   Guo Q, 2011, INT SYMP MICROARCH, P339
   Hai K., 2019, MIT TECHNOL REV
   Hasegawa T, 2012, ADV MATER, V24, P252, DOI 10.1002/adma.201102597
   HOPFIELD JJ, 1985, BIOL CYBERN, V52, P141
   HOPFIELD JJ, 1986, SCIENCE, V233, P625, DOI 10.1126/science.3755256
   HOPFIELD JJ, 1982, P NATL ACAD SCI-BIOL, V79, P2554, DOI 10.1073/pnas.79.8.2554
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   Hosomi M, 2005, INT EL DEVICES MEET, P473
   Hsieh M.-C., 2013, 2013 IEEE INT EL DEV, p10.3.1
   Hsu CW, 2014, NANOTECHNOLOGY, V25, DOI 10.1088/0957-4484/25/16/165202
   Hu M, 2018, ADV MATER, V30, DOI 10.1002/adma.201705914
   Hua QL, 2019, GLOB CHALL, V3, DOI 10.1002/gch2.201900015
   Huang P, 2016, ADV MATER, V28, P9758, DOI 10.1002/adma.201602418
   Hui F, 2017, ADV ELECTRON MATER, V3, DOI 10.1002/aelm.201600195
   Ielmini D, 2007, IEEE T ELECTRON DEV, V54, P308, DOI 10.1109/TED.2006.888752
   Ielmini D, 2020, NANOTECHNOLOGY, V31, DOI 10.1088/1361-6528/ab554b
   Ielmini D, 2018, NAT ELECTRON, V1, P333, DOI 10.1038/s41928-018-0092-2
   Ielmini D, 2016, SEMICOND SCI TECH, V31, DOI 10.1088/0268-1242/31/6/063002
   Ielmini D, 2011, MATER TODAY, V14, P600, DOI 10.1016/S1369-7021(11)70301-7
   Ielmini D, 2011, PHASE TRANSIT, V84, P570, DOI 10.1080/01411594.2011.561478
   Ielmini D, 2011, IEEE T ELECTRON DEV, V58, P4309, DOI 10.1109/TED.2011.2167513
   Ielmini D, 2009, IEEE T ELECTRON DEV, V56, P1070, DOI 10.1109/TED.2009.2016397
   Ikeda S, 2010, NAT MATER, V9, P721, DOI [10.1038/NMAT2804, 10.1038/nmat2804]
   Indiveri G, 2015, P IEEE, V103, P1379, DOI 10.1109/JPROC.2015.2444094
   Jang JW, 2015, IEEE ELECTR DEVICE L, V36, P457, DOI 10.1109/LED.2015.2418342
   Jo SH, 2010, NANO LETT, V10, P1297, DOI 10.1021/nl904092h
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kau D, 2009, INT EL DEVICES MEET, P571
   Kim H., 2019, ARXIV190710228
   Kim S., 2013, 2013 IEEE INT EL DEV
   Kim S., 2019, 2019 IEEE INT EL DEV
   Kim T, 2018, INT EL DEVICES MEET
   Kumar S, 2017, NATURE, V548, P318, DOI 10.1038/nature23307
   Kuzum D, 2012, NANO LETT, V12, P2179, DOI 10.1021/nl201040y
   Le Gallo M, 2018, IEEE T ELECTRON DEV, V65, P4304, DOI 10.1109/TED.2018.2865352
   Le Gallo M, 2018, NAT ELECTRON, V1, P246, DOI 10.1038/s41928-018-0054-8
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Lee MJ, 2007, INT EL DEVICES MEET, P771, DOI 10.1109/IEDM.2007.4419061
   Lee MJ, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3629
   Li C, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15254-4
   Li C, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04484-2
   Li C, 2018, NAT ELECTRON, V1, P52, DOI 10.1038/s41928-017-0002-z
   Li F, 2004, IEEE T DEVICE MAT RE, V4, P416, DOI 10.1109/TDMR.2004.837118
   Li TK, 2002, JPN J APPL PHYS 1, V41, P6890, DOI 10.1143/JJAP.41.6890
   Liang JL, 2012, IEEE T ELECTRON DEV, V59, P1155, DOI 10.1109/TED.2012.2184542
   Lin YH, 2019, IEEE T ELECTRON DEV, V66, P1289, DOI 10.1109/TED.2019.2894273
   Linn E, 2010, NAT MATER, V9, P403, DOI [10.1038/nmat2748, 10.1038/NMAT2748]
   Liu TY, 2014, IEEE J SOLID-ST CIRC, V49, P140, DOI [10.1109/JSSC.2013.2280296, 10.1109/ISSCC.2013.6487703]
   Mahmoodi MR, 2019, NAT COMMUN, V10, DOI 10.1038/s41467-019-13103-7
   Mahmoodi M.R., 2019, 2019 IEEE INT ELECT
   Malavena G, 2019, IEEE T ELECTRON DEV, V66, P4733, DOI 10.1109/TED.2019.2940599
   Malavena G, 2019, IEEE T ELECTRON DEV, V66, P4727, DOI 10.1109/TED.2019.2940602
   Mantegazza D, 2006, INT EL DEVICES MEET, P519
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Midya R, 2017, ADV MATER, V29, DOI 10.1002/adma.201604457
   Mikolajick T, 2001, MICROELECTRON RELIAB, V41, P947, DOI 10.1016/S0026-2714(01)00049-X
   Milo V, 2019, PROC EUR S-STATE DEV, P174, DOI 10.1109/essderc.2019.8901818
   Milo V, 2019, APL MATER, V7, DOI 10.1063/1.5108650
   Milo V., 2017, 2017 IEEE International Electron Devices Meeting (IEDM), p11.2.1, DOI 10.1109/IEDM.2017.8268369
   MOORE GE, 1965, ELECTRONICS, V38
   Mulaosmanovic H, 2017, ACS APPL MATER INTER, V9, P3792, DOI 10.1021/acsami.6b13866
   Ni K, 2019, NAT ELECTRON, V2, P521, DOI 10.1038/s41928-019-0321-3
   Nirschl T, 2007, INT EL DEVICES MEET, P461, DOI 10.1109/IEDM.2007.4418973
   Oh S, 2018, IEEE ELECTR DEVICE L, V39, P1768, DOI 10.1109/LED.2018.2872434
   Ohno T, 2011, NAT MATER, V10, P591, DOI [10.1038/NMAT3054, 10.1038/nmat3054]
   Pagiamtzis K, 2006, IEEE J SOLID-ST CIRC, V41, P712, DOI 10.1109/JSSC.2005.864128
   Pedretti G, 2017, SCI REP-UK, V7, DOI 10.1038/s41598-017-05480-0
   Pi S, 2019, NAT NANOTECHNOL, V14, P35, DOI 10.1038/s41565-018-0302-0
   Pickett MD, 2013, NAT MATER, V12, P114, DOI [10.1038/NMAT3510, 10.1038/nmat3510]
   Rao MY, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993465
   Raoux S, 2008, IBM J RES DEV, V52, P465, DOI 10.1147/rd.524.0465
   Raoux S, 2010, CHEM REV, V110, P240, DOI 10.1021/cr900040x
   Richter I, 2015, GOV MICR APPL CRIT T
   Romero LP, 2019, FARADAY DISCUSS, V213, P371, DOI 10.1039/c8fd00107c
   Russo U., 2009, IEEE T ELECTRON DEV, V56, P5
   Sakai S, 2008, 2008 JOINT NON-VOLATILE SEMICONDUCTOR MEMORY WORKSHOP AND INTERNATIONAL CONFERENCE ON MEMORY TECHNOLOGY AND DESIGN, PROCEEDINGS, P103, DOI 10.1109/NVSMW.2008.36
   Sakamoto T, 2003, APPL PHYS LETT, V82, P3032, DOI 10.1063/1.1572964
   Sakhare S, 2018, INT EL DEVICES MEET
   Sangkil Kim, 2015, 2015 IEEE MTT-S International Microwave Symposium (IMS2015), P1, DOI 10.1109/MWSYM.2015.7166723
   Sangwan VK, 2018, NATURE, V554, P500, DOI 10.1038/nature25747
   Sangwan VK, 2015, NAT NANOTECHNOL, V10, P403, DOI [10.1038/nnano.2015.56, 10.1038/NNANO.2015.56]
   Sawa A, 2008, MATER TODAY, V11, P28, DOI 10.1016/S1369-7021(08)70119-6
   Serrano-Gotarredona R, 2009, IEEE T NEURAL NETWOR, V20, P1417, DOI 10.1109/TNN.2009.2023653
   Servalli G, 2009, INT EL DEVICES MEET, P103
   Sheridan PM, 2017, NAT NANOTECHNOL, V12, P784, DOI [10.1038/NNANO.2017.83, 10.1038/nnano.2017.83]
   Shin JH, 2018, INT EL DEVICES MEET
   Son M, 2011, IEEE ELECTR DEVICE L, V32, P1579, DOI 10.1109/LED.2011.2163697
   Truong SN, 2014, J SEMICOND TECH SCI, V14, P356, DOI 10.5573/JSTS.2014.14.3.356
   Sun Z, 2020, IEEE T ELECTRON DEV, V67, P1466, DOI 10.1109/TED.2020.2966908
   Sun Z, 2020, SCI ADV, V6, DOI 10.1126/sciadv.aay2378
   Sun Z, 2019, P NATL ACAD SCI USA, V116, P4123, DOI 10.1073/pnas.1815682116
   Sun Z, 2018, ADV MATER, V30, DOI 10.1002/adma.201802554
   Tang JS, 2018, INT EL DEVICES MEET
   Tang MH, 2011, IEEE T ELECTRON DEV, V58, P370, DOI 10.1109/TED.2010.2090883
   Tracy T, 2016, LECT NOTES COMPUT SC, V9697, P200, DOI 10.1007/978-3-319-41321-1_11
   Tsai CL, 2013, ACS NANO, V7, P5360, DOI 10.1021/nn401212p
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/nmat4856, 10.1038/NMAT4856]
   Wang Q., 2019, 2019 IEEE INT EL DEV, p14.4.1
   Wang ZQ, 2020, NAT COMMUN, V11, DOI 10.1038/s41467-020-15158-3
   Wang ZQ, 2015, FRONT NEUROSCI-SWITZ, V8, DOI 10.3389/fnins.2014.00438
   Wang ZR, 2019, NAT MACH INTELL, V1, P434, DOI 10.1038/s42256-019-0089-1
   Wang ZR, 2018, NAT ELECTRON, V1, P137, DOI 10.1038/s41928-018-0023-2
   Wang ZR, 2017, NAT MATER, V16, P101, DOI [10.1038/nmat4756, 10.1038/NMAT4756]
   Waser R, 2007, NAT MATER, V6, P833, DOI 10.1038/nmat2023
   Wong HSP, 2015, NAT NANOTECHNOL, V10, P191, DOI 10.1038/nnano.2015.29
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wong HSP, 2010, P IEEE, V98, P2201, DOI 10.1109/JPROC.2010.2070050
   Woo J., 2013, 2013 S VLSI TECHN VL, P168
   Wootae Lee, 2012, 2012 IEEE Symposium on VLSI Technology, P37, DOI 10.1109/VLSIT.2012.6242449
   Wu T, 2019, 2019 4TH INTERNATIONAL CONFERENCE ON INTELLIGENT GREEN BUILDING AND SMART GRID (IGBSG 2019), P631, DOI 10.1109/IGBSG.2019.8886333
   Xiong F, 2011, SCIENCE, V332, P568, DOI 10.1126/science.1201938
   Yang JJS, 2013, NAT NANOTECHNOL, V8, P13, DOI [10.1038/nnano.2012.240, 10.1038/NNANO.2012.240]
   Yang TJ, 2019, INT EL DEVICES MEET, DOI 10.1109/iedm19573.2019.8993662
   Yao P, 2020, NATURE, V577, P641, DOI 10.1038/s41586-020-1942-4
   Yao P, 2017, NAT COMMUN, V8, DOI 10.1038/ncomms15199
   Yu M, 2016, SCI REP-UK, V6, DOI 10.1038/srep21020
   Yu SM, 2018, P IEEE, V106, P260, DOI 10.1109/JPROC.2018.2790840
   Yu SM, 2013, ACS NANO, V7, P2320, DOI 10.1021/nn305510u
   Zamarreño-Ramos C, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00026
   Zhang ZP, 2015, IEEE ELECTR DEVICE L, V36, P29, DOI 10.1109/LED.2014.2367542
   Zhao M., 2018, 2018 IEEE INT EL DEV, p20.2.1
   Zhou Y, 2019, ADV FUNCT MATER, V29, DOI 10.1002/adfm.201900155
   Zhou Z, 2018, INT EL DEVICES MEET
   Zhu XJ, 2019, NAT MATER, V18, P141, DOI 10.1038/s41563-018-0248-5
   Zidan MA, 2018, NAT ELECTRON, V1, P411, DOI 10.1038/s41928-018-0100-6
   Zidan MA, 2018, NAT ELECTRON, V1, P22, DOI 10.1038/s41928-017-0006-8
NR 187
TC 74
Z9 74
U1 7
U2 74
PD JUL
PY 2020
VL 2
IS 7
AR 2000040
DI 10.1002/aisy.202000040
WC Automation & Control Systems; Computer Science, Artificial Intelligence;
   Robotics
DA 2023-11-11
ER

PT J
AU Rahmani, AM
   Mirmahaleh, SYH
AF Rahmani, Amir Masoud
   Mirmahaleh, Seyedeh Yasaman Hosseini
TI A predictor circuit and a delay-aware algorithm for identifying data
   transfer pattern on NoC-based communication networks
SO MICROELECTRONICS JOURNAL
DT Article
DE Prediction; Processing-in-memory (PIM); Address assignment; Pattern
   recognition; Network-on-Chip (NoC)
ID HIGH-THROUGHPUT; ACCELERATOR; CNN
AB Deploying the Internet of Things and machine learning (ML)-based applications increased processing rate and data transfer between main memory and processing elements (PEs) in NoC-based communication networks, leading to memory access problems. Predicting and identifying reusable data for different tasks can reduce memory accesses and support various applications with high flexibility. Therefore, we propose a method to minimize memory access. It provides a predictor circuit to assign the address for PEs based on data buffering into task cores due to their reusability. We also present a delay-aware algorithm to investigate the initial relationship between tasks and identify a similar pattern for the mapped task graph on the various topologies. Our algorithm and predictor circuit decrease latency for determining related data to tasks and transfers data from global buffer onto PEs and buffers them according to its reusability for tasks with similar patterns. We utilized real data of the reported COVID-19 statistics and particulate matter 2.5 (PM2.5) condensation for evaluating our method. Simulation results demonstrate reducing energy consumption, delay, memory access, and increasing area consumption by approximately 61.83%, 39.96%, 66.66%, and 0.13%, respectively, for the mapped task graphs on a mesh network before employing the circuit and algorithm.
C1 [Rahmani, Amir Masoud] Natl Yunlin Univ Sci & Technol, Future Technol Res Ctr, 123 Univ Rd,Sect 3, Touliu 64002, Yunlin, Taiwan.
   [Mirmahaleh, Seyedeh Yasaman Hosseini] Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
RP Mirmahaleh, SYH (corresponding author), Islamic Azad Univ, Dept Comp Engn, Sci & Res Branch, Tehran, Iran.
EM yasamanhosseini1986@gmail.com
CR Ahmed H., 2019 DES AUT TEST EU
   Do AT, 2019, IEEE T VLSI SYST, V27, P126, DOI 10.1109/TVLSI.2018.2875934
   [Anonymous], 2017 IEEE CUSTOM INT, DOI DOI 10.1109/CICC.2017.7993628
   Catania V, 2016, ACM T MODEL COMPUT S, V27, DOI 10.1145/2953878
   Chen CH, 2019, IEEE T PARALL DISTR, V30, P1738, DOI 10.1109/TPDS.2019.2892957
   Chen KC, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352376
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chen YJ, 2014, INT SYMP MICROARCH, P609, DOI 10.1109/MICRO.2014.58
   Cho K., 2019, 2019 IEEE 28 C EL PE, P1
   Deb D, 2019, IET COMPUT DIGIT TEC, V13, P417, DOI 10.1049/iet-cdt.2019.0035
   Du ZD, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P92, DOI 10.1145/2749469.2750389
   Nguyen DT, 2019, IEEE T VLSI SYST, V27, P1861, DOI 10.1109/TVLSI.2019.2905242
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Guo X., 2017, IEDM, P6
   Hadidi R, 2017, ACM T ARCHIT CODE OP, V14, DOI 10.1145/3155287
   Hayashikoshi M, 2020, IEEE INT MEM WORKSH, P95, DOI 10.1109/imw48823.2020.9108132
   Jeong W.S., 2019, IEEE T PARALLEL DIST, V31
   Jerger Natalie Enright, 2017, ON CHIP NETWORKS, Vsecond, p2ND
   Kang G, 2019, IEEE T VLSI SYST, V27, P1343, DOI 10.1109/TVLSI.2019.2901291
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Kwon H, 2017, INT SYM PERFORM ANAL, P195, DOI 10.1109/ISPASS.2017.7975291
   Lee DY, 2019, IEEE T VLSI SYST, V27, P1450, DOI 10.1109/TVLSI.2019.2891507
   Lian XC, 2019, IEEE T VLSI SYST, V27, P1874, DOI 10.1109/TVLSI.2019.2913958
   Liu DF, 2015, ACM SIGPLAN NOTICES, V50, P369, DOI 10.1145/2694344.2694358
   Mirmahaleh SYH, 2020, J PARALLEL DISTR COM, V144, P80, DOI 10.1016/j.jpdc.2020.04.011
   Mirmahaleh SYH, 2019, PROCEEDINGS OF THE 13TH IEEE/ACM INTERNATIONAL SYMPOSIUM ON NETWORKS-ON-CHIP (NOCS'19), DOI 10.1145/3313231.3352378
   Mirmahaleh SYH, 2019, MICROELECTRON J, V94, DOI 10.1016/j.mejo.2019.104655
   Mochida R, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P175, DOI 10.1109/VLSIT.2018.8510676
   Nabavinejad SM, 2020, IEEE J EM SEL TOP C, V10, P268, DOI 10.1109/JETCAS.2020.3022920
   Peng XC, 2019, IEEE INT SYMP CIRC S
   Sun RD, 2020, IEEE T VLSI SYST, V28, P565, DOI 10.1109/TVLSI.2019.2945982
   Wang Y, 2019, IEEE T PARALL DISTR, V30, P589, DOI 10.1109/TPDS.2018.2868062
   Zhou SJ, 2020, IEEE T PARALL DISTR, V31, P1897, DOI 10.1109/TPDS.2020.2974744
   Zhou SJ, 2019, IEEE T PARALL DISTR, V30, P2249, DOI 10.1109/TPDS.2019.2910068
NR 36
TC 2
Z9 2
U1 1
U2 1
PD OCT
PY 2021
VL 116
AR 105250
DI 10.1016/j.mejo.2021.105250
EA SEP 2021
WC Engineering, Electrical & Electronic; Nanoscience & Nanotechnology
DA 2023-11-11
ER

PT J
AU Higham, NJ
   Pranesh, S
AF Higham, Nicholas J.
   Pranesh, Srikara
TI SIMULATING LOW PRECISION FLOATING-POINT ARITHMETIC
SO SIAM JOURNAL ON SCIENTIFIC COMPUTING
DT Article
DE floating-point arithmetic; half precision; low precision; IEEE
   arithmetic; fp16; bfloat 16; subnormal numbers; mixed precision;
   simulation; rounding error analysis; round to nearest; directed
   rounding; stochastic rounding; bit flips; MATLAB
ID ITERATIVE REFINEMENT; ACCURACY
AB The half-precision (fp16) floating-point format, defined in the 2008 revision of the IEEE standard for floating-point arithmetic, and a more recently proposed half-precision format bfloatl6, are increasingly available in GPUs and other accelerators. While the support for low precision arithmetic is mainly motivated by machine learning applications, general purpose numerical algorithms can benefit from it, too, gaining in speed, energy usage, and reduced communication costs. Since the appropriate hardware is not always available, and one may wish to experiment with new arithmetics not yet implemented in hardware, software simulations of low precision arithmetic are needed. We discuss how to simulate low precision arithmetic using arithmetic of higher precision. We examine the correctness of such simulations and explain via rounding error analysis why a natural method of simulation can provide results that are more accurate than actual computations at low precision. We provide a MATLAB function, chop, that can be used to efficiently simulate fp16, bfloatl6, and other low precision arithmetics, with or without the representation of subnormal numbers and with the options of round to nearest, directed rounding, stochastic rounding, and random bit flips in the significand. We demonstrate the advantages of this approach over defining a new MATLAB class and overloading operators.
C1 [Higham, Nicholas J.; Pranesh, Srikara] Univ Manchester, Sch Math, Manchester M13 9PL, Lancs, England.
RP Higham, NJ (corresponding author), Univ Manchester, Sch Math, Manchester M13 9PL, Lancs, England.
EM nick.higham@manchester.ac.uk; srikara.pranesh@manchester.ac.uk
CR [Anonymous], 2018, ARM ARCH REF MAN ARM
   [Anonymous], 2010, IEEE INT S PARALLEL
   [Anonymous], 1985, 7541985 IEEE ANSI
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2018, P INT C HIGH PERF CO, DOI DOI 10.1109/SC.2018.00050
   Carson E, 2018, SIAM J SCI COMPUT, V40, pA817, DOI 10.1137/17M1140819
   Carson E, 2017, SIAM J SCI COMPUT, V39, pA2834, DOI 10.1137/17M1122918
   Chantry M, 2019, MON WEATHER REV, V147, P645, DOI 10.1175/MWR-D-18-0308.1
   Cox AJ, 1999, BIT, V39, P34, DOI 10.1023/A:1022365107361
   Dawson A, 2018, CLIM DYNAM, V51, P2657, DOI 10.1007/s00382-017-4034-x
   Dawson A, 2017, GEOSCI MODEL DEV, V10, P2221, DOI 10.5194/gmd-10-2221-2017
   Dongarra J., 2014, NUMERICAL COMPUTATIO, P1
   Dutta S., 2019, CODENET TRAINING LAR
   Feldman M., 2018, IBM TAKES AIM REDUCE
   Feldman M., 2018, FUJITSU REVEALS DETA
   Feldman M., RECORD BREAKING EXAS
   Feldman M., INTEL LAYS OUT ROADM
   Figueroa S. A., 1995, SIGNUM Newsletter, V30, P21, DOI 10.1145/221332.221334
   Fousse L, 2007, ACM T MATH SOFTWARE, V33, DOI 10.1145/1236463.1236468
   Haidar A., 2017, P 8 WORKSHOP LATEST, P1
   Haidar A, 2018, LECT NOTES COMPUT SC, V10860, P586, DOI 10.1007/978-3-319-93698-7_45
   Hatfield S, 2018, J ADV MODEL EARTH SY, V10, P2177, DOI 10.1029/2018MS001341
   Higham N. J., MATRIX COMPUTATION T
   Higham N. J., 2002, ACCURACY STABILITY N, DOI [10.1137/1.9780898718027, DOI 10.1137/1.9780898718027]
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA2536, DOI 10.1137/18M1229511
   Higham NJ, 2019, SIAM J SCI COMPUT, V41, pA59, DOI 10.1137/18M1182802
   HIGHAM NJ, 1989, SIAM J NUMER ANAL, V26, P1252, DOI 10.1137/0726070
   HIGHAM NJ, 1993, SIAM J SCI COMPUT, V14, P783, DOI 10.1137/0914050
   Intel Corporation, 2018, CISC VIS NETW IND GL
   Isaacson E., 2012, ANAL NUMERICAL METHO
   Lefèvre V, 2017, P S COMP ARITHM, P18, DOI 10.1109/ARITH.2017.28
   MALONE D, 2013, IRISH MATH SOC B, V71, P59
   Moler C. B., HALF PRECISION 16 BI
   Moler C. B., 1982, CS811 U NEW MEX
   Moler C. B., VARIABLE FORMAT HALF
   Moler C. B., HIST MATLAB USERS GU
   O'uchi S, 2018, IEEE INT SYMP CIRC S, DOI 10.1109/ISCAS.2018.8350953
   Palem K, 2013, ACM T EMBED COMPUT S, V12, DOI 10.1145/2465787.2465789
   Palmer TN, 2014, PHILOS T R SOC A, V372, DOI 10.1098/rsta.2013.0391
   Rao N., CPU GPU WHY ENTERPRI
   Rau C., 2017, IEEE 1 12 IEEE 754 B
   Roux P, 2014, J FORMALIZ REASON, V7, P131
   Rump S.M., 1999, DEV RELIABLE COMPUTI, P77, DOI DOI 10.1007/978-94-017-1247-7
   Rump SM, 2017, ACM T MATH SOFTWARE, V43, DOI 10.1145/2785965
   Rump SM, 2010, ACTA NUMER, V19, P287, DOI 10.1017/S096249291000005X
   Shah V., COMMENT NJ HIGHAM HA
   Svyatkovskiy A., 2017, MLHPC 17, DOI 10.1145/3146347.3146358
   Tagliavini G, 2018, DES AUT TEST EUROPE, P1051, DOI 10.23919/DATE.2018.8342167
   Thornes T, 2017, Q J ROY METEOR SOC, V143, P897, DOI 10.1002/qj.2974
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Wang N., 2018, TRAINING DEEP NEURAL
   Yoon S. H., 2019, 7542019 IEEE, P1, DOI DOI 10.1109/IEEESTD.2019.8766229
   Young M, 2016, CURRICULUM AND THE SPECIALIZATION OF KNOWLEDGE: STUDIES IN THE SOCIOLOGY OF EDUCATION, P3
NR 53
TC 32
Z9 33
U1 0
U2 8
PY 2019
VL 41
IS 5
BP C585
EP C602
DI 10.1137/19M1251308
WC Mathematics, Applied
DA 2023-11-11
ER

PT C
AU Fargo, F
   Franza, O
AF Fargo, Farah
   Franza, Olivier
GP IEEE
TI Autonomic Secure HPC Architecture Against Power Attacks
SO 2018 IEEE/ACS 15TH INTERNATIONAL CONFERENCE ON COMPUTER SYSTEMS AND
   APPLICATIONS (AICCSA)
SE International Conference on Computer Systems and Applications
DT Proceedings Paper
CT 15th IEEE/ACS International Conference on Computer Systems and
   Applications (AICCSA)
CY OCT 28-NOV 01, 2018
CL Aqaba, JORDAN
DE High Performance Computing; Autonomic Computing; Security; Data
   Analytics; Power Attacks; Intrusion Detection System; Anomaly Behavior
   Analysis
AB High Performance Computing (HPC) systems are enabling broad computing capabilities across scientific simulations, data analytics, and machine learning. Such HPC systems are composed of high-end compute elements (CPUs, accelerators, co-processors...) to handle high throughput and high parallelism, which results in significant power consumption. However, the power infrastructures built for such systems are proportionately older and may not be built to sustain system's peak power for extensive periods of time. Therefore, innovative power management schemes are used to allocate power across all system's components within a given power limit. HPC power management systems regulate resources' power within budget constraints and the overall system's power limit. Failing not to limit system's power consumption can result in operational failures that can bring down the whole system. Additionally, system reliability would be compromised under extensive computational system power and temperature. In addition to power consumption, possible attack scenarios can cause reliability issues where the attackers can manipulate the reported data of the measured power that is used for power management, which in turn can misguide the schedulers or can assign tasks that will result in exceeding the power limits, leading to system failures. Hence, intrusion detection systems (IDS) for power attacks are extremely important. This paper presents a framework for power attack IDS and describe each steps to be taken.
C1 [Fargo, Farah; Franza, Olivier] Intel Corp, Hudson, MA 01749 USA.
RP Fargo, F (corresponding author), Intel Corp, Hudson, MA 01749 USA.
EM farah.e.fargo@intel.com; olivier.franza@intel.com
CR [Anonymous], 4 ANN INT C MOB UB S
   Can O, 2015, INT CONF MODEL SIM
   Cohen W. W., 1995, Machine Learning. Proceedings of the Twelfth International Conference on Machine Learning, P115
   Fargo F., 2014, INT C CLOUD AUT COMP
   Fargo F., 2014, IEEE INT C CLOUD AUT
   Greengard S, 2016, COMMUN ACM, V59, P29, DOI 10.1145/2898969
   Padmavathi G., 2013, INT J NETWORK SECURI, V15, P391
   Pan Z., 2014, IEEE ACS 11 INT C CO
   Pan ZW, 2016, I C COMP SYST APPLIC
   Qu Guangzhi, 2005, IEEE T KNOWLEDGE DAT, V17
   RISTENPART T., P ACM CCS 09, P199
   Rowland C. H., 2002, U.S. Patent, Patent No. [6 405 318, 6405318, 6, 405, 318]
NR 12
TC 0
Z9 0
U1 0
U2 0
PY 2018
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Sun, XY
   Peng, XC
   Chen, PY
   Liu, R
   Seo, JS
   Yu, SM
AF Sun, Xiaoyu
   Peng, Xiaochen
   Chen, Pai-Yu
   Liu, Rui
   Seo, Jae-sun
   Yu, Shimeng
GP IEEE
TI Fully Parallel RRAM Synaptic Array for Implementing Binary Neural
   Network with (+1,-1) Weights and (+1,0) Neurons
SO 2018 23RD ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC)
SE Asia and South Pacific Design Automation Conference Proceedings
DT Proceedings Paper
CT 23rd Asia and South Pacific Design Automation Conference (ASP-DAC)
CY JAN 22-25, 2018
CL Jeju, SOUTH KOREA
AB Binary Neural Networks (BNNs) have been recently proposed to improve the area-/energy-efficiency of the machine/deep learning hardware accelerators, which opens an opportunity to use the technologically more mature binary RRAM devices to effectively implement the binary synaptic weights. In addition, the binary neuron activation enables using the sense amplifier instead of the analog-to-digital converter to allow bitwise communication between layers of the neural networks. However, the sense amplifier has intrinsic offset that affects the threshold of binary neuron, thus it may degrade the classification accuracy. In this work, we analyze a fully parallel RRAM synaptic array architecture that implements the fully connected layers in a convolutional neural network with (+1, -1) weights and (+1, 0) neurons. The simulation results with TSMC 65 nm PDK show that the offset of current mode sense amplifier introduces a slight accuracy loss from similar to 98.5% to similar to 97.6% for MNIST dataset. Nevertheless, the proposed fully parallel BNN architecture (P-BNN) can achieve 137.35 TOPS/W energy efficiency for the inference, improved by similar to 20X compared to the sequential BNN architecture (S-BNN) with row-by-row read-out scheme. Moreover, the proposed P-BNN architecture can save the chip area by similar to 16% as it eliminates the area overhead of MAC peripheral units in the S-BNN architecture.
C1 [Sun, Xiaoyu; Peng, Xiaochen; Chen, Pai-Yu; Liu, Rui; Seo, Jae-sun; Yu, Shimeng] Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
RP Yu, SM (corresponding author), Arizona State Univ, Sch Elect Comp & Energy Engn, Tempe, AZ 85281 USA.
EM shimengy@asu.edu
CR [Anonymous], 2016, ARXIV160305279
   Burr G. W, 2014, IEEE IEDM
   Chang M.-F., 2012, IEEE ICSICT
   Chang MF, 2013, IEEE J SOLID-ST CIRC, V48, P864, DOI 10.1109/JSSC.2012.2235013
   Chen P.-Y., 2015, ACM IEEE ICCAD
   Chen  Y.-H., 2016, IEEE ISSCC
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Fackenthal R., 2014, IEEE ISSCC
   Hu M, 2014, IEEE T NEUR NET LEAR, V25, P1864, DOI 10.1109/TNNLS.2013.2296777
   Krizhevsky A, 2012, NIPS, P1097
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li B., 2015, ACM IEEE DAC
   Park S., 2013, IEEE IEDM
   Tang  T., 2017, ACM IEEE ASP DAC
   Yu  S., 2016, IEEE IEDM
NR 16
TC 57
Z9 60
U1 1
U2 15
PY 2018
BP 574
EP 579
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Colangelo, P
   Segal, O
   Speicher, A
   Margala, M
AF Colangelo, Philip
   Segal, Oren
   Speicher, Alex
   Margala, Martin
GP IEEE
TI Automated Hardware and Neural Network Architecture co-design of FPGA
   accelerators using multi-objective Neural Architecture Search
SO 2020 IEEE 10TH INTERNATIONAL CONFERENCE ON CONSUMER ELECTRONICS
   (ICCE-BERLIN)
SE International Conference on Consumer Electronics
DT Proceedings Paper
CT 10th IEEE International Conference on Consumer Electronics (ICCE-Berlin)
CY NOV 09-11, 2020
CL Berlin, GERMANY
DE Evolutionary Algorithms; Machine Learning; FPGA; Automated Design
AB State-of-the-art Neural Network Architectures (NNAs) are challenging to design and implement efficiently in hardware. In the past couple of years, this has led to an explosion in research and development of automatic Neural Architecture Search (NAS) tools. AutoML tools are now used to achieve state of the art NNA designs and attempt to optimize for hardware usage and design. Much of the recent research in the auto-design of NNAs has focused on convolution networks and image recognition, ignoring the fact that a significant part of the workload in data centers is general-purpose deep neural networks. In this work, we develop and test a general multilayer perceptron (MLP) flow that can take arbitrary datasets as input and automatically produce optimized NNAs and hardware designs. We test the flow on six benchmarks. Our results show we exceed the performance of currently published MLP accuracy results and are competitive with non-MLP based results. We compare general and common GPU architectures with our scalable FPGA design and show we can achieve higher efficiency and higher throughput (outputs per second) for the majority of datasets. Further insights into the design space for both accurate networks and high performing hardware shows the power of co-design by correlating accuracy versus throughput, network size versus accuracy, and scaling to high-performance devices.
C1 [Colangelo, Philip] Intel PSG, San Jose, CA 95134 USA.
   [Segal, Oren; Speicher, Alex] Hofstra Univ, Hempstead, NY 11550 USA.
   [Margala, Martin] Univ Massachusetts Lowell, Lowell, MA USA.
RP Colangelo, P (corresponding author), Intel PSG, San Jose, CA 95134 USA.
EM philip.colangelo@intel.com; oren.segal@hofstra.edu;
   aspeicher1@pride.hofstra.edu; Martin_Margala@uml.edu
CR [Anonymous], 2017, CORR ABS170807747
   [Anonymous], 2018, ARXIV PREPRINT ARXIV
   Burges, 2010, MNIST HANDWRITTEN DI, DOI DOI 10.1561/2400000035
   Colangelo P, 2019, IEEE HIGH PERF EXTR
   Culurciello E., 2016, ARXIV PREPRINT ARXIV
   Fernando C., 2017, ARXIV PREPRINT ARXIV
   GOLD D, 1991, CONFERENCE RECORD OF THE TWENTY-FIFTH ASILOMAR CONFERENCE ON SIGNALS, SYSTEMS & COMPUTERS, VOLS 1 AND 2, P69, DOI 10.1109/ACSSC.1991.186416
   Hazelwood K, 2018, INT S HIGH PERF COMP, P620, DOI 10.1109/HPCA.2018.00059
   Jouppi NP, 2018, IEEE MICRO, V38, P10, DOI 10.1109/MM.2018.032271057
   Kohavi R., 1995, IJCAI-95. Proceedings of the Fourteenth International Joint Conference on Artificial Intelligence, P1137
   MILLER GF, 1989, PROCEEDINGS OF THE THIRD INTERNATIONAL CONFERENCE ON GENETIC ALGORITHMS, P379
   Park J., 2018, ARXIV PREPRINT ARXIV
   Real E., 2017, LARGE SCALE EVOLUTIO
   Real E, 2019, AAAI CONF ARTIF INTE, P4780
   Stanley KO, 2002, EVOL COMPUT, V10, P99, DOI 10.1162/106365602320169811
   Vanschoren J., 2014, SIGKDD EXPLORATIONS, V15, P49, DOI [10.1145/2641190.2641198, DOI 10.1145/2641190.2641198]
   Venieris SI, 2018, ACM COMPUT SURV, V51, DOI 10.1145/3186332
   Vishwanath A., 2016, CISC VIS NETW IND GL
   Wu CJ, 2019, INT S HIGH PERF COMP, P331, DOI 10.1109/HPCA.2019.00048
   Zoph B, 2018, PROC CVPR IEEE, P8697, DOI 10.1109/CVPR.2018.00907
NR 20
TC 0
Z9 0
U1 0
U2 0
PY 2020
DI 10.1109/ICCE-Berlin50680.2020.9352153
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Fawzi, H
   Goulbourne, H
AF Fawzi, Hamza
   Goulbourne, Harry
BE Ranzato, M
   Beygelzimer, A
   Dauphin, Y
   Liang, PS
   Vaughan, JW
TI Faster proximal algorithms for matrix optimization using Jacobi-based
   eigenvalue methods
SO ADVANCES IN NEURAL INFORMATION PROCESSING SYSTEMS 34 (NEURIPS 2021)
SE Advances in Neural Information Processing Systems
DT Proceedings Paper
CT 35th Conference on Neural Information Processing Systems (NeurIPS)
CY DEC 06-14, 2021
CL ELECTR NETWORK
ID THRESHOLDING ALGORITHM; SEMIDEFINITE; CONVERGENCE
AB We consider proximal splitting algorithms for convex optimization problems over matrices. A significant computational bottleneck in many of these algorithms is the need to compute a full eigenvalue or singular value decomposition at each iteration for the evaluation of a proximal operator.
   In this paper we propose to use an old and surprisingly simple method due to Jacobi to compute these eigenvalue and singular value decompositions, and we demonstrate that it can lead to substantial gains in terms of computation time compared to standard approaches. We rely on three essential properties of this method: (a) its ability to exploit an approximate decomposition as an initial point, which in the case of iterative optimization algorithms can be obtained from the previous iterate; (b) its parallel nature which makes it a great fit for hardware accelerators such as GPUs, now common in machine learning, and (c) its simple termination criterion which allows us to trade-off accuracy with computation time. We demonstrate the efficacy of this approach on a variety of algorithms and problems, and show that, on a GPU, we can obtain 5 to 10x speed-ups in the evaluation of proximal operators compared to standard CPU or GPU linear algebra routines. Our findings are supported by new theoretical results providing guarantees on the approximation quality of proximal operators obtained using approximate eigenvalue or singular value decompositions.
C1 [Fawzi, Hamza; Goulbourne, Harry] Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge, England.
RP Fawzi, H (corresponding author), Univ Cambridge, Dept Appl Math & Theoret Phys, Cambridge, England.
EM hf323@cam.ac.uk; hmg42@cam.ac.uk
CR [Anonymous], J REINE ANGEW MATH, DOI DOI 10.1515/CR11.1846.30.51
   Bandeira A. S., 2016, P 29 C LEARNING THEO, V49, P361
   Barre Mathieu, 2020, ARXIV200606041
   Beck A, 2009, SIAM J IMAGING SCI, V2, P183, DOI 10.1137/080716542
   Ben-Tal A., 2001, LECT MODERN CONVEX O
   Boyd Stephen, 2010, Foundations and Trends in Machine Learning, V3, P1, DOI 10.1561/2200000016
   Burer S, 2003, MATH PROGRAM, V95, P329, DOI 10.1007/s10107-002-0352-8
   Cai JF, 2010, SIAM J OPTIMIZ, V20, P1956, DOI 10.1137/080738970
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Chao HH, 2018, IEEE T SIGNAL PROCES, V66, P4826, DOI 10.1109/TSP.2018.2862399
   Davis C., 1957, ARCH MATH, V8, P276, DOI [10.1007/BF01898787, DOI 10.1007/BF01898787]
   ECKSTEIN J, 1992, MATH PROGRAM, V55, P293, DOI 10.1007/BF01581204
   Forsythe G. E., 1960, T AM MATH SOC, V94, P1, DOI DOI 10.1090/S0002-9947-1960-0109825-2
   Friedman J, 2008, BIOSTATISTICS, V9, P432, DOI 10.1093/biostatistics/kxm045
   Fukuda M., 2000, SIAM Journal on Optimization, V11, P647, DOI 10.1137/S1052623400366218
   Golub G.H., 2013, MATRIX COMPUTATIONS, V4th ed., DOI DOI 10.56021/9781421407944
   Goulart PJ, 2020, LINEAR ALGEBRA APPL, V594, P177, DOI 10.1016/j.laa.2020.02.014
   Halko N, 2011, SIAM REV, V53, P217, DOI 10.1137/090771806
   Harris CR, 2020, NATURE, V585, P357, DOI 10.1038/s41586-020-2649-2
   Helmberg C, 2000, SIAM J OPTIMIZ, V10, P673, DOI 10.1137/S1052623497328987
   Jiang Xin, 2021, BREGMAN PRIMAL DUAL
   Knyazev AV, 2001, SIAM J SCI COMPUT, V23, P517, DOI 10.1137/S1064827500366124
   Lanckriet GRG, 2004, J MACH LEARN RES, V5, P27
   LEWIS A. S., 1995, J CONVEX ANAL, V2, P173
   Madani R, 2015, IEEE DECIS CONTR P, P5932, DOI 10.1109/CDC.2015.7403152
   Marshall Albert W, 1979, INEQUALITIES THEORY, V143
   Nesterov Yurii, 2003, INTRO LECT CONVEX OP, V87
   NVIDIA, 2020, CUS LIB
   O'Donoghue B, 2016, J OPTIMIZ THEORY APP, V169, P1042, DOI 10.1007/s10957-016-0892-3
   ODonoghue B., 2019, SCS SPLITTING CONIC
   Okuta R., 2017, P WORKSHOP MACHINE L
   Parikh Neal, 2014, Foundations and Trends in Optimization, V1, P127, DOI 10.1561/2400000003
   Recht B, 2010, SIAM REV, V52, P471, DOI 10.1137/070697835
   Renegar James, 2014, ARXIV14095832
   Rontsis Nikitas, 2019, ARXIV191202767
   Scheinberg Katya, 2010, ARXIV10110097
   Schmidt M., 2011, NEURAL INFORM PROCES, P415
   Schonhage A, 1964, NUMERISCHE MATH
   Trefethen L.N, 2000, NUMERICAL LINEAR ALG
   VANKEMPEN HP, 1966, NUMER MATH, V9, P19, DOI 10.1007/BF02165225
   VANKEMPEN HP, 1966, NUMER MATH, V9, P11, DOI 10.1007/BF02165224
   Wilkinson J. H., 1962, NUMER MATH, V4, P296, DOI [10.1007/BF01386321, DOI 10.1007/BF01386321]
   Yao W., 2016, THESIS TU MUNCHEN
   Yurtsever A, 2021, SIAM J MATH DATA SCI, V3, P171, DOI 10.1137/19M1305045
   ZHENG C, 2006, P 23 INT C MACH LEAR, P89
   Zheng Y, 2020, MATH PROGRAM, V180, P489, DOI 10.1007/s10107-019-01366-3
NR 46
TC 0
Z9 0
U1 0
U2 0
PY 2021
VL 34
WC Computer Science, Artificial Intelligence
DA 2023-11-11
ER

PT C
AU Khandelwal, A
   Kejariwal, A
   Ramasamy, K
AF Khandelwal, Anurag
   Kejariwal, Arun
   Ramasamy, Karthikeyan
GP Assoc Comp Machinery
TI <i>Le Taureau</i>: Deconstructing the Serverless Landscape & A Look
   Forward
SO SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE
   ON MANAGEMENT OF DATA
DT Proceedings Paper
CT ACM SIGMOD International Conference on Management of Data (SIGMOD)
CY JUN 14-19, 2020
CL ELECTR NETWORK
AB Akin to the natural evolution of programming in assembly language to high-level languages, serverless computing represents the next frontier in the evolution of cloud computing: bare metal. virtual machines. containers. serverless. The genesis of serverless computing can be traced back to the fundamental need of enabling a programmer to singularly focus on writing application code in a high-level language and isolating all facets of system management (for example, but not limited to, instance selection, scaling, deployment, logging, monitoring, fault tolerance and so on). This is particularly critical in light of today's, increasingly tightening, time-to-market constraints. Currently, serverless computing is supported by leading public cloud vendors, such as AWS Lambda, Google Cloud Functions, Azure Cloud Functions and others. While this is an important step in the right direction, there are many challenges going forward. For instance, but not limited to, how to enable support for dynamic optimization, how to extend support for stateful computation, how to efficiently bin-pack applications, how to support hardware heterogeneity (this will be key especially in light of the emergence of hardware accelerators for deep learning workloads).
   Inspired by Picasso's Le Taureau(1), in the tutorial proposed herein, we shall deconstruct evolution of serverless the overarching intent being to facilitate better understanding of the serverless landscape. This, we hope, would help push the innovation frontier on both fronts, the paradigm itself and the applications built atop of it.
C1 [Khandelwal, Anurag] Yale Univ, New Haven, CT 06520 USA.
   [Kejariwal, Arun] Facebook Inc, Menlo Pk, CA USA.
   [Ramasamy, Karthikeyan] Splunk Inc, San Francisco, CA USA.
RP Khandelwal, A (corresponding author), Yale Univ, New Haven, CT 06520 USA.
CR Akkus IE, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P923
   Anil R., 2018, COMPUTING RES REPOSI
   [Anonymous], DATA STREAMS MODELS
   [Anonymous], 2019, IEEE T MED IMAGING, DOI DOI 10.1109/TMI.2018.2867261
   [Anonymous], 2017, GOOGLE
   [Anonymous], 2016, 8 USENIX WORKSH HOT
   [Anonymous], 2018, SERVERLESS ARCHITECT
   [Anonymous], 2018, SERVERLESS COMMUNITY
   Ao LX, 2018, PROCEEDINGS OF THE 2018 ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '18), P263, DOI 10.1145/3267809.3267815
   Arik S. O., 2017, P INT C MACH LEARN
   Aytekin A, 2019, IEEE INT CONF CLOUD, P499, DOI 10.1109/CLOUD.2019.00090
   Banerjee S., 2019, COMPUTING RES REPOSI
   Bugnion E, 1997, ACM T COMPUT SYST, V15, P412, DOI 10.1145/269005.266672
   Cai H, 2017, WSDM'17: PROCEEDINGS OF THE TENTH ACM INTERNATIONAL CONFERENCE ON WEB SEARCH AND DATA MINING, P661, DOI 10.1145/3018661.3018702
   Carreira J, 2019, PROCEEDINGS OF THE 2019 TENTH ACM SYMPOSIUM ON CLOUD COMPUTING (SOCC '19), P13, DOI 10.1145/3357223.3362711
   Carter J. B., 1995, Proceedings Fifth Workshop on Hot Topics in Operating Systems (HotOS-V) (Cat. No.95TH8059), P119, DOI 10.1109/HOTOS.1995.513466
   Castro M., P S NETW SYST DES IM
   Castro P, 2019, COMMUN ACM, V62, P44, DOI 10.1145/3368454
   Chard R., 2019, ABS190804907 CORR
   Chen X., 2017, COMPUTING RES REPOSI
   Choi S., 2019, COMPUTING RES REPOSI
   Cormode G, 2005, J ALGORITHMS, V55, P58, DOI 10.1016/j.jalgor.2003.12.001
   Cormode G., 2007, REFERENCES DATA STRE
   CREASY RJ, 1981, IBM J RES DEV, V25, P483, DOI 10.1147/rd.255.0483
   DASGUPTA P, 1991, COMPUTER, V24, P34, DOI 10.1109/2.116849
   Dean J., 2012, P C NEUR INF PROC SY
   Falkner S., 2018, COMPUTING RES REPOSI
   Feng L, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P334, DOI 10.1109/CLOUD.2018.00049
   Figiela K., 2017, FUTURE GENER COMP SY
   Fingler H, 2019, APSYS'19: PROCEEDINGS OF THE 10TH ACM SIGOPS ASIA-PACIFIC WORKSHOP ON SYSTEMS, P23, DOI 10.1145/3343737.3343750
   Fouladi S, 2017, PROCEEDINGS OF NSDI '17: 14TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P363
   Gabbrielli M., 2019, COMPUTING RES REPOSI
   Gafni O., 2019, COMPUTING RES REPOSI
   López PG, 2018, INT CONF UTIL CLOUD, P148, DOI 10.1109/UCC-Companion.2018.00049
   Garcia-Lopez P, 2019, SERVERMIX TRADEOFFS
   Goldreich O, 1996, J ACM, V43, P431, DOI 10.1145/233551.233553
   Gomes HM, 2017, ACM COMPUT SURV, V50, DOI 10.1145/3054925
   Gray Cary, 1989, LEASES EFFICIENT FAU, V23
   Hall A, 2019, PROCEEDINGS OF THE 2019 INTERNATIONAL CONFERENCE ON INTERNET OF THINGS DESIGN AND IMPLEMENTATION (IOTDI '19), P225, DOI 10.1145/3302505.3310084
   Hellerstein J. M., 2018, ARXIV181203651
   Hung L.H., 2018, COMPUTING RES REPOSI
   Hung L.-H., 2019, BIORXIV
   Hunt Patrick, 2010, USENIX TECHN C ATC
   Isard M., 2007, Operating Systems Review, V41, P59, DOI 10.1145/1272998.1273005
   Ivanov V., 2019, COMPUTING RES REPOSI
   Jangda A, 2019, P ACM PROGRAM LANG, V3, DOI 10.1145/3360575
   Jonas E, 2017, PROCEEDINGS OF THE 2017 SYMPOSIUM ON CLOUD COMPUTING (SOCC '17), P445, DOI 10.1145/3127479.3128601
   Joy T. T., 2019, COMPUTING RES REPOSI
   Joyner S., 2020, COMPUTING RES REPOSI
   JUL E, 1988, ACM T COMPUT SYST, V6, P109, DOI 10.1145/35037.42182
   Karsai G., 2019, COMPUTING RES REPOSI
   Kavukcuoglu K., 2015, COMPUTING RES REPOSI
   Kawaguchi K, 2019, NEURAL COMPUT, V31, P1462, DOI 10.1162/neco_a_01195
   Kejariwal A., 2017, COMPUTING RES REPOSI
   Khalid J, 2018, PROCEEDINGS OF THE 15TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI'18), P313
   Kim Y, 2018, PROCEEDINGS 2018 IEEE 11TH INTERNATIONAL CONFERENCE ON CLOUD COMPUTING (CLOUD), P451, DOI 10.1109/CLOUD.2018.00063
   Kjerrumgaard D., 2018, REAL TIME ANAL PULSA
   Klimovic A, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P789
   Klimovic A, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P427
   Koller R, 2017, PROCEEDINGS OF THE 16TH WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS 2017), P169, DOI 10.1145/3102980.3103008
   Konecny J., 2016, COMPUTING RES REPOSI
   Król M, 2017, PROCEEDINGS OF THE 4TH ACM CONFERENCE ON INFORMATION-CENTRIC NETWORKING (ICN 2017), P134, DOI 10.1145/3125719.3125727
   Lazar D, 2019, PROCEEDINGS OF THE TWENTY-SEVENTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '19), P211, DOI 10.1145/3341301.3359648
   Lee BD, 2019, NUCLEIC ACIDS RES, V47, pW20, DOI 10.1093/nar/gkz404
   Lee K, 2018, IEEE T INFORM THEORY, V64, P1514, DOI 10.1109/TIT.2017.2736066
   Li K., 1988, Proceedings of the 1988 International Conference on Parallel Processing, P94
   Li L., 2018, COMPUTING RES REPOSI
   Lim H., 2014, S NETWORKED SYSTEMS, P429
   Lin W, 2016, 13TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION (NSDI '16), P439
   Madhavapeddy A, 2013, ACM SIGPLAN NOTICES, V48, P461, DOI 10.1145/2499368.2451167
   Malewicz Grzegorz, 2010, P 2010 ACM SIGMOD IN, P135, DOI [10.1145/1807167.1807184, DOI 10.1145/1807167, DOI 10.1145/1582716.1582723, DOI 10.1145/1807167.1807184]
   Manco F, 2017, PROCEEDINGS OF THE TWENTY-SIXTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES (SOSP '17), P218, DOI 10.1145/3132747.3132763
   McGregor A, 2014, SIGMOD REC, V43, P9, DOI 10.1145/2627692.2627694
   mei Hwu W., 2018, COMPUTING RES REPOSI
   Mirzasoleiman B., 2019, COMPUTING RES REPOSI
   Moritz P, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P561
   Muthukrishnan S, 2005, FOUND TRENDS THEOR C, V1, P1, DOI 10.1561/0400000002
   Niu XZ, 2019, ACM-BCB'19: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL CONFERENCE ON BIOINFORMATICS, COMPUTATIONAL BIOLOGY AND HEALTH INFORMATICS, P683, DOI 10.1145/3307339.3343465
   Ousterhout J., 2010, ACM SIGOPS OPERAT SY, V43, P92, DOI DOI 10.1145/1713254.1713276
   Passwater Andrea, 2018, 2018 SERVERLESS COMM
   PHILLIPS JM, 2016, COMPUTING RES REPOSI
   Picasso P., 1946, TAUREAU
   Ping W., 2017, COMPUTING RES REPOSI
   Pinto D., 2018, COMPUTING RES REPOSI
   Popek Gerald, 1989, MIRAGE COHERENT DIST, V23
   Pu QF, 2019, PROCEEDINGS OF THE 16TH USENIX SYMPOSIUM ON NETWORKED SYSTEMS DESIGN AND IMPLEMENTATION, P193
   Quick L, 2012, 2012 IEEE/ACM INTERNATIONAL CONFERENCE ON ADVANCES IN SOCIAL NETWORKS ANALYSIS AND MINING (ASONAM), P457, DOI 10.1109/ASONAM.2012.254
   Ramchandran K., 2019, P 36 INT C MACH LEAR
   Rhodes L., 2019, COMPUTING RES REPOSI
   Sampé J, 2018, MIDDLEWARE INDUSTRY'18: PROCEEDINGS OF THE 2018 ACM/IFIP/USENIX MIDDLEWARE CONFERENCE (INDUSTRIAL TRACK), P1, DOI 10.1145/3284028.3284029
   Sanada T., 2019, COMPUTING RES REPOSI
   Seaborn M., EXPLOITING DRAM ROWH
   Shankar V., 2019, TECHNICAL REPORT UCB
   Shen ZM, 2019, TWENTY-FOURTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXIV), P121, DOI 10.1145/3297858.3304016
   Sievert S., 2019, BETTER FASTER HYPERP
   Silva JA, 2013, ACM COMPUT SURV, V46, DOI 10.1145/2522968.2522981
   Sivasubramanian S., 2012, P ACM SIGMOD INT C M, P729, DOI [DOI 10.1145/2213836.2213945, 10.1145/2213836.2213945]
   Slominski A., 2017, COMPUTING RES REPOSI
   Soltesz S., 2007, Operating Systems Review, V41, P275, DOI 10.1145/1272998.1273025
   Sreekanti V., 2020, COMPUTING RES REPOSI
   Stefanov E., 2013, CCS
   STRASSEN V, 1969, NUMER MATH, V13, P354, DOI 10.1007/BF02165411
   Sun S., 2015, COMPUTING RES REPOSI
   Sun X., 2018, COMPUTING RES REPOSI
   Sundaram N, 2015, PROC VLDB ENDOW, V8, P1214, DOI 10.14778/2809974.2809983
   Toader L, 2019, INT SYMP PARA DISTR, P66, DOI 10.1109/ISPDC.2019.00012
   Uta A, 2018, IEEE INT C CL COMP, P381, DOI 10.1109/CLUSTER.2018.00056
   van den Hooff J, 2015, SOSP'15: PROCEEDINGS OF THE TWENTY-FIFTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P137, DOI 10.1145/2815400.2815417
   van Eyk E, 2018, IEEE INTERNET COMPUT, V22, P8, DOI 10.1109/MIC.2018.053681358
   Verma Abhishek, 2015, PARKINSONS DIS-US
   Vershynin R., 2018, P C NEUR INF PROC SY
   Wagner T., 2019, SERVERLESS NETWORKIN
   Wang L, 2018, PROCEEDINGS OF THE 2018 USENIX ANNUAL TECHNICAL CONFERENCE, P133
   Werner S, 2018, IEEE INT CONF BIG DA, P358, DOI 10.1109/BigData.2018.8622362
   Wolski R, 2019, SEC'19: PROCEEDINGS OF THE 4TH ACM/IEEE SYMPOSIUM ON EDGE COMPUTING, P236, DOI 10.1145/3318216.3363314
   Xiong Z., 2018, COMPUTING RES REPOSI
   Yan MT, 2016, FIRST INTERNATIONAL WORKSHOP ON MASHUPS OF THINGS AND APIS (MOTA), DOI 10.1145/3007203.3007217
   Zaharia M, 2013, SOSP'13: PROCEEDINGS OF THE TWENTY-FOURTH ACM SYMPOSIUM ON OPERATING SYSTEMS PRINCIPLES, P423, DOI 10.1145/2517349.2522737
   Zhang M, 2019, PROCEEDINGS OF THE 29TH ACM WORKSHOP ON NETWORK AND OPERATING SYSTEMS SUPPORT FOR DIGITAL AUDIO AND VIDEO (NOSSDAV'19), P61, DOI 10.1145/3304112.3325608
   Zhang M, 2019, IEEE INT CONF CLOUD, P404, DOI 10.1109/CLOUD.2019.00071
   Zhao J, 2018, KDD'18: PROCEEDINGS OF THE 24TH ACM SIGKDD INTERNATIONAL CONFERENCE ON KNOWLEDGE DISCOVERY & DATA MINING, P1021, DOI 10.1145/3219819.3219918
   Zhong C., 2019, COMPUTING RES REPOSI
NR 122
TC 8
Z9 8
U1 0
U2 2
PY 2020
BP 2641
EP 2650
DI 10.1145/3318464.3383130
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT J
AU Zhang, Y
   Zhang, F
   Jin, ZM
   Bakos, JD
AF Zhang, Yan
   Zhang, Fan
   Jin, Zheming
   Bakos, Jason D.
TI An FPGA-Based Accelerator for Frequent Itemset Mining
SO ACM TRANSACTIONS ON RECONFIGURABLE TECHNOLOGY AND SYSTEMS
DT Article
DE Performance; Frequent itemset mining; data mining; Eclat; data
   intensive; co-processor; high performance computing; reconfigurable
   applications; reconfigurable
ID PATTERNS
AB In this article we describe a Field Programmable Gate Array (FPGA)-based coprocessor architecture for Frequent Itemset Mining (FIM). FIM is a common data mining task used to find frequently occurring subsets amongst a database of sets. FIM is a nonnumerical, data intensive computation and is used in machine learning and computational biology. FIM is particularly expensive-in terms of execution time and memory-when performed on large and/or sparse databases or when applied using a low appearance frequency threshold. Because of this, the development of increasingly efficient FIM algorithms and their mapping to parallel architectures is an active field. Previous attempts to accelerate FIM using FPGAs have relied on performance-limiting strategies such as iterative database loading and runtime logic unit reconfiguration. In this article, we present a novel architecture to implement Eclat, a well-known FIM algorithm. Unlike previous efforts, our technique does not impose limits on the maximum set size as a function of available FPGA logic resources and our design scales well to multiple FPGAs. In addition to a novel hardware design, we also present a corresponding compression scheme for intermediate results that are stored in on-chip memory. On a four-FPGA board, experimental results show up to 68X speedup compared to a highly optimized software implementation.
C1 [Zhang, Yan; Zhang, Fan; Jin, Zheming; Bakos, Jason D.] Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
RP Zhang, Y (corresponding author), Univ S Carolina, Dept Comp Sci & Engn, Columbia, SC 29208 USA.
EM jbakos@cse.sc.edu
CR Alachiotis N., 2011, P IEEE S FIELD PROGR
   [Anonymous], 1994, P 20 INT C VER LARG
   [Anonymous], 2003, FIMI
   [Anonymous], 1993, PROC 1993 ACM SIGMOD
   BAKER Z, 2006, P IEEE S FIELD PROGR
   Baker ZK, 2005, ANN IEEE SYM FIELD P, P3
   Bodon F, 2003, MATH COMPUT MODEL, V38, P739, DOI [10.1016/0895-7177(03)90058-6, 10.1016/S0895-7177(03)00275-9]
   Bodon F., 2006, SURVEY FREQUENT ITEM
   BORGELT C., 2003, P IEEE ICDM WORKSH F
   FIMI Repository, 2003, FREQ IT MIN DAT REP
   Fukuzaki M, 2010, LECT NOTES ARTIF INT, V6119, P147
   Gidel Ltd, 2009, PROSTAR3 DAT BOOK VE
   GOETHALS B, 2003, P IEEE ICDM WORKSH F
   GOETHALS B, 2002, SURVEY FREQUENT PATT
   Han JW, 2000, SIGMOD RECORD, V29, P1
   Heighton J., 2006, P C EXH DES AUT TEST
   IBM, 2012, IBM SYNTH DAT GEN
   Park JS, 1997, IEEE T KNOWL DATA EN, V9, P813, DOI 10.1109/69.634757
   Sun S., 2008, P INT C REC COMP FPG
   Sun S, 2011, IEEE T PARALL DISTR, V22, P1497, DOI 10.1109/TPDS.2011.34
   Thoni D. W., 2009, P INT C FIELD PROGR
   Wen YH, 2008, IEEE T KNOWL DATA EN, V20, P784, DOI 10.1109/TKDE.2008.39
   Witten I.H., 2005, DATA MINING PRACTICA, P27
   Zaki MJ, 2000, IEEE T KNOWL DATA EN, V12, P372, DOI 10.1109/69.846291
   Zhang Y, 2011, IEEE INT C CL COMP, P585, DOI 10.1109/CLUSTER.2011.69
   Zhou L., 2008, IEEE T COMPUT, V57, P12
NR 26
TC 20
Z9 20
U1 0
U2 15
PD MAY
PY 2013
VL 6
IS 1
AR 2
DI 10.1145/2457443.2457445
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT C
AU Wang, ZY
   Nalla, PS
   Krishnan, G
   Joshi, RV
   Cady, NC
   Fan, DL
   Seo, JS
   Cao, Y
AF Wang, Zhenyu
   Nalla, Pragnya Sudershan
   Krishnan, Gokul
   Joshi, Rajiv V.
   Cady, Nathaniel C.
   Fan, Deliang
   Seo, Jae-sun
   Cao, Yu
GP IEEE
TI Digital-Assisted Analog In-Memory Computing with RRAM Devices
SO 2023 INTERNATIONAL VLSI SYMPOSIUM ON TECHNOLOGY, SYSTEMS AND
   APPLICATIONS, VLSI-TSA/VLSI-DAT
DT Proceedings Paper
CT International VLSI Symposium on Technology, Systems and Applications
   (VLSI-TSA/VLSI-DAT)
CY APR 17-20, 2023
CL Hsinchu, TAIWAN
DE In-memory computing; ADC; RRAM; SRAM; Deep neural networks (DNNs)
   acceleration
AB In-memory computing (IMC) has been proposed as a solution to accelerate deep neural networks (DNNs) and other machine learning algorithms. RRAM-based IMC accelerators combine memory access and computation into the same array structure, saving a significant amount of chip area. However, the output from RRAM crossbar array requires an analog-to-digital converter (ADC) for further processing which causes the accuracy drop, extra power dissipation, and area overhead. In addition, the RRAM device also suffers from several nonidealities that degrade the accuracy. In this work, we propose a digital-assisted analog IMC architecture that combines analog RRAM-based IMC with the digital SRAM macro, using a programmable shifter, to compensate for the accuracy loss from ADC and the RRAM variations. By adding the precise output from the digital SRAM macro, the non-ideal output from the RRAM macro will be compensated. In this way, we achieve digital-assisted analog in-memory computing. We also designed a silicon prototype of the proposed hybrid IMC architecture in the 65nm CMOS process to demonstrate its efficacy. Our hybrid IMC architecture, evaluated through simulation on ResNet-20 with CIFAR-10, achieves a post-mapping testing accuracy to 91.15%, higher to that of the RRAM macro with 3-bit ADC, while requiring 1.19x smaller area and 1.90x less average power.
C1 [Wang, Zhenyu; Nalla, Pragnya Sudershan; Krishnan, Gokul; Fan, Deliang; Seo, Jae-sun; Cao, Yu] Arizona State Univ, Sch ECEE, Tempe, AZ 85287 USA.
   [Joshi, Rajiv V.] IBM TJ Watson Res Ctr, Yorktown Hts, NY USA.
   [Cady, Nathaniel C.] SUNY Polytech, Dept Nanobiosci, Albany, NY USA.
RP Wang, ZY (corresponding author), Arizona State Univ, Sch ECEE, Tempe, AZ 85287 USA.
CR Azamat A, 2021, ICCAD-IEEE ACM INT, DOI 10.1109/ICCAD51958.2021.9643502
   Chakraborty I, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218688
   Charan G, 2020, DES AUT CON, DOI 10.1109/dac18072.2020.9218605
   Choi J, 2018, Arxiv, DOI arXiv:1805.06085
   Krishnan G, 2022, IEEE T COMPUT AID D, V41, P4241, DOI 10.1109/TCAD.2022.3197516
   Li BX, 2015, DES AUT CON, DOI 10.1145/2744769.2744870
   Liehr M, 2020, INT INTEG REL WRKSP, P82, DOI 10.1109/IIRW49815.2020.9312855
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shim W, 2020, SEMICOND SCI TECH, V35, DOI 10.1088/1361-6641/abb842
   Yang L, 2020, AAAI CONF ARTIF INTE, V34, P6623
   Zhou S, 2016, ARXIV
NR 11
TC 0
Z9 0
U1 4
U2 4
PY 2023
DI 10.1109/VLSI-TSA/VLSI-DAT57221.2023.10134272
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Khalil, K
   Eldash, O
   Kumar, A
   Bayoumi, M
AF Khalil, Kasem
   Eldash, Omar
   Kumar, Ashok
   Bayoumi, Magdy
BE Zhao, D
   Basu, A
   Bayoumi, M
   Hwee, GB
   Tong, G
   Sridhar, R
TI <i>N</i><SUP>2</SUP>OC: Neural-Network-on-Chip Architecture
SO 32ND IEEE INTERNATIONAL SYSTEM ON CHIP CONFERENCE (IEEE SOCC 2019)
SE IEEE International SOC Conference
DT Proceedings Paper
CT 32nd IEEE International System-on-Chip Conference (IEEE SOCC)
CY SEP 03-06, 2019
CL Singapore, SINGAPORE
DE Machine learning; Neural network; Hardware neural network; Hardware
   accelerator; FPGA architecture; Network-on-chip
AB Neural networks are increasingly being used in many applications because of their ability to solve complex problems. In order to increase the processing speed of neural networks, hardware-based techniques are being actively researched in the literature. However, implementing a neural network using conventional hardware design methods is a complex and challenging task for hardware designers as there are many hyperparameters and trade-offs that need to be examined in depth. This paper presents a novel Neural-Network-on-Chip (N2OC) to provide a hardware implementation of a neural network based on network-on-chip. The proposed approach provides reconfigurability when the number of nodes per layer varies depending on the desired performance and application. The proposed method provides a flexible hardware implementation of a neural network where the number and order of nodes can he controlled. Two datasets have been used for testing the proposed method, and the proposed method has a comparable result with the state-of-the-art. The hardware design is implemented using VHDL and Altera Arria 10 GX FPGA 10AX115N2F45E1SG. Throughput and average delay of the network are studied, and the simulation result shows the design has stable performance. On a problem studied (in handwritten digits classification), the proposed method has an accuracy of 99.24% while the state-of-the-art has an accuracy of 98.17%.
C1 [Khalil, Kasem; Eldash, Omar; Kumar, Ashok; Bayoumi, Magdy] Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
   [Bayoumi, Magdy] Univ Louisiana Lafayette, Dept Elect & Comp Engn, Lafayette, LA 70504 USA.
RP Khalil, K (corresponding author), Univ Louisiana Lafayette, Ctr Adv Comp Studies, Lafayette, LA 70504 USA.
EM kmk8148@louisiana.edu; oke1206@louisiana.edu; axk1769@louisiana.edu;
   mab0778@louisiana.edu
CR Bohrn M, 2013, 2013 36TH INTERNATIONAL CONFERENCE ON TELECOMMUNICATIONS AND SIGNAL PROCESSING (TSP), P727, DOI 10.1109/TSP.2013.6614033
   Carleo G, 2017, SCIENCE, V355, P602, DOI 10.1126/science.aag2302
   Chae YT, 2016, ENERG BUILDINGS, V111, P184, DOI 10.1016/j.enbuild.2015.11.045
   Deng J, 2009, PROC CVPR IEEE, P248, DOI 10.1109/CVPRW.2009.5206848
   HORNIK K, 1989, NEURAL NETWORKS, V2, P359, DOI 10.1016/0893-6080(89)90020-8
   Huang CW, 2017, IEEE INT CON MULTI, P583, DOI 10.1109/ICME.2017.8019296
   Ke Y., 2015, NONLINEAR DYNAM, P1
   Khalil K, 2018, INT SOC DESIGN CONF, P152, DOI 10.1109/SOCC.2018.8618525
   Khalil K, 2018, IEEE I C ELECT CIRC, P745, DOI 10.1109/ICECS.2018.8617887
   Khalil K, 2017, IEEE I C ELECT CIRC, P330, DOI 10.1109/ICECS.2017.8292030
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lemley J, 2017, IEEE CONSUM ELECTR M, V6, P48, DOI 10.1109/MCE.2016.2640698
   Moghaddam Amin Hedayati, 2016, Journal of Economics, Finance and Administrative Science, V21, P89
   Rasul RA, 2017, MIDWEST SYMP CIRCUIT, P1216, DOI 10.1109/MWSCAS.2017.8053148
   Sayed MS, 2012, COMPUT MATH APPL, V64, P1301, DOI 10.1016/j.camwa.2012.03.074
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Schrimpf Martin, 2020, BIORXIV, P8, DOI [10.1101/407007, DOI 10.1101/407007]
   Shi BG, 2017, IEEE T PATTERN ANAL, V39, P2298, DOI 10.1109/TPAMI.2016.2646371
   Steinbach L, 2019, APPL ACOUST, V145, P149, DOI 10.1016/j.apacoust.2018.09.024
   Vapnik V, 2017, ANN MATH ARTIF INTEL, V81, P3, DOI 10.1007/s10472-017-9538-x
   Won E, 2007, NUCL INSTRUM METH A, V581, P816, DOI 10.1016/j.nima.2007.08.163
   Zhang ZH, 2017, ENVIRONMENTAL DATA ANALYSIS: METHODS AND APPLICATIONS, P1, DOI 10.1515/9783110424904-002
   Zyarah AM, 2017, MIDWEST SYMP CIRCUIT, P543, DOI 10.1109/MWSCAS.2017.8052980
NR 23
TC 6
Z9 6
U1 0
U2 0
PY 2019
BP 272
EP 277
DI 10.1109/SOCC46988.2019.1570558351
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Silfa, F
   Dot, G
   Arnau, JM
   Gonzàlez, A
AF Silfa, Franyell
   Dot, Gem
   Arnau, Jose-Maria
   Gonzalez, Antonio
GP Assoc Comp Machinery
TI E-PUR: An Energy-Efficient Processing Unit for Recurrent Neural Networks
SO 27TH INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURES AND COMPILATION
   TECHNIQUES (PACT 2018)
DT Proceedings Paper
CT 27th IEEE/ACM/IFIP International Conference on Parallel Architectures
   and Compilation Techniques (PACT)
CY NOV 01-04, 2018
CL Limassol, CYPRUS
DE Recurrent Neural Networks; Long Short Term Memory; Accelerators
AB Recurrent Neural Networks (RNNs) are a key technology for emerging applications such as automatic speech recognition, machine translation or image description. Long Short Term Memory (LSTM) networks are the most successful RNN implementation, as they can learn long term dependencies to achieve high accuracy. Unfortunately, the recurrent nature of LSTM networks significantly constrains the amount of parallelism and, hence, multicore CPUs and many-core GPUs exhibit poor efficiency for RNN inference.
   In this paper, we present E-PUR, an energy-efficient processing unit tailored to the requirements of LSTM computation. The main goal of E-PUR is to support large recurrent neural networks for low-power mobile devices. E-PUR provides an efficient hardware implementation of LSTM networks that is flexible to support diverse applications. One of its main novelties is a technique that we call Maximizing Weight Locality (MWL), which improves the temporal locality of the memory accesses for fetching the synaptic weights, reducing the memory requirements by a large extent.
   Our experimental results show that E-PUR achieves real-time performance for different LSTM networks, while reducing energy consumption by orders of magnitude with respect to general-purpose processors and GPUs, and it requires a very small chip area. Compared to a modern mobile SoC, an NVIDIA Tegra X1, E-PUR provides an average energy reduction of 88x.
C1 [Silfa, Franyell; Dot, Gem; Arnau, Jose-Maria; Gonzalez, Antonio] Univ Politecn Cataluna, Barcelona, Spain.
RP Silfa, F (corresponding author), Univ Politecn Cataluna, Barcelona, Spain.
EM fsilfa@ac.upc.edu; gdot@ac.upc.edu; jarnau@ac.upc.edu;
   antonio@ac.upc.edu
CR Al-Rfou Rami, 2016, ABS160502688 ARXIV
   [Anonymous], 2015, CORR
   [Anonymous], 2016, CORR
   Baldi P., 2001, Sequence learning. Paradigms, algorithms, and applications (Lecture Notes in Artificial Intelligence Vol.1828), P80
   Chang Andre Xian Ming, 2015, ARXIV151105552
   Chen YH, 2016, CONF PROC INT SYMP C, P367, DOI 10.1109/ISCA.2016.40
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Donahue J, 2015, PROC CVPR IEEE, P2625, DOI 10.1109/CVPR.2015.7298878
   Friesen Merlin, LINUX POWER MANAGEME
   Gers FA, 2000, IEEE IJCNN, P189, DOI 10.1109/IJCNN.2000.861302
   Graves A, 2005, IEEE IJCNN, P2047
   Graves A, 2012, STUD COMPUT INTELL, V385, P1, DOI [10.1007/978-3-642-24797-2, 10.1162/neco.1997.9.1.1]
   Greff K., 2016, ARXIV150304069, V28, P2222, DOI DOI 10.1109/TNNLS.2016.2582924
   Guan YJ, 2017, ASIA S PACIF DES AUT, P629, DOI 10.1109/ASPDAC.2017.7858394
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Han Song, 2015, C NEUR INF PROC SYST
   Jiang YF, 2010, 2010 IEEE INTERNATIONAL CONFERENCE ON WIRELESS COMMUNICATIONS, NETWORKING AND INFORMATION SECURITY (WCNIS), VOL 2, P343, DOI 10.1109/WCINS.2010.5542315
   Kim J, 2017, INTERSPEECH, P1591, DOI 10.21437/Interspeech.2017-477
   Lee M, 2016, 2016 IEEE INTERNATIONAL WORKSHOP ON SIGNAL PROCESSING SYSTEMS (SIPS), P230, DOI 10.1109/SiPS.2016.48
   Li SC, 2015, ANN IEEE SYM FIELD P, P111, DOI 10.1109/FCCM.2015.50
   Lipton Z. C., 2015, P INT C LEARN REPR, P1
   Miao YJ, 2015, 2015 IEEE WORKSHOP ON AUTOMATIC SPEECH RECOGNITION AND UNDERSTANDING (ASRU), P167, DOI 10.1109/ASRU.2015.7404790
   Micron Inc, TN 53 01 LPDDR4 SYST
   Muralimanohar N., 2009, HP LAB
   Ng JYH, 2015, PROC CVPR IEEE, P4694, DOI 10.1109/CVPR.2015.7299101
   Schuster M, 1997, IEEE T SIGNAL PROCES, V45, P2673, DOI 10.1109/78.650093
   Sundermeyer M, 2012, 13TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2012 (INTERSPEECH 2012), VOLS 1-3, P194
   Sutskever I., 2014, ADV NEURAL INFORM PR, P3104, DOI DOI 10.5555/2969033.2969173
   Tabani Hamid, 2017, PAR ARCH COMP TECHN
   Venugopalan S, 2015, IEEE I CONF COMP VIS, P4534, DOI 10.1109/ICCV.2015.515
   Vinyals O, 2015, PROC CVPR IEEE, P3156, DOI 10.1109/CVPR.2015.7298935
   Wu, 2016, ARXIV160908144
   Yazdani Reza, 2016, P INT S MICROARCHITE, P1, DOI DOI 10.1109/MICRO.2016.7783750
NR 33
TC 18
Z9 18
U1 0
U2 1
PY 2018
DI 10.1145/3243176.3243184
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Seong, JH
   Choi, Y
AF Seong, Jeong Hoon
   Choi, Younggeun
GP IEEE
TI Design and Implementation of User Interface through Hand Movement
   Tracking and Gesture Recognition
SO 2018 INTERNATIONAL CONFERENCE ON INFORMATION AND COMMUNICATION
   TECHNOLOGY CONVERGENCE (ICTC)
SE International Conference on Information and Communication Technology
   Convergence
DT Proceedings Paper
CT 9th International Conference on Information and Communication Technology
   Convergence (ICTC)
CY OCT 17-19, 2018
CL SOUTH KOREA
DE HCI; wearable devices; gesture recognition; inertial measurement unit
AB In this paper, we investigate about how to track the movement of the hand and how to recognize the click gesture to implement a new type of user interface. We developed a wristwatch-type human computer interface (HCI) device that can estimate and express the user's intuitive hand movements based on a 9-axis inertial measurement unit (IMU) sensor, which includes an accelerator, a magnetometer, and a gyroscope. We defined the Euler angular projection function to map the hand angle intuitively on the screen and to represent its motion reliably. We also proposed a machine-learning-based gesture-recognition algorithm by extracting the window size optimized for the click gesture and collecting the accurate ground truth in a real computing environment with noise. Finally, we designed a natural user interface, which is robust to the actual environment, by integrating hand motion tracking and click gesture recognition. We proved the reliability of motion by comparing the proposed hand motion-tracking function with the conventional method. In the experimental environment with noise, the click gesture recognition algorithm yielded a recognition rate of 98.94%. In conclusion, we modeled the optimized click gesture-recognition algorithm and integrated the mapping functions to track hand movements, and compared the system with existing interface devices. A usability test was performed for evaluation, and usability was verified compared with existing interface equipment.
C1 [Seong, Jeong Hoon; Choi, Younggeun] Dankook Univ, Dept Comp Engn, Yongin, South Korea.
RP Choi, Y (corresponding author), Dankook Univ, Dept Comp Engn, Yongin, South Korea.
EM Jason.sjh7@gmail.com; younggch@dankook.ac.kr
CR Basak S., 2014, INT J COMPUTER APPL
   Hong D., 2008, TELECOMMUNICATIONS R
   Kim YS, 2005, IEEE T IND ELECTRON, V52, P1490, DOI 10.1109/TIE.2005.858736
   Lee C., 2012, STUDY CONTACT TYPE N
   Lee J, 2013, 2013 INTERNATIONAL CONFERENCE ON ICT CONVERGENCE (ICTC 2013): FUTURE CREATIVE CONVERGENCE TECHNOLOGIES FOR NEW ICT ECOSYSTEMS, P274, DOI 10.1109/ICTC.2013.6675356
   Xu C, 2015, 16TH INTERNATIONAL WORKSHOP ON MOBILE COMPUTING SYSTEMS AND APPLICATIONS (HOTMOBILE' 15), P9, DOI 10.1145/2699343.2699350
NR 6
TC 3
Z9 3
U1 0
U2 1
PY 2018
BP 552
EP 555
WC Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Chi, P
   Li, SC
   Xu, C
   Zhang, T
   Zhao, JS
   Liu, YP
   Wang, Y
   Xie, Y
AF Chi, Ping
   Li, Shuangchen
   Xu, Cong
   Zhang, Tao
   Zhao, Jishen
   Liu, Yongpan
   Wang, Yu
   Xie, Yuan
GP IEEE
TI PRIME: A Novel Processing-in-memory Architecture for Neural Network
   Computation in ReRAM-based Main Memory
SO 2016 ACM/IEEE 43RD ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER
   ARCHITECTURE (ISCA)
SE Conference Proceedings Annual International Symposium on Computer
   Architecture
DT Proceedings Paper
CT 43rd ACM/IEEE Annual International Symposium on Computer Architecture
   (ISCA)
CY JUN 18-22, 2016
CL Seoul, SOUTH KOREA
DE processing in memory; neural network; resistive random access memory
AB Processing-in-memory (PIM) is a promising solution to address the "memory wall" challenges for future computer systems. Prior proposed PIM architectures put additional computation logic in or near memory. The emerging metal-oxide resistive random access memory (ReRAM) has showed its potential to be used for main memory. Moreover, with its crossbar array structure, ReRAM can perform matrix-vector multiplication efficiently, and has been widely studied to accelerate neural network (NN) applications. In this work, we propose a novel PIM architecture, called PRIME, to accelerate NN applications in ReRAM based main memory. In PRIME, a portion of ReRAM crossbar arrays can be configured as accelerators for NN applications or as normal memory for a larger memory space. We provide microarchitecture and circuit designs to enable the morphable functions with an insignificant area overhead. We also design a software/hardware interface for software developers to implement various NNs on PRIME. Benefiting from both the PIM architecture and the efficiency of using ReRAM for NN computation, PRIME distinguishes itself from prior work on NN acceleration, with significant performance improvement and energy saving. Our experimental results show that, compared with a state-of-the-art neural processing unit design, PRIME improves the performance by similar to 2360x and the energy consumption by similar to 895x, across the evaluated machine learning benchmarks.
C1 [Chi, Ping; Li, Shuangchen; Xie, Yuan] Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
   [Xu, Cong] HP Labs, Palo Alto, CA 94304 USA.
   [Zhang, Tao] INVIDIA Corp, Santa Clara, CA 95950 USA.
   [Zhao, Jishen] Univ Calif Santa Cruz, Dept Comp Engn, Santa Cruz, CA 95064 USA.
   [Liu, Yongpan; Wang, Yu] Tsinghua Univ, Dept Elect Engn, Beijing 100084, Peoples R China.
RP Chi, P (corresponding author), Univ Calif Santa Barbara, Dept Elect & Comp Engn, Santa Barbara, CA 93106 USA.
EM pingchi@ece.ucsb.edu; shuangchenli@ece.ucsb.edu; yuanxie@ece.ucsb.edu
CR Agarwal N., 2015, P ASPLOS
   Akin B., 2015, P ISCA
   Alibart F., 2011, P AHS
   Alibart F, 2013, NAT COMMUN, V4, DOI 10.1038/ncomms3072
   Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], P ISLPED
   [Anonymous], WORKSH MIX LOG DRAM
   [Anonymous], 2016, P ISCA
   [Anonymous], 2014, P ASPLOS
   [Anonymous], P ICML
   [Anonymous], J EMERG TECHNOL COMP
   [Anonymous], P VLSIT
   [Anonymous], P ASPLOS
   [Anonymous], 1997, WORKSH MIX LOG DRAM
   [Anonymous], 2014, CORR
   [Anonymous], P VLSIT
   [Anonymous], 2004, P ASPLOS
   [Anonymous], 2015, P ISCA
   [Anonymous], P ICS
   [Anonymous], P MICRO
   [Anonymous], P ICCAD
   [Anonymous], 2014, P HPDC
   [Anonymous], P MICRO
   [Anonymous], P IEDM
   [Anonymous], P ISLPED
   [Anonymous], P IJCAI
   [Anonymous], 2015, ICLR
   [Anonymous], P ISCAS
   [Anonymous], P ASPLOS
   Balasubramonian R, 2014, IEEE MICRO, V34, P36, DOI 10.1109/MM.2014.55
   Burr G., 2014, P IEDM
   Burr G. W., 2015, P IEDM
   Chen K., 2012, P DATE
   Chi P., 2015, 2015001 SEAL LAB
   Dong XY, 2012, IEEE T COMPUT AID D, V31, P994, DOI 10.1109/TCAD.2012.2185930
   Esmaeilzadeh H., 2012, P MICRO
   Esser S. K., 2013, P IJCNN
   Farabet C., 2009, P FPL
   Gao L., 2013, P NVMW
   GOKHALE M, 1995, COMPUTER, V28, P23, DOI 10.1109/2.375174
   Guo Q., 2013, P ISCA
   Guo Q., 2011, P MICRO
   Guz Z., 2014, P WONDP
   Hu M., 2015, ICCAD 15 WORKSH EFF
   Hu M., 2013, P CISDA
   Hu M., 2012, P DAC
   Jeddeloh J., 2012, P VLSIT
   Jouppi N. P., 2012, P ICCAD
   Jung M., 2013, P ICS
   Kawahara A., 2012, P ISSCC
   Keckler SW, 2011, IEEE MICRO, V31, P7, DOI 10.1109/MM.2011.89
   Kim JY, 2010, IEEE J SOLID-ST CIRC, V45, P32, DOI 10.1109/JSSC.2009.2031768
   Kozyrakis CE, 1997, COMPUTER, V30, P75, DOI 10.1109/2.612252
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Lee D. U., 2014, P ISSCC P ISSCC
   Lee MJ, 2011, NAT MATER, V10, P625, DOI [10.1038/nmat3070, 10.1038/NMAT3070]
   Li B., 2014, P ASP DAC
   Li BX, 2015, IEEE T COMPUT AID D, V34, P1905, DOI 10.1109/TCAD.2015.2445741
   Li J., 2011, P IMW
   Li S., 2016, P DAC, P1
   Liu B., 2013, P DAC
   Liu B., 2014, P ICCAD
   Liu S., 2016, P ISCA
   Merolla P., 2011, P CICC
   Mirzadeh N., 2015, P ASBD
   Nair R, 2015, IBM J RES DEV, V59, DOI 10.1147/JRD.2015.2409732
   Oskin M., 1998, P ISCA
   Patterson D., 1997, P ICCD
   Pawlowski J. T., 2011, P HOT CHIPS S
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   Pugsley Seth H., 2014, P ISPASS
   Qureshi M., 2010, P ISCA
   Sahin S, 2006, LECT NOTES COMPUT SC, V4234, P1105
   Schmidhuber J., 2012, P CVPR
   Seo J., 2011, P CICC
   Seshadri V., 2013, P MICRO
   St Amant R., 2014, P ISCA
   Taha T., 2013, P IJCNN
   Wong HSP, 2012, P IEEE, V100, P1951, DOI 10.1109/JPROC.2012.2190369
   Wu MC, 2012, SEMICOND SCI TECH, V27, DOI 10.1088/0268-1242/27/6/065010
   Xu C., 2015, P HPCA
   Xu C., 2013, P DAC
   Yu SM, 2011, APPL PHYS LETT, V98, DOI 10.1063/1.3564883
   Zhang L., 2014, P PACT
NR 84
TC 909
Z9 966
U1 6
U2 92
PY 2016
BP 27
EP 39
DI 10.1109/ISCA.2016.13
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Carrazza, S
   Cruz-Martinez, JM
AF Carrazza, Stefano
   Cruz-Martinez, Juan M.
TI VegasFlow: Accelerating Monte Carlo simulation across multiple hardware
   platforms
SO COMPUTER PHYSICS COMMUNICATIONS
DT Article
DE Monte Carlo; Graphs; Integration; Machine learning; Hardware
   acceleration
AB We present VegasFlow, a new software for fast evaluation of high dimensional integrals based on Monte Carlo integration techniques designed for platforms with hardware accelerators. The growing complexity of calculations and simulations in many areas of science have been accompanied by advances in the computational tools which have helped their developments. VegasFlow enables developers to delegate all complicated aspects of hardware or platform implementation to the library so they can focus on the problem at hand. This software is inspired on the Vegas algorithm, ubiquitous in the particle physics community as the driver of cross section integration, and based on Google's powerful TensorFlow library. We benchmark the performance of this library on many different consumer and professional grade GPUs and CPUs.
   Program summary
   Program Title: VegasFlow
   CPC Library link to program files: http://dx.doi.org/10.17632/rpgcbzzhdt.1
   Developer's repository link: https://github.com/N3PDF/vegasflow
   Licensing provisions: GPLv3
   Programming language: Python
   Nature of problem: The solution of high dimensional integrals requires the implementation of Monte Carlo algorithms such as Vegas. Monte Carlo algorithms are known to require long computation times.
   Solution method: Implementation of the Vegas algorithm using the dataflow graph infrastructure provided by the TensorFlow framework. Extension of the algorithm to take advantage of multi-threading CPU and multi-GPU setups. (C) 2020 Elsevier B.V. All rights reserved.
C1 [Carrazza, Stefano; Cruz-Martinez, Juan M.] Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.
   [Carrazza, Stefano; Cruz-Martinez, Juan M.] INFN, Sez Milano, Via Celoria 16, I-20133 Milan, Italy.
RP Carrazza, S (corresponding author), Univ Milan, TIF Lab, Dipartimento Fis, Via Celoria 16, I-20133 Milan, Italy.
EM stefano.carrazza@unimi.it
CR Abadi M., 2015, TENSORFLOW LARGE SCA
   Alwall J, 2014, J HIGH ENERGY PHYS, DOI 10.1007/JHEP07(2014)079
   [Anonymous], **DATA OBJECT**, DOI DOI 10.5281/ZEN0D0.592154
   [Anonymous], **DATA OBJECT**, DOI DOI 10.5281/ZEN0D0.3691926
   [Anonymous], 1984, TOOLS METHODS LANGUA
   Bothmann E., ARXIV200105478
   Brucherseifer M, 2014, PHYS LETT B, V736, P58, DOI 10.1016/j.physletb.2014.06.075
   Buckley A., 2019, 19 INT WORKSH ADV CO
   Campbell J, 2019, J HIGH ENERGY PHYS, DOI 10.1007/JHEP12(2019)034
   Campbell JM, 2015, EUR PHYS J C, V75, DOI 10.1140/epjc/s10052-015-3461-2
   Gao C., ARXIV200110028
   Gao C., ARXIV200105486
   Gehrmann T, 2018, POS RADCOR2017, V074, DOI DOI 10.22323/1.290.0074
   Gleisberg T, 2009, J HIGH ENERGY PHYS, DOI 10.1088/1126-6708/2009/02/007
   Lepage G. P., 1980, VEGAS ADAPTIVE MULTI
   LEPAGE GP, 1978, J COMPUT PHYS, V27, P192
   Muller T., CORR
   Nickolls John, 2008, ACM Queue, V6, DOI 10.1145/1365490.1365500
NR 18
TC 9
Z9 9
U1 0
U2 7
PD SEP
PY 2020
VL 254
AR 107376
DI 10.1016/j.cpc.2020.107376
WC Computer Science, Interdisciplinary Applications; Physics, Mathematical
DA 2023-11-11
ER

PT C
AU Danopoulos, D
   Kachris, C
   Soudris, D
AF Danopoulos, Dimitrios
   Kachris, Christoforos
   Soudris, Dimitrios
BE Pnevmatikatos, DN
   Pelcat, M
   Jung, M
TI Approximate Similarity Search with FAISS Framework Using FPGAs on the
   Cloud
SO EMBEDDED COMPUTER SYSTEMS: ARCHITECTURES, MODELING, AND SIMULATION,
   SAMOS 2019
SE Lecture Notes in Computer Science
DT Proceedings Paper
CT 19th International Conference on Embedded Computer Systems:
   Architectures, Modeling, and Simulation (SAMOS)
CY JUL 07-11, 2019
CL Pythagorion, GREECE
DE Big-data; Similarity search; Approximate KNN; Cloud; FPGA;
   Reconfigurable computing
AB Machine Learning algorithms, such as classification and clustering techniques, have gained significant traction over the last years because they are vital to many real-world problems. K-Nearest Neighbor algorithm (KNN) is widely used in text categorization, predictive analysis, data mining etc. but comes at the cost of high computation. In the era of big data, modern data centers adopt this specific algorithm with approximate techniques to compute demanding workloads every day. However, high dimensional nearest neighbor queries on billion-scale datasets still produce a significant computational and energy overhead. In this paper, we describe and implement a novel design to address this problem based on a hardware accelerated approximate KNN algorithm built upon FAISS framework (Facebook Artificial Intelligence Similarity Search) using FPGA-OpenCL platforms on the cloud. This is an original deployment of FPGA architecture on this framework that also shows how the persistent index build times on big scale inputs for similarity search can be handled in hardware and even outperform other high performance systems. The experiments were done on AWS cloud F1 instance achieving 98x FPGA accelerator speed-up over single-core CPU and 2.1x end-to-end system speed-up over a 36-thread Xeon CPU. Also, the performance/watt of the design was 3.5x from the same CPU and 1.2x from a Kepler-class GPU.
C1 [Danopoulos, Dimitrios; Soudris, Dimitrios] NTUA, Dept Elect & Comp Engn, Athens, Greece.
   [Kachris, Christoforos] Democritus Univ Thrace, Athens, Greece.
   [Kachris, Christoforos] ICCS NTUA, Athens, Greece.
RP Danopoulos, D (corresponding author), NTUA, Dept Elect & Comp Engn, Athens, Greece.
EM dimdano@microlab.ntua.gr; kachris@microlab.ntua.gr;
   dsoudris@microlab.ntua.gr
CR Andoni A., 2018, ABS180609823 CORR
   BENTLEY JL, 1975, COMMUN ACM, V18, P509, DOI 10.1145/361002.361007
   Chen QF, 2012, PROC CVPR IEEE, P869, DOI 10.1109/CVPR.2012.6247760
   Chen YJ, 2010, SENSORS-BASEL, V10, P11259, DOI 10.3390/s101211259
   Danopoulos D, 2018, 2018 7TH INTERNATIONAL CONFERENCE ON MODERN CIRCUITS AND SYSTEMS TECHNOLOGIES (MOCAST)
   FUKUNAGA K, 1975, IEEE T COMPUT, VC 24, P750, DOI 10.1109/T-C.1975.224297
   Gionis A, 1999, PROCEEDINGS OF THE TWENTY-FIFTH INTERNATIONAL CONFERENCE ON VERY LARGE DATA BASES, P518
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Kachris C, 2016, I C FIELD PROG LOGIC, DOI 10.1109/FPL.2016.7577381
   Kouiroukidis N., 2011, 2011 15 PANH C INF, P42
   Kybic J., 2010, APPROXIMATE BEST BIN, V10, P420
   Liu S, 2015, PROC CVPR IEEE, P1419, DOI 10.1109/CVPR.2015.7298748
   Lu XX, 2020, NEW ENGL J MED, V382, P1663, DOI 10.1056/NEJMc2005073
   Mavridis S, 2017, I C FIELD PROG LOGIC
   Norouzi M, 2013, PROC CVPR IEEE, P3017, DOI 10.1109/CVPR.2013.388
   Pu YL, 2015, ANN IEEE SYM FIELD P, P167, DOI 10.1109/FCCM.2015.7
   Sharifzadehand M., 2019, APPROXIMATE VORONOI
   Yinger J, 2017, 2017 INTERNATIONAL CONFERENCE ON FIELD PROGRAMMABLE TECHNOLOGY (ICFPT), P259, DOI 10.1109/FPT.2017.8280155
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
NR 20
TC 3
Z9 3
U1 2
U2 5
PY 2019
VL 11733
BP 373
EP 386
DI 10.1007/978-3-030-27562-4_27
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Ullah, S
   Sahoo, SS
   Kumar, A
AF Ullah, Salim
   Sahoo, Siva Satyendra
   Kumar, Akash
GP IEEE
TI CLAppED: A Design Framework for Implementing Cross-Layer Approximation
   in FPGA-based Embedded Systems
SO 2021 58TH ACM/IEEE DESIGN AUTOMATION CONFERENCE (DAC)
SE Design Automation Conference DAC
DT Proceedings Paper
CT 58th ACM/IEEE Design Automation Conference (DAC)
CY DEC 05-09, 2021
CL San Francisco, CA
DE Approximate Computing; Embedded Systems; Cross-layer System Design;
   FPGA; High-level Synthesis
AB With the rising variation and complexity of embedded workloads, FPGA-based systems are being increasingly used for many applications. The reconfigurability and high parallelism offered by FPGAs are used to enhance the overall performance of these applications. However, the resource constraints of embedded platforms can limit the performance in multiple ways. In recent years, Approximate Computing has emerged as a viable tool for improving the performance by utilizing reduced precision data structures and resource-optimized high-performance arithmetic operators. However, most of the related state-of-the-art research has mainly focused on utilizing approximate computing principles individually on different layers of the computing stack. Nonetheless, approximations across different layers of computing stack can substantially enhance the system's performance. To this end, we present a framework to enable the intelligent exploration and highly accurate identification of the feasible design points in the large design space enabled by cross-layer approximations. Our framework proposes a novel polynomial regression-based method to model approximate arithmetic operators. The proposed method enables machine learning models to better correlate approximate operators with their impact on an application's output quality. We use a 2D convolution operator as a test case and present the results for FPGA-based approximate hardware accelerators.
C1 [Ullah, Salim; Sahoo, Siva Satyendra; Kumar, Akash] Tech Univ Dresden, Ctr Adv Elect Dresden CfAED, Dresden, Germany.
RP Ullah, S (corresponding author), Tech Univ Dresden, Ctr Adv Elect Dresden CfAED, Dresden, Germany.
EM salim.ullah@tu-dresden.de; siva_satyendra.sahoo@tu-dresden.de;
   akash.kumar@tu-dresden.de
CR Abadi M, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P265
   Biscani F, 2018, ESAPAGMO2 PAGMO 2 9
   Bruestel M, 2017, DES AUT TEST EUROPE, P298, DOI 10.23919/DATE.2017.7927003
   Chippa V. K., 2013, P 50 ANN DESIGN AUTO, P1, DOI DOI 10.1145/2463209.2488873
   Chippa VK, 2014, IEEE T VLSI SYST, V22, P2004, DOI 10.1109/TVLSI.2013.2276759
   De la Parra C, 2020, FUTURE GENER COMP SY, V113, P597, DOI 10.1016/j.future.2020.07.031
   De S, 2020, DES AUT TEST EUROPE, P1680, DOI 10.23919/DATE48585.2020.9116552
   Düben P, 2015, DES AUT TEST EUROPE, P764
   Fan YH, 2019, 24TH ASIA AND SOUTH PACIFIC DESIGN AUTOMATION CONFERENCE (ASP-DAC 2019), P317, DOI 10.1145/3287624.3287627
   Goiri I, 2015, ACM SIGPLAN NOTICES, V50, P383, DOI [10.1145/2694344.2694351, 10.1145/2775054.2694351]
   Hanif MA, 2018, J LOW POWER ELECTRON, V14, P520, DOI 10.1166/jolpe.2018.1575
   Liang JH, 2013, IEEE T COMPUT, V62, P1760, DOI 10.1109/TC.2012.146
   Liu HY, 2013, DES AUT CON
   MASSEY FJ, 1951, J AM STAT ASSOC, V46, P68, DOI 10.2307/2280095
   Mehrabi A, 2020, DES AUT TEST EUROPE, P151, DOI 10.23919/DATE48585.2020.9116473
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Mockus J., 1975, OPTIMIZATION TECHNIQ, P400, DOI [10.1007/3-540-07165-2_55, DOI 10.1007/3-540-07165-2_55]
   Mrazek V, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317781
   Mrazek V, 2017, DES AUT TEST EUROPE, P258, DOI 10.23919/DATE.2017.7926993
   Shafique M, 2016, DES AUT CON, DOI 10.1145/2897937.2906199
   Ullah S., 2020, IEEE T COMPUT
   Ullah S, 2020, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE48585.2020.9116373
   Ullah S, 2018, DES AUT CON, DOI 10.1145/3195970.3196115
   Xilinx, 2018, UG1270 VIV HLS OPT M
   Yazdanbakhsh A, 2017, IEEE DES TEST, V34, P60, DOI 10.1109/MDAT.2016.2630270
NR 25
TC 4
Z9 4
U1 0
U2 0
PY 2021
BP 475
EP 480
DI 10.1109/DAC18074.2021.9586260
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Computer Science, Software Engineering; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Liao, SY
   Li, Z
   Lin, X
   Qiu, QR
   Wang, YZ
   Yuan, B
AF Liao, Siyu
   Li, Zhe
   Lin, Xue
   Qiu, Qinru
   Wang, Yanzhi
   Yuan, Bo
GP IEEE
TI Energy-Efficient, High-Performance, Highly-Compressed Deep Neural
   Network Design using Block-Circulant Matrices
SO 2017 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER-AIDED DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT IEEE/ACM 36th International Conference on Computer-Aided Design (ICCAD)
CY NOV 13-16, 2017
CL Irvine, CA
AB Deep neural networks (DNNs) have emerged as the most powerful machine learning technique in numerous artificial intelligent applications. However, the large sizes of DNNs make themselves both computation and memory intensive, thereby limiting the hardware performance of dedicated DNN accelerators. In this paper, we propose a holistic framework for energy-efficient high-performance highly-compressed DNN hardware design. First, we propose block-circulant matrix-based DNN training and inference schemes, which theoretically guarantee Big-O complexity reduction in both computational cost (from O(n(2)) to O(n log n)) and storage requirement (from O(n(2)) to O(n)) of DNNs. Second, we dedicatedly optimize the hardware architecture, especially on the key fast Fourier transform (FFT) module, to improve the overall performance in terms of energy efficiency, computation performance and resource cost. Third, we propose a design flow to perform hardware-software cooptimization with the purpose of achieving good balance between test accuracy and hardware performance of DNNs. Based on the proposed design flow, two block-circulant matrix-based DNNs on two different datasets are implemented and evaluated on FPGA. The fixed-point quantization and the proposed block-circulant matrix-based inference scheme enables the network to achieve as high as 3.5 TOPS computation performance and 3.69 TOPS/W energy efficiency while the memory is saved by 108X similar to 116X with negligible accuracy degradation.
C1 [Liao, Siyu; Yuan, Bo] CUNY, New York, NY 10021 USA.
   [Li, Zhe; Qiu, Qinru; Wang, Yanzhi] Syracuse Univ, Syracuse, NY 13244 USA.
   [Lin, Xue] Northeastern Univ, Boston, MA 02115 USA.
RP Liao, SY (corresponding author), CUNY, New York, NY 10021 USA.; Li, Z (corresponding author), Syracuse Univ, Syracuse, NY 13244 USA.
EM sliao2@gradcenter.cuny.edu; zli89@syr.edu; xue.lin@northeastern.edu;
   qiqiu@syr.edu; ywang393@syr.edu; byuan@ccny.cuny.edu
CR Andri R, 2016, IEEE COMP SOC ANN, P236, DOI 10.1109/ISVLSI.2016.111
   [Anonymous], 2015, INAISTATS
   [Anonymous], 2011, NEURAL INFORM PROCES
   [Anonymous], ACM ICCAD
   [Anonymous], 1977, DISCRETE TIME SIGNAL
   [Anonymous], 1998, MNIST DATABASE HANDW
   [Anonymous], F AST F OURIER T RAN
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Chung J, 2016, DES AUT CON, DOI 10.1145/2897937.2898092
   Collobert R, 2011, J MACH LEARN RES, V12, P2493
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Gardner MW, 1998, ATMOS ENVIRON, V32, P2627, DOI 10.1016/S1352-2310(97)00447-0
   Han S., 2015, ARXIV151000149
   Han S, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P75, DOI 10.1145/3020078.3021745
   Hwang K, 2014, IEEE WRK SIG PRO SYS, P174
   Jouppi N.P., 2017, P 44 ANN INT S COMPU
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   LeCun Y, 1989, NIPS, V2, P589
   McCulloch Warren S., 1943, BULL MATH BIOPHYS, V5, P115, DOI 10.1007/BF02478259
   Mittal S, 2016, ACM COMPUT SURV, V48, DOI 10.1145/2893356
   Pan Victor, 2012, STRUCTURED MATRICES
   Qiu JT, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P26, DOI 10.1145/2847263.2847265
   Schmidhuber J, 2015, NEURAL NETWORKS, V61, P85, DOI 10.1016/j.neunet.2014.09.003
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
NR 26
TC 7
Z9 7
U1 0
U2 0
PY 2017
BP 458
EP 465
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Faingnaert, T
   Besard, T
   De Sutter, B
AF Faingnaert, Thomas
   Besard, Tim
   De Sutter, Bjorn
TI Flexible Performant GEMM Kernels on GPUs
SO IEEE TRANSACTIONS ON PARALLEL AND DISTRIBUTED SYSTEMS
DT Article
DE Libraries; Kernel; Graphics processing units; Codes; Programming;
   Instruction sets; Productivity; Matrix multiplication; graphics
   processors; high-level programming languages
ID TENSOR CONTRACTION
AB General Matrix Multiplication or GEMM kernels take centre place in high performance computing and machine learning. Recent NVIDIA GPUs include GEMM accelerators, such as NVIDIA's Tensor Cores. Their exploitation is hampered by the two-language problem: it requires either low-level programming which implies low programmer productivity or using libraries that only offer a limited set of components. Because rephrasing algorithms in terms of established components often introduces overhead, the libraries' lack of flexibility limits the freedom to explore new algorithms. Researchers using GEMMs can hence not enjoy programming productivity, high performance, and research flexibility at once. In this paper we solve this problem. We present three sets of abstractions and interfaces to program GEMMs within the scientific Julia programming language. The interfaces and abstractions are co-designed for researchers' needs and Julia's features to achieve sufficient separation of concerns and flexibility to easily extend basic GEMMs in many different ways without paying a performance price. Comparing our GEMMs to state-of-the-art libraries cuBLAS and CUTLASS, we demonstrate that our performance is in the same ballpark of the libraries, and in some cases even exceeds it, without having to write a single line of code in CUDA C++ or assembly, and without facing flexibility limitations.
C1 [Faingnaert, Thomas; De Sutter, Bjorn] Univ Ghent, Dept Elect & Informat Syst, B-9042 Ghent, Belgium.
   [Besard, Tim] Univ Ghent, Julia Comp, B-9042 Ghent, Belgium.
RP De Sutter, B (corresponding author), Univ Ghent, Dept Elect & Informat Syst, B-9042 Ghent, Belgium.
EM thomas.faingnaert@ugent.be; tim@juliacomputing.com;
   bjorn.desutter@ugent.be
CR Abadi M, 2016, ACM SIGPLAN NOTICES, V51, P1, DOI [10.1145/3022670.2976746, 10.1145/2951913.2976746]
   Abdelfattah A, 2019, PROCEEDINGS OF SCALA 2019: 2019 IEEE/ACM 10TH WORKSHOP ON LATEST ADVANCES IN SCALABLE ALGORITHMS FOR LARGE-SCALE SYSTEMS (SCALA), P17, DOI 10.1109/ScalA49573.2019.00008
   Aprà E, 2014, INT CONF HIGH PERFOR, P674, DOI 10.1109/SC.2014.60
   Auer AA, 2006, MOL PHYS, V104, P211, DOI 10.1080/00268970500275780
   Bader BW, 2006, ACM T MATH SOFTWARE, V32, P635, DOI 10.1145/1186785.1186794
   Barham P, 2019, PROCEEDINGS OF THE WORKSHOP ON HOT TOPICS IN OPERATING SYSTEMS (HOTOS '19), P177, DOI 10.1145/3317550.3321441
   Baskaran MM, 2008, ICS'08: PROCEEDINGS OF THE 2008 ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING, P225
   Besard T, 2019, ADV ENG SOFTW, V132, P29, DOI 10.1016/j.advengsoft.2019.02.002
   Besard T, 2019, IEEE T PARALL DISTR, V30, P827, DOI 10.1109/TPDS.2018.2872064
   Bhaskaracharya S. G., 2020, ARXIV200612645
   BLASContributors, 2017, BLAS BAS LIN ALG SUB
   Bondhugula U., 2020, ARXIV200300532
   Bondhugula U, 2008, ACM SIGPLAN NOTICES, V43, P101, DOI 10.1145/1379022.1375595
   Churavy V, 2020, KERNELABSTRACTIONSJL
   Churavy V., 2020, GPUIFYLOOPSJL SUPPOR
   Di Napoli E, 2014, APPL MATH COMPUT, V235, P454, DOI 10.1016/j.amc.2014.02.051
   Elango V, 2018, MAPL'18: PROCEEDINGS OF THE 2ND ACM SIGPLAN INTERNATIONAL WORKSHOP ON MACHINE LEARNING AND PROGRAMMING LANGUAGES, P42, DOI 10.1145/3211346.3211354
   Grosser T, 2012, PARALLEL PROCESS LET, V22, DOI 10.1142/S0129626412500107
   Haidar A, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Haidari A, 2019, PROBAB ENG INFORM SC, V33, P460, DOI 10.1017/S0269964818000220
   Hinton GE, 2018, 6 INT C LEARN REPR I, P1
   Ichimura T, 2018, PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE, AND ANALYSIS (SC'18)
   Julia, 2020, JUL LANG
   JuliaLang.org, 2020, JUL MICR BENCHM
   JuliaLang.org, 2020, JUL LANG OFF DOC
   Khronos Group, 2020, OPENCL OP STAND PAR
   Kim J, 2019, INT SYM CODE GENER, P85, DOI [10.1109/CGO.2019.8661182, 10.6084/m9.figshare.7403732]
   Li JJ, 2015, PROCEEDINGS OF SC15: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/2807591.2807671
   LLVM contributors, 2020, LLVM COMPILER INFRAS
   Ma WJ, 2011, J CHEM THEORY COMPUT, V7, P1316, DOI 10.1021/ct1007247
   Matthews DA, 2018, SIAM J SCI COMPUT, V40, pC1, DOI 10.1137/16M108968X
   Mehta V., 2019, P NVIDIA GPU TECHN C
   Nelson T, 2015, PROC INT CONF PARAL, P969, DOI 10.1109/ICPP.2015.106
   NVIDIA, 2020, CUTLASS CUDA TEMPL
   NVIDIA, 2019, DEEP LEARN PERF GUID
   NVIDIA, 2020, CUDA C PROGRAMMING G
   NVIDIA, 2020, NVIDIA V100
   Paszke A, 2019, ADV NEUR IN, V32
   Peng Di, 2012, 2012 41st International Conference on Parallel Processing (ICPP 2012), P350, DOI 10.1109/ICPP.2012.19
   Poya R, 2017, COMPUT PHYS COMMUN, V216, P35, DOI 10.1016/j.cpc.2017.02.016
   Psarras C., CORR 2021ABS21031375
   Revels J., 2016, ARXIV160707892
   Rink NA, 2018, RWDSL2018: PROCEEDINGS OF THE REAL WORLD DOMAIN SPECIFIC LANGUAGES WORKSHOP 2018, DOI 10.1145/3183895.3183900
   Sioutas S, 2020, PROCEEDINGS OF THE 23RD INTERNATIONAL WORKSHOP ON SOFTWARE AND COMPILERS FOR EMBEDDED SYSTEMS (SCOPES 2020), P36, DOI 10.1145/3378678.3391880
   Solomonik E, 2013, INT PARALL DISTRIB P, P813, DOI 10.1109/IPDPS.2013.112
   Springer P., 2017, P WORKSH BATCH REPR
   Springer P, 2018, ACM T MATH SOFTWARE, V44, DOI 10.1145/3157733
   Van Zee FG, 2020, SIAM J SCI COMPUT, V42, pC221, DOI 10.1137/19M1282040
   Van Zee FG, 2015, ACM T MATH SOFTWARE, V41, DOI 10.1145/2764454
   Verdoolaege S, 2013, ACM T ARCHIT CODE OP, V9, DOI 10.1145/2400682.2400713
   Yan D, 2020, INT PARALL DISTRIB P, P634, DOI 10.1109/IPDPS47924.2020.00071
NR 51
TC 1
Z9 1
U1 1
U2 3
PD SEPT 1
PY 2022
VL 33
IS 9
BP 2230
EP 2248
DI 10.1109/TPDS.2021.3136457
WC Computer Science, Theory & Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Khawaja, SG
   Akram, MU
   Khan, SA
   Shaukat, A
   Rehman, S
AF Khawaja, Sajid Gul
   Akram, M. Usman
   Khan, Shoab Ahmed
   Shaukat, Arslan
   Rehman, Saad
TI Network-on-Chip based MPSoC architecture for <i>k</i>-mean clustering
   algorithm
SO MICROPROCESSORS AND MICROSYSTEMS
DT Article
DE k-means; MPSoC; NoC; Scalable; Unfolding
ID HIGH-PERFORMANCE
AB Data and image segmentation plays pivotal role in the application of machine learning. k-means, as a tool for unsupervised clustering, is a widely used algorithm for segmentation due to its inherent simplicity and efficiency. k-means partitions datasets into subsets based on their fitness value. As such k-means is a well suited algorithm for implementation on hardware platform such as Field Programmable Gate Array (FPGA) but requires high computation time. Hardware accelerators can help in reducing the computation complexity of the algorithm. In this paper, we present a simplified multicore based scalable hardware architecture for implementation of k-means. Mean and fitness modules in proposed architecture are further unfolded to further enhance the speed of k-means clustering algorithm. The unfolding factor has to be selected by keeping the area of the target device in check. In the proposed architecture, the cores are further connected through Network on Chip (NoC) interconnect network which allows for higher scalability while elevating the bottleneck of message passing. The performance of our MPSoC architecture has been evaluated with respect to Average Speedup, Average Throughput and Area consumption with and without use of NoC interconnect. Finally, we compare the use of different NoC interconnect models with respect to maximum Operating Frequency, average Throughput and Area overhead. (C) 2016 Elsevier B.V. All rights reserved.
C1 [Khawaja, Sajid Gul; Akram, M. Usman; Khan, Shoab Ahmed; Shaukat, Arslan; Rehman, Saad] Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
RP Akram, MU (corresponding author), Natl Univ Sci & Technol, Dept Comp Engn, Islamabad, Pakistan.
EM sajid.gul@ceme.nust.edu.pk; usmakram@gmail.com; kshoab@yahoo.com;
   arslan.asp@gmail.com; rehman.saad@gmail.com
CR [Anonymous], 2001, FPGA 01
   [Anonymous], 2008, P 2008 ACM CONEXT C
   [Anonymous], P IEEE C COMP VIS PA
   Belanovic P., 2002, THESIS
   Benini L, 2002, COMPUTER, V35, P70, DOI 10.1109/2.976921
   Birem M, 2014, J SYST ARCHITECT, V60, P519, DOI 10.1016/j.sysarc.2014.01.006
   Dally W. J., 2004, PRINCIPLES PRACTICES
   Dally WJ, 2001, DES AUT CON, P684, DOI 10.1109/DAC.2001.935594
   Drineas P, 2004, MACH LEARN, V56, P9, DOI 10.1023/B:MACH.0000033113.59016.96
   Estlick M., 2002, THESIS
   Fularz M, 2015, INT J ADV ROBOT SYST, V12, DOI 10.5772/61434
   Gao SL, 2014, ANN IEEE SYST CONF, P78, DOI 10.1109/SysCon.2014.6819239
   Gokhale M, 2003, J SUPERCOMPUT, V26, P131, DOI 10.1023/A:1024495400663
   Hussain H. M., 2011, Proceedings of the 2011 International Conference on Reconfigurable Computing and FPGAs (ReConFig 2011), P475, DOI 10.1109/ReConFig.2011.49
   Hussain H. M., 2011, Proceedings of the 2011 NASA/ESA Conference on Adaptive Hardware and Systems (AHS), P248, DOI 10.1109/AHS.2011.5963944
   Jain AK, 1999, ACM COMPUT SURV, V31, P264, DOI 10.1145/331499.331504
   Jain AK, 2010, PATTERN RECOGN LETT, V31, P651, DOI 10.1016/j.patrec.2009.09.011
   Jiang ZL, 2012, COMPUT VIS IMAGE UND, V116, P730, DOI 10.1016/j.cviu.2012.02.004
   Khawaja SG, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0125230
   Kunzhi X., 2013, 3 INT C MULT TECHN I
   Lavenier D, 2000, FPGA IMPLEMENTATION
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Lin Z., 2012, FPL 12, P437
   Mehmood S, 2015, J REAL-TIME IMAGE PR, V10, P75, DOI 10.1007/s11554-012-0256-7
   Mehmood S, 2009, LECT NOTES COMPUT SC, V5484, P369, DOI 10.1007/978-3-642-01129-0_41
   Modarressi M, 2011, IEEE T VLSI SYST, V19, P2010, DOI 10.1109/TVLSI.2010.2066586
   Morro A, 2015, PLOS ONE, V10, DOI 10.1371/journal.pone.0124176
   Peng XS, 2013, IEEE T DIELECT EL IN, V20, P754
   González CP, 2011, PLOS ONE, V6, DOI 10.1371/journal.pone.0021399
   Qu YR, 2016, IEEE T PARALL DISTR, V27, P197, DOI 10.1109/TPDS.2015.2389239
   Saegusa T, 2007, J REAL-TIME IMAGE PR, V2, P309, DOI 10.1007/s11554-007-0055-8
   Salgarelli L, 2006, STAT TRAFFIC CLASSIF
   Silva DRG, 2014, IEEE I C ELECT CIRC, P431, DOI 10.1109/ICECS.2014.7050014
   Tadesse M., 2015, AFRICON 2015, P1
   Tran AT, 2014, IEEE T VLSI SYST, V22, P1391, DOI 10.1109/TVLSI.2013.2268548
   Winterstein F., 2013, FIELD PROGR LOG APPL, P1
   Woehrle H., 2015, FORMAL MODELING VERI, P311
   Yoneda T, 2014, 2014 IEEE ASIA PACIFIC CONFERENCE ON CIRCUITS AND SYSTEMS (APCCAS), P679, DOI 10.1109/APCCAS.2014.7032872
   Yu J, 2005, IEEE T PATTERN ANAL, V27, P1197, DOI 10.1109/TPAMI.2005.160
   Zawadzki A, 2015, J SYST ARCHITECT, V61, P681, DOI 10.1016/j.sysarc.2015.08.003
   Zou Y, 2013, INT SYM QUAL ELECT, P643, DOI 10.1109/ISQED.2013.6523678
NR 41
TC 3
Z9 3
U1 0
U2 2
PD OCT
PY 2016
VL 46
BP 1
EP 10
DI 10.1016/j.micpro.2016.08.006
PN A
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Vandebon, J
   Coutinho, JGF
   Luk, W
   Nurvitadhi, E
   Naik, M
AF Vandebon, Jessica
   Coutinho, Jose G. F.
   Luk, Wayne
   Nurvitadhi, Eriko
   Naik, Mishali
GP IEEE
TI Enhanced Heterogeneous Cloud: Transparent Acceleration and Elasticity
SO 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT
   2019)
DT Proceedings Paper
CT International Conference on Field-Programmable Technology (ICFPT)
CY DEC 09-13, 2019
CL Tianjin, PEOPLES R CHINA
DE FPGA; PaaS; heterogeneous clouds; transparent acceleration;
   heterogeneous elasticity
AB This paper presents ORIAN, a fully-managed Platform-as-a-Service (PaaS) for deploying high-level applications onto large-scale heterogeneous cloud infrastructures. We aim to make specialised, accelerator resources in the cloud accessible to software developers by extending the traditional homogeneous PaaS execution model to support automatic runtime management of heterogeneous compute resources such as CPUs and FPGAs. In particular, we focus on two mechanisms: transparent acceleration, which automatically maps jobs to the most suitable resource configuration, and heterogeneous elasticity, which performs automatic vertical (type) and horizontal (quantity) scaling of provisioned resources to guarantee QoS (Quality of Service) objectives while minimising cost. We develop a prototype to validate our approach, targeting a hardware platform with combined computational capacity of 28 FPGAs and 36 CPU cores, and evaluate it using case studies in three application domains: machine learning, bioinformatics, and physics. Our transparent acceleration decisions achieve on average 96% of the maximum manually identified static configuration throughput for large workloads, while removing the burden of determining configuration from the user; an elastic ORIAN resource group provides a 2.3 times cost reduction compared to an over-provisioned group for non-uniform, peaked job sequences while guaranteeing QoS objectives; and our malleable architecture extends to support a new, more suitable resource type, automatically reducing the cost by half while maintaining throughput, and achieving a 23% throughput increase while fulfilling resource constraints.
C1 [Vandebon, Jessica; Coutinho, Jose G. F.; Luk, Wayne] Imperial Coll London, London, England.
   [Nurvitadhi, Eriko; Naik, Mishali] Intel Corp, San Jose, CA USA.
RP Vandebon, J (corresponding author), Imperial Coll London, London, England.
EM jessica.vandebon17@imperial.ac.uk; gabriel.figueiredo@imperial.ac.uk;
   w.luk@imperial.ac.uk; eriko.nurvitadhi@intel.com; mishali.naik@intel.com
CR Arram J, 2017, IEEE ACM T COMPUT BI, V14, P668, DOI 10.1109/TCBB.2016.2535385
   Asiatici M, 2017, IEEE ACCESS, V5, P1900, DOI 10.1109/ACCESS.2017.2661582
   Coutinho J., 2017, HARNESS PLATFORM HAR
   Eskandari N, 2019, PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19), P262, DOI 10.1145/3289602.3293909
   Graepel Thore, 2010, P 27 INT C MACH LEAR, P13, DOI DOI 10.1109/TNSE.2021.3102582
   Heroku, SCAL YOUR DYN FORM
   Mbongue J., 2018, 2018 IEEE 11 INT C C
NR 7
TC 2
Z9 2
U1 0
U2 0
PY 2019
BP 162
EP 170
DI 10.1109/ICFPT47387.2019.00027
WC Computer Science, Interdisciplinary Applications; Engineering,
   Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Gao, W
   Zhou, PQ
AF Gao, Wei
   Zhou, Pingqiang
TI Customized High Performance and Energy Efficient Communication Networks
   for AI Chips
SO IEEE ACCESS
DT Article
DE AI accelerators; NoC; communication network
AB The convolutional and deep neural networks are prevalent machine learning algorithms for real-world applications. As the neural network needs large computations, many artificial intelligence (AI) chips are designed to accelerate the computation. AI chips have achieved better energy efficiency and high computational capacity in the neural network implementation. The communication network in AI chips influences the data transformation and hardware efficiency. The network-on-chip (NoC) is one feasible solution to meet the data communication requirements in AI chips. This paper introduces the communication network in AI chips and the strategy of mapping neural network to chips with the extensible hierarchical architecture. We also conclude the opportunities for communication optimization in the design of AI chips. In this paper, we propose our processor architecture and optimize the performance and energy of intra-communication in chips from three aspects: data reuse, topology, and router architecture. The experimental results show that our optimization can totally achieve 25.31x latency reduction and 79.92 x energy less than the baseline. The results show that our design can reduce the latency by 5.47x and save communication energy by 7.5x when compared with the state-of-the-art design DaDianNao. When compared with another design Eyeriss, our design can reduce latency by 7.57x and save communication energy by 3.03x.
C1 [Gao, Wei] Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.
   [Gao, Wei; Zhou, Pingqiang] ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.
   [Gao, Wei] Univ Chinese Acad Sci, Beijing, Peoples R China.
RP Gao, W (corresponding author), Chinese Acad Sci, Shanghai Inst Microsyst & Informat Technol, Shanghai 200050, Peoples R China.; Gao, W (corresponding author), ShanghaiTech Univ, Sch Informat Sci & Technol, Shanghai 201210, Peoples R China.; Gao, W (corresponding author), Univ Chinese Acad Sci, Beijing, Peoples R China.
EM gaowei@shanghaitech.edu.cn
CR Akopyan F, 2015, IEEE T COMPUT AID D, V34, P1537, DOI 10.1109/TCAD.2015.2474396
   [Anonymous], 2018, EYERISS V2 FLEXIBLE
   Bojarski Mariusz, 2016, arXiv
   Chen Y., 2014, MICRO DEC
   Chen YH, 2016, ISSCC DIG TECH PAP I, V59, P262, DOI 10.1109/ISSCC.2016.7418007
   Cota E., 2012, RELIABILITY AVAILABI, DOI 10.1007/978-1-4614-0791-1
   Dally W. J., 2004, PRINCIPLES PRACTICES
   Deng J., 2009, CVPR JUN
   Emer J., 2017, ISCA TUT JUN
   Farabet C., 2011, CVPR WORKSH JUN
   He K., 2015, ARXIV
   Hosseinabady M., 2006, DATE MAR
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Larochelle H., 2007, ICML JUN
   Le QV., 2011, BUILDING HIGH LEVEL
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Lee HG, 2007, ACM T DES AUTOMAT EL, V12, DOI 10.1145/1255456.1255460
   Liu X., 2018, ASPDAC JAN
   Liu XX, 2016, IEEE T CIRCUITS-I, V63, P617, DOI 10.1109/TCSI.2016.2529279
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Ramanujam R. S., 2010, NOCS MAY
   Rhu M., 2016, MICRO OCT
   Silver D, 2016, NATURE, V529, P484, DOI 10.1038/nature16961
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Van Thiem C, 2011, ICNC DEC
   Vanhoucke V., 2011, NIPS DEC
   Yin SY, 2018, IEEE J SOLID-ST CIRC, V53, P968, DOI 10.1109/JSSC.2017.2778281
NR 27
TC 5
Z9 5
U1 1
U2 19
PY 2019
VL 7
BP 69434
EP 69446
DI 10.1109/ACCESS.2019.2916338
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Zhou, SJ
   Kannan, R
   Prasanna, VK
AF Zhou, Shijie
   Kannan, Rajgopal
   Prasanna, Viktor K.
BE Athanas, P
   Cumplido, R
   Feregrino, C
   Sass, R
TI Accelerating Low Rank Matrix Completion on FPGA
SO 2017 INTERNATIONAL CONFERENCE ON RECONFIGURABLE COMPUTING AND FPGAS
   (RECONFIG)
SE Proceedings International Conference on Reconfigurable Computing and
   FPGAs
DT Proceedings Paper
CT International Conference on Reconfigurable Computing and FPGAs
   (ReConFig)
CY DEC 04-06, 2017
CL Cancun, MEXICO
DE Analysis of incomplete datasets; Matrix factorization; Machine learning;
   Parallel processing; Data partitioning
AB Low Rank Matrix Completion (LRMC) is widely used in the analysis of incomplete datasets. In this paper, we propose a novel FPGA-based accelerator to speedup a matrix-factorization-based LRMC algorithm that uses stochastic gradient descent. The accelerator is a multi-pipelined architecture with parallel pipelines processing distinct data from a shared on-chip buffer. We propose two distinct on-chip buffer architectures based on a design-space exploration of the performance tradeoffs offered by two competing design methodologies: memory-efficiency versus concurrent conflict-free accesses. Our first design (i.e., memory-efficient design) organizes the buffer into banks and maximally utilizes available on-chip memory for matrix chunk processing without requiring complex address translation tables for on-chip addressing; however, it could incur bank conflicts when concurrent accesses to the same bank occur. The second design (i.e., bank-conflict-free design) exploits parallel multiport memory access and completely eliminates bank conflicts by duplicating the stored data; however, it has much higher on-chip RAM consumption. Intuitively, design one enables (slower) acceleration of (larger) chunks of the input matrix whereas design two enables (faster) processing of (smaller) matrix chunks but requires more iterations for processing the complete matrix. We propose a simple but efficient partitioning approach for supporting large input matrices that do not fit in the on-chip memory of FPGA. We also develop algorithmic optimizations based on matching to reduce data dependencies for parallel pipeline execution. We implement our designs on a state-of-the-art UltraScale+FPGA device. We use real-life datasets for the evaluation and compare these two designs by varying the number of pipelines. The data dependency optimization results in at least 21.6x data dependency reduction and improves the execution time by up to 66.3x compared with non-optimized baseline designs. The memory-efficient design is also shown to be more scalable than the bank-conflict-free design. Compared with the state-of-the-art multi-core implementation and GPU implementation, the bank-conflict-free design achieves 5.4x and 5.2x speedup, respectively; the memory-efficient design achieves 16.7x and 16.2x speedup, respectively.
C1 [Zhou, Shijie; Prasanna, Viktor K.] Univ Southern Calif, Los Angeles, CA 90089 USA.
   [Kannan, Rajgopal] US Army, Res Lab, Los Angeles, CA 90094 USA.
RP Zhou, SJ (corresponding author), Univ Southern Calif, Los Angeles, CA 90089 USA.
EM shijiezh@usc.edu; rajgopal.kannan.civ@mail.mil; prasanna@usc.edu
CR Alwani M., 2016, P MICRO
   Benne J., 2007, P KDD CUP WORKSH
   Brozovsky L., 2007, RECOMMENDER SYSTEM O
   Candès EJ, 2010, P IEEE, V98, P925, DOI 10.1109/JPROC.2009.2035722
   Candès EJ, 2009, FOUND COMPUT MATH, V9, P717, DOI 10.1007/s10208-009-9045-5
   Dean J., 2012, ADV NEURAL INFORM PR, P1223, DOI DOI 10.5555/2999134.2999271
   Ding  C., 2017, P MICRO, P11
   Ham TJ, 2016, INT SYMP MICROARCH
   Jain P, 2013, STOC'13: PROCEEDINGS OF THE 2013 ACM SYMPOSIUM ON THEORY OF COMPUTING, P665
   Kaleem Rashid, 2015, P 8 WORKSHOP GEN PUR, P81
   Keshavan RH, 2010, IEEE T INFORM THEORY, V56, P2980, DOI 10.1109/TIT.2010.2046205
   Koren Y, 2009, COMPUTER, V42, P30, DOI 10.1109/MC.2009.263
   Kuppannagari S., 2014, P HPEC
   LaForest CE, 2010, FPGA 10, P41
   Li Y., 2016, P FPL
   Luo Y., 2017, P FPL
   Morris GR, 2006, ANN IEEE SYM FIELD P, P3
   Satish N, 2014, SIGMOD'14: PROCEEDINGS OF THE 2014 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P979, DOI 10.1145/2588555.2610518
   Singer A, 2008, P NATL ACAD SCI USA, V105, P9507, DOI 10.1073/pnas.0709842104
   Tomasi C., 1992, INT J COMPUTER VISIO, V9
   Wei Tan, 2016, P 25 ACM INT S HIGH, P219
   Wilson R., 1996, INTRO GRAPH THEORY
   Zeng H., 2017, P RECONFIG
   Zhang MX, 2016, PROCEEDINGS OF OSDI'16: 12TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P285
   Zhou PP, 2016, ANN IEEE SYM FIELD P, P172, DOI 10.1109/FCCM.2016.50
   Zhou S., 2014, P RECONFIG
   Zhou S., 2015, P IPDPSW
   Zhou S., 2016, P FCCM
   Zhou S., 2015, P RECONFIG
   Zhou SJ, 2015, IEEE INT CONF ASAP, P226, DOI 10.1109/ASAP.2015.7245738
NR 30
TC 1
Z9 1
U1 0
U2 0
PY 2017
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Krymova, E
   Obozinski, G
   Schenk, M
   Coyle, L
   Pieloni, T
AF Krymova, Ekaterina
   Obozinski, Guillaume
   Schenk, Michael
   Coyle, Loic
   Pieloni, Tatiana
TI Data-driven modeling of beam loss in the LHC
SO FRONTIERS IN PHYSICS
DT Article
DE beam losses; accelerator control; predictive model; ARMAX; Kalman filter
ID STATE-SPACE
AB In the Large Hadron Collider, the beam losses are continuously measured for machine protection. By design, most of the particle losses occur in the collimation system, where the particles with high oscilla-tion amplitudes or large momentum error are scraped from the beams. The particle loss level is typically optimized manually by changing control parameters, among which are currents in the focusing and defocusing magnets. It is generally challenging to model and predict losses based only on the control parameters, due to the presence of various (non-linear) effects in the system, such as electron clouds, resonance effects, etc., and multiple sources of uncertainty. At the same time understanding the influence of control parameters on the losses is extremely important in order to improve the operation and performance, and future design of accelerators. Prior work [1] showed that modeling the losses as an instantaneous function of the control parameters does not generalize well to data from a different year, which is an indication that the leveraged statistical associations are not capturing the actual mechanisms which should be invariant from 1 year to the next. Given that this is most likely due to lagged effects, we propose to model the losses as a function of not only instantaneous but also previously observed control parameters as well as previous loss values. Using a standard reparameterization, we reformulate the model as a Kalman Filter (KF) which allows for a flexible and efficient estimation procedure. We consider two main variants: one with a scalar loss output, and a second one with a 4D output with loss, horizontal and vertical emittances, and aggregated heatload as components. The two models once learned can be run for a number of steps in the future, and the second model can forecast the evolution of quantities that are relevant to predicting the loss itself. Our results show that the proposed models trained on the beam loss data from 2017 are able to predict the losses on a time horizon of several minutes for the data of 2018 as well and successfully identify both local and global trends in the losses.
C1 [Krymova, Ekaterina; Obozinski, Guillaume] EPFL, Swiss Data Sci Ctr, Zurich, Switzerland.
   [Krymova, Ekaterina; Obozinski, Guillaume] Swiss Fed Inst Technol, Zurich, Switzerland.
   [Schenk, Michael; Coyle, Loic; Pieloni, Tatiana] Ecole Polytech Fed Lausanne, Inst Phys, Particle Accelerator Phys Lab, Lausanne, Switzerland.
   [Coyle, Loic] CERN, Geneva, Switzerland.
RP Krymova, E (corresponding author), EPFL, Swiss Data Sci Ctr, Zurich, Switzerland.; Krymova, E (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
EM ekaterina.krymova@sdsc.ethz.ch
CR Abada A., 2019, European Physical Journal Special Topics, V228, P1109, DOI 10.1140/epjst/e2019-900088-6
   Abada A, 2019, EUR PHYS J-SPEC TOP, V228, P755, DOI 10.1140/epjst/e2019-900087-0
   Abernethy J, 2009, J MACH LEARN RES, V10, P803
   Aquilina N, 2015, NUCL INSTRUM METH A, V778, P6, DOI 10.1016/j.nima.2014.12.081
   Arpaia P, 2021, NUCL INSTRUM METH A, V985, DOI 10.1016/j.nima.2020.164652
   Belomestny D, 2021, ECON MODEL, V101, DOI 10.1016/j.econmod.2021.105531
   Brüning O, 2012, PROG PART NUCL PHYS, V67, P705, DOI 10.1016/j.ppnp.2012.03.001
   Casals J, 2012, MATH COMPUT SIMULAT, V82, P924, DOI 10.1016/j.matcom.2012.01.001
   Casals J, 1999, ECON LETT, V65, P329, DOI 10.1016/S0165-1765(99)00165-2
   Coyle L., 2021, PROC 12 INT PARTICLE, P4318, DOI [10.18429/JACoW-IPAC2021-THPAB260, DOI 10.18429/JACOW-IPAC2021-THPAB260]
   Coyle LTD, 2018, MACHINE LEARNING APP
   de Jong P, 2004, STAT PROBABIL LETT, V70, P119, DOI 10.1016/j.spl.2004.08.006
   Edelen A, 2020, PHYS REV ACCEL BEAMS, V23, DOI 10.1103/PhysRevAccelBeams.23.044601
   Edwards D A., 2008, INTRO PHYS HIGH ENER
   Evans L, 2007, NEW J PHYS, V9, DOI 10.1088/1367-2630/9/9/335
   Fokianos K, 2009, J AM STAT ASSOC, V104, P1430, DOI 10.1198/jasa.2009.tm08270
   Hamilton J. D., 1994, TIME SERIES ANAL
   Hermes PD., 2015, 6 INT PART ACC C RIC
   Hou K., 2013, ADV NEURAL INF PROCE, V26, P1
   Koser D, 2022, FRONT PHYS-LAUSANNE, V10, DOI 10.3389/fphy.2022.875889
   Krymova Ekaterina, 2022, Zenodo, DOI 10.5281/ZENODO.7305102
   Li SC, 2021, INFORMATION, V12, DOI 10.3390/info12030121
   Ohtani K, 2000, ECON MODEL, V17, P473, DOI 10.1016/S0264-9993(99)00034-6
   Schenk M., 2021, JACOW IPAC, P1923, DOI [10.18429/JACoW-IPAC2021-TUPAB216, DOI 10.18429/JACOW-IPAC2021-TUPAB216]
   Solfaroli Camillocci M., 2016, P IPAC2016, P1489
   Zimmermann F, 2002, CERN REPORT, V2002, P47
   Zimmermann F, 1997, 95 LHC CERN, P18
NR 27
TC 0
Z9 0
U1 1
U2 2
PD JAN 5
PY 2023
VL 10
AR 960963
DI 10.3389/fphy.2022.960963
WC Physics, Multidisciplinary
DA 2023-11-11
ER

PT J
AU Roy, S
   Sridharan, S
   Jain, S
   Raghunathan, A
AF Roy, Sourjya
   Sridharan, Shrihari
   Jain, Shubham
   Raghunathan, Anand
TI TxSim: Modeling Training of Deep Neural Networks on Resistive Crossbar
   Systems
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Deep neural network (DNN) training; in-memory; computing; neural
   networks; resistive random-access memory (ReRAM)
AB Deep neural networks (DNNs) have gained tremendous popularity in recent years due to their ability to achieve superhuman accuracy in a wide variety of machine learning tasks. However, the compute and memory requirements of DNNs have grown rapidly, creating a need for energy-efficient hardware. Resistive crossbars have attracted significant interest in the design of the next generation of DNN accelerators due to their ability to natively execute massively parallel vector-matrix multiplications within dense memory arrays. However, crossbar-based computations face a major challenge due to device and circuit-level nonidealities, which manifest as errors in the vector-matrix multiplications and eventually degrade DNN accuracy. To address this challenge, there is a need for tools that can model the functional impact of nonidealities on DNN training and inference. Existing efforts toward this goal are either limited to inference or are too slow to be used for large-scale DNN training. We propose TxSim, a fast and customizable modeling framework to functionally evaluate DNN training on crossbar-based hardware considering the impact of nonidealities. The key features of TxSim that differentiate it from prior efforts are: 1) it comprehensively models nonidealities during all training operations (forward propagation, backward propagation, and weight update) and 2) it achieves computational efficiency by mapping crossbar evaluations to well-optimized Basic Linear Algebra Subprograms (BLAS) routines and incorporates speedup techniques to further reduce simulation time with minimal impact on accuracy. TxSim achieves 6x-108x improvement in simulation speed over prior works, and thereby makes it feasible to evaluate the training of large-scale DNNs on crossbars. Our experiments using TxSim reveal that the accuracy degradation in DNN training due to nonidealities can be substantial (3%36.4%) for large-scale DNNs and data sets, underscoring the need for further research in mitigation techniques. We also analyze the impact of various device and circuit- level parameters and the associated nonidealities to provide key insights that can guide the design of crossbar-based DNN training accelerators.
C1 [Roy, Sourjya; Sridharan, Shrihari; Jain, Shubham; Raghunathan, Anand] Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
   [Jain, Shubham] IBM Res, TJ Watson Res Ctr, Yorktown Hts, NY 10598 USA.
RP Roy, S; Sridharan, S (corresponding author), Purdue Univ, Sch Elect & Comp Engn, W Lafayette, IN 47906 USA.
EM roy48@purdue.edu; sridhar4@purdue.edu; shubham.jain35@ibm.com;
   raghunathan@purdue.edu
CR Agarwal S, 2016, IEEE IJCNN, P929, DOI 10.1109/IJCNN.2016.7727298
   Akinaga H, 2010, P IEEE, V98, P2237, DOI 10.1109/JPROC.2010.2070830
   Ankit A., 2019, IEEE T COMPUT, V68, P1128
   [Anonymous], 2019, ARXIV190602698
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2014, ARXIV14125567V2CSCL
   [Anonymous], 2011, WW1
   Chakraborty I, 2018, IEEE TETCI, V2, P335, DOI 10.1109/TETCI.2018.2829919
   Chen PY, 2018, IEEE T COMPUT AID D, V37, P3067, DOI 10.1109/TCAD.2018.2789723
   Chen PY, 2015, ICCAD-IEEE ACM INT, P194, DOI 10.1109/ICCAD.2015.7372570
   Fowers J, 2018, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2018.00012
   Gokmen T, 2017, FRONT NEUROSCI-SWITZ, V11, DOI 10.3389/fnins.2017.00538
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   He ZH, 2020, PSYCHOL MED, V50, P2768, DOI 10.1017/S0033291719002915
   Hutter F, 2019, SPRING SER CHALLENGE, P1, DOI 10.1007/978-3-030-05318-5
   Jain S, 2019, IBM J RES DEV, V63, DOI 10.1147/JRD.2019.2947011
   Jain S, 2021, IEEE T COMPUT AID D, V40, P326, DOI 10.1109/TCAD.2020.3000185
   Jain S, 2020, ACM T EMBED COMPUT S, V18, DOI 10.1145/3362035
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kendall Jack, 2020, ARXIV200601981
   Kim KH, 2012, NANO LETT, V12, P389, DOI 10.1021/nl203687n
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Parloff R., REVOLUTION WHY DEEP
   Peng XC, 2021, IEEE T COMPUT AID D, V40, P2306, DOI 10.1109/TCAD.2020.3043731
   Rajendran B, 2007, PROCEEDINGS OF THE 2007 INTERNATIONAL WORKSHOP ON THE PHYSICS OF SEMICONDUCTOR DEVICES: IWPSD-2007, P92, DOI 10.1109/IWPSD.2007.4472460
   Ramasubramanian SG, 2014, I SYMPOS LOW POWER E, P15, DOI 10.1145/2627369.2627625
   Schuman D. C., 2017, ARXIV170506963
   Song LH, 2017, INT S HIGH PERF COMP, P541, DOI 10.1109/HPCA.2017.55
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Xia LX, 2018, IEEE T COMPUT AID D, V37, P1009, DOI 10.1109/TCAD.2017.2729466
   Zhang JT, 2016, SYMP VLSI CIRCUITS
NR 31
TC 18
Z9 18
U1 0
U2 7
PD APR
PY 2021
VL 29
IS 4
BP 730
EP 738
DI 10.1109/TVLSI.2021.3063543
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Yeh, CW
   Tu, CH
   Hung, SH
AF Yeh, Chih-Wei
   Tu, Chia-Heng
   Hung, Shih-Hao
TI Rapid Hybrid Simulation Methods for Exploring the Design Space of Signal
   Processors with Dynamic and Scalable Timing Models
SO JOURNAL OF SIGNAL PROCESSING SYSTEMS FOR SIGNAL IMAGE AND VIDEO
   TECHNOLOGY
DT Article
DE Embedded system; Efficient data transfer; Simulation; Approximate timing
   model; Acceleration; Design space exploration
ID EXPLORATION; FRAMEWORK; SYSTEM
AB As today's state-of-the-art signal processing systems often require heterogeneous computing and special-purpose accelerators to offer highly efficient performance for mixed application workloads, including not only traditional signal processing algorithms, but also the demands to enable smart applications with data analytics, machine learning, as well as the capability interacting with both physical and cyber worlds via sensors and networks. Thus, the complexity of such systems has been increasing, and the focus of designing has been shifting to exploring the design space with a mixture of processing cores/accelerators and the interconnection networks between the components to optimize the performance and efficiency at the system level. Traditional simulation tools may offer accurate performance estimation at micro architectural level, but it is highly complicated to combine the simulators for various components to perform complex applications, and they fall in short in terms of their capabilities to profiling application workload. Furthermore, the speed of such complex simulation would be unacceptably slow with traditional system-level simulation framework such as SystemC. To solve the problem, we develop a rapid hybrid emulation/simulation framework that allows the user to execute full-blown system and application software and plug in emulators, simulators, and timing models for various components in the prototype system, switching the timing models dynamically with our just-in-time model selection mechanism, and connect the emulated/simulated components with scalable communication channels, so that the framework can be accelerated effectively by a multicore host. Our just-in-time model selection mechanism is capable of detecting and skipping regular program patterns to save the simulation time dramatically. In addition, our framework is capable of estimating the performance of different system configurations with concurrent multiple timing models, which further saves the time needed for traversing the design space. Our experimental results have shown that our dynamic model selection and multi-model approach collectively can speed up the design space exploration by 13.4 times on a quad-core host for cache simulation.
C1 [Yeh, Chih-Wei; Hung, Shih-Hao] Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
   [Tu, Chia-Heng] Natl Cheng Kung Univ, Dept Comp Sci & Informat Engn, Tainan, Taiwan.
RP Yeh, CW (corresponding author), Natl Taiwan Univ, Dept Comp Sci & Informat Engn, Taipei, Taiwan.
EM medicinehy@gmail.com; chiaheng@mail.ncku.edu.tw; hungsh@csie.ntu.edu.tw
CR Angiolini F, 2006, DES AUT TEST EUROPE, P1145
   [Anonymous], INTEL PERFORMANCE BO
   [Anonymous], LOADS BLOCK STOR FOR
   [Anonymous], P 2015 C RES AD CONV
   [Anonymous], BUILDROOT MAKING EMB
   [Anonymous], 2011, P 18 INT C CONTROL S
   [Anonymous], INT SYM PERFORM ANAL
   [Anonymous], P 2014 INT C HARDW S
   [Anonymous], INTEL DEV FORUM 4K A
   [Anonymous], 2013, P 50 ANN DES AUT C D
   [Anonymous], 1 INT QEMU US FOR
   [Anonymous], SESC CYCLE ACCURATE
   [Anonymous], 2011, INTRO NETWORK SIMULA
   Beltrame G, 2010, IEEE T COMPUT AID D, V29, P1083, DOI 10.1109/TCAD.2010.2049053
   Binkert Nathan, 2011, Computer Architecture News, V39, P1, DOI 10.1145/2024716.2024718
   Binkert NL, 2006, IEEE MICRO, V26, P52, DOI 10.1109/MM.2006.82
   Bray T., 2014, JAVASCRIPT OBJECT NO
   Burger D., 1997, Computer Architecture News, V25, P13, DOI 10.1145/268806.268810
   Calborean H, 2010, 9TH ROEDUNET IEEE INTERNATIONAL CONFERENCE, P202
   Chen TS, 2014, CONF PROC INT SYMP C, P85, DOI 10.1109/ISCA.2014.6853198
   Cheng-Yen Lin, 2010, 2010 IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis (CODES+ISSS), P95
   Chiou D, 2007, INT SYMP MICROARCH, P249, DOI 10.1109/MICRO.2007.36
   Dubach C, 2007, INT SYMP MICROARCH, P262, DOI 10.1109/MICRO.2007.12
   Durillo JJ, 2010, IEEE C EVOL COMPUTAT
   Dutta R., 1992, Proceedings. 29th ACM/IEEE Design Automation Conference (Cat. No.92CH3144-3), P644, DOI 10.1109/DAC.1992.227806
   Edler J., 1998, DINERO 4 TRACE DRIVE
   Eunsuk Kang, 2010, Foundations of Computer Software. Modeling, Development, and Verification of Adaptive Systems. 16th Monterey Workshop 2010. Revised Selected Papers, P33, DOI 10.1007/978-3-642-21292-5_3
   Guthaus MR, 2001, WWC-4: IEEE INTERNATIONAL WORKSHOP ON WORKLOAD CHARACTERIZATION, P3, DOI 10.1109/WWC.2001.990739
   Hsu HC, 2016, 2016 RESEARCH IN ADAPTIVE AND CONVERGENT SYSTEMS, P230, DOI 10.1145/2987386.2987431
   Hung SH, 2013, 2013 SEVENTH INTERNATIONAL CONFERENCE ON INNOVATIVE MOBILE AND INTERNET SERVICES IN UBIQUITOUS COMPUTING (IMIS 2013), P260, DOI 10.1109/IMIS.2013.52
   Hung SH, 2012, ASIA S PACIF DES AUT, P395, DOI 10.1109/ASPDAC.2012.6164980
   Ipek E, 2007, ACM T ARCHIT CODE OP, V4, DOI 10.1145/1328195.1328196
   Mohanty S, 2002, ACM SIGPLAN NOTICES, V37, P18, DOI 10.1145/566225.513835
   Ozisikyilmaz B, 2008, DES AUT CON, P966
   Power J, 2015, IEEE COMPUT ARCHIT L, V14, P34, DOI 10.1109/LCA.2014.2299539
   Pullini A, 2016, IEEE INT SYMP CIRC S, P2910, DOI 10.1109/ISCAS.2016.7539213
   Rosenfeld P, 2011, IEEE COMPUT ARCHIT L, V10, P16, DOI 10.1109/L-CA.2011.4
   Sanchez Daniel, 2013, INT S COMPUTER ARCHI, P475, DOI DOI 10.1145/2485922.2485963
   Schatz Bernhard, 2010, Proceedings of the 2010 17th IEEE International Conference and Workshops on Engineering of Computer-Based Systems (ECBS 2010), P173, DOI 10.1109/ECBS.2010.25
   Shih-Hao Hung, 2012, 2012 IEEE 1st Global Conference on Consumer Electronics (GCCE 2012), P586, DOI 10.1109/GCCE.2012.6379922
   Stoif C, 2011, IEEE INT SYMP CIRC S, P2557
   Tu CH, 2012, ACM T DES AUTOMAT EL, V17, DOI 10.1145/2348839.2348840
   Ubal R, 2007, INT SYM COMP ARCHIT, P62, DOI 10.1109/SBAC-PAD.2007.17
   Yu K., 2006, P 23 INT C MACH LEAR, P1081
NR 44
TC 0
Z9 0
U1 0
U2 3
PD MAR
PY 2019
VL 91
IS 3-4
SI SI
BP 247
EP 259
DI 10.1007/s11265-017-1285-z
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Ghiglio, P
   Dolinsky, U
   Goli, M
   Narasimhan, K
AF Ghiglio, Pietro
   Dolinsky, Uwe
   Goli, Mehdi
   Narasimhan, Kumudha
TI Improving performance of SYCL applications on CPU architectures using
   LLVM-directed compilation flow
SO CONCURRENCY AND COMPUTATION-PRACTICE & EXPERIENCE
DT Article; Early Access
DE compiler optimizations; multi-cores; parallel programming; portability;
   software acceleration; standards; SYCL
AB The wide adoption of SYCL as an open-standard API for accelerating C++ software in domains such as HPC, automotive, artificial intelligence, machine learning, and other areas necessitates efficient compiler and runtime support for a growing number of different platforms. Existing SYCL implementations provide support for various devices like CPUs, GPUs, DSPs, FPGAs and so forth, typically via OpenCL or CUDA backends. While accelerators have increased the performance of user applications significantly, employing CPU devices for further performance improvement is beneficial due to the significant presence of CPUs in existing data-centers. SYCL applications on CPUs, currently go through an OpenCL backend. Though an OpenCL backend is valuable in supporting accelerators, it may introduce additional overhead for CPUs since the host and device are the same. Overheads like a run-time compilation of the kernel, transferring of input/output memory to/from the OpenCL device, invoking the OpenCL kernel and so forth, may not be necessary when running on the CPU. While some of these overheads (such as data transfer) can be avoided by modifying the application, it can introduce disparity in the SYCL application's ability to achieve performance portability on other devices. In this article, we propose an alternate approach to running SYCL applications on CPUs. We bypass OpenCL and use a CPU-directed compilation flow, along with the integration of whole function vectorization to generate optimized host and device code together in the same translation unit. We compare the performance of our approach-the CPU-directed compilation flow, with an OpenCL backend for existing SYCL-based applications, with no code modification for BabelStream benchmark, Matmul from the ComputeCpp SDK, N-body simulation benchmarks and SYCL-BLAS (Aliaga et al. Proceedings of the 5th International Workshop on OpenCL; 2017.), on CPUs from different vendors and architectures. We report a performance improvement of up to 72%$$ 72\% $$ on BabelStream benchmarks, up to 63%$$ 63\% $$ on Matmul, up to 21%$$ 21\% $$ on the N-body simulation benchmark and up to 16% on SYCL-BLAS.
C1 [Ghiglio, Pietro; Dolinsky, Uwe; Goli, Mehdi; Narasimhan, Kumudha] Codeplay Software Ltd, Edinburgh, Scotland.
RP Ghiglio, P (corresponding author), Codeplay Software Ltd, Edinburgh, Scotland.
EM pietro.ghiglio@codeplay.com
CR 01.org, ONEAPI DEEP NEURAL N
   Aliaga JI., P 5 INT WORKSH OPENC
   Aliaga JI., 2017, P 5 INT WORKSHOP OPE, DOI [10.1145/3078155.3078189, DOI 10.1145/3078155.3078189]
   Alpay A., P INT WORKSH OPENCL
   [Anonymous], ONEDPL ONEAPI DPC LI
   [Anonymous], NVIDIA CUDA PROGRAMM
   [Anonymous], SYCL N BODY SIMULATI
   [Anonymous], SYCL SPECIFICATION C
   Ashbaugh B., P INT WORKSH OPENCL
   Bellard F., P USENIX ANN TECHN C
   Brown G., P INT WORKSH OPENCL
   Burns R., P INT WORKSH OPENCL, DOI [10.1145/3456669.3456687, DOI 10.1145/3456669.3456687]
   Burns R, 2019, PROCEEDINGS OF THE INTERNATIONAL WORKSHOP ON OPENCL (IWOCL'19), DOI 10.1145/3318170.3318183
   clang.llvm, CROSS COMPILING CLAN
   Copik M., P 5 INT WORKSH OPENC
   Deakin T, 2016, LECT NOTES COMPUT SC, V9945, P489, DOI 10.1007/978-3-319-46079-6_34
   developer.codeplay, COMPUTECPP COMMUNITY
   Feng W., P INT WORKSH OPENCL
   Ghiglio P., IMPROVING PERFORMANC, DOI [10.1145/3528425.3529099, DOI 10.1145/3528425.3529099]
   github, COMPUTECPP SDK
   github, WHOLE FUNCTION VECTO
   github, HECBENCH
   Goli M., P 4 INT WORKSH OPENC
   Gozillon A., P 2020 INT C HIGH PE
   intel, VECTORIZATION SIMD P
   Karrenberg R, 2015, AUTOMATIC SIMD VECTO, P85
   Ke YA, 2020, PROCEEDINGS OF INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING IN ASIA-PACIFIC REGION (HPC ASIA 2021), P50, DOI 10.1145/3432261.3432268
   Lattner C., P BSD C
   Lawson J, 2021, PARALLEL COMPUT, V107, DOI 10.1016/j.parco.2021.102813
   Meyer J., INT WORKSH OPENCL IW, DOI [10.1145/3529538.3530216, DOI 10.1145/3529538.3530216]
   Murray A., P INT WORKSH OPENCL, DOI [10.1145/3388333.3388652, DOI 10.1145/3388333.3388652]
   oneapi, INTEL ONEAPI MATH KE
   oneapi, ONEAPI SPECIFICATION
   Pheatt C., 2008, J COMPUT SCI COLL, V23, P298
   portablecl, PORTABLE COMPUTING L
   qemu, RISC V SYSTEM EMULAT
   Reinders J., 2021, DATA PARALLEL C MAST
   Sato M., P 2020 19 INT S PAR
   Stone JE, 2010, COMPUT SCI ENG, V12, P66, DOI 10.1109/MCSE.2010.69
   Thoman P., P INT WORKSH OPENCL
   Yamada Y., P S HIGH PERF CHIPS
NR 41
TC 0
Z9 0
U1 1
U2 1
PD 2023 MAY 30
PY 2023
DI 10.1002/cpe.7810
EA MAY 2023
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Koppula, S
   Orosa, L
   Yaglikçi, AG
   Azizi, R
   Shahroodi, T
   Kanellopoulos, K
   Mutlu, O
AF Koppula, Skanda
   Orosa, Lois
   Yaglikci, A. Giray
   Azizi, Roknoddin
   Shahroodi, Taha
   Kanellopoulos, Konstantinos
   Mutlu, Onur
GP Assoc Comp Machinery
TI EDEN: Enabling Energy-Efficient, High-Performance Deep Neural Network
   Inference Using Approximate DRAM
SO MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON
   MICROARCHITECTURE
DT Proceedings Paper
CT 52nd Annual IEEE/ACM International Symposium on Microarchitecture
   (MICRO)
CY OCT 12-16, 2019
CL Columbus, OH
DE deep neural networks; error tolerance; energy efficiency; machine
   learning; DRAM; memory systems
AB The effectiveness of deep neural networks (DNN) in vision, speech, and language processing has prompted a tremendous demand for energy-efficient high-performance DNN inference systems. Due to the increasing memory intensity of most DNN workloads, main memory can dominate the system's energy consumption and stall time. One effective way to reduce the energy consumption and increase the performance of DNN inference systems is by using approximate memory, which operates with reduced supply voltage and reduced access latency parameters that violate standard specifications. Using approximate memory reduces reliability, leading to higher bit error rates. Fortunately, neural networks have an intrinsic capacity to tolerate increased bit errors. This can enable energy-efficient and high-performance neural network inference using approximate DRAM devices.
   Based on this observation, we propose EDEN, the first general framework that reduces DNN energy consumption and DNN evaluation latency by using approximate DRAM devices, while strictly meeting a user-specified target DNN accuracy. EDEN relies on two key ideas: 1) retraining the DNN for a target approximate DRAM device to increase the DNN's error tolerance, and 2) efficient mapping of the error tolerance of each individual DNN data type to a corresponding approximate DRAM partition in a way that meets the user-specified DNN accuracy requirements.
   We evaluate EDEN on multi-core CPUs, GPUs, and DNN accelerators with error models obtained from real approximate DRAM devices. We show that EDEN's DNN retraining technique reliably improves the error resiliency of the DNN by an order of magnitude. For a target accuracy within 1% of the original DNN, our results show that EDEN enables 1) an average DRAM energy reduction of 21%, 37%, 31%, and 32% in CPU, GPU, and two different DNN accelerator architectures, respectively, across a variety of state-of-the-art networks, and 2) an average (maximum) speedup of 8% (17%) and 2.7% (5.5%) in CPU and GPU architectures, respectively, when evaluating latency-bound neural networks.
C1 [Koppula, Skanda; Orosa, Lois; Yaglikci, A. Giray; Azizi, Roknoddin; Shahroodi, Taha; Kanellopoulos, Konstantinos; Mutlu, Onur] Swiss Fed Inst Technol, Zurich, Switzerland.
RP Koppula, S (corresponding author), Swiss Fed Inst Technol, Zurich, Switzerland.
CR Advani S., 2014, ICCD
   Albericio J, 2016, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2016.11
   Alwani M., 2016, MICROPAGE, P1
   Andri R., 2017, TCAD
   [Anonymous], 2009, PERFORMANCE ANAL GUI
   [Anonymous], ICCD
   [Anonymous], 2017, THESIS CARNEGIE MELL
   [Anonymous], 2013, DAC
   [Anonymous], 2003, HPCA
   [Anonymous], 2017, ICLR
   [Anonymous], 2013, THESIS
   Aurisano A., 2016, JINST
   Baek S., 2013, TC
   Bakhoda A, 2009, INT SYM PERFORM ANAL, P163, DOI 10.1109/ISPASS.2009.4919648
   Baseman E., 2018, DFT
   Boroumand A, 2018, ACM SIGPLAN NOTICES, V53, P316, DOI [10.1145/3173162.3173177, 10.1145/3296957.3173177]
   Cavigelli L., 2017, TCSVT
   Chandrasekar K., 2012, DRAMPOWER OPEN SOURC
   Chandrasekar K., 2014, DATE
   Chang KK, 2017, P ACM MEAS ANAL COMP, V1, DOI 10.1145/3084447
   Chang KK, 2016, SIGMETRICS/PERFORMANCE 2016: PROCEEDINGS OF THE SIGMETRICS/PERFORMANCE JOINT INTERNATIONAL CONFERENCE ON MEASUREMENT AND MODELING OF COMPUTER SCIENCE, P323, DOI [10.1145/2896377.2901453, 10.1145/2964791.2901453]
   Chang KK, 2016, INT S HIGH PERF COMP, P568, DOI 10.1109/HPCA.2016.7446095
   Chang KKW, 2014, INT S HIGH PERF COMP, P356, DOI 10.1109/HPCA.2014.6835946
   Chen G., 2014, ICASSP
   Chen T., 2016, TRAINING DEEP NETS W
   Chen TQ, 2018, PROCEEDINGS OF THE 13TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION, P579
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Chen YH, 2019, IEEE J EM SEL TOP C, V9, P292, DOI 10.1109/JETCAS.2019.2910232
   Chen YH, 2017, IEEE J SOLID-ST CIRC, V52, P127, DOI 10.1109/JSSC.2016.2616357
   Chetlur S., 2014, CUDNN EFFICIENT PRIM
   Chi P., 2016, P INT S COMP ARCH IS
   Choi J, 2015, 2015 ACM/IEEE 42ND ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA), P223, DOI 10.1145/2749469.2750402
   Chou Y, 2004, CONF PROC INT SYMP C, P76, DOI 10.1109/ISCA.2004.1310765
   Courbariaux Matthieu, 2016, ABS160202830 CORR
   Cun Y. L., 1990, NIPS
   Dally, 2016, ARXIV161201064
   Das A., 2018, DAC
   David H., 2011, P 8 ACM INT C AUT CO, P31, DOI DOI 10.1145/1998582.1998590
   De Sa C., 2018, HIGH ACCURACY LOWPRE
   Deng J., 2015, DATE
   Deng QY, 2011, ACM SIGPLAN NOTICES, V46, P225, DOI 10.1145/1961296.1950392
   Deng Q, 2018, DES AUT CON, DOI 10.1145/3195970.3196029
   Dong C, 2014, LECT NOTES COMPUT SC, V8692, P184, DOI 10.1007/978-3-319-10593-2_13
   Du S. S., 2018, ARXIV PREPRINT ARXIV
   Dundas J., 1997, Conference Proceedings of the 1997 International Conference on Supercompting, P68, DOI 10.1145/263580.263597
   Dundas J. D., 1999, TECH REP
   Gao MY, 2017, TWENTY-SECOND INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS (ASPLOS XXII), P751, DOI 10.1145/3037697.3037702
   Ghose S., 2019, SIGMETRICS
   Ghose S, 2018, P ACM MEAS ANAL COMP, V2, DOI 10.1145/3224419
   Gomez A. N., 2017, P 31 INT C NEUR INF, P2211
   Graves A, 2014, PR MACH LEARN RES, V32, P1764
   Guan M., 2015, ISQED
   Guo K., 2017, TCAD
   Gupta S., 2018, RAPIDNN IN MEMORY DE
   Hamamoto T., 1998, TED
   Han S., 2015, ARXIV151000149
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Hassan H, 2019, PROCEEDINGS OF THE 2019 46TH INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA '19), P129, DOI 10.1145/3307650.3322231
   Hassan H, 2017, INT S HIGH PERF COMP, P241, DOI 10.1109/HPCA.2017.62
   Hassan H, 2016, INT S HIGH PERF COMP, P581, DOI 10.1109/HPCA.2016.7446096
   He K., 2016, P IEEE C COMPUTER VI
   He Yang, 2019, CVPR
   He YH, 2018, LECT NOTES COMPUT SC, V11211, P815, DOI 10.1007/978-3-030-01234-2_48
   Hosang J, 2017, PROC CVPR IEEE, P6469, DOI 10.1109/CVPR.2017.685
   Hubara I., 2017, IMLR
   Iandola F., 2014, ARXIV14041869, P1, DOI DOI 10.1080/08839514.2013.848751
   Iandola F. N., 2016, SQUEEZENET ALEXNET L
   Jacob B, 2018, PROC CVPR IEEE, P2704, DOI 10.1109/CVPR.2018.00286
   JEDEC Standard, 2012, JESD794 JEDEC DDR4 S
   Jin W, 2017, ADV NEURAL INFORM PR, P2607
   Joseph RK, 2016, CRIT POL ECON S ASIA, P1
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Jung M., 2015, MEMSYS
   Jung M., 2016, DAC
   KEETH B, 2000, DRAM CIRCUIT DESIGN
   Khan Samira, 2016, 2016 46th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). Proceedings, P239, DOI 10.1109/DSN.2016.30
   Khan Samira, 2014, ACM SIGMETRICS Performance Evaluation Review, V42, P519, DOI 10.1145/2591971.2592000
   Kim JS, 2019, INT S HIGH PERF COMP, P582, DOI 10.1109/HPCA.2019.00011
   Kim JS, 2018, PR IEEE COMP DESIGN, P282, DOI 10.1109/ICCD.2018.00051
   Kim JS, 2018, INT S HIGH PERF COMP, P194, DOI 10.1109/HPCA.2018.00026
   Kim Y, 2016, IEEE COMPUT ARCHIT L, V15, P45, DOI 10.1109/LCA.2015.2414456
   Kim Y, 2012, CONF PROC INT SYMP C, P368
   Kokkinos I, 2017, PROC CVPR IEEE, P5454, DOI 10.1109/CVPR.2017.579
   Kozlov A., 2019, INTELLISYS
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   Kwon H, 2018, ACM SIGPLAN NOTICES, V53, P461, DOI [10.1145/3296957.3173176, 10.1145/3173162.3173176]
   Kwon Hyoukjun, 2018, MAESTRO OPEN SOURCE
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y., 1995, CTP PBSRI
   LeCun Y., 1990, ADV NEURAL INFORM PR, P598, DOI DOI 10.5555/109230.109298
   Lecun Yann, 2015, NATURE
   Lee D., 2013, HPCA
   Lee D., 2017, SIGMETRICS
   Lee D., 2015, PACT
   Lee D, 2015, INT S HIGH PERF COMP, P489, DOI 10.1109/HPCA.2015.7056057
   Leng Jingwen, 2013, ISCA
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Li H., 2016, 5 INT C LEARNING REP, P1
   Li J., 2018, DATE
   Li S., MICRO
   Li S., 2018, MICRO
   Lillicrap TP., 2015, ARXIV, DOI DOI 10.1016/S1098-3015(10)67722-4
   Lin DD, 2016, PR MACH LEARN RES, V48
   Lin TY, 2014, LECT NOTES COMPUT SC, V8693, P740, DOI 10.1007/978-3-319-10602-1_48
   Liu JM, 2012, CONF PROC INT SYMP C, P1, DOI 10.1109/ISCA.2012.6237001
   Long Y., 2018, TVLSI
   Lu S.-L., 2015, MICRO
   Lu WY, 2017, INT S HIGH PERF COMP, P553, DOI 10.1109/HPCA.2017.29
   Marques J., 2017, SIPS
   Meza J, 2015, I C DEPEND SYS NETWO, P415, DOI 10.1109/DSN.2015.57
   Micron, TN4007 MICR
   Mutlu O., 2005, CAL
   Mutlu O., 2015, MORE MOORE TECHNOLOG
   Mutlu O., 2005, ISCA
   Nazemi M., 2018, NULLANET TRAINING DE
   Neggaz M. A., 2018, ICCD
   Neubeck Alexander, 2006, ICPR
   Neyshabur Behnam, 2018, UNDERSTANDING ROLE O
   Nguyen D. T., 2018, ISCAS
   Nguyen D.-T., 2019, DAC
   Novak R., 2018, ICLR
   Oh K.-S., 2004, JPRR
   Panda P., 2016, DAC
   Parashar A, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P27, DOI 10.1145/3079856.3080254
   Patel M., 2019, DSN
   Patel M, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P255, DOI 10.1145/3079856.3080242
   Phatak D. S., 1995, TNN
   Qin M., 2017, ROBUSTNESS NEURAL NE
   Qureshi MK, 2015, I C DEPEND SYS NETWO, P427, DOI 10.1109/DSN.2015.58
   Rau PLP, 2013, ADV HUM-COMPUT INTER, V2013, DOI 10.1155/2013/263721
   Reagen B, 2018, DES AUT CON, DOI 10.1145/3195970.3195997
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Redmon J., 2013, DARKNET OPEN SOURCE
   Rezatofighi H, 2019, PROC CVPR IEEE, P658, DOI 10.1109/CVPR.2019.00075
   ROBBINS H, 1951, ANN MATH STAT, V22, P400, DOI 10.1214/aoms/1177729586
   Russakovsky O, 2015, INT J COMPUT VISION, V115, P211, DOI 10.1007/s11263-015-0816-y
   Salami B., 2018, RESILIENCE RTL NN AC
   Salami B, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P724, DOI [10.1109/MICR0.2018.00064, 10.1109/MICRO.2018.00064]
   Salavati A. H., 2012, ISIT
   Samajdar A., 2018, COMPUTING RES REPOSI
   Sanchez D., 2013, ISCA, P475
   Sandler M, 2018, PROC CVPR IEEE, P4510, DOI 10.1109/CVPR.2018.00474
   Schroeder B, 2009, PERF E R SI, V37, P193
   Schuiki F., 2018, SCALABLE NEAR MEMORY
   Segler M., 2017, ACS CENTRAL SCI
   Seshadri V., 2019, CORR
   Seshadri V, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P273, DOI 10.1145/3123939.3124544
   Shafiee A, 2016, CONF PROC INT SYMP C, P14, DOI 10.1109/ISCA.2016.12
   Shazeer N., 2017, OUTRAGEOUSLY LARGE N, P1
   Shen YM, 2017, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2017.47
   Shi W., 2014, CASES
   Shixiang Gu, 2017, 2017 IEEE International Conference on Robotics and Automation (ICRA), P3389, DOI 10.1109/ICRA.2017.7989385
   Simonyan K, 2015, Arxiv, DOI arXiv:1409.1556
   Son Y. H., 2013, ISCA
   Song L., 2016, P 53 ANN DES AUT C D
   Sprangle E., 2002, ISCA
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Sze V, 2017, IEEE CUST INTEGR CIR
   Tang X., 2016, MICRO
   Temam O, 2012, CONF PROC INT SYMP C, P356, DOI 10.1109/ISCA.2012.6237031
   Tu F., 2018, ISCA
   Ueyoshi K, 2018, ISSCC DIG TECH PAP I, P216, DOI 10.1109/ISSCC.2018.8310261
   Venkataramani S, 2014, I SYMPOS LOW POWER E, P27, DOI 10.1145/2627369.2627613
   Vogelsang T., 2010, MICRO
   Wang YH, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P298, DOI 10.1109/MICRO.2018.00032
   Whatmough PN, 2017, ISSCC DIG TECH PAP I, P242, DOI 10.1109/ISSCC.2017.7870351
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Xie SN, 2017, PROC CVPR IEEE, P5987, DOI 10.1109/CVPR.2017.634
   Yang L., 2017, ISVLSI
   Yang LT, 2017, INT SYM QUAL ELECT, P7, DOI 10.1109/ISQED.2017.7918284
   Yang TJ, 2018, LECT NOTES COMPUT SC, V11214, P289, DOI 10.1007/978-3-030-01249-6_18
   Yang TJ, 2017, PROC CVPR IEEE, P6071, DOI 10.1109/CVPR.2017.643
   Yu JC, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P548, DOI 10.1145/3079856.3080215
   Zhang, 2016, P 49 ANN IEEE ACM IN, P20, DOI DOI 10.1109/MICRO.2016.7783723
   Zhang J.J., 2018, P VLSI TEST S VTS 20, P1, DOI 10.1109/VTS.2018.8368656
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang Q, 2015, DES AUT TEST EUROPE, P701
   Zhang T, 2014, CONF PROC INT SYMP C, P349, DOI 10.1109/ISCA.2014.6853217
   Zhang X., 2016, MEMSYS
NR 179
TC 57
Z9 57
U1 1
U2 8
PY 2019
BP 166
EP 181
DI 10.1145/3352460.3358280
WC Computer Science, Hardware & Architecture
DA 2023-11-11
ER

PT J
AU Mund, K
   Maloney, L
   Lu, B
   Wu, J
   Li, J
   Liu, C
   Yan, GH
AF Mund, Karl
   Maloney, Luke
   Lu, Bo
   Wu, Jian
   Li, Jonathan
   Liu, Chihray
   Yan, Guanghua
TI Reconstruction of volume averaging effect-free continuous photon beam
   profiles from discrete ionization chamber array measurements using a
   machine learning technique
SO JOURNAL OF APPLIED CLINICAL MEDICAL PHYSICS
DT Article
DE artificial neural network; ion chamber array; volume averaging effect
ID QUALITY-ASSURANCE; COMMITTEE
AB Purpose The use of the ionization chamber array ICProfiler (ICP) is limited by its relatively poor detector spatial resolution and the inherent volume averaging effect (VAE). The purpose of this work is to study the feasibility of reconstructing VAE-free continuous photon beam profiles from ICP measurements with a machine learning technique. Methods In- and cross-plane photon beam profiles of a 6 MV beam from an Elekta linear accelerator, ranging from 2 x 2 to 10 x 10 cm(2) at 1.5 cm, 5 cm, and 10 cm depth, were measured with an ICP. The discrete measurements were interpolated with a Makima method to obtain continuous beam profiles. Artificial neural networks (ANNs) were trained to restore the penumbra of the beam profiles. Plane-specific (in- and cr-plane) ANNs and a combined ANN were separately trained. The performance of the ANNs was evaluated using the penumbra width difference (PWD, the difference between the penumbra widths of the reconstructed and the reference profile). The plane-specific and the combined ANNs were compared to study the feasibility of using a single ANN for both in- and cross-plane. Results The profiles reconstructed with all the ANNs had excellent agreement with the reference. For in-plane, the ANNs reduced the PWD from 1.6 +/- 0.7 mm at 1.5 cm depth to 0.1 +/- 0.1 mm, from 1.8 +/- 0.6 mm at 5.0 cm depth to 0.1 +/- 0.1 mm, and from 2.4 +/- 0.1 mm at 10.0 cm depth to 0.0 +/- 0.0 mm; for cross-plane, the ANNs reduced the PWD from 1.2 +/- 0.4 mm at 1.5 cm depth, 1.2 +/- 0.3 mm at 5.0 cm depth, and 1.6 +/- 0.1 mm at 10.0 cm depth, to 0.1 +/- 0.1 mm. Conclusions This study demonstrated the feasibility of using simple ANNs to reconstruct VAE-free continuous photon beam profiles from discrete ICP measurements. A combined ANN can restore the penumbra of in- and cross-plane beam profiles of various fields at different depths.
C1 [Mund, Karl; Maloney, Luke; Lu, Bo; Wu, Jian; Li, Jonathan; Liu, Chihray; Yan, Guanghua] Univ Florida, Dept Radiat Oncol, POB 100385, Gainesville, FL 32610 USA.
RP Yan, GH (corresponding author), Univ Florida, Dept Radiat Oncol, POB 100385, Gainesville, FL 32610 USA.
EM yangua@shands.ufl.edu
CR Barraclough B, 2015, PHYS MED BIOL, V60, P6213, DOI 10.1088/0031-9155/60/16/6213
   Das IJ, 2008, MED PHYS, V35, P4186, DOI 10.1118/1.2969070
   Feng M, 2018, FRONT ONCOL, V8, DOI 10.3389/fonc.2018.00110
   Fraass B, 1998, MED PHYS, V25, P1773, DOI 10.1118/1.598373
   Gao S, 2019, J APPL CLIN MED PHYS, V20, P111, DOI 10.1002/acm2.12719
   Kalet AM, 2020, MED PHYS, V47, pE168, DOI 10.1002/mp.13445
   Karimnia V, 2018, J APPL CLIN MED PHYS, V19, P323, DOI 10.1002/acm2.12466
   Klein EE, 2009, MED PHYS, V36, P4197, DOI 10.1118/1.3190392
   Liu H, 2018, MED PHYS, V45, P5586, DOI 10.1002/mp.13230
   Low DA, 2003, MED PHYS, V30, P1706, DOI 10.1118/1.1582558
   Mund K, 2020, J APPL CLIN MED PHYS, V21, P53, DOI 10.1002/acm2.12865
   Perik TJ, 2018, PHYS MED BIOL, V63, DOI 10.1088/1361-6560/aae90a
   RIKNER G, 1987, PHYS MED BIOL, V32, P1109, DOI 10.1088/0031-9155/32/9/004
   Simon TA, 2010, MED PHYS, V37, P6101, DOI 10.1118/1.3505452
   Smit K, 2014, PHYS MED BIOL, V59, P1845, DOI 10.1088/0031-9155/59/7/1845
   Valdes G., 2020, FRONT ARTIF INTELL, V3
   Westermark M, 2000, PHYS MED BIOL, V45, P685, DOI 10.1088/0031-9155/45/3/308
   Yan GH, 2008, MED PHYS, V35, P3661, DOI 10.1118/1.2952643
NR 18
TC 2
Z9 2
U1 1
U2 2
PD OCT
PY 2021
VL 22
IS 10
BP 161
EP 168
DI 10.1002/acm2.13411
EA SEP 2021
WC Radiology, Nuclear Medicine & Medical Imaging
DA 2023-11-11
ER

PT J
AU Zhang, ZZ
   Zhu, GX
   Wang, R
   Lau, VKN
   Huang, KB
AF Zhang, Zezhong
   Zhu, Guangxu
   Wang, Rui
   Lau, Vincent K. N.
   Huang, Kaibin
TI Turning Channel Noise Into an Accelerator for Over-the-Air Principal
   Component Analysis
SO IEEE TRANSACTIONS ON WIRELESS COMMUNICATIONS
DT Article
DE Principal component analysis; Servers; Distributed databases; Signal to
   noise ratio; Convergence; Atmospheric modeling; Optimization; Federated
   edge learning; principal component analysis (PCA); over-the-air
   computation; power control; convergence analysis
ID APPROXIMATION; QUANTIZATION; RECOGNITION
AB The enormous data distributed at the network edge and ubiquitous connectivity have led to the emergence of the new paradigm of distributed machine learning and large-scale data analytics. Distributed principal component analysis (PCA) concerns finding a low-dimensional subspace that contains the most important information of high-dimensional data distributed over the network edge. The subspace is useful for distributed data compression and feature extraction. This work advocates the application of over-the-air federated learning to efficient implementation of distributed PCA in a wireless network under a data-privacy constraint, termed AirPCA. The design features the exploitation of the waveform-superposition property of a multi-access channel to realize over-the-air aggregation of local subspace updates computed and simultaneously transmitted by devices to a server, thereby reducing the multi-access latency. The original drawback of this class of techniques, namely channel-noise perturbation to uncoded analog modulated signals, is turned into a mechanism for escaping from saddle points during stochastic gradient descent (SGD) in the AirPCA algorithm. As a result, the convergence of the AirPCA algorithm is accelerated. To materialize the idea, descent speeds in different types of descent regions are analyzed mathematically using martingale theory by accounting for wireless propagation and techniques including broadband transmission, over-the-air aggregation, channel fading and noise. The results reveal the accelerating effect of noise in saddle regions and the opposite effect in other types of regions. The insight and results are applied to designing an online scheme for adapting receive signal power to the type of current descent region. Specifically, the scheme amplifies the noise effect in saddle regions by reducing signal power and applies the power savings to suppressing the effect in other regions. From experiments using real datasets, such power control is found to accelerate convergence while achieving the same convergence accuracy as in the ideal case of centralized PCA.
C1 [Zhang, Zezhong; Huang, Kaibin] Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China.
   [Zhang, Zezhong] Chinese Univ Hong Kong Shenzhen, Future Network Intelligence Inst FNii, Shenzhen 518172, Peoples R China.
   [Zhu, Guangxu] Shenzhen Res Inst Big Data, Shenzhen 518172, Peoples R China.
   [Wang, Rui] Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China.
   [Lau, Vincent K. N.] Hong Kong Univ Sci & Technol, Dept Elect & Comp Engn, Hong Kong, Peoples R China.
RP Huang, KB (corresponding author), Univ Hong Kong, Dept Elect & Elect Engn, Hong Kong, Peoples R China.; Wang, R (corresponding author), Southern Univ Sci & Technol, Dept Elect & Elect Engn, Shenzhen 518055, Peoples R China.
EM zhangzezhong@cuhk.edu.cn; gxzhu@sribd.cn; wang.r@sustech.edu.cn;
   eeknlau@ust.hk; huangkb@eee.hku.hk
CR Abdi H, 2010, WIRES COMPUT STAT, V2, P433, DOI 10.1002/wics.101
   Amiri MM, 2020, IEEE T WIREL COMMUN, V19, P3546, DOI 10.1109/TWC.2020.2974748
   Bartlett MS, 2002, IEEE T NEURAL NETWOR, V13, P1450, DOI 10.1109/TNN.2002.804287
   Belhumeur PN, 1997, IEEE T PATTERN ANAL, V19, P711, DOI 10.1109/34.598228
   Bertsekas D, 1978, STOCHASTIC OPTIMAL C
   Chen MZ, 2021, IEEE T WIREL COMMUN, V20, P269, DOI 10.1109/TWC.2020.3024629
   Du YQ, 2020, IEEE T SIGNAL PROCES, V68, P2128, DOI 10.1109/TSP.2020.2983166
   Fan JQ, 2019, ANN STAT, V47, P3009, DOI 10.1214/18-AOS1713
   Friedlander MP, 2013, SIAM J SCI COMPUT, V35, pB950, DOI 10.1137/130908257
   Ge Rong, 2015, C LEARNING THEORY, P797, DOI DOI 10.1109/ICMTMA.2015.197
   Grammenos A., 2020, ADV NEURAL INFORM PR, P6453
   Iwen MA, 2016, SIAM J MATRIX ANAL A, V37, P1699, DOI 10.1137/16M1058467
   Jin C, 2017, PR MACH LEARN RES, V70
   Liang Y., 2014, ADV NEURAL INFORM PR, P3113
   Lim WYB, 2020, IEEE COMMUN SURV TUT, V22, P2031, DOI 10.1109/COMST.2020.2986024
   Lin ZY, 2022, IEEE T WIREL COMMUN, V21, P1542, DOI 10.1109/TWC.2021.3104834
   Liu DZ, 2021, IEEE J SEL AREA COMM, V39, P170, DOI 10.1109/JSAC.2020.3036948
   Luo SQ, 2020, IEEE T WIREL COMMUN, V19, P6535, DOI 10.1109/TWC.2020.3003744
   McMahan HB, 2017, PR MACH LEARN RES, V54, P1273
   Mertikopoulos Panayotis, 2020, ADV NEURAL INFORM PR, V33, P1117
   Narayanamurthy P, 2022, Arxiv, DOI arXiv:2002.12873
   OJA E, 1985, J MATH ANAL APPL, V106, P69, DOI 10.1016/0022-247X(85)90131-3
   Samarakoon S, 2020, IEEE T COMMUN, V68, P1146, DOI 10.1109/TCOMM.2019.2956472
   Shlezinger N, 2021, IEEE T SIGNAL PROCES, V69, P500, DOI 10.1109/TSP.2020.3046971
   Sun YW, 2020, IEEE T WIREL COMMUN, V19, P6331, DOI 10.1109/TWC.2020.3002719
   Wang AD, 2020, IEEE T WIREL COMMUN, V19, P6786, DOI 10.1109/TWC.2020.3006042
   Xiaopeng Mo, 2021, Journal of Communications and Information Networks, V6, P110, DOI 10.23919/JCIN.2021.9475121
   YANG B, 1995, IEEE T SIGNAL PROCES, V43, P95, DOI 10.1109/78.365290
   Yang HH, 2020, IEEE T COMMUN, V68, P317, DOI 10.1109/TCOMM.2019.2944169
   Yang K, 2020, IEEE T WIREL COMMUN, V19, P2022, DOI 10.1109/TWC.2019.2961673
   Yang ZH, 2021, IEEE T WIREL COMMUN, V20, P1935, DOI 10.1109/TWC.2020.3037554
   Zeng QS, 2021, IEEE T WIREL COMMUN, V20, P7947, DOI 10.1109/TWC.2021.3088910
   Zhai XF, 2021, IEEE T COMMUN, V69, P2737, DOI 10.1109/TCOMM.2021.3051397
   Zhang NF, 2021, IEEE T WIREL COMMUN, V20, P5115, DOI 10.1109/TWC.2021.3065748
   Zhu GX, 2021, IEEE T WIREL COMMUN, V20, P2120, DOI 10.1109/TWC.2020.3039309
   Zhu GX, 2020, IEEE T WIREL COMMUN, V19, P491, DOI 10.1109/TWC.2019.2946245
   Zhu GX, 2019, IEEE INTERNET THINGS, V6, P6089, DOI 10.1109/JIOT.2018.2871070
NR 37
TC 2
Z9 2
U1 3
U2 6
PD OCT
PY 2022
VL 21
IS 10
BP 7926
EP 7941
DI 10.1109/TWC.2022.3162868
WC Engineering, Electrical & Electronic; Telecommunications
DA 2023-11-11
ER

PT C
AU Mokhtari, A
   Rawls, D
   Huynh, T
   Green, J
   Salehi, MA
AF Mokhtari, Ali
   Rawls, Drake
   Huynh, Tony
   Green, Jeremiah
   Salehi, Mohsen Amini
GP IEEE
TI E2C: A Visual Simulator to Reinforce Education of Heterogeneous
   Computing Systems
SO 2023 IEEE INTERNATIONAL PARALLEL AND DISTRIBUTED PROCESSING SYMPOSIUM
   WORKSHOPS, IPDPSW
SE IEEE International Symposium on Parallel and Distributed Processing
   Workshops
DT Proceedings Paper
CT 37th IEEE International Parallel and Distributed Processing Symposium
   (IPDPS)
CY MAY 15-19, 2023
CL St Petersburg, FL
ID TOOLKIT
AB Heterogeneity has been an indispensable aspect of distributed computing throughout the history of these systems. In particular, with the increasing popularity of accelerator technologies (e.g., GPUs and TPUs) and the emergence of domain-specific computing via ASICs and FPGA, the matter of heterogeneity and understanding its ramifications on the system performance has become more critical than ever before. However, it is challenging to effectively educate students about the potential impacts of heterogeneity on: (a) the performance of distributed systems; and (b) the logic of resource allocation methods to efficiently utilize the resources. Making use of the real infrastructure (such as those offered by the public cloud providers) for benchmarking the performance of heterogeneous machines, for different applications, with respect to different objectives, and under various workload intensities is cost- and time-prohibitive. Moreover, not all students (globally and nationally) have access or can afford such real infrastructure. To reinforce the quality of learning about various dimensions of heterogeneity, and to decrease the widening gap in education, we develop an open-source simulation tool, called E2C, that can help students researchers and practitioners to study any type of heterogeneous (or homogeneous) computing system and measure its performance under various system configurations. To make the learning curve shallow, E2C is equipped with an intuitive graphical user interface (GUI) that enables its users to easily examine system-level solutions (scheduling, load balancing, scalability, etc.) in a controlled environment within a short time and at no cost. In particular, E2C is a discrete event simulator that offers the following features: (i) simulating a heterogeneous computing system; (ii) implementing a newly developed scheduling method and plugging it into the system, (iii) measuring energy consumption and other output-related metrics; and (iv) powerful visual aspects to ease the learning curve for students. We used E2C as an assignment in the Distributed and Cloud Computing course. Our anonymous survey study indicates that students rated E2C with the score of 8.7 out of 10 for its usefulness in understanding the concepts of scheduling in heterogeneous computing. Moreover, our pre- and post-evaluations indicate that E2C has improved the students' understanding of heterogeneous computing systems by around 18%.
C1 [Mokhtari, Ali; Rawls, Drake; Huynh, Tony; Green, Jeremiah; Salehi, Mohsen Amini] Univ Louisiana Lafayette, Sch Comp & Informat, High Performance Cloud Comp HPCC Lab, Lafayette, LA 70503 USA.
RP Mokhtari, A (corresponding author), Univ Louisiana Lafayette, Sch Comp & Informat, High Performance Cloud Comp HPCC Lab, Lafayette, LA 70503 USA.
EM ali.mokhtaril@louisiana.edu; drake.rawlsl@louisiana.edu;
   tony.huynhl@louisiana.edu; jeremiah.greenl@louisiana.edu;
   amini@louisiana.edu
CR Ali Shoukat, 2000, J APPL SCI ENG, V3, P195
   amazon, AM SAG
   Bobda C, 2022, ACM T RECONFIG TECHN, V15, DOI 10.1145/3506713
   Calheiros RN, 2011, SOFTWARE PRACT EXPER, V41, P23, DOI 10.1002/spe.995
   Cardwell Suma George, 2020, SMOKY MOUNTAINS COMP, P349
   Denninnart C, 2020, J PARALLEL DISTR COM, V142, P46, DOI 10.1016/j.jpdc.2020.03.018
   Esmaeilzadeh H, 2011, ISCA 2011: PROCEEDINGS OF THE 38TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE, P365, DOI 10.1145/2024723.2000108
   Gentry J, 2019, INT PARALL DISTRIB P, P375, DOI 10.1109/IPDPS.2019.00047
   google, GLASS ENT
   Gupta H, 2017, SOFTWARE PRACT EXPER, V47, P1275, DOI 10.1002/spe.2509
   Jararweh Yaser, 2013, International Journal of Cloud Computing, V2, P237
   Maheswaran M, 1999, J PARALLEL DISTR COM, V59, P107, DOI 10.1006/jpdc.1999.1581
   Mokhtari A, 2020, IEEE SYM PARA DISTR, P17, DOI 10.1109/IPDPSW50202.2020.00013
   Mokhtari Ali, 2022, P 15 IEEE INT C CLOU
   Núñez A, 2012, J GRID COMPUT, V10, P185, DOI 10.1007/s10723-012-9208-5
   Panda SK, 2019, CLUSTER COMPUT, V22, P509, DOI 10.1007/s10586-018-2858-8
   Panda SK, 2015, J SUPERCOMPUT, V71, P1505, DOI 10.1007/s11227-014-1376-6
   qualcomm, QUALC REV WORLDS 1 D
   Sonmez C, 2018, T EMERG TELECOMMUN T, V29, DOI 10.1002/ett.3493
   Taylor MB, 2012, DES AUT CON, P1131
   Taylor MB, 2020, COMMUN ACM, V63, P103, DOI 10.1145/3399734
   Zobaed SM, 2022, P 15 IEEEACM INT C U
NR 22
TC 0
Z9 0
U1 0
U2 0
PY 2023
BP 270
EP 277
DI 10.1109/IPDPSW59300.2023.00052
WC Computer Science, Hardware & Architecture; Computer Science,
   Interdisciplinary Applications; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Heinz, C
   Koch, A
AF Heinz, Carsten
   Koch, Andreas
GP IEEE Comp Soc
TI Near-Data FPGA-Accelerated Processing of Collective and Inference
   Operations in Disaggregated Memory Systems
SO PROCEEDINGS OF SEVENTH INTERNATIONAL WORKSHOP ON HETEROGENEOUS
   HIGH-PERFORMANCE RECONFIGURABLE COMPUTING (H2RC 2021)
DT Proceedings Paper
CT IEEE/ACM 7th International Workshop on Heterogeneous High- Performance
   Reconfigurable Computing (H2RC) Part of International Conference for
   High Performance Computing, Networking, Storage and Analysis (SC)
CY NOV 14-19, 2021
CL St Louis, MO
AB With growing data set sizes, many scientific and data center HPC workloads observe an increasing scaling imbalance, e.g., between compute and memory capacities. As a solution, disaggregated system architectures employ spatial distribution of the different resources. They aim for independent scaling of the different resource kinds (e.g., compute, non-volatile storage, memory), and use fast communication fabrics for their interconnection.
   However, for some bulk operations, such as reductions and collections, it is still beneficial to perform them close to the memories, avoiding the need to move large volumes of data over the fabric.
   This work realizes a disaggregated system capable of performing such near-data processing (NDP) operations by extending the distributed memory controllers with hardware-accelerated compute capabilities. The actual computations execute on FPGAs and can be abstractly described using C/C++ as compilable by high-level hardware synthesis (HLS) tools.
   We have aimed for high usability of our technology also by HPC experts unfamiliar with hardware design. An automated toolflow encapsulates the creation and deployment of the actual accelerators in the disaggregated system. The NDP operations execute distributed across all memory nodes, and are easily accessed using a simple MPI-based programming interface that requires only minimal effort to use in existing applications.
   Our solution is demonstrated using a prototype disaggregated system based on the low-latency EXTOLL fabric for communication. We evaluate both conventional reductions/collectives as well as complete machine-learning inference tasks.
C1 [Heinz, Carsten; Koch, Andreas] Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
RP Heinz, C (corresponding author), Tech Univ Darmstadt, Embedded Syst & Applicat Grp, Darmstadt, Germany.
EM heinz@esa.tu-darmstadt.de; koch@esa.tu-darmstadt.de
CR [Anonymous], 2006, P INT C FIELD PROGRA
   Arap O, 2014, LECT NOTES COMPUT SC, V8632, P632, DOI 10.1007/978-3-319-09873-9_53
   De Matteis T, 2019, PROCEEDINGS OF SC19: THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3295500.3356201
   Dua D, 2020, UCI MACHINE LEARNING
   Fröning H, 2013, IEEE ACM INT SYMP, P498, DOI 10.1109/CCGrid.2013.43
   Gen-Z Consortium, COMPUTER IND ALLIANC
   Graham Richard L., 2010, Proceedings 2010 10th IEEE/ACM International Conference on Cluster, Cloud and Grid Computing (CCGrid), P53, DOI 10.1109/CCGRID.2010.9
   Graham RL, 2016, PROCEEDINGS OF FIRST WORKSHOP ON OPTIMIZATION OF COMMUNICATION IN HPC RUNTIME SYSTEMS (COM-HPC 2016), P1, DOI [10.1109/COM-HPC.2016.6, 10.1109/COMHPC.2016.006]
   Gropp W., 1999, USING MPI 2 ADV FEAT
   Guz Z, 2017, SYSTOR'17: PROCEEDINGS OF THE 10TH ACM INTERNATIONAL SYSTEMS AND STORAGE CONFERENCE, DOI 10.1145/3078468.3078483
   Heinz C., 2020, P 10 INT WORKSH RUNT
   Koch A, 2019, INT S APPL REC COMP
   Kwon Y, 2019, IEEE MICRO, V39, P82, DOI 10.1109/MM.2019.2929165
   Li JJ, 2020, 2020 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA '20), P51, DOI 10.1145/3373087.3375320
   Lim K, 2009, CONF PROC INT SYMP C, P267, DOI 10.1145/1555815.1555789
   Poon H., 2011, 2011 IEEE International Conference on Computer Vision Workshops (ICCV Workshops), P689, DOI 10.1109/ICCVW.2011.6130310
   RIKEN, JAP FUG GAINS TITL W
   Ringlein B., 2020, 6 INT WORKSH HET HIG
   Schmidt J., 2017, THESIS
   Schmidt J, 2016, INT C HIGH PERF COMP
   Sommer L, 2020, ANN IEEE SYM FIELD P, P75, DOI 10.1109/FCCM48280.2020.00020
   Sommer L, 2018, PR IEEE COMP DESIGN, P350, DOI 10.1109/ICCD.2018.00060
   Vinçon T, 2020, PROC VLDB ENDOW, V13, P2981, DOI 10.14778/3415478.3415524
   Xi Sam Likun, 2015, P 11 INT WORKSH DAT
NR 24
TC 1
Z9 1
U1 0
U2 1
PY 2021
BP 44
EP 51
DI 10.1109/H2RC54759.2021.00010
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Gonugondla, SK
   Sakr, C
   Dbouk, H
   Shanbhag, NR
AF Gonugondla, Sujan K.
   Sakr, Charbel
   Dbouk, Hassan
   Shanbhag, Naresh R.
GP IEEE
TI Fundamental Limits on the Precision of In-memory Architectures (Invited
   Talk)
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
DE in-memory computing; taxonomy of in-memory; in-memory noise; machine
   learning; accelerator; in-memory precision; in-memory accuracy; compute
   in-memory
ID MACRO
AB This paper obtains the fundamental limits on the computational precision of in-memory computing architectures (IMCs). Various compute SNR metrics for IMCs are defined and their interrelationships analyzed to show that the accuracy of IMCs is fundamentally limited by the compute SNR (SNRa) of its analog core, and that activation, weight and output precision needs to be assigned appropriately for the final output SNR SNRT -> SNRa. The minimum precision criterion (MPC) is proposed to minimize the output and hence the column analog-to-digital converter (ADC) precision. The charge summing (QS) compute model and its associated IMC QS-Arch are studied to obtain analytical models for its compute SNR, minimum ADC precision, energy and latency. Compute SNR models of QS-Arch are validated via Monte Carlo simulations in a 65 nm CMOS process. Employing these models, upper bounds on SNRa of a QS-Arch-based IMC employing a 512 row SRAM array are obtained and it is shown that QS-Arch's energy cost reduces by 3.3x for every 6 dB drop in SNRa, and that the maximum achievable SNRa reduces with technology scaling while the energy cost at the same SNRa increases. These models also indicate the existence of an upper bound on the dot product dimension N due to voltage headroom clipping, and this bound can be doubled for every 3 dB drop in SNRa.
C1 [Gonugondla, Sujan K.; Sakr, Charbel; Dbouk, Hassan; Shanbhag, Naresh R.] Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
RP Gonugondla, SK (corresponding author), Univ Illinois, Dept Elect & Comp Engn, Champaign, IL 61820 USA.
EM gonugon2@illinois.edu; sakr2@illinois.edu; hdbouk2@illinois.edu;
   shanbhag@illinois.edu
CR [Anonymous], 2018, ARXIV181104047
   [Anonymous], 2005, UNDERSTANDING DELTA
   [Anonymous], 2019, ADC PERFORMANCE SURV
   Biswas A, 2018, ISSCC DIG TECH PAP I, P488, DOI 10.1109/ISSCC.2018.8310397
   Chen WH, 2018, ISSCC DIG TECH PAP I, P494, DOI 10.1109/ISSCC.2018.8310400
   Cheng-Xin Xue, 2020, 2020 IEEE International Solid- State Circuits Conference - (ISSCC), P244, DOI 10.1109/ISSCC19947.2020.9063078
   Dbouk H., 2020, P IEEE CUST INT CIRC, P1
   Dong Q, 2020, ISSCC DIG TECH PAP I, P242, DOI [10.1109/ISSCC19947.2020.9062985, 10.1109/isscc19947.2020.9062985]
   Fick L, 2017, IEEE CUST INTEGR CIR
   Gonugondla SK, 2018, IEEE J SOLID-ST CIRC, V53, P3163, DOI 10.1109/JSSC.2018.2867275
   Gonugondla SK, 2018, ISSCC DIG TECH PAP I, P490, DOI 10.1109/ISSCC.2018.8310398
   Guo RQ, 2019, SYMP VLSI CIRCUITS, pC120, DOI [10.23919/vlsic.2019.8778028, 10.23919/VLSIC.2019.8778028]
   Gupta S, 2015, PR MACH LEARN RES, V37, P1737
   ITRS-collaborations, 2015, ITRS ROADM TABL
   Jiang ZW, 2018, 2018 IEEE SYMPOSIUM ON VLSI TECHNOLOGY, P173, DOI 10.1109/VLSIT.2018.8510687
   Kang M., 2020, DEEP IN MEMORY ARCHI
   Kang MG, 2018, IEEE J SOLID-ST CIRC, V53, P642, DOI 10.1109/JSSC.2017.2782087
   Kang Mingu, 2015, IEEE INT C AC SPEECH
   Khwa WS, 2018, ISSCC DIG TECH PAP I, P496, DOI 10.1109/ISSCC.2018.8310401
   Kim J, 2019, SYMP VLSI CIRCUITS, pC118, DOI [10.23919/VLSIC.2019.8778160, 10.23919/vlsic.2019.8778160]
   LLOYD SP, 1982, IEEE T INFORM THEORY, V28, P129, DOI 10.1109/TIT.1982.1056489
   Mingu Kang, 2014, 2014 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), P8326, DOI 10.1109/ICASSP.2014.6855225
   Murmann Boris, 2015, IEEE Solid-State Circuits Magazine, V7, P58, DOI 10.1109/MSSC.2015.2442393
   Murmann B, 2008, IEEE CUST INTEGR CIR, P105, DOI 10.1109/CICC.2008.4672032
   Okumura S, 2019, S VLSI TECH, pC248
   Rekhi AS, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317770
   Sakr C., 2017, PROC INT C MACH LEAR, P3007
   Sakr C, 2018, 2018 IEEE INTERNATIONAL CONFERENCE ON ACOUSTICS, SPEECH AND SIGNAL PROCESSING (ICASSP), P1090, DOI 10.1109/ICASSP.2018.8461702
   Shanbhag N., 2017, U. S. Patent, Patent No. [9 697 877 B2, 9697877]
   Shanbhag NR, 2019, P IEEE, V107, P90, DOI 10.1109/JPROC.2018.2869867
   Si X, 2020, ISSCC DIG TECH PAP I, P246, DOI [10.1109/ISSCC19947.2020.9062995, 10.1109/isscc19947.2020.9062995]
   Si X, 2019, ISSCC DIG TECH PAP I, V62, P396, DOI 10.1109/ISSCC.2019.8662392
   Su JW, 2020, ISSCC DIG TECH PAP I, P240, DOI 10.1109/isscc19947.2020.9062949
   Valavi H, 2018, SYMP VLSI CIRCUITS, P141, DOI 10.1109/VLSIC.2018.8502421
   Verma Naveen, 2019, IEEE Solid-State Circuits Magazine, V11, P43, DOI 10.1109/MSSC.2019.2922889
   Xue CX, 2019, ISSCC DIG TECH PAP I, V62, P388, DOI 10.1109/ISSCC.2019.8662395
   Yan BN, 2019, S VLSI TECH, pT86, DOI [10.23919/vlsit.2019.8776485, 10.23919/VLSIT.2019.8776485]
   Yue Jinshan, 2020, IEEE INT SOL STAT CI, P234
   Zha Y, 2019, SYMP VLSI CIRCUITS, pC206
   Zhang Jia, 2017, Zhongguo Kangshengsu Zazhi, V42, P915
NR 40
TC 0
Z9 0
U1 0
U2 1
PY 2020
DI 10.1145/3400302.3416344
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering,
   Manufacturing; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Ozen, E
   Orailoglu, A
AF Ozen, Elbruz
   Orailoglu, Alex
GP IEEE
TI Just Say Zero: Containing Critical Bit-Error Propagation in Deep Neural
   Networks With Anomalous Feature Suppression
SO 2020 IEEE/ACM INTERNATIONAL CONFERENCE ON COMPUTER AIDED-DESIGN (ICCAD)
SE ICCAD-IEEE ACM International Conference on Computer-Aided Design
DT Proceedings Paper
CT 39th IEEE/ACM International Conference On Computer Aided Design (ICCAD)
CY NOV 02-05, 2020
CL ELECTR NETWORK
DE fault tolerance; deep neural networks; robust machine learning
AB DNNs are abundantly employed in a variety of applications, including real-time systems with strict safety constraints. The consequences of errors prove disastrous in safety-critical systems, such as autonomous driving, healthcare, and industrial applications. DNNs are resilient to limited numerical perturbations yet fragile under large deviations in weights and activations. The traditional error tolerance measures fail to meet the tight design constraints of DNN processing systems due to extensive overheads or limited advantages in abundant error conditions. The algorithmic particularities of DNNs though create novel opportunities to deal with errors more effectively and economically. We revisit the two fundamental tasks in fault-tolerant system design, namely, error detection and correction, and demonstrate that the precise versions of these operations could be replaced by approximated counterparts in DNNs to deliver an extensive bit-error resilience even at high error rates while necessitating no information redundancy. We first maintain DNN accuracy even under extreme error rates by suppressing the numerical contributions of anomalous activations, eliminating any reliance on precise error correction. We tackle the problem of no redundancy error detection by establishing in training numerical associations among activations, and employing them for anomaly detection. Anomalous feature detection and suppression, performed efficiently at inference with minimal resources in a DNN accelerator, is shown to deliver significant resilience boosts while imposing neither information redundancy nor perceptible overheads.
C1 [Ozen, Elbruz; Orailoglu, Alex] Univ Calif San Diego, La Jolla, CA 92093 USA.
RP Ozen, E (corresponding author), Univ Calif San Diego, La Jolla, CA 92093 USA.
EM elozen@eng.ucsd.edu; alex@cs.ucsd.edu
CR Baleani M., 2003, P INT C COMPILERS AR, P170
   Chen LR, 2017, DES AUT TEST EUROPE, P19, DOI 10.23919/DATE.2017.7926952
   Choi W, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317908
   dos Santos FF, 2019, IEEE T RELIAB, V68, P663, DOI 10.1109/TR.2018.2878387
   Ernst D, 2004, IEEE MICRO, V24, P10, DOI 10.1109/MM.2004.85
   HAMMING RW, 1950, BELL SYST TECH J, V29, P147, DOI 10.1002/j.1538-7305.1950.tb00463.x
   He KM, 2016, PROC CVPR IEEE, P770, DOI 10.1109/CVPR.2016.90
   He Zhezhi, 2019, P 56 ANN DES AUT C D P 56 ANN DES AUT C D
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Hubara I., 2016, ADV NEURAL INFORM PR, P4107, DOI DOI 10.5555/3157382.3157557
   Jouppi Norman P., 2017, ISCA
   Klachko Michael, 2019, IEEE IJCNN
   Koren Israel, 2010, FAULTTOLERANT SYSTEM
   Krizhevsky Alex, 2022, LEARNING MULTIPLE LA
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   Li GP, 2017, SC'17: PROCEEDINGS OF THE INTERNATIONAL CONFERENCE FOR HIGH PERFORMANCE COMPUTING, NETWORKING, STORAGE AND ANALYSIS, DOI 10.1145/3126908.3126964
   Liu Chenchen, 2017, P 54 ANN DES AUT C D P 54 ANN DES AUT C D
   Liu T, 2019, PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE (DAC), DOI 10.1145/3316781.3317742
   Long Y, 2019, DES AUT TEST EUROPE, P1769, DOI [10.23919/DATE.2019.8715178, 10.23919/date.2019.8715178]
   Neggaz MA, 2018, PR IEEE COMP DESIGN, P476, DOI 10.1109/ICCD.2018.00077
   Ozen Elbruz, 2020, 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). Proceedings, P169, DOI 10.1109/ASP-DAC47756.2020.9045662
   Ozen E, 2019, ASIAN TEST SYMPOSIUM, P7, DOI 10.1109/ATS47505.2019.000-8
   Paszke A., 2019, PROC INT C NEURAL IN, P8026
   Reagen B, 2016, CONF PROC INT SYMP C, P267, DOI 10.1109/ISCA.2016.32
   Reagen Brandon, 2018, P 55 ANN DES AUT C D P 55 ANN DES AUT C D
   Redmon J., 2016, ARXIV160207360, P779
   Schorn C, 2018, LECT NOTES COMPUT SC, V11093, P205, DOI 10.1007/978-3-319-99130-6_14
   Schorn C, 2018, DES AUT TEST EUROPE, P979, DOI 10.23919/DATE.2018.8342151
   Sharma H, 2016, INT SYMP MICROARCH
   Srivastava N, 2014, J MACH LEARN RES, V15, P1929
   Stallkamp J, 2012, NEURAL NETWORKS, V32, P323, DOI 10.1016/j.neunet.2012.02.016
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Zhang J, 2018, DES AUT CON, DOI 10.1145/3195970.3196129
   Zhang J, 2018, IEEE VLSI TEST SYMP
NR 34
TC 16
Z9 16
U1 0
U2 2
PY 2020
DI 10.1145/3400302.3415680
WC Computer Science, Hardware & Architecture; Computer Science, Software
   Engineering; Computer Science, Theory & Methods; Engineering,
   Manufacturing; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT J
AU Teng, SH
   Lu, M
   Yang, AF
   Zhang, J
   Nian, YJ
   He, M
AF Teng, Shu-Hua
   Lu, Min
   Yang, A-Feng
   Zhang, Jun
   Nian, Yongjian
   He, Mi
TI Efficient attribute reduction from the viewpoint of discernibility
SO INFORMATION SCIENCES
DT Article
DE Rough set; Discernibility viewpoint; Attribute reduction; Attribute
   significance
ID MATRIX SIMPLIFICATION; FEATURE-SELECTION; ROUGH; APPROXIMATION;
   ACCELERATOR; GRANULATION; MODEL
AB Attribute reduction is an important preprocessing step in pattern recognition, machine learning and data mining. As an effective method for attribute reduction, rough set theory offers a useful and formal methodology. It retains the discernibility power of the original datasets; thus, attribute reduction has been extensively studied in rough set theory. However, the inefficiency of the existing attribute reduction algorithms limits the application of rough sets. In this paper, we first analyse the limitations of existing attribute reduction algorithms. Then, a novel measure of attribute quality, called the relative discernibility degree, is proposed based on the discernibility. Theoretical analysis shows that this measure can find relative dispensable attributes and remain unchanged after removing the relative dispensable attributes and redundant objects in the process of selecting attributes. This property can be used to reduce the search space and accelerate the heuristic process of attribute reduction. Consequently, a new attribute reduction algorithm is proposed from the viewpoint of discernibility. Furthermore, the relationships among the reduction definitions of the algebra view, information view and discernibility view are derived. Some non-equivalent relationships among these views of rough set theory in inconsistent decision tables are discovered. A set of numerical experiments was conducted on UCI datasets. Experimental results show that the proposed algorithm is effective and efficient and is applicable to the case of large-scale datasets. (C) 2015 Elsevier Inc. All rights reserved.
C1 [Teng, Shu-Hua; Lu, Min; Yang, A-Feng; Zhang, Jun] Natl Univ Def Technol, Sci & Technol Automat Target Recognit Lab, Changsha 410073, Hunan, Peoples R China.
   [Nian, Yongjian; He, Mi] Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
RP He, M (corresponding author), Third Mil Med Univ, Sch Biomed Engn, Chongqing 400038, Peoples R China.
EM hmcherry@126.com
CR Chen DG, 2012, IEEE T KNOWL DATA EN, V24, P2080, DOI 10.1109/TKDE.2011.89
   Chen DG, 2012, IEEE T FUZZY SYST, V20, P385, DOI 10.1109/TFUZZ.2011.2173695
   Chouchoulas A, 2001, APPL ARTIF INTELL, V15, P843, DOI 10.1080/088395101753210773
   Deng TQ, 2012, PATTERN RECOGN LETT, V33, P1638, DOI 10.1016/j.patrec.2012.03.028
   Hu QH, 2008, KNOWL-BASED SYST, V21, P294, DOI 10.1016/j.knosys.2007.07.001
   Hu QH, 2007, PATTERN RECOGN, V40, P3509, DOI 10.1016/j.patcog.2007.03.017
   Hu QH, 2010, IEEE T SYST MAN CY B, V40, P137, DOI 10.1109/TSMCB.2009.2024166
   Hu XH, 2004, FUND INFORM, V59, P135
   Jensen R, 2004, IEEE T KNOWL DATA EN, V16, P1457, DOI 10.1109/TKDE.2004.96
   Jensen R, 2004, FUZZY SET SYST, V141, P469, DOI 10.1016/S0165-0114(03)00021-6
   Jiang F, 2015, PATTERN RECOGN, V48, P2151, DOI 10.1016/j.patcog.2015.01.023
   Komorowski J, 1999, ROUGH FUZZY HYBRIDIZ, P3
   Lang GM, 2013, KNOWL INF SYST, V37, P611, DOI 10.1007/s10115-012-0589-3
   Li M, 2014, INFORM SCIENCES, V254, P155, DOI 10.1016/j.ins.2013.08.038
   Liang JY, 2013, KNOWL-BASED SYST, V44, P90, DOI 10.1016/j.knosys.2013.01.027
   Mac Parthaláin N, 2009, PATTERN RECOGN, V42, P655, DOI 10.1016/j.patcog.2008.08.029
   Meng ZQ, 2012, INFORM SCIENCES, V204, P44, DOI 10.1016/j.ins.2012.04.004
   Miao DQ, 2009, INFORM SCIENCES, V179, P4140, DOI 10.1016/j.ins.2009.08.020
   Pawlak Z., 1991, SPRINGER SCI BUSINES, VVolume 9, DOI DOI 10.1007/978-94-011-3534-4
   Pawlak Z, 2007, INFORM SCIENCES, V177, P3, DOI 10.1016/j.ins.2006.06.003
   Pedrycz W., 2013, GRANULAR COMPUTING A
   Prasad PSVSS, 2009, LECT NOTES ARTIF INT, V5908, P152, DOI 10.1007/978-3-642-10646-0_18
   Qian J, 2011, INT J APPROX REASON, V52, P212, DOI 10.1016/j.ijar.2010.07.011
   Qian J, 2015, KNOWL-BASED SYST, V73, P18, DOI 10.1016/j.knosys.2014.09.001
   Qian YH, 2008, INT J UNCERTAIN FUZZ, V16, P179, DOI 10.1142/S0218488508005121
   Qian YH, 2011, PATTERN RECOGN, V44, P1658, DOI 10.1016/j.patcog.2011.02.020
   Qian YH, 2010, ARTIF INTELL, V174, P597, DOI 10.1016/j.artint.2010.04.018
   Skowron A., 1992, INTELLIGENT DECISION, P331, DOI DOI 10.1007/978-94-015-7975-9_21
   Susmaga R, 2004, FUND INFORM, V61, P159
   Swiniarski RW, 2003, PATTERN RECOGN LETT, V24, P833, DOI 10.1016/S0167-8655(02)00196-4
   Teng SH, 2010, 2ND IEEE INTERNATIONAL CONFERENCE ON ADVANCED COMPUTER CONTROL (ICACC 2010), VOL. 4, P471, DOI 10.1109/ICACC.2010.5486877
   Teng SH, 2009, 2009 IEEE INTERNATIONAL CONFERENCE ON ROBOTICS AND BIOMIMETICS (ROBIO 2009), VOLS 1-4, P1189, DOI 10.1109/ROBIO.2009.5420845
   Tsang ECC, 2008, IEEE T FUZZY SYST, V16, P1130, DOI 10.1109/TFUZZ.2006.889960
   Wang Guo-Yin, 2002, Chinese Journal of Computers, V25, P759
   Wang GY, 2012, FUND INFORM, V115, P219, DOI 10.3233/FI-2012-651
   Wang GY, 2005, FUND INFORM, V68, P289
   Wang GY, 2003, PROC SPIE, V5098, P103, DOI 10.1117/12.486854
   Xu Zhang-Yan, 2006, Chinese Journal of Computers, V29, P391
   Yamaguchi D, 2009, INT J APPROX REASON, V51, P89, DOI 10.1016/j.ijar.2009.08.002
   Yang T, 2013, INFORM SCIENCES, V228, P175, DOI 10.1016/j.ins.2012.11.005
   Yao YY, 2009, INFORM SCIENCES, V179, P867, DOI 10.1016/j.ins.2008.11.020
   Zhang WX, 2007, SCI CHINA SER F, V50, P188, DOI 10.1007/s11432-007-0017-6
   Zhao Y, 2007, INFORM SCIENCES, V177, P4959, DOI 10.1016/j.ins.2007.06.031
NR 43
TC 29
Z9 42
U1 1
U2 41
PD JAN 1
PY 2016
VL 326
BP 297
EP 314
DI 10.1016/j.ins.2015.07.052
WC Computer Science, Information Systems
DA 2023-11-11
ER

PT C
AU Bal, S
   Mummidi, CS
   Ferreira, VD
   Srinivasan, S
   Kundu, S
AF Bal, Sandeep
   Mummidi, Chandra Sekhar
   Ferreira, Victor da Cruz
   Srinivasan, Sudarshan
   Kundu, Sandip
BE IEEE
TI A Novel Fault-Tolerant Architecture for Tiled Matrix Multiplication
SO 2023 DESIGN, AUTOMATION & TEST IN EUROPE CONFERENCE & EXHIBITION, DATE
SE Design Automation and Test in Europe Conference and Exhibition
DT Proceedings Paper
CT Design, Automation and Test in Europe Conference and Exhibition (DATE)
CY APR 17-19, 2023
CL Antwerp, BELGIUM
DE accelerator; matrix multiplication; abft; concurrent error detection;
   low power
AB General matrix multiplication (GEMM) is common to many scientific and machine-learning applications. Convolution, the dominant computation in Convolutional Neural Networks (CNNs), can be formulated as a GEMM problem. Due to its widespread use, a new generation of processors features GEMM acceleration in hardware. Intel recently announced an Advanced Matrix Multiplication (AMX (R)) instruction set for GEMM, which is supported by 1kB AMX registers and a Tile Multiplication unit (TMUL) for multiplying tiles (sub-matrices) in hardware. Silent Data Corruption (SDC) is a well-known problem that occurs when hardware generates corrupt output. Google and Meta recently reported findings of SDC in GEMM in their data centers. Algorithm-Based Fault Tolerance (ABFT) is an efficient mechanism for detecting and correcting errors in GEMM, but classic ABFT solutions are not optimized for hardware acceleration. In this paper, we present a novel ABFT implementation directly on hardware. Though the exact implementation of Intel TMUL is not known, we propose two different TMUL architectures representing two design points in the area-power-performance spectrum and illustrate how ABFT can be directly incorporated into the TMUL hardware. This approach has two advantages: (i) an error can be concurrently detected at the tile level, which is an improvement over finding such errors only after performing the full matrix multiplication; and (ii) we further demonstrate that performing ABFT at the hardware level has no performance impact and only a small area, latency, and power overhead.
C1 [Bal, Sandeep; Mummidi, Chandra Sekhar; Kundu, Sandip] Univ Massachusetts, Amherst, MA 01003 USA.
   [Ferreira, Victor da Cruz; Srinivasan, Sudarshan] Intel Corp, Bengaluru, India.
RP Bal, S (corresponding author), Univ Massachusetts, Amherst, MA 01003 USA.
CR Asgari B, 2020, ANN IEEE SYM FIELD P, P204, DOI 10.1109/FCCM48280.2020.00035
   Bosilca G, 2009, J PARALLEL DISTR COM, V69, P410, DOI 10.1016/j.jpdc.2008.12.002
   Dattatraya H., 2021, SILENT DATA CORRUPTI
   Frangiotti M, 1995, PROCEEDINGS OF THE EIGHTH INTERNATIONAL KANT CONGRESS, VOL II, PT 1, SECT 1-9, P207, DOI 10.1109/DFTVS.1995.476954
   Georganas E, 2019, Arxiv, DOI arXiv:1906.06440
   Hari SKS, 2022, IEEE T DEPEND SECURE, V19, P2546, DOI 10.1109/TDSC.2021.3063083
   Hochschild Peter H., 2021, P WORKSH HOT TOP OP, P9, DOI 10.1145/3458336.3465297
   HUANG KH, 1984, IEEE T COMPUT, V33, P518, DOI 10.1109/TC.1984.1676475
   Intel, 2021, INT R ARCH INSTR SET
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Koomey JG, 2008, ENVIRON RES LETT, V3, DOI 10.1088/1748-9326/3/3/034008
   Li GF, 2019, CLUSTER COMPUT, V22, pS2719, DOI 10.1007/s10586-017-1435-x
   Naumov Maxim, 2020, DEEP LEARNING TRAINI
   Note F. W., 2016, BLISLAB SANDBOX OPTI
   Raschka S, 2020, INFORMATION, V11, DOI 10.3390/info11040193
   Roy-Chowdhury A., 1994, Digest of Papers. The Twenty-Fourth International Symposium on Fault-Tolerant Computing (Cat. No.94CH3441-3), P38, DOI 10.1109/FTCS.1994.315659
NR 16
TC 0
Z9 0
U1 0
U2 0
PY 2023
WC Automation & Control Systems; Computer Science, Hardware & Architecture;
   Engineering, Industrial
DA 2023-11-11
ER

PT J
AU Chatterjee, S
   Jagadeesan, M
   Qin, W
   Idreos, S
AF Chatterjee, Subarna
   Jagadeesan, Meena
   Qin, Wilson
   Idreos, Stratos
TI Cosine: A Cloud-Cost Optimized Self-Designing Key-Value Storage Engine
SO PROCEEDINGS OF THE VLDB ENDOWMENT
DT Article; Proceedings Paper
CT 48th International Conference on Very Large Data Bases (VLDB)
CY 2022
CL Sydney, AUSTRALIA
AB We present a self-designing key-value storage engine, Cosine, which can always take the shape of the close to "perfect" engine architecture given an input workload, a cloud budget, a target performance, and required cloud SLAs. By identifying and formalizing the first principles of storage engine layouts and core key-value algorithms, Cosine constructs a massive design space comprising of sextillion (1036) possible storage engine designs over a diverse space of hardware and cloud pricing policies for three cloud providers AWS, GCP, and Azure. Cosine spans across diverse designs such as Log-Structured Merge-trees, B-trees, Log-Structured Hash-tables, in-memory accelerators for filters and indexes as well as trillions of hybrid designs that do not appear in the literature or industry but emerge as valid combinations of the above. Cosine includes a unified distribution-aware I/O model and a learned concurrency-aware CPU model that with high accuracy can calculate the performance and cloud cost of any possible design on any workload and virtual machines. Cosine can then search through that space in a matter of seconds to find the best design and materializes the actual code of the resulting storage engine design using a templated Rust implementation. We demonstrate that on average Cosine outperforms state-of-the-art storage engines such as write-optimized RocksDB, read-optimized WiredTiger, and very write-optimized FASTER by 53x, 25x, and 20x, respectively, for diverse workloads, data sizes, and cloud budgets across all YCSB core workloads and many variants.
C1 [Chatterjee, Subarna; Jagadeesan, Meena; Qin, Wilson; Idreos, Stratos] Harvard Univ, Cambridge, MA 02138 USA.
RP Chatterjee, S (corresponding author), Harvard Univ, Cambridge, MA 02138 USA.
EM subarna@seas.harvard.edu; mjagadeesan@seas.harvard.edu;
   wilson@seas.harvard.edu; stratos@seas.harvard.edu
CR Amazon, 2020, CLOUD STOR
   AMDAHL GM, 1967, P APR 18 20 1967 SPR, P483, DOI DOI 10.1145/1465482.1465560
   [Anonymous], 2021, MUCH ARE STARTUPS SP
   [Anonymous], 2010, NSDI
   Apache, 2020, CASSANDRA
   Apache, 2020, HBASE
   Armstrong T. G., 2013, ACM SIGMOD, P1185, DOI DOI 10.1145/2463676.2465296
   AWS, 2019, CLOUDENDURE DIS REC
   AWS, 2019, PRIOR VERS AM EC2 SE
   AWS, 2019, WHAT IS DEVOPS
   AWS, 2019, AWS DAT MIGR SERV PR
   Azure, 2019, PRIC AZ DEVOPS
   Azure, 2019, AZ DAT MIGR SERV PRI
   Azure, 2019, AZ SIT REC PRIC
   Azure, 2019, SLA VIRT MACH
   Ball Nicholas, 2013, SKYL DYN WORKL AW DA
   Ballani H., 2011, PRICE IS RIGHT LOCAT
   Brazeal F, 2017, WHY AMAZON DYNAMODB
   Bruck J, 2006, 2006 IEEE INTERNATIONAL SYMPOSIUM ON INFORMATION THEORY, VOLS 1-6, PROCEEDINGS, P2304, DOI 10.1109/ISIT.2006.261978
   Bruno Nicolas, 2018, ENCY DATABASE SYSTEM
   Cao Zhao, 2013, P BIENN C INN DAT SY
   Chandramouli B, 2018, INT CONF MANAGE DATA, P275, DOI 10.1145/3183713.3196898
   Chaudhuri S., 1998, Proceedings of the Seventeenth ACM SIGACT-SIGMOD-SIGART Symposium on Principles of Database Systems. PODS 1998, P34, DOI 10.1145/275487.275492
   Cooney M, 2016, 10 BEST CLOUD SLA PR
   Cooper B. F., 2010, SOCC 10, P143, DOI DOI 10.1145/1807128.1807152
   Dai YF, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P155
   Das S, 2019, INT CONF MANAGE DATA, P666, DOI 10.1145/3299869.3314035
   Dayan N, 2018, ACM T DATABASE SYST, V43, DOI 10.1145/3276980
   Dayan N, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P79, DOI 10.1145/3035918.3064054
   DeCandia Giuseppe, 2007, Operating Systems Review, V41, P205, DOI 10.1145/1323293.1294281
   Ditto, 2022, ACCUBITS
   DSM, 2018, AWS AZ OFF CLOUD CON
   Nguyen DT, 2021, IEEE T CLOUD COMPUT, V9, P302, DOI 10.1109/TCC.2018.2844379
   Facebook, 2020, ROCKSDB
   Finkle V., 2015, HERES WHAT WE FOUND
   Fisk N, 2019, OP CLEAR MULT CONF
   GCP, 2019, GOOGL CLOUD FUNCT SE
   GCP, 2019, DEVOPS
   GCP, 2019, DIS REC PLANN GUID
   GCP, 2019, PRIC MIGR WORKL
   Graefe G, 2010, ACM T DATABASE SYST, V35, DOI 10.1145/1806907.1806908
   Griffiths Selinger P., 1979, P 1979 ACM SIGMOD IN, P23, DOI DOI 10.1145/582095.582099
   Gruneir Bram, 2017, SCALABLE SQL MADE EA
   Hein D, 2019, 5 THINGS LOOK CLOUD
   Hennessy JL., 2003, COMPUTER ARCHITECTUR
   Hill MD, 2008, COMPUTER, V41, P33, DOI 10.1109/MC.2008.209
   Hoy Darrell, 2016, P 12 INT C WEB INT E, P73
   Huang HY, 2021, INT CONF MANAGE DATA, P749, DOI 10.1145/3448016.3457297
   Huang KC, 2021, PROC INT CONF DATA, P612, DOI 10.1109/ICDE51399.2021.00059
   Idreos S., 2007, P BIENN C INN DAT SY
   Idreos S., 2019, CIDR
   Idreos S, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2667, DOI 10.1145/3318464.3383133
   Idreos S, 2019, INT CONF MANAGE DATA, P2054, DOI 10.1145/3299869.3314034
   Idreos S, 2018, INT CONF MANAGE DATA, P535, DOI 10.1145/3183713.3199671
   Idreos Stratos, 2021, VLDB
   Jain M. R, 2019, WHY WE CHOOSE BADGER
   Jain V, 2019, INT CONF MANAGE DATA, P1829, DOI 10.1145/3299869.3300097
   Karger D., 1997, P 29 ANN ACM S THEOR, V10, P654, DOI DOI 10.1145/258533.258660
   Kester MS, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P715, DOI 10.1145/3035918.3064049
   Kicinski A., 2019, ICEAA PROF DEV TRAIN
   Kraska T., 2019, CIDR
   Kraska T, 2018, INT CONF MANAGE DATA, P489, DOI 10.1145/3183713.3196909
   Lahn M, 2019, MUCH DOES SERVER COS
   Liang JK, 2021, PROC INT CONF DATA, P1032, DOI 10.1109/ICDE51399.2021.00094
   Liao Y., 2020, PROC MACH LEARN SYST
   Lu LY, 2016, 14TH USENIX CONFERENCE ON FILE AND STORAGE TECHNOLOGIES (FAST '16), P133
   Luo C, 2020, VLDB J, V29, P393, DOI 10.1007/s00778-019-00555-y
   Luo SQ, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P2071, DOI 10.1145/3318464.3389731
   Lustiber Graham, 2017, P ACM SIGMOD INT C M, P13
   Malkowski P, 2018, MYROCKS DISK FULL ED
   Metafilter, 2010, CLOUD MIGHT RUN ME D
   Mogul JC, 2012, ACM SIGCOMM COMP COM, V42, P44, DOI 10.1145/2378956.2378964
   NordicBackup, 2018, 10 MIST COMP MAK CHO
   Oledzki W, 2013, MEMC IS WEIRD CREAT
   Padilha R., 2016, P USENIX ANN TECHN C
   Parlette C, 2018, 7 WAYS CLOUD SERVICE
   Pavlo Andrew, 2017, CIDR, V4
   Preez D. D, 2014, VIBER MIGRATES MONGO
   Ralph J, 2019, WHICH CLOUD IS BEST
   RapidValue, 2018, CHOOS AZ AWS GCP CLO
   Sarkar S, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P893, DOI 10.1145/3318464.3389757
   Sarkar Subhadeep, 2021, PROC VLDB ENDOW
   Sun W, 2015, SIGMOD'15: PROCEEDINGS OF THE 2015 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1887, DOI 10.1145/2723372.2723732
   Tan J, 2019, PROC VLDB ENDOW, V12, P1221, DOI 10.14778/3339490.3339503
   Tan Junjay, 2019, PVLDB, V12
   Taylor Twain, 2019, ORACLE CLOUD DIGS LO
   Tkatchuk R, 2017, CLOUD IS SO GREAT WH
   Van Aken D, 2017, SIGMOD'17: PROCEEDINGS OF THE 2017 ACM INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1009, DOI 10.1145/3035918.3064029
   Vinçon T, 2020, PROC VLDB ENDOW, V13, P2981, DOI 10.14778/3415478.3415524
   Wang S, 2018, PROC VLDB ENDOW, V11, P1137, DOI 10.14778/3231751.3231762
   Wasay Abdul, 2021, MORE LESS BUILD CONV
   Wei XD, 2020, PROCEEDINGS OF THE 14TH USENIX SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDI '20), P117
   Wei Z, 2012, IEEE T SERV COMPUT, V5, P525, DOI 10.1109/TSC.2011.18
   WIRED INSIDER, 2011, SERVICE LEVEL AGREEM
   WiredTiger, 2020, SOURCE CODE
   Wu CG, 2019, PROC VLDB ENDOW, V12, P624, DOI 10.14778/3311880.3311881
   Wu FG, 2020, PROCEEDINGS OF THE 2020 USENIX ANNUAL TECHNICAL CONFERENCE, P603
   Yang Fan, 2021 IEEE 37 INT C D, P1020
   Zhang HC, 2020, SIGMOD'20: PROCEEDINGS OF THE 2020 ACM SIGMOD INTERNATIONAL CONFERENCE ON MANAGEMENT OF DATA, P1601, DOI 10.1145/3318464.3380583
NR 99
TC 5
Z9 5
U1 0
U2 4
PD SEP
PY 2021
VL 15
IS 1
BP 112
EP 126
DI 10.14778/3485450.3485461
WC Computer Science, Information Systems; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Chen, Y
   He, J
   Zhang, XF
   Hao, C
   Chen, DM
AF Chen, Yao
   He, Jiong
   Zhang, Xiaofan
   Hao, Cong
   Chen, Deming
GP ACM
TI Cloud-DNN: An Open Framework for Mapping DNN Models to Cloud FPGAs
SO PROCEEDINGS OF THE 2019 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'19)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 24-26, 2019
CL Seaside, CA
DE DNN Accelerator; FPGA; High-Level Synthesis; Cloud Computing
AB The efficacy and effectiveness of Convolutional Neural Networks (CNNs) have been proven in a wide range of machine learning applications. However, the high computational complexity of CNNs presents a critical challenge towards their broader adoption in real-time and power-efficient scenarios. FPGAs are poised to take a significant role for high-performance and energy-efficient computation of CNNs for both mobile (e.g., UAVs, self-driving cars, and IoT devices) and cloud computing domains. However, implementing an effective CNN system onto FPGAs efficiently remains problematic. The current cloud-based FPGAs with unique design constraints and architectural characteristics further increase the challenges. To address these challenges, we propose a novel open-source automated tool chain called Cloud-DNN. Our tool chain takes trained CNN models specified in Caffe as input, performs a set of transformations, and maps the model to a cloud-based FPGA. Cloud-DNN can significantly improve the overall design productivity of CNNs on FPGAs while satisfying the emergent computational requirements. Our design provides an alternative solution compared to other cloud-based options (e.g., GPUs or TPUs) while offering flexible, and high performance DNN inferences. The unique features of Cloud-DNN include the optimizations with cloud-platform characteristics and the support of easier and streamlined implementation. Experimental results demonstrate up to 104.55x performance improvement when compared to CPU implementation and comparable usability, flexibility, and strong quality compared to other state-of-the-art DNN inference implementations on standalone FPGAs.
C1 [Chen, Yao; He, Jiong; Chen, Deming] Adv Digital Sci Ctr, Singapore, Singapore.
   [Zhang, Xiaofan; Hao, Cong; Chen, Deming] Univ Illinois, Champaign, IL USA.
RP Chen, Y (corresponding author), Adv Digital Sci Ctr, Singapore, Singapore.
EM yao.chen@adsc-create.edu.sg; Jiong.he@adsc-create.edu.sg;
   xiaofan3@illinois.edu; congh@illinois.edu; dchen@illinois.edu
CR [Anonymous], 2016, P ICCAD
   [Anonymous], 2016, ESE EFFICIENT SPEECH
   Canis Andrew, 2011, P FPGA
   Chen DM, 2010, IEEE T VLSI SYST, V18, P564, DOI 10.1109/TVLSI.2009.2013353
   Del Sozzo Emanuele, 2016, P IPDPSW
   DiCecco Roberto, 2016, P FPT
   Guan Yijin, 2017, P FCCM
   Gysel Philipp Mohammad, 2016, HARDWARE ORIENTED AP
   Han S., 2015, ARXIV151000149
   Jia Yangqing, 2014, P ACMMM
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Li Huimin, 2016, P FPL
   Liu Su, 2011, P SAAHPC
   Liu Xinheng, 2016, P FPGA
   Ma Yufei, 2017, PROF FPL
   Ma Yufei, 2017, P FPGA
   Qin Li, 2019, P ASP DAC
   Qiu J., 2016, P FPGA
   Rupnow Kyle, 2011, P FPT
   Sharma H, 2016, INT SYMP MICROARCH
   Shen Yongming, 2017, P ISCA
   Suda N., 2016, P FPGA
   Wang Junsong, 2018, P FPL
   Xilinx, 2012, LARG FPGA METH GUID
   Zhang C., 2015, P 2015 ACM SIGDA INT, P161, DOI 10.1145/2684746.2689060
   Zhang Jialiang, 2017, P FPGA
   Zhang Xiaofan, 2017, P ICCAD
   Zhang Xiaofan, 2017, P FPL
   Zhang Xiaofan, 2018, P ICCAD
NR 29
TC 67
Z9 67
U1 1
U2 8
PY 2019
BP 73
EP 82
DI 10.1145/3289602.3293915
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Nonlaopon, K
   Khan, MF
   Sulaiman, M
   Alshammari, FS
   Laouini, G
AF Nonlaopon, Kamsing
   Khan, Muhammad Fawad
   Sulaiman, Muhammad
   Alshammari, Fahad Sameer
   Laouini, Ghaylen
TI Analysis of MHD Falkner-Skan Boundary Layer Flow and Heat Transfer Due
   to Symmetric Dynamic Wedge: A Numerical Study via the SCA-SQP-ANN
   Technique
SO SYMMETRY-BASEL
DT Article
DE heat transfer; magnetic field; dynamic wedge; sine-cosine algorithm;
   nonlinear systems; dynamic parameters; sequential quadratic programming;
   machine learning; heuristics
ID SINE-COSINE ALGORITHM; POROUS-MEDIUM; ENTROPY GENERATION; STRETCHING
   SHEET; NANOFLUID FLOW; RADIATION; PLATE; FLUID
AB This article considers Falkner-Skan flow over a dynamic and symmetric wedge under the influence of a magnetic field. The Hall effect on a magnetic field is negligible for small magnetic Reynolds numbers. The magnetic field B(x) is considered over x-axis, which is in line with the wedge i.e., parallel, while the flow is transverse over the y-axis. This study has numerous device-centric applications in engineering, such as power generators, cooling reactor and heat exchanger design, and MHD accelerators. The Third and second-ordered ordinary differential equations characterize the system. A novel hybrid computational technique is designed for the surrogate solutions of the Falkner-Skan flow system. The designed technique is based on the sine-cosine optimization algorithm and sequential quadratic programming. Reference solutions are calculated by using the Runge-Kutta numerical technique. Performance matrices evaluate the accuracy and stability of our surrogate solutions, mean-absolute deviation (MAD), root-mean-square error (RMSE), and error in Nash--Sutcliffe efficiency (ENSE). Furthermore, graphical representations in terms of convergence graphs, mesh graphs, stem graphs, stairs plots, and boxplots are presented to establish the symmetry, reliability, and validity of our solutions.
C1 [Nonlaopon, Kamsing] Khon Kaen Univ, Fac Sci, Dept Math, Khon Kaen 40002, Thailand.
   [Khan, Muhammad Fawad; Sulaiman, Muhammad] Abdul Wali Khan Univ, Dept Math, Mardan 23200, Pakistan.
   [Alshammari, Fahad Sameer] Prince Sattam Bin Abdulaziz Univ, Coll Sci & Humanities Alkharj, Dept Math, Al Kharj 11942, Saudi Arabia.
   [Laouini, Ghaylen] Amer Univ Middle East, Coll Engn & Technol, Egaila 54200, Kuwait.
RP Sulaiman, M (corresponding author), Abdul Wali Khan Univ, Dept Math, Mardan 23200, Pakistan.
EM msulaiman@awkum.edu.pk
CR Abbas Z, 2006, THEOR COMP FLUID DYN, V20, P229, DOI 10.1007/s00162-006-0025-y
   Abbasbandy S, 2009, COMMUN NONLINEAR SCI, V14, P3591, DOI 10.1016/j.cnsns.2009.01.030
   Ali B., 2021, INT J ALGORITHM COMP, V7, P1
   Ali B, 2020, CHINESE J PHYS, V68, P368, DOI 10.1016/j.cjph.2020.09.026
   Ali L, 2022, CHINESE J PHYS, V77, P1963, DOI 10.1016/j.cjph.2021.12.008
   Anusha T, 2022, TRANSPORT POROUS MED, V142, P333, DOI 10.1007/s11242-021-01695-y
   Anusha T, 2022, APPL SCI-BASEL, V12, DOI 10.3390/app12157527
   Attia AF, 2018, INT J ELEC POWER, V99, P331, DOI 10.1016/j.ijepes.2018.01.024
   Bararnia H, 2012, CURR SCI INDIA, V103, P169
   Bararnia H, 2012, ADV ENG SOFTW, V43, P44, DOI 10.1016/j.advengsoft.2011.08.005
   Bejan A., 1982, ADV HEAT T, V15, P1, DOI [10.1016/S0065-2717(08)70172-2, DOI 10.1016/S0065-2717(08)70172-2]
   Berrehal H, 2019, J MECH SCI TECHNOL, V33, P2949, DOI 10.1007/s12206-019-0542-4
   Butt AS, 2013, INT J EXERGY, V13, P85, DOI 10.1504/IJEX.2013.055779
   Cui W, 2022, ENERGY REP, V8, P10203, DOI 10.1016/j.egyr.2022.07.178
   Cui W, 2022, J CLEAN PROD, V367, DOI 10.1016/j.jclepro.2022.133031
   Das C, 2013, SENSOR ACTUAT A-PHYS, V201, P43, DOI 10.1016/j.sna.2013.06.023
   Dasgupta K, 2020, ELECTR POW SYST RES, V178, DOI 10.1016/j.epsr.2019.106018
   Dehsara M, 2014, J MECH SCI TECHNOL, V28, P1819, DOI 10.1007/s12206-014-0329-6
   Elsaid E.M., 2022, RES SQ, DOI [10.21203/rs.3.rs-34729/v1, 10.21203/rs.3.rs-1591028/v1, DOI 10.21203/RS.3.RS-1591028/V1]
   Falkner VM, 1931, PHILOS MAG, V12, P865
   Khan MF, 2022, COMPLEXITY, V2022, DOI 10.1155/2022/9660746
   Garia R, 2021, CHINESE J PHYS, V74, P421, DOI 10.1016/j.cjph.2021.10.030
   Goud BS, 2022, PROC I MECH ENG PART, DOI 10.1177/23977914221100961
   Guo ZG, 2022, ENERG CONVERS MANAGE, V257, DOI 10.1016/j.enconman.2022.115435
   Guo ZG, 2021, INT J HEAT MASS TRAN, V174, DOI 10.1016/j.ijheatmasstransfer.2021.121296
   Habib D, 2022, WAVE RANDOM COMPLEX, DOI 10.1080/17455030.2022.2088892
   Habib D, 2022, INT COMMUN HEAT MASS, V135, DOI 10.1016/j.icheatmasstransfer.2022.106141
   Hekimoglu B, 2019, T I MEAS CONTROL, V41, P1761, DOI 10.1177/0142331218811453
   Howarth L, 1938, PROC R SOC LON SER-A, V164, P0547, DOI 10.1098/rspa.1938.0037
   Huang KX, 2022, APPL THERM ENG, V204, DOI 10.1016/j.applthermaleng.2021.117942
   Huang W, 2021, COMPLEXITY, V2021, DOI 10.1155/2021/6639032
   Ishak A, 2009, MAGNETOHYDRODYNAMICS, V45, P103
   Johansen TA, 2004, IEEE T CONTR SYST T, V12, P211, DOI 10.1109/TCST.2003.821952
   Khan MF, 2022, IEEE ACCESS, V10, P34133, DOI 10.1109/ACCESS.2022.3159973
   Khan MF, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111513
   Khan MF, 2021, ENTROPY-SWITZ, V23, DOI 10.3390/e23111448
   Khan NA, 2021, PHYS FLUIDS, V33, DOI 10.1063/5.0042676
   Khazayinejad M, 2022, INT J THERM SCI, V172, DOI 10.1016/j.ijthermalsci.2021.107265
   Kudenatti RB, 2013, COMMUN NONLINEAR SCI, V18, P1151, DOI 10.1016/j.cnsns.2012.09.029
   Makinde OD, 2012, INT J EXERGY, V10, P142, DOI 10.1504/IJEX.2012.045862
   Marinca V, 2008, INT COMMUN HEAT MASS, V35, P710, DOI 10.1016/j.icheatmasstransfer.2008.02.010
   Mehmood A, 2020, NEURAL COMPUT APPL, V32, P10337, DOI 10.1007/s00521-019-04573-3
   Mirjalili S.M., 2020, NATURE INSPIRED OPTI, P201, DOI DOI 10.1007/978-3-030-12127-3_12
   Mirjalili S, 2016, KNOWL-BASED SYST, V96, P120, DOI 10.1016/j.knosys.2015.12.022
   Mukhopadhyay S, 2005, INT J HEAT MASS TRAN, V48, P4460, DOI 10.1016/j.ijheatmasstransfer.2005.05.027
   Qi H, 2016, OPT EXPRESS, V24, P24297, DOI 10.1364/OE.24.024297
   Rai P., 2022, J ADV RES FLUID MECH, V95, P120
   RamReddy C, 2022, P I MECH ENG E-J PRO, V236, P2558, DOI 10.1177/09544089221102404
   Sayyed SR, 2018, APPL MATH COMPUT, V321, P472, DOI 10.1016/j.amc.2017.10.062
   Siddique I, 2022, ARAB J SCI ENG, DOI 10.1007/s13369-022-07129-1
   Sindhu R, 2017, NEURAL COMPUT APPL, V28, P2947, DOI 10.1007/s00521-017-2837-7
   Suid MH., 2019, INDONES J ELECT ENG, V16, P101, DOI 10.11591/ijeecs.v16.i1.pp101-106
   Wolpert D. H., 1997, IEEE Transactions on Evolutionary Computation, V1, P67, DOI 10.1109/4235.585893
   Xia C, 2023, INT J ENGINE RES, V24, P1327, DOI 10.1177/14680874221084052
   Yacob NA, 2011, INT COMMUN HEAT MASS, V38, P149, DOI 10.1016/j.icheatmasstransfer.2010.12.003
   Yaseen M, 2022, J HEAT TRANS-T ASME, V144, DOI 10.1115/1.4055046
   Yazdi MH, 2012, ENTROPY-SWITZ, V14, P1, DOI 10.3390/e14010001
   Zhao MQ, 2020, ENERGIES, V13, DOI 10.3390/en13010215
NR 58
TC 3
Z9 3
U1 3
U2 6
PD OCT
PY 2022
VL 14
IS 10
AR 2180
DI 10.3390/sym14102180
WC Multidisciplinary Sciences
DA 2023-11-11
ER

PT J
AU Mohammadirad, M
   Sojodishijani, O
AF Mohammadirad, Majid
   Sojodishijani, Omid
TI Improving the efficiency of DNN hardware accelerator by replacing
   digital feature extractor with an imprecise neuromorphic hardware
SO TURKISH JOURNAL OF ELECTRICAL ENGINEERING AND COMPUTER SCIENCES
DT Article
DE Artificial neural networks; memristor; in-memory computation;
   convolutional neural networks; imprecise computation; fault tolerance
AB Mixed-signal in-memory computation can drastically improve the efficiency of the hardware implementing machine learning (ML) algorithms by (i) removing the need to fetch neural network parameters from internal or external memory and (ii) performing a large number of multiply-accumulate operations in parallel. However, this boost in efficiency comes with some disadvantages. Among them, the inability to precisely program nonvolatile memory devices (NVM) with neural network parameters and sensitivity to noise prevent the mixed-signal hardware to perform a precise and deterministic computation. Unfortunately, these hardware-specific errors can get magnified while propagating along with the layers of the deep neural network. In this paper, we show that the inability to implement parameters of the already trained network with enough precision can completely stop the network from performing any meaningful operation. However, even at this level of degradation, the feature extractor section of the network still extracts enough information from which an acceptable level of performance can be achieved by just retraining the last classification layers of the network. Our results suggest that instead of just blindly trying to implement software algorithms in hardware as precisely as possible, it might be more efficient to implement neural networks with imperfect devices and circuits and let the network itself compensate for these imprecise computations by only retraining few layers.
C1 [Mohammadirad, Majid; Sojodishijani, Omid] Islamic Azad Univ, Dept Comp Engn, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
RP Sojodishijani, O (corresponding author), Islamic Azad Univ, Dept Comp Engn, Qazvin Branch, Fac Comp & Informat Technol Engn, Qazvin, Iran.
EM o_sojoodi@qiau.ac.ir
CR Bayat FM, 2018, NAT COMMUN, V9, DOI 10.1038/s41467-018-04482-4
   Bayat FM, 2017, ICCAD-IEEE ACM INT, P549, DOI 10.1109/ICCAD.2017.8203825
   Bojarski Mariusz, 2016, arXiv
   Fouda M.E., 2015, MATH MODELING MEMRIS
   Gibney E, 2016, NATURE, V529, P445, DOI 10.1038/529445a
   Han S., 2015, ARXIV151000149
   Hannun A., 2014, DEEP SPEECH SCALING
   Howard A. G., 2017, ARXIV
   Hubara I, 2018, J MACH LEARN RES, V18
   Indiveri G, 2011, FRONT NEUROSCI-SWITZ, V5, DOI 10.3389/fnins.2011.00073
   Jayakumar H, 2016, ASIA S PACIF DES AUT, P298, DOI 10.1109/ASPDAC.2016.7428027
   Krizhevsky Alex, 2017, Communications of the ACM, V60, P84, DOI 10.1145/3065386
   LeCun Y, 2015, NATURE, V521, P436, DOI 10.1038/nature14539
   Merrikh-Bayat F, 2018, IEEE T NEUR NET LEAR, V29, P4782, DOI 10.1109/TNNLS.2017.2778940
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   WANG XB, 2017, PROC CVPR IEEE, P1, DOI DOI 10.1109/IEDM.2017.8268341
   Williams RS, 2013, CHAOS, CNN, MEMRISTORS AND BEYOND: A FESTSCHRIFT FOR LEON CHUA, P483
NR 17
TC 0
Z9 0
U1 0
U2 0
PY 2020
VL 28
IS 5
BP 2797
EP 2807
DI 10.3906/elk-1911-77
WC Computer Science, Artificial Intelligence; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU Schuiki, F
   Schaffner, M
   Gürkaynak, FK
   Benini, L
AF Schuiki, Fabian
   Schaffner, Michael
   Gurkaynak, Frank K.
   Benini, Luca
TI A Scalable Near-Memory Architecture for Training Deep Neural Networks on
   Large In-Memory Datasets
SO IEEE TRANSACTIONS ON COMPUTERS
DT Article
DE Parallel architectures; memory structures; memory hierarchy; machine
   learning; neural nets
ID POWER
AB Most investigations into near-memory hardware accelerators for deep neural networks have primarily focused on inference, while the potential of accelerating training has received relatively little attention so far. Based on an in-depth analysis of the key computational patterns in state-of-the-art gradient-based training methods, we propose an efficient near-memory acceleration engine called NTX that can be used to train state-of-the-art deep convolutional neural networks at scale. Our main contributions are: (i) a loose coupling of RISC-V cores and NTX co-processors reducing offloading overhead by 7 x over previously published results; (ii) an optimized IEEE 754 compliant data path for fast high-precision convolutions and gradient propagation; (iii) evaluation of near-memory computing with NTX embedded into residual area on the Logic Base die of a Hybrid Memory Cube; and (iv) a scaling analysis to meshes of HMCs in a data center scenario. We demonstrate a 2.7 x energy efficiency improvement of NTX over contemporary GPUs at 4.4 x less silicon area, and a compute performance of 1.2 Tflop/s for training large state-of-the-art networks with full floating-point precision. At the data center scale, a mesh of NTX achieves above 95 percent parallel and energy efficiency, while providing 2.1 x energy savings or 3.1 x performance improvement over a GPU-based system.
C1 [Schuiki, Fabian; Schaffner, Michael] Swiss Fed Inst Technol, D ITET, CH-8092 Zurich, Switzerland.
   [Gurkaynak, Frank K.] Swiss Fed Inst Technol, Microelect Design Ctr, CH-8092 Zurich, Switzerland.
   [Benini, Luca] Univ Bologna, Scuola Ingn & Architettura, Dipartimento Elettron Informat & Sistemist, I-40126 Bologna, Emilia Romagna, Italy.
RP Schuiki, F (corresponding author), Swiss Fed Inst Technol, D ITET, CH-8092 Zurich, Switzerland.
EM fschuiki@iis.ee.ethz.ch; schaffner@iis.ee.ethz.ch; kgf@ee.ethz.ch;
   lbenini@iis.ee.ethz.ch
CR Andri R, 2018, IEEE T COMPUT AID D, V37, P48, DOI 10.1109/TCAD.2017.2682138
   [Anonymous], PROC CVPR IEEE
   [Anonymous], 2017, CNN BENCHMARKS
   [Anonymous], 2014, MEASURING DDR4 POWER
   [Anonymous], ARXIV170309039CSCV
   [Anonymous], HOTCHIPS AUG
   [Anonymous], P IEEE INT S CIRC SY
   [Anonymous], 301342 ISOIEC
   [Anonymous], 2017, TENSORFLOW BENCHMARK
   [Anonymous], ART INT ARCH
   [Anonymous], 2014, 2 WORKSH NEAR DAT PR
   [Anonymous], 2015, HYBRID MEMORY CUBE S
   [Anonymous], 2017, P 22 INT C ARCHITECT
   [Anonymous], AV PRIC EL ULT CUST
   [Anonymous], 2016, ARXIV160205629CSLG
   [Anonymous], ARXIV160401946CSLG
   [Anonymous], ARXIV150102876CSCV
   [Anonymous], 2017, DEEP LEARNING BENCHM
   [Anonymous], IEDM 2013 PREVIEW
   [Anonymous], 53 DES AUT C AUST TX
   Azarkhish Erfan, 2018, IEEE Transactions on Parallel and Distributed Systems, V29, P420, DOI 10.1109/TPDS.2017.2752706
   Azarkhish Erfan, 2016, Architecture of Computing Systems - ARCS 2016. 29th International Conference. Proceedings: LNCS 9637, P19, DOI 10.1007/978-3-319-30695-7_2
   Cavigelli L, 2015, DES AUT CON, DOI 10.1145/2744769.2744788
   Chen TS, 2014, ACM SIGPLAN NOTICES, V49, P269, DOI 10.1145/2541940.2541967
   Gao J, 2014, MACHINE LEARNING APP
   Gautschi M, 2017, IEEE T VLSI SYST, V25, P2700, DOI 10.1109/TVLSI.2017.2654506
   Goodfellow I, 2016, ADAPT COMPUT MACH LE, P1
   Hong S, 2010, CONF PROC INT SYMP C, P280, DOI 10.1145/1816038.1815998
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kim D, 2016, CONF PROC INT SYMP C, P380, DOI 10.1109/ISCA.2016.41
   Koster U, 2017, PROC TEH 31 C NEURAL, P1740, DOI DOI 10.48550/ARXIV.1711.02213
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Luo T, 2017, IEEE T COMPUT, V66, P73, DOI 10.1109/TC.2016.2574353
   Pattnaik A, 2016, 2016 INTERNATIONAL CONFERENCE ON PARALLEL ARCHITECTURE AND COMPILATION TECHNIQUES (PACT), P31, DOI 10.1145/2967938.2967940
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Simunic T, 2001, DES AUT CON, P524, DOI 10.1109/DAC.2001.935564
   Szegedy C., 2015, PROC CVPR IEEE, DOI DOI 10.1109/CVPR.2015.7298594
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   Venkataramani S, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P13, DOI 10.1145/3079856.3080244
   Wen W., 2016, ADV NEURAL INFORM PR, P2082, DOI DOI 10.1016/J.CCR.2008.06.009
   Zhang C., 2016, PROC IEEEACM INT C C, P1
NR 41
TC 35
Z9 36
U1 3
U2 22
PD APR
PY 2019
VL 68
IS 4
BP 484
EP 497
DI 10.1109/TC.2018.2876312
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT J
AU da Rosa, MMA
   Paim, G
   da Costa, PUL
   da Costa, EAC
   Soares, RI
   Bampi, S
AF Azevedo da Rosa, Morgana Macedo
   Paim, Guilherme
   Leleu da Costa, Patricia Ucker
   Cesar da Costa, Eduardo Antonio
   Soares, Rafael, I
   Bampi, Sergio
TI AxPPA: Approximate Parallel Prefix Adders
SO IEEE TRANSACTIONS ON VERY LARGE SCALE INTEGRATION (VLSI) SYSTEMS
DT Article
DE Adders; Approximate adders (AxA); approximate computing (AxC);
   energy-efficient operators; parallel prefix adders (PPAs)
ID DESIGN; HARDWARE; COMPRESSORS; ALGORITHM
AB Addition units are widely used in many computational kernels of several error-tolerant applications such as machine learning and signal, image, and video processing. Besides their use as stand-alone, additions are essential building blocks for other math operations such as subtraction, comparison, multiplication, squaring, and division. The parallel prefix adders (PPAs) is among the fastest adders. It represents a parallel prefix graph consisting of the carry operator nodes, called prefix operators (POs). The PPAs, in particular, are among the fastest adders because they optimize the parallelization of the carry generation ( $G$ ) and propagation ( $P$ ). In this work, we introduce approximate PPAs (AxPPAs) by exploiting approximations in the POs. To evaluate our proposal for approximate POs (AxPOs), we generate the following AxPPAs, consisting of a set of four PPAs: approximate Brent-Kung (AxPPA-BK), approximate Kogge-Stone (AxPPA-KS), Ladner-Fischer (AxPPA-LF), and Sklansky (AxPPA-SK). We compare four AxPPA architectures with energy-efficient approximate adders (AxAs) i.e., Copy, error-tolerant adder I (ETAI), lower-part or adder (LOA), and Truncation (trunc). We tested them generically in stand-alone cases and embedded them in two important signal processing application kernels: a sum of squared differences (SSDs) video accelerator and a finite impulse response (FIR) filter kernel. The AxPPA-LF provides a new Pareto front in both energy-quality and area-quality results compared to state-of-the-art energy-efficient AxAs.
C1 [Azevedo da Rosa, Morgana Macedo; Soares, Rafael, I] Univ Fed Pelotas UFPel, Dept Comp Sci, BR-96010610 Pelotas, RS, Brazil.
   [Paim, Guilherme; Leleu da Costa, Patricia Ucker; Bampi, Sergio] Univ Fed Rio Grande Sul UFRGS, Dept Microelect, BR-90010150 Porto Alegre, RS, Brazil.
   [Cesar da Costa, Eduardo Antonio] Univ Catolica Pelotas UCPel, Dept Elect & Comp, BR-96015560 Pelotas, RS, Brazil.
RP Soares, RI (corresponding author), Univ Fed Pelotas UFPel, Dept Comp Sci, BR-96010610 Pelotas, RS, Brazil.
EM mmarosa@inf.ufpel.edu.br; gppaim@ieee.org; eduardo.costa@ucpel.edu.br
CR Aksoy L, 2010, MICROPROCESS MICROSY, V34, P151, DOI 10.1016/j.micpro.2009.10.001
   Alhazmi B, 2019, IEEE ACCESS, V7, P58704, DOI 10.1109/ACCESS.2019.2914641
   Arya N, 2021, IEEE T VLSI SYST, V29, P1994, DOI 10.1109/TVLSI.2021.3114616
   Bossen F, 2013, JCTVCL1100
   BRENT RP, 1982, IEEE T COMPUT, V31, P260, DOI 10.1109/TC.1982.1675982
   Briechle K, 2001, PROC SPIE, V4387, P95, DOI 10.1117/12.421129
   da Costa P., 2022, 2022 IEEE 13 LATIN A, P1
   da Rosa M. M. A., 2020, 2020 27 IEEE INT C E, P1
   da Rosa M. M. A., 2022, PROC IEEE INT S CIRC, P1
   Daphni S., 2017, 2017 IEEE International Conference on Circuits and Systems (ICCS). Proceedings, P103, DOI 10.1109/ICCS1.2017.8325971
   Du K, 2012, DES AUT TEST EUROPE, P1257
   Ene TD, 2021, PR IEEE COMP DESIGN, P125, DOI 10.1109/ICCD53106.2021.00030
   Esposito D, 2018, IEEE T CIRCUITS-I, V65, P4169, DOI 10.1109/TCSI.2018.2839266
   Esposito D, 2016, IEEE T CIRCUITS-I, V63, P1200, DOI 10.1109/TCSI.2016.2564699
   Esposito D, 2015, IEEE T CIRCUITS-I, V62, P1353, DOI 10.1109/TCSI.2015.2403036
   Guidotti V, 2020, CIRC SYST SIGNAL PR, V39, P5729, DOI 10.1007/s00034-020-01431-9
   Gupta V., 2011, 2011 International Symposium on Low Power Electronics and Design (ISLPED 2011), P409, DOI 10.1109/ISLPED.2011.5993675
   Gupta V, 2013, IEEE T COMPUT AID D, V32, P124, DOI 10.1109/TCAD.2012.2217962
   Hisham MB, 2015, IEEE ST CONF RES DEV, P100, DOI 10.1109/SCORED.2015.7449303
   HM, 2017, HEVC TEST MODEL HM 1
   Jiang HL, 2019, IEEE T CIRCUITS-I, V66, P313, DOI 10.1109/TCSI.2018.2856513
   Kahng AB, 2012, DES AUT CON, P820
   Kim Y, 2013, ICCAD-IEEE ACM INT, P130, DOI 10.1109/ICCAD.2013.6691108
   KOGGE PM, 1973, IEEE T COMPUT, VC-22, P786, DOI 10.1109/TC.1973.5009159
   LADNER RE, 1980, J ACM, V27, P831, DOI 10.1145/322217.322232
   Lee J, 2021, IEEE ACCESS, V9, P119939, DOI 10.1109/ACCESS.2021.3108443
   Liu WQ, 2018, IEEE T CIRCUITS-I, V65, P2856, DOI 10.1109/TCSI.2018.2792902
   Lu SL, 2004, COMPUTER, V37, P67, DOI 10.1109/MC.2004.1274006
   Ma YZ, 2019, IEEE T COMPUT AID D, V38, P2298, DOI 10.1109/TCAD.2018.2878129
   Macedo M, 2017, IEEE I C ELECT CIRC, P298, DOI 10.1109/ICECS.2017.8292078
   Mahdiani HR, 2010, IEEE T CIRCUITS-I, V57, P850, DOI 10.1109/TCSI.2009.2027626
   Reddy KM, 2020, IEEE T VLSI SYST, V28, P1230, DOI 10.1109/TVLSI.2020.2976131
   Mazahir S., 2016, PROC 53 ACM EDAC IEE, P1
   Miao J, 2012, ICCAD-IEEE ACM INT, P728
   Ning Zhu, 2010, Proceedings 2010 International SoC Design Conference (ISOCC 2010), P323, DOI 10.1109/SOCDC.2010.5682905
   Paim G, 2022, IEEE T CIRC SYST VID, V32, P398, DOI 10.1109/TCSVT.2021.3059229
   Paim G, 2021, IEEE T CIRCUITS-I, V68, P1481, DOI 10.1109/TCSI.2021.3058451
   Paim G, 2020, IEEE T CIRC SYST VID, V30, P3814, DOI 10.1109/TCSVT.2019.2945763
   Paim G, 2019, IEEE T CIRCUITS-I, V66, P680, DOI 10.1109/TCSI.2018.2868513
   Paim G, 2017, IEEE I C ELECT CIRC, P482, DOI 10.1109/ICECS.2017.8292070
   Paim G, 2017, 2017 30TH SYMPOSIUM ON INTEGRATED CIRCUITS AND SYSTEMS DESIGN (SBCCI 2017): CHOP ON SANDS, P168, DOI 10.1145/3109984.3110021
   Paim G, 2016, IEEE I C ELECT CIRC, P261, DOI 10.1109/ICECS.2016.7841182
   Pashaeifar M, 2019, IEEE T CIRCUITS-I, V66, P327, DOI 10.1109/TCSI.2018.2856757
   Pereira P.M., 2021, 2021 TEL C CONFTELE, P1
   Pereira PTL, 2022, IEEE T CIRCUITS-I, V69, P4524, DOI 10.1109/TCSI.2022.3191180
   Pudi V, 2017, IEEE T COMPUT, V66, P1824, DOI 10.1109/TC.2017.2696524
   Rehman S, 2016, ICCAD-IEEE ACM INT, DOI 10.1145/2966986.2967005
   Roy Rajarshi, 2021, 2021 58th ACM/IEEE Design Automation Conference (DAC), P853, DOI 10.1109/DAC18074.2021.9586094
   Roy S, 2013, DES AUT CON
   Seidel HB, 2021, IEEE T CIRCUITS-I, V68, P1814, DOI 10.1109/TCSI.2021.3057584
   Seidel I, 2016, IEEE LAT AMER SYMP, P327, DOI 10.1109/LASCAS.2016.7451076
   Shafique M, 2015, DES AUT CON, DOI 10.1145/2744769.2744778
   Silveira B, 2017, IEEE T CIRCUITS-I, V64, P3126, DOI 10.1109/TCSI.2017.2728802
   Sklansky J., 1960, IRE EC, V9, P226, DOI DOI 10.1109/TEC.1960.5219822
   Soares L. B., 2015, P IEEE INT NEW CIRCU, P1, DOI DOI 10.1109/NEWCAS.2015.7182095
   Soares LB, 2020, CIRC SYST SIGNAL PR, V39, P6098, DOI 10.1007/s00034-020-01448-0
   Soares LB, 2019, IEEE T CIRCUITS-I, V66, P2137, DOI 10.1109/TCSI.2019.2892588
   Stanley-Marbell P, 2020, ACM COMPUT SURV, V53, DOI 10.1145/3394898
   Strollo AGM, 2020, IEEE T CIRCUITS-I, V67, P3021, DOI 10.1109/TCSI.2020.2988353
   Tasoulas ZG, 2020, IEEE T CIRCUITS-I, V67, P4670, DOI 10.1109/TCSI.2020.3019460
   Tsai KL, 2021, IEEE T CIRCUITS-I, V68, P3328, DOI 10.1109/TCSI.2021.3085572
   Tzanetakis G, 2002, IEEE T SPEECH AUDI P, V10, P293, DOI 10.1109/TSA.2002.800560
   Verma AK, 2008, DES AUT TEST EUROPE, P1092
   Weste N.E.H., 2015, CMOS VLSI DESIGN CIR
   Ye R, 2013, ICCAD-IEEE ACM INT, P48, DOI 10.1109/ICCAD.2013.6691096
   Zhu N, 2009, PROCEEDINGS OF THE 2009 12TH INTERNATIONAL SYMPOSIUM ON INTEGRATED CIRCUITS (ISIC 2009), P400
   Zhu N, 2010, IEEE T VLSI SYST, V18, P1225, DOI 10.1109/TVLSI.2009.2020591
NR 67
TC 4
Z9 4
U1 1
U2 4
PD JAN
PY 2023
VL 31
IS 1
BP 17
EP 28
DI 10.1109/TVLSI.2022.3218021
EA NOV 2022
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

PT C
AU Lee, Y
   Choi, H
   Min, S
   Lee, H
   Beak, S
   Jeong, D
   Lee, JW
   Ham, TJ
AF Lee, Yejin
   Choi, Hyunji
   Min, Sunhong
   Lee, Hyunseung
   Beak, Sangwon
   Jeong, Dawoon
   Lee, Jae W.
   Ham, Tae Jun
GP IEEE Comp Soc
TI ANNA: Specialized Architecture for Approximate Nearest Neighbor Search
SO 2022 IEEE INTERNATIONAL SYMPOSIUM ON HIGH-PERFORMANCE COMPUTER
   ARCHITECTURE (HPCA 2022)
SE International Symposium on High-Performance Computer
   Architecture-Proceedings
DT Proceedings Paper
CT 28th Annual IEEE International Symposium on High-Performance Computer
   Architecture (HPCA)
CY APR 02-06, 2022
CL ELECTR NETWORK
DE Similarity Search; Hardware Accelerator; Approximate Nearest Neighbor
   Search; Product Quantization
AB Similarity search or nearest neighbor search is a task of retrieving a set of vectors in the (vector) database that are most similar to the provided query vector. It has been a key kernel for many applications for a long time. However, it is becoming especially more important in recent days as modern neural networks and machine learning models represent the semantics of images, videos, and documents as high-dimensional vectors called embeddings. Finding a set of similar embeddings for the provided query embedding is now the critical operation for modern recommender systems and semantic search engines. Since exhaustively searching for the most similar vectors out of billion vectors is such a prohibitive task, approximate nearest neighbor search (ANNS) is often utilized in many real-world use cases. Unfortunately, we find that utilizing the server-class CPUs and GPUs for the ANNS task leads to suboptimal performance and energy efficiency. To address such limitations, we propose a specialized architecture named ANNA (Approximate Nearest Neighbor search Accelerator), which is compatible with state-of-the-art ANNS algorithms such as Google ScaNN and Facebook Faiss. By combining the benefits of a specialized dataflow pipeline and efficient data reuse, ANNA achieves multiple orders of magnitude higher energy efficiency, 2.3-61.6x higher throughput, and 4.3-82.1x lower latency than the conventional CPU or GPU for both million- and billion-scale datasets.
C1 [Lee, Yejin; Choi, Hyunji; Min, Sunhong; Lee, Hyunseung; Beak, Sangwon; Jeong, Dawoon; Lee, Jae W.; Ham, Tae Jun] Seoul Natl Univ, Seoul, South Korea.
RP Lee, Y (corresponding author), Seoul Natl Univ, Seoul, South Korea.
EM yejinlee@snu.ac.kr; hyunjichoi@snu.ac.kr; sunhongmin@snu.ac.kr;
   hs_lee@snu.ac.kr; bsw1907@gmail.com; daun20211@snu.ac.kr;
   jaewlee@snu.ac.kr; ham.taejun@gmail.com
CR Abdelhadi AMS, 2019, 2019 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2019), P90, DOI 10.1109/ICFPT47387.2019.00019
   Babenko A, 2016, PROC CVPR IEEE, P2055, DOI 10.1109/CVPR.2016.226
   Babenko A, 2014, PROC CVPR IEEE, P931, DOI 10.1109/CVPR.2014.124
   Barz B, 2019, IEEE WINT CONF APPL, P638, DOI 10.1109/WACV.2019.00073
   berkeley.edu, ABT US
   Bhagwan R., 2000, Proceedings IEEE INFOCOM 2000. Conference on Computer Communications. Nineteenth Annual Joint Conference of the IEEE Computer and Communications Societies (Cat. No.00CH37064), P538, DOI 10.1109/INFCOM.2000.832227
   Cer D, 2018, Arxiv, DOI arXiv:1803.11175
   Chen QW, 2019, 1ST INTERNATIONAL WORKSHOP ON DEEP LEARNING PRACTICE FOR HIGH-DIMENSIONAL SPARSE DATA WITH KDD (DLP-KDD 2019), DOI 10.1145/3326937.3341261
   Chen W, 2021, COMPUT ELECTR ENG, V90, DOI 10.1016/j.compeleceng.2021.107002
   Covington P, 2016, PROCEEDINGS OF THE 10TH ACM CONFERENCE ON RECOMMENDER SYSTEMS (RECSYS'16), P191, DOI 10.1145/2959100.2959190
   Danopoulos D, 2019, 2019 14TH INTERNATIONAL SYMPOSIUM ON RECONFIGURABLE COMMUNICATION-CENTRIC SYSTEMS-ON-CHIP (RECOSOC 2019), P59, DOI 10.1109/ReCoSoC48741.2019.9034938
   Datar M., 2004, P 20 ANN S COMP GEOM, P253
   Dong Y., 2021, IEEE INTERNET THINGS, P1
   Ge TZ, 2014, IEEE T PATTERN ANAL, V36, P744, DOI 10.1109/TPAMI.2013.240
   github, ANNOY
   github.com, KGRAPH LIB APPR NEAR
   github.com, NEIGHBORHOOD GRAPH T
   github.com, 2018, SPTAG LIB FAST APPRO
   github.com, FALCONN FAST LOOKUPS
   github.com, BENCHMARKING NEAREST
   github.com, FAISS
   gsitechnology.com, GEM APU EN HIGH PERF
   Guo RQ, 2020, PR MACH LEARN RES, V119
   Harwood B, 2016, PROC CVPR IEEE, P5713, DOI 10.1109/CVPR.2016.616
   Hyv”nen V, 2016, Arxiv, DOI arXiv:1509.06957
   Iwasaki M, 2016, LECT NOTES COMPUT SC, V9939, P20, DOI 10.1007/978-3-319-46759-7_2
   Jégou H, 2011, INT CONF ACOUST SPEE, P861
   Jégou H, 2011, IEEE T PATTERN ANAL, V33, P117, DOI 10.1109/TPAMI.2010.57
   Johnson J, 2021, IEEE T BIG DATA, V7, P535, DOI 10.1109/TBDATA.2019.2921572
   Klein B, 2019, PROC CVPR IEEE, P5036, DOI 10.1109/CVPR.2019.00518
   Lu A, 2020, 2020 INTERNATIONAL CONFERENCE ON FIELD-PROGRAMMABLE TECHNOLOGY (ICFPT 2020), P139, DOI 10.1109/ICFPT51103.2020.00027
   Malkov YA, 2020, IEEE T PATTERN ANAL, V42, P824, DOI 10.1109/TPAMI.2018.2889473
   Matsui Y, 2018, ITE TRANS MEDIA TECH, V6, P2, DOI 10.3169/mta.6.2
   Matsumoto T, 2015, IEEE DATA MINING, P320, DOI 10.1109/ICDM.2015.125
   microsoft.com, BING VECTOR SEARCH
   Miech Antoine, 2020, 2020 IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR). Proceedings, P9876, DOI 10.1109/CVPR42600.2020.00990
   Mikolov T, 2013, Arxiv, DOI [arXiv:1301.3781, DOI 10.48550/ARXIV.1301.3781]
   Muja M, 2014, IEEE T PATTERN ANAL, V36, P2227, DOI 10.1109/TPAMI.2014.2321376
   Muthusundari S, 2021, ANN ROMANIAN SOC CEL, V25, P2602
   Naumov Maxim, 2019, ARXIV
   Nvidia, NVIDIA VIS PROF
   nvidia. com, 2020, NVIDIA V100 TENS COR
   nvidia.com, NVIDIA MERLIN
   nvidia.com, NVIDIA NSIGHT SYSTEM
   Pennington J., 2014, P EMNLP, P1532, DOI DOI 10.3115/V1/D14-1162
   Pu YL, 2015, ANN IEEE SYM FIELD P, P167, DOI 10.1109/FCCM.2015.7
   Razavian AS, 2014, IEEE COMPUT SOC CONF, P512, DOI 10.1109/CVPRW.2014.131
   Shrivastava A, 2014, Arxiv, DOI arXiv:1405.5869
   Sun H, 2020, IEEE T CIRCUITS-II, V67, P1644, DOI 10.1109/TCSII.2020.3013758
   Wang RX, 2021, PROCEEDINGS OF THE WORLD WIDE WEB CONFERENCE 2021 (WWW 2021), P1785, DOI 10.1145/3442381.3450078
   wikichip.org, LCC SOC SKYLAKE SERV
   Xu TC, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P629, DOI 10.1145/3352460.3358259
   yandex.com, BENCHMARKS BILLION S
   Zhan JT, 2021, PROCEEDINGS OF THE 30TH ACM INTERNATIONAL CONFERENCE ON INFORMATION & KNOWLEDGE MANAGEMENT, CIKM 2021, P2487, DOI 10.1145/3459637.3482358
   Zhang JL, 2018, PROC CVPR IEEE, P4924, DOI 10.1109/CVPR.2018.00517
   Zhao WJ, 2020, PROC INT CONF DATA, P1033, DOI 10.1109/ICDE48307.2020.00094
NR 56
TC 0
Z9 0
U1 1
U2 5
PY 2022
BP 169
EP 183
DI 10.1109/HPCA53966.2022.00021
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods; Engineering, Electrical & Electronic
DA 2023-11-11
ER

PT C
AU Khoram, S
   Zhang, JL
   Strange, M
   Li, J
AF Khoram, Soroosh
   Zhang, Jialiang
   Strange, Maxwell
   Li, Jing
GP ACM
TI Accelerating Graph Analytics by Co-Optimizing Storage and Access on an
   FPGA-HMC Platform
SO PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON
   FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18)
DT Proceedings Paper
CT ACM/SIGDA International Symposium on Field-Programmable Gate Arrays
   (FPGA)
CY FEB 25-27, 2018
CL Monterey, CA
DE Graph Analytics; Graph Clustering; Hybrid Memory Cube; Reconfigurable
   Logic; Hardware Accelerators
ID ALGORITHM
AB Graph analytics, which explores the relationships among interconnected entities, is becoming increasingly important due to its broad applicability, from machine learning to social sciences. However, due to the irregular data access patterns in graph computations, one major challenge for graph processing systems is performance. The algorithms, softwares, and hardwares that have been tailored for mainstream parallel applications are generally not effective for massive, sparse graphs from the real-world problems, due to their complex and irregular structures.
   To address the performance issues in large-scale graph analytics, we leverage the exceptional random access performance of the emerging Hybrid Memory Cube (HMC) combined with the flexibility and efficiency of modern FPGAs. In particular, we develop a collaborative software/hardware technique to perform a level-synchronized Breadth First Search (BFS) on a FPGA-HMC platform. From the software perspective, we develop an architecture-aware graph clustering algorithm that exploits the FPGA-HMC platform's capability to improve data locality and memory access efficiency. From the hardware perspective, we further improve the FPGA-HMC graph processor architecture by designing a memory request merging unit to take advantage of the increased data locality resulting from graph clustering. We evaluate the performance of our BFS implementation using the AC-510 development kit from Micron and achieve 2.8x average performance improvement compared to the latest FPGA-HMC based graph processing system over a set of benchmarks from a wide range of applications.
C1 [Khoram, Soroosh; Zhang, Jialiang; Strange, Maxwell; Li, Jing] Univ Wisconsin, Dept Elect & Comp Engn, Madison, WI 53706 USA.
RP Khoram, S (corresponding author), Univ Wisconsin, Dept Elect & Comp Engn, Madison, WI 53706 USA.
EM khoram@wisc.edu; jialiang.zhang@ece.wisc.edu; mbstrange@wisc.edu;
   jli@ece.wisc.edu
CR Bader GD, 2003, BMC BIOINFORMATICS, V4, DOI 10.1186/1471-2105-4-2
   Beamer S, 2012, INT CONF HIGH PERFOR
   Blatt M, 1996, PHYS REV LETT, V76, P3251, DOI 10.1103/PhysRevLett.76.3251
   Brandes U, 2003, LECT NOTES COMPUT SC, V2832, P568
   Brohée S, 2006, BMC BIOINFORMATICS, V7, DOI 10.1186/1471-2105-7-488
   Dai GH, 2016, PROCEEDINGS OF THE 2016 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'16), P105, DOI 10.1145/2847263.2847339
   Davis TA, 2011, ACM T MATH SOFTWARE, V38, DOI 10.1145/2049662.2049663
   Felzenszwalb PF, 2011, IEEE T PATTERN ANAL, V33, P721, DOI 10.1109/TPAMI.2010.135
   Gjoka M, 2010, IEEE INFOCOM SER, DOI 10.1109/infcom.2010.5462078
   Haveliwala TH, 2003, IEEE T KNOWL DATA EN, V15, P784, DOI 10.1109/TKDE.2003.1208999
   King AD, 2004, BIOINFORMATICS, V20, P3013, DOI 10.1093/bioinformatics/bth351
   Koyutürk M, 2004, BIOINFORMATICS, V20, P200, DOI 10.1093/bioinformatics/bth919
   Lee BC, 2010, COMMUN ACM, V53, P99, DOI 10.1145/1785414.1785441
   Lei Guoqing, 2015, ENG SCI TECHNOLOGY I, V5, P313
   Locke Kyle, 2011, PARAMETERIZABLE CONT
   Merrill D, 2012, ACM SIGPLAN NOTICES, V47, P117, DOI 10.1145/2370036.2145832
   Pawlowski J. Thomas, 2011, 2011 IEEE Hot Chips 23 Symposium (HCS), P1, DOI 10.1109/HOTCHIPS.2011.7477494
   Picocomputing, ULTR BAS SUPERPROCES
   Picocomputing, HYBR MEM CUB HMC CON
   Rosenfeld P., 2014, PERFORMANCE EXPLORAT
   Umuroglu Yaman, 2015, 2015 25th International Conference on Field Programmable Logic and Applications (FPL), P1, DOI 10.1109/FPL.2015.7293939
   VANDONGEN S, 2000, THESIS U UTRECHT UTR
   Wang YZH, 2015, ACM SIGPLAN NOTICES, V50, P265, DOI [10.1145/2688500.2688538, 10.1145/2858788.2688538]
   Zhang JL, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P207, DOI 10.1145/3020078.3021737
NR 24
TC 21
Z9 24
U1 0
U2 0
PY 2018
BP 239
EP 248
DI 10.1145/3174243.3174260
WC Computer Science, Theory & Methods
DA 2023-11-11
ER

PT J
AU Ambrogio, S
   Narayanan, P
   Tsai, HY
   Shelby, RM
   Boybat, I
   di Nolfo, C
   Sidler, S
   Giordano, M
   Bodini, M
   Farinha, NCP
   Killeen, B
   Cheng, C
   Jaoudi, Y
   Burr, GW
AF Ambrogio, Stefano
   Narayanan, Pritish
   Tsai, Hsinyu
   Shelby, Robert M.
   Boybat, Irem
   di Nolfo, Carmelo
   Sidler, Severin
   Giordano, Massimo
   Bodini, Martina
   Farinha, Nathan C. P.
   Killeen, Benjamin
   Cheng, Christina
   Jaoudi, Yassine
   Burr, Geoffrey W.
TI Equivalent-accuracy accelerated neural-network training using analogue
   memory
SO NATURE
DT Article
ID SYNAPSES; DEVICES
AB Neural-network training can be slow and energy intensive, owing to the need to transfer the weight data for the network between conventional digital memory chips and processor chips. Analogue non-volatile memory can accelerate the neural-network training algorithm known as backpropagation by performing parallelized multiply-accumulate operations in the analogue domain at the location of the weight data. However, the classification accuracies of such in situ training using non-volatile-memory hardware have generally been less than those of software-based training, owing to insufficient dynamic range and excessive weight-update asymmetry. Here we demonstrate mixed hardware-software neural-network implementations that involve up to 204,900 synapses and that combine long-term storage in phase-change memory, near-linear updates of volatile capacitors and weight-data transfer with 'polarity inversion' to cancel out inherent device-to-device variations. We achieve generalization accuracies (on previously unseen data) equivalent to those of software-based training on various commonly used machine-learning test datasets (MNIST, MNIST-backrand, CIFAR-10 and CIFAR-100). The computational energy efficiency of 28,065 billion operations per second per watt and throughput per area of 3.6 trillion operations per second per square millimetre that we calculate for our implementation exceed those of today's graphical processing units by two orders of magnitude. This work provides a path towards hardware accelerators that are both fast and energy efficient, particularly on fully connected neural-network layers.
C1 [Ambrogio, Stefano; Narayanan, Pritish; Tsai, Hsinyu; Shelby, Robert M.; di Nolfo, Carmelo; Sidler, Severin; Giordano, Massimo; Bodini, Martina; Farinha, Nathan C. P.; Killeen, Benjamin; Cheng, Christina; Jaoudi, Yassine; Burr, Geoffrey W.] IBM Res Almaden, San Jose, CA 95120 USA.
   [Boybat, Irem] IBM Res Zurich, Ruschlikon, Switzerland.
   [Boybat, Irem; di Nolfo, Carmelo; Sidler, Severin; Bodini, Martina] Ecole Polytech Fed Lausanne, Lausanne, Switzerland.
RP Burr, GW (corresponding author), IBM Res Almaden, San Jose, CA 95120 USA.
EM gwburr@us.ibm.com
CR Alibart F, 2012, NANOTECHNOLOGY, V23, DOI 10.1088/0957-4484/23/7/075201
   [Anonymous], 2017, PREPRINT
   [Anonymous], 2015 IEEE INT EL DEV
   [Anonymous], 2017 S VLSI TECHN T1
   [Anonymous], WCCFTECH
   [Anonymous], 2013, PROC 30 INT C MACH L
   [Anonymous], 1997, NEURAL COMPUT
   [Anonymous], 2014, PREPRINT
   [Anonymous], 2016, PREPRINT
   [Anonymous], 2014 IEEE INT EL DEV
   [Anonymous], 2014, P 31 INT C INT C MAC
   [Anonymous], 2016, DEEP LEARNING
   [Anonymous], 2015, 32 ICML
   [Anonymous], 2009, ACMSIGDA NEWSLETTER
   [Anonymous], 2009, LEARNING MULTIPLE LA
   Bengio Y., 2009, P 26 ANN INT C MACHI, P41, DOI DOI 10.1145/1553374.1553380
   Burr GW, 2017, ADV PHYS-X, V2, P89, DOI 10.1080/23746149.2016.1259585
   Burr GW, 2015, IEEE T ELECTRON DEV, V62, P3498, DOI 10.1109/TED.2015.2439635
   Burr GW, 2014, J VAC SCI TECHNOL B, V32, DOI 10.1116/1.4889999
   Esser SK, 2016, P NATL ACAD SCI USA, V113, P11441, DOI 10.1073/pnas.1604850113
   Fuller EJ, 2017, ADV MATER, V29, DOI 10.1002/adma.201604310
   Gao LG, 2015, NANOTECHNOLOGY, V26, DOI 10.1088/0957-4484/26/45/455204
   Gokmen T, 2016, FRONT NEUROSCI-SWITZ, V10, DOI 10.3389/fnins.2016.00333
   Hu M, 2016, DES AUT CON, DOI 10.1145/2897937.2898010
   Ielmini D, 2007, IEEE T ELECTRON DEV, V54, P308, DOI 10.1109/TED.2006.888752
   Jang JW, 2015, IEEE ELECTR DEVICE L, V36, P457, DOI 10.1109/LED.2015.2418342
   Jeong Y, 2015, APPL PHYS LETT, V107, DOI 10.1063/1.4934818
   Jouppi NP, 2017, 44TH ANNUAL INTERNATIONAL SYMPOSIUM ON COMPUTER ARCHITECTURE (ISCA 2017), P1, DOI 10.1145/3079856.3080246
   Kaneko Y, 2014, IEEE T ELECTRON DEV, V61, P2827, DOI 10.1109/TED.2014.2331707
   Kim S, 2017, MIDWEST SYMP CIRCUIT, P422, DOI 10.1109/MWSCAS.2017.8052950
   Lecun Y, 1998, P IEEE, V86, P2278, DOI 10.1109/5.726791
   LeCun Y, 2015, NATURE, V521, p7553 436 444, DOI [10.1038/nature14539, DOI 10.1038/NATURE14539]
   Merolla PA, 2014, SCIENCE, V345, P668, DOI 10.1126/science.1254642
   MORIE T, 1994, IEEE J SOLID-ST CIRC, V29, P1086, DOI 10.1109/4.309904
   Narayanan P, 2017, IBM J RES DEV, V61, DOI 10.1147/JRD.2017.2716579
   Narayanan P., 2017, 2017 IEEE INT S CIRC, P1
   Nurvitadhi E, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P5, DOI 10.1145/3020078.3021740
   Papandreou N, 2011, IEEE INT SYMP CIRC S, P329
   PELGROM MJM, 1989, IEEE J SOLID-ST CIRC, V24, P1433, DOI 10.1109/JSSC.1989.572629
   Prezioso M, 2015, NATURE, V521, P61, DOI 10.1038/nature14441
   RUMELHART DE, 1986, NATURE, V323, P533, DOI 10.1038/323533a0
   Szegedy C, 2016, PROC CVPR IEEE, P2818, DOI 10.1109/CVPR.2016.308
   van de Burgt Y, 2017, NAT MATER, V16, P414, DOI [10.1038/nmat4856, 10.1038/NMAT4856]
   Xu ZH, 2014, PROCEDIA COMPUT SCI, V41, P126, DOI 10.1016/j.procs.2014.11.094
NR 44
TC 643
Z9 657
U1 12
U2 286
PD JUN 7
PY 2018
VL 558
IS 7708
BP 60
EP +
DI 10.1038/s41586-018-0180-5
WC Multidisciplinary Sciences
HC Y
HP N
DA 2023-11-11
ER

PT J
AU Borbon, JMR
   Huang, JJ
   Wong, BM
   Najjar, W
AF Borbon, Jose M. Rodriguez
   Huang, Junjie
   Wong, Bryan M.
   Najjar, Walid
TI Acceleration of Parallel-Blocked QR Decomposition of Tall-and-Skinny
   Matrices on FPGAs
SO ACM TRANSACTIONS ON ARCHITECTURE AND CODE OPTIMIZATION
DT Article
DE QR decomposition; accelerators; FPGA; reconfigurable computing
AB QR decomposition is one of the most useful factorization kernels in modern numerical linear algebra algorithms. In particular, the decomposition of tall-and-skinny matrices (TSMs) has major applications in scientific computing, machine learning, image processing, wireless networks, and numerical methods. Traditionally, CPUs and GPUs have achieved better throughput on these applications by using large cache hierarchies and compute cores running at a high frequency, leading to high power consumption. With the advent of heterogeneous platforms, however, FPGAs are emerging as a promising viable alternative. In this work, we propose a high-throughput FPGA-based engine that has a very high computational efficiency (ratio of achieved to peak throughput) compared to similar QR solvers running on FPGAs. Although comparable QR solvers achieve an efficiency of 36%, our design exhibits an efficiency of 54%. For TSMs, our experimental results show that our design can outperform highly optimized QR solvers running on CPUs and CPUs. For TSMs with more than 50K rows, our design outperforms the Intel MKL solver running on an Intel quad-core processor by a factor of 1.5x. For TSMs containing 256 columns or less, our design outperforms the NVIDIA CUBLAS solver running on a K40 GPU by a factor of 3.0x. In addition to being fast, our design is energy efficient-competing platforms execute up to 0.6 GFLOPS/Joule, whereas our design executes more than 1.0 GFLOPS/Joule.
C1 [Borbon, Jose M. Rodriguez; Huang, Junjie; Najjar, Walid] Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
   [Wong, Bryan M.] Univ Calif Riverside, Dept Chem & Environm Engn, Riverside, CA 92521 USA.
RP Borbon, JMR (corresponding author), Univ Calif Riverside, Dept Comp Sci & Engn, Riverside, CA 92521 USA.
EM jrodr050@ucr.edu; jhuan308@ucr.edu; bryan.wong@ucr.edu;
   najjar@cs.ucr.edu
CR Agullo E., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P932, DOI 10.1109/IPDPS.2011.90
   Anderson M., 2011, Proceedings of the 25th IEEE International Parallel & Distributed Processing Symposium (IPDPS 2011), P48, DOI 10.1109/IPDPS.2011.15
   [Anonymous], 2016, PROGRAMMING MASSIVEL
   [Anonymous], 2011, MAPREDUCE 11 P 2 INT, DOI DOI 10.1145/1996092.1996103
   [Anonymous], 2004, ACMSIGDA INT S FIELD
   [Anonymous], 2010, PARALLEL DISTRIBUTED
   [Anonymous], 2009, P 2 WORKSHOP GEN PUR
   Aslan S, 2012, MIDWEST SYMP CIRCUIT, P470, DOI 10.1109/MWSCAS.2012.6292059
   Benson AR, 2013, IEEE INT CONF BIG DA
   BISCHOF C, 1987, SIAM J SCI STAT COMP, V8, pS2, DOI 10.1137/0908009
   Boonpoonga A, 2010, LECT NOTES COMPUT SC, V5992, P394, DOI 10.1007/978-3-642-12133-3_39
   Burtscher M, P WORKSHOP GEN PURPO, P28, DOI [10.1145/2588768.2576783, DOI 10.1145/2576779.2576783]
   Candès EJ, 2011, J ACM, V58, DOI 10.1145/1970392.1970395
   Chauhan Abha, 2014, 2014 International Conference on Electronic Systems, Signal Processing and Computing Technologies (ICESC), P69, DOI 10.1109/ICESC.2014.20
   Che SA, 2008, 2008 SYMPOSIUM ON APPLICATION SPECIFIC PROCESSORS, P101, DOI 10.1109/SASP.2008.4570793
   Cong J, 2018, ANN IEEE SYM FIELD P, P93, DOI 10.1109/FCCM.2018.00023
   Danalis Anthony, 2010, P 3 WORKSHOP GEN PUR, P63, DOI [10.1145/1735688.1735702, DOI 10.1145/1735688.1735702]
   Demmel J, 2012, SIAM J SCI COMPUT, V34, pA206, DOI 10.1137/080731992
   Dongarra J, 2000, COMPUT SCI ENG, V2, P22, DOI 10.1109/MCISE.2000.814652
   Dua D, 2020, UCI MACHINE LEARNING
   Feist Tom, 2012, WP416 XIL
   Gerards M, 2009, PROCEEDINGS OF THE 2009 12TH EUROMICRO CONFERENCE ON DIGITAL SYSTEM DESIGN, ARCHITECTURES, METHODS AND TOOLS, P287, DOI 10.1109/DSD.2009.141
   Golub G. H., 2012, MATRIX COMPUTATIONS, V3
   Hill Tom, 2009, WP357 XIL
   Horowitz M, 2014, ISSCC DIG TECH PAP I, V57, P10, DOI 10.1109/ISSCC.2014.6757323
   HOUSEHOLDER AS, 1958, J ACM, V5, P339, DOI 10.1145/320941.320947
   Kahn G., 1974, IFIP 74 N HOLLAND, P471
   Langhammer M, 2018, PROCEEDINGS OF THE 2018 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS (FPGA'18), P183, DOI 10.1145/3174243.3174273
   Micron, 2020, MICR SB 852 WOLV 2
   Micron, 2018, CONV PDK REF MAN
   Muñoz SD, 2015, IEEE T CIRCUITS-II, V62, P861, DOI 10.1109/TCSII.2015.2435753
   NVIDIA, 2018, CUBLAS NVIDIAS DENS
   NVIDIA, 2018, CUDA TOOLK DOC
   NVIDIA, 2019, NVML API REF
   Ofenbeck G, 2014, INT SYM PERFORM ANAL, P76, DOI 10.1109/ISPASS.2014.6844463
   Omran Safaa S., 2018, 2018 International Conference on Advanced Science and Engineering (ICOASE), P189, DOI 10.1109/ICOASE.2018.8548895
   Parker M, 2016, PROC NAECON IEEE NAT, P416, DOI 10.1109/NAECON.2016.7856841
   Rafique A., 2012, 2012 22nd International Conference on Field Programmable Logic and Applications (FPL), P443, DOI 10.1109/FPL.2012.6339142
   Rodríguez-Borbón JM, 2020, J CHEM THEORY COMPUT, V16, P2085, DOI 10.1021/acs.jctc.9b01284
   Sergyienko A, 2002, LECT NOTES COMPUT SC, V2328, P458
   Shannon L, 2015, ANN IEEE SYM FIELD P, P1, DOI 10.1109/FCCM.2015.11
   Sirowy S., 2008, WHERES BEEF WHY FPGA
   Stewart GW, 2000, COMPUT SCI ENG, V2, P50, DOI 10.1109/5992.814658
   Tomov S, 2010, PARALLEL COMPUT, V36, P232, DOI 10.1016/j.parco.2009.12.005
   Trefethen L.N., 1997, NUMERICAL LINEAR ALG
   Treibig J., 2010, 2010 39th International Conference on Parallel Processing Workshops (ICPPW), P207, DOI 10.1109/ICPPW.2010.38
   Wang E., 2014, INTEL MATH KERNEL LI
   Wang Q, 2014, INT J APPL CERAM TEC, V11, P911, DOI 10.1111/ijac.12065
   Wang XJ, 2009, ACM T EMBED COMPUT S, V9, DOI 10.1145/1596532.1596535
   Watkins D. S., 2004, FUNDAMENTALS MATRIX
   Xinying Wang, 2014, 2014 IEEE Computer Society Annual Symposium on VLSI (ISVLSI), P541, DOI 10.1109/ISVLSI.2014.92
   Yi-Gang Tai, 2011, 2011 International Conference on Field Programmable Logic and Applications, P464, DOI 10.1109/FPL.2011.91
   Zhuo L, 2007, IEEE T PARALL DISTR, V18, P1377, DOI 10.1109/TPDS.2007.1068
NR 53
TC 0
Z9 0
U1 0
U2 3
PD JUN
PY 2021
VL 18
IS 3
AR 27
DI 10.1145/3447775
WC Computer Science, Hardware & Architecture; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT J
AU Qin, ZD
   Zhu, D
   Zhu, XW
   Chen, X
   Shi, YH
   Gao, Y
   Lu, ZH
   Shen, QH
   Li, L
   Pan, HB
AF Qin, Zidi
   Zhu, Di
   Zhu, Xingwei
   Chen, Xuan
   Shi, Yinghuan
   Gao, Yang
   Lu, Zhonghai
   Shen, Qinghong
   Li, Li
   Pan, Hongbing
TI Accelerating Deep Neural Networks by Combining Block-Circulant Matrices
   and Low-Precision Weights
SO ELECTRONICS
DT Article
DE hardware acceleration; deep neural networks (DNNs); fully-connected
   layers; network compression; VLSI
ID EXTREME LEARNING-MACHINE
AB As a key ingredient of deep neural networks (DNNs), fully-connected (FC) layers are widely used in various artificial intelligence applications. However, there are many parameters in FC layers, so the efficient process of FC layers is restricted by memory bandwidth. In this paper, we propose a compression approach combining block-circulant matrix-based weight representation and power-of-two quantization. Applying block-circulant matrices in FC layers can reduce the storage complexity from <mml:semantics>O(k2)</mml:semantics> to <mml:semantics>O(k)</mml:semantics>. By quantizing the weights into integer powers of two, the multiplications in the reference can be replaced by shift and add operations. The memory usages of models for MNIST, CIFAR-10 and ImageNet can be compressed by <mml:semantics>171x</mml:semantics>, <mml:semantics>2731x</mml:semantics> and <mml:semantics>128x</mml:semantics> with minimal accuracy loss, respectively. A configurable parallel hardware architecture is then proposed for processing the compressed FC layers efficiently. Without multipliers, a block matrix-vector multiplication module (B-MV) is used as the computing kernel. The architecture is flexible to support FC layers of various compression ratios with small footprint. Simultaneously, the memory access can be significantly reduced by using the configurable architecture. Measurement results show that the accelerator has a processing power of 409.6 GOPS, and achieves 5.3 TOPS/W energy efficiency at 800 MHz.
C1 [Qin, Zidi; Zhu, Di; Zhu, Xingwei; Chen, Xuan; Shen, Qinghong; Li, Li; Pan, Hongbing] Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
   [Shi, Yinghuan; Gao, Yang] Nanjing Univ, State Key Lab Novel Software Technol, Nanjing 210023, Jiangsu, Peoples R China.
   [Lu, Zhonghai] KTH Royal Inst Technol, Sch Elect Engn & Comp Sci, S-11428 Stockholm, Sweden.
RP Pan, HB (corresponding author), Nanjing Univ, Sch Elect Sci & Engn, Nanjing 210023, Jiangsu, Peoples R China.
EM qinzidi@smail.nju.edu.cn; zhudi@smail.nju.edu.cn; flzs@smail.nju.edu.cn;
   cx0705@smail.nju.edu.cn; syh@nju.edu.cn; gaoy@nju.edu.cn;
   zhonghai@kth.se; qhshen@nju.edu.cn; lili@nju.edu.cn; phb@nju.edu.cn
CR Ando K, 2018, IEEE J SOLID-ST CIRC, V53, P983, DOI 10.1109/JSSC.2017.2778702
   [Anonymous], 2017, ICCAD-IEEE ACM INT
   [Anonymous], 2012, ADV NEURAL INFORM PR
   [Anonymous], 2015, INT C NEUR INF PROC
   Cheng Y., 2015, ARXIV150203436
   Cheng Y, 2015, IEEE I CONF COMP VIS, P2857, DOI 10.1109/ICCV.2015.327
   Choi Y., 2016, P INT C LEARN REPR S
   Courbariaux M., 2015, ADV NEURAL INFORM PR, P3123, DOI DOI 10.5555/2969442.2969588
   Courbariaux M., 2016, C NEUR INF PROC SYST
   Ding CW, 2017, 50TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P395, DOI 10.1145/3123939.3124552
   Dominguez-Sanchez A, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110301
   Han S., 2016, P INT C LEARN REPR S
   Han S, 2016, CONF PROC INT SYMP C, P243, DOI 10.1109/ISCA.2016.30
   Krizhevsky A, 2017, COMMUN ACM, V60, P84, DOI 10.1145/3065386
   Liu XF, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7060078
   Mikolov T, 2010, 11TH ANNUAL CONFERENCE OF THE INTERNATIONAL SPEECH COMMUNICATION ASSOCIATION 2010 (INTERSPEECH 2010), VOLS 1-2, P1045
   Mirza B, 2016, PROC ADAPT LEARN OPT, V6, P39, DOI 10.1007/978-3-319-28397-5_4
   Muralimanohar N, 2007, INT SYMP MICROARCH, P3, DOI 10.1109/MICRO.2007.33
   Nguyen TV, 2017, NEUROCOMPUTING, V260, P123, DOI 10.1016/j.neucom.2017.04.007
   Shin D, 2017, ISSCC DIG TECH PAP I, P240, DOI 10.1109/ISSCC.2017.7870350
   Sze V, 2017, P IEEE, V105, P2295, DOI 10.1109/JPROC.2017.2761740
   Tang ZL, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7070122
   TEIXEIRA M, 1995, IEEE SIGNAL PROC LET, V2, P92, DOI 10.1109/97.386287
   Teixeira M, 2008, IEEE T SIGNAL PROCES, V56, P2755, DOI 10.1109/TSP.2008.917375
   Wang XQ, 2018, ELECTRONICS-SWITZ, V7, DOI 10.3390/electronics7110302
   Wang YZ, 2018, IEEE T VLSI SYST, V26, P280, DOI 10.1109/TVLSI.2017.2767624
   Wang ZS, 2017, IEEE T VLSI SYST, V25, P2763, DOI 10.1109/TVLSI.2017.2717950
   Wu JX, 2016, PROC CVPR IEEE, P4820, DOI 10.1109/CVPR.2016.521
   Zhao L., 2017, CORR
   Zhao R, 2017, FPGA'17: PROCEEDINGS OF THE 2017 ACM/SIGDA INTERNATIONAL SYMPOSIUM ON FIELD-PROGRAMMABLE GATE ARRAYS, P15, DOI 10.1145/3020078.3021741
   Zisserman A., 2014, 14091556 ARXIV
NR 31
TC 3
Z9 4
U1 0
U2 5
PD JAN
PY 2019
VL 8
IS 1
AR 78
DI 10.3390/electronics8010078
WC Computer Science, Information Systems; Engineering, Electrical &
   Electronic; Physics, Applied
DA 2023-11-11
ER

PT C
AU Tri, N
   Becchi, M
AF Tri Nguyen
   Becchi, Michela
GP IEEE
TI A GPU-accelerated Data Transformation Framework Rooted in Pushdown
   Transducers
SO 2022 IEEE 29TH INTERNATIONAL CONFERENCE ON HIGH PERFORMANCE COMPUTING,
   DATA, AND ANALYTICS, HIPC
SE International Conference on High Performance Computing
DT Proceedings Paper
CT 29th Annual IEEE International Conference on High Performance Computing,
   Data, and Analytics (HiPC)
CY DEC 18-21, 2022
CL Bangalore, INDIA
DE Finite state transducers; Pushdown transducers; Data transformation; GPU
   acceleration
ID FINITE-STATE TRANSDUCERS; ARCHITECTURE; EFFICIENT
AB With the rise of machine learning and data analytics, the ability to process large and diverse sets of data efficiently has become crucial. Research has shown that data transformation is a key performance bottleneck for applications across a variety of domains, from data analytics to scientific computing. Custom hardware accelerators and GPU implementations targeting specific data transformation tasks can alleviate the problem, but suffer from narrow applicability and lack of generality.
   To tackle this problem, we propose a GPU-accelerated data transformation engine grounded on pushdown transducers. We define an extended pushdown transducer abstraction (effPDT) that allows expressing a wide range of data transformations in a memory-efficient fashion, and is thus amenable for GPU deployment. The effPDT execution engine utilizes a data streaming model that reduces the application's memory requirements significantly, facilitating deployment on high- and low-end systems. We showcase our GPU-accelerated engine on a diverse set of transformation tasks covering data encoding/decoding, parsing and querying of structured data, and matrix transformation, and we evaluate it against publicly available CPU and GPU library implementations of the considered data transformation tasks. To understand the benefits of the effPDT abstraction, we extend our data transformation engine to also support finite state transducers (FSTs), we map the considered data transformation tasks on FSTs, and we compare the performance and resource requirements of the FST-based and the effPDT-based implementations.
C1 [Tri Nguyen; Becchi, Michela] NC State Univ, Raleigh, NC 27606 USA.
RP Tri, N (corresponding author), NC State Univ, Raleigh, NC 27606 USA.
EM tmnguye7@ncsu.edu; mbecchi@ncsu.edu
CR A. Parquet, US
   Alur R, 2020, THEOR COMPUT SCI, V807, P15, DOI 10.1016/j.tcs.2019.11.018
   [Anonymous], PAND
   [Anonymous], CUD TOOLK
   [Anonymous], GNU SCI LIB
   [Anonymous], OP GPU DAT SCI
   [Anonymous], CANT COR
   [Anonymous], RAL OP DAT
   [Anonymous], INT MKL
   [Anonymous], 2003, SOSP, DOI 10.1145/1165389.945450
   Becchi M., 2008, P 4 ACM IEEE S ARCH, P50, DOI DOI 10.1145/1477942.1477950
   Bell N, 2009, STUDENTS GUIDE TO THE MA TESOL, P1
   Brodie BC, 2006, CONF PROC INT SYMP C, P191, DOI 10.1145/1150019.1136500
   Das T., 2012, P 9 USENIX C NETWORK, P2, DOI DOI 10.1111/J.1095-8649.2005.00662.X
   Dean J, 2004, USENIX ASSOCIATION PROCEEDINGS OF THE SIXTH SYMPOSIUM ON OPERATING SYSTEMS DESIGN AND IMPLEMENTATION (OSDE '04), P137
   Dlugosch P, 2014, IEEE T PARALL DISTR, V25, P3088, DOI 10.1109/TPDS.2014.8
   Fang YW, 2015, PROCEEDINGS OF THE 48TH ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO-48), P533, DOI 10.1145/2830772.2830809
   Filiot E, 2018, J COMPUT SYST SCI, V97, P147, DOI 10.1016/j.jcss.2018.05.002
   Grathwohl BB, 2016, ACM SIGPLAN NOTICES, V51, P284, DOI 10.1145/2914770.2837647
   Kanev S, 2016, IEEE MICRO, V36, P54, DOI 10.1109/MM.2016.38
   Khairoutdinov MF, 2001, GEOPHYS RES LETT, V28, P3617, DOI 10.1029/2001GL013552
   Kourtis K, 2011, ACM SIGPLAN NOTICES, V46, P247, DOI 10.1145/2038037.1941587
   Langr D, 2016, IEEE T PARALL DISTR, V27, P428, DOI 10.1109/TPDS.2015.2401575
   Liu HY, 2018, 2018 51ST ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE (MICRO), P908, DOI [10.1109/MICRO.2018.00078, 10.1109/MICR0.2018.00078]
   Liu WF, 2015, PROCEEDINGS OF THE 29TH ACM INTERNATIONAL CONFERENCE ON SUPERCOMPUTING (ICS'15), P339, DOI 10.1145/2751205.2751209
   Meduna A., 2000, AUTOMATA LANGUAGES T
   Mitra A., 2007, PROC 2007 ACMIEEE S, P127
   Mohri M, 1997, COMPUT LINGUIST, V23, P269
   Mohri M, 2002, COMPUT SPEECH LANG, V16, P69, DOI 10.1006/csla.2001.0184
   Moon SK, 2019, MULTIMED TOOLS APPL, V78, P22045, DOI 10.1007/s11042-019-7503-x
   Nishtala Rajesh, 2013, P 10 USENIX S NETW S, P385
   Ousterhout K., 2015, NSDI, P293
   Page L., 1999, PAGERANK CITATION RA, VVolume 8090, P422, DOI DOI 10.1007/978-3-319-08789-4_10
   Papadimitriou C. H, 1994, COMPLEXITY THEORY
   Qiu JQ, 2021, ASPLOS XXVI: TWENTY-SIXTH INTERNATIONAL CONFERENCE ON ARCHITECTURAL SUPPORT FOR PROGRAMMING LANGUAGES AND OPERATING SYSTEMS, P887, DOI 10.1145/3445814.3446705
   Sadredini E, 2019, MICRO'52: THE 52ND ANNUAL IEEE/ACM INTERNATIONAL SYMPOSIUM ON MICROARCHITECTURE, P87, DOI 10.1145/3352460.3358324
   Safieh M, 2019, IET CIRC DEVICE SYST, V13, P576, DOI 10.1049/iet-cds.2018.5017
   Sidhu R., 2001, 9 ANN IEEE S FIELD P, P227, DOI DOI 10.1109/FCCM.2001.22
   Stuedi P., 2014, P ACM S CLOUD COMPUT, P1, DOI 10.1145/2670979.2670994
   Su B.-Y., 2012, P 26 ACM INT C SUPER, P353, DOI DOI 10.1145/2304576.2304624
   Sugimoto T, 2017, IEEE T BROADCAST, V63, P426, DOI 10.1109/TBC.2017.2687699
   T. A. University, SUIT MATR COLL
   van Lunteren J, 2012, INT SYMP MICROARCH, P461, DOI 10.1109/MICRO.2012.49
   Veanes M, 2012, POPL 12: PROCEEDINGS OF THE 39TH ANNUAL ACM SIGPLAN-SIGACT SYMPOSIUM ON PRINCIPLES OF PROGRAMMING LANGUAGES, P137
   Wadden J, 2018, INT S HIGH PERF COMP, P749, DOI 10.1109/HPCA.2018.00069
   Wang H, 2019, IEEE T VLSI SYST, V27, P2423, DOI 10.1109/TVLSI.2019.2921249
   Yu X., 2013, P ACM INT C COMPUTIN, DOI [10.1145/2482767.2482791, DOI 10.1145/2482767.2482791]
   Zhang Y, 2010, ACM SIGCOMM COMP COM, V40, P20, DOI 10.1145/1880153.1880157
   Zhao Y, 2018, ACM SIGPLAN NOTICES, V53, P94, DOI 10.1145/3200691.3178495
   Zhao ZJ, 2015, ACM SIGPLAN NOTICES, V50, P619, DOI [10.1145/2694344.2694369, 10.1145/2775054.2694369]
   Zu Y, 2012, ACM SIGPLAN NOTICES, V47, P129, DOI 10.1145/2370036.2145833
NR 51
TC 0
Z9 0
U1 0
U2 0
PY 2022
BP 215
EP 225
DI 10.1109/HiPC56025.2022.00038
WC Computer Science, Hardware & Architecture; Computer Science, Information
   Systems; Computer Science, Theory & Methods
DA 2023-11-11
ER

PT C
AU Liu, G
   Primmer, J
   Zhang, ZR
AF Liu, Gai
   Primmer, Joseph
   Zhang, Zhiru
GP ACM
TI Rapid Generation of High-Quality RISC-V Processors from Functional
   Instruction Set Specifications
SO PROCEEDINGS OF THE 2019 56TH ACM/EDAC/IEEE DESIGN AUTOMATION CONFERENCE
   (DAC)
DT Proceedings Paper
CT 56th ACM/EDAC/IEEE Design Automation Conference (DAC)
CY JUN 02-06, 2019
CL Las Vegas, NV
AB The increasing popularity of compute acceleration for emerging domains such as artificial intelligence and computer vision has led to the growing need for domain-specific accelerators, often implemented as specialized processors that execute a set of domain-optimized instructions. The ability to rapidly explore (1) various possibilities of the customized instruction set, and (2) its corresponding micro-architectural features is critical to achieve the best quality-of-results (QoRs). However, this ability is frequently hindered by the manual design process at the register transfer level (RTL). Such an RTL-based methodology is often expensive and slow to react when the design specifications change at the instruction-set level and/or micro-architectural level.
   We address this deficiency in domain-specific processor design with ASSIST, a behavior-level synthesis framework for RISC-V processors. From an untimed functional instruction set description, ASSIST generates a spectrum of RISC-V processors implementing varying micro-architectural design choices, which enables effective tradeoffs between different QoR metrics. We demonstrate the automatic synthesis of more than 60 in-order processor implementations with varying pipeline structures from the RISC-V 32I instruction set, some of which dominate the manually optimized counterparts in the area-performance Pareto frontier. In addition, we propose an autotuning-based approach for optimizing the implementations under a given performance constraint and the technology target. We further present case studies of synthesizing various custom instruction extensions and customized instruction sets for cryptography and machine learning applications.
C1 [Liu, Gai; Primmer, Joseph; Zhang, Zhiru] Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA.
   [Liu, Gai] Xilinx Inc, San Jose, CA 95124 USA.
RP Liu, G (corresponding author), Cornell Univ, Sch Elect & Comp Engn, Ithaca, NY 14850 USA.; Liu, G (corresponding author), Xilinx Inc, San Jose, CA 95124 USA.
EM gai.liu@xilinx.com; jp2228@cornell.edu; zhiruz@cornell.edu
CR [Anonymous], 2017, VIVADO DESIGN SUITE
   [Anonymous], 2017, INT S COMP ARCH ISCA
   [Anonymous], 2014, INT S COMP ARCH ISCA
   Ansel J, 2014, INT CONFER PARA, P303, DOI 10.1145/2628071.2628092
   Arvind R. S. Nikhil, 2004, INT C COMP AID DES I
   Asanovic K., 2014, UCBEECS2014146 EECS
   Borkar S, 2011, COMMUN ACM, V54, P67, DOI 10.1145/1941487.1941507
   Buchty R., 2004, INT C ARCH COMP SYST
   Celio C, SODOR PROCESSOR COLL
   Choudhary N. K., 2011, INT S COMP ARCH ISCA
   Cong J., 2014, DESIGN AUTOMATION C
   Cong J, 2011, IEEE T COMPUT AID D, V30, P473, DOI 10.1109/TCAD.2011.2110592
   Dreesen R., 2012, INT C HARDW SOFTW CO
   Gonzalez RE, 2000, IEEE MICRO, V20, P60, DOI 10.1109/40.848473
   Hara Y., 2008, INT S CIRC SYST ISCA
   LEISERSON CE, 1991, ALGORITHMICA, V6, P5, DOI 10.1007/BF01759032
   Mishra P., 2004, ACM T DES AUTOMAT EL, V11, P626
   Mokhov A, 2014, IEEE T COMPUT, V63, P1551, DOI 10.1109/TC.2013.37
   Nurvitadhi E, 2011, IEEE T COMPUT AID D, V30, P441, DOI 10.1109/TCAD.2010.2088950
   Schliebusch O., 2002, AS S PAC DES AUT C A
   Zhu Q., 2018, U.S. Patent, Patent No. 9965824
NR 21
TC 2
Z9 2
U1 0
U2 1
PY 2019
DI 10.1145/3316781.3317890
WC Computer Science, Software Engineering; Computer Science, Theory &
   Methods
DA 2023-11-11
ER

PT C
AU Kybaniec, R
   Przygoda, K
   Ayvazyan, V
   Branlard, J
   Butkowski, L
   Cichalewski, W
   Pfeiffer, S
   Schmidt, C
   Schlarb, H
   Sekutowicz, J
AF Kybaniec, Radoslaw
   Przygoda, Konrad
   Ayvazyan, Valeri
   Branlard, Julien
   Butkowski, Lukasz
   Cichalewski, Wojciech
   Pfeiffer, Sven
   Schmidt, Christian
   Schlarb, Holger
   Sekutowicz, Jacek
GP IEEE
TI FPGA Based RF and Piezo Controllers for SRF Cavities in CW Mode
SO 2016 IEEE-NPSS REAL TIME CONFERENCE (RT)
DT Proceedings Paper
CT IEEE-NPSS Real Time Conference (RT)
CY JUN 06-10, 2016
CL ITALY
AB Modern digital low level radio frequency (LLRF) control systems used to stabilize the accelerating field in facilities such as Free Electron Laser in Hamburg (FLASH) or European X-Ray Free Electron Laser (E-XFEL) are based on the Field Programmable Gate Array (FPGA) technology. Presently these accelerator facilities are operated with pulsed RF. In future, these facilities should be operated with continuous wave (CW) which requires significant modifications on the real-time feedbacks realized within the FPGA. For example, higher loaded quality factor of the cavities when operated in a CW mode requires sophisticated resonance control methods. However, iterative learning techniques widely used for machines operated in pulsed mode are not applicable for CW. In addition, the mechanical characteristic of the cavities have now a much more important impact on the choice of the feedback scheme. To overcome the limitations of classical PI-controllers novel real-time adaptive feed forward algorithm is implemented in the FPGA. Also, the high power RF amplifier which is an inductive output tube (IOT) for continuous wave operation instead of a klystron for the pulsed mode has major impact on the design and implementation of the firmware for regulation. In this paper, we report on our successful approach to control multi-cavities with ultra-high precision (dA/A<0.01%, dphi<0.02 deg) using a single IOT source and individual resonance control through piezo actuators. Performance measurements of the proposed solution were conducted at Cryo Module Test Bench (CMTB) facility.
C1 [Kybaniec, Radoslaw] Warsaw Univ Technol, PL-00661 Warsaw, Poland.
   [Przygoda, Konrad; Ayvazyan, Valeri; Branlard, Julien; Butkowski, Lukasz; Pfeiffer, Sven; Schmidt, Christian; Schlarb, Holger; Sekutowicz, Jacek] Deutsch Elektronen Synchrotron DESY, D-22607 Hamburg, Germany.
   [Cichalewski, Wojciech] Lodz Univ Technol TUL, PL-90924 Lodz, Poland.
RP Kybaniec, R (corresponding author), Warsaw Univ Technol, PL-00661 Warsaw, Poland.
EM rrybanie@mion.elka.pw.edu.pl
CR Kuo SM, 1999, P IEEE, V87, P943, DOI 10.1109/5.763310
   Przygoda K., 2011, THESIS
   Rutkowski I., 2015, IEEE T NUCL SCI
   Rutkowski I, 2013, IEEE T NUCL SCI, V60, P3609, DOI 10.1109/TNS.2013.2278372
   Rybaniec R., 2014, P 5 INT PART ACC C
   Schilcher T., 1998, THESIS
   Sekutowicz J, 2015, PHYS REV SPEC TOP-AC, V18, DOI 10.1103/PhysRevSTAB.18.050701
   [No title captured]
NR 8
TC 0
Z9 0
U1 0
U2 1
PY 2016
WC Computer Science, Hardware & Architecture; Engineering, Electrical &
   Electronic
DA 2023-11-11
ER

EF